university,konu,tr,en
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Duyarga düğümleri kısa mesafelerde iletişim kurma yetisine sahip, belirli amaçlarayönelik bilgi toplayabilen elektromekanik cihazlardır. Duyarga düğümleri genellikleküçük, düşük enerji tüketen, pil gücü zayıf ve kısıtlı hesaplama yapmaya uygun biryapıya sahiptirler. Bir duyarga ağında, geniş bir alana dağılmış çok miktarda duyargacihazı vardır. Herhangi iki duyarga düğümü arasında güvenli bir iletişim için, güvenli veşifrelenmiş bir hat oluşturmak gerekir. Güvenli bir hat oluşturmak için gerekli olan ortakanahtar türetmek işi, duyarga düğümlerinin kısıtlı kaynaklara sahip olmaları yüzündenbasit bir şekilde yapılamaz. Genel anlamda ağlar için önerilen açık anahtarlı şifrelemeyöntemi, kısıtlı kaynakları sebebiyle duyarga ağları için uygun değildir. Ayrıca, duyargaağları güvenilir bir altyapıya sahip olmadıkları için, anahtarların ve diğer güvenlikbilgilerinin duyarga düğümlerine konuşlandırma öncesi yüklenmesi gereklidir. Bu tipşemalara ön-yüklemeli anahtar dağıtım şemaları denir. Konuşlandırma sonrası duyargadüğümleri, önceden yüklenmiş olan anahtarları ve diğer güvenlik bilgilerini değişikmetotlarda kullanarak güvenli hat oluştururlar.Bu tezde, rastlantısal ön yüklemeli bir anahtar dağıtım mekanizması önerilmektedir.Önerilen yöntemde, duyarga cihazlarının konuşlandırma sonrası konumlarına ait bazıbilgilere kısmen sahip olunabileceği kabul edilmektedir. Kullanılan şemada, duyargadüğümleri arasında iki sıralı bir yapı mevcuttur. Duyarga ağını iki tip düğüm oluşturur:sıradan ve aracı düğümler. Aracı duyarga düğümleri duyarga ağının az bir kısmınıoluşturur ve sıradan duyarga düğümlerine göre daha gelişmiş özelliklere sahiptir.Önerilen yöntemin performans analizi simülasyonlar ile yapılmıştır ve analiz sonuçlarıgöstermektedir ki, önerilen anahtar dağıtım yöntemi yüksek bağlanabilirlik özelliğinesahiptir. Ayrıca, önerilen anahtar dağıtım yöntemi ufak çaplı saldırılara karşı güçlüdayanıklılığa sahiptir. Tezde önerilen yöntemin bir başka özelliği de kolay bir şekildeölçeklenebilir olmasıdır. Bununla birlikte, önerilen yöntem duyarga düğümükopyalanması ve wormhole saldırılarına karşı dayanıklıdır.","Sensor nodes are low power, tiny, and computationally restrictedmicroelectromechanical devices that usually run on battery. They are capable ofcommunicating over short distances and of sensing information for specific purposes. Insensor networks, large amount of sensor nodes are deployed over a wide region. Forsecure communication among sensor nodes, secure links must be established via keyagreement. Due to resource constraints, achieving such key agreement in wireless sensornetworks is non-trivial. Many key establishment schemes, like Diffie-Hellman andpublic-key cryptography based protocols, proposed for general networks are not sosuitable for sensor networks due to resource constraints. Since one cannot generallyassume a trusted infrastructure, keys and/or keying materials must be distributed tosensor nodes before deployment of them. Such key distribution schemes are called keypredistribution schemes. After deployment, sensor nodes use predistributed keys and/orkeying materials to establish secure links using various techniques.In this thesis, we propose a probabilistic key predistribution scheme, in which weassume that certain deployment knowledge is available prior to deployment of sensornodes. We use a two-tier approach in which there are two types of nodes: regular nodesand agent nodes. Agent nodes, which constitute a small percentage of all nodes, are morecapable than regular nodes. Most of the regular nodes can establish shared keys amongthemselves without the help of agent nodes, whereas some other regular nodes make useof agent nodes as intermediaries for key establishment. We give a comparative analysisof our scheme through simulations and show that our scheme provides good connectivityfor the sensor network. Moreover, our scheme exhibits substantially strong node-captureresiliency against small-scale attacks, while the resiliency of the network degradesgracefully as the number of captured nodes increases. In addition, the proposed scheme isscalable such that increasing the number of nodes in the network does not degrade theperformance and does not increase the complexity. Another good characteristic of ourscheme is that it is resistant against node fabrication and partially resistant againstwormhole attacks."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar teknolojisi ve yazılım mühendisliËindeki ilerlemelerle, sistemleru ggitgide daha büyüyor ve karmaşıklaşıyor. Sıradan test metodları bu karmaşıklıklauu s s sbaşetmekte yetersiz kalıyor ve hizmet kalitesini korumak işin daha düzenli tests c umetodları gerekiyor.Kontrol dizileri, sonlu durumlu davranış modellerine dayanan ve belli koşullars saltında test edilen sistem hakkında garantiler verebilen yapılardır. Ancak, karmaşıklıklarısyüksektir ve kullanılmalarını uygulanabilir kılmak işin uretim metodları geliştirilmelidir.u cü sBiz, ayırıcı serilerin varlıËında kontrol serisi uretiminde kullanılabilecek kimig ümetodları inceledik, esnek spesiï¬kasyonlardan net algoritmalar ureterek bunlarıüuyguladık ve metodların performanslarını karşılaştırdık. Ek olarak, daha kısasskontrol serilerinin uretimine olanak saËlayacak, şeşitli gelişmeler üneriyoruz. Buü g cs s ogelişmelerin, kontrol serilerinin kullanılabileceËi şerveşenin gelişmesini saËlamadas gc c s gyararlı olacaËına inanıyoruz.g","With advances in computer technology and software engineering, systems areconstantly becoming larger and more complex. Straightforward testing methodsare insuï¬cient to cope with the complexity and maintaining quality of servicedemands the use of more structured testing methods.Checking sequences are testing mechanisms based on ï¬nite state behaviormodels that can oï¬er guarantees about a system under test, under certain as-sumptions. However, their complexities are high, and to make their implemen-tation feasible methods of their construction need to be reï¬ned.We have studied several methods of checking sequence construction in thepresence of distinguishing sequences, developed fully formed algorithms fromloose speciï¬cations, then implemented and compared their performances. Wehave also proposed several improvements that will allow generation of shorterchecking sequences. We are conï¬dent that these developments will be instru-mental in making the use of checking sequences feasible in a larger scope."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"A ba lantılı kontrol sitemlerinin getirileri çe itlidir ve sanayinin geli imininbirçok talebine kar ılık vermektedir. Günden güne karma ıkla an sorunlarlabirlikte a ba lantılı kontrol sistemleri bir kolaylık olmaktan ziyade vazgeçilmezbir unsur olacaklardır. A üzerinden kontrol yapan sistemlerin getirileri oldu ugibi gecikmelerden ötürü olu an belirsizlikler birtakım sorunları da beraberindegetirir. Bu gecikmelerin sebebi haberle me ortamındaki zaman payla ımı ilekontrol algoritmasını hesaplamak ve dijitalden analo a çevrim yapmak içingerekli zamanın de i ken olmasıdır. Gecikmelerin sistem performansı üzerindedenge bozucu etkisi vardır. Bilgisayarların ve bilgisayar a larının süratı yakınzamanda kaydade er artı göstermi tir. En çok veriyi aktarmak üzere optimizeedilmi tir olan bilgisayar sistemlerinin gercek zamanlı karakterleri kontrol bakıaçısıyla özel bir verinin süratli transferi icin optimize edilmemi tir.Bu ko ullardaçalı abilen hatta bu ko ulları avantaja çevirerek kullanan kontrol sistemleripiyasaya çıkmaktadır.Bu çalı ma öncelikle a ba lantılı kontrol sistemleri ile ilgili tasarım ve uygulamaalanındaki güncel geli melerden bahsetmektedir. Ardından gürültülü ve idealolmayan network ko ullarında çalı abilen yeni bir a ba lantılı kontrol sistemimimarisi tanıtılmaktadır. Önerilen a ba lantılı kontrol sistemi mimarisi kontrolviedilen sistemin modelinden faydalanarak tesisin gelecekteki halini thamin ederekbu hallere de uygulanması gereken kontrol siynallerini üretmektedir. Bu sinyallereöngörülen sinyaller denmektedirler. Kontrol birimi eyleyici birimine gerçekde erlerden ve öngörülen de erlerden yola çıkılarak hesaplanan bir sinyal paketiyollamaktadır. Bu paketteki sinyaller kontrol edilecek sistemi belirli bir sürekontrol edebilecek özelliktedir fakat ideal ko ullar altında bu paketteki sinyallerinço u kullanılmamktadır. Kopukluk olması durumunda ise en son yollananpaketteki öngörülen sinyaller kullanılmaya ba lanır. Bu sayede kontrol edileceksistem a da kopukluk olması durumunda öngörülmü ekilde kontroledilebilmektedir. Bunun neticesinde sitem dengesini bozmamaktadır amakaçınılmaz olumsuzluk olarak referans sinyalinin kontrol edilen sisteme etkimesigecikir. Bu yakla ımda model kullanıldı ı için ve zaman kar ı hassas birçokalgoritma oldu u için e zamanlama çok önemlidir. Kontrol birimi ile eyleyicibirim arasında olu abilecek e zamanlama sorunların sebebi kullanılan sistemmodelinin durumu ile geçek sistemin durumunun biribirinden farklıla masıdır. Busorun eyleyici tarafında kullanılan ve gelen konrol paketlerinden güvenilmezolanları ayıklayan bir algoritma tarafından çözülmektedir. Algılayıcı birimi vekontrol birimi arasında olu abilecek e zamanlama sorunları da kontrol birimindeuygulanan algoritmanın da ıtık bir yapıda uygulanmasıyla çözülmü tür.Algılayıcı biriminden bir a paketi geldi i zaman, kontrol biriminin kullanaca ızamana ba lı de i kenler hesaplanmı olarak gelmektedirler. Bu sayede kontrolbirimi algılayıcıdan yeni bir a paketi aldı ı anda e zamanlama tamamlanmıolacaktır.Önerilen a ba lantılı kontrol sistemi mimarisi bir DC motor üzerinde simüleedilmi tir. Sitemin a üzerinde olu an verikaybına kar ı dayanıklılı ı sınanmı tırve önerilen sistemin veri kaybına kar ı dayanıklı oldu u tespit edilmi tir. Verikaybının kaçınılmaz neticesi olarak referans sinyalinin kontrol edilen sistemeuygulanmasında gecikme görülmü tür. Gürültünün de sistem üzerindeki etkisiincelenmi tir. A da olu an dü ük miktarlardaki veri kaybının sistem üzerindeetkisin az oldu u görülmü tür. Ama veri kaybının yüzdesi arttıkça sistemingeribesleme döngüsünde olu an kopukluk yüzünden kontrol birimi hatadanhaberdar olamamakta ve sistemde olu an hatalara müdahale edememektedir.Son olarak öngörü penceresinin boyutunu belirlemek için bir metotönerilmektedir. Sistemin maksimum refererans de i ikli inde yatı ma süresiviiincelenmetedir. Öngörü penceresinin yatı ma süresi kadar tutulması yapılacaki lem yükünü en az seviyede tutmaktadır. Bu metot yanlızca açık döngüde kararlısitemler için geçerlidir.viii","Advantages of networked control systems (NCS) are very diverse and NCS?saddress many of the demands of industrial development. As more and moresophisticated problems arise, networked control systems will not only become aconvenience or an advantage but they will become an indispensable necessity.However usage of networked control systems introduces different forms of time-delay uncertainty in closed-loop system dynamics. These time delays are causedby the time sharing of the communication medium as well as computation timenecessary for control algorithms and digital to analog conversions and have adestabilizing effect on system performance.Computational power of computers has increased dramatically; networks speedhas also increased. Although both the network and computer architectures havetended to improve throughput over time, their real-time characteristics have notevolved to match the requirements from a control point of view. New controlmethodologies that cope with these factors and even take advantage of them areemerging.This work first examines some current methods in design and implementation ofnetworked control systems that try to improve existing methods. Then a novelivnetworked control system architecture that runs under non ideal networkconditions with packet loss and noise is introduced. The proposed network controlsystem architecture uses a model to predict the plant states into the future andgenerate corresponding control signals, then an array of the predicted controlsignals is sent to the actuator node side of the NCS rather than a single controlsignal like in basic networked control systems. This array of signals can controlthe plant if they are applied consecutively with sampling time intervals. Howeverthis is not the case under ideal conditions, where the network is lossless. Only thefirst control signal in each array is applied to the plant as a newer packet arrivesevery sampling period. The remainder of the array of predicted control signals isonly used when packet loss occurs. This approach enables the system to becontrolled in a pre-simulated manner and stability can be maintained even withhigh packet loss probabilities. Synchronization of the network elements becomesa major problem in this approach since models are involved. Synchronizing theactuator and controller nodes is done by an algorithm that can identify controlsignal arrays that have trustable information. Also the controller has a distributedarchitecture; some parts of the controller are implemented in the sensor node. Thisis to ensure that sensor to controller synchronization is not broken.The proposed model based predictive networked control system architecturewas tested on a DC motor. The effects of packet loss were examined to reveal thatthe packet loss does not cause destabilization of the system, when packet lossoccurs and the control packet cannot be sent to the actuator node, which preventsthe changes in reference from being applied to the plant. The overall effect is theretardation of the response of the plant to the reference. Effects of noise are alsoexamined. Under low packet loss conditions noise does not have an unusual effecton the system but when packet loss increases noise cannot be tolerated becausethe feedback loop is interrupted due to packet loss.Finally a method for determining the number of predictions to be made atthe controller node (the prediction horizon) is suggested. The systems settlingtime is examined and the settling time is taken as the basis for the predictionhorizon. The transmission of a single array of control signals from the controllernode to the actuator node will enable the system to reach the desired reference.However this approach is only valid for open loop stable systems.v"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde üretilen ürünlerin mikrometre seviyelerine varanminyatürle tirilmeleriyle ve mikrosistem üretim teknolojisinde olan son zamanlardakigeli melerle, karma ık melez mikrosistemler olu turmak için gerekli olan montajsürecine büyük bir ihtiyaç duyulmaktadır. De i ik materyallerden ve de i ikmikroüretim teknolojileriyle üretilmi mikro parçaların entegrasyonu; manipüleedilecek parçaların boyutlarının küçük olması, yüksek hassasiyet gereksinimi ve mikrodünyaya özel birtakım problemlerden kaynaklanan bazı ana sorunların henüz daha tamolarak incelenmemi olmasından dolayı mikrosistem teknolojisinde halen en temelsorunlardan birini olu turmaktadır.Bu tezde, mikroüretim teknikleriyle üretilmi parçaların verimli ve güvenilir birekilde montajlarının yapılması amaçlanılarak açık-mimarili ve yenidenyapılandırılabilir bir mikro montaj i istasyonunun tasarımı ve uygulaması sunulmu tur.istasyonu, mikromontaj alanındaki problemlerin incelenebilmesine olanak sa lamakamacıyla bir ara tırma aracı olarak tasarlanmı tır.Bu tip bir i istasyonunun geli tirilmesi u tasarım süreçlerini içermektedir. (i)mikromontaj görevlerini gerçekle tirebilmek için gerekli olan hareket mesafesi vehassasiyeti sa layabilecek hareket platformlarını içeren bir manipülasyon sistemi, (ii)mikro dünyayı görselle tirmek ve montajı yapılacak mikro parçaların konumunu veviyönelimlerini belirlemek için bir görü sistemi, (iii) Gürbüz bir kontrol sistemi ve sistemintanımlanmı görevlere hazır olabilmesi için gerçekle tirilecek olan göreve uygunmanipülasyon araçlarının kolaylıkla sisteme entegrasyonunu sa lamak için gereklisonlandırıcı ba lama fikstürleri. Bunlara ek olarak tasarlanan mikro sistemde uzaktankomutalı ve yarı otomatik montaj kavramları da gerçekle tirilmi tir.Tasarımın uygulanılabilirli i, mikro parçaların manipülasyonunu içeren çe itlimontaj görevlerinin gerçekle tirilmesiyle do rulanmı tır. istasyonunun çok yönlülü üyapılan deneylerle kanıtlanmı olup konumlandırmada yüksek hassasiyetlere ula ıldı ıgösterilmi tir.vii","With the miniaturization of products to the levels of micrometers and the recentdevelopments in microsystem fabrication technologies, there is a great need for anassembly process for the formation of complex hybrid microsystems. Integration ofmicrocomponents made up of different materials and manufactured using differentmicro fabrication techniques is still a primary challenge since some of the fundamentalproblems originating from the small size of parts to be manipulated, high precisionnecessity and specific problems of the microworld in that field are still not fullyinvestigated.In this thesis, design and development of an open-architecture and reconfigurablemicroassembly workstation for efficient and reliable assembly of micromachined partsis presented. The workstation is designed to be used as a research tool for investigationof the problems in microassembly. The development of such a workstation includes thedesign of: (i) a manipulation system consisting of motion stages providing necessarytravel range and precision for the realization of assembly tasks, (ii) a vision system tovisualize the microworld and the determination of the position and orientation of microcomponents to be assembled, (iii) a robust control system and necessary fixtures for theend effectors that allow easy change of manipulation tools and make the system readyivfor the desired task. In addition tele-operated and semi-automated assembly conceptsare implemented.The design is verified by implementing tasks in various ranges for micro-partsmanipulation. The versatility of the workstation is demonstrated and high accuracy ofpositioning is shown.v"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mevcut yüz tanıma algoritmalarinin başarımı düşük çözünürlüklü yüz imgelerineuygulandıklarında önemli ölçüde azaltmaktadır. Bu problemin çözmek için çözürlülükarttırma yöntemleri piksel alanında yahut yüz alt-uzayında uygulanabilmektedir. Yüzimgeleri coğu yüz tanıma işlevi açısından gereksiz yüksek boyutlu verilerden oluşur, bu daboyut düşüren öznitelik çıkarma yöntemlerini yüz analizinde standart uygulama halinegetirmiştir. Dolayısıyla çözünürlülük artırma yöntemlerini piksel alani yerine öznitelikalanında, bir başka deyişle yüz alt-uzayında, uygulamanın hesaplamalar açısından yararlarıolduğu gibi gürültüye ve hareket kestirimi hatalarına karşı gürbüzlüğü de sağlamıştır. Bunedenle, biz Bayesçi kestirim ve dışbükey kümelere izdüşüm yöntemleriyle öznitelik tabanlıçözünürlülük arttırıcı yeni algoritmalar önermekte ve önerilen yöntemleri literatürde mevcutolanlar ile karşılaştırmalı analizini sunmaktayız.","Performance of current face recognition algorithms reduces significantly when they areapplied to low-resolution face images. To handle this problem, superresolution techniques canbe applied either in the pixel domain or in the face subspace. Since face images are highdimensional data which are mostly redundant for the face recognition task, feature extractionmethods that reduce the dimension of the data are becoming standard for face analysis.Hence, applying super-resolution in this feature domain, in other words in face subspace,rather than in pixel domain, brings many advantages in computation together with robustnessagainst noise and motion estimation errors. Therefore, we propose new super-resolutionalgorithms using Bayesian estimation and projection onto convex sets methods in featuredomain and present a comparative analysis of the proposed algorithms and those already inthe literature."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Cift taraï¬ı kontrol, iletişim ağıyla bağlı iki sistemin kuvvet ve pozisyonlarının ciftş s g g şyünlü olarak kontrolü demektir. Tipik olarak kuvvet geribeslemeli uzaktan kumandaou uËişin kullanılır.c Iki sistemden yakında olanı (efendi sistem) operatür tarafındanoyünetilir ve hareketleri uzaktaki (küle) sisteme iletilir. Bu hareketlerden doğano o gkuvvetler ise operatüre geri beslenir. Büylece operatürün uzak ortamda sanal varlığıo o ou gsağlanır.g Cift taraï¬ı kontrolün gerekliliği bağımsız robot kollarının tam olarakş u g gcüzemediği insanlarınsa erişemediği gürevlerde ortaya cıkar.şo g s go şCift taraï¬ı kontrol tasarım ve performansının ana etkenleri, şeï¬aï¬ık, ülşeklemeş s ocve gecikme olarak sayılabilir. Bu calışmada, bahsedilen etkenler ve yol aştıklarışs cproblemler hedeï¬enmiş, yüksek şeï¬aï¬ığa sahip ve ülşeklemeyi mümkün kılan bir ciftsu s g oc uu ştaraï¬ı denetleyici işin iki kesikli-zaman kayan kipli yaklaşım cüzümü getirilmiştir.c s şo u u sËIlk yaklaşımın kuvvet-melez yapısı işinde küle sistemi yüneten basamaklı kayans c o okipli melez kuvvet/pozisyon denetleyicisi dış kuvvetlere doğrudan tepki güsterir.s g oBüylece, uzak sistemde operatürün gecikme nedeniyle zamanında karşılık veremediğio ou s gyüksek dış kuvvetlere karşı bir korunma (reï¬eks) mekanizması sağlanmaktadır.u s s gËIkinci yaklaşım dağıtılmış bir niteliktedir. Bu yaklaşımda sistem uzayından gürevs g s s ouzayına düzlemsel bir dünüşum ile sanal sistemler elde edilmiş be kayan kipli kontrolu o usü ssanal sistemler uzerinde yapılmıştır. Bu denetleyicinin ünemi kontrol problemini,ü s ogürevleri sistemlere bülüştürerek merkezileştirmektense, doğrudan gürev gereksin-o o us u s g oimlerini hedeï¬emesidir. Büylece cift taraï¬ı kontrolün iki tarafı birbirinin yerineo ş ugeşebilir olmuştur. Denetleyicinin dağıtılmış yapısı problemi ikiden fazla sistem işinc s g s cişbirliği ya da eşgüdüm gibi problemlere genellemeye imkan sağlamaktadır.s g suu gËIki yaklaşım işin de deneylerle yüksek hassasiyet sağlanmıştır. Tezde kullanılans c u g skesikli zaman kayan kipli denetleyiciler detaylı olarak tasarlanmış ve aşıklanmıştır.","Bilateral control is bi-directional control of force-position between two systemsconnected by a communication link. It is typically used for teleoperation with forcefeedback, such that the master system is handled by an operator. Motions of theoperator are fed forward to the slave system, generally remote to the operator andforces encountered are fed back to the master system, enabling a telepresence ofthe operator in the remote environment. The necessity of bilateral control lies inits applicability to the tasks that cannot be handled by autonomous manipulatorsand/or reached by human beings.Main issues of consideration for bilateral control, namely transparency, scalingand time delay, are addressed and two discrete-time sliding-mode approaches arepresented as solutions to highly transparent bilateral controllers that support scal-ing.First approach has a force-hybrid architecture, where the cascaded sliding modehybrid force/position controller on the slave side reacts to the external forces directly.Therefore, it provides a protection (reï¬ex) mechanism on the slave side to largeexternal forces, that the operator cannot respond in time due to the time delay.Second approach has a decentralized nature. Virtual systems are devised bya linear transformation from the plant space to the task space and sliding modecontrol has been applied to those virtual systems, hence sides of bilateral controlare interchangable. The decentralized structure of the controller makes it possibleto generalize the problem to a coordination and/or cooperation of more than twoplants.High precision has been achieved on experiments for both approaches designedand discussed in detail."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Görsel izleme, görmeye dayalı kontrol, insan-makina arayüzü, gözetleme, tarımsalotomasyon, medikal imgeleme gibi birçok uygulama alanındaki sistemlerin önemli birbileşeni olmaya başlamıştır. Görsel izlemedeki temel sorun çerçeve dizisi boyunca bir veyabirden çok nesnenin duruşunu ve yerini izleyebilmektir.Örtük cebirsel 2 boyutlu eğriler en güçlü şekil temsil yöntemleri arasındadır ve modeltabanlı uygulamalardaki faydaları son yirmi yıllık süreçte kanıtlanmıştır. Bu yaklaşımla 2boyutlu imgelerdeki nesneler silüetleriyle tanımlanıp 2 boyutlu örtük polinom eğrileriyletemsil edilirler.Bu çalışmada, güçlü 2 boyutlu örtük cebirsel eğriler yöntemini görsel izleme olgusuiçerisinde etkin uygulamaya çalışan farklı yaklaşımlar denenmişitr. Önerilen kavramlar vealgoritmalar yoluyla, eğri uydurma algoritmalarının hesaplama karmaşıklığı azaltılmayaçalışılmıştır. Bu yöntemin kullanımı sınır veri benzetimleriyle gösterilmiş ve örtük cebirseleğrinin hedef bölgenin tanımlanmasında kullanıldığı gerçek video deneyleri degerçeklenmiştir.","Visual tracking has emerged as an important component of systems in severalapplication areas including vision-based control, human-computer interfaces, surveillance,agricultural automation, medical imaging and visual reconstruction. The central challenge invisual tracking is to keep track of the pose and location of one or more objects through asequence of frames.Implicit algebraic 2D curves and 3D surfaces are among the most powerfulrepresentations and have proven very useful in many model-based applications in the past twodecades. With this approach, objects in 2D images are described by their silhouettes and thenrepresented by 2D implicit polynomial curves.In our work, we tried different approaches in order to efficiently apply the powerfulimplicit algebraic 2D curve representation to the phenomenon of visual tracking. Through theproposed concepts and algorithms, we tried to reduce the computational burden of fittingalgorithms. Besides showing the usage of this representation on boundary data simulations,use of the implicit polynomial as a representative of the target region is also experimented onreal videos."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Telsiz mobil tasarsız ağlarda, uçtan-uca bağlantılarda, bağlantıyı işlemez hale getirmeyen fakat iletişimi kısa süreler için durduran kesikli bozulmalar olur. Bu kesikli bozulmalar genellikle, ağ elemanlarının (host) devingenliğinden, telsiz ortamın dinamik yapısından ve enerji tasarruf stratejilerinden kaynaklanır ve çoğuşma biçiminde (bursty) paket yitimlerine neden olur. Bu tip bir ortamda güvenilir iletişimin önemi, tasarsız ağlarda ses, video, veri gibi çeşitli çoğul ortam uygulamalarının ortaya çıkması ile artmaktadır. Bu tezde, ağdaki yolların kesikli kullanılabilirliğini yansıtan yeni bir yol güvenilirlik (path reliability) modeli ortaya konulmuş ve bu model üzerine, ağ güvenilirliğini iyileştirmek için bir yönlendirme stratejisi geliştirilmiştir. Geliştirdiğimiz yönlendirme stratejisi ağdaki yol çeşitliliğinden yararlanır ve verimliliği artırmak üzere çeşitleme kodlaması (diversity coding) kullanılır. Çeşitleme kodlaması yönteminde, özgün bilgi bir (N,K) kodu ile kodlanmışsa, alıcının gönderilen N bitlik bilgiden herhangi K bitlik bilgiyi alması, özgün bilginin elde edilmesi için yeterlidir. Bizim yöntemimizde, özgün bilgi N tane pakete bölünür ve paketler ağda var olan ayrışık yollar arasında dağıtılır. Paketlerin hangi yollara ne kadar dağıtıldıkları çok önemlidir. Paketler, yollara özgün bilginin alıcıda başarılı bir şekilde yeniden elde edilme olasılığım en yüksek kerteye çıkaracak biçimde 'akıllıca' yapılmalıdır. Yolların bozulma olasılıkları ve kodlama oram verildiğinde, önerdiğimiz strateji, her bir yol için o yol üzerinden gönderilecek paket sayısını, özgün bilginin alıcıda başarılı bir biçimde yeniden elde edilme olasılığım en yüksek kerteye çıkaracak biçimde bulur. Benzetim sonuçlan, yaklaşımımızın doğruluğunu ve verimliliğini destekler biçimdedir. Ayrıca, benzetim sonuçlan çokyollu yönlerdime stratejimizin ağ güvenilirliğini, bir yollu yönlendirmeye göre yeterince çok iyileştirdiğini göstermiştir. Telsiz ağlarda, sıkça kullanılan bir yöntem, batarya ömürlerini uzatmak amacıyla, ağ düğümlerinin az enerji tüketilen uyku kipine geçirilmesidir. Bu çalışmada, ağ düğümlerinin kesikli yararlanırlıklarının uyku/uyanık (sleep/awake) çevrimlerinden kaynaklandığı durumları da göz önünde bulundurduk. Paket gecikmesini en aza indiren ve aynı zamanda enerji tasarruf dizgesi tarafından belirlenen enerji tasarruf oranım sağlayan bir uyku/uyanık zamanlama stratejisi önerilmiştir.","ABSTRACT In wireless mobile ad hoc networks, end-to-end connections are often subject to failures which do not make the connection non-operational indefinitely but interrupt the communication for intermittent short periods of time. These intermittent failures usually arise from the mobility of hosts, dynamics of the wireless medium or energy-saving mechanisms, and cause bursty packet losses. Reliable communication in this kind of an environment is becoming more important with the emerging use of ad hoc networks for carrying diverse multimedia applications such as voice, video and data. In this thesis, we present a new path reliability model that captures intermittent availability of the paths, and we devise a routing strategy based on our path reliability model in order to improve the network reliability. Our routing strategy takes the advantage of path diversity in the network and uses a diversity coding scheme in order not to compromise efficiency. In diversity coding scheme, if the original information is encoded by using a (N,K) code, then it is enough for the destination to receive any K bits correctly out of N bits to successfully decode the original information. In our scheme, the original information is divided into N subpackets and subpackets are distributed among the available disjoint paths in the network. The distribution of subpackets among the diverse paths is a crucial decision. The subpackets should be distributed 'intelligently' so that the probability of successful reconstruction of the original information is maximized. Given the failure statistics of the paths, and the code rate (N, K), our strategy determines the allocation of subpackets to each path in such a manner that the probability of reconstruction of the original information at the destination is maximized. Simulation results justify the accuracy and efficiency of our approach. Additionally, simulation results show that our multipath routing strategy improves the network reliability substantially compared to the single path routing. In wireless networks, a widely used strategy is to place the nodes into a low energy consuming sleep mode in order to prolong the battery life. In this study, we also consider the cases where the intermittent availability of the nodes is due to the sleep/awake cycles of wireless nodes. A sleep/awake scheduling strategy is proposed which minimizes the packet latency while satisfying the energy saving ratio specified by the energy saving mechanism. IV"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu şalışma kalem ile giriş yapılabilen tablet PC, PDA, dışarıdan bağlanan kalemlics s s gpadler, elektronik yazı tahtaları gibi aygıtlarda yazılan elyazısı matematik denklem-lerin algılanmasını sağlayacak sistemin isterlerini ve parşalarını ele almaktadır.g cMatematik ifadeleri tanıyabilecek bir sistem integral, bülüm, ustler, indisler,ou ükarekükler, toplam sembolü vs. gibi matematiksel yapıları tanıyabilmelidir. Kağıto u guzerine kalem ile yazarak bu yapıların hepsini kolayca belirtmemiz mümkün olduğuü uu ghalde, şu ana kadar bilgisayara bu yapıları tanımlamak işin yeterince kolay birs cmetod geliştirilememiştir. Yukarıda saydığımız aygıtlar ve bu calışmada onerdiğimizs s g şs ü gmetod ile bilgisayar ortamında da yeterince kolay bir şekilde matematik yapılarınstanımlanabilmesi sağlanmıştır.g sBu aygıtlarda el yazısı dizisini elde etmek işin bir kalem kullanılmaktadır. Buckalemin cıktısının sayısallaştırılması ile, kalemin yazmaya başlaması ve yazmayış s sbitirmesi arasındaki noktaların koordinatları ve bu koordinatlara ait zaman bilgilerielde edilmektedir. Her bir kalem darbesi programımızın işerisinde bir koleksiyondactutulmaktadır.Her bir kalem darbesi bir yapay sinir ağından geşirilmekte ve bu ağdan gelen sem-g c gbol bilgisi, denklemin yapısal bilgisi ile birleştirilerek recursive bir okuyucu modüls utarafından okunmaktadır.Bu şalışmada onerilen sistemin arayüzü, aynı zamanda Microsoft'un Tablet PC-cs ü uuAPI'si işerisinde bulunan el yazısı tanıma modülünü de kullanmakta ve bu sayedec uu uhem matematik, hem de yazı girişini mümkün kılmaktadır. Bu sayede, tek birs uuarayüzde, hem matematik hem yazı işeren sayfaların oluşturulabilmektedir. Tanımau c sve okuma işlemleri tamamlandığında, tüm cıktılar birleştirilerek tek bir Latex kodus g uş soluşturulmakta ve bir PDF dosyası uretilmektedir.s üviii","This thesis presents a system for online handwritten mathematical expression recog-nition that involves integrals, summation notation, superscripts and subscripts,square-roots, fractions, trigonometric and logarithmic functions; together with auser-interface for writing scientiï¬c articles.The aim of this study is to utilize the most convenient man-machine-interface, apen, for input of mathematical expressions. In pen-enabled devices, handwriting se-quences are collected by the digitization of pen movements which outputs an arrayof coordinates called strokes.A neural network is trained for recognizing each stroke and a recursive algorithmparses the expression by combining neural network output and structure of the ex-pression.The interface associated with the proposed system integrates the built-in recog-nition capabilities of the Microsoft?s Tablet PC-API for recognizing textual inputand also supports conversion of hand-drawn ï¬gures into PNG format, which enablethe user to enter text, mathematics and draw ï¬gures in a single interface. After therecognition, all output is combined into one Latex code and compiled into a PDF ï¬le.The system presented in this thesis provides a natural interface, hence enables easy-input of mathematical expressions in all pen-enabled devices such as tablet PCs,PDAs, external tablet pads, electronic pen-boards etc.vi"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZEt Akıllı Anten (AA) sistemleri yüksek kalitede bağlara olanak tanımasının yanı sıra kablosuz kanalların uzaysal tekrar kullanımını sağlayarak ağda üretilen iş miktarını artırmaktadır. Ancak akıllı anten sistemlerinin başarımı saklı ve sağır istasyon problemleri yüzünden sınırlıdır. Bu çalışmada istasyonlarda tutulan tablolar yardımı ile bu problemleri ortadan kaldırmayı amaçlayan açısal tabanlı bir ortam erişim protokolü (ANMAC) önerilmektedir. ANMAC için değişik topolojilerde ve trafik senaryolarında ayrıntılı başarım analizi yapılmış, uzay bölmeli çoğullamaya (SDMA) tam olarak erişilebilmek için akıllı bir paket çizelgecisine ihtiyaç olduğu gösterilmiştir. Bununla beraber konum tabanlı çizelgelemeli ANMAC (ANMAC-LS) önerilmiş ve başarımı diğer akıllı anten yaklaşımlarıyla ve IEEE 802.11 MAC protokolü ile karşılaştırılmıştır. Akıllı anten kullanan kablosuz sistemlerde konum tabanlı çizelgelemenin etkisi ispatlanmış ve gerçek anten paternleri kullanılarak anten huzmesi yönlendirmesinin ağda iş çıkarmaya etkisi gösterilmiştir. Bununla birlikte istasyonların çarpışmayı önlemek amacıyla kullandığı çekişme penceresi değerinin ağın başarımına etkisi incelenmiştir. Bu değerin doğru ayarlanması ile ağda her zaman en yüksek başarımı elde etmek mümkündür. Çalışmamızda bu doğru değeri elde etmeye yarayan dinamik bir algoritma da sunulmuştur.","ABSTRACT Smart antenna systems not only enable users to have high quality links but also increase network throughput by allowing spatial reuse of wireless channels by the use of directional transmission. However performance of smart antenna systems is limited because of the increased hidden terminal problem and deafness of nodes. In this work, we have proposed the Angular MAC (ANMAC) protocol that avoids both problems through medium access tables in the nodes that keep track of the locations of the destination nodes as well as all communicating neighbors. We present detailed performance analysis of ANMAC considering different topologies and traffic scenarios, and we show that SDMA cannot be fully exploited without a smart scheduler. We have also proposed ANMAC with Location based Scheduling (ANMAC-LS) and compared its performance with other smart antenna approaches and omni 802.1 1 MAC. We prove the efficacy of location based scheduling in wireless networks with smart antennas, and we also show the effects of antenna orientation on throughput, using realistic antenna patterns and the ANMAC protocol. We have also analyzed the effect of contention window size on the performance of the network. By adjusting the contention window according to channel conditions, we can always get the maximum network throughput. We propose an updating algorithm for contention window, and we have analyzed the results both analytically and through simulations. IV"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"SIRALI TESTLER İLE SINIFLANDIRMA Özet Test düzenleme problemi adı da verilen, minimum maliyetle teşhis koymak için gerekli test sırası oluşturma problemi ele alınmıştır. Test düzenleme problemi, çözümünün NP-tam olduğu bilinen ikili VE/VEYA karar ağacı şeklinde formüle edilebilir. Problemin en iyi çözümü dinamik programlama ve ya VE/VE YA grafiği arama yöntemleriyle (AO*, CF, ve HS) elde edilebilir. Ancak büyük sistemlerde, di namik programlama ve ya VE/ VE YA arama yöntemleri, VE/VE YA arama grafiğinde hızla artan noktalar yüzünden, ağır hesaplamaları beraberinde getirmektedir. Bu hesaplama patlamasının üstesinden gelmek için, test düzenleme problemini çözecek bir-adım ya da çok-adım ileri bakma yöntemi algoritmaları geliştirildi. Bizim yaklaşımımız, bir-adım ileri bakma yöntemi algoritmalarıyla, Huffman kodlamasmda kullanılan stratejileri birleştirmektir. Algoritmaların etkinliği bir çok test durumu için gösterilmiştir. Geleneksel test düzenleme problemi asimetrik testler de katılarak genelleştirilmiştir. Test düzenleme problemine yaklaşımımız, karar tablosu problemi, tıbbî tanı, veri- tabanı sorgu işleme, kalite güvencesi, ve örüntü tanıma problemlerinde karşılaşılan ikili teşhis problemlerine uyarlanabilir. vıı","CLASSIFICATION VIA SEQUENTIAL TESTING Abstract The problem of generating the sequence of tests required to reach a diagnos tic conclusion with minimum average cost, which is also known as test sequencing problem, is considered. The test sequencing problem is formulated as an optimal binary AND/OR decision tree construction problem, whose solution is known to be NP-complete. The problem can be solved optimally using dynamic programming or AND/OR graph search methods (AO*, CF, and HS). However, for large systems, the associated computational effort with dynamic programming or AND/OR graph search methods is substantial, due to the rapidly increasing number of nodes in AND/OR search graph. In order to prevent the computational explosion, one-step or multistep lookahead heuristic algorithms have been developed to solve the test sequencing problem. Our approach is based on integrating concepts from the one- step lookahead heuristic algorithms and the strategies used in Huffman coding. The effectiveness of the algorithms is demonstrated on several test cases. The tradi tional test sequencing problem is generalized here to include asymmetrical tests. Our approach to test sequencing can be adapted to solve a wide variety of binary identification problems arising in decision table programming, medical diagnosis, database query processing, quality assurance, and pattern recognition. VI"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Geniş bilgisayar ağlan işleten organizasyonlar, bu ağlardaki bilgisayarların bakımım sağlamalıdırlar. Son zamanlarda, bu bakım işini uzman servis firmalarına devretmek genel bir iş pratiği haline gelmiştir. Servis firmaları güvenilir bulunmayabilir. Bu yüzden bakım teknisyeninin bilmesi gereken yerel bilgisayarların yönetici şifreleri periyodik olarak değiştirilmelidir. Ayrıca, teknisyenin bir bilgisayarın mevcut yerel yönetici şifresini öğrenmesinin bir yolu olmalıdır. Bu tezde, güvenli bir şifre senkronizasyonu ve sorgulama sistemi sunulmaktadır. Bu sistemde, bilgisayarların yerel yönetici şifreleri, sistemi idare eden bir sunucu ile senkronizasyon içinde belli aralıklarla değiştirilmektedir. Teknisyenler, bir bilgisayarın mevcut şifresini sunucuyu sorgulayarak öğrenebilirler. Senkronizasyon ve sorgulama mekanizmaları için simetrik ve asimetrik şifreleme tekniklerinin kullanıldığı üç güvenli protokol önermekteyiz. Bu tezde önerilen protokoller bir yazılım ürünü olarak gerçekleştirilmiştir. Ortalama başarılı senkronizasyon sayısı, bilgisayar sayısı 3.000'den 20.000'e artırıldığında sabit kalmaktadır. Sistemin davranışı, bilgisayar sayısındaki artıştan etkilenmemektedir. Ayrıca, sistemin kötü ağ koşullarına rağmen çalışmaya devam edecek şekilde ayarlanabileceği de gösterilmiştir. Uygulama detayları ve sistemin performans değerlendirilmesi bu tezde sunulmuştur.","ABSTRACT Organizations that run large computer networks should also provide maintenance for the computers on these networks. Nowadays, it is a common practice to outsource this maintenance task to specialized service firms. These service firms may not be considered trustworthy. Therefore, the local administrator password of a local machine that a maintenance technician needs to access should be changed periodically. Consequently, the technician needs a way to learn the current local administrator password of each computer. In this thesis, a secure password synchronization and querying system is presented. In this system, the local administrator passwords of computers are changed periodically in synchronization with a server managing the system. The maintenance technicians can learn the current password of a computer by querying the server. For synchronization and querying mechanisms, we propose three secure protocols that employ symmetric and asymmetric encryption techniques. Moreover, in this thesis, the proposed protocols are implemented as a software product and the performance of the system is evaluated by simulating the system. The average of the number of successful synchronizations stays constant when the number of computers is increased from 3,000 to 20,000 in the simulation. An increase in the number of computers doesn't change the behavior of the system. In addition, it is shown that the system can be configured to survive under rough network conditions. The implementation details and the performance evaluation of the system are presented in the thesis."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tez seri flaş belleklerin kontrolünü sağlayan devrenin sayısal olarak tasarımı, ve uygulanması aşamalarından oluşmuştur. İlk olarak seri flaş bellek kontrolör bloğunun da içerisinde bulunduğu işlemci platformu, seri flaş bellekler ve SPI (Serial Peripheral Interface) protokolü, seri flaş belleklerin kontrolündeki mevcut problemler için araştırılmıştır. Tezin uygulama bölümünde seri flaş bellek kontrolör bloğu VHDL (VHSIC Hardware Description Language-VHDL) kullanılarak sayısal olarak tasarlanmış, 0.35 um sayısal CMOS teknolojisi kullanılarak sentezlenmiş, fonksiyonel ve kapı seviyesinde test edilmiştir. Tezin son aşamasında, sentezlenmiş blok yerleştirme ve yol atama işlemlerinden geçirilmiştir. Seri flaş bellek kontrolör bloğunun jenerik olarak tasarlamasının yanında bloğun basit bir yazılıma ve minimum işlemci kontrolüne ihtiyaç duymasına büyük önem verilmiştir. Seri flaş belleğe transfer edilecek bilginin içeriği ve SPI (Serial Peripheral Interface) protokolüne uygun olarak gönderilmesi, seri flaş bellek kontrolör bloğu tarafından, işlemcinin programlandığı operasyona göre kontrol edilir. Seri flaş bellek kontrolör bloğu farklı seri flaş belleklerle kullanılabilir. Blok, işlemci tarafından seri flaş belleklerin farklı operasyonları için programlanabilir. Seri flaş bellek kontrolör bloğunun maksimum 20 MHz seri transfer hızına kadar çıkabilmektedir. Blok AMBA (Advanced Microcontroller Bus Architecture) APB (Advanced Peripheral Bus) arayüzü bulunan işlemci platformlarına entegre edilebilir.","ABSTRACT This thesis presents digital design and implementation of a controller module for serial flash memories. Firstly, the platform including the serial flash memory controller, flash memories and SPI (Serial Peripheral Interface) protocol have been investigated to solve the current problems related with controlling of serial flash memories. Then, in the implementation part of the thesis, the Serial Flash Memory Controller module has been designed by using VHDL (VHSIC Hardware Description Language-VHDL) and synthesized in CMOS 0.35 urn technology. Functional and gate-level simulations have been done with Cadence simulator. Lastly the final gate level netlist has been placed and routed with Cadence Silicon Ensemble. A great deal of attention has been given to design a generic controller that needs simple software and minimum processor access cycle. It is programmed from the processor for different operations of serial flash memories. The structure of the frame, control data and timings are controlled by hardware according to the programmed operation. In addition to this, our Serial Flash Memory Controller module can be used with different flash memories. This is very important property for reusability of the module. The Serial Flash Memory Controller module is capable to work up to 20 MHz serial communication speed and it can be integrated to processor platforms that have AMBA (Advanced Microcontroller Bus Architecture) APB (Advanced Peripheral Bus) interface. IV"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tez, adil takas problemini bazı özel durumlar için ele almaktadır. Genel olarak adil takas problemi, birbirlerine güvenmeyen iki tarafın rastgele seçtikleri verileri takas etme sorunu olarak tanımlanabilir. Bu iki taraf birbirlerine güvenmedikleri için, almayı bekledikleri verileri elde etmeden kendi verilerini yollamak istemezler. Bu iki tarafın farklı ülkelerde bulunması ve taraflardan birinin haksızlığa uğraması halinde, uluslar arası hukuk bürokrasisi yüzünden bu anlaşmazlığı çözmek para ve zaman gerektirebilir. Bu tezde adil takas probleminin özel bir uygulaması olan, büyük boyutlardaki elektronik mallar için adil e-ticaret protokolü tasarlanmış ve uygulanmıştır. Önerilen bu protokol elektronik para karşılığında elektronik mallan adil bir şekilde takas eder. Aynı zamanda takas edilen elektronik malların kalitesi ve içeriğinin kontrolünü de yapar. Sunulan bu protokol verimli bir şekilde çalışmaktadır. Öyleki, taraflardan hiçbiri hile yapmayı denemezse, sadece üç mesaj yeterlidir. Taraflardan biri hile yapmayı denerse, anlaşmazlığı çözmek için üç mesaja daha ihtiyaç olacaktır. Literatürde daha önce yapılan başka çalışmalarda önerilen protokollerde, elektronik mallar taraflar arasında birçok kez transfer edilmiştir. Bu durum elektronik malların büyük boyutlarda olması halinde yüksek maliyetlere sebep olmaktadır. Bu tezde önerilen protokolde elektronik mallar sadece bir kez transfer edilmektedir. Bu protokolün başka önemli bir özelliği ise müşterilerin kimlMerinin anonim bırakılmasıdır. Öyleki, protokol akışı sırasında müşterilerin alışveriş alışkanlıkları hakkında hiçbir bilgi toplanamamaktadır. Uygulama sonuçlan, adil e-ticaret protokolünün verimli, güvenilir ve az sayıda kriptografik operasyona ihtiyaç olduğunu göstermektedir. Bu tezde sunulan e-ticaret protokolü dışında yine adil takas probleminin özel bir uygulaması olan, ancak farklı bir yöntemle tasarlanmış ve uygulanmış bir adil çoğulortam takas protokolü sunulmaktadır. Bu protokolü tasarımının ardındaki amaç farklı tipdeki uygulamaların farklı yöntem gereksinimleridir. Adil çoğulortam takas protokolünde iki birey birbiri ile bazı çoğulortam dosyalannı (ör: görüntü veya ses dosyalan) takas etmek isterler. Bu protokol adil e-ticaret protokolüne göre daha azgüvenlik gerektirmekte ve daha düşük derecede adalet sağlamaktadır. Adil çoğulortam takas protokolünde bebek-adımları yöntemi kullanılmıştır. Bu yöntemde protokolünün başarılı bir biçimde tamamlanma olasılığı her adımda artmaktadır. Taraflar değişmek istedikleri elektronik mallan parçalara ayırıp birbirlerine sırayla bu parçalan yollarlar. Protokol sona erdiğinde elektronik mallar elde edilen parçalar birleştirerek oluşturulur.","ABSTRACT In this thesis, the problem of fair exchange on specific cases is addressed. The main idea of fair exchange is as follows: Two entities that do not trust each other want to exchange some arbitrary data over a communication network. Since they do not trust each other, neither party wants to transmit their own data before receiving the other entity's data. Even though either party could prove an unjust situation after termination of the protocol, if they are in different countries, solving disputes may require time and money due to the bureaucracy of international laws. In this thesis, a special application of fair exchange, a fair e-commerce protocol for large e-goods is designed and implemented. The proposed protocol provides a method for fair exchange of e-money to e-products, and a method for verifying the contents of the exchanged items. The presented protocol is efficient such that when none of the parties tries to cheat, only three messages are sufficient. In case of disputes, three more messages are needed. Furthermore, in most of the previously proposed protocols in the literature, e-goods are transferred multiple times among some entities. This situation is too costly when e-goods are large. In the presented protocol, e-goods are transferred only once. Another important property of the protocol is the anonymity of the customer; no information about the customers shopping habits can be gathered through the protocol. The implementation results show that the protocol is efficient and secure and that small number of cryptographic operations is sufficient In addition to the fair e-commerce protocol, another special application of fair exchange, a fair multimedia exchange protocol using a different method is designed and implemented. This protocol is designed due to different requirements of different applications. In the fair multimedia exchange protocol, two entities want to exchange some multimedia files such as video or audio files. This protocol requires lower security and has a different a lower degree of fairness as compared to the fair e-commerce protocol. Fair multimedia exchange protocol uses a baby-step approach in which theprobability of protocol completion is gradually increased over several cycles. In baby- step approach protocols, entities exchange pieces of the items, which they want to barter. At protocol completion, the complete items are formed by using the pieces exchanged."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Özet Biometrik doğrulama insanın kişisel özelliklerini (parmak izi, yüz, iris, ses gibi) kullanarak gerçekleştirilen kimlik doğrulama yöntemidir. Günümüz teknolojisinin getirdiği olanaklarla önemi gün geçtikçe artan biometrik doğrulama, kart veya parola tabanlı güvenlik sistemlerine göre daha pratik (parola hatırlama, kart kaybetme ve çaldırma sorunları yok), aynı zamanda daha güvenlidir (örn. bir parolayı tah min etmek bir parmak izini taklit etmekten daha kolaydır). İmza kişinin fiziksel özelliklerine bağlı olmayan, davranışsal bir biometriktir, bundan dolayı imza za manla değişebilir ve parmakizi veya iris kadar özebir değildir. Göz irisi veya par- makizi gibi biometrikler kişiye özgü olmalarına karşın, suçlular ile ilişkilendirildikleri ve kişi hakkında sağlık gibi konularda istenmeyen bilgileri açığa çıkardıkları için, bu sistemleri kullanmaya başlayan ülkelerde toplum tarafından kolaylıkla kabul görmemişlerdir. Öte yandan imza, günümüzde hemen her ortamda kimlik doğrulama işlemleri için gerekli bir bilgi olarak görülmektedir. İmza doğrulama statik (off-line) veya dinamik (on-line) imza doğrulama şeklinde iki ana konu olarak değerlendirilmektedir. Kağıt üzerindeki statik bir imzadan, tarama yoluyla sadece imzanın şeklini içeren bir imge elde edilmesine karşın, dokun maya hassas tabletlere atılan dinamik imzalarda hem imzanın şekli, hem de di namik özellikleri (hızı, kaç darbede atıldığı, kalemin ne kadar bastırıldığı gibi) elde edilebilir. Statik bir imzanın kopyalanması elde bir örnek varsa oldukça kolay ol masına karşın, dinamik özellikler imzayı daha kişiye özgü kılar ve taklit edilmesini zorlaştırır. Yine de her iki imza türüne dayalı doğrulama sistemlerinin kullanım alanları farklıdır: mesela statik imza doğrulayıcı bir sistem banka çeklerindeki sahte ciliklerin yakalanmasında kullanılırken, dinamik imza doğrulama sistemleri özellikle kredi kartındaki sahteciliklerin yakalanmasında kullanılmaktadır. Dinamik imza doğrulama sistemleri ayrıca bina girişlerinde, eliçi ve avuçiçi bilgisayarlarındaki bil gilerin korunmasında kullanılmaktadır. Bu çalışmada iki ayrı imza türüne dayalı (statik ve dinamik) iki farklı imza doğrulama sistemi sunulmaktadır. Her iki sistemde de kullanıcı bir kaç referans imzavererek sisteme kaydolur. Bu referans imzalarından, kişinin imzalarının özelliklerini ve değişkenliğini karakterize eden öznitelikler çıkarılır ve sistemde bu kullanıcıya özgü değerler olarak saklanır. Her iki sistemin girdi olarak kabul ettikleri imza türleri ve imzalardan çıkarılan öznitelikler farklı olmalarına rağmen, sistemler aynı doğrulama yöntemine dayanmaktadırlar: herhangi bir imza doğrulanacağı zaman, bu imza iddia edilen kişinin bütün referans imzalarıyla karşılaştırılır ve test edilen imzanın referans imzalarına uzaklığı (farklılığı) hesaplanır. Herhangi iki imza arasın daki farklılık, farklı uzunluklardaki iki dizinin, linear olmayan bir değişimle gelebile cekleri en benzer hallerin uzaklığını hesaplamak için kullanılan ""Dynamic Time Warping"" algoritması ile bulunur. Daha önce geliştirilmiş imza doğrulama sistem lerinde, bu işlemin sonucunda elde edilen minimum uzaklık (test imzasının en yakın referans imzasına uzaklığı) veya test imzasının şablon referans imzasına uzaklığı, bu kişiye ait ortalama değerlerle karşılaştırılarak, imzanın gerçek mi, taklit mi olduğuna buluşsal yöntemlerle karar verilmekteydi. Önerdiğimiz doğrulama yönteminde bahsi geçen uzaklıklar kendilerine karşılık gelen referans imzalar arasındaki ortalama uzak lıklarla normalize edilerek, sahte ve gerçek imzaların birbirinden ayrık oldukları öznitelik uzayı oluşturmaktadırlar. Çalışmamızda imzalardan çıkarılan üç boyutlu öznitelik vektörleri Bayes sınırlandırıcı, Destekçi Vektör Makinesi, ve Linear sınırlan dırıcı kullanarak imzaların sahte olup olmadığını tespit etmek için kullanılmışlardır. Sistemleri denemek için 100 ayrı kişiden toplam 620 dinamik ve 20 kişiden toplam 100 statik deneme imzası (gerçek ve sahte) toplanmıştır. Gerçek taklit imzaları elde etmek zor olduğu için, taklit edeceği imzanın şeklini ve mümkünse imzalama haraketlerini görebilen taklitçilerden nitelikli sahte imzalar alınmıştır. Dinamik imza doğrulama sistemi gerçek imzaların %1.4'ünü yanlışlıkla redederken, sahte imzaların sadece %1.3'ü yanlışlıkla kabul etmiştir. Statik imzayı taklit etmek daha kolay olduğu için, statik imza doğrulama sistemi sahte imzaların %25'ini yanlışlıkla kabul ederken, gerçek imzaların %20'sini yanlışlıkla redetmiştir. Önerilen dinamik doğrulama sistemi var olan sistemlerden daha üstün performans sergilerken, statik doğrulama sistemimizden de bu konudaki uzman kişilerin başarısıyla kıyaslanabilir performans elde edilmiştir. ıx","Abstract Biometrics is the utilization of biological characteristics (face, iris, fingerprint) or behavioral traits (signature, voice) for identity verification of an individual. Biomet- ric authentication is gaining popularity as a more trustable alternative to password- based security systems as it is relatively hard to be forgotten, stolen, or guessed. Signature is a behavioral biometric: it is not based on the physical properties, such as fingerprint or face, of the individual, but behavioral ones. As such, one's signature may change over time and it is not nearly as unique or difficult to forge as iris patterns or fingerprints, however signature's widespread acceptance by the pub lic, make it more suitable for certain lower-security authentication needs. Signature verification is split into two according to the available data in the input. Off-line signature verification takes as input the image of a signature and is useful in au tomatic verification of signatures found on bank checks and documents. On-line signature verification uses signatures that are captured by pressure-sensitive tablets and could be used in real time applications like credit card transactions or resource accesses. In this work we present two complete systems for on-line and off-line signature verification. During registration to either of the systems the user has to submit a number of reference signatures which are cross aligned to extract statistics describ ing the variation in the user's signatures. Both systems have similar verification methodology and differ only in data acquisition and feature extraction modules. A test signature's authenticity is established by first aligning it with each reference signature of the claimed user, resulting in a number of dissimilarity scores: distances to nearest, farthest and template reference signatures. In previous systems, only one of these distances, typically the distance to the nearest reference signature or the distance to a template signature, was chosen, in an ad-hoc manner, to classify the signature as genuine or forgery. Here we propose a method to utilize all of these dis tances, treating them as features in a two-class classification problem, using standard pattern classification techniques. The distances are first normalized, resulting in athree dimensional space where genuine and forgery signature distributions are well separated. We experimented with the Bayes classifier, Support Vector Machines, and a linear classifier used in conjunction with Principal Component Analysis, to classify a given signature into one of the two classes (forgery or genuine). Test data sets of 620 on-line and 100 off-line signatures were constructed to evaluate performances of the two systems. Since it is very difficult to obtain real forgeries, we obtained skilled forgeries which are supplied by forgers who had access to signature data to practice before forging. The online system has a 1.4% error in rejecting forgeries, while rejecting only 1.3% of genuine signatures. As an offline signature is easier to forge, the offline system's performance is lower: a 25% error in rejecting forgery signatures and 20% error in rejecting genuine signatures. The results for the online system show significant improvement over the state-of-the-art results, and the results for the offline system are comparable with the performance of experienced human examiners. Vll"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Özet Görüntü dönüşümüne uğramış objeleri tanımak, bilgisayarlı görüntüleme alanındaki önemli problemlerden biridir. Son zamanlardaki birçok araştırma, özellikle ge ometrik dönüşümler üzerine odaklanmıştır. Bu dönüşümlerin en önemlileri kam era hareketi ile meydana gelen perspektif dönüşümü ve onun yakınsaması olan il gin dönüşümdür. Bunun için geliştirilmiş birçok yöntem mevcuttur. Bunları en önde gelenleri Fourier tanımlıyıcıları; Momentler ve Örtük polinom eğrileridir. Bu yöntemler geleneksel yöntemler olarak da adlandırılırlar. Wavelet bazlı ilgin fonksiy onlar, son zamanlarda geliştirilen yöntemlerdir. Bu yöntem diğer yöntemlere göre daha efektif ve gürültüye karşı daha etkilidir. Bu yöntemlerde objelerin çevre eğrileri ve ""undecimated wavelet"" dönüşüm kullanılır. Bu tezde, ilgin dönüşüme uğramış nesneleri bilgisayarla tanımak için yeni bir yöntem önerilmektedir. Bu yöntemde ilgin fonksiyonlar, görüntü projeksiyonları ve high-pass filtrelenmiş resimlerin pro jeksiyonları kullanlmaktadr. Ayrıca, diğer ""wavelet"" bazlı metodlarm aksine ""dec imated wavelet"" dönüşüm tercih edilmiştir. Yöntemimizi diğer ""wavelet"" bazlı yöntemi olan Khalil-Baoumi metodu ile ve geleneksel yöntemlerle karşılaştırdık.","A WAVELET BASED METHOD FOR AFFINE INVARIANT 2D OBJECT RECOGNITION Abstract Recognizing objects that have undergone certain viewing transformations is an im portant problem in the field of computer vision. Most current research has focused almost exclusively on single aspects of the problem, concentrating on a few geomet ric transformations and distortions. Probably, the most important one is the affine transformation which may be considered as an approximation to perspective trans formation. Many algorithms were developed for this purpose. Most popular ones are Fourier descriptors and moment based methods. Another powerful tool to recognize affine transformed objects, is the invariants of implicit polynomials. These three methods are usually called as traditional methods. Wavelet-based affine invariant functions are recent contributions to the solution of the problem. This method is better at recognition and more robust to noise compared to other methods. These functions mostly rely on the object contour and undecimated wavelet transform. In this thesis, a technique is developed to recognize objects undergoing a general affine transformation. Affine invariant functions are used, based on on image projections and high-pass filtered images of objects at projection angles. Decimated Wavelet Transform is used instead of undecimated Wavelet Transform. We compared our method with the an another wavelet based affine invariant function, Khalil-Bayoumi and also with traditional methods."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Özet insan beyni büyük sayıda bilgiyi kaydeden ve uzun süre bunu saklayabilen en iyi hafızadır. Kelimeler, tanımları, kullanım alanları, kelimeler arasındaki ilişkiler ve dillerin gramerleri beynin dilsel bölümünde çok iyi organize edilmiştir. Konuşurken ve yazarken, genellikle duygu ve düşüncelerimizi doğru ve uygun kelimelerin ne olduğunu üzerinde fazla düşünmeden ifade edebiliriz. Fakat, bazen işler insan beyni için bile yolunda gitmeyebilir. Günlük yaşantımızda, çok kullandığımız ve an lamını iyi bildiğimiz kelimeleri sık sık unutur, hatırlayanlayız. Bir yazı yazarken arkadaşlarla konuşurken ya da bir bulmaca çözerken söyleyeceğimiz ya da yazacağımız kelimeyi bir türlü hatırlayanlayız. Böyle bir problem ile karşılaştığımızda, hatırlayamadığımız kelimeyi bulmak için klasik bir sözlüğü kullanmanın faydası olmaz. Bu gibi durumlarda, anlamından ke limeyi bulmayı sağlayacak kaynaklara ihtiyaç vardır. Bu tezde, kullanıcının tanımına dayalı en iyi uyan doğru Türkçe kelimeyi bulan ""Anlamdan Kelimeye"" sisteminin tasarım ve uygulanması sunulmuştur. Anlamdan kelime çıkarma yaklaşımı, herhangi bir anlamsal ve dilbilgisel bilgi kullanmadan kullanıcının tanımı ile Türkçe sözlükteki tanımlar arasındaki benz erlikleri bulmaya dayalıdır. ""Anlamdan Kelimeye"" sistemi, bilgisayar destekli dil öğrenme, bulmaca çözme veya birden fazla kelimeli tanımların, bir kelime ile ifade edilebilen versiyonunu ya da eşanlamlarını öğrenmeye yarayan ters sözlükler gibi bir çok alanda uygulanabilir. Sistem, daha önce hiç görmediği gerçek kullanıcı tanımlarında %72, farklı bir sözlükten alman tanımlarda %90 doğru kelimeyi anılan sıraya göre ilk 50 sonuçta bulmaktadır.","RETRIEVING WORDS FROM THEIR ""MEANINGS"" Abstract The human brain is the best memory that can record and keep a huge number of information for a long time. Words, their meanings, domains, relationships between different words, and the grammars of languages are well organized in the linguis tic component of brain. While speaking or writing, we can generally express our thoughts and feelings by words without thinking for a long time what the correct words can be. But, sometimes things do not go like clockwork even for human brain. In our daily life, we can often forget or not remember a word that we use frequently and exactly know its meaning. While writing a document, talking with friends, or solving a puzzle, we can not remember which word to say or to write. When we face this problem, it will be of no use to attempt searching in a traditional dictionary to find the word that we can not remember. In such cases, there is a need for resources that can locate the word from its meaning. This thesis presents the design and the implementation of a Meaning to Word dictionary (MTW), that locates a set of Turkish words, which most closely matches the correct/appropriate one based on a definition entered by the user. The approach of extracting words from ""meaning"" s is based on checking the similarity between the user's definition and an entry of the Turkish dictionary without considering any semantics or grammatical information. MTW can be used in various application areas such as computer-assisted lan guage learning, finding the correct words for the definition questions in solving crossword puzzles, and searching the one word representations or synonyms of a multi-word definitions in a reverse dictionary. Results on unseen data indicate that in 72% of the real users queries and 90% of different dictionaries queries, our system returns the correct answer in the first 50 results, respectively."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tez, yüksek hızlı, faz kilitlemeli çevrim tabanlı saat ve veri yakalama devresinin (clock and data recovery - CDR) tasarımı, sınanması, sistem düzeyinde tümleştirilmesi ve fiziksel tasarımının gerçekleştirilmesi aşamalarından oluşmuştur. CDR mimarisi, her biri girişindeki düşük hızlı referans saat işaretini ve rasgele veriyi işleyebilen kaba ayar çevrimi ve ince ayar çevrimi isimli iki farklı çevrimden oluşmuştur. Başlangıçta, kaba ayar çevrimi, veri frekansına referans saat işaretinin de yardımı ile kilitlenmeyi sağlar. Gerilim kontrollü osilatör (GKO) veri hızına yakın bir frekansta işaret üretmeye başladığı anda kilitlenme kontrol işareti (LOCK) üretilir. Bu kontrol işareti sayesinde kaba ayar çevrimi devreden çıkarılarak ince ayar çevrimi devreye sokulur. İnce ayar çevrimi GKO tarafından üretilen saat işaretinin yükselen kenarı veri biti göz açıklığının ortasına gelecek şekilde saat işaretini sürekli izler. İnce ayar çevrimini oluşturan alt-bloklann tasarımında hız ve simetri konulan son derece önemlidir. Bu çevrimin çalışması esnasında oluşabilecek asimetrik yükleme etkileri, zaman kaymaları ve örnekleme anlanndaki zamanlama hataları devre çıkışma statik faz hatası olarak yansıyacağından, tüm devre mimarisi özel düşük gerilim devre tasarım teknikleri kullanılarak tasarlanmıştır. Bu çalışma kapsamında ele alınan CDR mimarisinin tüm analog ve sayısal alt- bloklan, blokların daha güvenli olarak çalışmalarını sağlamak amacıyla, devre tasarımını büyük ölçüde zorlaştırmasına rağmen, diferansiyel işaret işleme tekniği kullanılarak tasarlanmıştır. Bu CDR'nin diğer önemli özellikleri arasında küçük kırmık alanı, tek güç kaynağı kullanılması, düşük güç gereksinimi, çok yüksek veri transfer hızlarında ve 2.4 Gbps ve 3.2 Gbps veri hızlan aralığında sorunsuz çalışabilme kabiliyeti sayılabilir. Bu tezde sunulan CDR mimarisi, daha düşük toplam maliyet ve tasanma daha iyi taşınabilirlik sağlamak amacıyla, endüstride yaygm olarak kullanılan 0.13 um sayısal CMOS teknolojisi (Üretici firma: UMC) kullanılarak gerçekleştirilmiştir. VITasarlanan devre, 3.2 GHz örnekleme frekansına kadar doğru çalışabilme ve bu yüksek örnekleme frekansında hedeflenmiş olan faz ayarlama özelliklerini yerine getirebilme kabiliyetine sahiptir. Devrenin tamamı bir tek 1.2 V güç kaynağı ile beslenebilecek şekilde tasarlanmıştır. 3.2 GHz örnekleme hızında, toplam güç tüketimi 18.6 m W olarak öngörülmektedir. Tümleştirilen çevrim süzgeci kapasiteleri ile birlikte CDR'nin toplan silikon alanı yaklaşık 0.3 mm2'dir Bu tez çalışmasında tasarlanan CDR mimarisi, optik haberleşme veya yüksek bant genişliğine sahip seri kablolu haberleşme gereksinimleri gibi çok yüksek hız gerektiren uygulamalarda kullanılmak amacıyla tasarlanmıştır. Bu devre, tek başına bir kırmık olarak veya daha büyük bir kırmık üzerine başka modüllerle birleştirilebilecek bir İP (intellectual property) bloğu olarak da kullanılabilir. vıı","ABSTRACT This thesis presents the design, verification, system integration and the physical realization of a high-speed monolithic phase-locked loop (PLL) based clock and data recovery (CDR) circuit. The architecture of the CDR has been realized as a two-loop structure consisting of coarse and fine loops, each of which is capable of processing the incoming low-speed reference clock and high-speed random data. At start up, the coarse loop provides fast locking to the system frequency with the help of the reference clock. After the VCO clock reaches a proximity of system frequency, the LOCK signal is generated and the coarse loop is turned off, while the fine loop is turned on. Fine loop tracks the phase of the generated clock with respect to the data and aligns the VCO clock such that its rising edge is in the middle of data eye. The speed and symmetry of sub-blocks in fine loop are extremely important, since all asymmetric charging effects, skew and setup/hold problems in this loop translate into a static phase error at the clock output. The entire circuit architecture is built with a special low-voltage circuit design technique. All analogue as well as digital sub-blocks of the CDR architecture presented in this work operate on a differential signalling, which significantly makes the design more complex while ensuring a more robust performance. Other important features of this CDR include small area, single power supply, low power consumption, capability to operate at very high data rates, and the ability to handle between 2.4 Gbps and 3.2 Gbps data rate. The CDR architecture was realized using a conventional 0.13-p.m digital CMOS technology (Foundry: UMC), which ensures a lower overall cost and better portability for the design. The CDR architecture presented in this work is capable of operating at sampling frequencies of up to 3.2 GHz, and still can achieve the robust phase alignment. The entire circuit is designed with single 1.2 V power supply. The overall power IVconsumption is estimated as 18.6 mW at 3.2 GHz sampling rate. The overall silicon area of the CDR is approximately 0.3 mm with its internal loop filter capacitors. Other researchers have reported similar featured PLL-based clock and data recovery circuits in terms of operating data rate, architecture and jitter performance. To the best of our knowledge, this clock recovery uses the advantage of being the first high-speed CDR designed in CMOS 0.13um technology with the superiority on power consumption and area considerations among others. The CDR architecture presented in this thesis is intended, as a state-of-the-art clock recovery for high-speed applications such as optical communications or high bandwidth serial wireline communication needs. It can be used either as a stand-alone single-chip unit, or as an embedded intellectual property (IP) block that can be integrated with other modules on chip."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bioinformatik alanında, protein katlanma problemi cüzüm bekleyen problem-lerden birisidir. Burada amaş proteinin uş boyutlu yapısını proteinin amino asitbilgisini kullanarak belirleyebilmektir. Bir proteinin uş boyuttaki yapısını bildiğimizzaman, onun hücre işindeki fonksiyonu hakkında da bilgi sahibi oluruz. Bir proteininbilmektedir. Bu nedenleyapısı bilinmeyen binlerce protein dizisinin yapısını belirleyebilmek işin daha etkilihesaba dayalı teknikler geliştirilmelidir.Bu tez şalışmasında proteinin ikincil yapısını tahminlemek amacıyla hesabadayalı yaklaşımlar geliştirilmiştir. Proteinlerin uş boyutlu yapısı, ikincil yapı oge-lerinden (Î±-helezonları, Î²-tabakaları, Î²-dünüşleri, ve düngüler) oluşmaktadır. Pro-teinin ikincil yapısının uş boyutlu yapısının oluşmasında büyük etkileri bulunmak-tadır. Bu nedenle bu tez şalışması kapsamında proteinin ikincil yapısının tahmin-lenmesi amacıyla iki farklı yaklaşım şalışılmıştır.Ilk yaklaşım, proteinlerin yapısal sınıï¬arını amino asit dizisi yardımıyla belir-lemek işin geliştirilmiştir. Proteinin yapısal sınıf bilgisi onun uc boyutlu katlanmışşekli hakkında ï¬kir verebilmektedir, cunkü proteinlerin ikincil yapısının onlarınalacağı katlanma şekli uzerinde büyük etkisi bulunmaktır. Bu yaklaşım işersinde,istatiksel sınıï¬andırma tekniklerinden birisi olan Destekşi Vectür Makinası ve ceşitliamino asit nitelik bilgileri birleştirilmiştir. Destekşi vectür makinasının yükseksınıï¬andırma yeteğine sahip olması ve amino asitler arasındaki komşuluk bilgisininkullanılması performans sonuşlarında iyileşmeye sebep olmuştur.Tez projesi işersinde yer alan ikinci calışma, proteinlerin ikincil yapı ogelerindenolan Î²-dünüşlerinin yine amino asit bilgisinden yararlanılarak tahminlenmesidir.Diğer ikincil yapı ogeleri kadar Î²-dünüşlerinin oluşmasının da proteinin katlamaaşamalarında onemi olduğu düşunülmektedir. Bu sebeple Î²-dünüşlerinin proteinişersindeki yerini belirleyebilmek ve tiplerini tespit edebilmek amacıyla saklı Markovmodeline ve yapay sinir ağına dayanan yaklaşımlar geliştirilmiştir. Î²-dünüşleri vediğer ikincil yapı ogeleri arasındaki komşuluk bilgisinin verilebilmesi uygun saklıMarkov model topolojilerinin oluşturulmasıyla sağ- lanmıştır. Proteinler arasındakievrimden kaynaklan ortak bilgiler de bir ceşit amino asit benzerlik matrisi ile sis-teme verilmektedir. Î²-dünüşlerinin yerlerini tahminleme probleminde saklı Markovmodellerinin ve amino asit benzerlik matrisinin kullanılması yeni bir yaklaşımdır.Bu şalışmada Î²-dünüşlerinin yerinin ve tiplerinin belirlenmesinde elde edilen ilksonuşlar oldukşa umit verici olmuştur.","One of the most promising problems in bioinformatics is still the protein foldingproblem which tries to predict the native 3D fold (shape) of a protein from its aminoacid sequence. The native fold information of proteins provide to understand theirfunctions in the cell. In order to determine the 3D structure of the huge amount ofprotein sequence, the development of eï¬cient computational techniques is needed.The thesis studies the computational approaches to provide new solutions forthe secondary structure prediction of proteins. The 3D structure of a protein iscomposed of the secondary structure elements: Î±-helices, Î²-sheets, Î²-turns, andloops. The secondary structures of proteins have a high impact on the formation oftheir 3D structures. Two subproblems within secondary structure prediction havebeen studied in this thesis.The ï¬rst study is for identifying the structural classes (all-Î±, all-Î², Î±/Î², Î±+Î²)of proteins from their primary sequences. The structural class information couldprovide a rough description of a protein?s 3D structure due to the high eï¬ects of thesecondary structures on the formation of 3D structure. This approach assemblesthe statistical classiï¬cation technique, Support Vector Machines (SVM), and thevariations of amino acid composition information. The performance results demon-strate that the utilization of neighborhood information between amino acids andthe high classiï¬cation ability of the SVM provides a signiï¬cant improvement for thestructural classiï¬cation of proteins.The second study in thesis is for predicting one of the secondary structureelement, Î²-turns, through primary sequence. The formation of Î²-turns has beenthought to have critical roles as much as other secondary structures in the proteinfolding pathway. Hence, Hidden Markov Models (HMM) and Artiï¬cial Neural Net-works (ANN) have been developed to predict the location and type of Î²-turns fromits amino acid sequence. The neighborhood information between Î²-turns and othersecondary structures has been introduced by designing the suitable HMM topolo-gies. One of the amino acid similarity matrices is used to give the evolutionaryinformation between proteins. Although applying HMMs and usage of amino acidsimilarity matrix is a new approach to predict Î²-turns through its protein sequence,the initial results for the prediction of Î²-turns and type classiï¬cation are promising."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"TÜRKÇE İÇİN VURGULU METİNDEN SES SENTEZLEYICISI Özet Metinden ses sentezleyicisi sistemlerinde doğallık kaliteli bir ses dalgası elde edilmesinde çok önemli bir rol oynar. Ses dalgasının doğallığı fonetik kapsama ve vurgusal özellikler olan perde frekans eğrisi ve süre bilgileriyle ilişkilidir. Süre bilgisi sentezlenen fonemin zaman bilgisini belirler, perde frekans eğrisi ise ses dalgasının temel frekans özelliklerini kapsar. Bu tezde, Festival ses sentezleme sistemi kullanılarak, Türkçe için vurgulu metinden ses sentezleyicisi geliştirilmiştir [31]. Yeni bir erkek sesi, Türkçedeki alofonları kap sayarak, temel frekans ve süre bilgileri kullanılarak oluşturulmuştur. Alofonların süresi ve kelime vurgusu geniş çapta çalışılmıştır. Cümle vurgusu ve kelime öbek vurgusu daha az detaylı olarak çalışılmıştır. Tüm alofon kombinasyonları için taşıyıcı kelimeler oluşturulmuştur. 1680 tane taşıyıcı kelime ses yalıtımlı bir kayıt stüdyosunda kaydedilmiştir. LPC ve RES parametreleri hesaplanmıştır. Kısaltmalar ve sayılar için metni normalize eden bir modül geliştirilmiştir. Alofonlar için süre bilgisi girilmiştir. Cümle ve kelime se viyelerinde F0 üretim modülleri geliştirilmiştir. Fonem sayısını arttırarak ve vurgu yaratarak Türkçe için daha doğal bir metinden ses sentezleyici sistem elde edilmiştir.","A PROSODIC TURKISH TEXT-TO-SPEECH SYNTHESIZER Abstract Naturalness in Text-to-Speech systems is very important in achieving high qual ity waveform. The naturalness of the waveform is highly correlated with phonetic coverage and prosodic features such as, duration and FO contour. Duration de termines the timing for the synthesized phoneme, whereas FO contour determines fundamental frequency component of the waveform. This thesis presents the development of a prosodic Text-to-Speech System for Turkish Language using the Festival Tool [31]. We describe a complete realization of a new male voice, covering allophones of Turkish using duration and FO parameters. The duration of the allophones and the word stress have been studied extensively. Sentence stress and phrasal stress are also discussed by in less detail. Carrier words are designed approximately for all allophone-allophone combina tions. 1680 carrier words are recorded in a sound-proof recording studio. LPC (linear predictive coding) and RES (residual) parameters are computed. The text normalisation module is implemented for abbreviations and numbers. Durations for the allophones are entered. Sentence level and word level FO generation modules are implemented. By increasing the number of phonemes and giving prosody we obtained a more natural sounding Text-to-Speech System for Turkish Language."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Özet Vi-XFST; XEROX SONLU DURUM MAKİNA DERLEYİCİSİ İÇİN GÖRSEL ARAYÜZ Yasin Yılmaz Bilgisayar Bilimleri Yüksek Lisans Programı Tez Danışmanı: Prof. Kemal Oflazer Temmuz, 2003 Bu tez çalışması, Xerox Sonlu Durum Makina Derleyicisi (Xerox Finite-State Toolkit- XFST) programının kullanıldığı sonlu durum proj eleri için bir yönetim modeli ve entegre geliştirme ortamı ortaya koyrnaktadır. XFST, doğal dil işleme araştırmalannda kullanılan sonlu durum tanıyıcı ve dönüştüracülerinin hazırlandığı popüler bir komut satın programıdır. Ancak, XFST yüzlerce sonlu durum tanımlarının bulunabildiği bu büyük projelerde ihtiyaç duyulan yetenekli yardımcı yönetim özelliklerinden yoksundur. Bu tezde, XFST sonlu durum ağlarının geliştirme aşamaları için yeni bir yaklaşım sunul maktadır: Kaynak kodlar, bir proje oturumu içerisinde, görsel bir çalışma ortamında ele alın makta ve proje etkileşimli olarak adım adım geliştirilmektedir. Geliştirmiş olduğumuz yazılım, Vi-XFST, otomatik düzgün deyimlerin bağımlılık takibi, proje kaynak kod yönetimi, görsel düzgün deyimlerin tanımlama araçları ve sonlu durum ağı test özellikleri sağlamaktadır. Vi-XFST sayesinde, daha önce bir metin dosyası ile hazırlanan proje geliştirme adımlan, modern yazılım geliştirme yöntemlerine benzer bir yaklaşım ile değiştirilmiştir. Vi-XFST'nin görsel özellikleri, kompleks sonlu durum ağlarının değişik detaylarda incelenebilmesine olanak sağlayarak büyük projeleri yönetilebilir ve anlaşılabilir kılmaktadır, özellikle sonlu durum pro jeleri için tasarlanmış bu entegre geliştirme ortamı, hata ayıklama ve proje geliştirmede önemli avantajlar sağlamaktadır. Anahtar Kelimeler: Doğal Dil İşleme, Sonlu Durum Makina Derleyicisi, XFST","Abstract Vi-XFST; A VISUAL INTERFACE FOR XEROX FINITE-STATE TOOLKIT Yasin Yılmaz MS in Computer Science Supervisor Prof. Kemal Oflazer August,2003 This thesis presents a management model and integrated development environment soft ware for finite-state network projects using Xerox Finite-State Toolkit (XFST). XFST is a pop ular command line tool to construct finite-states networks, used in natural language processing research. However, XFST lacks various sophisticated management features to help the devel opment phase of large projects where there are hundreds of finite-state definitions. In this thesis, we introduce a new approach to XFST finite-state development: The source files are handled in a visual workspace associated with a project, and the project is developed step by step interactively by the user just like contemporary software development projects. Vi-XFST, the software we have created for our development model, includes automatic de pendency tracking, source file management, visual regular expression construction, definition management and network testing features. With Vi-XFST, a textual file editing is replaced with a project-building concept similar to modern software development tools. The benefits of adopting an integrated development envi ronment designed for finite-suite development include productivity gains by substantial reduced time for debug and management. The visual features of Vi-XFST enable viewing complex net works at different levels of detail and make even large projects manageable and comprehensible. Keywords: Natural Language Processing, Finite-State Toolkit, XFST"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Açık anahtar tabanlı kriptografi algoritmalarını kullanan sistemler anahtar dağıtım ve yönetim işlerini genellikle açık anahtar altyapıları (PKI) ile yaparlar. Bu tezde bu yaklaşımın sorunlarından bahsedilmiştir ve anahtar dağıtım ve yönetimini kendine özgü bir şekilde yapan bir e-posta sistemi önerilmiştir. Bu e-posta sistemi ""Pratik ve Güvenli E-posta"" (""PGE"") olarak adlandırılmıştır. PGE açık anahtar altyapılarından farklı olarak anahtar dağıtımında sertifikalandırma yöntemini kullanmaz. PGE sisteminde bütün kullanıcıların güvendiği merkezi bir otorite (sunucu) anahtar dağıtımını üstlenir. Anahtar yönetimi de bu otorite tarafından yerine getirilir. PGE sisteminin kullanıcılarına bakan kısmı kullanıcı e-posta programlandır. Bu programlar normal bir e-posta programının özelliklerine sahiptir ve kullanıcılarının açık anahtar tabanlı kriptografi algoritmalarını kullanarak, kendi aralarında şifreli ve/veya imzalı e-posta göndermelerini de sağlar. PGE nesneye dayalı analiz ve tasarım (OOAD) aşamalarına uyularak gerçeklenmiştir. PGE'nin gerçeklenmesinde Java programlama dili kullanılmıştır. PGE sisteminde, son kullanıcıların kendi açık anahtarlarını açık anahtar deposuna koyabilmeleri, depodan silebilmeleri, yenileyebilmeleri ve başka kullanıcıların açık anahtarlarını depodan alabilmeleri için güvenli protokoller tasarlanmıştır. PGE sisteminin anahtar dağıtım ve yönetim mekanizması, PKI tabanlı sistemlerde olduğu gibi kullanıcıların e-posta adreslerinin kontrolsüz dolaşımına izin vermez. PGE'de sertifika iptali ve onun getirdiği problemlere rastlanmaz. PGE'nin güven mekanizması ortalama kullanıcıların kolayca kullanabilecekleri kadar basit ve düzgündür. Bütün bu özellikler PGE sistemini ""pratik"" yapmaktadır. PGE şifreleme, imzalama ve doğrulayarak kayıt yapma gibi özellikleri desteklediği için yeterince ""güvenli"" bir e- posta sistemidir.vm PGE sisteminin ilk sürümü organizasyon içi e-posta değişimini sağlayacaktır. PGE uygulaması, şirket ve üniversite gibi kuruluşların hiç bir ücret ödemeden kullanmalarına izin vermektedir.","Key distribution and management in applications that use public key cryptosystems generally rely on Public Key Infrastructures (PKI). In this thesis, the disadvantages of this approach are discussed and an e-mail system that performs public key distribution and management in a unique way is proposed. The name of this system is ""Practical and Secure E-Mail System"" (""PractiSES""). PractiSES does not use the certification mechanisms of PKIs. A central authority, which is trusted by all users, takes the responsibility of key distribution and management in PractiSES. PractiSES Client is an e-mail application that is designed for end users. On top of regular e-mail client features, PractiSES Client can also be used to exchange e-mails among users in encrypted and/or signed fashion. PractiSES is designed according to the phases of ""Object Oriented Analyses and Design (OOAD)"". It is implemented using Java programming language. In PractiSES, there are several secure protocols developed for initializing users, removing and updating public keys of the users and obtaining the others' public keys. Key management and distribution features of PractiSES do not let the e-mail addresses move around in an uncontrolled fashion - this is one of the problems of PKI based systems. Moreover, certificate revocation problem does not exist in PractiSES. The trust mechanism of PractiSES is simple and straightforward so that an average user can easily use. Those characteristics of PractiSES make it ""practical"". On the other hand, PractiSES supports enough security features, such as authentic registration, encryption and digital signatures. The first version of PractiSES will be for closed-group e-mail exchange. PractiSES will be a free application that can be used without any warranty by companies and universities."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmada, proteinlerin hem fonksiyonlarının doğrudan bulunması, hem de fonksiyonlarının bulunmasında dolaylı olarak işe yarayan hücre içindeki yerlilerinin saptanmasının mümkün olduğu iki işlemsel yaklaşım sunulmaktadır. Proteinlerin hücre içindeki yerlerinin, içerdikleri amino asit oranları kullanılmak suretiyle, yapay zeka teknikleriyle saptanmaya çalışıldı. Bitkisel ve diğer proteinlerin hücre içindeki yerlerinin ve özellikle de ökaryotların fonsiyonlarının tespiti için Destek Vektörü Makineleri adı verilen yapay zeka uygulamasına dayanan uzman sistemler tasarlandı. Bu sistemler kullanılarak, bitki ve diğer protein sınıfları için dörder hücre içi protein konumu, sırasıyla %95.4 ve %99.7 oranlarında doğru bir şekilde tahmin edilmiştir. Her iki grup için tahmin edilen mitokondri, hücredışı / sinyal ve nükleer sınıflarının yanı sıra, bitkiler için kloroplast, hayvanlar için ise sitozolik hücre konumları da sınıflandırmaya dahil edildiler. Hücre içindeki organellerle ilgili faaliyet gösteren proteinlerin fonksiyonları, konum bulmada kullanılan yöntem kullanılarak tahmin edilmeye çalışıldı. 2321 protein dizisinin %92.3'ü, seçilmiş 10 fonksiyonel kategori içine doğru bir şekilde sınıflandı. Son olarak, MEDLINE makalelerinin veri madenciliği ile analizinin fonksiyon tahminine katkı yapabileceği ayrı bir protein veri tabanı kullanılarak gösterildi. vııı","ABSTRACT In this study, we present a computational approach in which it is possible to directly predict the protein functional categories from sequence and to identify the protein subcellular localization, which, in turn, is helpful for functional classification. ^"" Subcellular protein locations and functions have been predicted basically from amino acid composition by using a machine learning approach. Expert systems based on Support Vector Machines have been designed to predict subcellular locations for proteins both in plants and nonplants, and function particularly for nonplants. Four subcellular localization categories for plant and nonplant proteins have been identified by correct prediction accuracies of 95.4%, and 99.7% respectively. In addition to the three common categories mitochondrial, extracellular / secretory, and nuclear; the classes cytosolic for nonplants, and, chloroplast for plants are included. Functional categories related to the subcellular compartments are predicted by using a similar approach applied for localization prediction. 92.9% of the 2321 protein sequences have been correctly assigned into the selected 10 functional categories. Finally, the contribution of the data-mining of the MEDLINE papers to the function prediction is tested by another protein data set. Vll"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Günümüzde toplum, çevre ve sağlık konusunda daha duyarlıdır. Bunun sonucu olarak, özellikle gelişen sanayi ve teknoloji ile birlikte, çevremizde bulunup, sağlığımızı etkileyen kimyasalların hızlı ve seçici bir şekilde algılanması daha da önem kazanmıştır. Değişik devre formlarında (pasif-resistör, aktif-mikroelektronik, akustik dalga), yarı-iletken tipi sensörler, 1960'lı yılların başından günümüze kadar, ticari uygulamalarda, bio-medikal, savunma ve endüstri alanlarında, kimyasalların türü ve miktarının ölçümünde yaygın olarak kullanılmakta dır. Bu tür devrelerin temel değerlendirme kriterleri; operasyonun basitliği, yapısının küçüklü ğü, maliyetinin ucuz olması, uzun ömürlü olması, tepkinin tekrarlanabilmesi, hassasiyeti ve seçiciliğidir. Pozlama, ince film, aşındırma, difüzyon ve yarı-iletken teknolojisinde meydana gelen gelişmeler, bugün kullandığımız yüksek hızda, düşük boyut ve fiyatlı entegre devrelerin üretimine imkan sağlamıştır. Daha çok iki boyutlu olan bu üretim teknolojisine, özel aşındırı cılar, aşındırma durdurma teknikleri ve geçici katmanların kombinasyonundan oluşan mikroiş- leme teknolojisi de eklenerek, üçüncü bir boyut kazandırılmıştır. Mikroişleme, mikron boyutlu yapıların üretimi için kullanılan tekniklerin genel adıdır. Mikroişleme tekniklerinin en önemli ayrıcalığı tümdevre (IC) yapımında kullanılan mikroelektronik endüstrisiyle aynı teknolojiyi kullanmasıdır. Bu iki üretim teknolojilerinin biriri ile olan benzerliği kullanılarak, mekanik yapıların ve bunları kontrol eden ve gözetleyen elektronik devrelerin aynı taban üzerinde gerçeklenmeleri sağlanarak, mikroelektromekanik (MEMS) yapıları oluşturulmuştur. Bu tezde, MEMS teknolojisi kullanılarak, performans parametreleri iyileştirilmiş kimyasal sensörlerinin ve sensör seçimine karar veren ve sinyali algılanabilir şekilde işleyen okuma ve kontrol tüm devrelerinin tasarımı ve üretimi gerçeklenmiştir. Bu amaçla matriksel yapılar kullanarak, seçiciliği ve duyarlılığı yüksek sensör sistemi ve yüksek sıcaklıkta ve düşük güc sarfiyatında çalışacak şekilde tasarlanmış ve simulasyon ile görülmüştür. Sensör işlenmesi için yüksek kazanç ve geniş bantlı işlemsel kuvvetlendirici tasarlanmış ve üretilmiştir.vıı","REALIZATION OF CMOS COMPATIBLE MICROMACHINED CHEMICAL SENSORS ABSTRACT The chemical sensors are fabricated using IC manufacturing technologies, providing a smaller size and lower weight, lower power consumption, and lower cost due to the auto mated and batch production. During the last two decades, largely two-dimensional Inte grated Circuit (IC) fabrication technology has been extended into the third dimension by micromachining technologies [1]. Micromachining has been used to produce a growing vari ety of micromechanical structures, including automotive pressure sensors, airbag deployment accelerometers and many others [2-4]. Given the similarities in IC fabrication and microma chining, microelectronics and micromechanics may be integrated on a single chip, allowing an on-chip monitoring and control of the mechanical/chemical functions. This has led to the term microelectromechanical systems (MEMS) to describe this technology. The use of MEMS technology could provide a number of opportunities for gas sensors: the sensing elements can be miniaturized (reducing power consumption), multiple elements can be integrated into array configurations with each element optimized to sense a different gas, improved selec tivity/sensitivity and the integration of sensing and signal processing/control devices on the same substrate. In addition, due to the small mass of micromachined-sensor element, rapid thermal programming can be employed to introduce a level of kinetic selectivity into the operation of the sensor. In this thesis, realization of Complementary Metal Oxide Semiconductor (CMOS) com patible chemical sensors using micromachining technology will be explained. During this realization 3x2 sensor array is designed to improve the selectivity and sensitivity of the sen sor system. To address the needs of convenient and batch processes CMOS compatibility is incorporated inside the fabrication flow because CMOS compatibility offers convenient merging with read-out circuitry which comprises of operational transconductance ampli- fiers(OTAs). OTAs are preferred in this design because they assist the detection of the resistance changes at the sensor output. VI"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ANALYSIS OF TEXTURAL IMAGE FEATURES FOR CONTENT BASED RETRIEVAL OZET Sayısal arkeoloji ve sanal gerçeklik uygulamaları ile arkeoloji verilerinin birleştirilmesi, son yıllarda bilimsel ilgi çeken konulardır55-56. Tez çalışmamız, çömlek parçalan, mermer röliyef veya mozaikler şeklindeki arkeolojik bulguların, şekil ve doku bilgileri kullanılarak bilgisayar desteği ile ilişkilendirilmesini hedefleyen projelere ön araştırma niteliğindedir. Kültürel mirasın sayısallaştırılarak kullanılması, yıllar süren61 restorasyon çalışmalarını kısaltacak, geri dönülebilir alternatifler üzerinde daha çok uzman fikrin paylaşılmasını ve yapay görme sistemleriyle de sonuçların gürbüzlüğünü sağlayacaktır. Ayrıca, sonlanan çalışmalardan elde edilen veriler sanal müze, sanal tur gibi çoklu medya uygulamaları ile elektronik ortamlarda kitlelere ulaştırılabilecek, ve objeler yıllar boyunca fiziksel risklerden uzak arşivlenebilecektir. Doku analizi günümüze kadar hata analizi amacıyla yapay görme ve imge işleme bilimlerinde sıkça araştırılmış ve yaygın olarak uygulanmıştır1-2-3,5-8-11-1415-16. Son yıllarda ise benzerlik analizi alanına kayarak içerik tabanlı sayısal imge arama yöntemlerinde kullanılmaya başlanmıştır'-410. Bu sistemlerin güncel problemleri verimli yapı ve hız özellikleri olduğundan imge metrikleri üzerinde henüz fazla yoğunlaşılmamıştır. Tez çalışmamız hata ve benzerlik analizlerindeki doku algoritmalarının sayısal imge arama platformunda toplu haldeki ilk karşılaştırma dokümanıdır. Benzerlik analizinden çıkan veriler ve tez çalışmasında elde edilen deneyimler 2 boyutlu bulmaca çözme, bir başka ismiyle devamlılık analizi yöntemlerini geliştirmek üzere ilk kez uygulancak olan arkeolojik verilerin doku metrikleri ile ilişkilendirilmesi çalışmalarında kullanılacaktır. Tezin ilk bölümünde problemlerimize model teşkil edecek insan görme sistemi incelenmiş ve biyolojik olarak hata, benzerlik ve devamlılık analizlerinin çözümlerinin tıp ve psikoloji bilimlerince nasıl açıklandığı araştırılmıştır. ikinci bölümde, sayısal içerik tabanlı 2 boyutlu durağan imge arama sistemleri, performans kriterleri ve yakınlık metrikleri incelenmiş, literatürdeki çalışmalar özetlenmiştir. Tez çalışması için, literatürde şimdiye kadar kullanılan en geniş doku örnek arşivi oluşturulmuştur. Doku analizi sonuçlarının görsel olarak izlenebileceği bir arayüz tasarlanmış, içerik tabanlı imge arama yapılabilecek bir platform geliştirilmiş, internet sayfaları kaynak kodlarından karakter seti resim bileşeni ayrıştırması yaparak resim dosyalarını bulup sabit diske indirecek içerik tabanlı arama motoru kod çalışmasının ilk yapısı uygulanmıştır; Ayrıca, doku analizi yöntemleri öncesi gerekli olan imge işleme ve doku metriklerinin gürbüz işlenmesi için örüntü analizi yöntemleri gerçekleştirilmiştir. Son bölümde ise geliştirilen en yaygın doku analizi ve bu yöntemlerin tüm metrikleri açıklanmış, yaratılan farklı boyutlardaki doku örnek arşivlerinde, yazılan kodların performans sonuçları özetlenmiştir. VII","ANALYSIS OF TEXTURAL IMAGE FEATURES FOR CONTENT BASED RETRIEVAL ABSTRACT Digital archaelogy and virtual reality with archaeological artefacts have been quite hot research topics in the last years55-56. This thesis is a preperation study to build the background knowledge required for the research projects, which aim to computerize the reconstruction of the archaelogical data like pots, marbles or mosaic pieces by shape and textural features. Digitalization of the cultural heritage may shorten the reconstruction time which takes tens of years currently61; it will improve the reconstruction robustness by incorporating with the literally available machine vision algorithms and experiences from remote experts working on a no-cost virtual object together. Digitalization can also ease the exhibition of the results for regular people, by multiuser media applications like internet based virtual museums or virtual tours. And finally, it will make possible to archive values with their original texture and shapes for long years far away from the physical risks that the artefacts currently face. On the literature1,2-3,5-8,11-14,15'16, texture analysis techniques have been throughly studied and implemented for the purpose of defect analysis purposes by image processing and machine vision scientists. In the last years, these algorithms have been started to be used for similarity analysis of content based image retrieval1,410. For retrieval systems, the concurrent problems seem to be building efficient and fast systems, therefore, robust image features haven't been focused enough yet. This document is the first performance review of the texture algorithms developed for retrieval and defect analysis together. The results and experiences gained during the thesis study will be used to support the studies aiming to solve the 2D puzzle problem using textural continuity methods on archaelogical artifects, Appendix A for more detail. The first chapter is devoted to learn how the medicine and psychology try to explain the solutions of similiarity and continuity analysis, which our biological model, the human vision, accomplishes daily. In the second chapter, content based image retrieval systems, their performance criterias, similiarity distance metrics and the systems available have been summarized. For the thesis work, a rich texture database has been built, including over 1000 images in total. For the ease of the users, a GUI and a platform that is used for content based retrieval has been designed; The first version of a content based search engine has been coded which takes the source of the internet pages, parses the metatags of images and downloads the files in a loop controlled by our texture algorithms. The preprocessing algorithms and the pattern analysis algorithms required for the robustness of the textural feature processing have been implemented. In the last section, the most important textural feature extraction methods have been studied in detail with the performance results of the codes written in Matlab and run on different databases developed. VI"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çalışmasında, sonlu durum makinalarında Benzersiz Girdi Çıktı (BGÇ) Dizileri bulunması için bazı sezgisel yöntemler önerilmektedir. BGÇ dizilerinin hesaplanmasının zor bir problem olduğu bilinmektedir. Bu çalışmada önerilen yöntemler de, literatürde bulunan diğer yöntemler gibi üstel büyüklükte bir ağaç yapısına dayanmaktadır. Fakat, bu çalışmada önerilen yöntemler bu ağacı oluşturması sırasında yapılan aramayı bazı sezgisel yöntemlerle yönlendirilmektedir. Bu yönlendirilmiş aramanın dışında çıkarım kullanarak BGÇ dizisi bulan yöntemlere de değinilmiş ve bu yöntemlerin bir dezavantajı olan uzun diziler çıkarma sorununa bir çare olarak, sınırlı çıkarım yapma önerilmiştir. Rasgele üretilen sonlu durum makinaları kullanılarak, bu çalışmada önerilen yöntemlerin birbirleri ve literatürde bulunan diğer yöntemler ile karşılaştırılması yapılmıştır.","In this thesis, several heuristic methods are proposed for the computation of Unique Input Output (UIO) Sequences for the states of a given finite state machine. UIO computation problem is known to be a hard problem. The methods suggested in this work are based on unfolding an exponential tree as the other methods existing in the literature. However, our methods perform a search guided by some heuristic information. We also introduce a parameter for inference based UIO sequence computation for a trade off between the memory used for the computation and the UIO sequence length. Based on a randomly generated set of finite state machines, an extensive experimental study is also provided to compare the performance of our methods between each other and to those already exist in the literature."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde üç boyutlu (3B) kafa takibi için ölçekten bağımsız öznitelik dönüşümüne (SIFT) dayalı bir yöntem önerilmektedir. Önerilen yöntemin, düzlem dışı öteleme ve dönmelere karşı gürbüz olduğu belirlenmiş aynı zamanda görüntüdeki ani değişen aydınlanma farklarından da etkilenmediği gözlenmiştir. Bunun yanı sıra optik akış yöntemine dayalı, Normal Flow Constraint ve 3B çakıştırma yöntemi olan tekrarlı en yakın nokta algoritmasını (ICP) değerlendirdik ve önerdiğimiz yöntem ile karşılaştırmasını yaptık. Kafa takibi, bir çok bilgisayarla görme uygulaması için önemli bir süreçtir. Eğer kafanın üç boyutlu uzaydaki yeri ve duruşu bilinirse, yüz tanıması, ifade analizi, dudak okuması gibi problemleri, 3B kafa izleyicisi tarafından oluşturulan dengelenmiş imgeleri kullanarak çözmek daha muhtemeldir.Önerdiğimiz sistem 2B bir yüz sezicisi kullanarak özişler bir biçimde başlamaktadır. Birbirini takip eden video imgelerinde SIFT öznitelik noktaları bulunur ve birbirlri ile eşleştirilir. Eşleştirilen noktalar, derinlik bilgisi de kullanılarak 3B ilişki kümesi oluşturulur. Birim kuaterniyon yöntemi ile 3B katı devinim hesaplanır. Önerdiğimiz SIFT yöntemi ötelemelerde NFC ve ICP yöntemlerin daha iyi sonuç verdi ve dönmelerde ise NFC benzer bir başarım gösterdi. Aynı zamanda önerilen yöntem uzun videolarda sürüklenmeden daha az etkilenmekte ve zamana bağlı aydınlanma değişikliklerine göre gürbüzdür. Önerilen SIFT tabanlı yöntemin başarısı sentetik ve stereo kamera ile çekilmiş gerçek görüntüler üzerinde denenip var olan diğer yöntemlerle karşılaştıması yapıldı.","In this thesis a new stereo-based 3D head tracking technique, based on scale-invariant feature transform (SIFT) features, that is robust to illumination changes is proposed. Also two major tracking techniques, one based on normal flow constraints (NFC) and a 3D registration-based method, based on iterative closest point (ICP) algorithm, are reviewed and compared against the proposed technique. A 3D head tracker is very important for many vision applications. The resulting tracker output parameters can be used to generate a stabilized view of the face that can be used as input to many existing 2D techniques such as facial expression analysis, lip reading, eye tracking, and face recognition.Our system can automatically initialize using a simple 2D face detector. We extract salient points from the intensity images using SIFT features and match them between frames. Together with the depth image and the matched features we obtain 3D correspondences. Using the unit quaternion method, we recover the 3D motion parameters. Our proposed method outperforms both NFC and ICP on translations; and performs as good as NFC on rotations. Experimentally, the proposed system is less likely to drift than NFC and ICP over long sequences and is robust to illumination changes. We present experiments to test the accuracy of our SIFT-based 3D tracker on sequences of synthetic and real stereo images."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"RSA, günümüzde en sık kullanılan Açık Anahtarlı Şifreleme (AAŞ) türüdür. Daha önce hiç karşılaşmamış iki tarafın birbirleri arasında güvenli bir iletişim kanalı oluşturabilmesi için AAŞ sistemleri kullanılır. RSA'de en temel işlem modüler çarpım işlemidir ve özellikle kullanılan anahtar 1024 bitten uzunsa, bu işlem çok yoğun bir hesaplama gücü gerektirir. Günümüzün kişisel bilgisayarları birkaç RSA işlemini bir saniyeden kısa bir zamanda bitirebilirken, avuçiçi bilgisayarları, cep telefonları ve smart kart gibi az işlem gücüne sahip ortamlarda, bu yüksek hesap gücü gerektiren işlem için kullanılacak ilave donanıma ihtiyaç vardır. Buna ek olarak binlerce kişinin aynı anda erişim isteyebileceği web servis sağlayıcılarında, bu işlem, bir performans darboğazı olarak görünebilir. Donanım için geliştirilen bazı özel algoritmalar sayesinde çok büyük ölçekte paralel hesaplamalar yapılabilir ve böylece donanımın kullanım oranı artırılarak hem enerji harcaması düşürülür, hem de toplam işlem zamanı kısaltılır. Bu amaçla, en verimli modüler çarpım işlemlerinden biri olarak bilinen ve birçok AAŞ alanında kullanılan ?Montgomery Modüler Çarpım? algoritmasını kullanacağız.İlk olarak ?2048-bitlik ve 4 tabanında çalışan Modüler Çarpım? dizaynını anlatacağız ve bunu daha önceki çalışmalarda sıkça kullanılan 2 tabanındaki modüler çarpım devreleriyle karşılaştıracağız. Bizim devrenin, diğer devreleri simule etmek için yaptığımız referans devreye göre çalışma hızının % 82 arttığını ve bunu sadece %33'lük bir alan artışıyla gerçekleştirdiğini gördük. Ayrıca, Xilinx xc2v6000 FPGA'inde 132 MHz'de çalışan bu devre, referans dizayna göre %37'lere varan oranlarda, zaman alan çarpımını azalttı. Benzer kazanımları, UMC 0,18 ?m teknolojisi için sentezlenen devre ile de elde ettik.İkinci bölümde ise nispeten ucuz FPGA'lere uygun, hızlı, parametrik ve yan kanal ataklarına karşı dayanıklı bir modüler çarpım devresini ve bir üs alma devresini sunuyoruz. Bu dizayn, FPGA üzerinde bulunan çarpım birimlerini ve blok RAM'i kullanacak şekilde geliştirildi. Dizaynımızda çarpım işlemi için kullanılan bileşenlerin tabanı (radixi), çarpım ünitelerinin sayısı ve toplam word sayısı parametrik olarak istenen özelliklere göre ayarlanabilir. Mimari yapıda pipelining tekniğini kullandık ve bu bize yüksek frekanslarda, aynı anda birçok çarpım işlemini yapma özelliği kazandırdı. Dizaynımız 1020-bitlik ve 2040-bitlik modüler çarpım işlemlerini Xilinx Spartan-3E 500 FPGA'i üzerinde sırasıyla 7,62 µs ve 27,0 µs'de bitirmektedir ve bu ölçümler FPGA'de bulunan çarpım birimlerinin sadece yarısı kullanılarak elde edilmiştir. Dizanımız daha önceki devrelerle karşılaştırıldığında en düşük alan zaman çarpımını elde etti. Ayrıca 2040-bitlik üs alma devresinin Xilinx Spartan-3E 500 çipine kolaylıkla sığabileceğini gördük. Kullandığımız üs alma devresi, bilinen tüm yan kanal ataklarına karşı korumalı bir şekilde dizayn edildi ve bu koruma çok ufak bir ek donanım getirilerek başarıldı. Üs alma devresi, işlemde kullanılan sayılar blok RAM'e sığdığı sürece her büyüklükteki sayı için kullanılabilir. Bu dizanımız ayrıca ilk dizaynla da avantaj ve dezavantajları açısından karşılaştırıldı.","RSA is the most popular Public Key Cryptosystem (PKC) and is heavily used today. PKC comes into play, when two parties, who have previously never met, want to create a secure channel between them. The core operation in RSA is modular multiplication, which requires lots of computational power especially when the operands are longer than 1024-bits. Although today?s powerful PC?s can easily handle one RSA operation in a fraction of a second, small devices such as PDA?s, cell phones, smart cards, etc. have limited computational power, thus there is a need for dedicated hardware which is specially designed to meet the demand of this heavy calculation. Additionally, web servers, which thousands of users can access at the same time, need to perform many PKC operations in a very short time and this can create a performance bottleneck. Special algorithms implemented on dedicated hardware can take advantage of true massive parallelism and high utilization of the data path resulting in high efficiency in terms of both power and execution time while keeping the chip cost low. We will use the ?Montgomery Modular Multiplication? algorithm in our implementation, which is considered one of the most efficient multiplication schemes, and has many applications in PKC.In the first part of the thesis, our ?2048-bit Radix-4 based Modular Multiplier? design is introduced and compared with the conventional radix-2 modular multipliers of previous works. Our implementation for 2048-bit modular multiplication features up to 82% shorter execution time with 33% increase in the area over the conventional radix-2 designs and can achieve 132 MHz on a Xilinx xc2v6000 FPGA. The proposed multiplier has one of the fastest execution times in terms of latency and performs better than (37% better) our reference radix-2 design in terms of time-area product. The results are similar in the ASIC case where we implement our design for UMC 0.18 ?m technology.In the second part, a fast, efficient, and parameterized modular multiplier and a secure exponentiation circuit intended for inexpensive FPGAs are presented. The design utilizes hardwired block multipliers as the main functional unit and Block-RAM as storage unit for the operands. The adopted design methodology allows adjusting the number of multipliers, the radix used in the multipliers, and number of words to meet the system requirements such as available resources, precision and timing constraints. The deployed method is based on the Montgomery modular multiplication algorithm and the architecture utilizes a pipelining technique that allows concurrent operation of hardwired multipliers. Our design completes 1020-bit and 2040-bit modular multiplications in 7.62 µs and 27.0 µs respectively with approximately the same device usage on Xilinx Spartan-3E 500. The multiplier uses a moderate amount of system resources while achieving the best area-time product in literature. 2040-bit modular exponentiation engine easily fits into Xilinx Spartan-3E 500; moreover the exponentiation circuit withstands known side channel attacks with an insignificant overhead in area and execution time. The upper limit on the operand precision is dictated only by the available Block-RAM to accommodate the operands within the FPGA. This design is also compared to the first one, considering the relative advantages and disadvantages of each circuit."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda ¸cok sekmeli kablosuz ¸sebekeler sivil ve askeri alanlardaki ¸cok ¸ce¸sitli potansiyel uygulamaları nedeniyle ¨onemli ¨ol¸c¨ude dikkat ¸cekmi¸stir. Bu t¨ur ¸sebekeler i¸cin ¸co˘ga g¨onderim temel bir veri da˘gıtım y¨ontemidir. ˙Iletim g¨u¸c kontrol¨un¨un kablosuz tasarsız a˘glar i¸cin ¸cok ¨onemli bir konudur ve hala tatmin edici ¸c¨oz¨umlerin bulunmamaktadır. Kablosuz a˘g olu¸sturma ortamı ¸co˘ga g¨onderim problemleri i¸cin zorlu bir alandır. ¨ Ozellikle kablosuz ortam ¨ozellikleri ve pille ¸calı¸san ara¸cların bulunması kablosuz ¸sebekelerde kısıtlı olan enerji kaynaklarının makul kullanılmasını ama¸clayan yeni modelleme yakla¸sımları ve algoritmik yakla¸sımlar gerektirmektedir. Buna ek olarak, ¸sebekelerin kaynaktan hedef cihazlara kadar olan her iletim yolu ¨uzerinde ileti gecikmesi ile ilgili olarak belli bir servis kalitesi garantisi sunması gerekmektedir. Dahası, her alıcı cihazda algılanan sinyalin ba¸sarılı bir ¸sekilde ¸c¨oz¨ulebilmesi i¸cin sinyalin yeteri kadar g¨u¸cl¨u olması gerekmektedir. Bu sebeble, bu ¸calı¸smada ¸cok sekmeli kablosuz a˘glarda en az enerjili ¸co˘ga g¨onderim problemini iki farklı kısıt do˘grultusunda incelemekteyiz: (i) her cihaz ¸co˘ga g¨onderim mesajını belli bir gecikme sınırı olan  i¸cerisinde almalıdır, ve (ii) alınan sinyalin i¸saret-parazit-artı-g¨ur¨ult¨u-oranı (SINR) e¸sik de˘ger 'nın ¨uzerinde olmalıdır ki sinyal ba¸sarı ile ¸c¨oz¨ulebilsin. Bu nedenle, sırasıyla kısıt (i) ve (ii) do˘grultusunda en az enerjili ¸co˘ga g¨onderim a˘gacı olu¸sturacak DTE ve SINR-BIP adlarında iki farklı algoritma ¨onermekteyiz. DTE minimum ¨orten a˘ga¸c algoritmasının da˘gıtık uygulanmasını baz almaktadır. Her yinelemede, gecikme sınırı kısıtını ihlal etmeden en az enerji artı¸sı gerektiren ve mevcut durumda ula¸sılamamı¸s d¨u˘g¨umlerden en fazlasına ula¸sabilen d¨u˘g¨um e˘gaca eklenerek ¸co˘ga g¨onderim a˘gacı b¨uy¨ur. SINR-BIP algoritmasında ise alınan sinyallerin SINR de˘gerleri g¨oz ¨on¨unde bulundurularak iyi bilinen ¸co˘ga g¨onderim g¨u¸c-artı¸sı (BIP) algoritmasındaki ana fikre benzer bir yakla¸sım uygulanmı¸stır. Buna ek olarak, algoritmanın miyop etkisini azaltmak i¸cin SINR-BIP'in i¸cine g¨om¨ul¨u olarak bir budama yordamı kullanılmı¸stır. C¸ o˘ga g¨onderim a˘gacı her yinelemede b¨uy¨ud¨u˘g¨u i¸cin her iki algoritma da do˘gası gere˘gi yapıcı algoritmalardır. DTE'nin mevcut algoritmalardan daha iyi performans g¨osterdi˘gini ve DTE ile elde edilen ¸co˘ga g¨onderim a˘gacının toplam enerji t¨uketiminin Tamsayı Programlama ile elde edilene %20 oranında yakın oldu˘gu g¨ozlenmektedir.","In recent years wireless multi-hop networks have attracted significant attention due to their wide range of potential civil and military applications. Broadcasting is a fundamental data dissemination scheme for these networks. The transmission power control is an important issue in wireless ad hoc networks and still has no satisfactory solution methods. The wireless networking environment presents formidable challenges to the study of broadcasting problems. In particular, the properties of the wireless medium and the presence of battery-powered devices require novel modeling and algorithmic approaches concentrating on judicious use of limited energy resources in wireless networks. In addition, networks are often required to provide certain quality of service (QoS) guarantees in terms of the end-to-end delay along the individual paths from the source to each of the destination nodes. Moreover, the received signal at each receiving node must be strong enough to be successfully decoded. In this study we address the minimum-energy broadcast problem in multi-hop wireless networks with respect to two different constraints: (i) each node must receive broadcast message within a given delay bound , and (ii) signal-to-interference-plus-noise ratio (SINR) of the received signal must be above a given threshold so that the received signal can be successfully decoded at the receiving node. We propose two distinct algorithms Distributed Tree Expansion (DTE) and SINR-BIP which aim to generate minimum power broadcast tree with respect to constraint (i) and (ii), respectively and exclusively. DTE is based on an implementation of a distributed minimum spanning tree algorithm in which the tree grows at each iteration by adding a node that can cover the maximum number of currently uncovered nodes in the network with minimum incremental transmission power and without violating the delay constraint. In SINR-BIP, we apply the similar idea of well-known Broadcast Incremental Power (BIP) algorithm while considering the SINR values of received powers. In addition, we use an embedded pruning procedure in SINR-BIP, so that the myopic effect of the algorithm is mitigated. Both the algorithms DTE and SINR-BIP are constructive in nature since the broadcast tree grows at each iteration. We observed that the DTE outperforms the existing algorithms and the total energy consumptions of the generated broadcast trees by DTE is within 20% percent of the solutions obtained by Integer Programming."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Güvenli çok partili hesaplama basitçe, birden fazla partinin her partidengelen bilgileri kullanarak ortaklasa hesap yapmasına izin veren metodlar ileilgilidir. Öyle ki bu hesaplamalar sonucunda her partinin bilgisi kendisindesaklı kalmaktadır. Güvenli çok partili hesaplama kavramının ortaya atıldığıgünden beri, bu amaca ulasmak için bir çok algoritma ve metod gelistirildi.Bu tez öncelikle güvenli çok partili hesaplamaya izin veren farklı metodlarıtanıtıp, daha sonra sır paylasımı bazlı güvenli çok partili hesaplama yontemleriuzerine odaklasıp, bu hesaplamaların nasıl verimli yapılabilece?gini açıklamaktadır.Ayrıca sır paylasımı bazlı güvenli çok partili hesaplama konusu anlatılırken,Asmuth Bloom sır paylasım yonteminin orjinal seklinde mümkünolmayan guvenli çok partili hesaplama'ya izin veren yeni bir teknik tanıtacağiz.Bu tezin amacı güvenli cok partili hesaplama yapmak icin kullanılabilecekbir programlama dili ve kütüphane tasarlayıp uygulamaktır. Bizimaracımızın kullanım kolaylığı ve güvenliği sayesinde, güvenlik veya kriptolojihakkında hiçbir bilgisi olmayan bir insanin bile güvenli çok partili hesaplamayapabileceğini gostereceğiz.","Secure multiparty computation is basically about techniques that allowmultiple parties to jointly carry out computations that are based on data fromeach of the players while the data held by each player remains private to thatplayer. Since the beginning of the notion of secure multiparty computation,many algorithms and methods were introduced on how to achieve this goal.This thesis first introduces different methods to do secure multiparty computationand later focusing on Secret sharing based multiparty computationit explains how efficient and secure multiparty operations can be done. Alsowhile introducing secret sharing based secure multiparty computation we introducea novel technique which allows to do secure multiparty computationusing the Asmuth Bloom secret sharing scheme, which is not possible in theoriginal scheme. The aim of this thesis is the design and implementationof a programming language and libraries for secure multiparty computation,SecurePL. We show that our tool?s ease of use and security allows even aperson who has absolutely no knowledge about security or cryptography towrite applications that can do secure multiparty computation."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Giyilebilir kuvvet yansıtımlı robotlar, haptik dış iskeletler, medikal ve sanal gerçeklik uygulamalarında geniş kullanım alanı bulduklarından, günümüzde oldukça yaygınlaşmaya başlamışlardır. Haptik dış iskeletler, bilgisayarda oluşturulmuş ortamlarla kullanıcıların mekanik etkileşimine izin vererek onların sanal gerçeklik ortamına daha iyi dahil olabilmelerini sağlamaktadırlar.Haptik dış iskeletlerin tasarımı oldukça zorlu bir görevdir, zira bu cihazların, ergonomi ve hafiflik kriterlerinine ek olarak, ideal herhangi bir kuvvet yansıtımlı makinadan beklenen özellikleri de sağlaması gerekmektir; insan tarafından uygulanan kuvvetlere çok yüksek katılıkla dayanabilmeli, ayrıca insanın algılayabileceği minimum empedansa kadar inebilen tam impedans aralığını sergileyebilme kapasitesine sahip olmalıdır. Robot, bu birbiriyle çelişen gereklilikler göz önünde bulundurularak tasarlanmazsa, cihazın kendisi yansıtılan kuvvetlerin şeffaflığını önemli ölçüde bozabilir. Bu yüzden, kinematik yapının seçimi ve boyutlarının belirlenmesinin, uygulanan kontrol algoritmasından bağımsız olarak, herhangi bir haptik yansıtımın genel performansında önemli etkileri vardır.Bu tezde, ilk olarak haptik aygıtların, özellikle kapalı kinematik yapıdakilerin, birden çok tasarım amacına göre optimum boyut sentezinde kullanılabilecek genel bir şablon sunuyoruz. Kuvvet yansıtımlı dış iskeletelerle ilgili performans kriterlerini belirleyip, sınıflandırıyoruz ve Pareto-front bazlı çok amaçlı tasarım en iyileştirmesi prosedürünü kullanarak aralarındaki ödünleşimi ifade ediyoruz. Önerilen çerçeve, hızlı yakınsayan gradient bazlı bir method kullandığından, hesaplama açısından verimlidir. Ayrıca, bu yaklaşım seçilen performans kriterlerinden bağımsız olup, istenilen sayıda tasarım kriteri için kullanılabilir.Ardından, bu çerçeveyi en uygun kinematik yapının seçimine yardımcı olacak şekilde genişletiyoruz. Özel olarak, insan ön kolu ve bileğinin ergonomik ihtiyaçlarını karşılayan iki küresel paralel mekanizmanın (KPM) titiz bir biçimde kıyaslanmasını gerçekleştirip, kuvvet yansıtımlı uygulamalarda daha iyi performans sergileyen kinematik yapıyı seçiyoruz. Ayrıca seçilen mekanizma için, Pareto eğrisindeki en iyi tasarımların bulunduğu kümeden, kinematik ve dinamik performanslar arasındaki optimum ödünleşimi sağlayan mekanizma boyutlarını belirliyoruz.Tasarım en iyileştirilmesi aşamasını takiben, model bazlı kontrolörlerin benzetim ve gerçek zamanlı uygulamalarını verimli olarak gerçekleştirebilmek için KPM bazlı dışiskeletin kinematik ve dinamik analizlerini, bağımsız kordinatlarda yapıyoruz. İnsan bileğinin tork ve kuvvet sınırlarını göz önünde bulundurarak donanım bileşenlerine karar verip, ilk prototip dış iskeleti üretiyoruz. Son olarak, model bazlı görev alanı pozisyon ve empedans tipi kontrolörlerin benzetimlerini uygulayıp, sonuçlarını sunuyoruz.","Wearable force feedback robotic devices, haptic exoskeletons, are becoming increasingly common as they find widespread use in medical and virtual reality (VR) applications. Allowing users to mechanically interact with computationally mediated environments, haptic exoskeletons provide users with better ?immersion? to VR environments.Design of haptic exoskeletons is a challenging task, since in addition to being ergonomic and light weight, such devices are also required to satisfy the demands of any ideal force-feedback device: ability withstand human applied forces with very high stiffness and capacity to display a full range of impedances down to the minimum value human can perceive. If not properly designed by taking these conflicting requirements into account, the interface can significantly deteriorate the transparency of displayed forces; therefore, the choice of the kinematic structure and determination of the dimensions of this kinematic structure have significantimpacts on the overall performance of any haptic display independent of the control algorithm employed.In this thesis, we first propose a general framework for optimal dimensional synthesis of haptic interfaces, in particular for haptic interfaces with closed kinematic chains, with respect to multiple design objectives. We identify and categorize the relevant performance criteria for the force feedback exoskeletons and address the trade-offs between them, by applying a Pareto-front based multi-objective design optimization procedure. Utilizing a fast converging gradient-based method, the proposed framework is computational efficient. Moreover, the approach is applicable to any set of performance indices and extendable to include any number of design criteria.Subsequently, we extend this framework to assist the selection of the most appropriate kinematic structure among multiple mechanisms. Specifically, we perform a rigorous comparison between two spherical parallel mechanisms (SPMs) that satisfy the ergonomic necessities of a human forearm and wrist and select the kinematic structure that results in superior performance for force-feedback applications. Utilizing the Pareto optimal set of solutions, we also assign dimensions to this mechanism to ensure an optimal trade-off between global kinematic and dynamic performance.Following the design optimization phase, we perform kinematic and dynamic analyses of the SPM-based exoskeleton in independent coordinates to facilitate efficient simulation and real-time implementation of model based controllers. We decide on the hardware components considering human wrist torque and force limits, safety and ergonomy constraints, and present the CAD model of a prototype of the exoskeleton. Finally, we implement model based task-space position and impedance controllers in simulation and present the results of them."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Anahtar Kelimeler: bilgisayar grafikleri, kültürel miras, çift-elli etkileşim, 3B modeller Bilgisayar destekli arkeoloji ve sanat tarihi araştırmalarının yaygınlaşması için kültürel miras sayılabilecek arkeolojik buluntu ve sanat eserlerinin 3B modelleri üzerinde çalışmak amacıyla özel olarak geliştirilmiş ve kullanımı kolay yazılımların varlığı en az ucuz ve başarılı 3B sayısallaştırma yöntemlerinin varlığı ve yaygınlığı kadar önemlidir. 3B tarama tekniklerindeki gelişmeler sayesinde bahsedilen türde araştırmalara uygun 3B model miktarı da her geçen gün artmaktadır. Be ve benzeri modeller ile çalışan yazılımlardaki uzaysal ölçüm araçlarındaki eksiklik veya bu araçların kullanımındaki zorluklar bize uzmanların sıklıkla kullandığı bazı ölçüm araçlarının sanal hallerini geliştirmek için ilham kaynağı oldu. Geliştirilen sanal mezura, yarıçap tahmini, kompas, ve yüzey alanı tahmin araçları CH Toolbox adı altında toplanmışlardır. Araştırmamızda bu araçların geliştirme aşamaları ve detaylı anlatımlarına ek olarak, CH Toolbox'ın kullanıcı arayüzü olarak seçilen çift-elli etkileşim yönteminin Guiard'in yetenek gerektiren asimetrik çift elli hareketler üzerine oluşturduğu Kinematik Zincir modeline göre tasarımda göz önüne alınan noktalar da anlatılmaktadır.","Keywords: computer graphics, cultural heritage, bi-manual interaction, 3D models The availability of intuitive, user-friendly and specialized software to work with 3D models of cultural heritage artifacts is as important as the availability of low-cost and robust data acquisition techniques for the adoption of digitized 3D models in cultural heritage research. As recent developments in 3D scanning technologies have made the digitization of artifacts affordable; the amount of digitized models available for research increases rapidly. Consequently the need for specialized software for cultural heritage research and practice on 3D models becomes more apparent. The lack of spatial measurement tools familiar to cultural heritage experts in traditional 3D modeling packages motivated us to create a simple, freely available, and extensible measurement tools system, CH Toolbox, which was designed exclusively for cultural heritage research. The proposed system visualizes digitized models of artifacts in 3D and allows the user to analyze the pieces using a spaceball and mouse driven bi-manual interface. We describe here the component of the CH Toolbox system, specificially the virtual tape measure, caliper, rim chart and an surface area estimation tool. Additionally, we present justification for CH Toolbox?s bi-manual interaction scheme according to Guiard?s Kinematic Chain model for asymmetric human skilled bi-manual actions. We also discuss the design decisions that were taken for producing an extensible and free software system based on open standards and widely available open source technologies, such as the OpenGL graphics and the OpenSceneGraph scene hierarchy libraries."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"Distributed structure of individual data makes it necessary for data holders to perform collaborative analysis over the collective database for better data mining results. However each site has to ensure the privacy of its individual data, which means no information is revealed about individual values. Privacy preserving distributed data mining is utilized for that purpose. In this study, we try to draw more attention to the topic of privacy preserving data mining by showing a model which is realistic for data mining, and allows for very efficient protocols. We give two protocols which are useful tools in data mining: a protocol for Yao?s millionaires problem, and a protocol for numerical distance. Our solution to Yao?s millionaires problem is of independent interest since it gives a solution which improves on known protocols with respect to both computation complexity and communication overhead. This protocol can be used for different purposes in privacy preserving data mining algorithms such as comparison and equality test of data records. Our numerical distance protocol is also applicable to variety of algorithms. In this study we applied our numerical distance protocol in a privacy preserving distributed clustering protocol for horizontally partitioned data. We show application of our protocol over different attribute types such as interval-scaled, binary, nominal, ordinal, ratio-scaled, and alphanumeric. We present proof of security of our protocol, and explain communication, and computation complexity analysis in detail. i"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"With the advancement of technology, it is now easy to collect the location information of mobile users over time. Spatio-temporal data mining techniques were proposed in the literature for the extraction of patterns from spatio-temporal data. However, current techniques can only produce patterns at the finest time granularity, and therefore overlooks potential patterns available at coarser time granularities. In this work, we propose several techniques to allow mining at different time granularities. Experimental results show that the proposed techniques are indeed effective and efficient for mining periodic spatio-temporal patterns at different time granularities."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Doğadan esinlenerek, sonlu eleman hesabına dayalı akışkanlar dinamiği modelleri yardımı ile ağdalı ortamlarda zamanla tersinemez-uzatılamaz dalga yayılımı ile eylenen mikro-itici yöntemi sunulmuştur. Öncelikle, sıvı ile dolu bir mikrokanal içerisinde çapalanmış uzatılamaz ince filmden oluşan iki ve üç boyutlu mikropompa modelleri analiz edilerek parametrik tasarım değişkenlerinin sıvı akışı, hidrolik güç tüketimi ve verim üzerindeki etkisi grafiksel olarak elde edilmiştir. Tüm modeler, sırasıyla sıkıştırılamaz-izotermal Stokes ve sıkıştırılamaz-izotermal Navier Stokes denklemleri, kütlenin korunumu yasası ve biçimi bozulan örgü yöntemi (ALE) kullanılarak çözülmüştür. Sonraki adımda, tamamen ağdalı akışkan içerisine batırılmış ve yürüyen-düzlemdalga hareketi ile eylenen kuyruk yardımı ile hareket eden üç boyutlu mikroyüzücü tasarımının parametrik tasarım değişkenlerinin itici hızı, hidrolik güç tüketimi ve yüzücü verimi üzerinki etkisi sıkıştırlamaz-izotermal Navier-Stokes, kütlenin korunumu yasası ve biçimi bozulan örgü yapısı (ALE) yardımı ile grafiksel olarak elde edilmiştir. Mikroyüzücünün hareketleri, etrafını saran ağdalı akışın mikroyüzücü yüzeyine uyguladığı kuvvetlerden yararlanılarak elde edilmiştir. Bu etkileşimden net itme kuvveti elde edilebileceği gözlemlenmiştir. Sayısal sonuçlar başlıca Taylor (1951), Katz (1974) ve Childress (1981) tarafından iki boyutlu varsayımlar üzerinde yapılmış analitik çalışmaların asemptotic sonuçları ile karşılaştırılmıştır. Üçüncü boyutun varlığının etkisi yüzünden dalga boyu grafiklerinde gözlemlenen sapma dışında, sayısal sonuçlarla asemptotic sonuçlar arasında güçlü bir tutarlılık olduğu görülmüştür. Anahtar Kelimeler: Mikropompa, mikroitici, mikroyüzücü, yürüyen-düzlem-dalga, uzatılamaz film, hidrolik güç, verim","A biologically-inspired micropropulsion method is presented by constructing a series of finite element computational fluid dynamics models for time irreversible inextensible wave propagation method in viscous medium. First, micropump models encompassing fully submerged and anchored waving inextensible film mounted inside a microchannel are analyzed to attain flow, hydraulic power consumption and efficiency plots with respect to parameterized design variables via both 2D and 3D models. Each model is governed by incompressible isothermal Stokes and Navier-Stokes equations respectively and conservation of mass, integrated with deforming mesh employing arbitrary Lagrangian Eulerian method. Next, propulsion velocity, power consumption and efficiency plots of a fully submerged free microswimmer utilizing a wave propagating tail inside a viscous environment is analyzed with respect to parameterized design variables via 3D models governed by incompressible isothermal Navier-Stokes equations and conservation of mass, integrated with deforming mesh employing arbitrary Lagrangian Eulerian Method. All resultant swimmer motions are modeled directly incorporating with stress interactions between surrounding viscous fluid and swimmer surfaces. It is demonstrated that net forward thrust can be harvested from this interaction. Numerical results are compared with the asymptotical results to analytical studies mainly carried out by Sir Taylor (1951), Katz (1974) and Childress (1981) based on mainly 2D assumptions. It is observed that there exists a strong agreement between earlier results and numerical results besides from wavelength parameter which illustrates slight deviation in power consumption characteristics due to the effects introduced by the existence of third dimension."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son kırk yılda insanların ve araştırmacıların robotik biliminden beklentilerinde bir değişim olduğu görülmüştür. Robotların endüstrideki yerini göz önünde bulundurmakla beraber, insanların günlük hayatlarındaki isteklerini karşılamaları da beklenmektedir. Bu sebepten insansı robotlara olan ilgi gün ve gün artış göstermektedir. ???? nsanların yaşadığı ortamlar uyum sağlamaları ve insana benzer yapıları sebebiyle kurtarma çalışmaları, hasta bakıcılığı ve asistanlık gibi görevleri üstlenmeleri istenmektedir. Fakat lineer olmayan karasız dinamikleri ve çok sayıda eklemleri yüzünden kontrol edilmeleri çok zorlu bir görev olmakla beraber bu robotlar için yürüyüş referansı elde edimi de çok zordur. Bu yüzden yaratılan referansların izlenmesi için çok fazla kontrol müdahalesi gerekmemesi istenmektedir. Lineer Ters Sarkaç Modeli (LIPM) böyle referansların elde edilmesi için uygun bir altyapı sağlamaktadır. Bu modelde vücut bir noktasal ağırlık olarak kabul edilmekle beraber bacaklar da ağırlıksız çubuklar olarak modellenmektedir. Buna ek olarak Sıfır Moment Noktası (ZMP) da kararlı referans elde edilmesi için güçlü bir yöntem olmakla beraber robotun kararlılığı açısından çok önemli bir kriterdir. Bu kriter yardımıyla gelişmiş Lineer Ters Sarkaç Modelleri elde edilmiş ve uygulanmıştır. Bu tezin amacı ağır bacaklı robotlar için LIPM tabanlı, işlemsel uygulama açısından avantajlı olan ve çok yönlü bir referans oluşturma tekniği geliştirmektir. Bunun için ayrık zamanlı durum-uzay modellerine sahip çift noktasal ağırlık içeren bir LIPM modeli önermektedir. LIPM modeli uygulaması tek ayak destek ve çift ayak destek safhalarına göre sırasıyla tek ve çift noktasal ağırlıklı modeller arasında geçiş yardımıyla elde edilmiştir. Elde edilen referanstan ters kinematik yardımıyla eklem değişkenleri elde edilmiş ve her eklem için bağımsız PID denetleyicileri kullanılmıştır. Yaratılan referansın verimi benzetim yardımıyla doğrulanmıştır. Benzetim, bu referansların 12 serbestlik dereceli bir robotun 3B dinamik modeline uygulanması ile gerçekleştirilmiştir. Elde edilen sonuçlar kullanılan modelin tek ağırlıklı modele göre daha iyi sonuçlar verdiğini doğrulamaktadır. Anahtar Kelimeler: Doğrusal Ters Sarkaç Modeli, Sıfır Moment Noktası, durum-uzay gösterimi, salınan bacak yer çekimi telafisi","Expectations of people and researchers from robotics have changed in the last four decades. Although robots are used to play their roles in the industrial environment, they are anticipated to meet social demands of people in daily life. Therefore, the interest in humanoid robotics has been increasing day by day. Their use for elderly care, human assistance, rescue, hospital attendance and many other purposes is suggested due to their adaptability and human like structure. Biped reference trajectory generation is a challenging task as well as control owing to the instability trend, non-linear robot dynamics and high number of degrees of freedom. Hence, the generated reference trajectories have to be followed with minimum control interference. Linear Inverted Pendulum Model (LIPM) is used to meet this demand which assumes the body as a falling point mass connected to the ground with a massless rod. The Zero Moment Point (ZMP) is a stability criterion for legged robots which provides a more powerful, stable reference generation. With the assistance of this methodology, advanced Linear Inverted Pendulum Models are implemented. This thesis aims to improve the applicability of the versatile and computationally effective LIPM based reference generation approach for the robots with heavy legs. It proposes a swing-leg gravity compensation technique based on a two-mass linear inverted pendulum model which is simulated on a discrete state space model. LIPM modeling is implemented by switching between one-mass and two-mass models during double support and single support phases, respectively. The joint trajectories are then obtained by inverse kinematics and PID controllers are employed independently at joint level for locomotion. The effectiveness of the generated reference trajectories is verified by simulation. The reference generation and control algorithm is tested with a 3-D full dynamic simulator on the model of a 12 DOF biped robot. Results indicate better performance of the one-mass-twomass switching LIPM over the one-mass LIPM. Keywords: Linear Inverted Pendulum Model, Zero Moment Point, state-space representation, swing leg gravity compensation"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tipik bir dağıtılmış kontrol sisteminde, ağ üstündeki kontrol sisteminin parçası olan cihazlar, veri kaybı veya rasgele gecikmelerin yaşanabileceği bir bilgisayar ağı kullanarak haberleşir. Bu problemlere genel bir çözüm sunmak, sistemin karmaşıklığından ve bu şartları etkileyebilecek muhtemel unsurların fazlalığından dolayı zordur. Modern bilgisayar ağlarında, bir veri kaybı yaşandığı zaman tekrar yollanarak problem giderilmektedir. Fakat gerçek zamanlı uygulamalarda gecikme veya kayıp halinde veriyi tekrar yollamanın bir anlamı yoktur. Eğer kaybolan gerçek zamanlı veri, ölçülen tesis çıktısı ise, tesis çıktısı tekrar ölçülüp en güncel haliyle yollanmalıdır. Eğer kaybolan gerçek zamanlı veri, kontrol çıktısı ise, çıktının tekrar gönderilmesi, çıktının tesise geç bir zamanda uygulanması demektir; bu durumda kontrol çıktısının tekrar hesaplanıp gönderilmesi daha sağlıklıdır. Bu tez, ağ üzerinde rasgele veri kaybı veya gecikmenin olabileceğini kabullenen bir dağıtılmış kontrol sistem metodunu uygulamaya geçirmek adına yapılmış bir çalışmadır. Bu çalışmada kullanılan metot, ağ üzerinde olabilecek muhtemel veri kaybı ve gecikmeden kaynaklanabilecek problemleri, tesisin bir modelini çalıştırıp belirli sayıdaki sonraki tesis durumunu ve karşılık gelen kontrol çıktısını hesaplayarak telafi etmeye çalışmaktadır. Bu çalışmada, bu konuda yapılmış daha önceki çalışmalar incelendikten sonra, uygulamaya geçirilen tahminsel kontrol metodu anlatılmıştır. Daha sonra tasarım ve uygulama aşamaları detaylarıyla anlatılmış ve test sonuçları yorumlanmıştır.","In a typical distributed control system, computer nodes communicate through a common communication channel that introduces data loss and random delays. Supplying a generic solution to these constraints is hard due to the complexity and large variety of possibilities that may affect these constraints in real life applications. In a modern communication network, if data is corrupted during transmission, it can be resent. However, it is not feasible to retransmit in control applications; if the packet contents correspond to measured plant outputs, then the most recent data should be measured and sent instead, or if the packet contents correspond to a control signal and the retransmission would cause the control signal to be applied late to the plant, it would be better to recalculate the signal and send it again. This thesis is an attempt to implement a distributed control system design method, Model Based Predictive Networked Control System (MBPNCS), which accepts the fact that arbitrary delay and data loss may happen. The MBPNCS method approaches the problem by using a plant model to predict a predefined number of future states of the plant and respective control signal for each, to compensate for the possible delay and data loss that can take place during the communication between nodes. In this work, after previous works have been examined, predictive control method that is used in the implementation is introduced. Design and implementation of the methodology is explained in detail and results of the tests are presented."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Genel olarak mekatronik sistemlerin planlama ve kontrolü için kullanılabilecek standart bir işletim sistemi yoktur. Amacımız, mikrosistem uygulamamızdaki mikro manipülasyon araçlarıyla mikro büyüklüklerin manipülasyonundaki kesinliği elde edecek ortam olarak kullanılacak çalışma düzlemini oluşturmaktır. Mikromontaj iş istasyonunda; manipülasyon sistemi, görüntü sistemi, gürbüz kontrol sistemi, manipülasyon araçları ve yapılacak göreve göre kullanılacak uç takımları için gerekli bağlantı elemanları bulunmaktadır. Bu tezde mikromontaj iş istasyonu manipülasyon sisteminin hareket planlama ve montajı için bir temel oluşturulmuştur. Çalışma düzleminin işlevselliğini göstermek için sanal çalışma alanı ortamında hareket planlama algoritmaları uygulanmıştır. Öncelikle konvansiyonel Euclidean uzaklık olmak üzere, yapay potansiyel alan ve son olarak A* algoritmalarının performansları incelenmiştir. Mikromontaj iş istasyonundaki hareket planlama algoritmalarıyla birlikte çalışma düzeninin hemen uygulanmasını mikro dünyanın engellemesi nedeniyle hareket planlama algoritmalarının testleri ve sonuçları sanal çalışma alanında gösterilmiştir. Fakat, nesne tabanlı programlamanın doğası gereği, hareket planlama algoritmalarını engelleyen problemler modellendiğinde sisteme kolaylıkla dahil edilebilip gerçek uygulamaya geçilebilir. Anahtar Kelimeler: Hareket planlama, mikromontaj, yolu planlama algoritmaları, nesne tabanlı programlama","In general, mechatronics systems have no standard operating system that could be used for planning and control when such devices are running. Our goal is to formulate a work platform that can be used as an environment for obtaining precision in the manipulation of micro-entities using micro-scale manipulation tools of our microsystem applications such as our microassembly workstation. The microassembly workstation setup is made up of the manipulation system, vision system, robust control system and manipulation tools. In this thesis we also provide groundwork for motion planning and assembly of the microassembly workstation manipulation system. We implemented the motion planning algorithms which are tested in the virtual workspace environment in order to demonstrate the functionality of the work platform. Firstly, we investigate the performance of the conventional Euclidean distance algorithm, then, artificial potential field algorithm, and finally A* algorithm when implemented on a virtual space. The physical conditions of the microworld hinder the immediate application of the work platform with the motion planning algorithms on the microassembly workstation. We demonstrate our test results of the motion planning algorithms on the virtual workspace and grid window of the work platform. However, due to object oriented programming nature of the work platform, eventually the work platform can be easily interfaced with the microassembly workstation once the problems which limit the micromanipulation and assembly are attended. Keywords: Motion planning, microassembly, path planning algorithms, object oriented programming"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hareket denetim sistemlerin önemi teknolojik gelişmelerin artması ile daha da artmaktadır. Teknolojik gelişmeler değişik çalışma alanlarını aynı çatı altında toplamaya teşvik ederken, gitgide karmaşıklaşan yapıdaki denetleyiciler belirsiz yapılı çevrelerde sistemlerin görevlerini gerçekleştirmeye çalışmaktadır. Hareket denetim sistemleri karışık yapılarından dolayı karışık ileri ya da ters kinematiklere sahip olabileceği gibi diğer sistemler ile karışık etkileşimlere de sahip olabilir. Bu çalışmada, sistemlerin hareketleri ?fonksiyon? diye adlandırılan görevlere ayrılmaktadır. Fonksiyon uzayında, bu fonksionlar için bağımsız denetleyiciler tasarlanmaktadır. Sistemin orjinal uzayına geri dönülüp, fonksiyon tabanlı denetleyici çıkışları doğrusal ekleme metodu ile birleştirildiğinde sistemin orjinal uzayında kontrol edildiği ispalanmaktadır. Bu yöntemin uygulanabilirliği çift taraflı sistemler ve paralel mekanizmalar ile gösterilmektedir. Çift taraflı sistem uygulamaları, bu yöntemin sistemlerin etkileşimini kontrol etmede ve sistemler arasında istenen fonksiyonel ilişkiyi kurabilmede kullanılacağını kanıtlamaktadır. Ayrıca, bağlı (coupled) ve doğrusal olmayan sistem dinamiklerine sahip olan paralel mekanizmalar ailesinden beş çubuklu bağlam (pantograph) ve üç bacaklı mekanizma incelemeleri, hareket denetim görevlerini gerçekleştirmek için oluşturulan uygun bir referans yapılandırmanın, sistem dinamiklerini ayırmayı ve basit denetleyiciler elde etmeyi sağladığını göstermektedir. Deney ve simülasyon sonuçları fonksiyonel denetimin haraket kontrol sistemlerinde uygulanabileceğini ve özelliklerinin bu sistemler için başarılı gelecek tasarımlar vaat ettiğini ortaya koymaktadır.","Motion control systems are gaining importance as more and more sophisticated developments arise in technology. Technological improvements enhance incorporation of different research areas into the same framework while trying to make systems function in unstructured environments renders the design of control systems increasingly complex. Since motion systems are complex, they have complex forward or inverse kinematics, or interactions with other systems. In this study, motion of the systems is decomposed into the tasks, so called ?functions?. Independent controllers are designed for these functions in the function space. It is proven that motion systems will be controlled in the original space if function based control outputs are superposed. Applicability of this method is demonstrated on bilateral systems and parallel mechanisms. Bilateral systems application proved that function based control can be used in controlling systems with interactions while establishing desired functional relation between them. Moreover, investigation of a pantograph and a three-legged manipulator, which come from the parallel mechanisms family and have nonlinear and coupled system dynamics, showed that creating an appropriate reference configuration to realize the task of motion control helps decouple system dynamics. Satisfactory simulation results show that functional control can be implemented and its characteristics promise successful future designs for motion control systems."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Anahtar Kelimeler: Esnek Bağlantılı Mekanizmalar, Paralel Mekanizmalar, Kiris Dinamiği, Dağınık Parametreli Sistemler Esnek bağlantılı mekanizmalar yüksek hassaslık gerektiren sistemlerde çok yaygın olarak kullanılmaktadır. Çünkü bu tip mekanizmalar yüksek çözünürlülük, sürtünmesiz, düzgün ve sürekli hareket sağlar. Bu tip mekanizmalar aynı zamanda diğer yüksek hassasiyet kazandıran mekanizmalardan maliyeti daha düsük olan sistemlerdir. Bu tip mekanizmaların temel fikri hareketi sağlamak için ilave bağlantı elemanları kullanmamaları, istenilen hareketi esnek elemanların eğilmesiyle sağlamalarıdır. Bu tezde, paralel ve düzlemsel olan esnek bağlantılı bir mekanizmanın tasarımı yapılmıstır. Mekanizma XY düzleminde hareket edecek sekilde üç noktasından piezomike mikro motorlar kullanılarak tahriki sağlanmıstır. Mekanizmanın matematiksel modeli, mekanizmada bulunan üç kirisin Euler Bernoulli dinamik denklemleri kullanılarak olusturulmustur. Değiskenleri ayırma metodu kullanılarak da bu denklemler çözülmüstür. Mekanizmanın merkezinin pozisyonu kirislerin eğilmeleri cinsinden yazılabilmesi için gerekli transformasyonlar hesaplanmıstır. Matematiksel model durum denklemlerine çevrilmis ve MATLAB Simulink kullanılarak benzetimi yapılmıstır. Benzetimden çıkan konum sonuçları COMET adı verilen baska bir benzetimle karsılastırılmıstır. Daha sonra sistemin matematiksel modeli, XY düzleminde pozisyon kontrolü PID kullanılarak yapılabilmesi için iki girisli iki çıkıslı sisteme indirgenmistir. Son olarak da, mekanizma lazer kesme ve su jeti kesme yöntemleriyle üretilmis, piezo motorlar elle ve voltaj sinyali vererek harekete geçirilerek sistemin açık döngülü deneyleri gerçeklestirilmistir.","Keywords: Compliant Mechanisms, Flexure Based Mechanisms, Beam Dynamics, Distributed Parameter Systems Compliant mechanisms are widely used in high precision systems, because they provide high resolution, frictionless, smooth and continuous motion. These kinds of mechanisms are also cheaper than the other types of high precision mechanisms. The main idea of this kind of mechanism is that no additional joints are used for creating the motion, the deflection of the flexible elements are used to create the desired motion. In this thesis, a planar parallel compliant mechanism is designed. The mechanism is actuated from three ends by using piezo mike micromotors to create motion in XY plane. The mathematical model of the mechanism is derived by using Euler Bernoulli dynamic equation for the three beams on the mechanism. The separation of variables technique is used to solve the dynamic equations. Necessary transformations are calculated for defining the center position of the stage in terms of the deflections of the beam. The mathematical model is represented in state space form and it is simulated in MATLAB Simulink. The position results are compared with another simulation called COMET. The mathematical model is reduced to two input and two output system in order to make the XY position control of the mechanism by using PID control. Finally, the mechanism is manufactured by using laser cutting and water jet cutting techniques, open loop experiments of the mechanism are verified by actuating the piezo motors manually and by giving voltage signal."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu calsmada, makro ve mikro duzeylerde gerceklestirilmis degisik gorevler icin deney sonuclarn degerlendirerek, modelden bagmsz gorsel geri beslemeli kontrol algoritmalar uzerine performans arastrmas yaplmstr. Modelden bagmsz yada bir diger adyla kalibre edilmemis gorsel geri beslemeli kontrol, komposit (imge+robot) Jakobyan' cevrimici olarak kestirebildiginden sistemin kalibre edilmesine (gorme sistemi + robotik sistem) ve incelenen ortamn modeline ihtiyac duymaz. Parametre degisimlerine ve bozucu ds etkilere kars gurbuzdur. Modelden bagmsz gorsel geri beslemeli kontrol yontemi 7 serbestlik derecesine sahip Mitsubishi PA10 robotik kol ve mikromontaj is istasyonu uzerinde test edilmistir. Makro dunyada, duzlemsel sekil hizalama icin yeni bir yaklasm sunulmustur. Sekil hizalama islemi, bir egrinin dsbukey zarf (convex-hull) kullanlarak elde edilen, iki noktada tegetler (bitangents) yardmyla gerceklestirilmistir. Hizalama islemi kalibre edilmis ve kalibre edilmemis gorsel geri beslemeli kontrol yaklasmlar kullanlarak gerceklestirilmis ve sonuclar karslastrlmstr. Buna ilave olarak, modelden bagmsz gorsel geri beslemeli kontrol kare, cember ve sinus gibi degisik yorunge takibi gorevleri icin denenmistir ve bu yorungeler kendileri boyunca ara hede er ureten bir dogrusal aradegerleyici kullanlarak olusturulmustur. Modelden bagmsz gorsel geri beslemeli kontrol metodunun, kalibrasyonu oldukca usandrc ve hata olaslg yuksek olan ve ayrca her farkl yaknlastrma seviyesinde sistemin yeniden kalibre edilmesini gerektiren optik sistemlerde kullanm oldukca rahatlk saglamaktadr. Bu nedenle makro dunyada yaplanlarn dsnda, mikrokonumlandrma ve uc farkl yorunge takip gorevi de mikro dunyada gerceklestirilmistir. Sunulan deneysel sonuclar, modelden bagmsz gorsel geri beslemeli kontrol algoritmalarnn makro ve mikro duzeylerde gerceklestirilen gorevlerde kullanlmasnda sagladg faydalar ortaya koymustur. Anahtar Kelimeler: Model bagmsz, gorsel geri beslemeli kontrol, sekil hizalama, iki noktada tegetler, mikrosistemler","This thesis explores model free visual servoing algorithms by experimentally evaluating their performances for various tasks performed both in macro and micro domains. Model free or so called uncalibrated visual servoing does not need the system (vision system + robotic system) calibration and the model of the observed scene, since it provides an online estimation of the composite (image + robot) Jacobian. It is robust to parameter changes and disturbances. A model free visual servoing scheme is tested on a 7 DOF Mitsubishi PA10 robotic arm and on a microassembly workstation which is developed in our lab. In macro domain, a new approach for planar shape alignment is presented. The alignment task is performed based on bitangent points which are acquired using convex-hull of a curve. Both calibrated and uncalibrated visual servoing schemes are employed and compared. Furthermore, model free visual servoing is used for various trajectory following tasks such as square, circle, sine etc. and these reference trajectories are generated by a linear interpolator which produces midway targets along them. Model free visual servoing can provide more exibility in microsystems, since the calibration of the optical system is a tedious and error prone process, and recalibration is required at each focusing level of the optical system. Therefore, micropositioning and three dierent trajectory following tasks are also performed in micro world. Experimental results validate the utility of model free visual servoing algorithms in both domains. Keywords: Model free, visual servoing, shape alignment, bitangents, microsystems"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"Keywords: phased arrays, acoustic imaging, object detection, ultrasound,FDTD The acoustic imaging technology is widely used for medical purposes and underwater imaging. In this work, an ultrasonic phased array device is developed by using piezoelectric transducers to provide autonomous navigation for robots and mobility aid for visually impaired people. To perform acoustic imaging, two different linear transducer arrays are composed with phase-delay focusing phenomenon in order to detect proximate objects with no mechanical scanning. The requirement of half wavelength spacing can not be satisfied between elements, because of using general purpose transducers. The transmitter array is formed by aligning the transducers with minimum spacing between them, which is 2.11 times of the wavelength. This placement strategy leads to the occurrence of unwanted grating lobes in the array response. To eliminate these grating lobes, the receiver array is formed with a different spacing between each transducer. By forming the receiver array and the transmitter array non-identical, the directivity pattern for both arrays become different. The off-alignment between two arrays causes the grating lobes to appear at different places. Since the overall gain of the system is the product of receiver gain and transmitter gain, the grating lobes diminish for the overall system. The developed phased array device can transmit/receive ultrasonic waves to/from the arbitrary front directions using electronic sector scanning circuits. A detailed scan can be performed to detect the presence of an object or distinguish different objects."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde, akdeniz anemisi gibi birçok kalıtsal hastalığın genlerde olan mutasyonlar sonucu ortaya çıktığı bilinmektedir. Bu hastalıkların ilerlemelerinin ve hatta ortaya çıkmalarının engellenmesini sağlayacak yöntemlerin bulunması konusunda mutasyonlar ve bu mutasyonların gerçekleştiği genlerin bilgisi büyük önem taşımaktadır. Hastalıklara ilişkin mutasyon ve gen bilgilerine herkese açık veri bankalarından ve biyomedikal literatür kaynaklarından erişmek mümkündür. Yalnız, bu kaynaklardan ilgili bilgilerin elde edilmesi iki sebepten ötürü problemli olabilir. İlk olarak bilgilerin elle girildiği veri bankaları genellikle eksik ve güncel olmayan bilgiler içermektedirler. İkinci olarak çok büyük miktarda biyomedikal dökümanı okumak oldukça zaman almaktadır. Bu yüzden ilgili bilgileri erişime açık mevcut kaynaklardan otomatik olarak çıkartacak sistemlere ihtiyaç vardır. Bu tezde, istenilen bir hastalık için MEDLINE özetlerinden mutasyongen çiftlerini otomatik olarak çıkartan MuGeX isimli sistemin tasarımı ve uygulanması sunulmaktadır. MuGeX sistemi temel olarak üç işlem gerçekleştirmektedir. İlk işlem, özetlerde geçen mutasyonların örüntü eşleştirme yönteminin bir makine öğrenimi algoritması ile birlikte kullanılması yolu ile tanımlanmasıdır. İkinci işlem, gen isimlerinin sözlük kullanımına dayanan bir metod ile tanımlanmasıdır. Sonuncu işlem ise mutasyonlar ve genler arasında yakınlık göz önünde bulundurularak ilişkilerin kurulmasıdır. Gerçekleştirilmiş olan deneylerin sonuçları gösteriyorki MuGeX deney özetlerinde mevcut olan mutasyonların %85.9'unu %95.9 doğruluk oranı ile bulmaktadır. Mutasyongen çiftlerinin tanımlanması işlemi için Alzheimer hastalığına odaklandık. Gözlemlediğimiz üzere MuGeX Alzheimer hastalığına ilişkin mutasyongen çiflerinin getirilmesinde %88.9'luk bir doğruluk oranına sahiptir.","Nowadays, it is known that several inherited genetic diseases? such as sickle cell anemia, are caused by mutations in genes. In order to find ways to prevent and even better to circumvent occurrence of these diseases, knowledge of mutations and the genes on which the mutations occur is of crucial importance. Information on disease related mutations and genes can be accessed through publicly available databases or biomedical literature sources. However, acquiring relevant information from such resources can be problematic because of two reasons. Firstly manually created databases are usually incomplete and not up to date. Secondly reading through vast amount of publicly available biomedical documents is very time consuming. Therefore, there is a need for systems that are capable of extracting relevant information from publicly available resources in an automated fashion. This thesis presents the design and implementation of a system, MuGeX, that automatically extracts mutationgene pairs from MEDLINE abstracts for a given disease. MuGeX performs mainly three tasks. First task is identification of mutations, applying pattern matching in conjunction with a machine learning algorithm. The second task is identification of gene names utilizing a dictionarybased method. The final task is building relations between genes and mutations based on proximity measures. Results of experiments indicate that MuGeX identifies 85.9% of mutations that are on experiment corpus at 95.9% precision. For mutationgene pair extraction, we focused on Alzheimer?s disease. We observed that 88.9% of mutationgene pairs retrieved by MuGeX for Alzheimer?s disease are correct."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mikro-manipülasyon uygulamalarında sıklıkla çok köşeli nesnelerin düzlemsel bir yüzey üzerinde konumlanması ve yöneltilmesi amaçlanmaktadır. Mikro nesneleri nokta teması sağlayarak itmek tutup sonra yerleştirme operasyonuna göre daha esnek ve daha az karmaşık bir yöntemdir. Mikro dünyada yüzey kuvvetlerinin atalet kuvvetlerine göre daha baskın olmasından ve bu kuvvetlerin düzensiz dağılımından dolayı, bir mikro nesneyi ağırlık merkezi doğrultusunda itme yöntemi sadece doğrusal bir harekete sebep olmamaktadır. Bir mikro nesneyi sadece doğrusal yönde hareket ettirebilmek için, itme yönü sürtünme merkezinden geçmelidir. Ayrıca, mikro nesne ve taban arasındaki sürtünme kuvvetlerinin beklemeyen mizacından dolayı, itici milde ya da mikro nesnede oluşabilecek zararları engellemek için, mikro nesneye uygulanan maksimum kuvvet değeri sınırlanmalıdır. Bu tezde, özel üretilmiş bir uzaktan mikro manipülasyon düzeneğini kullanarak, insan yardımı ile mikro nesneleri sadece doğrusal yönde hareket ettirmeyi başaran bir yarı-otomatik manipülasyon tasarısı önerilmektedir. İtme operasyonu eş zamanlı gerçekleşen iki adet sürece ayrılabilir. İlkinde, kuvvet ve konum kontrolleri arasında geçiş yapmak için empedans denetleyicisi gibi davranan operatör, kuvvet geri beslemeli, ölçekli ve iki yönlü uzaktan kumanda etme yöntemi ile mikro nesnenin hızını değiştirir. Diğer süreçte ise, mikro nesnenin istenen itilme yönü, her zaman değişken olan sürtünme merkezinden geçecek şekilde belirlenir. Mikro nesnenin sadece doğrusal bir hareket yapmasını sağlamak için, temas noktasındaki bileşke hız vektörünün sürtünme merkezinden geçmesini sağlayan görsel geri besleme prosedürleri benimsenmiştir. Önerilen denetleyicinin etkinliğini ispatlamak için deneysel sonuçlarla birlikte nanometre ölçüsünde konum kontrolü, nano Newton ölçeğinde kuvvet algısı ve kuvvet geri beslemeli, ölçekli ve iki yönlü uzaktan kumanda etme yöntemi gösterilmiştir.","In micromanipulation applications, it is often desirable to position and orientpolygonal micro-objects lying on a planar surface. Pushing micro-objects using pointcontact provides more flexibility and less complexity compared to pick and place operation.Due to the fact that in micro-world surface forces are much more dominantthan inertial forces and these forces are distributed unevenly, pushing through thecenter of mass of the micro-object will not yield a pure translational motion. Inorder to translate a micro-object, the line of pushing should pass through the centerof friction. Moreover, due to unexpected nature of the frictional forces between themicro-object and substrate, the maximum force applied to the micro-object needsto be limited to prevent any damage either to the probe or micro-object. In thisdissertation, a semi-autonomous manipulation scheme is proposed to push microobjectswith human assistance using a custom built tele-micromanipulation setupto achieve pure translational motion. The pushing operation can be divided intotwo concurrent processes: In one process human operator who acts as an impedancecontroller to switch between force-position controllers and alters the velocity of thepusher while in contact with the micro-object through scaled bilateral teleoperationwith force feedback. In the other process, the desired line of pushing for themicro-object is determined continuously so that it always passes through the varyingcenter of friction. Visual feedback procedures are adopted to align the resultantvelocity vector at the contact point to pass through the center of friction in orderto achieve pure translational motion of the micro-object. Experimental resultsare demonstrated to prove the effectiveness of the proposed controller along withnanometer scale position control, nano-Newton range force sensing, scaled bilateralteleoperation with force feedback."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Coğrafi bilgi görselleştirmesi teknikleri oldukça uzun bir süreçte geliştirilen geniş birçeşitliliğe sahiptir. Bilinen tekniklerin çoğu az boyutlu coğrafi verilerin görselleştirmesi içinyetkin olsalar da, çok boyutlu verilerin coğrafi bağlam içerisinde görselleştirilmesine dairoldukça az sayıda metod önerilmiştir. Bu tez, coğrafi bileşenleri olan ve zamana bağlı değişenağ verilerinin coğrafi çerçeve içerisinde görselleştirilmesi problemini araştırmaktadır. Tezinsonucu olarak önerilen görselleştirme sistemi, verinin niteliksel özelliklerini görselleştirmekiçin çok boyutlu veri görselleştirmesi teknikleri ile harita görselleştirmesi tekniklerini birarada kullanırken, istatistiksel nicel değerlerin incelenmesi için çubuk ve yay gibi klasik ağgörselleştirmesi tekniklerini kullanmaktadır. Ortaya çıkan görselleştirme sistemi veriiçerisindeki uzaysal olmayan bileşenlerin uzaysal bileşenlere göre değişiminin algılanmasınayardımcı olmaktadır.","Visualization techniques for geographic data show vast variations which are well-developedover centuries. While most of the known techniques are sound for low dimensional data sets,few techniques exist for visualization of high dimensional data within the geographicframework. This thesis investigates visualization of temporal, high dimensional network datawithin the geographic context. The resulting visualization system employs networkvisualization techniques in conjunction with cartographic visualization methods for providinga qualitative feel for the data, while conventional methods are employed for detailedexamination. In turn, the visualization facilitates comprehension of non-spatial variables withrespect to the geographic context."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dokunma hisli (haptik) sistemlerin gelişimi, 1950'lilerdeki açık döngülü uzaktankomutalı sistemlerden bugünkü modern dokunsal öğretim ve cerrahi destek tertibatlarınakadar süren uzun bir yol katetmiştir. Uygulama alanları minimal invaziv cerrahidenastronotlar için uzay eğitim sistemlerine kadar uzanmakta olup, yine de gelişme için geniş biralan bulunmaktadır. Çeşitli alanlarda gelişen uygulamalar dokunma hisli ara yüzler içinbirçok talep ortaya koymaktadır. Sadakat, geniş çalışma alanı ve yüksek kuvvet/torkkapasitesi bu talepler arasındadır.Bu tezde dokunma hisli ana kolun tasarımı üzerine yoğunlaşılmıştır. Sistemin dinamiközelliklerinin analizi ile oluşturulmuş mekanik sistem, elektronik donanım, ileri ve terskinematik çözümleri için algoritmalar ve algılayıcı ve eyleyici uyumu için yazılım; dokunmahisli etkileşimin alt yapısını oluşturmak için geliştirilmiştir. Her ne kadar bu tasarımda anatasarım kriterleri geniş iş alanı, yüksek kuvvet/tork kapasitesi olsa da geliştirilen altyapının birparçası olarak sadakat kriterini geliştirmek amacıyla dinamik telafi teknikleri de tezdeişlenmiştir. Tezin ana konusu dokunma hisli denetleme algoritmaların tasarımından çokdokunma hisli uygulamalar için yazılım ve donanım tasarımıdır.Tezde ilk olarak haptik arabirimler ve kol tasarım kriterleri üzerine yapılan literatürtaraması sunulmuştur. Genel ve çok amaçlı, aynı zamanda ergonomik bir kol için tasarımbelirtimleri belirlenmiştir. Newton-Euler tabanlı benzeşim teknikleri kullanılarak eyleyici vetransmisyon elemanları seçilmiştir. Haptik denetleme algoritmalarının gerektirdiği algılayıcıve denetleyici donanımı seçilmiştir. Tasarlanan manipülatör için dinamik telafi teknikleriüzerinde durulmuş ve bu teknikler benzeşim ortamında denenmiştir. Son olarak tasarlanan kolmonte edilmiş ve elektriksel bağlantıları yapılmıştır. Tez sonuçların sunulması ve tartışılmasıile sonlandırılmıştır.","From the open-loop tele-operator systems of 1950?s to the modern kinesthetic trainingand surgery support setups, haptic systems took a long way of evolution. Application areasranging from minimally invasive surgery to space training systems for astronauts, still there isa large room for improvements. The vast areas of emerging applications put a number ofdemands on haptic interfaces. Fidelity, large workspace and high force/torque capacity areamong those demands.The thesis concentrates on the design of a haptic master arm. The mechanical systemwith an analysis of dynamics properties, electronic hardware, algorithms for forward andinverse kinematics and software for the integration of sensors and actuators are developed tocreate an infrastructure for haptic interaction. Though the major design criteria applied in thisdesign are a large workspace and high force/torque capacity, dynamics compensationtechniques are also discussed as part of the developed infrastructure. The main focus of thethesis is the design of this hardware and software base for haptic applications rather than thedesign of haptic control algorithms.A survey on haptic interfaces and master arm design criteria is presented firstly. A set ofspecifications for the master arm is determined for a general and multipurpose yet ergonomicuse. Newton-Euler based simulation techniques are employed for the component selection.Sensors and controller hardware are selected according to the demands of the haptic controlproblem. Dynamics compensation techniques for the designed manipulator are considered andtested in simulation. Finally the designed master arm is assembled and electrically integrated."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, network üzerinden çalışan, eğitim amaçlı doku ve organ simülasyonları veyaişbirliği yapılabilen sanal ortamlarda kumaş simulasyonları için kullanılabilecek, 3boyutlu kapalı yüzeylerin deformasyonu için uygun bir metod sunuyor. İşbirliğiyapılabilen sanal ortamlar (İSO) uzun yıllardır çok yaygın olarak eğitim, dizayn veoyun amaçlı kullanılmaktadır. İSO da, deforme olabilen bir nesneyi canlandırabilmekiçin, doğrusal sonlu eleman bölünmesine uğramış bir yüzeye dayanan eşit gerginliktebir zarın gerçek zamanlı fiziksel simulasyonu, yüzeyden çıkarılan seyrek denklemsistemi Runge-Kutta Fehlberg methodu ile çözülerek yapılmıştır. Sunulan metodfiziksel simulasyonun hesap yükünü kullanıcılar arasında bölen bir mimari ortayakoyuyor. Yaklaşımımız benzetimi yapılan muntazam bir ağ yapısı gerektirdiği içinaynı zamanda düzensiz üçgenlenmiş sıfırıncı takımdan yüzeyleri, düzenli bağlantılarıolan muntazam işlenmiş ağ yapılarına çeviren bir algoritma dizaynı yapıldı vetamamlandı. Algoritma küresel parametrizasyon adımında esnetme optimizasyonuiçin yay düzenekleri kullanmaktadır. Yaklaşımımız gücünü grafik gösterim, fizikselsimulasyon ve network iletşimi sırasında kullanılan, simulasyon doğruluğu ve grafikgösterminden ödün vermeyen, farklı çözünürlüklü alt bölümlere ayırmametodolojisinden almaktadır.V","This thesis presents a method for deformations on closed surfaces in 3D over anetwork, which is suitable for simulation of tissue and organs for training purposes, aswell as cloth simulation in collaborative virtual environments (CVE). CVE's areextensively used for training, design and gaming for several years. To demonstrate adeformable object on a CVE, we employ a real-time physical simulation of a uniform-tension-membrane, based on linear finite-element-discretization of the surfaceyielding a sparse linear system of equations, which is solved using the Runge-KuttaFehlberg method. The proposed method introduces an architecture that distributes thecomputational load of physical simulation between clients. As our approach requires auniform-mesh representation of the simulated structure, we also designed andimplemented an algorithm that converts irregularly triangulated genus zero surfacesinto a uniform triangular mesh with regular connectivity. This algorithm uses spring-embedders for stretch optimization of the spherical parameterization step. Thestrength of our approach comes from the subdivision methodology that enables to usemulti-resolution surfaces for graphical representation, physical simulation, andnetwork transmission, without compromising simulation accuracy and visual quality.IV"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,">""$(9 ""2$""!"" (& ,$$""!"" ?!$& @ 6""!,&, ""!,!""6 3& %,!(""3, 39$'$$""!,36$6$$""&,#,3@$$2$'(&""&%""""$""&,@$""!,!7 ( ?!$&@6""!,&,?6($63&""@6""!A&!""!@6&$?B+ C -!& ""!,!""& 3!3- !$@ $""!,,!7 D 3""$,@"""" %,!(""3, 39$'$ $""!,3!3- !$@!$""!,$"" !$6 '$""&,@,!7   ;/.7<<&   ;/.7<<& >""$(9 E!$ 2$""!,&"" '$""&"" "" 6$$""&,$""& 3!3- !$@! $ !$6 -""! $""& %,!(""3, 39$'$ $""!,&,& 6$$""&,,& ) $"",2, 'A(!$@!72""6)$""?!$&@6""!,&,&36$""""63&6""&""$!$""!,&, -6!6!$""!,&,!$62!$&!&&39$'$$""!,'$@!$@!7 &$,639$'$!6$!&'A!$""),$""#""66$$""&,#,,(3&39$'$#$!& ""&, (,!"" "" "" 9& 9""""& ""!""$,6$""!,&"" 'A! ?!$& @ 6""!,&, & 36$""""& 39$'$ A&$! A&!$@!7 D 39$'$#$! ;/.7<<& 3&  9 &#"" '$@!$&6!6$""""$&&3,6""!,$""&(&3$""!""&%""""$""&""6"",!$""!7F&!$& &""$'!""$""!:""!,&,$,&9 (&3$""!, (&#&"" %,!(""3,$""""&-""3 'A9$? 39$'$#$!'A!""2""6)$""?!$&@6""!,&""A&$""!,@'A(!@$!!7 $@!$& ""$'!""$""! ""!,#"" ?!$& @ 6""!, - &6(!$$6 6&(&""  ! (3 (&""6"",!$""!7 !3- !$@!#$ 39$'$#$! !A$$ 6$$""&,,&,& 6$!&#$&@!7","$(!-!() &&& ""(&4)$-""))!&(#(# $&' %! &#!""(&' ((  !' ) & 5!$(( &5!6( !#&$7 !"" ""''!'""& 5 # &#!""(( + %%#&#(""& ! && ""&#&'(( !' )7 ))!&(#(# $&' ""(&)$8&$5 %!""""''!'""&&!! ""49 (( !' )& (5!67 (%4(&'))!&(#(# ( ""( & ( 5& &   )""$ 5 & %!"" ""''!'""& ( (: ""( ""))$ &     ;/.7<<& !$(( #""$ !"" 5!6 (""&""!7 5 (# $&' ""))!""# ( 5 #  #& # ""&&$ (""( 5  * (""( ""- & )!)( 5    "" % ""49&'   ""$ &5!6  !' )7 & ""&  (# $!( 5 #  ($# !""&( (!( ""##!&'  &(""&""&( (# $&' !#(: (# $!( 5 #  ""49 !' )-!$""!'!&!-""$( ""-&)!)(7 ( (# $!( $9!($(""&%! *&'$-$)%!;/.7<<& !'  (  ((7   )!)( &5 ""$'! ( ""! ( 5&  %%! ('&%#""& )!-& & &5!6  !' ) -! &&=))!&(# ""& '! (# $!(  !'  ""$ ($""&(7   -$) ""$'! ( ""$( )!- "" ' #)!( 5&  !' )""& %""!&((7 %%#%&#!)!""&' !$""&'& (# $!(""))$ %! %!""""''!'""&((( ""(""$(&""&""$97"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KABLOSUZ DUYARGA AĞLARI Ç N KONUŞLANDIRMA B LG S KULLANILANBAS T VE ESNEK, RASTLANTISAL ÖN YÜKLEMEL ANAHTAR DAĞITIMŞEMALARISinan Emre TAŞÇIÖZETDuyarga düğümleri genellikle değişik alanlara belirli bir tipteki veriyi algılamakmaksadıyla dağıtılan küçük, düşük enerjiyle çalışan ve pil gücü zayıf elektromekanikcihazlardır. Hafızaları ve sayısal hesaplama kabiliyetleri kısıtlı olduğundan dolayı açıkanahtarlı şifreleme sistemleri (PKC) duyarga düğümlerinin güvenliğini sağlamak içinkullanılmaya uygun değildir. Açık anahtarlı şifreleme sistemlerinin yerine özel(tek) anahtarlışifreleme teknikleri tercih edilmektedir fakat duyarga düğümlerinin hafıza kısıtlarından dolayıhala özel anahtarlı şifreleme sistemlerinin kullanımıyla ilgili sorunlar mevcuttur. Bir duyargadüğümüne yüklenebilecek anahtar sayısı o düğümün eldeki hafıza miktarı tarafından belirlenirve özel anahtarlı şifreleme yöntemlerinin kullanılmasını da sınırlandırır. Böylelikle birduyarga düğümüne dağıtılan anahtar sayısını azaltabilecek yeni anahtar dağıtımmekanizmalarına ihtiyaç ortaya çıkmaktadır.Duyarga düğümlerinin hafıza sorunlarının üstesinden gelebilmek için rastlantısal önyüklemeli anahtar dağıtım mekanizmaları önerilmiştir. Bu mekanizmalar duyarga ağlarınıngüvenliğinin sağlanmasında genel kabul görmüşlerdir. Basit olarak bu mekanizmalar her birduyarga düğümüne yüklenen anahtar sayısını azaltmaya çalışırken aynı zamanda duyargaağlar için kabul edilebilir seviyede güvenlik sağlamaya çalışmaktadırlar.Şu ana kadar önerilen rastlantısal ön yüklemeli anahtar dağıtım mekanizmalarının bazıeksiklikleri vardır. Bazıları çok karmaşık, bazılarının ise uygulaması çok zordur. Önerilenmekanizmaların uygulanabilir olanlarının gerçek dağıtım senaryoları düşünüldüğünde gerçekdışı kabullenmeleri mevcuttur. Bu tezde uygulanması ve dağıtılması kolay rastantısal önyüklemeli anahtar dağıtım mekanizmaları önerilmektedir.Bu tezde öncelikle genel bir ön yüklemeli anahtar dağıtım şeması önerilmiştir. Dahasonra bu genel mekanizmanın üzerine bina edilmiş üç rastgele ön yüklemeli anahtar dağıtımmekanizması önerilmiş, bunların simülasyon neticeleri sunulmuş ve literatürde iyi bilinenşemalarla karşılaştırmaları yapılmıştır. Genel mekanizma dağıtım ihtiyaçlarına göre farklışemaların türetilmesine olanak tanır. Ayrıca basit, kolaylıkla dağıtılabilen, kabul edilebilirbağlantı oranı ve dayanıklılık sağlayan mekanizmalar önerir.","SIMPLE AND FLEXIBLE RANDOM KEY PRE-DISTRIBUTION SCHEMES FORWIRELESS SENSOR NETWORKS USING DEPLOYMENT KNOWLEDGESinan Emre TAŞÇIABSTRACTSensor nodes are tiny, low-power and battery constrained electromechanical devicesthat are usually deployed for sensing some type of data in different types of areas. Because oftheir memory and computational restrictions, public key cryptography (PKC) systems are notsuited for sensor nodes to provide security. Instead, private key cryptography is preferred tobe used with sensor networks and there has been considerable work in this area, but there stillexist problems with private key cryptography because of memory restrictions of sensor nodes.Number of keys that can be deployed into a sensor node is determined by the availablememory of that node which is limited even private key cryptographic techniques are applied.So, new key distribution mechanisms are required to decrease number of pairwise keys thatare deployed into a sensor node.Random key pre-distribution mechanisms have been proposed to overcome memoryrestrictions of sensor nodes. These mechanisms are widely accepted for sensor networksecurity. Simply, these schemes try do decrease the number of keys to be deployed in eachsensor node in a sensor network and provide reasonable security for the sensor network.Random key pre-distribution schemes proposed until now have some deficiencies.Some of these schemes are too complicated and too difficult to be applied. Schemes that seemdeployable involve unrealistic assumptions when real world scenarios are considered. In thisthesis, we propose random key pre-distribution mechanisms that are simple and easilydeployable.In this thesis, we first developed a generalized random key pre-distribution scheme.Then we proposed three random key pre-distribution mechanisms based on this generalizedscheme and we provided their simulation results and their comparison to well-known randomkey pre-distribution schemes in the literature. Our generalized scheme allows differentsystems to be derived according to deployment needs. It offers simple, easily deployabledistribution mechanisms and provides reasonable connectivity and resiliency with respect toits simplicity."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"!% '  #% #))%$#!( #(  ! #,'#! &#A!4(  ! )!!#$!! "" (4!))%!'A##%((!(@A""$""$!%%$ (D( )!(!@ !#! ! ,()( !& #$,(1!( #,'#! &#A!4( #$4 %!$#! #  ""# ' !& "" (  "" '%!#% $!! # &# (' %!#% !(!' ( 23 ##1  "" !"" ""# @  "" A##% $!)' ## (#$""((  #'%# ##!&""#! ('(""%!$#%$!! #&# ('#%!#!#$4(1 )!)!(#$!#!!&'%!#%# %!$#%$!! # &##))!#$""(#  )!,  # $!BC#A# #$! &#A!4 &! !% ,$(  (#%((% $""#'' #)""$#% ( &#$( 2 (3 &! ) (#( A# '  # ,!(1""((( (' # ( !#(!#%'#%(((#23 #( ""# ""% )!!)! A""#$,# #%!#!#$41 ! $(#""! !(#!#!!&#!%(D(""# 1""$!'! #%'!""(#( !(##(!('' C%##%((!&)$""#'%#  #'%# ,%!$ !& "" !#! #$41 "" )!!) (( $# &&# A"")!((($$((&%%1#((!$# #$"")!(A"" &&$!B( A""$"" # !& ( &! ) (# #,'#! (((> ,('#!@ #,'#! #  %1 ""(@A! $"" #""#!$!#!#$4($#)#!&!% $!)(@ "" $#  (  ! $# ##% #$! $""*( A"" !% $!)(1"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,Ã ÃÇ ÃÃÃÃ ÃÃ ÃÃ Ã ÃÃ Ã ÃÃÃ ÃÃ ÃÃ ÃÃÃÃÃÃÃÃÇÃ ÃÃÃ ÃÃÇÃ ÃÇÃÃÃ Ã İ ÃÃ Ã ÃÃ ÃÃ Ö Ã Ã İ Ã ÃÃ Ã ÃÃÃÃÃ Ã Ã ÃÃ Ã Ö Ã Ã Ã Ã ÃÃ ÖÃÃ Ã ÃÃ Ã ÃİÃ ÃÃ Ã Ã Ã Ã Ã ÖÂº ÃÃ ÖÃ Ã ÃÃÃÃÃÃ ÃÃÃÃ Ã Ã Ã Ã Ã ÃÃ ÃÃ ÃÃ Ö Ã Ã Ã Ö ÃÖÃ ÃÃ Ã İ Ã ÃÃ Ã Ã Ã Ã Ã Ã ÃÃ Ã ÖÂº Ã Ã Ã Ã Ã ÃÃ Ã Ö Ã Ã İ ÃÃ Ã ÃÃ ÃÃ Ö Ã Ã İÃ Ã Ã Ö ÃÖÃ ÃÃÃ Ã ÃÃ Ã Ö Ã Ã Ã ÃÃÃ ÃÃ Ã Ã ÃÃ Ã ÖÃ Ã Ã Ã ÃÃ Ö Ã ÃÃ Ã Ã Ã Ã ÃÃ Ã Ö Ã Ã ÃÃ Ö ÃÃ Ã ÖÖ Ã Ã ÖÂº Ã ÃÃÖ Ã Ã ÃÃ Ã Ö ÃÃÃÃÃÃÖÃ Ã Ã Ã Ã Ã Ã Ã Ã ÃÃ Ã ÖÃ ÃÃ Ã Ã Ö Ã ÃÃ ÃÃ Ã Ö Ã ÖÃ Ã Ö Ã Ã Ã Ã Ö ÖÃ ÃÃ Ö Ã Ö Ã Ã Ã Ã Ã Ã ÖÃÃÃ ÃÃÃ Ö Ã Ö Ö Ã ÖÃ Ã ÖÂºÃ Ã Ã ş Â¬ÃÃ ÖÂ» Ö ÃÃ Ã Ã ÃÃ ÃÃ Ã Ã ÖÃ ÃÃ ÃÃÃ Ö Ã Ã Ã Ö ÃÖÃ ÃÃÃ Ö ÃÂ¹Ã ÃÃ Ã ÖÂº Ã ÃÃÖ Â¬ÃÃ ÖÂ» Ö ÃÃ Ã Ã Ã ÃÃ ÃÃ ÃÃ Ö Ã Ã Ö Ã Ã Ã şÃÃ Ã ÃÃ Ã Ã Ã ş Ã Ã Ã Ã ş Â¹ ÃÖÃÃÃÃ İ Ã ÃÃ Ã Ã Â¿Â¹ ÃÖÃÃÃÃİ Ã ÃÃ Ã Âº ÃÃ ÃÃ Ö ÃÃÃ Ã ÃÃ ÃÃ Ö Ã Ã Ã Ã Ã Ã Ã ÃÃÃÃ Ã Ö ş Ã ÖÃ Ã İÃ Ã ÃÃ Ö Ã ÖÃ Ã Ã Â­ İ ÃÃ Ã Ö Ã Ö Ã ÃÖ ÖÃ Ã Ö Ã Ã ÖÂºÃ ÃÃÃÃÃÖ Ã ÃÃ ÃÃ Ã Ö Ã ÃÃ ÃÃ Ã ÃİÃÃÃ Ö Ö Ö İ Ã Ö Ã Ãş ÃÖÃ Ã Ö ÃÖÃ ÃÃÃ ÖÃ Ã Ã Ã Ã ÃÃ Ã ÃİÃÃÃ Ö Ã Ã Ã Ã Ã Ã ÃÃÃÃ Ã Ö Ã Ã ÃÃ Ã Ã ÖÃ Ã Ã ÃÃ ÃÃÃ Ã ÖÃÃÃ Ã ÃÃ ÃÃ Ö ÖÃÃ Ö ÃÃÃ ÃÃ Ã ÂºÃ Ã Ã Ãİ ÃÃ Ã Ã Ö Ã ÃÃÖ Ã Ö İ ÃÃ Ã ÃÃ Ã Ö Ã Ã Âº Ã Ã ÃÃ ÃÃş Ã ÃÂ¹ Ö ÃÃ Ö Ã Ã ÃÃ ÃÃ ÃÃ Ã Ã ÃÃÃ Ã ÃÃ ÃÃ Ö Â¿ Ã ÃÃ Ã Ã Ã Ö Ã ÃÃÃÃ Ã ÂºİÖ Ã Ã Ã Ã Ã Ã Ö ÃÖÃ ÃÃ ÖÃÃ ÖÃ Ã Ã ÃÃ Ã Ã Ö Ã ÃÖ Ã Ö Ã Ã Â¹İÃÃÃ Ã İÃ ÖÃ ÃÃ Ö ÃÃ Ã İÃÃÃÃ Ã Âº Ã ÃÃ Ã Ã ÖÃ ÖÃ ÃÃ ÖÃ Ã ÖÃ ÃÃ ÃÖÖ Ö Ã Ö ÃÃ Ãş ÃÃÖ Ã ÃÃ Ö İÃÃ Ã Ã Ã Ö ÃÃÖÃ Ã Ã Ã ÖÃ Ã Âº Ã Ã ÃÖ Ã ÃÃ Ö Ã Ã Ã Ã Ã Ã Ã Ã ÃÃ Ã Ã Â± ÂºÂ¾ Ã Ã Ã Ã Ã Ã Ã ÖÃÃÃ ÃÃ ÃÃ Ã Ã ÂºÃ Ã ÖÃ ÃÃ Ã Ö ÃÃ Ã Ã ÖÃ Ã ÖÃ Ã Â»ÇÃ Ã ş ÃÃ ÖÂ» Ö ÃÃ Ãş İÂ¹ÃÃ Ã ÃÃ ÃÃ Ö ş Ã Ã Ã Ã Ã ş ÃÃ Ã Ã ÖÃ ÇÃ ÃÃÃ Ö Â»ÇÃ ÃÃ ÃÖ,ÃÃÃ Ã ÃÇ Ã Ã ÃÇÃ Ã Ã Ã ÇÃ Ã Ã Ã ÃÃÃ Ã ÇÃÃÃÇÃ Ã Ã ÃÇ Ã Ã ÃÃ ÃÃÃÃÖ ÃÃÃ ÃÃÃ ÖÃ Ã ÃÃ Ã ÃÃ Ã ÃÃÃ Ã ÃÃÃ Ã Ã Ö Ã Ã ÃÃ ÃÃ ÖÃÃ Ã Ã Ö ÃÃ ÃÃÃ Â¹ÃÖ Ã ÃİÂº ÃÃÛ Ã Öş Ã Ã Ö ÃÖÃ Ã Ã ÃÖÖ ÃÃ ÃÃ Ö Ã Ã Ã ÃÃ ÃİÃÃ ÃÃ Ö ÖÖÃÃ Ã Ö ÃÂº ÃÃ ÃÖ Ö ÃÃ ÃÃ Ã ÃÃ Â« Ã Ã Ãİ Û Ã ÃÃ Ö Ã ÃÃ Ö Ã Ã Ã ÃÃş ÃÃÖ Ã ÃÃÂ¬ Ã Ã ÃÖ Ã Ã Ã ÃÃ Ã ÃÃÃ ÃÃÃÃİ Âº ÃÃ Ã ÖÃ Ã ÃÃÂ¬Â¹Ã Ã ÃÖ ÃÖ İÃÃÃ Ã Ãş ÖÃ Ã ÃÃÂ¬ Ã ÃÃÖ Ã Ö ÃÃ Ã ÂºÃÃ Ã Ã Ã Ã Ãş Ã Ã Ö ÃÖÃ Ã Ã Â¬ÃÃ ÖÂ¹ÃÃ Ã Ã ÃÃÂ¬ Ã ÃÃÖ Ã Ã ÃÃÃ ÃÃ Ã Âº Ã ÃİÃ Ã Ã Â¬ÃÃ Ö ÃÃ Ã Û Ö Â¬Ã ÃÖ Ã ÃÃ Â¹Ã ÃÛÃÖ ş Ã ÃÃ Â¹Ã ÃÛÃÖ ş Ã ÃÃ Â¹ Ã ÃÃ Ã ÃÛÃÖ ş Â¹ÃÃ Ã Ã Â¹ ÃÃ ÃÃ Ã Ã Â¿Â¹ÃÃ Ã Ã Â¹ ÃÃ ÃÃ ÃÂºÖÃÃ ÃÃ ÃÃ ÃÃ Û Ö Ã ÃÃ Ã Ã Ã ÖÃÃ Ã Ã Ö Ã Ãİ ÃÃ ÃÖÖ ÃÃİ Ã Â´Ö Ã Ã Ã ÃÃÂ¹ÖÖÃÖ ÃÖ ÃÖÖ ÃÂµ Ö Ã Ã Ã ÃÃ İÃÃÃ Ã ÃÂº Ã Ö ş Ã ÃÃ Ã Ö ÃÖÃ Ã Û Ã Ã Ã ÃÖÃÃ ÃÖ Ã ÃÃ Ö Ã Ã Ã ÃÃ Ã ÃÛÃÖ Âº Ã Ã Ã Ã Ö ÃÖÃ Ã Ã Ö Ã Ã ÃÃ Ã Ã ÃÃÃÃ Ã Ã ÃÃ ÃÃ Û Ö ÃÃ ÃÃ Ã Ã Ã Û Ã Ã Ã ÖÃ Ã Ã ÖÃ Ã Ö Ã Ã ÃÃ Â¹Ã Ã ÃÃÃ Ã Â¬ÃÃ Ö ÃÃ ÃÃ ÃÃÃ Ã Ã Â¬ ÃÃÃİ ÃÃÖÃÃ Ã ÃÖ İ Ã Ã ÃÃÂ¬ ÃÃÃÃÃ Ã ÃÃÂºÇÃ Ã ÃÖ Ã Ã Ã Ã Ã ÛÃÖ ş ÃÃ Ã Ã Ã Ã ÃÃ ÃİÃÃ Ã Û Ã ÃÃÃ Ã ÃÃÃÖ ÃÃÖ Ã Âº ÃÖ ÃÃÃÃ ÃÃ Ã ÃÖ Ã Ã ş Â¿Â¹ ÃÃÖ ÃÃ Ã Û Ã ÃÃÃ Ã Âº ÃÃ ÃÂ¹Ö Ã Ã ÃÃ Ö Ã ÃÃ ÃÃ ÃÖ İş ÃÃÃ Ã Ö Ã Ã ÖÃ Û Ö Ã İ ÃÃ Ã Ã ÃÃÃÖ ÃÂº ÃÖ Ã ÃÖ Ã ÃÃÃÃ Ö Ã ş Ã Ã ÃÃ Ã Ã Ã ÃÃ ÃÃ ÃÃÃ Û Ã ÃÃÃÃÖÃ Ã ÃÖÃÃÖ Ã ÃÖ Ã ÃÃ ÃÂº Ã Ã Ã Ã Ã ÃÃÃ Û Ã Ã Ã Â± ÂºÂ¾ ÛÃÖ Ö Ã Ã Ã ÃÃ ÃÖ İÂºÃ İÛÃÖ Ã ÃÃÂ¬ Ã Ã ÃÖ Ã Â»Ã ÃÃÖ Ã ş ÃÃ ÖÂ» Ö ÃÃ ÃÃş ÃÃ Ã ÃİÃÂ¹Ã ÃÃş ÃÃÂ¬ Ã Ã ÃÃÖ ÃÂ» ÃÃÖ Ãş ÃÃ Ã Ã Ã Ã ÃÃ
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Anahtar Kelimeler: Dizilim problemi, kırık arkeolojik parçaların geri çatılması,imge genişletme, Fourier tabanlı imge çakıştırmaArkeolojik parçaların birleştirilmesi ve onarılması, kırık nesnelerin tamiri,parçalanmış dokümanların yeniden oluşturulması ve hatta moleküler kenetlenmeninçözümlenmesi genel olarak dizilim problemine dayanmaktadır. Görüntü işlemededizilim; geometri ve doku olarak birbiriyle ilişkili parçaların birleşerek en iyi bütünüortaya çıkarması olarak tanımlanmaktadır. Bugüne kadar dizilim problemi üzerindeyapılan çalışmalar sadece geometrik şekil bilgisine dayalı olarak ele alınmış, parçacıklarüzerindeki görsel bilgi kullanılmamıştır.Bu bildiride daha önceki eğri uyumlama yöntemlerine dayalı geometrikyaklaşımlardan farklı olarak hem resim hem geometri bilgisinin kullanıldığı bir çalışmasunulmaktadır. İlk aşamada parçaların etrafındaki bir bantta doku öngörüsüyapılmaktadır. Öngörülen bu dokudan elde edilen özniteliklerden bir uyum ölçüsübulunmakta ve parçaların birbirlerine birleştirilmeleri Fourier tabanlı imge çakıştırmayöntemleri kullanılarak çözülmektedir. Geliştirilen yöntemler yapay ve gerçek datalarüzerinde sınanarak performansları incelenmiştir. Bu çalışmanın ana katkıları şu şekildeözetlenebilir:â¢ Doku ve şekil bilgisine dayalı olarak dizilimin başarımını sayısal olarakortaya koyan bir performans ölçütü geliştirilmesiâ¢ Dizilim probleminin Fourier metodları kullanılarak çözülmesi","Keywords: Puzzle assembly, reconstruction of the artifacts in archaeology,expanding images, Fourier based image registrationPuzzle assembly?s importance lies into application in many areas such asrestoration and reconstruction of archeological findings, the repairing of broken objects,solving of the jigsaw type puzzles, molecular docking problem, etc. Puzzle piecesusually include not only geometrical shape information but also visual information oftexture, color, continuity of lines, and so on. Moreover, textural information is mainlyused to assembly pieces in some cases, such as classic jigsaw puzzles.This research presents a new approach in that pictorial assembly, in contrast toprevious curve matching methods, uses texture information as well as geometric shape.The assembly in this study is performed using textural features and geometricalconstraints. First, the texture of a band outside the border of pieces is predicted byinpainting and texture synthesis methods. The feature values are derived by theseoriginal and predicted images of pieces. A combination of the feature and confidencevalues is used to generate an affinity measure of corresponding pieces. Two newalgorithms using Fourier based image registration techniques are developed to optimizethe affinity. The algorithms for inpainting, affinity and Fourier based assembly areexplained with experimental results on real and artificial data.The main contributions of this research are:â¢ The development of a performance measure that indicates the level of success ofassembly of pieces based on textural features and geometrical shape.â¢ Solution of the assembly problem by using of the Fourier based methods."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dokumanlar arasında benzerlik bulunmasının gerçek hayatta tekrarlayan web sayfalarını veya intihalleri bulmak gibi önemli uygulama alanı vardır. Her ne kadar $k$-benzerlik algoritması gibi temel teknikler literatürde uzun zamandır mevcut olsa da, özellikle çok büyük boyutlardaki verilerle çalışmanın gerektiği büyük veri uygulamalarında bu tür basit teknikler yavaş ve yetersiz kalırlar. Özellikle dokümanları ikili olarak bir ortak terimi içeriyor mu diye karşılaştırmak çok yüksek depolama ve hesaplama gücü gereksinimleri doğurur. Bulut bilişimin hızla yaygınlaşması, kullanıcıların bu ihtiyaçlarına cevap vermektedir. Veriyi bu tür bulut servis sağlayıcılar üzerinden paylaşmak, verinin erişilebilirliğini garanti etse de, verinin mahremiyeti ve gizliliği garanti edilemez. Bu durum, özellikle hassas verilerin mahremiyetini koruma problemini ortaya çıkarmıştır. Geleneksel dokümanlar arası benzerlik bulma algoritmaları çoğunlukla sorgulanan dokümanı veri tabanındaki diğer tüm dokümanlarla karşılaştırmayı gerektirir. Bizim önerdiğimiz sistemde ise, açık (şifrelenmemiş) metin verileri üzerinde gerekli olan karşılaştırma sayısını önemli oranda azaltan yeni bir filtreleme tekniği kullanımı önerilmiştir. Bu sistem açık veriler üzerindeki benzerlik karşılaştırmalarında çok verimli olarak çalışmaktadır. Bu sistemin yanı sıra, mahremiyeti de sağlayacak üç güvenli benzerlik arama algoritması da (Secure Sketch Search, Secure Minhash Search ve Secure ZOLIP) tasarlanmıştır. Bunlardan ilki dokümanlar arasındaki kosinüs benzerliğini konum hassasiyetli özütleme (locality sensitive hashing) teknikleri kullanarak yapar. İkinci yöntem MinHash algoritmalarını kullanırken üçüncüsü ise öncelikle açık metinler için tasarladığımız ZOLIP imzalarının şifrelenmiş hallerini kullanarak benzerlik hesaplaması yapar. Önerdiğimiz yöntemleri gerçeklerken büyük veriler için de ölçeklenebilir olması için, Hadoop dağıtımlı dosya sistemleri ve MapReduce paralel programlama modelinden yararlanıyoruz. Gerçek veriler üzeride yaptığımız deneyler, önerilen yöntemlerin literatürde var olan diğer sistemlerden daha az sayıda birleştirme/karşılaştırma işlemine ihtiyaç duyduğunu, ve dolayısıyla daha hızlı olduğunu göstermiştir.","Document similarity has important real life applications such as finding du- plicate web sites and identifying plagiarism. While the basic techniques such as k-similarity algorithms have been long known, overwhelming amount of data, being collected such as in big data setting, calls for novel algorithms to find highly similar documents in reasonably short amount of time. In particular, pairwise comparison of documents sharing a common feature, necessitates prohibitively high storage and computation power. The wide spread availability of cloud computing provides users easy access to high storage and processing power. Furthermore, outsourcing their data to the cloud guarantees reliability and availability for their data while privacy and security concerns are not always properly addressed. This leads to the prob- lem of protecting the privacy of sensitive data against adversaries including the cloud operator. Generally, traditional document similarity algorithms tend to compare all the documents in a data set sharing same terms (words) with query docu- ment. In our work, we propose a new filtering technique that works on plain- text data, which decreases the number of comparisons between the query set and the search set to find highly similar documents. The technique, referred as ZOLIP algorithm, is efficient and scalable, but does not provide security. We also design and implement three secure similarity search algorithms for text documents, namely Secure Sketch Search, Secure Minhash Search and Secure ZOLIP. The first algorithm utilizes locality sensitive hashing tech- niques and cosine similarity. While the second algorithm uses the Minhash Algorithm, the last one uses the encrypted ZOLIP Signature, which is the secure version of the ZOLIP algorithm. We utilize the Hadoop distributed file system and the MapReduce parallel programming model to scale our techniques to big data setting. Our experi- mental results on real data show that some of the proposed methods perform better than the previous work in the literature in terms of the number of joins, and therefore, speed."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım sistemleri daha karmaşık hale geldikçe, bu tip sistemleri düşük maliyetli test etmek için etkili tekniklere olan talep de artmaktadır. Bunlara örnek olarak web sunucuları (Apache vb.) ve veritabanları (MsSQL vb.) gibi yapılandırılabilirliği yüksek yazılım sistemleri verilebilir. Bu sistemler birbiriyle etkileşim içinde olan birçok yapılandırabilir parametrelere sahiptir ve bu etkileşimler üstel büyüme hızıyla parametre konfigürasyonla- rının sayısının artmasına yol açar. Bundan dolayı, bu tip yazılım sistemleri parametrelerin etkileşimlerinden dolayı oluşabilecek hatalara karşı daha çok eğilimlidir. Bu soruna bir çözüm olarak konfigürasyon uzayını sistematik şekilde kümeleyip ve bu kümeleri ayrı ayrı test eden kombinatoryal etkileşim testi (combinatorial interaction testing) verilebilir. Kombinatoryal etkileşim testi, az sayıda parametre konfigürasyonları içeren test senaryoları olarak kullanılması için kapsayan diziler adı verilen objeleri üretir. Bir \textit{t-yollu kapsayan dizisi} (t-way covering array) test edilecek sistemin bütün t-yollu parametrelerinin değer kombinasyonlarını en küçük sayıda konfigürasyon kullanarak kapsamayı hedefler. Yapılan birçok araştırmanın kayda değer çoklukta hataların küçük sayıda parametre etkileşimlerinden kaynaklandı{g}ını göstermesinin ardından, kapsayan dizinin uygulamalarına özellikle teşvik edilmiştir. Yine de, özellikle de konfigürasyon uzayı büyük olduğunda ve sistem içinde parametreler arasında bazı konfigürasyonları geçersiz kılan kısıtlamalar olduğunda, minimum sayıda konfigürasyon içeren kapsayan diziler oluşturmak kolay bir iş değildir. Bundan ötürü, bu çalışma alanı farklı alandan birçok araştırmacıların ilgisini çekmektedir. çoğu çalışma ölçeklendirme konusunda sorun yaşamasına rağmen, kapsayan dizi oluşturma konusunda bazı başarılı çalışmalarda yapılmıştır. Fakat, konfigürasyon uzayı büyüdükçe, çoğu yaklaşım zorlanmaya başlar. Kombinatorik problemler, bizim durumda kapsayan dizi oluşturmak, çoğunlukla etkili sayma teknikleri kullanılarak çözülür. Bu varsayımı baz alarak, sayma problemlerinin kolay bir iş olmasından ve paralel programlama teknikleri kullanılarak verimli bir şekilde çözülebileceğinden dolayı, kapsayan dizilerin paralel algoritmalar kullanılarak etkili bir şekilde oluşturulabileceğine dair öngörüde bulunuyoruz. Farklı mimariler farklı araştır- ma alanlarında daha etkili olabileceğinden dolayı, biz GPU tabanlı paralel programlama teknikleri kullanmaya karar verdik. çünkü GPU'ların aritmetik hesaplama birimleri küçük olmasına karşın, yüzlerce çekirdekleri, hatta bazen binlerce çekirdekleri olabilir. Bu çekirdeklerin kapasiteleri kısıtlı ve sınırlı olmalarına rağmen, bizim tek yapmak istedi- ğimiz defalarca basit sayma işlemleri olduğu için bizim çalışmamızda amacımıza çok iyi hizmet ederler. Bu fikrimizi hesaplama zamanını azaltmak için daha önce birçok defa kapsayan dizi oluşturmada kullanılmış ve çoğu zaman en küçük boyutlarda sonuçlar vermiş olan benzetilmiş tavlama algoritması (simulated annealing) üzerinde uyguladık. Bunlara ek olarak, benzetilmiş tavlama algoritmasının her adımında paralel olarak çoklu sayıda komşu durumları üretebilen bir teknik geliştirdik. Son olarak da, uzayı tamamen rastgele aramanın kötü etkisini düşürmek ve kapsayan dizilerin boyutunu daha da azaltmak için SAT (SATisfiability) algoritması ve paralel programlama teknikleri kullanarak melez bir yaklaşım öne sürdük.","As software systems becomes more complex, demand for efficient approaches to test these kind of systems with a lower cost is increased highly, too. One example of such applications can be given highly configurable software systems such as web servers (e.g. Apache) and databases (e.g. MySQL). They have many configurable options which interact each other and these option interactions lead having exponential growth of option configurations. Hence, these software systems become more prone to bugs which are caused by the interaction of options. A solution to this problem can be combinatorial interaction testing which systematically samples the configuration space and tests each of these samples, individually. Combinatorial interaction testing computes a small set of option configurations to be used as test suites, called covering arrays. A \textit{t-way covering array} aims to cover all t-length option interactions of system under test with a minimum number of configurations where t is a small number in practical cases. Applications of covering arrays are especially encouraged after many researches empirically pointed out that substantial number of faults are caused by smaller value of option interaction. Nevertheless, computing covering arrays with a minimal number of configurations in a reasonable time is not easy task, especially when the configuration space is large and system has inter-option constraints that invalidate some configurations. Therefore, this study field attracts various researchers. Although most of approaches suffer in scalability issue, many successful attempts have been also done to construct covering arrays. However, as the configuration scape gets larger, most of the approaches start to suffer. Combinatorial problems e.g., in our case constructing covering arrays, are mainly solved by using efficient counting techniques. Based on this assumption, we conjecture that covering arrays can be computed using parallel algorithms efficiently since counting is an easy task which can be carried out with parallel programming strategies. Although different architectures are effective in different researches, we choose to use GPU-based parallel computing techniques since GPUs have hundreds even sometimes thousands of cores however with small arithmetic logic units. Despite the fact that these cores are exceptionally constrained and limited, they serve our purpose very well since all we need to do is basic counting, repeatedly. We apply this idea in order to decrease the computation time on a meta-heuristic, search method simulated annealing, which is well studied in construction of covering arrays and, in general, gives the smallest size results in previous studies. Moreover, we present a technique to generate multiple neighbour states in each step of simulated annealing in parallel. Finally, we propose a novel hybrid approach using SAT solver with parallel computing techniques to decrease the negative effect of pure random search and decrease the covering array size further. Our results prove our assumption that parallel computing is an effective and efficient way to compute combinatorial objects."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son zamanlarda, yeni teknolojilerin daha yaygın hale gelmesiyle, çok büyük miktarda veri çok hızlı bir şekilde üretilmeye ve güvenilir olmayan sunucularda depolanmaya başlandı. Büyük veri kavramı sadece veri kümesinin olağanüstü boyutunu değil, aynı zamanda yüksek veri oluşum hızını ve verilerin çok çeşitli türlerde olduğunu vurgulama için kullanılır. Büyük veri, çok cazip avantajlar sağlasa da, güvenlik sorunları hala açık olan bir problemdir. Bu tezde, belli bir büyük veri uygulaması ile ilişkili güvenlik ve mahremiyet sorunlarını adresliyoruz. Bir diğer deyişle, şifreli bulut verisi üzerinde güvenli kelime-tabanlı arama işleminin büyük veri ortamından zor olduğunu vurgulayıp, bunun önündeki teknik zorlukları belirtiyoruz. Daha özel olarak ise, mahremiyet gereksinimlerinin tam olarak ortaya konabilmesi için gerekli formal tanımları veriyoruz. Ayrıca, sadece devasa değil aynı zamanda değişen ve çok hızlı biriken büyük veri ortamı için, şifreli veriler üzerinde uygulanabilir temel işlemlerden biri olan mahremiyet korumalı kelime arama işlemi üzerinde varolan bir çalışmayı uyarlıyoruz. Geliştirilen çözümler, büyük veri ortamında şifreli veriler üzerinde aramaya olanak veren güvenli endeks yapısını makul bir hız ile inşa edebilmeli, ayrıca verimli ve etkili bir kelime arama işlemi yöntemi için çok hızlı güncelleyebilmelidir. Önerdiğimiz çözümlerin, çok büyük veri kümeleri ile çalışacak şekilde ölçeklendirilebilmesi için, Hadoop Dağıtılmış Dosya Sistemi (HDFS) ve MapReduce programlama modeli gibi paralel programlama teknikleri ve dağıtık dosya sistemleri kullanılmaktadır. Dinamik olarak değişen, büyük veri kümesindeki belgelerin ilgili puanlarını verimli işleyebilen bir tembel idf güncelleme yöntemini de öneriyoruz. Gerçek veriler üzerinde gerçekleştirdiğimiz kapsamlı deneyler vasıtasıyla önerdiğimiz yöntemin etkinliğini ve doğruluğunu deneysel olarak gösteriyoruz.","As the new technologies recently became widespread, enormous amount of data started to be generated in very high speeds and stored in untrusted servers. The big data concept covers not only the exceptional size of the datasets, but also high data generation rate and large variety of data types. Although the Big Data provides very tempting benefits, the security issues are still an open problem. In this thesis, we identify security and privacy problems associated with a certain big data application, namely secure keyword-based search over encrypted cloud data and emphasize the actual challenges and technical difficulties in the big data setting. More specifically, we provide definitions from which privacy requirements can be derived. In addition, we adapt an existing work on privacy-preserving keyword-based search method, which is one of the fundamental operations that can be performed over encrypted data, to the big data setting, in which, not only data is huge but also changing and accumulating very fast. Therefore, in the big data setting, a secure index that allows search over encrypted data should be constructed and updated very fast in addition to an efficient and effective keyword-based search operation method. Our proposal is scalable in the sense that it can leverage distributed file systems and parallel programming techniques such as the Hadoop Distributed File System (HDFS) and the MapReduce programming model to work with very large datasets. We also propose a lazy idf-updating method that can efficiently handle the relevancy scores of the documents in dynamically changing and large datasets. We empirically show the efficiency and accuracy of the method through extensive set of experiments on real data."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İmza doğrulama, bir kişinin gerçek imzalarından yararlanarak taklit imzalarını saptama problemidir. Zorluk, bir kişinin imzalarındaki geçerli çeşitliliği, yüksek sınıf içi ve düşük sınıflararası çeşitliliğin varlığına rağmen tespit etmekte yatar (taklitler, bir kişinin gerçek bir imzasına, aynı kişinin diğer gerçek imzalarından daha fazla benziyor olabilir). Problem, sınıfların birbirlerine çok benzer olduğu bir esnemez-olmayan nesne karşılaştırma gibi görülebilir. Biyometrik alanında imza, davranışsal bir biyometrik olarak kabul edilir ve ek olarak teknik taklit durumundan dolayı probleme parmak izi tanıma gibi diğer yöntemlerden ileri zorluklar hakimdir. Bu tezde özgün bir çevrimdışı (resim-bazlı) imza doğrulama sistemi önerilmiştir. İmzanın istikrarlı parçalarını yakalamak ve evrensel karşılaştırmanın zorluğunu hafifletmek için, yerel bölgelerdeki eğim ve komşuluk bilgilerini kullanan yerel öznitelikler (yönlü eğimlerin histogramı, yerel ikili örnekleme) kullanılmıştır. Çıkarılan özniteliklerin ayrıştırıcı gücü karar destek makinası (KDM) ile incelenmiş ve kaynaştırma, literatürdekilerden daha iyi sonuç vermiştir. Ölçekten bağımsız öznitelik dönüşüm karşılaştırması da tamamlayıcı bir yaklaşım olarak kullanılmıştır. Sınıflandırıcı eğitimi için, evrensel ve kullanıcı-bazlı olmak üzere iki farklı yaklaşım incelenmiştir. Her kullanıcı için ayrı ayrı eğitilen kullanıcı-bazlı KDMler, bir kişinin referans (gerçek) imzalarını diğer imzalardan ayırmayı öğrenir. Diğer taraftan, eğitim kümesindeki tüm kullanıcıların sorgu ve referans imzalarının öznitelikleri arasındaki fark vektörleriyle eğitilen tek bir evrensel KDM, değişik farklılık türlerinin önemlerinin nasıl ağırlıklandırılması gerektiğini öğrenir. Tüm sınıflandırıcıların kaynaştırılması ile halka açık GPDS-160 imza veritabanında, teknik taklitleri sadece testte kullanmak suretiyle %6.97 eşit hata oranı elde edilmiştir. Sistemin daha önceki sürümleri çeşitli imza doğrulama yarışmalarını kazanmıştır: 4NSigComp2010 ve 4NSigComp2012 yarışmalarında birincilik (kimlik-inkar-etme imzaları olmadan), 4NSigComp2011 yarışmasında Çin imzaları kategorisinde birincilik, SigWiComp2013 yarışmasında tüm kategorilerde birincilik. Elde edilen sonuçlar, literatürde yayınlanan sonuçlardan daha iyi olmuştur. Önerilen yöntemin en büyük avantajlarından birisi, gerçek hayattaki uygulamalara uygun olarak, kullanıcı kaydı sırasında teknik taklit imzalara ihtiyaç duymamasıdır.","Signature verification deals with the problem of identifying forged signatures of a user from his/her genuine signatures. The difficulty lies in identifying allowed variations in a user's signatures, in the presence of high intra-class and low interclass variability (the forgeries may be more similar to a user's genuine signature, compared to his/her other genuine signatures). The problem can be seen as a nonrigid object matching where classes are very similar. In the field of biometrics, signature is considered a behavioral biometric and the problem possesses further difficulties compared to other modalities (e.g. fingerprints) due to the added issue of skilled forgeries. A novel offline (image-based) signature verification system is proposed in this thesis. In order to capture the signature's stable parts and alleviate the difficulty of global matching, local features (histogram of oriented gradients, local binary patterns) are used, based on gradient information and neighboring information inside local regions. Discriminative power of extracted features is analyzed using support vector machine (SVM) classifiers and their fusion gave better results compared to state-of-the-art. Scale invariant feature transform (SIFT) matching is also used as a complementary approach. Two different approaches for classifier training are investigated, namely global and user-dependent SVMs. User-dependent SVMs, trained separately for each user, learn to differentiate a user's (genuine) reference signatures from other signatures. On the other hand, a single global SVM trained with difference vectors of query and reference signatures' features of all users in the training set, learns how to weight the importance of different types of dissimilarities. The fusion of all classifiers achieves a 6.97% equal error rate in skilled forgery tests using the public GPDS-160 signature database. Former versions of the system have won several signature verification competitions such as first place in 4NSigComp2010 and 4NSigComp2012 (the task without disguised signatures); first place in 4NSigComp2011 for Chinese signatures category; first place in SigWiComp2013 for all categories. Obtained results are better than those reported in the literature. One of the major benefits of the proposed method is that user enrollment does not require skilled forgeries of the enrolling user, which is essential for real life applications."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Holografi, nesneleri girişim desenleri ile analiz ederek üç boyutlu görüntü elde edebilmeyi sağlayan bir metoddur. Ancak bir hologramı yapılandırabilmek için nesnenin kamera düzleminden uzaklığının bilinmesi gereklidir, aksi takdirde elde edilen yapılandırmalar odaklanmamış olacaktır. Eğer bu 'yeniden yapılandırma uzaklığı' önceden bilinmiyorsa, bu mesafenin otomatik odaklama tekniği kullanılarak hesaplanması gerekir. Görüntü işleme literatüründe bulunan geleneksel otomatik odaklama teknikleri sayısal holografiye uygulanabilmektedir. Bu tezde, on bir geleneksel netlik kriteri dijital hologramlara uygulanarak, doğru yapılandırma mesafesinin bulunması incelenmiştir. Kaydedilen hologramlar çeşitli uzaklıklarda yapılandırılarak elde edilen görüntülerin genlikleri netlik kriterleri ile karşılaştırılmıştır. Sayısal olarak en keskin hatlara sahip genlik resmi, odaklanmış olan yeniden yapılandırmayı ifade etmektedir. Bu şekilde elde edilen yeniden yapılandırma uzaklığına 'doğru-odak-uzaklığı' ismi verilmiştir. Ancak, yüksek çözünürlükteki hologramların otomatik odaklanması oldukça uzun sürmektedir. Bu amaçla bir ölçekleme metodu geliştirilmiş ve sunulmuştur. Bu ölçekleme metodu ile doğru-odak-uzaklığı halen yüksek hassasiyet ile hesaplanabilirken, hesaplama süresi de ölçeğin karesi oranında kısalmaktadır. Ancak, çok yüksek ölçek değerleri kullanıldığında otomatik odaklama işlemi güvenilir olmamaktadır, çünkü ölçekleme metodu netlik kriterleri ile hesaplanan netlik eğrilerinde bozulmaya yol açmaktadır. Bu sebeple, ölçekleme metodu ile otomatik odaklama işleminin güvenilirliğini ölçmek için insan portresi, manzara ve mikro-yapılar içeren elli adet resimden sentetik hologramlar türetilmiştir. Bu hologramlar artan ölçek değerleri ile ölçeklenerek otomatik odaklamaya tabi tutulmuş, ve otomatik odaklamanın güvenilirliği istatistiksel olarak incelenmiştir. Simülasyon sonuçları deneysel sonuçlar ile uyuşmakta, ve ölçekleme tekniği kullanılarak güvenilir otomatik odaklama yapılabileceği gösterilmektedir.","Holography is a method for three-dimensional (3D) imaging of objects by applying interferometric analysis. A recorded hologram is required to be reconstructed in order to image an object. However one needs to know the appropriate reconstruction distance prior to the hologram reconstruction, otherwise the reconstruction is out-of-focus. If the focus distance of the object is not known priori, then it must be estimated using an autofocusing technique. Traditional autofocusing techniques used in image processing literature can also be applied to digital holography. In this thesis, eleven common sharpness functions developed for standard photography and microscopy are applied to digital holograms, and the estimation of the focus distances of holograms is investigated. The magnitude of a recorded hologram is quantitatively evaluated for its sharpness while it is reconstructed on an interval, and the reconstruction distance which yields the best quantitative result is chosen as the true focus distance of the hologram. However autofocusing of highresolution digital holograms is very demanding in means of computational power. In this thesis, a scaling technique is proposed for increasing the speed of autofocusing in digital holographic applications, where the speed of a reconstruction is improved on the order of square of the scale-ratio. Experimental results show that this technique offers a noticeable improvement in the speed of autofocusing while preserving accuracy greatly. However estimation of the true focus point with very high amounts of scaling becomes unreliable because the scaling method detriments the sharpness curves produced by the sharpness functions. In order to measure the reliability of autofocusing with the scaling technique, fifty computer generated holograms of gray-scale human portrait, landscape and micro-structure images are created. Afterwards, autofocusing is applied to the scaleddown versions of these holograms as the scale-ratio is increased, and the autofocusing performance is statistically measured as a function of the scale-ratio. The simulation results are in agreement with the experimental results, and they show that it is possible to apply the scaling technique without losing significant reliability in autofocusing."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yapılandırılabilirliği yüksek yazılım sistemlerinin eksiksiz bir şekilde test edilmesi pratikte olanaksızdır. Bu nedenle, konfigürasyon uzayının verimli bir şekilde örneklendirilmesi testlerin kapsamını artırmak için önemlidir. Bu amaca yönelik geliştirilen t-yollu kapsayan diziler (t-way covering arrays) (KAD), konfigürasyon seçeneklerinin bütün t-yollu kombinasyonları için bütün değer kombinasyonlarını kapsamak üzere sistematik bir şekilde oluşturulmuş bir konfigürasyon kümesidir. KAD'lar konfigürasyon seçeneklerinin etkileşimlerinden kaynaklanan hataları keşfetmeyi hedeflemektedir. Elde ettikleri birçok başarıya rağmen, pratikte KAD'ları kullanmak zor olabilir. Bir t-yollu KAD oluşturduktan sonra, diziye seçilmiş tüm konfigürasyonlar sistemin her bir test durumu (test case) için test edilir. Böyle yaparak, geleneksel KAD'lar, test durumlarının hepsinin seçilmiş bütün konfigürasyonlarda çalışabileceğini varsayar. Ancak yapılan son çalışmalar, yapılandırılabilirliği yüksek yazılım sistemlerinin test durumlarının üzerinde çalışacakları konfigürasyon hakkında varsayımlarının (kısıtlama) olmasının muhtemel olduğunu göstermektedir. Eğer bir konfigürasyon bir test durumunun kısıtlamalarına uymazsa, o test durumu o konfigürasyonu atlar ve bu da sadece o konfigürasyonda görünen değerlerinin o test durumunu tarafından test edilememesi sorununa yol açar. Bu soruna maskeleme etkisi denmektedir. Bu sorunu çözmenin bir yöntemi, son zamanlarda geliştirilen test durumlarını dikkate alan kapsayan diziler (test-case-aware covering arrays) (T-KAD) kullanmaktır.T-KAD'lar test durumlarının konfigürasyon seçeneklerinin aldıkları değerlerle ilgili olan kısıtlamalarını hesaba katarak bu kısıtlamalarından kaynaklanan maskeleme etkilerinin oluşmasını önler. Test durumlarının kısıtlarıyla zenginleştirilmiş bir konfigürasyon uzay modeli icin hesaplanmıs bir T-KAD, geleneksel kapsayan dizilerde olduğu gibi sadece bir konfigürasyon kümesi degil, her bir konfigürasyonun bir dizi test durumuyla ilişkilendirildiği bir konfigürasyon kümesidir. Bu yapıda, bir konfigürasyonla ilişkilendirilmiş test durumları kumesi, o konfigürasyonda çalıştırılması gereken test durumlarını ifade eder. Yapılan araştırmalarda, KAD'lar ile karşılaştırıldığında, T-KAD'ların maskeleme etkilerini ortadan kaldırarak kombinatoryal etkileşim testinin kalitesini önemli ölçüde arttırdığı gösterilmiş olmasına rağmen, kavram ispatı olarak geliştirilen birkaç algoritma haricinde, T-KAD hesaplamanın etkili ve verimli bir yöntemi yoktur. Bu sorunun, T-KAD'ların kombinatoryal etkileşim testine adapte olmasını engellediğini öngörmekteyiz. Bu tezde, benzetilmiş tavlama-tabanlı etkili ve verimli T-KAD hesaplama algoritmaları ve bu algoritmaları uygulayan bir yazılım geliştirdik. Ayrıca, iki yapılandırılabilirliği yüksek yazılım sistemi kullanarak büyük çaplı deneyler yaparak geliştirdiğimiz algoritmaların performanslarını karşılaştırdık ve değerlendirdik. Deneylerimizin sonuçları, önerilen algoritmaların T-KAD hesaplamada verimli ve etkili bir yol olduğunu ve mevcut yaklaşımlara göre performansının daha yüksek olduğunu göstermektedir.","Exhaustive testing of highly configurable software systems is generally infeasible in practice. For this reason, efficient sampling of the configuration space is important to improve the coverage of testing. A t-way covering array is a list of systematically selected configurations covering all value combinations for every t-way option combinations and it aims to discover faults caused by interactions of configuration options. Despite its many successes, it can be difficult to use covering arrays in practice. Once a traditional t-way covering array is constructed, the system is then tested by running its test cases in all the selected configurations. By doing so, traditional covering arrays assume that all test cases can run in all configurations of covering array. Recent studies, however, show that test cases of configurable systems are likely to have assumptions about the underlying configurations, i.e., they are like to have some test case-specific inter-option constraints. When a configuration does not satisfy the test case-specific constraints of a test case, that test case simply skips the configuration, which prevents the test case from testing all valid combinations of option settings appearing in the configuration – an effect called a masking effect. A harmful consequence of masking effects is that they can make the developers to believe that they have tested certain option setting combinations while they in fact have not. A solution approach is to use test case-aware covering arrays – a novel type of combinatorial objects for testing that has been recently introduced. Test case-aware covering arrays take test case-specific inter-option constraints into account when computing combinatorial interaction test suites, such that no masking effects caused by overlooked constraints occur. Given a configuration space model augmented with test case-specific constraints, a test case-aware covering array is not just a set of configurations as is the case in traditional covering arrays, but a set of configurations each of which is associated with a set of test cases, indicating the test cases scheduled to be executed in the configuration. Although it has been empirically demonstrated that test case-aware covering arrays, compared to traditional covering arrays, can significantly improve the quality of combinatorial interaction testing by avoiding masking effects, there is no efficient and effective algorithms to compute them, except for a couple of proof-of-concept algorithms. We conjecture that this greatly hurts the adaptation of test case-aware covering arrays in practice. In this thesis, we have developed simulated annealing-based, efficient and effective algorithms to compute test case-aware covering arrays and a tool implementing these algorithms. We, furthermore, compare and contrast the performance of our algorithms by conducting large-scale experiments in which we used two highly configurable large software systems. The results of our empirical studies strongly suggest that the proposed algorithms are an efficient and effective way of computing test case-aware covering arrays and that they perform better than existing approaches."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Konuşmacı bölütleme, ses verisinin konuşmacı kimliğine göre homojen bölütlere ayrlması süreci olarak özetlenebilir. Bu tezde olasılıksal doğrusal ayırtaç analizi (ODAA) metodunun telefon konuşmaları üzerinde konuşmacı bölütleme alanına uygulanması incelenmiştir. Konuşmacı bölütlemede kullanılan bölütsel i-vektörlerin ODAA modeli altında değişkenli Bayes (DB) yöntemi ile çıkarsaması ilk olarak bu çalışmada denenmiştir. Değişkenli Bayes iterasyonlarında yerel en uygun sonuçlardan kaçınmak için belirleyici tavlama (BT) algoritması kullanılmıştır. Önerilen sistem, bu alanda bilinen bir sistem olan, bölütsel i-vektörlerin temel bileşenler analizi katsayıları üzerinde k-ortalama topaklama yöntemininin uygulandığı sistem ile karşılaştırılmıştır. Performans değerlendirmesi Ulusal Standartlar ve Teknoloji Enstitüsü tarafından 2008 Konuşmacı Tanıma Değerlendirmesi için belirlenen test veri kümesi üzerinde yapılmıştır. Önerilen sistem, baz alınan sistemin Bölütleme Hata Oranı'na göre %20 daha iyi performans göstermiştir.",Speaker diarization can be summarized as the process of partitioning an audio data into homogeneous segments according to speaker identity. This thesis investigates the application of the probabilistic linear discriminant analysis (PLDA) to speaker diarization of telephone conversations. We introduce a variational Bayes (VB) approach for inference under a PLDA model for modeling segmental i-vectors in speaker diarization. Deterministic annealing (DA) algorithm is employed in order to avoid locally optimal solutions in VB iterations. We compare our proposed system with a well-known system that applies k-means clustering on principal component analysis coefficients of segmental i-vectors. We used summed channel telephone data from the National Institute of Standards and Technology 2008 Speaker Recognition Evaluation as the test set in order to evaluate the performance of the proposed system. We achieve about 20% relative improvement in diarization error rate as compared to the baseline system.
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Görüntü mozaikleme, ayrı ayrı çekilmiş resimlerin bütünleştirilmesini ve bütünleşik resimlerin sahne hakkında daha iyi bir tanımlama sunmasından dolayı bu şekilde sahne hakkındaki görsel algının artırılmasını amaçlar. Mozaik resimlerden elde edilen durumsal farkındalık sivil ve askeri uygulamalar açısından önem taşır. Muhtemel sivil kullanım alanları, doğal felaketlerden dolayı hasar görmüş kentsel bölgelerin keşfi ve geniş dikili alanların incelenmesi olarak verilebilir. Askeri uygulamalar içinse, görüntü mozaikleme geniş alanda süregelen düşman aktiviteleri hakkında kritik bilgiler sağlayabilir. Literatürdeki farklı uygulamalar için geliştirilmiş çeşitli gerçek zamanlı görüntü mozaikleme çalışmalarına rağmen, birçok pratik uygulama için daha hızlı ve doğru sonuçlar veren yöntemlere duyulan ihtiyaç sebebiyle, konu hala gelişmeye açıktır. Bu tezde, havadan alınmış düzlemsi sahnelere ait görüntülerin hızlı ve doğru şekilde mozaiklenmesini amaçlayan yeni yöntemler geliştirilmiştir. İlk olarak, yeni gelen bir resmin yerleşiminin belirlenmesi için bu resim ile kesişen bütün eski resimlerin kullanıldığı bir mozaikleme yaklaşımı geliştirilmiştir. Kesişen resimleri belirlemek için Bilgisayar Grafikleri literatüründe kullanılan Ayırıcı Eksen Teoremi kullanılmıştır. Mozaik görüntü üzerindeki global tutarlılığın artırımı için yeni bir afin iyileştirme yöntemi sunulmuştur. İkinci olarak, sahne normali ve kamera poz parameterelerinin Genişletilmiş Kalman Süzgeci ile kestirimine dayalı bir mozaikleme yöntemi önerilmiştir. Mozaik görüntü, durum vektörü parametrelerinden elde edilen homografiler yardımıyla oluşturulmaktadır. Bütün parametrelerin kestiriminin birlikte yapılması ve bu sayede döngü kapanışlarındaki hataların kompanze edilmesinden dolayı, Genişletilmiş Kalman Süzgeci temelli bir yaklaşım kullanmak, mozaik görüntüye kayda değer oranda global tutarlılık sağlamaktadır. Önerilen metod ayrıca robotik uygulamalarda kullanışlı olabilecek kameranın yer ve duruş bilgisini de sağlamaktadır. İki yöntem de farklı durumlar için deneylere tabi tutulmuş ve bazı diğer gelişmiş mozaikleme algoritmaları ile karşılaştırılmaları sunulmuştur. Sonuçlar, geliştirilen yöntemlerin amaçlandığı gibi başarılı bir şekilde çalıştığını göstermektedir.","Image mosaicing aims to increase visual perception by composing data from separate images since a mosaic image provides a more powerful scene description. Gaining and maintaining situational awareness from image mosaics is important for both civil and military applications. Inspection of the urban areas suffering from natural disasters and examination of the large plantations are possible civil areas of utilization. For military applications, image mosaicing can provide critical information about enemy activities in wide areas. Although there are many studies in the literature that focus on creating real-time image mosaics for different applications, there is still room for improvement due to the need for faster and more accurate mosaicing for a variety of practical scenarios. In this thesis, novel techniques for creating fast and accurate aerial image mosaics of quasi-planar scenes are developed. First, a sequential mosaicing approach is proposed where all the past images intersecting the new image are used to estimate alignment of the new image. A tool from computer graphics, Separating Axis Theorem (SAT), is employed to detect image intersections. A new local affine refinement is introduced to provide global consistency throughout the mosaic. Second, a pose estimation based mosaicing technique is developed where the scene normal and the camera pose parameters are estimated through an Extended Kalman Filter (EKF). Mosaic is formed by using the homographies constructed from the estimated state vector. Using an EKF based approach provides a significant global consistency throughout the mosaic since all the parameters are updated by which error accumulations in the loop closing regions are compensated. Proposed algorithm also provides localization and attitude information of the camera which might be beneficial for robotics applications. Both methods are verified through several experiments and comparisons with some state-of-the-art algorithms are presented. Results show that the developed algorithms work successfully as intended."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tam Homomorfik Şifreleme (THS) programları, kullanıcıların şifrelenmiş veri üzerinde her türlü işlemi yapmasına olanak verir. Bu, şifrelenmiş veri bitleri üzerinde uygulanan çarpma ve toplama, bir diğer deyişle mantıksal VE veya ÖZELVEYA işlemleri sayesinde mümkün olur. Her türlü mantıksal devre sadece ÖZELVEYA ve VE mantıksal işlemlerini gerçekleştiren mantıksal kapılar kullanılarak oluşturulabildiği için, bu iki temel THS işlemi, şifreli metinler üzerinde daha karmaşık operasyonların da hesaplanabilmesini sağlar. Bulut bilişim kullanıcıları çoğunlukla bulut sunucularına güvenmemeye meyilli olduklarından, güvenlikleri gereği, bilgilerini şifreleyerek saklama yoluna giderler. Dolayısıyla şifreli veriler üzerinde işlem yapabilmeyi olanaklı kılan homomorfik şifreleme sistemleri, özellikle bulut bilişim uygulamalarında yaygın kullanım alanı bulacaktır. THS sayesinde, bulut sunucuları artık istenilen herhangi bir işlemi, kullanıcının gizli şifresini veya açık veriyi görmeden, THS yapıtaşlarını kullanarak gerçekleyebilir. Bu tez kapsamında, bir sunucunun uygulamak isteyebileceği bu tür işlemlerden biri olan sıralama problemine odaklanılmıştır. Bu amaçla, tam homomorfik şifreleme sistemi ile şifrelenmiş¸ veriyi verimli bir şekilde sıralamaya yarayacak iki yeni sıralama algoritması sunulmuştur. Bu algoritmalar karşılaştırma sayısı gibi geleneksel ölçütlerin yanısıra, oluşacak sıralama devresinin derinliğinin en aza indirgenmesine odaklanarak tasarlanmışlardır. Derinliğin azaltılması, operasyonlar sırasında şifrelenmis¸ veri bitlerinde oluşan ve şifre çözümünü olanaksız kılan gürültünün daha yavaş bir şekilde artmasını, dolayısıyla daha küçük güvenlik parametreleriyle çalışılabilmesini sağlamış ve bu da verimin artmasını mümkün kılmıştır. Önerilen sıralama algoritmaları, NTRU temelli THS sistemi icin geliştirilmiş bir yazılım kütüphanesi kullanılarak gerçeklenmiş ve klasik sıralama algoritmalarına göre çok daha iyi sonuçlar verdiği gösterilmiştir.","Fully Homomorphic Encryption (FHE) schemes allow users to perform computations over encrypted data without decrypting the ciphertext. This is possible via two operations which are bitwise addition and multiplication, namely logical XOR and logical AND operations, which can be applied over the bits individually encrypted under the fully homomorphic encryption scheme. Since any Boolean circuit can be realized using only AND and XOR gates, they can be used to build circuits for the computation of even more complicated operations over encrypted data. This property of FHE cryptosystems is especially useful in cloud computing applications, since data owners who use cloud computing for storage and computation, usually tend not to trust servers and for security reasons, they prefer storing their data in encrypted form. By using FHE cryptographic primitives, now servers are allowed to perform any desired task over the encrypted user data without the knowledge of secret key or plaintext. In this thesis, we focus on solving one such task that cloud server performs over encrypted data; sorting the elements of an integer array. We introduce two sorting schemes, both of which are capable of efficiently sorting data in fully homomorphic encrypted form. The technique is obtained by focusing on the minimization of the depth of the sorting circuit in addition to more traditional metrics such as the number of comparisons. The reduced depth of the sorting network allows a slower growth in the noise of encrypted bits and thereby makes it possible to select smaller parameter sizes for the underlying homomorphic encryption scheme resulting in much faster computation of homomorphic sorting. We present a leveled/batched implementation for the proposed sorting algorithms, using an NTRU based homomorphic encryption library, which yields significant improvements over classical sorting algorithms."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal medya günümüzde en büyük bilgi akış ortamlarından biri olmasına karşın geleneksel kamuoyu araştırması kendi merkezi önemine rağmen sosyal medyayı gözardı etmektedir. Geleneksel kamu araştırması onun yerine anketlere yönelmektedir. Ama doğası gereği en titiz hazırlanmış anket bile zaman sınırlı ve meyilli olabilmektedir. Eğer düzgün kullanılabilirse sosyal medya bu sorunları aşmakta yardımcı olabilir; sosyal medya bizim haberleşmeyi ve bilgi akışını zaman ve yer olarak kesintisiz olarak izlememize imkan vererek araştırmacının anket ile meyilli olmayan, hem de daha büyük verisetine ulaşmasını sağlamaktadır. Bu tezde disiplinler arası bir çalışma göstererek, ağ analizi ve makine öğrenmesi kullanarak,sosyal bilim sorularına empirik ölçülebilir cevaplar vermeye çalıştık. Bu çalışma sosyal ağ analizi ve fikir madenlemesinin birleştirerek, kavram kanıtlamak için 2014 İstanbul yerel seçimlerini analiz etmektedir. Ve, sonuçlarda fikir madenlemesi sistemizin performasını ve iki politik grup arasındaki yapısal farkları sunmaktadır.","Social media is one of the largest information flow medium today. Nevertheless, despite its centrality, conventional public opinion research doesn't take social media into account but instead focuses on surveys, polls and interviews. These research methods have their limitations. By nature, even the most meticulously designed survey, for example, is limited by time and seldom bias free. If properly utilized social media, can address limitations of these shortcomings; Social Media allows us to continuously observe how information flows both temporally and spatially since its users communicate with each other rather than answering survey questions; the data is without experimenter bias and sample size is much larger than of conventional methods. We aimed to show an interdisciplinary work that provides empirical quantifiable answers for social science problems using network analysis and machine learning. With this aim in mind, this work combines network analysis and sentiment analysis to analyze Istanbul 2014 local elections as a proof of concept. Furthermore, it illustrates the performance of our sentiment analysis system and structural differences between two parties in the event."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hem akademik hem de endüstri çevrelerinde, hassas bilgi içeren verilerin bulut hizmeti veren firmalara aktarılması akımının başlamasıyla, şifrelenmiş veri üzerinde arama yapmak çok kritik ve önemli bir işlem haline geldi. Bulut yapısının, çok yüksek depolama ve hesaplama kapasitesini uygun fiyatlarla kullanıcılara sunuyor olması, bu akımın temel çıkış noktasıdır. Problemin öneminden dolayı, şifrelenmiş veri üzerinde mahremiyet korumalı arama yapmak, literatürde farklı modeller altında geniş çaplı bir şekilde incelenmiştir. Bulut yapısının faydaları kabul edilmekle birlikte, aktarılan verilerin mahremiyeti konusu hala çözülmesi gereken bir problemdir. Sorgu sırasında gönderilen anahtar terimlerin içeriği, sorgu terimlerinin kullanım sıklığı, geri dönen verilerin içeriği, bu verilerin sorgu ile ne oranda örtüştüğü gibi bilgilerin tamamı kullanıcılarla ilgili hassas bilgiler olarak nitelendirilebilir. Mahremiyet korumalı arama metotları, bu hassas bilgilerin korunmasını hedeflemektedir. Bu çalışmada iki farklı mahremiyet korumalı anahtar kelime arama yöntemi öneriyoruz. Her iki yöntem de, hem başka kullanıcılara karşı, hem de bulut sunucusunun kendisine karşı verilerin mahremiyetini sağlıyor. Mahremiyeti sağlamak için, kriptografik yöntemlerin yanı sıra, sorguları ve dönen cevapları rastgele hale getirme yöntemlerinden de faydalanıyoruz. Güvenlik parametrelerinin doğru bir şekilde ayarlanması sağlandığı taktirde, önerdiğimiz yöntemler hem sorguların hem de buluta aktarılan verilerin mahremiyetini koruyacak niteliktedir. Önerdiğimiz yöntemler arama yapmanın dışında, eşleşen verileri sorgu ile alakalarına göre sıralama özelliğine de sahiptir. Bu özellik sayesinde sadece sorgu ile en alakalı eşleşmeler döndürülebilmektedir. Hem gerçek, hem de sentetik olarak yaratılmış veri kümeleri üzerinde yaptığımız detaylı analizler, önerdiğimiz yöntemlerin mahremiyeti koruyan ve yüksek oranda doğru sonuçları doğru bir şekilde döndürebilen yapılar olduğunu göstermektedir.","Search over encrypted data recently became a critical operation that raised a considerable amount of interest in both academia and industry, especially as outsourcing sensitive data to cloud proves to be a strong trend to benefit from the unmatched storage and computing capacities thereof. Indeed, privacy-preserving search over encrypted data, an apt term to address privacy related issues concomitant in outsourcing sensitive data, has been widely investigated in the literature under different models and assumptions. Although its benefits are welcomed, privacy is still a remaining concern that needs to be addressed. Some of those privacy issues can be summarized as: submitted search terms and their frequencies, returned responses and their relevancy to the query, and retrieved data items may all contain sensitive information about the users. In this thesis, we propose two different multi-keyword search schemes that ensure users' privacy against both external adversaries including other authorized users and cloud server itself. The proposed schemes use cryptographic techniques as well as query and response randomization. Provided that the security and randomization parameters are appropriately chosen, both search terms in queries and returned responses are protected against privacy violations. The scheme implements strict security and privacy requirements that essentially can hide similarities between queries that include same keywords. One of the main advantages of all the proposed methods in this work is the capability of multi-keyword search in a single query. We also incorporate effective ranking capabilities in the proposed schemes that enable user to retrieve only the top matching results. Our comprehensive analytical study and extensive experiments using both real and synthetic data sets demonstrate that the proposed schemes are privacy-preserving, effective, and highly efficient."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Radyo Frekanslı Kimlik Tanımlama (RFID) teknolojisi, son zamanlarda günlük hayatımızdaki bir çok uygulamalarda kullanılmaktadır. Özellikle pasaportlarda, ödeme sistemlerinde, giriş/çıkış kontrollerinde, tedarik zincirinde vb. uygulamalarda kullanılmaktadır. RFID etiketleri nesne veya canlılar üzerinde yerleştirilen bir çip olup radyo frekansı aracılığı ile kimlik tanımlamaya ve takip edilmeye olanak sağlar. Kimlik doğrulama gerektiren uygulamalarda güvenlik ve mahremiyet iki önemli sorundur. Öte yandan, RFID etiketleri güçlü fiziksel saldırılara karşı dayanıklı değildirler ve sınırlı hesaplama kaynaklarına sahiptirler. Bu nedenle, endüstriyel uygulamalar için mahremiyet odaklı, güvenli ve maliyet etkin bir doğrulama mekanizması tasarlamak çok zor bir istir. Ayrıca, RFID sistemleri kimlik doğrulama amaçlı kullanıldığında aktarma saldırılarına ( yani mafya , terörist ve dolandırıcılık saldırıları) açıktır. Mesafe sınırlama protokolleri özellikle bu saldırılara karsı bir önlem olarak tasarlanmıştır. Bu protokollerde, etiketler ile okuyucu arasında hızlı bir sorgu/cevap işleminde mesajların gidiş-dönüş gecikme süreleri ölçülerek etiketlerin dar ve sınırlı bir alan içerisinde kimlik doğrulama yapmaları hedeflenmektedir. Son zamanlarda, literatürde bir çok RFID mesafe sınırlayıcı protokolleri sunuldu, ancak bunların hiçbiri terörist dolandırıcılığa karşı ideal bir güvenlik çözümü sunmamaktadır. Öte yandan, okuyucu ve sunucu tarafında kaynakların yetersiz olması durumunda güvenli ve verimli bir kimlik doğrulama protokolünü tasarımı inşa etmek zorlaşmaktadır. Bulut bilişim bu soruna etkili bir çözüm sağlamak için umut verici bir teknoloji olarak karsımıza çıkmaktadır. Bulut bilişimde birey ve şirketler hakkında belge ve dokümanların sayısı arttıkça ve bu bilgilerin bulut bilişimde korunması gerekliliği endişelerini arttırmaktadır. RFID kimlik doğrulama sistemleri içine bulut hizmetlerini entegre ederken, bulut bilişime karsı RFID etiket sahibinin mahremiyetinin korunması da dikkate alınmalıdır . Bu motivasyonla, bu doktora tezi, yukarıda belirtilen problemlere çözüm olmak amacı ile güvenli ve mahremiyet odaklı RFID protokollerin tasarımlarına katkıda bulunmaktadır. Öncelikle, Klonlanamayan fonksiyonlara (PUF) dayalı iki farklı RFID mahremiyet modeli önerildi. Modellerin uygulanabilirliği için çeşitli kimlik doğrulama protokolleri önerildi. Ayrıca, mesafe sınırlama protokolleri üzerinde katkılar yapıldı. PUF fonksiyonlar kullanılarak yeni bir RFID mesafe sınırlayıcı protokolü önerildi ve bu protokol ile en yüksek güvenlik seviyelerinin nasıl sağlandığı gösterildi. Son olarak, RFID sistemleri içine bulut bilişim teknolojilerinin entegre edilmesi için yeni bir güvenlik ve mahremiyet modeli tanımlandı ve bu modelin pratikte uygulanabilir olduğunu göstermek için iki farklı protokol önerildi.","RFID is a leading technology that has been rapidly deployed in several daily life applications such as payment, access control, ticketing, e-passport, supply-chain, etc. An RFID tag is an electronic label that can be attached to an object/individual in order to identify or track the object/individual through radio waves. Security and privacy are two major concerns in several applications as the tags are required to provide a proof of identity. The RFID tags are generally not tamper-resistant against strong adversarial attacks. They also have limited computational resources. Therefore, the design of a privacy preserving and cost-effective RFID authentication protocol is a very challenging task for industrial applications. Moreover, RFID systems are also vulnerable to relay attacks (i.e., mafia, terrorist and distance frauds) when they are used for authentication purposes. Distance bounding protocols are particularly designed as a countermeasure against these attacks. These protocols aim to ensure that the tags are in a bounded area by measuring the round-trip delays during a rapid challenge-response exchange of short authentication messages. Several RFID distance bounding protocols have been proposed recently in the literature. However, none of them provides the ideal security against the terrorist fraud. Besides, the requirements of low resources and inefficient data management trigger to make use of cloud computing technology in RFID authentication systems. However, as more and more information on individuals and companies is placed in the cloud, concerns about data safety and privacy raise. Therefore, while integrating cloud services into RFID authentication systems, the privacy of tag owner against the cloud must also be taken into account. Motivated by this need, this dissertation contributes to the design of algorithms and protocols aimed at dealing with the issues explained above. First of all, we introduce two privacy models for RFID authentication protocols based on Physically Unclonable Functions (PUF). We propose several authentication protocols in order to demonstrate these models. Moreover, we study distance bounding protocols having bit-wise fast phases and no final signature. We give analysis for the optimal security limits of the distance bounding protocols. Furthermore, we propose a novel RFID distance bounding protocol based on PUFs and it satisfies the highest security levels. Finally, we provide a new security and privacy model for integrating cloud computing into RFID systems. For the sake of demonstration of this model, we also propose two RFID authentication protocols that require various computational resources and provide different privacy levels."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sonlu durum makinelerine (SDM'e) dayalı sınama yöntemleri 1956 yılında makine tanıma üzerine yapılan çalışmalar ile başlamış ve elli yılı aşkın bir süredir üzerinde çalışılan bir konu olmuştur. Makine tanıma çalışmalarını takiben bir gerçekleştirmenin bir spesifikasyona uygun olup olmadığının sınanması üzerine çalışmalar başlamış ve verilen SDM'nin durumları tanımlandığı ve belli bir hata kümesi göz önüne anlındığı zaman verilen bir SDM için sınama dizilerinin üretilmesi için polinom zamana ihtiyaç duyulduğu bilinmektedir. Bu tezde iki farklı sınama dizisi ele alınmıştır: Sınama Dizisi (SDi) ve Sınama Deneyleri (SDe). Sınama dizileri ister SDi ister SDe olsun genelde belli bir prensipte çalışır: bir kez üret ve çok kez kullan. Bu yüzden sınama dizilerinin boylarının kısa olması sınama sırasında geçen yekün süreyi azaltacağı gerekçesi ile oldukça önemlidir. Bu yüzden literatürde bu alanda çalışmalar yapılmaya başlanmıştır. Bu tezde ilk önce SDi'lerin boyunu kısaltmayı amaçlayan stratejiler gösterilmiştir. Bir SDi birden fazla kendisinden ufak girdi dizilerinden oluşur mesela Sıralama Dizisi, Durum Tanıma Dizisi. Bu konu üzerine yapılan hemen hemen tüm çalışmalar bu dizilerin SDM ile birlikte verildiğini tahmin etnişlerdir ve bu diziler ile oluşturulacak SDi'ler belli bir hata kümesi göz önünde bulundurularak üretildiğinde bir spesifikasyonun hatalı tüm gerçekleştirmelerini bulacağı bilinmektedir. Bir başka değiş ile verilen hatalı bir gerçekleştirme üretilen bir SDi tarafından belirlenebilir. Farklı SDi oluşturma yöntemleri bu dizileri farklı şekilde bir araya getirerek SDi'leri daha kısa boyda oluşturmayı amaçlamışlardır. Ancak Sıralama ve Durum Tanıma dizileri bir SDi'nin en büyük parçaları olduğu bilgisi ile hareket edersek bu dizilerin boylarının kısaltılması, oluşturulacak SDi'lerin boylarını'da kısaltacağı düşünülmelidir. 1991'de verilen bir SDM'nin en kısa sıralama dizinin üretilmesinin NP != P eşitsizliği var olduğu sürece polinom zamanda üretilemeyeceği ispat edilmiştir. Ancak yakın geçmişte bir SDM'nin durumlar arası geçişlerinin özel bir türde olması ""monotonik"" durumunda en kısa sıralama dizisinin polinom zamanda üretileceği gösterilmiştir. ancak kısmi tanımlı bir monotonik SDM'nin en kısa sıralama dizisinin hesaplanma zorluğu açık bir problemdi. Bu tezde bu problemin NP-Zor olduğunu gösterdik. Öteyandan, 1994 yılında özellikli bir durum tanıma dizisinin (uyarlamalı ayrıştırma dizisi (UAD)) polinom zamanda üretilebileceği gösterilmiştir. Aynı çalışmada yazarlar aynı zamanda bir SDM için bu diziyi polinom zamanda üretebilen bir algoritma da göstermişlerdir. Ancak bu algoritma herhangi bir ayrıştırma dizisini büyüklüğünü aldırmadan üretmektedir. Bu çalışmadan başka tam tanımlı yada kısmi tanımlı SDM'ler için uyarlamalı ayrıştırma dizisi üretebilen başka bir çalışma yoktur. Bu tezde kısa uyarlamalı ayrıştırma dizisi üretmenin NP-TAM ve en kısa UAD'ye yaklaşmanın da NP-Zor olduğunu gösterdik. Bunun yanında SDi nin boyunu ortalama %29.2 kadar kısaltabilen sezgisel yöntemler sunduk. Bu tezde SDe'lerin boyunu kısaltmayı hedefleyen çalışmalar yaptık. SDe'ler SDi'lerin aksine birbiri ile birleşmeyen çok sayıda ufak sınama konuları içerir her bir sınama konusu gerçekleştirmenin farklı bir yönünü sınar. Ancak SDi'ler de olduğu gibi bu sınama konularının büyük bir bölümü yine durum tanıma dizilerinden oluşur. SDe'ler için sınırlı sayıda durum tanıma dizisi mevcuttur, bu tezde yeni bir durum tanıma dizisi sunduk ve gösterdik ki bu yeni durum tanıma dizisinin oluşturulmasının PSPACE-Tam olduğunu gösterdik. Bu sonucu takiben bu dizileri üretmek için sezgisel yöntem ürettik ve endüstriden alınmış SDM'ları üzerinde deneylar yaptık ve teklif edilen yöntem ile SDe'lerin boylarını %65'e varan oranlarda kısaltılabileceğini gösterdik. Dağıtık SDM'lerin (DSDM'lerin) sınanması tabanlı sınama çalışmalarının ilginç bir ayağı olmaktadır. Sınama dizilerinin üretiminde yaşanan zorluklara ek olarak dağıtık mimarilerin getirmiş olduğu kontrolledilebilirlik ve gözlemlenebilirlik problemleri eklenmektedir. Hernekadar mevcut SDi üretme yöntemleri durum tanıma dizilerinin DSDM ile birlikte verildiği düşünülmüşsede kontrol edilebilen durum tanıma disizin üretlimesine değinen bir çalışma yoktur. Bu tezde bu dizilerin üretilmesinin zorluğunu araştırmış ve bu dizilerin polinom zamanda üretilemeyeceğini ispatlamış bulunmaktayız.","Finite State Machine (FSM) based testing methods have a history of over half a century, starting in 1956 with the works on machine identification. This was then followed by works checking the conformance of a given implementation to a given specification. When it is possible to identify the states of an FSM using an appropriate input sequence, it's been long known that it is possible to generate a Fault Detection Experiment with fault coverage with respect to a certain fault model in polynomial time. In this thesis, we investigate two notions of fault detection sequences; Checking Sequence (CS), Checking Experiment (CE). Since a fault detection sequence (either a CS or a CE) is constructed once but used many times, the importance of having short fault detection sequences is obvious and hence recent works in this field aim to generate shorter fault detection sequences. In this thesis, we first investigate a strategy and related problems to reduce the length of a CS. A CS consists several components such as Reset Sequences and State Identification Sequences. All works assume that for a given FSM, a reset sequence and a state identification sequence are also given together with the specification FSM M. Using the given reset and state identification sequences, a CS is formed that gives full fault coverage under certain assumptions. In other words, any faulty implementation N can be identified by using this test sequence. In the literature, different methods for CS construction take different approaches to put these components together, with the aim of coming up with a shorter CS incorporating all of these components. One obvious way of keeping the CS short is to keep components short. As the reset sequence and the state identification sequence are the biggest components, having short reset and state identification sequences is very important as well. It was shown in 1991 that for a given FSM M, shortest reset sequence cannot be computed in polynomial time if P\neq\NP. Recently it was shown that when the FSM has particular type (``monotonic"") of transition structure, constructing one of the shortest reset word is polynomial time solvable. However there has been no work on constructing one of the shortest reset word for a monotonic partially specified machines. In this thesis, we showed that this problem is NP-hard. On the other hand, in 1994 it was shown that one can check if M has special type of state identification sequence (known as an adaptive distinguishing sequence) in polynomial time. The same work also suggests a polynomial time algorithm to construct a state identification sequence when one exists. However, this algorithm generates a state identification sequence without any particular emphasis on generating a short one. There has been no work on the generation of state identification sequences for complete or partial machines after this work. In this thesis, we showed that construction of short state identification sequences is NP-complete and NP-hard to approximate. We propose methods of generating short state identification sequences and experimentally validate that such state identification sequences can reduce the length of fault detection sequences by $29.2% on the average. Another line of research, in this thesis, devoted for reducing the cost of checking experiments. A checking experiment consist of a set of input sequences each of which aim to test different properties of the implementation. As in the case of CSs, a large portion of these input sequences contain state identification sequences. There are several kinds of state identification sequences that are applicable in CEs. In this work, we propose a new kind of state identification sequence and show that construction of such sequences are PSPACE-complete. We propose a heuristic and we perform experiments on benchmark FSMs and experimentally show that the proposed notion of state identification sequence can reduce the cost of CEs by 65% in the extreme case. Testing distributed architectures is another interesting field for FSM based fault detection sequence generation. The additional challenge when such distributed architectures are considered is to generate a fault detection sequence which does not pose controllability or observability problem. Although the existing methods again assume that a state identification sequence is given using which a fault detection sequence is constructed, there is no work on how to generate a state identification sequence which do not have controllability/observability problem itself. In this thesis we investigate the computational complexities to generate such state identification sequences and show that no polynomial time algorithm can construct a state identification sequence for a given distributed FSM."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Birden fazla farklı yapıda robot takımlarından oluşan, verilmiş bir üretim siparişini en yakın teslim tarihine yetiştirmenin hedeflendiği bir bilişsel fabrika ortamını ele alıyoruz. İhtiyaç durumunda takımlar birbirine robot ödünç vererek yardım edebilirler. Söz konusu ortam şu zorlukları barındırmaktadır: Farklı yapıdaki robotların farklı kabiliyetlerinin modelde dikkate alınması gerekmektedir; uygulanabilir planların elde edilebilmesi için (örn., çarpışmalardan sakınmak amacıyla) kesikli simgesel gösterimin sürekli harici hesap-lamalarla birleştirilmesi gerekmektedir; eniyileştirilmiş uygulanabilir geniş çaplı (en kısa üretim süreli) bir plan için takımların bir koordinasyonu bulunmalıdır; plan icrası sırasında bir uyuşmazlık ile karşılaşılması halinde, hedefe ulaşabilmek için, oluşan aksaklıklar eğer geriye kalan planın icrasını engelliyorsa, onları teşhis edebilmek ve uygun iyileşmeyi yapabilmek gerekmektedir. Bu zorlukların üstesinden gelmek amacıyla, sürekli uzayda yapılan harici hesaplamaların gömülebildiği mantık tabanlı biçimselcilikler ve otomatik akıl yürütücülerin kullanıldığı bir biçimsel planlama, icra ve denetleme sistemini öne sürüyoruz. En kısa üretim süreli eniyileştirilmiş geniş çaplı planı bulmak için bir aracının kullanıldığı, takımların ve aracının birbirlerinin çalışma alanları ya da görevleri hakkında bilgi sahibi olmadıkları, yarı-dağıtık bir yöntem öneriyoruz. Bu yönteme göre, 1) aracı, takımların kaç adet hangi yapıdaki robotu ne zaman ödünç verebilecekleri/alabilecekleri bilgisini toplar, 2) bu bilgilere göre, aracı, eniyileştirilmiş bir koordinasyon hesaplar ve her takımı bu koordinasyon konusunda bilgilendirir, 3) aracı tarafından verilen bilgiyi ve çarpışmalardan sakın-mak için yapılan harici hesaplamaları kullanarak her takım eniyileştirilmiş yerel planını hesaplar, 4) eniyileştirilmiş yerel planlar eniyileştirilmiş ortak plan elde etmek için birleş-tirilir. Birinci ve üçüncü aşamalarda, hibrid akıl yürütme yöntemlerini ve araçlarını kullanıyoruz. İkinci aşamada, takımlar için eniyileştirilmiş koordinasyon bulma problemini tanımlıyoruz, zorluğunu kanıtlıyoruz, ve problemin mevcut otomatik akıl yürütücülerle nasıl çözülebileceğini gösteriyoruz. Son aşama için, geniş çaplı planın eniyileştirilmiş olduğunu kanıtlıyoruz. Eniyileştirilmiş geniş çaplı planın icrası ve denetlenmesi için, bozuk robotlar nedeniyle oluşan başarısızlıkları teşhis edebilmeyi sağlayan, ve üretim siparişinde ve çalışma alanlarında oluşabilecek değişikliklerle başa çıkabilen bir biçimsel sistem tanıtıyoruz. Yaklaşımlarımızın uygulanabilirliğini bilişsel fabrikalar üzerinde çeşitli senaryolarla yaptığımız simülasyon ve fiziksel uygulamalar aracılığıyla gösteriyoruz.","We consider a cognitive factory domain with multiple teams of heterogeneous robots where the goal is for all teams to complete their tasks as soon as possible to achieve overall shortest delivery time for a given manufacturing order. Should the need arise, teams help each other by lending robots. This domain is challenging in the following ways: different capabilities of heterogeneous robots need to be considered in the model; discrete symbolic representation and reasoning need to be integrated with continuous external computations to find feasible plans (e.g., to avoid collisions); a coordination of the teams should be found for an optimal feasible global plan (with minimum makespan); in case of an encountered discrepancy/failure during plan execution, if the discrepancy/failure prevents the execution of the rest of the plan, then finding a diagnosis for the discrepancy/failure and recovering from the plan failure is required to achieve the goals. We introduce a formal planning, execution and monitoring framework to address these challenges, by utilizing logic-based formalisms that allow us to embed external computations in continuous spaces, and the relevant state-of-the-art automated reasoners. To find a global plan with minimum makespan, we propose a semi-distributed approach that utilizes a mediator subject to the condition that the teams and the mediator do not know about each other's workspaces or tasks. According to this approach, 1) the mediator gathers sufficient information from the teams about when they can/need lend/borrow how many and what kind of robots, 2) based on this information, the mediator computes an optimal coordination of the teams and informs each team about this coordination, 3) each team computes its own optimal local plan to achieve its own tasks taking into account the information conveyed by the mediator as well as external computations to avoid collisions, 4) these optimal local plans are merged into an optimal global plan. For the first and the third stages, we utilize methods and tools of hybrid reasoning. For the second stage, we formulate the problem of finding an optimal coordination of teams that can help each other, prove its intractability, and describe how to solve this problem using existing automated reasoners. For the last stage, we prove the optimality of the global plan. For execution and monitoring of an optimal global plan, we introduce a formal framework that provides methods to diagnose failures due to broken robots, and to handle changes in manufacturing orders and in workspaces. We illustrate the applicability of our approaches on various scenarios of cognitive factories with dynamic simulations and physical implementation."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal medya kısa zamanda hayatlarımızda önemli bir yer edindi. İnsanlar deneyimlerini, fikirlerini ve ilgi alanlarını bu platform üzerinde gerçek zamanlı olarak paylaşmaya devam ediyorlar. Son yıllarda sosyal medyada süratle artan kullanıcı sayısı, bu alanda yapılan araştırmaların kullanıcı beklentilerini karşılamak üzere yoğunlaşmasına sebep olduğu gibi sosyal medyanın toplumlar ve iş dünyası içerisinde yer alan karar mekanizmalarında kritik bir önem taşımasına yol açtı. Bu çalışmamızda sosyal medya kullanıcılarını ve onların ilgi alanlarını saptamaya yönelik yöntemler geliştirdik. İlk uygulamamız, Türkiye'deki Twitter kullanıcılarının politik ilgi odağını belirlemeye yöneliktir. Ülkedeki iki farklı politik duruşu tarif eden iki anahtar kelime kümesi belirleyerek, bu kümelerdeki kelimeleri içeren tweetleri ve bu tweetlerin kullanıcılarını topluyoruz. Bu kullanıcıların profil fotoğrafları üzerinde bir bilgisayarlı görüntü işleme tekniği olan görüntü özüt çıkarımı yöntemini uyguluyor ve fotoğrafların içeriği hakkında metinsel bilgi elde ediyoruz. Bu bilgileri ve başta tanımladığımız anahtar kelime kümelerini kullanarak Mart 2014 yerel seçimlerinden önce iki farklı politik duruşu destekleyen grupların rakamsal oranlarını tahmin etmeyi hedefliyoruz. Uygulamamızda elde ettiğimiz sonuçlarla seçim sonuçlarının birebir örtüştüğünü gözlemledik. İkinci çalışmamızda insanların tanımlama bilgilerini (Örn. İsim, yaşadığı yer) kullanarak bu insanların Facebook profil sayfalarına ulaşmaya çalışıyoruz. 1500 tanımlama bilgisini kullanarak 1332 Facebook profiline ulaştık. Son uygulamamız ise bir ilgi alanı etrafında, bu konuyla ilgili insanları yakalamayı hedefliyor. Sosyal medya üzerinde halihazırda bu konuyla ilgili olan toplulukların üyelerini bir kümede toplayarak bu üyeleri önerdiğimiz ilgi değerlendirme yöntemiyle notlandırıyoruz. Eşik değerin altında notlandırılan üyeler, belirlenen ilgi alanıyla alakasız oldukları öngörülerek kümeden eleniyorlar ve böylece geride kalan üyeler belirlenen konuyla ilgili üyeler oluyor. Sonuçlarımızı doğrulamak için yaptığımız çalışmada, insanlar tarafından ilgili olduğu tespit edilen sosyal medya kullanıcılarıyla uygulamamızın tespit ettiği kullanıcılar arasında %76'lık bir örtüşme olduğunu gözlemledik.","Social media has taken an important part in our lives in a short amount of time. People share parts of their experiences, opinions, and interests with others in a timely-fashion on these platforms. In recent years, fast growth of user population in social media is not only driving the research towards analyzing its inhabitants for fulfilling their expectations but also making it a very crucial information source for decision making processes in societies and in businesses. In this work, we propose methods for identifying users and their interests by using the multimedia data shared in social media. We show effectiveness of these methods in three applications. Our first application considers extracting political interests of Turkish Twitter users. We collect tweets that include a set of predefined words representing two different political stances in Turkey. We extract profile images of the users who wrote those tweets and apply a computer vision technique called image context extraction on this set of images to obtain some textual explanations for each picture. The main goal of this work is inferring proportions of two different political stances to forecast results of March 2014 local elections. Our results show that the proportions obtained from our method are almost the same as the vote percentages of two parties. In our second application, we find Facebook profiles of people whose identification information (Name, surname and location) is given by querying Facebook Graph API. Each query result returns a number of profiles due to people having same name. We refine these results by checking location in profile pages online. Our method achieves a successful match rate of 88% (1332/1500 people). The third application deals with building a community about a given topic of interest by condensing existing communities in a social media platform. We collect members of the communities about the given topic in a set and apply our relevance scoring method on these members. Those who receive a score below a threshold value are assumed to be irrelevant to given topic and they are eliminated so that remaining users in the set are the ones relevant to given topic. We validated the results of our framework by a user-study. There is a 76% of match between user labelled and automated results."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Düşük maliyetli derinlik yakalayan cihazların piyasaya sürülmesiyle tespit, takip ve tanıma gibi birçok önemli bilgisayarla görme probleminde derinlik verisinin kullanımı yükselen bir trend haline geldi. Kinect 3D kamerası kullanılarak insan aktivitelerini tanıma konusu üzerine de bir çok çalışma yapılmış ve bu bağlamda derinlik verisinin 2D imgelerden daha efektif olduğu kanıtlanmıştır. Biz bu tezde derinlik verisinden insan aktivitelerini tanıma üzerine yeni bir yöntem geliştirdik. Bu yöntem hem 3D eklem bilgisini hem de derinlik imgelerinden hesaplanan optik akışı kullanmaktadır. Derinlik ve yoğunluk imgeleri arasında kurduğumuz bağıntı doğrultusunda derinlik imgelerinden 2D optik akış vektörleri bütün bir aktivite örneği süresince hesaplanmaktadır. Sonra, 3D eklem konumları baz alınarak bölgesel hareket değişimlerini öğrenebilmek için her bir eklemin çevresinden optik akış vektörlerini içeren parçalar çıkartılmaktadır. Bu parçalar bulunduğu ekleme göre gruplanıp geliştirdiğimiz HOOFD (Histogram of Oriented Optical Flows from Depth) özniteliğini hesaplamakta kullanılmaktadır. Zamansal değişimleri de takip edebilmek için HOOFD öznitelikleri piramitsel bir yaklaşımla hesaplanmıştır. Piramidin her seviyesinde aktivite eşit iki bölüme ayrılıp her bölüm histogramları doldurabilmek için ayrı değerlendirilmiştir. Ölçek ve hareket yönü değişmezliği avantajlarından dolayı optik akış vektörlerinin yönelimlerinden oluşan histogramlar kullanılmıştır. Naive Bayes ve Destek Vektör Makinaları (DVM) sınıflandırıcıları HOOFD öznitelikleri kullanılarak eğitilmiş ve birbirinden farklı birçok aktiviteyi tanımak için kullanılmıştır. Farklı veri kümeleri ile birçok deney yapılmış ve önerilen yöntem literatürdeki en gelişkin yöntemlerle karşılaştırılmıştır. Sonuçlar oldukça umut vericidir ve önerdiğimiz yöntem mevcut bazı tekniklerden daha iyi performans göstermektedir.","With the recent release of low-cost depth acquisition devices, there is an increasing trend towards investigation of depth data in a number of important computer vision problems, such as detection, tracking and recognition. Much work has focused on human action recognition using depth data from Kinect type 3D cameras since depth data has proven to be more effective than 2D intensity images. In this thesis, we develop a new method for recognizing human actions using depth data. It utilizes both skeletal joint information and optical flows computed from depth images. By drawing an analogy between depth and intensity images, 2D optical flows are calculated from depth images for the entire action instance. From the resulting optical flow vectors, patches are extracted around each joint location to learn local motion variations. These patches are grouped in terms of their joints and used to calculate a new feature called `HOOFD' (Histogram of Oriented Optical Flows from Depth). In order to encode temporal variations, these HOOFD features are calculated in a pyramidal fashion. At each level of the pyramid, action instance is partitioned equally into two parts and each part is employed separately to form the histograms. Oriented optical flow histograms are utilized due to their invariance to scale and direction of motion. Naive Bayes and SVM classifiers are then trained using HOOFD features to recognize various human actions. We performed several experiments on publicly available databases and compared our approach with state-of-the-art methods. Results are quite promising and our approach outperforms some of the existing techniques."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bulut bilişime ilginin artmasıyla birlikte, uzak sunucularda saklanan kullanıcı bilgilerinin güvenliği önemli bir sorun haline gelmiştir. İstemcilerin erişim modellerini gizlemek, özellikle borsa veya patent veritabanı gibi uygulamalarda elzem olabilmektedir. Mahremiyet-Korumalı Bilgi Erişimi (PIR), bir istemcinin bulut sunucuda saklanan bir veri öğesini (örneğin bir dosya) sunucuya hangisine eriştiğini söylemeden elde etmesini sağlamak için tasarlanmış bir protokoldür. Bu tezde, Lipmaa tarafından önerilen bir PIR protokolü olan BddCpir üzerine iyileştirmeler sunulmuştur. Orijinal BddCpir, veri yapısı olarak, veri öğelerini uç düğümlerde depolayan ikili Karar Diyagramlarını (BDD) kullanmaktadır. Öncelikle, veri yapısı olarak BDD yerine dörtlü ve sekizli ağaçların kullanımını önerilmiştir. Bu tür ağaçlarda uç olmayan her düğümün sırasıyla dört ve sekiz alt düğümü olduğu için, daha az derinliği olan ağaçlar elde edilerek, sunucu performansı orijinal asimptotik karmaşıklığı değişmeden bir mertebe iyileştirilebilmektedir. İkinci olarak, sunucu işlem gecikmesini daha da azaltabilmek için paylaşımlı bellek kullanan çok çekirdekli işlemciler için tasarlanmış bir paralelleştirme yöntemi sunulmuştur. Üçüncü olarak da, bu tezde önerilen PIR protokolünün, bant genişliğine yalnızca ufak bir ek yük ekleyerek nasıl ölçeklenebileceği gösterilmiştir. Son olarak, önerilen protokolün bir çalışmasında harcadığı bant genişliği bakımından, veri tabanı boyutuna oranla, ne kadar verimli olduğunun analizi yapılmaktadır.","With the current increase of interest in cloud computing, the security of user data stored in remote servers has become an important concern. Hiding access patterns of clients can be crucial in particular applications such as stock market or patent databases. Private Information Retrieval (PIR) is proposed to enable a client to retrieve a file stored in a cloud server without revealing the queried file to the server. In this work, we offer improvements to BddCpir, which is a PIR protocol proposed by Lipmaa. The original BddCpir uses Binary Decision Diagrams (BDD) as the data structure, where data items are stored at the sink nodes of the tree. First of all, we offer the usage of quadratic and octal trees instead, where every non-sink node has four and eight child nodes, respectively, to reduce the depth of the tree. By adopting more shallow trees, we obtain an improved server implementation which is an order of magnitude faster than the original scheme, without changing the asymptotic complexity. Secondly, we suggest a non-trivial parallelization method that takes advantage of the shared-memory multi-core architectures to further decrease server computation latencies. Finally, we show how to scale the PIR scheme for larger database sizes with only a small overhead in bandwidth complexity, with the utilization of shared-memory many-core processors. Consequently, we show how our scheme is bandwidth-efficient in terms of the data being exchanged in a run of the CPIR protocol, in proportion to the database size."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda kameraların ucuzlamasıyla görsel gözetleme sistemlerinin önemi gitgide artmaktadır. Bilimsel, ticari ve son kullanıcı uygulamalarında yaygın olarak kullanılan bu sistemler yoğun miktarda bilgiyi depolayabilir, ayıklayabilir, ve bu bilgileri bir insanın yardımı olmadan yeni bilgi çıkarımında kullanabilir. Bu tezde, bir görsel gözetim sistemi kapsamında kullanılabilecek obje tespit, takip ve görüntü mozaikleme algoritmalarının geliştirilmesine yoğunlaşılmıştır. İlk olarak gerçek zamanlı çalışabilen, hareket ipuçlarını kullanan obje tespit algoritmaları incelenmiş ve dinamik sahnelerde de çalışabilecek bir obje tespit algoritması geliştirilmiştir. Adı geçen algoritma, nonparametrik olasılıksal bir model aracılığı ile piksel komşuluklarını kullanarak görüntüdeki önplan bölgelerini ufak kamera hareketleri altında tespit edebilmektedir. Bundan sonra, önerilen obje tespiti algoritmasını bir önadım olarak kullanan bir çoklu obje takibi yöntemi geliştirilmiştir. Algoritma çoklu obje etkileşimlerini olasılıksal bir çerçevede inceleyerek, sanal kabuklar ile yoğun örtmeye sahip durumlarda objeleri takip etmektedir. Tezin son bölümünde ise sıralı görüntüleri dikerek daha geniş ve görsel olarak etkileyici bir mozaik oluşturan bir görüntü mozaikleme algoritması önerilmiştir. Önerilen yöntem lineer olmayan eniyileme tekniklerini devre dışı bırakarak, geniş görüntü kümeleri için dahi gerçek-zamanlı çalışabilmektedir. Deney sonuçları göstermektedir ki, önerilen algoritmalar gerçek zamanlı olarak dinamik ve kalabalık ortamlarda başarıyla çalışmaktadır.","Visual surveillance systems are becoming increasingly important in the last decades due to proliferation of cameras. These systems have been widely used in scienti c, commercial and end-user applications where they can store, extract and infer huge amount of information automatically without human help. In this thesis, we focus on developing object detection, tracking and image mosaicing algorithms for a visual surveillance system. First, we review some real-time object detection algorithms that exploit motion cue and enhance one of them that is suitable for use in dynamic scenes. This algorithm adopts a nonparametric probabilistic model over the whole image and exploits pixel adjacencies to detect foreground regions under even small baseline motion. Then we develop a multiple object tracking algorithm which utilizes this algorithm as its detection step. The algorithm analyzes multiple object interactions in a probabilistic framework using virtual shells to track objects in case of severe occlusions. The nal part of the thesis is devoted to an image mosaicing algorithm that stitches ordered images to create a large and visually attractive mosaic for large sequence of images. The proposed mosaicing method eliminates nonlinear optimization techniques with the capability of real-time operation on large datasets. Experimental results show that developed algorithms work quite successfully in dynamic and cluttered environments with real-time performance."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Duygu analizi geniş kapsamlı uygulama alanı olan önemli bir öğrenme problemidir. Online sosyal medyanın hızlı yükselişi ve burada ifade edilen kamuoyunun artan önemi, pek çok zorluğun yanı sıra bu araştırma için fırsat kapılarını açmaktadır. Zorluklar gittikçe büyüyen duygu analizi problemlerinin ve görevlerinin yer aldığı bir listeye eklenerek literatürde ifade edilirken, fırsatlar bu zorlukları çözmek için önerilen yeni algoritmalar ve teknikler ile avantaja dönüştürülmektedir. Ancak bu yaklaşımlar çoğunlukla diğer araştırmacıların doğrudan erişimine uzak omaktadır. Bu araştırmacılar ya her zaman mevcut olmayan kıyaslama veri setlerine dayanmak zorunda kalmakta veya karşılaştırma yaparken yaratıcı olmak durumundadırlar. Bu tezde genişletilebilir, temel ve modern yaklaşımları entegre ederek duygu analiz problemlerini çözmek için tasarlanmış ve kamuya açık bir sistem olan Duygu Analizi Araştırma Ortamı (SARE) sunulmaktadır. Araştırma alanını tüm genişliğiyle ele almak bu çalışmanın kapsamı dışında olduğu için, bu ortamın yararlılığı bir kısım görüş tabanlı duygu analizi problemlerinin çözümlerinin ortama entegrasyonuyla gösterilmektedir. Şu anda sistem, altın standardında bir sözlük oluşturulmasını sağlayan yarı otomatik bir yöntem, görüş ifadelerini otomatik çıkarmak için bir yöntem, ve önceden varolan temel bir duygu analiz motoru içermektedir. Kullanıcılara bizim önerdiğimiz set kaplama yaklaştırımı algoritması kullanılarak altın standardında bir sözlük oluşturmak için yardım edilmektedir. Önerilen bu algoritma, sözlüğü oluşturmak için gerekli olan belgeler setinin eleman sayısını ciddi miktarda düşürmektedir. Ayrıca, görüş ifadelerini ayıklamak için yarı denetimli ve Destekçi Vektör Makinası (SVM) sınıflandırıcı tabanlı otomatik bir algoritma önerilmiştir.","Sentiment analysis is an important learning problem with a broad scope of applications. The meteoric rise of online social media and the increasing significance of public opinion expressed therein have opened doors to many challenges as well as opportunities for this research. The challenges have been articulated in the literature through a growing list of sentiment analysis problems and tasks, while the opportunities are constantly being availed with the introduction of new algorithms and techniques for solving them. However, these approaches often remain out of the direct reach of other researchers, who have to either rely on benchmark datasets, which are not always available, or be inventive with their comparisons. This thesis presents Sentiment Analysis Research Environment (SARE), an extendable and publicly-accessible system designed with the goal of integrating baseline and stateof-the-art approaches to solving sentiment analysis problems. Since covering the entire breadth of the field is beyond the scope of this work, the usefulness of this environment is demonstrated by integrating solutions for certain facets of the aspect-based sentiment analysis problem. Currently, the system provides a semi-automatic method to support building gold-standard lexica, an automatic baseline method for extracting aspect expressions, and a pre-existing baseline sentiment analysis engine. Users are assisted in creating gold-standard lexica by applying our proposed set cover approximation algorithm, which finds a significantly reduced set of documents needed to create a lexicon. We also suggest a baseline semi-supervised aspect expression extraction algorithm based on a Support Vector Machine (SVM) classifier to automatically extract aspect expressions"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz Örgü Ağları (KÖA) çok sekmeli, yüksek bağlantı hızı sağlayabilen ağ teknolojileridir. Alışılagelmiş ağ servisi sağlayan sistemlere nazaran kurulumu kolay ve ekonomiktir. Bu tezde, güvenli ve kesintisiz bir ön ödeme sistemini (SSPayWMN) anlatıyoruz.Ağ bağlantısı için tasarlanmış ödeme sistemleri genelde servis sağlayıcısının güvenilirliğinden kuşku duymazlar. Fakat servis sağlayıcılar bazen istemeden de olsa fazladan ücretlendirme yapabilirler. Bu tarz durumlar müşteri ve servis sağlayıcı arasında anlaşmazlığa sebebiyet verir. Servis sağlayıcılar haklı dahi olsalar bunu müşteriye kanıtlayacak inkar edilemez kanıtları olmadığı için müşteriyi ikna edemezler.SSPayWMN'in asıl amacı güvenli bir ödeme sistemi kurmanın yanı sıra hem servis sağlayıcı hem de müşteri için adil bir ödeme sistemi sağlamaktır. Kriptografik algoritmaları ve teknikleri kullanarak, sistemin bütün elemanları kimliklerini kanıtlayabilir ve sonradan inkar edilemeyecek şekilde servis sağlayabilir veya servislerden faydalanabilirler. Bunun yanında, SSPayWMN kullanıcıların mahremiyetini ve sistemdeki hareketlerinin takip edilememesini sağlar.SSPayWMN bir ağ simülatörü (ns-3) üzerinde test edildi ve performansı değerlendirildi. Sistem tarafından sebep olunmuş gecikmeler hesaplandı. Sonuçlar protokollerimizin düşük gecikme değerlerinde dengeyi yakaladıklarını göstermiştir ve protokollerin sisteme minimum oranda yük getirdiğini kanıtlamıştır.","Wireless Mesh Network (WMN) is multi-hop high-speed networking technology for broadband access. Compared to conventional network service providing systems, WMNs are easy to deploy and cost-effective. In this thesis, we propose a secure and seamless pre-payment system for the Internet access through WMNs (SSPayWMN).Practical payment systems for network access generally depend on trustworthiness of service provider. However, in real life, service providers may unintentionally overcharge their clients. This misbehavior in the system may cause disputes between the clients and the service providers. Even if the service provider is rightful, it is very difficult to convince the customer since the service providers generally do not have justifiable proofs that can easily be denied by the clients.The main goal of SSPayWMN is to provide a secure payment scheme, which is fair to both operators and clients. Using cryptographic tools and techniques, all system entities are able to authenticate each other and provide/get service in an undeniable way. Moreover, SSPayWMN provides privacy and untraceability in order not to track down particular user's network activities.We implemented SSPayWMN on a network simulator (ns-3) and performed performance evaluation to understand the latency caused by the system's protocols. Our results show that our protocols achieve low steady state latency and in overall put very little burden on the system."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, alt ekstremitelerin robot yardımlı rehabilitasyonu amaçlı birimsel ve kendini hizalayan dışiskelet, AssistOn-Leg sunulmaktadır. AssistOn-Leg, sırasıyla ayak bileği, diz ve kalça eklemlerini hedefleyen üç kendini hizalayan ve güçlendirilmiş dışiskelet biriminden oluşmaktadır. Her bir birim bağımsız olarak ilgilendiği eklemin rehabilitasyonunda kullanılabilirken, birimlerin bir araya getirilmesiyle de doğal yürüyüş alıştırmaları gerçekleştirilebilir. AssistOn-Ankle ayak bileğinin plantar fleksiyon/dorsifleksiyon ve supinasyon/pronasyon hareketlerini hedeflemekte ve denge/propriosepsionu ya da hareket aralığı/güçlendirme alıştırmalarını verebilecek şekilde yeniden yapılandırılabilmektedir. AssistOn-Knee diz ekleminin fleksiyon/ekstensiyon hareketini hedeflemekte ve aynı anda bu harekete bağlı sagital düzlemde oluşan öteleme hareketlerini de desteklemektedir. AssistOn-Hip kalça ekleminin fleksiyon/ekstensiyon hareketini hedeflemekte ve kalça-leğen kemiği bileşiğinin sagital düzlemdeki öteleme hareketlerine izin vermektedir. Eklem eksenlerinin kendi kendine hizalanması sonucunda, AssistOn-Leg ve birimleri insan eklem eksenleri ve robot eksenleri arasında kusursuz bir eşleşmeyi garanti etmektedir. Bu sayede, kendini hizalama, terapi süresince ergonomi ve rahatlığı sağlarken cihazların kurulumu ve hastaya bağlanması için gereken süreyi de önemli ölçüde azaltmaktadır. Bowden kablo sürülü seri elastik eyleyicilerden ayak bileği ve diz birimlerinde, insan yürüyüşünü destekleyecek yüksek eyleyici torku sağlanırken sistemin belirgin ataletinin düşük tutulması amacıyla yararlanıldı. Ayrıca seri elastiklik, iyi kuvvet takibi nitelikleri, kontrol bant genişliği içerisinde aktif geri sürülebilirlik, pasif yumuşaklık ve kontrol bant genişliği dışındaki uyarılmalara karşı darbe direnci gibi özellikleri imkan vermektedir. AssistOn-Hip tasarımında ise pasif geri sürülebilir olması amacıyla çoklu seviyeli ırgat temelli bir iletim kullanılmıştır. Ayak bileği ve diz birimlerindeki pasif yumuşaklık ve kalça birimindeki pasif geri sürülebilirlik sayesinde, genel sistem tasarımının güç kaybında bile emniyetli olması ve tüm frekans tayfında gürbüzlük garanti edilmiştir.","We present AssistOn-Leg, a modular, self-aligning exoskeleton for robotassisted rehabilitation of lower extremities. AssistOn-Leg consists of three selfaligning, powered exoskeletons targeting ankle, knee and hip joints, respectively. Each module can be used in a stand-alone manner to provide therapy to its corresponding joint or the modules can be connected together to deliver natural gait training to patients. In particular, AssistOn-Ankle targets dorsiflexion/ plantarflexion and supination/pronation of human ankle and can be configured to deliver balance/proprioception or range of motion/strengthening exercises; AssistOn-Knee targets flexion/extension movements of the knee joint, while also accommodating its translational movements in the sagittal plane; and AssistOn- Hip targets flexion/extension movements hip joint, while allowing for translations of hip-pelvis complex in the sagittal plane. Automatically aligning their joint axes, modules of AssistOn-Leg ensure an ideal match between human joint axes and the exoskeleton axes. Self-alignment of the modules not only guarantees ergonomy and comfort throughout the therapy, but also significantly shortens the setup time required to attach a patient to the exoskeleton. Bowden cable-driven series elastic actuation is utilized in the modules located at the distal (knee and ankle) joints of AssistOn-Leg to keep the apparent inertia of the system low, while simultaneously providing large actuation torques required to support human gait. Series elasticity also provides good force tracking characteristics, active back-driveability within the control bandwidth and passive compliance as well as impact resistance for excitations above this bandwidth. AssistOn-Hip is designed to be passively back-driveable with a capstan-based multi-level transmission. Thanks to passive compliance of the distal modules and passive backdriveability of the hip module, the overall design ensures safety even under power losses and robustness throughout the whole frequency spectrum."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Proteinlere farklı proteinlerin eklenmesi yönteminin, birbirinden farklı protein mühendisliği uygulamalarında kullanılan farklılaştırılmış protein üretimi sürecindeki etkinliği kanıtlanmıştır. Protein ekleme, proteini ifade eden gen üstünde belli başlı bölgelere gen yerleştirerek farklı bir protein elde edilir ve proteinin işlevselliğinde değişikliğe yol açar. Proteinler, sadece üzerlerinde belli başlı alanlara yapılan yerleştirmeleri tolere edebilirler. Bu yüzden bu tolere edilen yerleştirme alanlarının tanımlanması, başarılı bir yerleştirme yapabilmek için büyük önem taşır. Bu yerleştirime alanları, deneme yanılma yöntemiyle tanımlanabilir. Fakat, bu alanlara yönelik doğruluk oranı yüksek bir tahmin yöteminin geliştirilmesi, bu alanların ortaya çıkarılmasını kolaylaştıracaktır.Bu çalışmada, makina öğrenmesi ve veri madenciliği yöntemlerini kullanarak, proteinlerin tolere edilebilen gen yerleştirme alanlarını tahmin etmekteyiz. Bu tahminler eğitilmiş tahminler olarak adlandırmaktayız. Eğitilmiş tahminlere, gen yerleştirme alanını çevreleyen amino asitlerin belirgin özelliklerini seçerek ulaşmaktayız. Bu tek sayıdaki yerleştirme bölgesini çevreleyen amino asitleri, boyu ayarlanabilen bir pencere yardımıyla belirlemekteyiz. Yerleştirme bölgesi, bu pencerenin ya merkez noktasına ya da orta değer noktasına düşmektedir. Bu pencere içerisinden, amino asitlerle alakalı bir grup özellik elde edilmiştir. Sonrasında, SVM makine öğrenme yöntemini kullanılarak, 10 farklı proteinden elde edilen gen yerleştirmeye elverişli ve elverişsiz 135 bölge ile eğitilerek bir model oluşturulmuştur.Eğitilmiş modelimiz, Dış zar yer gösterici proteini FasD, Laktoz kalıt baskılayıcı LacI, Tip II sekresyon sistemi proteini XpsD ve de Maltoz periplazmik proteini MalE için sırasıyla %70.59, %61.11, %61.90 ve %90.00 doğruluk oranlarına erişmiştir.","The procedure of domain insertion is proven to be very effective in the process of creating modified proteins that can be used for different protein engineering applications. Domain insertion alters the functionality of the protein by inserting gene or genes into certain domains. Proteins usually tolerate insertions in specific sites only, therefore identifying those permissive insertion sites is crucial for any successful insertion attempt. Normally, determining permissive insertion sites is performed experimentally by a genetic approach. However an educated guess can assist in predicting the potential permissive insertion sites.In this work, we introduced a method for predicting permissive insertion sites through the utilization of machine learning and data mining techniques. We have adopted an educated guess approach to predict permissive sites by extracting distinctive features from the amino acids surrounding the insertion site included within any captured amino acid window. The window size was made adjustable and can capture any odd number of amino acids. We used a number of features related to amino acids obtained from this window and then used a machine learning based approach to construct a trained SVM model using 135 permissive and non-permissive sites obtained from 10 different proteins.Our trained model was used to predict permissive insertion sites in Outer membrane usher protein FasD, Lactose operon repressor LacI, Type II secretion system protein XpsD, and Maltose periplasmic protein MalE and 70.59%, 61.11%, 61.90% and 90.00% accuracies were achieved respectively."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaretleyicisiz insan hareket analizinin, hareket tanıma ve vücut poz tahmini için verimli maliyete sahip çözüm sunma potansiyeli vardır. İnsan-bilgisayar etkileşimi, video gözetlemesi, içerik tabanlı video indeksleme, ve otomatik açıklama da dahil olmak üzere birçok uygulama, bu güçlü çözümden yararlanacaktır. Geleneksel video doğasındaki çeşitli belirsizlikler sebebiyle çok zor olarak kabul edilen otomatik görüntü tabanlı insan hareketi tanıma sorunu, son yıllardaki derinlik algılama teknolojileri sayesinde olumlu değişiklikler gösterdi. Bu çalışmada, ilk olarak değişmeyen spatiotemporal özellikli büyük bir set, hareket halindeki iskelet eklemlerinden (derinlik sensöründen alınan) elde edilir ve temel performans olarak değerlendirilmektedir. Sonra, bir lineer SVM sınıflandırıcı ile kombine edildiğinde etkileyici hareket tanıma performansına ulaşma kapasitesine sahip bir ayrımcı Rastgele Karar Ormanı tabanlı özellik seçimi çatısı tanıttık. Bu yaklaşım özellik kümesi önemli ölçüde daha az sayıda (orijinalin onda biri) kullanarak tüm özellik kümesini kullanarak elde edilen temel performansa üstünlük sağlar. Bu yaklaşım aynı zamanda insan hareketlerinin mekan-zamansal dinamikleri üzerinde fikir edinmek için kullanılabilir. Yeni bir tedavi edici hareket tanıma veri kümesi (WorkoutSU-10) sunulmuştur. Önerilen yöntemlerimizin güvenilirliğini değerlendirmek için testlerimizde bir kriter olarak bu veri kümesinden yararlandık. Yakın geçmişte, veri kümesi hareket tanıma toplumuna bir katkı olmak üzere kamuya yayınlanmıştır. Buna ek olarak, yaşlı insanlardaki 'düşüş algılama' gibi gerçek hayat problemlerine veya motor engelli hastalar için otomatik terapi programına yardımcı olmak için sunulan yöntemler kullanılarak interaktif bir hareket değerlendirme uygulaması geliştirilmiştir.","Markerless human motion analysis has strong potential to provide cost-efficient solution for action recognition and body pose estimation. Many applications including human-computer interaction, video surveillance, content-based video indexing, and automatic annotation among others will benefit from a robust solution to this problem. Depth sensing technologies in recent years have positively changed the climate of the automated vision-based human action recognition problem, deemed to be very difficult due to the various ambiguities inherent to conventional video. In this work, first a large set of invariant spatiotemporal features, is extracted from skeleton joints (retrieved from depth sensor) in motion and evaluated as baseline performance. Next we introduce a discriminative Random Decision Forest-based feature selection framework capable of reaching impressive action recognition performance when combined with a linear SVM classifier. This approach improves upon the baseline performance obtained using the whole feature set with a significantly less number of features (one tenth of the original). The approach can also be used to provide insights on the spatiotemporal dynamics of human actions. A novel therapeutic action recognition dataset (WorkoutSU-10) is presented. We took advantage of this dataset as a benchmark in our tests to evaluate the reliability of our proposed methods. Recently the dataset has been published publically as a contribution to the action recognition community. In addition, an interactive action evaluation application is developed by utilizing the proposed methods to help with real life problems such as `fall detection? in the elderly people or automated therapy program for patients with motor disabilities."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok fazlı Telsiz Duyarga Ağlarında, duyarga düğümleri bataryaları tükenmiş düğümlerin yerine geçmek üzere periyodik olarak tekrar konuşlandırılır. Ağı, nesil adı verilen farklı konuşlandırma zaman aralıklarında düğüm ele geçirme saldırılarına karşı daha güçlü hale getirmek için kriptografik anahtarların dağıtımının yapıldığı anahtar havuzunu tazelemek gerekmektedir. Bu tezde, her nesil için farklı anahtar havuzları kullanan Eşitsiz Ön Yüklemeli Anahtar Dağıtım şeması anlatılmaktadır. Bu anahtar havuzlarından alınan farklı sayıda anahtarlar duyarga düğümlere konuşlandırılmanın öncesinde yüklenir. Düğümlerde yüklü olan anahtarlar, düğümün sadece kendi nesline değil, aynı zamanda gelecek nesillere ait anahtarlardan da oluşmaktadır. Simulasyonlarımızda, performans değerlendirmesini mobil ortamlar için üç tane mobilite modeli kullandık. Bunlardan bir tanesi olan Çembersel Hareket Mobilite modeli ilk olarak bu tezde sunulmaktadır. Eşitsiz Ön Yüklemeli Anahtar Dağıtım şeması literatürde bulunan bir şemaya göre daha ağın dayanıklılığını ağır saldırı altında %50'ye kadar arttıran bir öz iyileşme sağlamaktadır. Bunların yanı sıra, şemamızda yerel ve genel bağlantı oranı yaklaşık 100% olmaktadır.","In multiphase Wireless Sensor Networks (WSNs), sensor nodes are redeployed periodically to replace nodes with depleted batteries. In order to keep the network resilient against node capture attacks across different deployment epochs, called generations, it is necessary to refresh the key pools from which cryptographic keys are distributed. In this thesis, we propose Uneven Key Predistribution (UKP) scheme that uses multiple different key pools at each generation. Keys are drawn unevenly from these key pools and loaded to sensor nodes prior to deployment. Nodes are loaded with keys not only from their current generation, but also from future generations. We conduct simulation based performance evaluation in mobile environments using three different mobility models. One of them, Circular Move Mobility model, is first proposed in this thesis. Our UKP scheme provides self healing that improves the resiliency of the network up to 50% under heavy attack as compared to an existing scheme in the literature. Moreover, our scheme provides almost perfect local and global connectivity."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hata Düzelten Çıktı Kodlaması (HDÇK) Çok sınıflı sınıflandırma problemleri için, pek Çok taban sınıflayıcının önceden belirlenmiş bir kod matrisine göre, orijinal sınıfların farklı bir ikiye ayırma problemini öğrendiği bir sınıflandırıcı birleştirme yöntemidir. HDÇK Çok sınıflı sınıflandırma problemleri iÇin en iyi yöntemlerden olsa da, bulunan Çözüm optimal değildir, Çünkü kod matrisi ve taban sınıflandırıcılar birbirlerinden bağımsız belirlenir. Bu tezde bu ayrımı azaltıcı, yinelemeli üÇ algoritma önerilmektedir. İlk olarak FlipHDÇK+ metotunu uyguladık. Bu metotta belli bir doğruluk değerinin altında kalan bütün matris elemanlarını sırayla döndürüyoruz ve eğer güncellediğimiz kod matrisinin doğruluk değeri daha yüksekse, döndürme işlemine yeni güncellediğimiz matris üzerinden devam ediyoruz. İkinci metot ise benzetilmiş tavlama uygulayarak her yinelemede, kod matrisi üzerinde önerilen matris elemanını döndürerek elde ettiğimiz güncellenmiş matrisi doğruluk oranıyla hesapladığımız olasılık değerine göre kabul etmektir. En son metot ise ışın araması kullanarak en yüksek doğruluk değerine sahip güncellenmiş kod matrisini bulmaktır. En son önerdiğimiz metot UCI (Irvine California üniversitesi) veritabanında en yüksek doğruluk oranını vermektedir. Bütün önerilen metotlar taban sınıflandırıcıları sabit tutar, yeniden eğitim gerektirmez; ayrıca herhangi bir HDÇK'ya uygulanabilir.","Error Correcting Output Coding (ECOC) is a multi-class classification technique in which multiple binary classifiers are trained according to a preset code matrix, such that each one learns a separate dichotomy of the classes. While ECOC is one of the best solutions to multi-class problems, it is suboptimal since the code matrix and the base classifiers are not learned simultaneously. In this thesis, we present three different algorithms that iteratively updates the ECOC code matrix to improve the performance of the ensemble by reducing the decoupling. Firstly, we applied the previously developed FlipECOC+ update algorithm. Second method is applying simulated annealing method on updating ECOC matrix by flipping proposed entries according to ascending order. Last method is applying beam search to find updated ECOC matrix which has highest validation accuracy. We applied all three algorithms on UCI (University of California Irvine) data sets. Beam search algorithm gives the best result on UCI data sets. All of the proposed update algorithms does not involve further training of the classifiers and can be applied to any ECOC ensemble."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mobil cihazlarda kullanılan yazılımlar otonom olmalı ve kendilerini yapılandırmak gibi elzem kararları verebilmelidirler. Ayrıca, mobil platformlarda veri madenciliğinin çeşitli uygulamalarda daha akıllı kararlar almaları doğrultusunda kullanılmaları önemlidir. Dolayısıyla, mobil cihazlarda veri madenciliğinin de otonom olması gereklidir. Bu tezde, mobil cihazlarda veri madenciliği algoritmalarını otomatik olarak yapılandırma konusunu ele aldık. Sunulan çözümde, konfigürasyon önerileri üretilirken cihazın kaynaklarının kullanımı ve cihazın kullanıldığı bağlam göz önüne alınmıştır çünkü mobil cihazların kullanıldıkları bağlam sıkça değişmektedir ve cihazın kaynakları da genellikle kısıtlıdır. Veri madenciliği algoritmasının önceki çalıştırılışlarından işleyiş modelinin çıkarılarak yapılandırılmasında kullanılmasını önermekteyiz. Bu amaçla iki farklı yöntem denenmiştir: Bayesian network ve decision tree classifier.Bayesian network kullanarak, cihazın kaynaklarının durumu, hangi bağlamda kullanıldığı ile veri madenciliği yapılandırma değerleri ve elde edilen performans arasındaki ilişki olasılıksal olarak gösterilmiştir. Bu bilgiye dayanarak, veri madenciliği uygulamasının ilerki çalıştırılışlarında mevcut duruma uygun yapılandırma kararları çıkarılmaktadır.Veri madenciliği algoritmasının işleyiş modelini çıkarmakta kullandığımız diğer yöntem ise decision tree classifier'dır. Cihaz kaynaklarının kullanım durumları ve cihazın hangi bağlamda kullanıldığı ile algoritma yapılandırmasının elde edilen veri modeli kalitesine etkisi decision tree yöntemiyle sınıflandırma yapılarak araştırılmıştır. Veri modeli kalitesi hiyerarşik olarak sınıflandırılmak suretiyle elde edilen olası veri madenciliği algoritması işleyiş modellerinden en yüksek tahmin doğruluğuna sahip olup aynı zamanda en özgül sınıflandırma yapan modeli seçmek için bir yöntem önerilmistir.Mobil cihazlarda çalışacak bir veri madenciliği algoritması işleyiş modelini oluşturan unsurlar tanımlanmış, yöntem association rule mining algoritması için örneklenmiş ve yöntemin kullanılabilirliği deneysel olarak gösterilmiştir.","Ubiquitous computing software needs to be autonomous so that essential decisions such as how to configure its particular execution are self-determined. Moreover, data mining serves an important role for ubiquitous computing by providing intelligence to several types of ubiquitous computing applications. Thus, automating ubiquitous data mining is also crucial. We focus on the problem of automatically configuring the execution of a ubiquitous data mining algorithm. In our solution, we generate configuration decisions in a resource-aware and context-aware manner. We propose to analyze the execution behavior of the data mining algorithm by mining its past executions. In order to extract the behavior model from algorithm's executions, we make use of two different data mining methods which are Bayesian network and decision tree classifier.Bayesian network is constructed in order to represent the probabilistic relationships among device's resource usage, context, algorithm parameter settings and the performance of data mining.Other data mining method that has been used is the decision tree classifier. The effects of resource and context states as well as parameter settings on the data mining quality are discovered through decision tree classifier. In this approach, a taxonomy is defined on data mining quality so that tradeoff between prediction accuracy and classification specificity of each behavior model that classifies by a different abstraction of quality, is scored for model selection.We formally define the behavior model constituents, instantiate the approach for association rules and validate the feasibility of the two of the approaches by the experimentation."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz Duyarga Ağları (KDA), duyarga düğümü adı verilen ve enerji kaynakları kısıtlı olan küçük aygıtlardan oluşur. Bu düğümler genellikle ağ ömrünün duyarga düğümünün pil ömründen çok daha fazla olduğu ortamlarda konuşlandırılırlar. Dolayısıyla KDA'lar yerel ve genel bağlantı oranlarını sabit bir değerde tutmak için ortama sürekli yeni düğümlerin konuşlandırıldığı çok fazlı bir biçimde çalışmaktadırlar. Bunun yanısıra, literatürdeki araştırmaların önemli bir kısmı statik KDAlar üzerine yapılan çalışmaları içerirken, duyarga düğümlerinin mobil olması durumunu değerlendiren çok kısıtlı çalışma bulunmaktadır. Bu tezde, mobil ve çok fazlı KDAlarda kullanılmak üzere tasarlanmış, sürekli ve geçici düğüm ele geçirme saldırılarına karşı dayanıklı bir anahtar ön dağıtım şeması sunulmaktadır. Önerilen Özet Çizgesi Tabanlı (ÖÇT) şemada, bütün nesillerin kendilerine ait bir anahtar havuzu bulunmaktadır. Bu havuzlar önceki neslin anahtar havuzu kullanılarak üretilmekte, ve bu sayede farklı nesillerde konuşlandırılan düğümler birbirleriyle iletişim kurma imkanı bulmaktadırlar. Ayrıca, ele geçirilen bir düğüm sadece kısıtlı bir sayıdaki ardışık nesillerin anahtar havuzlarından ufak bir miktarda anahtarı ifşa etmektedir. Önerilen şema ile iyi bilinen bir şema arasında karşılaştırmalı analizler gerçekleştirilmiş ve saldırı oranı düşük olduğu durumda önerilen şemanın çok daha iyi dayanıklılık performansı sergilendiği gözlemlenmiştir. Saldırı oranı artırıldığında da, karşılaştırılan şemadan daha az anahtar kullanarak aynı yerel bağlantı oranı yakalandığı gözlenmiş ve yine daha iyi oranda dayanıklılık performansı görülmüştür.","Wireless Sensor Networks (WSN) consist of small sensor nodes which operate until their energy reserve is depleted. These nodes are generally deployed to the environments where network lifespan is much longer than the lifetime of a node. Therefore, WSN are typically operated in a multiphase fashion, where new nodes are periodically deployed to the environment to ensure constant local and global network connectivity. Besides, significant amount of the research in the literature studies only static WSN and there is very limited work considering mobility of the sensor nodes. In this thesis, we present a key predistribution scheme for mobile and multiphase WSN which is resilient against eager and temporary node capture attacks. In our Hash Graph based (HaG) scheme, every generation has its own key pool which is generated using the key pool of the previous generation. This allows nodes deployed at different generations to have the ability to establish secure channels. Likewise, a captured node can only be used to obtain keys for a limited amount of successive generations. We also consider sensor nodes as mobile and use different mobility models to show its effects on the performance. We compare the connectivity and resiliency performance of our scheme with a well-known multiphase key predistribution scheme and show that our scheme performs better when the attack rate is low. When the attack rate increases, our scheme still has better resiliency performance considering that it requires less key ring size compared to a state-of-the-art multiphase scheme."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Duygu analizi, verilen bir metnin hissiyatını pozitif, negatif veya objektif olarak otomatik bir biçimde tahmin etmeyi, aynı zamanda da bu hissiyatın derecesini belirlemeyi amaçlar. Her bir kelimenin ne kadar pozitif, ne kadar negatif olduğunu gösteren veri sözlükleri birçok duygu analizi yönteminin de temelini oluşturur. Üzerinde çalışılan bağlama-özel veri sözlüklerini oluşturmak ciddi biçimde zaman alan bir süreç olduğu için, araştırmacılar sıklıkla bağlam-bağımsız veri sözlüklerini tercih ediyorlar. Biz bu çalışmamızda, hissiyat analizinin iki alt problemine çözüm getirmeye çalışıyoruz. Öncelikle, bağlam-bağımsız veri sözlüğü değerlerini temel alan bir yöntemle yeni makine öğrenimi özellikleri öneriyoruz. Bunları cümlelerin uzunluğunu, cümle içindeki kelimelerin ne kadar tek tipte olduğunu (hepsi pozitif ya da hepsi negatif), cümlenin subjektifliğini, dilek kipi içerip içermediğini ve cümlenin verilen metin içindeki yeri gibi farklı özellikleri de hesaba katarak yapıyoruz. Bu analizi verilen metnin genel hissiyatıyla ilgili daha fazla bilgi taşıyan cümleleri bulmak için kullanıyoruz. Bu nedenle, yaptığımız bu çalışma diğer çalışmalardan farklı olarak cümle temelli duygu analizi üzerine yoğunlaşıyor. Ayrıca, bu yapılandırdığımız sistemin duygu analizi konusunda ne kadar başarılı olduğunu değerlendirebilmek için sistemi iki farklı bağlam üzerinde çalıştırıp, sonuçları karşılaştırıyoruz.","Sentiment analysis aims to automatically estimate the sentiment in a given text as positive, objective or negative, possibly together with the strength of the sentiment. Polarity lexicons that indicate how positive or negative each term is, are often used as the basis of many sentiment analysis approaches. Domain-specific polarity lexicons are expensive and time-consuming to build; hence, researchers often use a general purpose or domain-independent lexicon as the basis of their analysis. In this work, we address two sub-tasks in sentiment analysis. We introduce a simple method to adapt a general purpose polarity lexicon to a specific domain. Subsequently, we propose new features to be used in a term polarity based approach to sentiment analysis. We consider different aspects of sentences, such as length, purity, irrealis content, subjectivity, and position within the opinionated text. This analysis is used to find sentences that may convey better information about the overall review polarity. Therefore, our work is also focused on the sentence-based sentiment analysis differently from the other works. Moreover, we worked on two distinct domains, hotel and Twitter with three different systems which are compared with the existing state-of-the-art approaches in the literature."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyolojik motiflerin keşfi biyoinformatik için önemli problemlerden biridir. Bu tür motifler, dizilerin sınıflandırılması, veri madenciliği ve rasyonel protein mühendisliği gibi amaçlarla kullanılabilir. Bu tez, proteinlerin dizi ve yapısal özelliklerinden ayrımcı motiflerin bulunması ve makine öğrenimi yöntemlerinin araştırma ve geliştirilmesinde kullanılmak üzere daha iyi bir temel oluşturma amacı barındırmaktadır. Bu tez, çeşitli biyolojik problemlere uygulanabilirliği olan makine öğrenim yapı blokları önermektedir. Öğrenim algoritmalarının girdisi ideal olarak yalnızca biyolojik veri örneklemleri ve bu örneklerin ait olduğu sınıf verileri olmalıdır. Bu girdiye denk gelen çıktı ise bu sınıfları ayıran faktör ve motifler olmalıdır (rastgele olmayan, makul sınıf tanımları için). Bu ideal iş akışı iki ana adıma ihtiyaç duyar. Birinci adım, biyolojik örneklerin araştırma için önem arz eden özelliklerle temsil edilmesidir. Makromoleküller kompleks üç boyutlu yapılar olduğu için, bu komplike gösterimin soyutlaştırılarak makine öğrenimi ve motif keşfi için kullanmaya daha uygun sayısal ve simgesel temsillere dönüştürülmesi gerekmektedir. İkinci adım ise bu temsili gösterimler üzerinde kullanılmaya uygun motif keşfi ve makine öğrenimi algoritmalarının geliştirilmesidir. Bir algoritma ilk adımda çıkartılan tanıtıcı temsilleri kullanalarak sınıflandırıcı ve ayırt edici motifleri keşfedebilmelidir. Bu çalışma ile çeşitli makine öğrenimi yöntemlerinde kullanılmak üzere bir çok yeni protein temsil yöntemleri; ve bu temsil sistemleri ile çalışmak üzere iki ayrı motif keşif yöntemi (zamana bağlı motif madenciliği ve derin öğrenim temelli motif keşfi) geliştirilmiştir. Bu temsil ve öğrenim algoritmaları yaşam bilimlerinde karşılaşılan çeşitli hesaplamalı problemlere uygulanmıştır.","Finding recurring motifs is an important problem in bioinformatics. Such motifs can be used for any number of problems including sequence classification, label prediction, knowledge discovery and biological engineering of proteins fit for a specific purpose. Our motivation is to create a better foundation for the research and development of novel motif mining and machine learning methods that can extract class-specific and discriminative motifs using both sequence and structural features.We propose the building blocks of a general machine learning framework to act on a biological input. This thesis present a combination of elements that are aimed to be applicable to a variety of biological problems. Ideally, the learner should only require a number of biological data instances as input that are classified into a number of different classes as defined by the researchers. The output should be the factors and motifs that discriminate between those classes (for reasonable, non-random class definitions). This ideal workflow requires two main steps. First step is the representation of the biological input with features that contain the significant information the researcher is looking for. Due to the complexity of the macromolecules, abstract representations are required to convert the real world representation into quantifiable descriptors that are suitable for motif mining and machine learning. The second step of the proposed workflow is the motif mining and knowledge discovery step. Using these informative representations, an algorithm should be able to find discriminative, class-specific motifs that are over-represented in one class and under-represented in the other.This thesis presents novel procedures for representation of the proteins to be used in a variety of machine learning algorithms, and two separate motif mining algorithms, one based on temporal motif mining, and the other on deep learning, that can work with the given biological data. The descriptors and the learners are applied to a wide range of computational problems encountered in life sciences."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez Artırılmış Gerçeklik (AG) ortamında sahne yaratılması ve incelenmesi konularını, özellikle açıkhava ortamında araştırma amacını güder. Bu amaçla AG sahneleri üç temel bileşende incelenip; a) Cihaz, b) Hedef Obje(ler), c) Görev, ve bu maddelerin kendi içlerindeki ilişkileri tartışılmıştır. Bu ilişkiler doğrultusunda kullanım senaryoları ve iş akışları tanımlanmıştır. Tezin literatüre ana katkısı, profesyonel çalışmalara odaklı olarak sağlanan açıkhava AG iş akışları ve bu iş akışlarının sahne bileşenleriye olan ilişkilerinin incelenmesinden kaynaklıdır. Diğer katkı noktaları ise şöyle sıralanabilir: i)Sahne bileşenlerinin içsel hatalarının tespit edilmesi ve incelenmesi. Bu inceleme doğrultusunda ortaya çıkan, sahnedeki hedefleri takip etmeye yarayan, geçişlere uygun şekilde hazırlanmış, melez bir izleme methodu. ii)Resim tabanlı, blokların birbirne bağlanması ile işleyen bir tekniğin modelleme amacıyla tanıtılması. Ayrıca, sahnelere eklenen bilgi notlarının, hacimsel ve zamansal olarak da incelenmesi ve uyarlanması. iii)Güncel X-Işını görsel-leştirme tekniklerinin deneysel bir metod ile karşılıklı incelenmesiyle çıkan sonuçlar ve bu sonuçlar doğrultusunda tasarlanan çok yüzeyli yeni bir görselleştirme tekniği. AG teknolojisi ve getirileri hızlı bir şekilde değişmekte olsa bile, sahne bileşenlerinin kendileriyle ve kullanıcıyla olan ilişkisinin incelenmesinden doğan pratik getirilerin değerli ve kalıcı olduğu kesindir. Bu tez içerisinde yer alan fikir ve çalışmaların şu çeşitli alanlara da uyarlanabileceğini düşünmekteyiz: Arkeoloji, mimari, kültürel miras, turizm, stratigrafi, inşaat ve şehircilik.","This thesis investigates Outdoor Augmented Reality (AR) especially for scene creation and exploration aspects. We decompose a scene into several components: a) Device, b) Target Object(s), c) Task, and discuss their interrelations. Based on those relations we outline use-cases and workflows. The main contribution of this thesis is providing AR oriented workflows for selected professional fields specifically for scene creation and exploration purposes, through case studies as well as analyzing the relations between AR scene components. Our contributions inlude, but not limited to: i) analysis of scene components and factoring inherintly available errors, to create a transitional hybrid tracking scheme for multiple targets, ii) a novel image-based approach that uses building block analogy for modelling and introduces volumetric and temporal labeling for annotations, iii) an evaluation of the state of the art X-Ray visualization methods as well as our proposed multi-view method. AR technology and capabilities tend to change rapidly, however we believe the relation between scene components and the practical advantages their analysis provide are valuable. Moreover, we have chosen case studies as diverse as possible in order to cover a wide range of professional field studies. We believe our research is extendible to a variety of field studies for disciplines including but not limited to: Archaeology, architecture, cultural heritage, tourism, stratigraphy, civil engineering, and urban maintenance."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, robotik rehabilitasyon terapilerinde hastanın görevine aktif katılımını arttırmak için, beyin ve bilgisayar arasında doğrudan iletişim sağlayan beyin-bilgisayar arayüzleri (BBA)'nin etkisini araştırdık. Robotik rehabilitasyon deneyleri bağlamında, hayali kol hareketleri hakkında bilgi elde etmek için kullanılan elektroensefalografi (EEG) tabanlı BBA sistemleri ile çeşitli deneysel paradigmalar tasarladık. Özellikle, gönüllünün istek düzeyi bilgisini elde eden ve bu bilgiyi rehabilitasyon deneyi sırasında robotu sürekli olarak kontrol etmek için kullanan bir protokol öneriyoruz. Bu bağlamda, çevrimiçi ve çevrimdışı karar verebilmek için EEG sinyalini işleme, öğrenme ve sınıflandırma algoritmaları geliştirdik ve uygulamaya koyduk. Robotik sistem üzerinde farklı kontrol yöntemleri kullandık ve rehabilitasyon süreci hakkında EEG'de yer alan bilgiyi, BBA'nın rehabilitasyona ve robotik dokunsal geribildirimin de BBA'ya olan etkisini inceledik. Sonuçlarımız robot hareket yoluyla yapılan dokunsal geribildirim kullanımının BBA performansını arttırdığını doğruluyor. Deneyde sürekli olarak BBA kullanımının, sadece robotik hareketi tetiklemek yerine tercih edilebilir olduğunu da görüyoruz. Son olarak, sonuçlarımız, BBA tabanlı deneylerde hareketin gönüllü katılımı olmadan robot tarafından yapıldığı geleneksel deneylere göre daha güçlü hayali motor etkinliği olduğunu göstermektedir.","In this thesis, we have investigated the e ect of brain-computer interfaces (BCI)which enable direct communication between a brain and a computer, to increase the patient's active involvement to his/her task in the robotic rehabilitation therapy. We have designed several experimental paradigms using electroencephalography (EEG)based BCIs which can be used to extract information about arm movement imagery in the context of robotic rehabilitation experiments. In particular, we propose a protocol that extracts and uses information about the level of intention of the subject to control the robot continuously throughout a rehabilitation experiment. In this context we have developed and implemented EEG signal processing, learning and classi cation algorithms for oine and online decision-making. We have used di erent types of controlling methods over the robotic system and examined the potential impact of BCI on rehabilitation, the e ect of robotic haptic feedback on BCI, and information contained in EEG about the rehabilitation process. Our results verify that the use of haptic feedback through robotic movement improves BCI performance. We also observe that using BCI continuously in the experiment rather than only to trigger robotic movement may be preferable. Finally, our results indicate stronger motor imagery activity in BCI-based experiments over conventional experiments in which movement is performed by the robot without the subject's involvement."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telsiz Duyarga Ağları (TDA), duyarga düğümleri olarak adlandırılan küçük ve pil gücü ile çalışan cihazlardan oluşur. Duyarga düğümleri, algılama, veri işleme ve iletişim yeteneklerini kullanarak çevreyi gözlemler ve veri toplarlar. TDA'ların, askeri taramadan orman yangını tespitine kadar çok çeşitli uygulama alanları bulunmaktadır. Bu uygulamalarda duyarga düğümleri genel olarak gözetimsiz ve kontrolden uzak alanlara bırakılırlar. Bu sebeple, düğümler fiziksel anlamda ele geçirilmeye müsaittirler. Ayrıca ağdaki bağlantılar bir saldırgan tarafından kolaylıkla dinlenebilir. Bu yüzden, TDA'larda ağ güvenliğini sağlamak önemli bir sorun haline gelmiştir. TDA'larda güvenlik sorununu çözmek için bir çok ön yüklemeli anahtar dağıtım şeması önerilmiştir. Fakat, bu şemaların çoğu duyarga düğümlerinin durağan olduğunu varsayar ve Mobil Telsiz Duyarga Ağlarına (MTDA) uygulandıklarında yetersiz kalırlar. Bu tezde, MTDA'lar için Dinamik Anahtar Halkası Güncelleme (DAHG) mekanizması sunulmaktadır. Bu mekanizmanın amacı, duyarga düğümlerinin hareketleri sırasında komşularında sıklıkla bulunan anahtarları gözlemleyerek, kendi anahtar halkalarını periyodik olarak güncellemeleridir. Mekanizmamız farklı ön yüklemeli anahtar dağıtım şemaları ile birlikte kullanılabilir ve bu şemaların performansının arttırılmasına yardımcı olur. Performans değerlendirmelerinde mekanizmamız, bir rastgele ön yüklemeli anahtar dağıtım şeması, bir de konuma dayalı ön yüklemeli anahtar dağıtım şeması olmak üzere iki farklı şemayı temel alacak şekilde kullanılmıştır. Her iki ön yüklemeli anahtar dağıtım şeması için ayrıca iki farklı mobilite modeli ile analizler yapılmıştır. Değerlendirme sonuçlarımız, DAHG mekanizmasının her durumda ağdaki yerel ve genel bağlantı oranlarını arttırdığını göstermiştir. Ayrıca mekanizmamız ölçeklendirilebilir olup, ağ dayanıklılığına zarar vermez ve düşük bir ek iletişim maliyeti gerektirir.","Wireless Sensor Networks (WSNs) are composed of small, battery-powered devices called sensor nodes. Sensor nodes have sensing, processing and communication capabilities to monitor the environment and gather data. WSNs have various application areas ranging from military surveillance to forest fire detection. Security is an important issue for Wireless Sensor Networks because sensor nodes are deployed in hostile and unattended areas. Nodes are vulnerable to physical capture attacks and the attackers can easily eavesdrop on network communications. To provide security to WSNs, many key predistribution schemes have been proposed. However, most of these schemes consider the static WSNs and they perform poorly when they are applied to Mobile Wireless Sensor Networks (MWSNs). In this thesis, we propose Dynamic Keyring Update (DKRU) mechanism for MWSNs. The aim of DKRU mechanism is to enable sensor nodes to update their keyrings periodically during movement, by observing the frequent keys in their neighbors. Our mechanism can be used together with different key predistribution schemes and it helps to increase the performance of them. For performance evaluation reasons, we used our mechanism together with an existing random key predistribution scheme and a location-based key predistribution scheme. For each of these key predistribution schemes, we analyzed our mechanism using two different mobility models. Our results show that DKRU mechanism increases the local and global connectivity when it is applied to MWSNs. Moreover, our mechanism is scalable and it does not cause significant degradation in network resiliency and communication overhead."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Fizik tabanlı simülasyonlar ile üretilen akış alanları, çok-değişkenli uzam-zamansal verilerin alt kümesi olup, bu verilerden sıvı davranışlarını yorumlamayı sağlayan görsellerin çıkarılması veri karmaşıklığından dolayı zordur. Bu tez içerisinde, vektör akış alanlarıın görselleştirme ve analizine yardımcı olmak üzere, Bilgi Kuramı'ndan faydalanılarak entropi haritaları çıkarılmaktadır. Ana katkı olarak, her örneklem penceresi için Temel Bileşen Analizi ile bulunan, polar koordinat düzleminde en yüksek yönsel varyasyonu veren projeksiyon kullanılarak yansıtılmış 3 boyutlu vektör alanlarının histogramları hesaplanmış ve geleneksel metotlardan daha az hatayla sonuçlar elde edilmiştir. Entropi haritaları üretilmesi için önerilen metodun değerlendirilmesi için, entropi rehberliğinde farklı veri setlerinin görselleştirilmesi sunulmuştur. Oluşturulan imgelerde yüksek entropili alanlar ve uyumlu yönsel bileşenler karışıklığa yol açmadan görünür haldedir. Araştırma amaçlı hazır veri setlerine ek olarak, geliştirilen Yumuşatılmış Parçacık Hidrodinamiği (YPH) simülasyon altyapısı ile üretilmiş akış alanları da kullanılmıştır. YPH akışkan simülasyonları için yaygın olarak kullanılan bir metot olup, doğrudan görselleştirme teknikleri ile yorumlanması zor veri setleri oluşturmaktadır. Sıvı içerisinde batmakta olan parçacık davranışına yakınsama hesabında faydalı olduğu bilinen kesirli türevler kullanılarak, YBH uygulamasının performans ve kararlığını artıran iyileştirme de sunulmaktadır.","Flow fields produced by physically based simulations are subsets of multivariate spatiotemporal data, and have been in interest of many researchers for visualization, since the data complexity makes it difficult to extract representative views for the interpretation of fluid behavior. In this thesis, we utilize Information Theory to find entropy maps for vector flow fields, and use entropy maps to aid visualization and analysis of the flow fields. Our major contribution is to use Principal Component Analyses (PCA) to find a projection that has the maximal directional variation in polar coordinates for each sampling window in order to generate histograms according to the projected 3D vector field, producing results with fewer artifacts than the traditional methods. Entropy guided visualization of different data sets are presented to evaluate proposed method for the generation of entropy maps. High entropy regions and coherent directional components of the flow fields are visible without cluttering to reveal fluid behavior in rendered images. In addition to using data sets those are available for research purposes, we have developed a fluid simulation framework using Smoothed Particle Hydrodynamics (SPH) to produce flow fields. SPH is a widely used method for fluid simulations, and used to generate data sets that are difficult to interpret with direct visualization techniques. A moderate improvement for the performance and stability of SPH implementations is also proposed with the use of fractional derivatives, which are known to be useful for approximating particle behavior immersed in fluids."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsanlar Twitter üzerinde bilgi ve fikir paylaşırlarken, araştırmacılar ve politika belirleyiciler de çeşitli olaylara karşı toplumsal algıyı öğrenmek isterler. Bu amacı gerçekleştirmenin bir yolu da tweetlerin etkisini ölçmektir. Bu tez içerisinde 3 tane araştırma konusunu cevaplamaya çalıştık: (1) ""Bir tweetin etkisi nasıl tanımlanır?"", (2) ""Tweetlerin ve konuların etkisini nasıl ölçeriz?"", (3) ""Tweetlerin ve konuların etkisini önceden tahmin edebilir miyiz?"". Bu sorulara cevap bulabilmek için öncelikle retweetlerin tweet etkisi üzerindeki önemini vurguluyoruz. Sonrasında bir tweetin yüksek sayıda retweet alıp almayacağını tahmin edebilmek için bir öğrenim modeli hazırladık. Bunun dışında kıvrımsal sinir ağlarını kullanarak tweetlerden içerik bazında bazı özellikler de çıkardık. Tweetlerin gerçek etkisini daha doğru bir şekilde ölçebilmek adına ""gizli retweetler"" kavramını tanımladık. İnsanlar var olan tweetleri yeniden gönderirlerken tweetin başına ya da sonuna bazı yorumlar ekleyebiliyorlar. Bunun dışında bilerek ya da bilmeyerek başka insanlarla tamamen aynı ya da çok benzer tweetleri yazabiliyorlar. Bu yüzden gizli retweetlerin incelenmesi tweetlerin gerçek etkisini ölçmek için son derece önemlidir. Bununla beraber gizli retweetlerin bulunması ve sayılarının tam olarak belirlenmesi çok pahalı bir işlemdir. Ağaç bazlı yapılarla ve lokal duyarlılık adresleme tekniğiyle geliştirdiğimiz karakter bazlı kümeleme yöntemlerinin bu pahalı işlemi çok etkili bir şekilde tamamlayabildiğini gösterdik. Tweetlerin arasındaki uzaklığı karakter bazlı metriklerle ölçen çeşitli kümeleme yöntemleri geliştirdik ve bunları deneysel olarak değerlendirdik. En uzun ortak altdizi yöntemi tweet gibi kısa metin dokümanları arasındaki benzerliği ölçmek için çok kullanılan bir yöntemdir. Ancak bu yöntem bir o kadar da pahalıdır. Bu sebeple en uzun altdizgi bazlı genelleştirilmiş son ek ağaçlarından faydalandık. Ayrıca yoğunluk bazlı kümeleme algoritması geliştirdik; sonrasında bu algoritmayı genelleştirilmiş son ek ağaçları ve lokal duyarlılık adresleme yöntemini kullanarak bu algoritmayı hızlandırdık.","People tend to spread information and share their ideas in Twitter, while researchers and policy makers would like to understand public opinion and reactions of people in Twitter towards various events. One way to do that is assessing and predicting the impact of tweets. In this thesis, we tried to answer three questions: (1) ""What does impact of a tweet mean?"", (2) ""How do we measure the impact of tweets or topics?"", and (3) ""Can we predict the impact of tweets or topics?"". In order to address these questions, we first emphasize the role of retweets and their importance in impact assessment. We then show that we can build a model through supervised learning to predict if a tweet will get a high number of retweets. We extracted various features from tweets including content based features through Convolutional Neural Networks (CNN). In order to have a more accurate impact assessment, we introduced the concept of hidden retweets. People tend to re-post tweets by adding some extra comments to the beginning or to the end of original tweet. Also they intentionally or unintentionally post the exact or near exact tweets with other people without explicitly retweeting them. Therefore hidden retweets are quite important for measuring the real impact of tweets. However, it is also computationally expensive to identify and count the number of hidden retweets. We show that aggregating hidden retweets can be done efficiently through a lexical similarity based clustering algorithm enhanced with a tree structured index and locality sensitive hashing. We adopted a document clustering based approach for discovering the hidden retweets. We developed and evaluated several clustering algorithms with lexical similarity as the distance measure between tweets. Longest Common Subsequence (LCS) is a widely accepted method to calculate the lexical similarity between short text documents such as tweets, but it is also very expensive. Therefore, we utilized an advanced data structure which is Generalized Suffix Tree (GST) based on Longest Common Substring which is an approximation of LCS. We, then developed a density based clustering approach based for tweet clustering and improved its performance by integrating GST and Locality Sensitive Hashing."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sinirsel morfoloji ve fonksiyon birbiriyle oldukça ilintilidir. Özellikle dendritik diken morfolojisi güçlü bir şekilde gelen sinirsel aktivite ile yönetilir. Önceki çalışmalarda dendritik dikenlerin hacminin diken morfolojisini incelemek ve yapı-fonksiyon ilişkisini anlamak için temel parametre olduğu düşünülüyordu. Fakat bu indirgemeci yaklaşım dikenlerin kapsamlı yapı dağarcığını içermemektedir. Zengin diken morfoloji bilgisini fonksiyonel eşleşmeyle bütünleştirmenin ilk adımı, diken şekillerinin literatürde önerilen temel şekil sınıflarına göre sınıflandırılmasıdır. Yeterli seviyede güvenilir otomatik analiz araçlarının olmaması nedeniyle sınıflandırma işlemi elle yapılmaktadır. Bu da analizin öznel ve zaman isteyen bir işlem olmasına yol açmaktadır. Otomatik diken şekil analiz araçları bu işlemi hızlandırarak sinirbilimcilerin altta yatan yapı ve fonksiyon ilişkisini anlamasına yardımcı olacaktır. Literatürde diken şekil sınıflandırması ile ilgili birçok çalışma yer almaktadır. Fakat diken şekillerinin ayrı sınıflar halinde mi yoksa bir şekil değişim süreci olarak mı ele alınması gerektiği konusunda bir fikir birliğine varılmamıştır. Bu problemde karşımıza çıkan bir diğer güçlük sınıflandırma yaklaşımlarının güdümlü yapısının getirdiği öznellik ve yanlılıktır. Bu tez, hem kümeleme hem de sınıflandırma yaklaşımlarını morfolojik, şekil ve görüntü öznitelikleriyle kullanarak dendritik diken şekil analizi gerçekleştirme üzerine kurulmuştur. Dendritik diken sınıflandırma problemine çok katlı (manifold) öğrenme yöntemlerini uyguladığımızda ISOMAP'in dolaylı olarak sınıflandırma için önemli öznitelikleri hesapladığını gözlemledik. Sınıflandırma amacıyla doğrusal temsil yaklaşımına başvurduğumuzda seyrek temsilin kısmen daha iyi bir sınıflandırma performansı sağladığını gördük. 2 boyutlu ve 3 boyutlu morfolojik özniteliklere dayalı diken şekil analizi yaklaşımında 3 boyutlu morfolojik özniteliklerin sağladığı avantajları gösterdik. Derin öğrenmeye dayanan sınıflandırma yaklaşımında Konvolüsyonel Sinir Ağlarından (CNNs) çıkarılan orta seviye özniteliklerin özel çıkarılmış öznitelikler kadar iyi performans gösterdiğine şahit olduk. Dendritik diken sınıflandırması için çekirdek yoğunluk tahminine (KDE) bağlı bir çerçeve tasarladık. Önerdiğimiz yaklaşımları sinirbilimci bir uzmanın belirlediği etiketlerle karşılaştırdık. Çekirdek yoğunluk tahminine bağlı çerçeve sinirbilimcilerin dikenlerin şekil sınıflarının ayrılabilirliğini olabilirlik oranı uzayında incelemelerine olanak vererek şekil analiz problemine daha derinden bakabilmelerini sağlayabilir. Bunlara ek olarak diken şekillerini güdümsüz öğrenme ve kümeleme yöntemleri üzerinde çalışmalar yaptık. Bayes bilgi kıstasını kullanarak küme sayısını veriden otomatik seçen x-ortalama (x-means) tekniğini kullandık. Bu bağlamda kümelemenin iki farklı amaçla kullanılmasından söz edilebilir: ayrı şekil sınıflarının varlığına dair hipotezi doğrulamak ve yeni gruplar keşfetmek. Elimizdeki veride çok sayıda diken standart şekil sınıfları içinde değerlendirilebilse de, önemli sayıda dikenin bu sınıflara uymadığını ve ara niteliklere sahip olduğunu gözlemledik.","Neuronal morphology and function are highly coupled. In particular, dendritic spine morphology is strongly governed by the incoming neuronal activity. Previously, volumes of dendritic spines have been considered as a primary parameter to study spine morphology and gain insight into structure-function coupling. However, this reductionist approach fails to incorporate the broad spine structure repertoire. First step towards integrating the rich spine morphology information into functional coupling is to classify spine shapes into main spine types suggested in the literature. Due to the lack of reliable automated analysis tools, classification is currently performed manually, which is a time-intensive task and prone to subjectivity. Availability of automated spine shape analysis tools can accelerate this process and help neuroscientists understand underlying structure and function relationship. Several studies on spine shape classification have been reported in the literature, however, there is an on-going debate on whether distinct spine shape classes exist or whether spines should be modeled through a continuum of shape variations. Another challenge is the subjectivity and bias that is introduced due to the supervised nature of classification approaches. This thesis focuses on morphological, shape, and appearance features based methods to perform dendritic spine shape analysis using both clustering and classification approaches. We apply manifold learning methods for dendritic spine classification and observe that ISOMAP implicitly computes prominent features suitable for classification purposes. We also apply linear representation based approach for spine classification and conclude that sparse representation provides slightly better classification performance. We propose 2D and 3D morphological features based approach for spine shape analysis and demonstrate the advantage of 3D morphological features. We also use a deep learning based approach for spine classification and show that mid-level features extracted from Convolutional Neural Networks (CNNs) perform as well as hand-crafted features. We propose a kernel density estimation (KDE) based framework for dendritic spine classification. We evaluate our proposed approaches by comparing labels assigned by a neuroscience expert. Our KDE based framework also enables neuroscientists to analyze separability of spine shape classes in the likelihood ratio space, which leads to further insights about the nature of the spine shape analysis problem. Furthermore, we also propose a methodology for unsupervised learning and clustering of spine shapes. In particular, we use x-means to perform cluster analysis that selects the number of clusters automatically using the Bayesian information criterion (BIC). The objective of clustering in this context is two-fold: confirm the hypothesis of some distinct shape classes and discover new natural groups. We observe that although there are many spines which easily fit into the definition of standard shape types (confirming the hypothesis), there are also a significant number of others which do not comply with standard shape types and demonstrate intermediate properties."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hiperspektral Görüntüleme, Uzaktan Algılama araştırmalarında önemli bir yer tutmaktadır. Sınıflandırma haritası oluşturmanın faydaları askeri uygulamalarda, doğal afetlerde ve hatta tarımda uzmanların görsel bilgisine katkı sağlayarak uygulama alanı bulmasını sağlamıştır. Bu tez çalısmasında, sınıflandırma haritası oluşturmak amacıyla, hiperspektral veri kümelerinden, Matematiksel Bicimbilim dalına ait bir yaklaşım olan Öznitelik Profilleri uygulanarak alan ve moment betimleyicileriyle her piksel için öznitelik vektörleri hesaplanmıştır. Veri girdileri, piksele ait spektrum verisi, farklı betimleyicilerden oluşturulan Öznitelik Profilleri ve bunların birleşimini de kapsayacak şekilde hazırlanmıştır. Bu veri girdileri, AlexNet ve GoogLeNet gibi bilinen ağlar ve kendi önerdiğimiz, hiperspektral veri kümelerinde nesnelerin komşuluk bilgisini de göz önüne alan ağlar da dahil olmak üzere beş farklı Evrişimsel Sinir Ağları'nda denenmiş ve derin öznitelikleri çıkarılmıştır. Rasgele Orman sınıflandırıcılarıyla kontrollü olarak yapılan deneylerin sonuçlarında sayısal açıdan Pavia Üniveristesi veri kümmesinde büyük ilerlemeler görülmüş ve oluşturulan sınıflandırma haritalarının daha anlaşılır olması sağlanmıştır. Böylece, alan ve moment betimleyicilerden elde edilen Öznitelik Profilleri ve spektral bilginin Evrişimsel Sinir Ağları ile kullanımının önemi gösterilmiştir.","Hyperspectral Imaging has a large potential for knowledge representation about the real world. Providing a pixel classification algorithm to generate maps with labels has become important in numerous fields since its inception, found use from military surveillance and natural resource observation to crop turnout estimation. In this thesis, within the branch of mathematical morphology, Attribute Profiles (AP) and their extension into the Hyperspectral domain have been used to extract descriptive vectors from each pixel on two hyperspectral datasets. These newly generated feature vectors are then supplied to Convolutional Neural Networks (CNNs), from off-the-shelf AlexNet and GoogLeNet to our proposed networks that would take into account local connectivity of regions, to extract further, higher level abstract features. Bearing in mind that the last layers of CNNs are supplied with softmax classifiers, and using Random Forest (RF) classifiers as a control group for both raw and deeply learned features, experiments are made. The results showed that not only there are significant improvements in numerical results on the Pavia University dataset, but also the classification maps become more robust and more intuitive as different, insightful and compatible attribute profiles are used along with spectral signatures with a CNN that is designed for this purpose."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yirmi yıllık süre içerisinde en çok öne çıkan araştırma alanlarından birisi olan elektroensefalografi (EEG) tabanlı beyin-bilgisayar arayüzü (BBA) teknolojileri, şiddetli nöromusküler engellilikler dolayısıyla içe kilitlenme sendromu yaşayan hastalar için beyin dalgaları aracılığıyla doğrudan bir iletişim kanalı sağlamayı, ve yakın zamanda geliştirilen yaklaşımlar ile felçli hastaların motor tedavi süreçlerini desteklemeyi amaçlamaktadır. Günümüzde genel olarak araştırmalarda kullanılan EEG-tabanlı BBA-destekli felç rehabilitasyonu protokolleri, duyumotor alanlardaki nöral aktivitelerin dokunsal geribeslemesi ile sınırlıdır. Üzerinde durulan bu beyin aktivitelerinin kapsamının, birçok çeşitli beyin ritminin motor yetersizlikler ile ilişkili olduğuna dair çalışmalara dayanarak, bu alandaki daha ileri gelişmelerin gerçekleşmesinde kısıtlayıcı bir etken olabileceği düşünülmektedir. Felç sonrası tedavi sürecinin bir motor öğrenme şekli olarak görülmesi dolayısıyla, motor öğrenmenin duyumotor alanların ötesindeki nöral ilintilerinin tanımlanması ve bu şekilde BBA-destekli felç rehabilitasyonu çalışmalarının günümüzdeki odak noktasının genişletilmesi ileri sürülmektedir. Bu amaçla, sağlıklı bireyler ile eş-zamanlı EEG verisi kaydı altında fiziksel bir kuvvet-alanı adaptasyonu deneyi tasarlayıp uyguladık. Bu tür motor adaptasyon deneyleri, hastaların felç sonrası tedavi süreçlerini temsil eden bir motor öğrenme formunda, insan beyininde motor kabiliyetler için içsel model oluşumlarını tetiklemektedir. Toplanan deneysel veriler ile, motor adaptasyon öğreniminin nöral ilintilerini dinlenme-durumu ve motor hareket-öncesi safhalarında tanımlamayı hedefledik. Bu bağlamda, kinematik öğrenme becerisi ve nöral veriler arasındaki ilişkiyi incelemek için bir sinyal işleme ve makine öğrenme yaklaşımı uyguladık. Hem dinlenme-durumu hem de motor hareket-öncesi EEG verileri ile elde ettiğimiz sonuçlar, duyumotor alanlarını kapsayan ve aynı zamanda onların ötesinde geniş bir ağdaki beyin alanlarının motor adaptasyon öğrenimiyle ilintili olduğunu doğrulamaktadır. Özellikle spektral olarak beta dalgalarının (15-30 Hz) ilişkili olduğu gözlemlenmiştir. Bunun ötesinde, öğrenme ile ilintli beyin aktivitelerinde motor adaptasyon süresince oluşan değişiklikler incelenmiş ve sonuçlarımızın insan motor davranışlarını anlamak amacıyla yürütülen literatürdeki diğer beyin görüntüleme çalışmaları ile tutarlılığı tartışılmıştır. Son olarak, bu sonuçların kullanımı için özgün bir BBA-tabanlı robotik felç rehabilitasyon ortamı önerilmektedir.","Being one of the most prominent research areas over the last two decades, electroencephalogram (EEG) based brain-computer interface (BCI) technology aims to provide direct brain communication for locked-in patients with severe neuromuscular disabilities and support motor restoration in stroke with recently developing approaches. In the context of EEG-based BCI-assisted stroke rehabilitation, we hypothesize that the extent of brain activities considered in state-of-the-art protocols, which are restricted to haptic feedback of neural activity in primary sensorimotor areas, might be a confounding factor for further progress in this field due to empirical evidence on a variety of brain rhythms being related to the extent of motor deficits. As post-stroke recovery is a form of motor learning, we propose to identify neural correlates of motor learning beyond sensorimotor areas to extend the current focus of BCI-assisted stroke rehabilitation. For this purpose, we designed and implemented a physical force-field adaptation learning experiment under simultaneous EEG recordings with healthy individuals, in which post-stroke recovery processes of patients will be likened to a plausible form of motor learning as such motor adaptation tasks are known to induce internal model formations for motor capabilities within the brain. With the experimental data, we aimed to identify neural correlates of motor adaptation learning during resting-state and pre-movement phases prior to motor execution. We implemented a signal processing and machine learning approach to investigate the relation between kinematic learning performance and neural data. Our results on both resting-state and pre-movement EEG data verify that Abstract ii a broad network of brain regions including and beyond sensorimotor areas are involved in motor adaptation learning with spectral relevance of beta oscillations (15{30 Hz) in particular. We further investigated changes in learning-correlated activities during the course of motor adaptation and discussed how our conclusions come into line with previous neuroimaging studies to understand human motor behavior. Finally, we propose to exploit these results in a novel BCI-assisted robotic stroke rehabilitation setting."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan beyni ile bilgisayar dünyası arasında ilave bir kanal oluşturma imkanı sağlayan beyin bilgisayar arayüzleri (BBA) felç, içe kilitlenme sendromu ve amyotrofik lateral skleroz (ALS) gibi hastalık sahiplerine yeni bir umut doğurmuştur. Bilim insanları BBA sistemlerinden hem iletişim, hem rehabilitasyon protokollerinin iyileştirilmesi hem de dış iskeletlerin daha etkin kullanılması anlamında fayda sağlarlar. Sağlıklı insanlar günlük aktivitelerini yerine getirirken uygulanacak kuvvete ve hareketin hızına kendileri karar verirken, dış iskelete bağlı yaşayan insanlar hareket ile ilgili bu özellikleri algılayabildikleri ve gerekli sinyalleri üretebildikleri halde motor hareket sistemine bu özellikleri iletememektedirler. Bu çalışmada elektroensefalografi (EEG) tabanlı bir BBA sistemi ile hareket hızı ve zorluğu tespiti problemleri ele alınmıştır. Bu amaçlarla 2 deney düzeneği hazırlanmış ve kullanıcılar iki farklı deney protokolünü uygularken bu düzenekler üzerinden EEG verileri kaydedilmiştir. Çalışmada toplanılan verinin sınıflandırılabilmesi için birçok metot denenmiş ve bu metotlar avantaj ve dezavantajlarıyla detaylıca incelenmiştir. Ayrıca çalışma normalde tespiti ve değerlendirmesi imkansız olan istek seviyesinin tespiti konusuna hareket zorluğu ve hız seviyesini bu problem üzerinde referans parametresi olarak kullanarak yeni bir soluk getirmiştir. Hastaların günlük moral seviyelerini saptayarak gerekli-olduğu-kadar-yardım protokolünü de iyileştirme amacıyla hazırladığımız bu çalışmada daha zor ya da daha hızlı hareket daha yüksek motivasyonla ve daha yavaş ya da daha kolay görevlerin düşük motivasyonla eşleştirilmiştir. Elde edilen veri setlerinin incelenmesi için birçok sınıflandırma metodu denenmiş ve bu metotların başarı analizleri yapılmıştır. Vargılar sonunda EEG verisinden hareket hızın ve zorluğunu anlamlı yüzdelerle elde etmenin mümkün olduğu gösterilmiştir.","Brain-computer interfaces (BCIs) which provide an alternative channel between human brain and computer world are hope for many patients who suffer from neurological diseases such as ALS and stroke. Scientists benefit from BCIs not only for communication but also for rehabilitation and effective use of robotic exoskeletons. While healthy people can decide the speed level and the amount of force applied for daily activities, stroke patients are not able to transfer their intended movement speed and force magnitude to robotic limbs and mechanical devices. Even though brain signals potentially contain such information about task execution, existing BCI systems do not exploit that information. In this thesis, the possibility of decoding intended human activity speed and task difficulty levels from an electroencephalography (EEG) based BCI system is investigated. In particular, two experimental setups are designed to collect data while subjects are performing two different tasks, and different protocols are proposed with their advantages and drawbacks to extract accurate information from these setups. Moreover, the problem of intention level detection is analyzed in response to task difficulty and speed level. As it is not possible to access the true intention level of a human being to execute a particular task, we use the difficulty and speed of the executed task as proxies for the true intention level and then analyze the corresponding neural correlates. We have applied several classification protocols and our results indicate that some classification protocols are able to detect task speed and difficulty from EEG signals."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Eliptik Eğri Kriptografi (EEK) günümüzde en sık kullanılan Açık Anahtarlı Şifreleme (AAŞ) türlerinden birisidir. Diğer AAŞ türlerine kıyasla EEK'nin kısa anahtar boyu ve daha hızlı ve verimli gerçekleme imkanı vermesi, onu hem endüstriyel hem de akademik çevrelerde popüler hale getirmektedir. Bu tez kapsamında, Galbraith-Lin-Scott (GLS) ailesine mensup eliptik eğriler üzerinde, eliptik eğri nokta çarpımı için, sabit zamanda çalışan bir donanım hızlandırıcı mimarisi tasarımı öneriyoruz. Bu donanım mimarisi, yaklaşık 128-bitlik güvenlik düzeyi sağlayan, n = 127 ile ikinci dereceye genişlemiş GF(2^2n) cebrik cismi için özelleştirilmiştir. Tez kapsamında, GF(2^2n) cebrik cismi üzerinde tanımlanmış GLS eğrileri aritmetiğini gerçekleyen basamak-temelli ve Karatsuba çarpma devreleri üzerinde denemeler gerçekleştirilmiş ve elde edilen alan ve zaman başarımları rapor edilmiştir. Tasarımın XILINX KINTEX-7 Alanda Programlanabilir Kapı Dizileri cihazı üzerinde gerçek donanım gerçeklemesi, bir eliptik eğri nokta çarpım işlemini, 3.98μs saniyede tamamlayabilmektedir. Bu süre, bu tezdeki tasarımın, bu işlem için literatürde rapor edilmiş 128 bit ve 128 bit'e yakın güvenlik düzeylerindeki tüm yazılım ve donanım uygulamalarından daha hızlı çalıştığını göstermektedir.","Elliptic Curve Cryptography (ECC) is one of the most popular public-key cryptosystems (PKC) today. Relatively shorter key lengths used in ECC compared to other popular PKCs and its potential for faster and more effcient implementations, both in software and in hardware, make it popular in industry and academia. In this thesis, we propose a scalar multiplication hardware accelerator that computes a constant-time variable-base point multiplication over the Galbraith-Lin-Scott (GLS) family of binary elliptic curves. Our hardware design is specifically customized for the quadratic extension field F22n; with n = 127; which provides a security level close to 128 bits. We experiment with digit-based and Karatsuba multipliers for performing F2127 arithmetic used in GLS elliptic curves and report the time and area performances obtained by these two classes of multipliers. The real hardware implementation of our design achieves a delay of about 3.98 s for computing one scalar multiplication on a XILINX KINTEX-7 FPGA device. This result clearly demonstrates that the proposed design claims the current speed record for this operation at or around the 128-bit security level for any hardware or software implementation reported in the literature."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyometrik uygulamalarn kullanm alan genişledikçe merkezi veritabanlarında tutulan biyometrik bilgininin mahremiyeti ve olası kötüye kullanım noktasında endişeler artmaktadır. Son yıllarda biyometrik sablon muhafazası konusunda yapılan calışmalar bu problemleri şablonun kendi içinde veya doğrulama mekanizmalarn etkilemeyecek başka bir veri yapsı ile izinsiz kullanım ve çapraz karşılastırma saldırılarına karşı korumaya yönelik çözümleri kapsamaktadr. Bu tez calışmaşında birden fazla biyometrik bilgiyi tek bir sablon üzerinde katmanlayarak bir çoklu biyometrik yapı oluşturma ve bilgilerin karısımından faydanlanarak bu bilgilerin güvenliğinin ve mahremiyetinin korunması amacı ile bir yöntem sunulmaktadır. Bu yöntem kişilerin biyometrik bilgilerini yine ayn kisilerin biyometrik bilgileri ile korumayı amaçlamaktadır ve böylece sadece biyometrik temelli bir çözüm sunmaktadır. Kullanılan yöntem çoklu biyometrik bilgiyi isleyip degerlendirdigi icin geleneksel tek biyometrili yöntemlere göre daha basarlı sonuçlar vermektedir. Sunulan yöntem değistirilebilen biyometrik bilgi ile icra edildigi durumlarda biyometrinin iptal edilebilirliği (yenilenebilirliği) de sağlanmış oluyor. Değistirilebilen biyometrik bilgiye örnek olarak bu çalışmada ses biyometrisi kullanılmaktadır. Kişilerin kendi seslerini kullanarak kendi belirledikleri bir gizli sözcüğü söylemesi ve bu bilginin biyometrik katmana karıştırılması ile olusturulan kayıtlar, ileride kisinin baska bir gizli sözcüğü tercih etmesi neticesinde değistirilebilir, iptal edilebilir ve yenilenebilir olma özelliklerine de kavuşmaktadır.","As biometric applications are gaining popularity, there is increased concern over the loss of privacy and potential misuse of biometric data held in central repositories. Biometric template protection mechanisms suggested in recent years aim to address these issues by securing the biometric data in a template or other structure such that it is suitable for authentication purposes, while being protected against unauthorized access or crosslinking attacks. We propose a biometric authentication framework for enhancing privacy and template security, by layering multiple biometric modalities to construct a multi-biometric template such that it is dicult to extract or separate the individual layers. Thus, the framework uses the subject's own biometric to conceal her biometric data, while it also enjoys the performance bene ts because of the use of multiple modalities. The resulting biometric template is also cancelable if the system is implemented with cancelable biometrics such as voice. We present two di erent realizations of this idea: one combining two di erent ngerprints and another one combining a ngerprint and a spoken passphrase. In either case, both biometric samples are required for successful authentication, leading to increased security, in addition to privacy gains. The performance of the proposed framework is evaluated using the FVC 2000-2002 and NIST ngerprint databases, and the TUBITAK MTRD speaker database. Results show only a small degradation in EER compared to a state-of-the-art ngerprint veri cation system and high identi cation rates, while cross-link rates are low even with very small databases."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tablet bilgisayarlar dokunmatik ekranları sayesinde, klavye ve fare kullanımına kıyasla daha doğal bir etkileşim olanağı sağladıklarından tüketiciler için önemli bir teknoloji haline gelmiştir. Bundan dolayı, özellikle çocuklara yönelik olarak eğitim alanında kullanımları artmaktadır. Bu tezde, el yazısı tanıma teknolojilerine dayalı olarak çalışan 1. sınıflara uygun bir eğitim uygulaması geliştirilmiştir. Geliştirilen uygulama, öğretmenlere öğrencilerin kullandığı ders kitapları üzerinden çevrimiçi çalışma materyalleri üretmelerine olanak sağlamakta, aynı zamanda öğrencinin tamamlanmış ödevinin yanı sıra, zamanlama ve yazma sırası gibi çok çeşitli verileri de öğretmenlere sunmaktadır. Uygulamaya birinci sınıf müfredatına uygun aritmetik ve sözel alıştırmalar yerleştirilmiştir. Bu tez; çocuklar için açık ve anlaşılır bir arayüz tasarlanması, ilkokul eğitimde kullanılan çeşitli soru tiplerine (eşleştirme, aritmetik, Türkçe) denk çalışma materyallerinin hazırlanması, ve hangi uygulamaların tablet platofrmunda en yararlı olacağının belirlenmesi gibi konuları ele alarak bir eğitim uygulamasının tasarlanması ve geliştirilmesi hususunda geniş çaplı bir çalışma gerçekleştirmiştir. Tasarım ve kullanıcı arayüzü ile ilgili hususların yanı sıra, Hidden Markov Modeli'ne dayalı bir tanıyıcının Android platformunda kullanımı ve verilen cevapların doğrulamasının yapılması gibi karmaşık uygulamaların geliştirilmesi ile ilgili teknik çözümler de geliştirilmiştir. İlk tasarımın ardından iki farklı zamanda birinci sınıf öğrencileri ile değerlendirme yapılmış ve uygulamanın tasarımı, halen motor becerileri gelişmekte olan ve yetişkinlere kıyasla teknoloji ile ilgili deneyimleri kısıtlı olan öğrencilere hitap edecek şekilde, aşamalı olarak iyileştirilmiştir.","Tablet computers have become a significant consumer technology by providing a more natural way of interaction via touch sensitive screens, compared to keyboard and mouse input. For this purpose, they are being used increasingly for education purposes, especially aimed for children. In this thesis, an educational application based on handwriting recognition technologies is developed for 1st grade students. The developed application lets teachers prepare online study material directly from text books that students write on and receive back a rich set of information such as timing and writing order, along with a student's completed homework. Arithmetic and linguistic exercises suitable for first grade curriculum are implemented into application. The thesis covers all aspects about designing and developing such an educational application, including: how to design a friendly and straightforward interface for children; how to prepare study material paralleling a variety of question types (matching, arithmetic, Turkish) found in elementary school education; and what applications would be most beneficial on the tablet platform. Besides the design and user interface issues, technical solutions are developed for how to implement sophisticated applications such as a Hidden Markov Model based recognizer on the Android platform, and how to verify answers. After the initial design, assessments are collected from first grade students on two separate occasions and the design of the application was iteratively improved to suit the young students' needs who have still-developing motor skills and lesser experience with technology compared to most adults."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Küçük ölçekli, düşük güçlü ve yalınkat algılayıcılardaki teknolojik ilerlemeler, giyilebilir duyarga düğümlerinin gelişmesine ve dolayısıyla bireylerin çevresinin hatasız bir biçimde gözlemlenebilmesine olanak sağlamıştır. Bunun üzerine, yaygın bilişim gelişmiş ve teknolojiler tak-çalıştır kavramını benimseyen Gövde Alan Ağları'nın (GAA) üretilmesine sebep olacak ölçüde olgunlaşmıştır. GAAlarda bulunan duyarga düğümlerinin başlıca işlevi, hayati önem taşıyan vücut sinyallerini etkin ve verimli bir biçimde toplamak, toplanan bu verileri komşu duyarga düğümleri ile paylaşmak ve gereğince kararlar almaktır. Duyarga düğümleri tarafından algılanan hassas kişisel tıbbi bilgilerin ağ elemanları arasında kablosuz iletişim aracılığıyla aktarılması, hem bu bilgilerin korunması için güvenlik mekanizmalarının geliştirilmesini, hem de ağ elemanları ile ağ kullanıcısı arasında güvenli bağdaştırma sağlanmasını gerektirmektedir. Ancak, duyarga düğümlerinin gerek enerji, gerek bellek, gerekse de bant genişliği kısıtlamaları sebebiyle geleneksel kriptografik yaklaşımların GAAlar için uygun olmadığı sonucuna varılmaktadır. Bu çalışmada, GAAlarda ağ içi iletişim güvenliği için özel olarak tasarlanmış özgün bir güvenlik altyapısı öneriyoruz. Bu bağlamda, küme uzlaştırma problemine dayalı, SKA-PS: Fizyolojik Sinyallerin Kullanıldığı Güvenli Anahtar Mutabakatı Protokolü isimli özgün bir anahtar mutabakatı protokolü öneriyoruz. Söz konusu protokol, kullanıcıların elektrokardiyogram ve kan basıncı gibi fizyolojik sinyallerinden türetilen fizyolojik parametrelerin kullanımı ile simetrik paylaşılan kriptografik anahtarlar üretmektedir. Ayrıca, yine bu çalışmada, kriptografik anahtar olarak kullanılmaya uygun 4 farklı fizyolojik parametre tanımlıyor ve bu parametrelerin nasıl üretildiğini anlatıyoruz. GAAlar için geliştirdiğimiz bu ağ içi iletişim güvenliği altyapısında, (1) ağ elemanları ile ağ kullanıcısı arasında güvenli bağdaştırma sağlanıyor, (2) biyo-kriptografinin performans arttırıcı nitelikleri ön plana çıkarılıyor, (3) düşük hata oranlarına sahip, bit frekanslarına bakan Shannon entropisine göre yeterli ölçüde rasgele ve bit uzaklıklarına bakan Hamming uzaklığına göre yeterli ölçüde bireyler arası ayırt edici fizyolojik parametreler benimseniyor, (4) anahtar mutabakatı protokolü dinamik olarak, önemli bir biçimde yüksek doğru eşleme ve son derece düşük hatalı eşleme oranları ile çalışıyor, ve (5) anahtar mutabakatı protokolü kaba kuvvet, yenileme ve taklit etme saldırılarına karşı dayanıklı olmakla birlikte, düşük iletişim, hesaplama ve bellek maliyetlerine sahip.","Advances in lightweight, small-size and low-power sensors led to the development of wearable biosensors, thus, to the accurate monitoring of human periphery. On top of this, pervasive computing has been improved and technologies have been matured enough to build the plug-and-play Body Area Networks (BANs). In a BAN, the main functionality of a node is to effectively and efficiently collect data from vital body parts, share it with the neighbors and make decisions accordingly. Because of the fact that the captured phenomenon is highly sensitive against privacy breaches in addition to being transmitted using the wireless communication medium, BANs require a security infrastructure. However, due to the extreme energy scarcity, bandwidth and storage constraints of the nodes,conventional solutions are inapplicable for BANs. In this dissertation, we propose a novel security infrastructure that is designed specifically for the intra-BAN communication. In this regard, we propose a novel key agreement protocol, SKA-PS (Secure Key Agreement using Physiological Signals), which is based on the set reconciliation paradigm. Our protocol generates symmetric shared keys using the physiological parameters derived from the physiological signals of the users, such as electrocardiogram and blood pressure. We also identify 4 different appropriate physiological parameters that can be used as cryptographic keys and propose the techniques of generating them. In the security infrastructure that we have developed for the intra-BAN communication, (i) secure node-to-host association is satisfied, (ii) performance enhancing characteristics of bio-cryptography is brought in the foreground, (iii) adopted physiological parameters are random and distinctive enough, based on the Shannon's entropy and Hamming Distance evaluations, which respectively, reveals the bit frequencies and measures the bit differences, along with possessing low error rates, (iv) key agreement protocol works dynamically, possessing remarkably high true match and exceedingly low false match rates, and (v) key agreement protocol resists against brute-force, replay and impersonation attacks, together with possessing low communication, computational and storage costs."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ön-bellek kullanılarak gerçekleştirilen yan-kanal saldırıları giderek artan bir hızla birçok kriptografik yazılım kütüphanesinin zaaflarını ortaya çıkartmaktadır. Kullanılan kriptografik algoritmalar teorik olarak güvenilir olsa da, yazılım olarak gerçeklerken yapılan hatalar nedeniyle, algoritmanın çalışması sırasında beklenmeyen bilgiler dışarıya sızmakta ve bu yolla gizli anahtarlar elde edilebilmektedir. Bu çalışmada ön-bellek kullanılarak gerçekleştirilen yan-kanal saldırılarının gerçek zamanlı olarak tespit edilmesi, önlenmesi ya da sızan hassas/gizli bilgi miktarının en aza indirgenmesi icin önerdiğimiz üç farklı yöntem ele alınacaktır. Bu tez kapsamında yaygın olarak kullanılan OpenSSL yazılım kütüphanesinde gerçeklenmiş üç adet kriptografik algoritmaya karşı geliştirilen saldırılara odaklanacağız: blok şifreleme algoritması AES, RSA ve eliptik eğri elektronik imza (ECDSA) algoritmaları. Geliştirdiğimiz ilk yöntem saldırı yapılan kriptografik algoritmayı çalıştıran prosesi bildiğimizi kabul ederek sistemdeki ilgili prosesleri izlemeyi gerektirmektedir. İzlediğimiz proseslerden elde edilen veriler arasında bir korelasyon bulmaya çalışarak, bir saldırının olup olmadığı, var ise saldırgan prosesin tespit edilmesi hedeflenmektedir. İkinci yöntem, temel olarak ayrık değer bulma ya da anomali tespiti yaklaşıını esas almaktadır. Bu yöntemde saldırgan olmayan proseslerin ve bunların dinamik davranışlarının bilindiği varsayılmaktadır. Saldırgan prosesin dinamik davranışının anomali oluşturduğu kabulüyle, sistemde bir saldırgan prosesin olup olmadığı ve varsa hangisinin olduğunun bulunması amaçlanmaktadır. Önerilen son yöntemde ise, saldırgan prosesin davranışının makina öğrenmesi yöntemleri kullanılarak modellenmesi esas alınmaktadır. Önerilen üç yöntemde de, saldırının gerçekleşmesi için gereken zamanın en fazla beşte biri kadar bir sürede, saldırı başarılı bir şekilde tespit edilebilmektedir. Yapılan deneylerde, hic pozitif yanlış durumu oluşmamıştır. Ayrıca saldırı tespit yöntemlerinin hız açısından sistem başarımındaki olumsuz etkisinin ihmal edilebilecek mertebelerde kaldığı gözlemlenmiştir. Saldırıyı gerçekleştiren prosesin farklı sürümleri kullanılarak saldırı tespit sisteminin başarımı da ölçülmüştür. Geliştirilen saldırı tespit yöntem ve yazılımları, daha da iyileştirilerek gerçek dünya senaryolarında da kullanılabilecek niteliğe sahip hale getirilebilir.","Cache-based side-channel attacks are increasingly exposing the weaknesses of many cryptographic libraries and tools by showing that, even though the algorithms might be considered strong, their implementations often lead to unexpected behaviors that can be exploited to obtain sensitive data, usually encryption keys. In this study we analyze three methods to detect cache-based side-channel attacks in real time, preventing or limiting the amount of leaked information. We focus our efforts on detecting three attacks on the well-known OpenSSL library: one that targets AES, one that targets RSA and one that targets ECDSA. The first method is based on monitoring the involved processes and assumes the victim process is known. By collecting and correlating the monitored data we find out whether there exists an attacker and pinpoint it. The second method uses anomaly detection techniques and assumes the benign processes and their behavior are known. By treating the attacker as a potential anomaly we understand whether an attack is in progress and which process is performing it. The last method is based on employing a neural network, a machine learning technique, to profile the attacker and to be able to recognize when a process that behaves suspiciously like the attacker is running. All the three of them can successfully detect an attack in about one fifth of the time required to complete it. We could not experience the presence of false positives in our test environment and the overhead caused by the detection systems is negligible. We also analyze how the detection systems behave with a modified version of one ofthe spy processes. With some optimization we are confident these systems can be used in real world scenarios."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Rüzgar enerjisi dönüşümü sistemlerinde kontrol tasarımları yüksek performansa ve verimliliğe ulaşmada önemli bir rol oynar. Bu çalışmada, küçük ölçekli dikey eksenli rüzgar türbini için kontrol algoritmaları tasarlamak amacıyla döngüde donanım simülasyonları (DDS) icra edilmiştir. DDSde, rüzgar torku deneysel bir dikey eksenli rüzgar türbininin güç katsayılarından hesaplanarak, gerçek dikey eksenli rüzgar türbini sisteminin dinamiklerini benzeten simülatöründeki jeneratörü süren motora uygulanmıştır. Simülatördeki parazit torkların üstesinden gelmek adına, gerçek sistemin hızındaki hatayı elde edebilmek için sanal bir sistem ortaya konulmuştur. Bu hata, bir oransal-integral denetleyici tarafından, parazit torkları kompanze sinyali oluşturmak için kullanılır. Dikey eksenli rüzgar türbini simülatörü, değişik rüzgar hızlarında başarılı bir şekilde gerçek türbinin dinamiklerini benzetiyor ve kontrol tasarımları için gerçekçi bir sistem sunuyor. Rüzgar türbininin kontrolü için bir maksimum güç noktası izleyici ve önerilen basit bir lineer olmayan denetleyici ortaya konulmuştur. Kontrol algoritmaları DDSde değişken basamak, sinuzoidal ve gerçekçi rüzgar hızı koşulları altında test edilmiştir. Çıkış güçleri kendi aralarında ve sayısal olarak hesaplanan ideal durum değerleriyle karşılaştırılmıştır. Sabit mıknatıslı senkron jeneratör (SMSJ) parametrelerinin sistemin verimliliği üzerindeki etkisi incelenmiş ve kullanılan SMSJ ile piyasada bulundan iki adet diğer jeneratörlerin parametreleri kullanılarak bir performans karşılaştırılması yapılmıştır.","Control designs play an important role in wind energy conversion systems to achieve high efficiency and performance. In this study, hardware-in-the-loop simulations (HILS) are carried out to design control algorithms for small vertical axis wind turbines (VAWT). In the HILS, the wind torque is calculated from the power coefficient of an experimental VAWT and applied to a motor that drives the generator in the VAWT simulator, which mimics the dynamics of the real VAWT rotor. To deal with the disturbance torques in the VAWT simulator, a virtual plant was introduced to obtain an error between the speeds in HIL system and the plant. This error is used to generate a disturbance torque compensation signal by a proportional-integral (PI) controller. The VAWT simulator successfully mimics the dynamics of the VAWT under various wind speed conditions and provides a realistic framework for control designs. A maximum-power-point-tracking (MPPT) and a proposed simple non-linear control are presented for the control of the VAWT. The control algorithms were tested in the HILS under step up-down, sinusoidal and realistic wind conditions. The output power results are compared with each other and the numerically estimated optimum values. The effects of the permanent-magnet synchronous generator (PMSG) parameters on the system efficiency were investigated, and a performance comparison in numerical simulation was made between the present PMSG and two other generators available in the market."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Twitter her geçen gün daha da büyüyen, insanların fikir ve düşüncelerinin olduğu bir sosyal platform. Bu platformda her gün kullanıcılar tarafından üretilen içerik, verinin hacmi, düzensizliği ve hızı nedeniyle işlemesi çok zor bir veriye ama bir o kadar da değerli bir veriye dönüşmektedir. 2010 verilerine göre günde 55 milyon tweet üretilirken şu anda bu sayı ikiye katlanmıştır. Bu tezde twitter platformunda kullanıcılar tarafından üretilen verinin işlenebilmesi ve anlaşılabilmesi için sunduğumuz algoritmaları anlatıyor olacağız. Daha sonra bu algoritmaların tweetler üzerinde nasıl kullanılacağını, çalışmalardan ne gibi sonuçlar çıkarılabileceğini ve ne tür uygulamalar için fayda sağlayabileceğini gösteriyor olacağız. Bahsettiğimiz metodu kullanarak Twitter üzerinde ""Robot"" hesapları bulma ve tüm verinin özetini çok daha az tweet ile temsil edebilme gibi sorunları da nasıl çözdüğümüzü anlatıyor olacağız.","Twitter is an ever growing social platform that is full of ideas and opinions. Huge amount of data is produced daily that is usually too cumbersome to process and mine for the opinions of individuals. As of 2010, 55 million tweets are sent daily and the number is doubled by now. Also twitter data is not structured as a text based information source, considering the lack of structure of the data along with its huge volume, it is nearly impossible to have a healthy summarization of all the ideas and opinions at real time. Therefore in this work we propose a set of algorithms to cluster relevant tweets and similar tweets talking about the same concept on twitter domain. We demonstrate and explain how this information can be used on tweets. As a side benefit we also use these algorithms to detect bots or spammer accounts on twitter since we place such tweets to the same clusters. We show that by transforming twitter data into a clustered structure we are able to overcome problems such as detecting bots and providing a neat summary of the data. these are solvable by transforming the unstructured data environment of twitter to a structured data environment by forming clusters and buckets over the data feed. Another interesting observation we made is that the clusters we form follow the Pareto principle therefore by inspecting only 20% of the clusters we can cover 80% of the whole data."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çalışmanın temel amacı NP-zor optimizasyon problemlerini çözmede Grafik İşlemci Birimi kullanımının avantajlarını göstermektir. Bu nedenle, gezgin satıcı problemini çözmek üzere 2-opt ve 3-opt yöntemleri paralel olarak uygulanmıştır. Yöntemler belirli bir değişim sisteminin tüm geçerli kombinasyonlarını karşılaştırmaktadır. Bunun anlamı çok fazla sayıda hesaplama ve karşılaştırma işlemine ihtiyaç duyacak olmalarıdır. Bu yöntemlerin Grafik İşlemci Birimi aracılığıyla paralelleştirilmesiyle, Merkezi İşlemci Biriminin performansıyla karşılaştırıldığında performans önemli ölçüde artmıştır. Grafik İşlemci Biriminin kendine özgü çalışma tarzı ve karmaşık mimari yapısı nedeniyle, uygulamalar zorlu olabilmektedir. Grafik İşlemci Biriminin özensiz kullanımı algoritmanın performansında kayda değer bir azalışa yol açabilir. Bu nedenle, Grafik ve Merkezi İşlemci Birimi performanslarının karşılaştırmalarına ek olarak, Grafik İşlemci Biriminin kaynak tahsisinin işlemci performansındaki etkisi de incelenmiştir. Kaynaklar farklı yollarla paylaştırılarak, çeşitli büyüklükteki gezgin satıcı problemleri üzerinde birtakım deneyler test edilmiştir. Deneylere göre Grafik İşlemci Birimi kaynaklarını ideal olarak paylaştırmak için bir yöntem belirlenmiştir. Grafik İşlemci Birimleri günden güne evrilmesine rağmen, bazı kaynakları hala oldukça sınırlı kapasiteye sahiptir. Bu sebeple, uygulama sırasında söz konusu büyük boyutlu problemler olduğunda, Grafik İşlemci üzerindeki özel bir bellek yetersiz kalmıştır. Sorunun üstesinden gelmek için, bazı yararlı yaklaşımlar önerilmiştir. Temel olarak, problem parçalara ayrılmıştır. Paralelleştirme işlemi her parçaya ayrı ayrı uygulanmıştır. Özetleyecek olursak, bu araştırmanın amacı Grafik İşlemci Biriminin etkin kullanımıyla ilgili faydalı bilgiler vermek ve optimizasyon alanındaki araştırmacıların bu konuya aşina olmalarını sağlamaktır.","The main purpose of this study is to demonstrate the advantages of the GPU usage to solve computationally hard optimization problems. Thus, to solve the Travelling Salesman Problem, 2-opt and 3-opt methods were implemented in parallel. These search techniques compare every possible valid combination of the certain exchange system. It means that large numbers of calculations and comparisons are required. Through the parallelization of these methods via the GPU, performance has increased remarkably compared to performance in the CPU. Because of the distinctive manner of work and the complicated memory structure of GPU, implementations can be tough. Imprecise usage of GPU causes considerable decrease in the performance of the algorithm. Therefore, in addition to comparisons between GPU and CPU performances, the effect of GPU resource allocations on the GPU performance was examined. Allocating resources in different ways, several experiments on various sized travelling salesman problems were tested. According to the experiments, a technique was specified to utilize GPU resources ideally. Although GPU devices evolve day to day, some resources of them have still quite restricted capacity. For this reason, when it came to large scale problems, a special on-chip memory of the GPU device remained incapable. In order to overcome this issue, some helpful approaches were proposed. Basically, the problem was divided into parts. Parallelism was applied to each part separately. To sum up, the aim of this research is to give some useful insights about effective GPU usage and making researchers in the optimization area familiar with it."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok fazla sayıda konfigürasyon seçeneği olan yapılandırılabilirliği yüksek yazılımların test edilmesinin zorlukları vardır. Kombinatoryal etkileşim teknikleri, kapsayan dizileri kullanarak yüksek düzeyde yapılandırılabilir sistemleri sistematik bir şekilde test etme yöntemidir. Bir t-yollu kapsayan dizi, bütün t-yollu konfigürasyon seçenek değerleri kombinasyonunu en az bir kere kapsayan bir konfigürasyon kümesidir. t-yollu kapsayan dizi kullanılarak test etmenin t veya daha az seçeneğin etkileşiminden kaynaklanan hataları açığa çıkarmada yüksek etkisinin olduğu ampirik çalışmalarla gösterilmiştir. Geleneksel kapsayan diziler etkili olsa bile, konfigürasyonlarında seçenekleri arasında komplex etkileşimler olduğunda geleneksel kapsayan dizilerin zorlandıklarını gördük. Bu gibi durumlara dolaşık (tangled) seçenekler diyoruz. Bir dolaşık konfigürasyon seçeneği kompleks yapıda bir küme konfigürasyon seçeneği ile ve/veya iç içe geçmiş konfigürasyon seçenekleri hiyerarşisi ile gösterilebilir. Bu tezde, dolaşık seçeneklerin olduğu sistemlerin kaynak kodları incelenerek kombinatoryal etkileşim testlerinin etkisinin önemli bir biçimde geliştirilebileceği hipotezine sahibiz. Kaynak kodunun analiz edilmesi, konfigürasyon seçeneklerinin birbirleri arasındaki etkileşimin açığa çıkartılmasında ve fazladan hangi seçenek kombinasyonlarının ve bu kombinasyonların hangi koşullarda test edileceğinin bulanmasında kullanılır. Gri kutu test metodları, test edilen sistemlerin yapısal bilgilerine ihtiyaç duymaktadır. Konfigürasyon seçeneklerinin yapısını ve hiyerarşisini çıkarmak için statik olarak test edilecek sistemlerin kaynak kodlarını analiz ettik. Her konfigürasyon seçeneği bir test kriterine göre yapısal olarak bir kapsayan dizi tarafından ve ardından t-yollu etkileşimleri test edildi. Bu kriter, tam bir kapsama elde etmek yolunda eksik kalan konfigürasyon seçenekleri kombinasyonlarını belirlemede kullanılır. Daha sonrasında bu eksik kombinasyonlar için ek test durumları üretilir. Biz t-yollu kofigürasyon seçenekleri etkileşimi için bir dizi yeni kombinatoryal etkileşim kriterleri sunuyoruz. Bu tezde, sunduğumuz metodu ölçmek için yapılandırılabilirliği yüksek 18 gerçek yazılım üzerinde geniş çapta deneysel çalışmalar gerçekleştirdik. Geleneksel t-yollu kapsayan dizilerin konfigürasyon seçenekleri testinde sadece %80'ler civarında kapsama sağlayabildiğini gözlemledik. Ayrıca, t'nin yüksek değerlerinde ve dolaşıklığın fazla olduğu yerlerde kapsama %50'nin altına düştü. Bu tezde önerilen metod, bu tarz sorunları hedef almaktadır ve tam bir kapsama elde etmek için bir teknik sunar.","The enourmous size of configuration spaces in highly configurable softwares pose challenges to testing. Typically exhaustive testing is neither an option nor a way. Combinatorial interaction techiques are a systematic way to test such enourmous configuration spaces by a systematic way of sampling the space, employed through covering arrays. A t-way covering array is a sampled subset of configurations which contains all t-way option setting combinations. Testing through t-way covering arrays is proven to be highly effective at revealing failures caused by interaction of t or fewer options. Although, traditional covering arrays are effective however, we've observed that they suffer in the presence of complex interactions among configuration options, referred as tangled options. A tangled configuration option is described as either a configuration option with complex structure and/or nested in hierarchy of configuration options. In this thesis, we conjecture the effectiveness of CIT in the presence of tangled options can greatly be improved, by analyzing the system's source code. The analysis of source code reveals the interaction of configuration options with each other, this information can be used to determine which additional option setting combinations and the conditions under which these combinations must be tested. Gray-box testing methods rely on partial structural information of the system during testing. We've statically analyzed the source code of subject applications to extract the structure and hierachy of configuration options. Each configuration option has been structurally tested according to a test criterion against a t-way covering array and subsequently their t-way interactions. The criterion revealed the missing coverage of options which were employed to drive the additional testcase generation phase to acheive complete coverage. We present a number of novel CIT coverage criteria for t-wise interaction testing of configuration options. In this thesis, we've conducted a series of large scale experiments on 18 different real-world highly configurable software applications from different application domains to evaluate the proposed approach. We've observed that traditional t-way CAs can provide above 80% coverage for configuration options testing. However, they significantly suffer to provide interaction coverage under high t and tangling effects where coverage is dropped to less than 50%. Our work address these issues and propose a technique to acheive complete coverage."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez tablet büyüklüğündeki dokunmatik cihazlarda çok sayıda görünüm kullanılarak yaratılmış bir keşif görselleştirmesini konu almaktadır. Son zamanlarda mobil cihazların artması ve yüksek miktarda veri üretimi böyle bir sistem gereksinimini doğurmuştur. Burada sunduğumuz sistem veri analizinin mobil olarak yapılabilmesine olanak sağlamaktadır. Tez kapsamında; mobil cihazlarda bilimsel veriler için bir etkileşim yaklaşımı, geçiş fonksiyonlarına dayalı bir seçim tekniği ve son olarak bu ikisinin veri görselleştirmeleri üzerinde birleşimi anlatılmaktadır. Burada anlatılan yaklaşım mobil cihazlar üzerindeki çok görünümlü veri görselleştirmelerinde ilklerden biridir.",In this thesis we describe an exploratory visualization system for scientific data using multiple views in tablet-sized touch devices. The increasing ubiquity of mobile devices and vast amount of data generation create a need for such exploration environment. We make the data analysis available anywhere at anytime with our approach. This thesis includes an interaction framework for scientific data and a spatial selection technique based on transfer functions. We then combine the interaction and selection with multiple information visualization views to make the data exploration possible. The proposed approach is one of the first multiview exploratory visualizations in tablet devices.
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma mahremiyet korumalı erim sorgulamalarında veri ve sorgu gizliliğinin yanı sıra, sorgunun erişim örüntüsünün gizlenmesi sorununu işlemektedir. Bu soruna çözüm olarak Mahremiyet Korumalı Bilgi Erişimi (PIR) ve İlgisiz Bellek (ORAM) tekniklerine dayalı iki farklı yöntem önerilmiştir. PIR'e dayalı mahremiyet korumalı erim sorguları için Lipmaa'nın daha önce sunmuş olduğu hesaba dayalı PIR (CPIR) yöntemi üzerinden yeni bir CPIR yöntemi sunulmaktadır. Özgün yöntemin hesaplama süresini düşürmek amacıyla, yeni CPIR yönteminde toplam modüler üst alma işlemi sayısının azaltımı, daha az derinlikli agaçların kullanımı ve üst hesaplamaları için eş zamanlı çoklu üst alma algoritmalarının kullanımı önerilmiştir. Dahası, koşut algoritmalar kullanılarak yeni CPIR yönteminin hesaplama süreleri iyileştirilmiştir. ORAM'a dayalı mahremiyet korumalı erim sorgulama tekniğinde ise Stefanov'un daha önce sunmuş olduğu Path ORAM yöntemi erim sorgularına uyarlanmıştır. Çözümleme sonuçları göstermektedir ki, iletişim maliyeti göz önünde bulundurulduğunda, PIR yöntemi özellikle büyük veritabanlarında daha düşük ağ kullanımı sağlamaktadır. Öte yandan, hesaplama maliyetleri düşünüldüğünde, sunucu tarafındaki maliyetin göz ardı edilebilir olmasından dolayı ORAM temelli yöntem daha iyi sonuçlar sunmaktadır. Bu sonuçlardan yola çıkarak, mahremiyet korumalı erim sorgularında sorgu erişim örüntüsünün gizlenmesinde, nitel açıdan yararları olmasına rağmen, hesaplama maliyetleri açısından CPIR yönteminin ORAM yöntemine göre daha pahalı olduğu söylenebilir.","This work addresses the problem of hiding query access patterns in privacypreserving range queries while guaranteeing data and query con dentiality. We propose two methods, which are based on Private Information Retrieval (PIR) and Oblivious RAM (ORAM) techniques, respectively. For the PIR based search operation, we introduce a new scheme based on Lipmaa's computationally-private information retrieval (CPIR) method. We reduce the computation cost of CPIR by reducing the number of modular exponentiation operations, employing shallow trees and utilizing multi-exponentiation techniques. Furthermore, we improved the performance of CPIR by applying parallel algorithms. For the ORAM based method, we adapted Stefanov's Path ORAM method to the privacy-preserving range search. Our analyses show that, in terms of communication cost, CPIR provides better bandwidth usage especially in large database sizes, while in computational cost, Path ORAM based method performs better due to the negligible cost of server operations. The results imply that, despite some advantageous qualitative aspects of CPIR and its highly parallel implementation, it is still an expensive scheme in terms of computation complexity in comparison with Path ORAM for hiding query access patterns in privacy preserving range queries."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günlük hayattaki verilerin artış hızından dolay, bu verilerin üzerine manual olarak analiz yapmak yöntemleri kullanışsız olmaya başlıyorlar. Sosyal media (orneği Twitter) bu alanda bilgi depolaması ve insanlara kendi fikirlerinin paylaşması konusunda önemli bir rol oynuyamaktadır. İnsanların duüşüncelerini sosyal mediadan çıkarmak, şirketler için önemli bir amac sayılır. Duygu analizi metinlerin (veya diğer veri tiplerin) olumlu veya olumsuz oldukların çıkarmaya çaliışıyor. Bu işlem, ticari ve gayri-ticari bir çok alanda kullanışlı olabilir. Sirketler kendi urunleri ve servisleri hakknda musterilerin yorumlarn bilmek istiyorlar. Aynı zamanda müşterilerde diğer müşterilerin fikirlerini ürünlere göre öğrenmek isterler. Başka bir örnek verilecek olursa, siyasi partilerde insanların politik olaylara karşı fikir ve düşüncelerine önem gostermek zorundadırlar. Bunların otomatik veya yarı otomatik yöntemlerle yaplmaları gerekmektedir. Duygu analiz teknikleri her dilde o dilin yapsına göre farklılık gösterir. Diğer dillere oranla daha fazla araştırma kaynağına ve sözlüklere sahip olduğundan dolayı, bu alanda en zengin dil İngilizce olarak gösterilebilir. Yapılan araştrmaların coğu İngilizce üzerine olduğundan dolayı, diğer diller bu alandaki araştırma kaynakların eksikliğini hissediyorlar. Bu nedenden dolay Türkçe duygu analizi alannda daha fazla kaynak sunabilmek için bu doktora tezi bu konuda yapmaya karar verdik. Bu çalşmamda Türkçe duygu anlizi yapabilmek için kapsamlı bir sistem tasarlayıp ve geliştirdik. Bu sistemde bir kaç Türkçe sözlük üretip, bunları  duygu analizi yapmak icin kullandık. Bunun dışında, problemi kapsaml bir şekilde araştırıp, onu daha kuüçük problemlere böldük. Üzerine kuüçük değisiklikler yapılırsa tasarladığımız sistem, diğer diller için de kullanlabilir. Tüm problemleri bu çalışmamızda cçözülmemiş olsak bile, her problem için farklı bir cçözum yöntemi önerdik. Elde ettiğimiz sonuçlar, uyguladığımız yöntemlerin başarılı olduğunu kanıtlamaktadır.","Due to the ever-increasing amount of online information, manual processing of data is impractical. Social media such as Twitter play an important role in storing such information and helping people share their ideas. Extracting the attitude and opinion of people from user entered data is worthwhile for companies. Sentiment analysis attempts to extract the embedded polarity from a segment of text (or other data types) with many commercial and con-commercial applications. Companies are interested in opinions of their customers. On the other hand, customers are interested in opinions of other customers. Politicians and policy makers are also interested in public's feedback on political events. The above mentioned opinions can be (semi)automatically extracted from social media such as Twitter or Facebook by the help of sentiment analysis techniques. Sentiment analysis is a language (e.g. English) dependent task that relies on natural language processing techniques. The richest language in terms of resources and research in sentiment analysis is English, while many other languages such as Turkish su er from a lack of resources and techniques for sentiment analysis. In this thesis, we try to ll this gap by designing and implementing a framework for sentiment analysis in Turkish. This framework can also be adapted to other languages with some minor changes. In the scope of the framework, we have built a few Turkish polarity lexicons for the rst time in the literature. We also comprehensively investigated the problem of sentiment analysis in Turkish and suggested some solutions. Experimental evaluation shows the eff ectiveness of the proposed resources and techniques for Turkish."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"GPS-etkin mobil cihazların geniş ulaşılabilirliği sayesinde mekan-zaman verileri toplanıyor ve konum temelli servislere temin etmek için veya veri analizi için depolanıyor. Konum-temelli reklamcılık, pazar araştırması ve veri madenciliği mekanzaman verisinin toplanmasında motivasyonlardan sadece bir kaçı. Fakat, konum bilgisi ayrıca çok hassas bir bilgi çünkü özel bilgi olarak düşünülen politik görüş, din, sağlık durumu ve çeşitli kişisel tercihler hakkında bilgileri açığa çıkarabilir. Hassas konum bilgilerini koruma yöntemlerinden biri gizlemedir. Bu tezde, iki konum gizleme tekniğini uyguladık, mekan-zaman verisi için tasarlanan modern bir saldırı algoritmasında ne kadar etkili olduğunu araştırmak amacıyla analitik ve deneysel çalışmalar yürüttük. Saldırı senaryosunda, karşı taraf, bir grup yörüngeler ve yörüngeler arasındaki ikili uzaklıklardan oluşan uzaklık matrisi bilinirken hedeflenen bir yörüngeyi tahmin etmeye çalışıyor ve daha sonra belirli bir alanda yörüngenin varlığı veya yokluğu hakkında bilgi çıkarıyor. Gizleme tekniklerini önceden tanımlı hastaneler, tıp merkezleri gibi hassas yerler etrafındaki bilgiyi saklamak için kullandık. Deney sonuçları gösteriyor ki uygulanan gizleme teknikleri mekan-zaman yörüngelerinin düzenli bir paterni takip etmeleri durumunda hassas bölgelerdeki kullanıcıların mahremiyetini korumak konusunda yardımcı olmuyor. Gizleme teknikleri hassas yörünge noktalarını hassas yerlerin yeterince uzağına dağıtmadığı için ve yörüngelerin lineerliği korunduğu için saldırı metodunun başarılı bir şekilde çalıştığını gözlemledik.","With the wide availability of GPS-enabled mobile devices, spatio-temporal data is being collected and stored for providing location-based services or for data analytics. Location-based advertisement, market research, and data mining are just some of the motivations for collecting spatio-temporal data. However, location data is also very sensitive since it may reveal information about the data subject such as his/her political views, religion, state of health, and various personal preferences, which is considered private information. One of the approaches to protect sensitive location data is obfuscation. In this thesis, we have implemented two location obfuscation techniques, performed an analytical and experimental study to investigate how effective they are on a state of the art attack algorithm designed for spatio-temporal data. In the attack scenario, given a set of known trajectories, and a distance matrix composed of known pairwise distances between trajectories, adversary tries to approximate the target trajectory and then extract information about absence or presence of the trajectory in a given area. We used obfuscation techniques to hide information around predefined sensitive places such as hospitals, medical centers. We then used obfuscated data on the attack. Experimental results show that the applied obfuscation methods do not help protecting the privacy of users in sensitive areas in case of spatio-temporal trajectories that follow a regular pattern. We observed that the attack method works successfully because the obfuscation techniques do not scatter the sensitive points far enough from sensitive places and the linearity of the trajectory is preserved."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Teknolojinin gelişimi, bizlere bilgiye oldukça kısa bir sürede ulaşma şansı vermektedir.Bilgiye ulaşmanın kolaylığı sadece pozitif sonuçlar yaratmamakta, aynı zamandaçyetkisi olmayan kişilerin bilgiyi ele geçirmesini kolaylaştırmaktadır. Bunun bir sonucu olarak, veriyi farklı güvenlik alıcılarından korumanın gerekliliği, bilgi sistemlerinin önemli bir sorunu haline gelmiştir. Bu sistemlerdeki bir başka husus ise özel bilgilerin herkes tarafından erişilmesini engellemek adına erişim izinlerini korumaktır. Tıbbi veri de özel bilgi kapsamında olduğundan ötürü, verinin yetkisiz kullanımını engellemenin yanısıra, veriyi açığa çıkkmaktan, değiştirilmekten ve tahribattan korumak da tıbbi ortamlardaki bilgi güvenliğinin önemli gereksinimlerindendir. Bu tezde, değişken ortamlardaki hastaların tıbbi verilerini korumak amacıyla yeni bir erişim denetimi mekanizması önerilmiştir. Erişim denetimi modelimiz MAR-BAC (Tıbbi Şartlara Uyum Sağlayabilen Rol Tabanlı Erişim Denetimi), rol tabanlı erişim denetimi (RBAC) ve kritik durumun farkında olan erişim denetimi (CAAC) modellerinin avantajlarını kullanmaktadır. Özgün yaklaşımımız, acil vakalarda, değişik rollerdeki tıbbi uzmanların tıbbi hasta kayıtlarına açık bir istek olmaksızın otomatik olarak erişim kazanmasına imkan sağlamaktadır. Bu kapsamda, başlangıçta oturum açmaktan, hastaların tıbbi verilerinin iletimine ve tıbbi uzmanlar tarafından erişimlerine kadar güvenli ve gizlilik bilinçli protokoller tasarladık. Erişim denetimi model tanımlarımızda ve yöntemlerimizde çoğunlukla biçemsel bir yöntem izledik. MAR-BAC modelimizin tıbbi farkındalık özelliği, hastaların tıbbi verilerinin yaklaşık gerçek zamanlı olarak analiz edildiğinden gelmektedir. Bu analizlerin her biri, acil tıbbi müdahale adına, erişim denetim kurallarının otomatik olarak güncellenmesiyle sonuçlanmaktadır. MAR-BAC modelimizin gecikme karakteristiklerini belirlemek için simulasyon tabanlı performans değerlendirmesi uygulanmıştır. Aynı zamanda sistemin ölçeklenebilirliği de analiz edilmiştir. Sonuçlarımız MAR-BAC sisteminin ortalama sistem yükü altında lineer bir şekilde ölçeklendiğini göstermektedir. 500 adet yatan hastaya sahip bir hastanede ve ortalama yük altında, tıbbi bir aciliyete, uçtan uca tepki verme süresi 12 saniyeden daha azdır.","The development of technology gives opportunity to reach information in a reasonably short amount of time. Ease of access to information does not only create positive consequences, but also provides an easy way to access to information by unauthorized parties. As a result, the requirement of protecting data from different aspects of security turns into a significant issue of the information systems. Another issue in such systems is safeguarding the access permissions in order not to allow public accesses to private data. Protecting the data from disclosure, tempering or destruction as well as prevention of unauthorized use of any resource are important aspects of the security in medical environments since the medical data is private data. In this thesis, we introduce a novel access control mechanism in order to safeguard privacy of medical data of patients in dynamic environments. Our access control model, called MAR-BAC (Medically Adaptive Role Based Access Control), takes advantages from role-based access control (RBAC) and criticality-aware access control (CAAC).Our original approach allows the medical professionals with different roles to be granted access to medical records of patients automatically and without explicit request in case of a medical emergency. In this context, we design secure and privacy aware protocols from initial login to patients' medical data transmission and retrieval by the medical professionals. We mostly take a formal approach in our access control model deffinitions and procedures. The medical awareness feature of our MAR-BAC model comes from the fact that medical data of the patients are analysed in near real-time. Each such analysis yields automatic updates in the access control rules for the sake of urgent medical attention. We carry out simulation based performance evaluation to determine the delay characteristics of our MAR-BAC model. We also analyse the scalability of the system. Our results show that MAR-BAC scales linearly under moderate system load. Again under moderate load and in a hospital with 500 inpatients, the maximum end-to-end delay to react a medical emergency is less than 12 seconds."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada Sonlu Durum Makinaları (SDM) bazlı sınamada yeni bir kontrol dizisi üretim yöntemi verilmektedir. Tek bir durum tanıma dizisi kullanmakta olan literatürdeki mevcut yöntemlerin aksine, birden fazla durum tanıma dizisinin kullanılması önerilmektedir. Birden fazla durum tanıma dizisinin kullanımı ile kontrol dizisi üretimi sırasında daha kısa durum belirleme dizileriyle kontrol dizisinin uzunluğunun azaltılacağı öngörülmektedir. Önerilen yöntem iki safhadan oluşmaktadır. Ilk safhada, birden fazla durum tanıma dizisi kullanılarak bir sınama dizisi w oluşturulmaktadır. Ikinci safhada ise w tekrar ele alınıp yapılan eklentilerle bir kontrol dizisi haline getirilmektedir. Bu çalışmada yeni yöntemin mevcut yöntemlere göre daha kısa kontrol dizileri ürettiğini goösteren deneysel çalışmalar da sunulmaktadır.","A new method for constructing a checking sequence for finite state machine (FSM) based testing is introduced. Unlike its predecessors, which are based on state recognition using a single state identification sequence, our approach makes use of multiple state identification sequences. Using multiple state identification sequences provides an opportunity to construct shorter checking sequences, based on a greedy approach of choosing a state identification sequence that best suits our goal at di↵erent points during the construction of the checking sequence. Our approach has two phases. In the first phase, a test sequence w is constructed using multiple state identification sequences. The sequence w is not guaranteed to be a checking sequence, however it is further extended to a checking a sequence by the second phase of our method. We present the results of an experimental study showing that our two phase approach produces shorter checking sequences than the previously published methods."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüz kablosuz teknolojileri artan ihtiyaca ve mobil trafikteki artışa yanıt vermeye çabalamaktadır. Öz-girişim engelleme tekniklerinin hayatımıza girmesi ile, kablosuz tam-çift yönlü iletişim, spektral verimliliği iki katına çıkarması ve de veri hızını yükseltmesi ile ilgi çekici bir çözüm haline gelmiştir. Bu tezde, kablosuz yerel alan ağlarında tam-çift yönlü iletişime olanak sağlama amacı ile Synchronized-Contention Window Full-Duplex (S-CW FD) isminde bir ortam erişim kontrolü (OEK) protokolü sunuyoruz. Önerilen protokol IEEE 802.11 kablosuz yerel alan ağlarının tasarsız ve altyapı modlarının yanısıra günümüzde kullanılan istasyonlar ile birlikte de çalışabilmektedir. Bu çalışmada, S-CW FD'nin doymuş trafik başarımı Bianchi'nin modelini esas alan iki boyutlu bir Markov zinciri modeli ile elde edilmiş ve bu sonuçlar OPNET simülasyonlarını doğrulamak için kullanılmıştır. S-CW FD, farklı öz-girişim engelleme modelleri ve de kablosuz ağ durumları altında detaylıca simüle edilerek değerlendirilmiştir. S-CW FD'nin yarı-çift yönlü IEEE 802.11'in başarımını ağda gizli terminal yokken iki katına, gizli terminal bulunan ağlarda ise orta seviye öz-girişim engellemesi ve yüksek trafikte bile on katına kadar çıkarabildiği tespit edilmiştir. Varolan benzer tam-çift yönlü OEK protokolleri ile yapılan karşılaştırmalar, S-CW FD'nin gerçekçi ağ kondisyonları ve artan öz-girişim altında en iyi çalışan protokol olduğunu göstermiştir. Bunun sonucu olarak, S-CW FD, kablosuz yerel alan ağları için sadece başarımı arttırması ile değil, esnekliği ve geri uyumluluğu ile tam-çift yönlü OEK'lar arasında dikkat çekmektedir.","Current wireless technologies strive to respond to the arising demand for the increase in mobile traffic. Recently, with the introduction of self-interference (SI) cancellation techniques, wireless full-duplex communication has become an attractive solution that doubles the spectral efficiency and enhances data rates. In this thesis, we present a medium access control (MAC) protocol, named Synchronized Contention Window Full-Duplex (S-CW FD) protocol for enabling full duplex communication in wireless local area networks (WLANs). The proposed S-CW FD protocol can not only work in ad hoc and infrastructure modes of IEEE 802.11 WLANs, but with the legacy nodes as well. In this work, saturated throughput of S-CW FD is derived based on a two dimensional Markov chain model, similar to Bianchi's, and those results are used to validate simulations in OPNET tool. Via detailed simulation experiments, the performance of S-CW FD is evaluated under different self-interference models and wireless network conditions. It is shown that when there are no hidden nodes in the network, the S-CW FD protocol can double the throughput of half-duplex IEEE 802.11, and in the presence of hidden nodes in the network, the throughput gain of full duplex over half-duplex can get as high as tenfold, even for moderate SI cancellation levels and heavy load. Comparisons with existing similar FD MAC protocols also indicate that the proposed S-CW FD protocol performs best under realistic network conditions and residual SI. Hence, S-CW FD stands out as a promising FD MAC protocol with a high chance of application in WLANs, not only for significant performance improvements, but also for its flexibility and backwards compatibility."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, özellik noktaları sırasız eleman dizilerinden oluşan biyometriklerin kullanımı ile güvenli anahtar mutabakatı protokolü tasarlanmıştır. Önerilen protokol, servis sağlayıcı ile kullanıcının yalnızca biyometrik özellik noktalarını kullanarak simetrik bir anahtar oluşturmalarını sağlamaktadır. Diğer bir deyişle, protokol anahtarı rastgele oluşturmamakta veya anahtar oluşturma sürecinde hiçbir rastgele veriden yararlanmamaktadır. Önerilen yöntemin kuram ispatı olarak, bu protokol modeli parmak izi kullanılarak gerçeklenmiştir. Protokolde eşik tabanlı nicemleme kullanılarak belirli bir komşuluk ilişkisi içerisindeki özellik noktaları gruplanmışlardır. Bu sayede, servis sağlayıcı ile kullanıcı arasında ortak özellik noktaları üzerinde anlaşılması ihtimali artırılmıştır. Protokol rauntlar halinde çalışmaktadır. Her rauntta ortak bulunan özellik noktası sayısı kullanılarak bir benzerlik skoru hesaplanmakta ve bu skora göre kullanıcının sisteme kabul/ret kararı verilmektedir. Bunun yanı sıra, çoklu değerlendirme ölçütleri kullanılarak güvenlik analizleri yapılmıştır. Güvenlik analizleri, oluşturulan anahtarların rastgelelik oranlarının Shannon'un entropisi metriğine göre güvenli seviyelerde olduğunu göstermiştir. Ayrıca protokolün sonunda oluşturulan tüm anahtarların birbirlerine benzer olmadıkları Hamming uzaklık metriği ile gösterilmiştir. Öte yandan protokolün, kaba kuvvet saldırısı, tekrarlama ve taklit etme ataklarına karşı dayanıklı olduğu yüksek atak zorluğu ve düşük hata oranları ile kanıtlanmıştır. Protokolün karmaşıklığının ve hafıza gereksinimlerinin sistemin gerçeklenmesine uygun olduğu raporlanmıştır. Son olarak, protokol ile literatürde var olan bir yöntemin karşılaştırılması ile, protokolün performans ve atak dayanıklılığı açısından daha başarılı olduğu gösterilmiştir.","In this thesis, we propose a novel secure key agreement protocol that uses biometrics with unordered set of features. Our protocol enables the user and the server to agree on a symmetric key, which is generated by utilizing only the feature points of the user's biometrics. It means that our protocol does not generate the key randomly or it does not use any random data in the key itself. As a proof of concept, we instantiate our protocol model using fingerprints. In our protocol, we employ a threshold-based quantization mechanism, in order to group the minutiae in a predefined neighborhood. In this way, we increase the chance of user-server agreement on the same set of minutiae. Our protocol works in rounds. In each round, depending on the calculated similarity score on the common set of minutiae, the acceptance/rejection decision is made. Besides, we employ multi-criteria security analyses for our proposed protocol. These security analyses show that the generated keys possess acceptable randomness according to Shannon's entropy. In addition, the keys, which are generated after each protocol run, are indistinguishable from each other, as measured by the Hamming distance metric. Our protocol is also robust against brute-force, replay and impersonation attacks, proven by high attack complexity and low equal error rates. At the end, the complexity analysis and the memory requirements of the protocol are discussed and it is showed that they are in acceptable limits. As shown by comparative analyses, this work outperforms the existing fuzzy vault method in terms of verification performance and the attack complexity."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, bitki resimleri üzerinde Dense SIFT yönteminin farklı veri yapıları ile uygulanarak bitki türünün tanınmasını araştırdık. Çiçeklenmiş bitkileri üç farklı yöntem ile tanımlamak üzerine odaklandık. Birinci yaklaşım Dense SIFT yönteminin işlem görmemiş resimlere doğrudan uygulanması ile tanıma, ikinci yaklaşım renk özniteliklerine dayalı kümelere ayırdığımız veri parçalarında Dense SIFT uygulayarak tanıma, üçüncü yaklaşımda ise ilgi bölgesi yöntemi ile odak noktaları seçme işlemini ikinci yaklaşımın öncesinde uygulayarak tanımayı denedik. Bu çalışmaların sonucunda Dense SIFT yöntemi ile bitki tanınmasında doygunluk ağılıklı renk özü histogramı ve ilgi bölgesi yöntemleri kullanılarak iyileştirmenin mümkün olduğunu gözlemledik. Tasarlanan sistemi kullanarak, LifecLEF 2014 veritabanı çiçek alt kümesinde 0.60 doğru tanıma başarısı elde ettik.","In this thesis, we investigate the use of Dense SIFT approach in automatic identification of plants from photographs. We concentrate on flowering plants and evaluate three alternative approaches. In the first one, we classify the plant directly using the dense SIFT method, using appropriate parameters that are found using experimental validation techniques. In the second approach, we first identify the dominant colour in the photograph and use a separate classifier in each of the colour cluster. The second approach is intended to reduce the problem complexity and the number of classes handled by each classifier. In this approach, the classifier for red flowers will not know about a plant that does not flower in red; furthermore a plant that is only observed with red flowers will only be handled by that classifier. In a third approach, we precede the second approach by adding a Region of Interest detector, in order to extract the flower color more reliably. We find that enhancement of Dense SIFT features based identification is possible with saturation-weighted hue histogram based color clustering and region of interest detector. Using the proposed system, we obtain a $0.60$ accuracy on the flower subset in the LifecLEF 2014 database."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde insan bilgisayar etkileşimini gelişterecek makine öğrenmesi metotları tasarlanmıştır. Tezin ilgilendiği iki konu (i) çizilmiş sembol tanıma ve (ii) resimlerden obje tanımadır. Spesifik olarak ise, tamamı çizilmeden sembollerin tanınması ve özellik tanıma kullanılarak resimlerdeki objelerin tanınması tazin temel çalışma alanını oluşturmaktadır. Tamamlanmamış sembollerin tanınmasının kullanıcının çizim yapma hızını arttırmak, kullanıcıya geri bildirim sağlamak, ya da kullanıcı hatalarını azaltmak gibi birçok kullanım alanı bulunmaktadır. Özellik tanıma ise resimleri insanların objeleri tanımlamak için kullandığı ""kare"", ""metalik"" ya da ""kırmızı"" gibi görsel özelliklerle açıklamayı sağlar. Objelerin özellikleri, resimlerin insanlar tarafından anlaşılabilen kelimelerle indekslenmesi, daha önce görülmemiş sınıfl arın sadece objeleri anlatan açıklamalar vasıtasıyla tanınması veya resimleri açıklayan yazılar üretilmesi gibi birçok alanda kullanılabilir.","In this thesis, machine learning algorithms to improve human computer interaction are designed. The two areas of interest are (i) sketched symbol recognition and (ii) object recognition from images. Specifically, auto-completion of sketched symbols and attribute-centric recognition of objects from images are the main focus of this thesis. In the former task, the aim is to be able to recognize partially drawn symbols before they are fully completed. Auto-completion during sketching is desirable since it eliminates the need for the user to draw symbols in their entirety if they can be recognized while they are partially drawn. It can thus be used to increase the sketching throughput; to facilitate sketching by offering possible alternatives to the user; and to reduce user-originated errors by providing continuous feedback. The latter task, allows machine learning algorithms to describe objects with visual attributes such as ""square"", ""metallic"" and ""red"". Attributes as intermediate representations can be used to create systems with human interpretable image indexes, zero-shot learning capability where only textual descriptions are available or capability to annotate images with textual descriptions."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Anjiyografideki görüntü kılavuzlu ameliyatlarda C-arm cihazından alınan gerçek zamanlı X-ışını görüntüleri doktorun ameliyat cihazlarını yönlendirmesini sağlar. Bu iki boyutlu görüntüler üç boyutlu ameliyat öncesi alınan görüntülerle çakıştırılarak derinlik, örtünmelerin kaldırılması ve daha detaylı görünüm gibi ek bilgiler sağlar. Bu tezde ameliyat öncesi görüntülerdeki damarların katı çakıştırılması için iki yeni yöntem sunulmuştur. İlk yöntemde koroner damarların 3B-2B çakıştırılması için dönme ve ötelenme bulunması ayrılır. Dönme üç boyutlu görüntüden alınan bölütlenmiş damarların döndürülmüş projeksiyonlarının bölütlenmiş damarlar arasındaki uzsaklıkların en aza indirilmesi ve örtüşmenin en yükseğe çıkarılması ile bulunur. İkinci yöntem ilk yönteme ayrı derinlik hesaplaması getirir ve bölütlenmiş görüntüler yerine gradyanları kullanır. Dönme ve derinlik hacmin dönme şablonlarıyla derinlik şablonlarının Fourier Büyüklük uzayında karşılaştırılmalarıyla bulunur. Düzlem üzerindeki ötelenme ise Fourier Faz korrelasyonu ile kestirilir. Çakıştırma sonuçları beyin damarlarının Altın Standardı veri kümesiyle ölçülür. Bu yöntem örtünme ve gürültülere gradyanlar ve frekans uzayındaki benzerlik sayesinde dayanıklıdır. Şablonlar sayesinde büyük yakalama menzili ve her adımı için sabit","Image guided interventions in angiography are performed with a real-time X-ray sequences acquired by a C-arm device which provides the surgeon two dimensional visualization needed to guide the surgical instruments. This visualization may be augmented by registering a three dimensional preoperative volume with the interventional images to provide additional information such as depth, removal of occlusions and alternative views of vessel paths. This thesis presents two novel methods for rigid registration of vascular structures in the preoperative volume to the interventional X-ray image for enhancing visualization in Image Guided Interventions. In the first part of this thesis, estimation of rotation and translation are decoupled in 3D-2D registration of coronary arteries. Rotation is estimated by comparing rotated projections of the segmented vessels of the volume with segmented X-ray vessels in frequency domain. Translation is then estimated by minimizing the distances and maximizing the overlap ratio between segmented vessels. The registration results are reported in mean Projection Distances. The second part of the thesis adds separation of out-of-plane translation estimation to the first part and replaces segmentation by gradients. Rotation and out-of-plane translation are estimated by comparing rotational projected templates of volume with depth templates formed by scaling the X-ray image in the Fourier Magnitude Domain. The in-plane translation is then estimated by a Fourier Phase correlation. The registration results are evaluated by a Gold Standard dataset on cerebral vessels. This method is robust against occlusions and noises due to its usage of gradients and frequency domain similarity, has high capture range and fast, fixed computation times for every step due to template based framework."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyolojik bir interaksiyon ağında, belirli bir hastalık ile alakalı ve birbiriyle yoğun etkileşim içerisinde olan genlerin bulunduğu gruplara aktif alt-ağ denilir. Bu alt-ağları bulmak hastalıkların moleküler mekanizmalarını anlamaya yardımcı olmakta ve tedavi yöntemleri tasarlamaya katkıda bulunmaktadır; bu nedenle aktif alt-ağların saptanması önemli bir problemdir. Bu tezde, aktif alt-ağların tespiti için bir kümeleme algoritmasının kullanımı önerilmektedir ve Markov Kümeleme (MCL) algoritmasına dayalı bir yöntem geliştirilmiştir. Bu yöntem, insan protein-protein etkileşim ağını temsil etmek için grafik temsili, ağdaki interaksiyonlara bir değer atamak için yeni bir skorlama tekniği, aktif alt-ağ araması için Markov Kümeleme algoritması, bulunan alt-ağlara skor atamak için yeni bir formul ve alt-ağların bazılarını elemek için de bu skorları kullanmaktadır. Bu aşama, saptanan alt-ağlarla ilişkili fonksiyonel olarak önemli olan KEGG yolaklar tespit edilerek takip edilmektedir. Tanımlanan teknik WTCCC Romatoid Artrit (RA) datası üzerinde test edilmiştir ve sıradaki yolakları RA-ilişkili yolaklar olarak saptamıştır: daha önce RA ile alakalı olduğu keşfedilmiş yolaklar (NF-kappaB, Jak-STAT, Toll-like receptor, MAPK signaling gibi) ve yeni yolaklar (Serotonergic synapse). Karşılaştırmalı bir çalışma, sunulan metodun son model tekniklerden daha iyi bir performansa sahip olduğunu göstermekte ve sonuçlar metodun başarılı bir şekilde kompleks ve multifaktoriyel bir hastalık olan RA ile alakalı alt-ağları saptayabileceğini kanıtlamaktadır. Bu nedenle, metodun başka kompleks hastalıkların dataları üzerine uygulanması durumunda o hastalıklarla ilişkili alt-ağları da tespit edebileceği önerilmektedir.","An active subnetwork is a group of highly interacting genes that are associated with a particular disease in a biological interaction network. Finding these subnetworks facilitates the understanding of the molecular mechanisms of diseases and contributes to the process of devising treatment strategies, making the identification of active subnetworks an important problem. In this thesis, the use of a clustering algorithm is proposed for the detection of active subnetworks and a methodology that is based on the Markov Cluster (MCL) algorithm is implemented. The methodology uses graph representation to represent the human protein-protein interaction network, a novel scoring scheme to appoint weights to the interactions among the network, the Markov Cluster algorithm for the active subnetwork search, a scoring formula to assign scores to each found subnetwork and an elimination of subnetworks depending on those scores, followed by a functional enrichment step to discover the functionally important KEGG pathways related with found subnetworks. This methodology is applied on WTCCC Rheumatoid Arthritis (RA) dataset and identified: KEGG pathways previously found to be RA-related (e.g., NF-kappaB, Jak-STAT, Toll-like receptor, MAPK signaling pathways), and additional pathways (e.g., Serotonergic synapse) as associated with RA. The comparative study shows that the presented method outperforms state-of-the-art techniques, and functional enrichment results demonstrate that the method can successfully detect significant subnetworks that are related with RA which is a complex multifactorial disease. Therefore, it is proposed that the method can be used on the datasets of other complex diseases to identify active disease-associated subnetworks."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gıda endüstrisi, tarım, farmakoloji ve iklim kontrolü gibi çeşitli alanlardaki kullanımıyla, bitkiler insan yaşamı bakımından çok önemlidir. Ot ve bitki türlerinde muazzam bir çeşitlilik görülmesi, üstelik yeterli niteliklere sahip botanistlerin sayıca bir hayli az olması nedeniyle son yıllarda otomatik bitki tanımlama sistemlerine duyulan ihtiyaç artmıştır. Nesne tanıma teknolojisindeki en zor sorunlardan birine çözüm getirmeyi amaçlayan otomatik bitki tanımlama, otomatik öğrenme ve bilgisayarla görme algoritmalarını kullanarak bir görselde yer alan bitkiyi bilinen text veya türe atamayı hedefler. Ancak tanıma işlemi bitki ailelerindeki sınıflararası benzerlikler ve arka plan, örtme, poz, renk ve aydınlatmadaki sınıf içi varyasyonlar nedeniyle zorlaşır. Bu tezde, derin konvolüsyonel ağ bazlı otomatik bitki tanımlama sistemi çözümü önerilmektedir. Gözetimsiz öğrenim yaklaşımına dayanan sistem, basit bir temel kullanarak görsel parçalarına Ana Bileşenl Analizi (ABA) uygulayıp ağ ağırlıklarını öğrenir. Çok aşamalı ABA filtre öbekleri öğrenildikten sonra, çıkış haritalarında basit ikili kıyım gerçekleştirilir. Ardından haritalarda maksimum havuzlama ile altörneklem elde edilir. Son olarak altörneklem ile elde edilen verilere uzamsal piramit birleştirmesi uygulanarak blok histogramdan özellik detayları çıkarılır. Bunun ardından, çok sınıflı lineer destek vektör makinesi farklı türleri sınıflandırmak üzere eğitilir. Sistem performansı, LifeCLEF 2014 bitki tanımlama veri kümeleri üzerinde sınıfland-ırma doğruluğu ve ters sıralama puanına ek olarak, poz (translasyon, ölçeklendirme, ve döndürme) ve aydınlatma varyasyonlarına karşı dayanıklılık bakımından değerlendirilmi-ştir. Elde ettiğimiz sonuçlar, LifeCLEF 2014 kampanyasına gönderilen en iyi sistemlerde elde edilen sonuçlar ile karşılaştırıldığında; Genel, Dal, Meyve, Yaprak, Taranmış Yaprak ve Kök kategorilerinde ikinci, Çiçek kategorisinde ise üçüncü sırayı denk gelmektedir; üstelik birinci sırayı alan sistem(ler)e kıyasla daha basit bir mimari kullandığımız ve hesaplama karmaşıklığının da daha düşük olduğu görülmektedir. En yüksek doğruluk oranını ise 0,6157 ters sıralama puanı ve 68,25% sınıflandırma doğruluğu elde ettiğimiz taranmış yaprak kategorisinde yakaladığımız anlaşılmıştır.","Plants have substantial effects in human vitality through their different uses in agriculture, food industry, pharmacology, and climate control. The large number of herbs and plant species and shortage of skilled botanists have increased the need for automated plant identification systems in recent years. As one of the challenging problems in object recognition, automatic plant identification aims to assign the plant in an image to a known taxon or species using machine learning and computer vision algorithms. However, this problem is challenging due to the inter-class similarities within a plant family and large intra-class variations in background, occlusion, pose, color, and illumination. In this thesis, we propose an automatic plant identification system based on deep convolutional networks. This system uses a simple baseline and applies principal component analysis (PCA) to patches of images to learn the network weights in an unsupervised learning approach. After multi-stage PCA filter banks are learned, a simple binary hashing is applied to output maps and the obtained maps are subsampled through max-pooling. Finally, the spatial pyramid pooling is applied to the downsampled data to extract features from block histograms. A multi-class linear support vector machine is then trained to classify the different species. The system performance is evaluated on the plant identification datasets of LifeCLEF 2014 in terms of classification accuracy, inverse rank score, and robustness against pose (translation, scaling, and rotation) and illumination variations. A comparison of our results with those of the top systems submitted to LifeCLEF 2014 campaign reveals that our proposed system would have achieved the second place in the categories of Entire, Branch, Fruit, Leaf, Scanned Leaf, and Stem, and the third place in the Flower category while having a simpler architecture and lower computational complexity than the winner system(s). We achieved the best accuracy in scanned leaves where we obtained an inverse rank score of 0.6157 and a classification accuracy of 68.25$\%$."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gerçek hayatta veriler sıklıkla çok etiketlidir, yani aynı anda birden fazla sınıfa ya da kategoriye ait olabilirler. Bazen bu sınıflar üst seviyeler genel, alt seviyeler ise daha özel olacak şekilde mantıksal bir hiyerarşi oluşturur. Makine öğrenmesi kapsamında geliştirilmiş olan çoğu sınıflandırma yöntemi ya tek etiketli sınıflandırma yapar ya da çok etiketli sınıflandırma yapacak şekilde değiştirilir.Hiyerarşik sınıflandırma yapmak için uygun sınıflandırma yöntemleri henüz bulunmamaktadır ancak bunun için tek etiketli sınıflandırmayı baz alan stratejiler geliştirilmiştir. Bu stratejilerden dördü literatürde iyi bilinmektedir. Hiyerarşik sınıflandırma metin ketogorizasyonu, web sayfası sınıflandırması, medikal tanı gibi alanlarda çalışılmış ve etkinliği gösterilmiştir. Ancak şu ana kadar Twitter'a özel hiyerarşik sınıflandırma üzerine çalışılmamıştır. Bunun yanında, gözetimli öğrenme yöntemleri için etiketli verilere ihtiyaç duyulur ve etiketleme için insan gücü, zaman, ve maddi kaynak gerekir. Bu da etiketlenen verilerin sınırlı olmasına sebep olur ve aktif öğrenme bu anlamda daha az verinin etiketlenmesi ile düzgün modeller oluşturulmasını sağlar. Aktif Öğrenmede, en fazla bilgi içeren etiketlenmemiş veri seçilir ve uzmanlara etiketlemesi için sunulur. Bu sayede gözetimli öğrenmeye yakın bir performansla daha az etiketli veri kullanılarak model oluşturulması sağlanır. Aktif öğrenme, etiketlenmemiş verilerin çok olduğu durumlar için uygundur. Tweetlerin hiyerarşik sınıflandırmasının aktif öğrenme ile gerçekleştirilmesi de bu bakımdan anlamlı bir araştırma alandır. Bu tezde, önde gelen 4 hiyerarşik sınıflandırma yaklaşımını uyguladık ve aktif öğrenme için bunları Twitter ortamına uyarladık. Elde ettiğimiz sonuçlar baz alındığında, aktif öğrenmenin Twitter alanında faydalı olduğunu görmekteyiz. Uyguladığımız dört ana yaklaşımı karşılaştırdığımızda düz sınıflandırmalı hiyerarşik kestirim kullanılarak yapılan aktif öğrenmenin diğer üç yöntemden daha iyi sonuçlar verdiğini gördük.","Real world data is mostly multi-labeled i.e., it belongs to multiple classes simultaneously, as opposed to single labeled data belonging to a single class. At times these multiple labels fit into a logical hierarchy such that parent labels up in the hierarchy are generic and the related child labels down the hierarchy are more specific. Most of the machine learning classifiers are either serving single label classification tasks or have been transformed to perform flat multi-label classification. At present, dedicated classifiers for hierarchical classification do not exist. For the purpose, strategies are designed relying on the single labeled classifiers to perform hierarchical classification. Four such strategies are well-known in literature. Hierarchical classification has been researched in many domains like text categorization, webpages classification, medical diagnosis and has been found very useful. So far Twitter has been neglected by the researchers in hierarchical classification perspective. For developing supervised models labeled data is needed and labeling task requires resources in terms of humans, money and time, delimiting the amount of data which can be labeled. Active learning, a type of supervised learning, achieves acceptable performance with minimal amount of labeled data as compared to supervised learning models. In active learning, the learner selects the most informative unlabeled instances and are labeled by the experts. This makes possible to achieve comparable model performance to that of supervised learning with lesser labeling effort and resources. Active learning is well-suited to the situations where unlabeled data is abundantly available. Hierarchical classification of tweets complemented by active learning as a viable labeling mechanism presents an interesting research problem. We implemented the prevailing four hierarchical classification approaches with active learning for twitter domain. Based on the results, we can safely say that active learning is equally beneficial in Twitter. Comparing the results of the four approaches, hierarchical prediction through flat classification with active learning approach outperforms the other approaches."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kriptografik uygulamalardaki karmaşıklık arttıkça, atak yapmak isten kişiler, hedefledikleri veriye ulaşmak için yan kanalları kullanmaya başvururlar. Ancak yan kanalları takip ederlerken, arkalarında farkedemedikleri izler bırakıyor olabilirler. Bu tezde, önbellek tabanlı yan kanal ataklarından olan Flush+Reload tipindeki atakları yakalayabilmek için çalışmalar yaptık. Bu tip ataklar, ortak aygıtlar üzerindeki kullanım tiplerinden gizli bilgileri elde etmeye çalışırlar. Bu tezdeki ortak aygıt, işlemcinin 1. Seviye önbelleğidir. Casusların önbellek üzerinde bıraktıklar izler, onların varlığını bulabilmek adına oldukça değerli bir bilgidir. Bu sebeple seçilen ortak aygıt üzerindeki kullanım ayrıntılarını donanım performans sayaçları ile topladık. Bu tezde otomatik öğrenme yöntemlerini kullanarak, casus programın sistemde çalışıp çalışmadığını buluyorum. Arkalarında daha az iz bırakmak isteyen casus yazılımlar, önbellğin yarısını veya daha küçük bir kısmını silerek, bellek üzerindeki izlerini küçültmeye calışabilir. Önbellek kullanımı üzerinde önemli etkisi olan bir diğer parametre de sistem üzerindeki iş yüküdür. Bu sebeple, bu tezdeki yaklaşımlarımızı 7 farklı iş yükü altınca ve 4 farklı silme stratejilerini kullanarak denedik. Bu tezde açıklanan sistem, casus yazılımın varlığını %85 den daha da yüksek bir oran ve bizim önerdiğimiz metodun çalışma süresine ek yükü de ortalama olarak 0.5% arttırmıştık.","With the increasing complexity of cryptographic algorithms, attackers are lo oking for side channels to compromise private data. While attackers are tracking side channels, they leave traces b ehind them unintentionally. In this work, we concentrated on Flush+Reload typ e of attacks which is aimed to retrieve private data by using intentional contentions on shared resource. Our shared resource is L1 Data Cache of CPU. The trace of attackers on shared resource is a great asset for extraction of utilization pattern which is strong indicator for presence of attacker in the system. For this reason we collected data and extract utilization characteristics of the resource by using hardware p erformance counters. In this work, by taking the advantage of machine learning approaches, we make a decision on running applications, whether attacker application is one of them or not. Smarter attackers may flush cache partially in order to minimize fo otprint on shared resource. Workload level is another significant factor that alters the utilization profile of shared resource. For this reason, we exp erimented our approaches under 4 different levels of partial cache flush and 7 different workload level which mimics e-commerce server load. Our approach is able to detect the presence of attacker with higher than 85% accuracy and lower than 0.5% average execution time overhead."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Twitter, 2006 yılında kullanıma açıldığından bu yana insanların fikirlerini ve hislerini özgürce paylaşabilecekleri bir ortam olarak en populer alanlardan biri oldu. Son istatistiklere göre dakikada 350.000 Tweet atılmaktadır. Bunun yanında Twitter herhangi bir olaya karşı tepkiyi takip etmek için bakılan ilk yerlerden biridir. Bu bakımdan, Twitter duygu analizi gibi birçok alandan araştırmacıların dikkatini çekmiştir. Gerçekten de Twitter verileri toplumun hissiyatını içermesi açısından önemli ancak düzensiz ve informal yapısından dolayı da çalışılması zor bir ortamdır. Büyük çapta verilerin olduğu bu alanda denetimli öğrenme amacıyla etiketleme yapmak neredeyse imkansızdır. Amacımız, makine öğrenmesinin bir alt dalı olan aktif öğrenme teknikleri kullanarak en fazla bilgi içeren örneklerin etiketlenmesi ve bu yolla etiketleme için gereken eforun azaltılmasıdır. Bu tezle, belirlediğimiz aktif öğrenme stratejilerinin Twitter alanında karşılaştırmalı analizini yapmayı hedefledik. Sonuçlar bize belirsiz örnekleme yöntemlerinin rastgele örnekleme ve komite ile sorgulama yöntemlerinden daha başarılı olduğunu göstermektedir. Bir başka analizde ise etiketleyen kişilerin davranışlarının aktif öğrenmeye etkisini gözlemledik.","Since its launch in the year 2006, Twitter has been one of the most popular social media platforms where users are free to share opinions, ideas and feelings. Latest statistics tell us that nearly 350,000 tweets are being posted every minute on Twitter. Also twitter is the first place to track the response to any important incident or events in the world. For this reason, Twitter has attracted the researchers from many fields, including Sentiment Analysis which deals with opinion mining from text. Twitter data is rich in containing the sentiments but is inherent with the problem of being very informal and unstructured, which makes it very difficult to convert this data into information. Labeling this large amount of data to build classifiers for supervised learning is next to impossible. So we make use of Active Learning which is a sub-field of Machine Learning and concerns with the selection of most informative instances to train the classifiers, thus saving labeling efforts. This thesis deals with the comparative analysis of selected Active learning sampling strategies with twitter domain. The results show Uncertainty Sampling beats Random Sampling and Query by Committee consistently. An analysis of agreement levels among annotators for twitter data has also been presented."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Veri depolama, programlama ve benzeri bulut hizmetleri, kullanıcılarını bahsi geçen işlemlerin doğrudan yerine getirilmesinin yükünden kurtarmayı amaçlar. Bulut hizmetleri, oldukça popüler ve zahmetsiz olmasının yanı sıra, depolanan verinin mahremiyeti dikkat edilmesi gereken önemli bir husustur. Bu noktada, verinin pratik ve verimli bir şekilde işlenebilmesi için, klasik şifreleme yöntemleri bir çözüm teşkil etmez. Şifrelenmiş veriler üzerinde derecelendirilmiş Çoklu anahtar kelime ile arama(MRSE), sorgulanabilir şifrelemenin(SSE) özel bir dalıdır. Bu yöntem, kullanıcılarının şifrelenmiş veriler üzerinde, sorgularına karşılık gelen en yakın sonuçları güvenli bir şekilde bulabilmelerini sağlar. Benzerlik hesaplamasında kosunüs benzerliği ve tf-idf sembolizasyonu gibi araçlar kullanılır. Bu çalışmada, k-NN ve kabaca homomorfik şifreleme(SWHE) gibi tekniklerden yardım alan özgün bir MRSE metodu sunuyoruz. Metodumuz veri, sorgu ve sorgu örüntüsü mahremiyetini sağlarken, erişim mahremiyetinin sağlanmasına da olanak sağlar. Bahsi geçen güçlü güvenlik ve mahremiyet seviyelerine ulaşabilmek için, sk-NN algoritmasının usule uygun bir güvenlik analizini sunarken, kullanılan SWHE şemasının sağladığı IND-CPA güvenlik seviyesinden de yararlanılıyor. Şema, benzer mahremiyet seviyeleri sağlayan ve sadece SWHE kullanan klasik MRSE modellerine nazaran 200 kat civarı bir performans artışı sağlarken, daha düşük seviyelerde mahremiyet seviyeleri vad eden çalışmalarla karşılaştırılabilir performanslar ortaya koyuyor. Uygulamamız ile şemamızı, yanıt süresi, depolama ve kota kullanımı cinsinden kıyaslarken, hafif bir istemci tanımlandığı ortaya koyuluyor","Cloud computing offers computing services such as data storage and computing power and relieves its users of the burden of their direct management. While being extremely convenient, therefore immensely popular, cloud computing instigates concerns of privacy of outsourced data, for which conventional encryption is hardly a solution as the data is meant to be accessed, used and processed in an efficient manner. Multi keyword ranked search over encrypted data (MRSE) is a special form of secure searchable encryption (SSE), which lets users to privately find out the most similar documents to a given query using document representation methods such as tf-idf vectors and metrics such as cosine similarity. In this work, we propose a secure MRSE scheme that makes use of both a new secure k-NN algorithm and somewhat homomorphic encryption (SWHE). The scheme provides data, query and search pattern privacy and is amenable to access pattern privacy. We provide a formal security analysis of the secure k-NN algorithm and rely on IND-CPA security of the SWHE scheme to meet the strong privacy claims. The scheme provides speedup of about two orders of magnitude over the privacy-preserving MRSE schemes using only SWHE while its overall performance is comparable to other schemes in the literature with weaker forms of privacy claims. We present implementations results including one from the literature pertaining to response times, storage and bandwidth requirements and show that the scheme facilitates a lightweight client implementation."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda bilgisayarlı görme; alışveriş yardımı, görsel ürün arama (ör. Google Lens), kasaların kullanılmadığı mağazalar (ör. Amazon Go), gerçek zamanlı stok takibi, stok dışı algılama ve raf uygulaması gibi akıllı uygulamaların geliştirilmesiyle birlikte perakende süreçlerinin otomasyonunda çok önemli bir araç haline gelmiştir. Bu uygulamaların temelinde, genel nesne tanımanın aksine çeşitli yeni zorluklar içeren ürün tanıma sorunu yatmaktadır Ürün tanıma en ince ayrıntıyı içeren çoklu benzer ürünlere dair özel bir sınıflandırma örneğidir. Bir hipermarketteki paketlenmiş ürünlerin çeşitliliği göz önüne alındığında, aynı marka altında sadece şekil, ambalaj dokusu, metrik boyut vb. küçük görsel farklılıklar göstermeleri dolayısıyla, birbirlerinden ayırt edilmelerinde güçlük çekilen on binlerce farklı ürünle karsı karsıya kalınmaktadır. Başka bir zorluk ise, ideal stüdyo koşullarında alınan ürün başına sadece birkaç eğitim setine sahip sınırlı sayıda veri kümesi olmasıdır. Bunun sonucu olarak, çapraz veri kümesi genellemesine ihtiyaç duyulur ya da veri kümeleri gerçek bir perakende ortamında raftan alınarak elde edilir. Bu yüzden bulanıklık, düşük çözünürlük, kapanma, beklenmedik arka planlar vb. sorunlarla karşı karşıya kalınır. Bu nedenle, etkili bir ürün sınıflandırma sistemi, ürün resimlerinden elde edilen bilgilere ek olarak büyük ölçüde daha fazla bilgi gerektirir. Bu tezde, ince ayrıntıyı içeren çoklu benzer perakende ürün tanıma sistemi için istatistiksel yöntemler önermekteyiz. İlk çerçevede, ince ayrıntıyı içeren çoklu benzer perakende ürün tanıma problemi için yeni alışılmadık bağlama bağlı bir hibrit sınıflandırma sistemi önermekteyiz. İkinci çerçevede, son teknoloji evrişimsel sinir ağları incelenmiş ve ince ayrıntıyı içeren çoklu benzer ürünleri sınıflandırması için adapte edilmiştir. Bu tezin en önemli katkısının yer aldığı üçüncü çerçevede ise, (1) raflardaki olası ürün düzenlemeleri hakkında istatistiksel bağlam bilgisini öğrenen ve kullanan, (2) markalar arasındaki görsel hiyerarşileri kuran ve (3) sınıflandırıcı çıktısını gerçek sınıf etiketini belirli bir güven seviyesinde içerecek şekilde garanti eden ""güven setleri"" olarak veren çoklu benzer bir perakende ürün tanıma sistemi önerilmektedir.","In recent years, computer vision has become a major instrument in automating retail processes with emerging smart applications such as shopper assistance, visual product search (e.g., Google Lens), no-checkout stores (e.g., Amazon Go), real-time inventory tracking, out-of-stock detection, and shelf execution. At the core of these applications lies the problem of product recognition, which poses a variety of new challenges in contrast to generic object recognition. Product recognition is a special instance of fine-grained classification. Considering the sheer diversity of packaged goods in a typical hypermarket, we are confronted with up to tens of thousands of classes, which, particularly if under the same product brand, tend to have only minute visual differences in shape, packaging texture, metric size, etc., making them very difficult to discriminate from one another. Another challenge is the limited number of available datasets, which either have only a few training examples per class that are taken under ideal studio conditions, hence requiring cross-dataset generalization, or are captured from the shelf in an actual retail environment and thus suffer from issues like blur, low resolution, occlusions, unexpected backgrounds, etc. Thus, an effective product classification system requires substantially more information in addition to the knowledge obtained from product images alone. In this thesis, we propose statistical methods for a fine-grained retail product recognition. In our first framework, we propose a novel context-aware hybrid classification system for the fine-grained retail product recognition problem. In the second framework, state-of-the-art convolutional neural networks are explored and adapted to fine-grained recognition of products. The third framework, which is the most significant contribution of this thesis, presents a new approach for fine-grained classification of retail products that learns and exploits statistical context information about likely product arrangements on shelves, incorporates visual hierarchies across brands, and returns recognition results as ""confidence sets"" that are guaranteed to contain the true class at a given confidence level."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dijital oyunların yapay zeka mimarilerinde en sık kullanılan yöntemler Karar Ağaçları (BT) ve Hedef-Odaklı Aksiyon Planlamadır (GOAP). Karar ağaçları mimarisi senaryo tabanlı çalıştığından ötürü çok kontrol edilebilirdir fakat genişletilmeye açık değildir. Bunun aksine GOAP mimarisi planlama temellidir, dolayısıyla kontrol edilebilirliği azdır fakat kolaylıkla genişletilebilirdir. Bu tez Hedef-Odaklı Hiyerarşik Görev Ağları'nı (GHTN) ileri sürer. GHTN; Planlama temelli olan Hedef-Odaklı Aksiyon Planlama mimarisi ile senaryo temelli Karar Ağacı mimarisinin karması olarak disayn edilmiştir. GHTN, Hiyeralşik Görev Ağları (HTN) yapısının mimarisinde değişikliklere giderek HTN'in yinelemeli planlama yapısını hedef odaklı bir planlama yapısı ile v değiştirir ve bu modifikasyon esnasında Karar Ağaçları'nda olduğu gibi bir senaryo yazım yapısını eklemeyi hedefler. GHTN'nin senaryo-planlama karması mimarisi, Etkileşimli Anlatı Planlama için kullanılabilir. Öncesinde yaratılmış bir görev ağı ile beraber çalıştırıldığında, tekrarsız ve devamlı bir anlatı akışı sağlar ve bu anlatı akışının dışarıdan verilen hedefler çerçevesinde düzenler. Kullanıcıya, anlatıyı hedefe götürmek üzere akıllıca seçilmiş sorular sorulur ve kullanıcının yaptığı seçimler doğrultusunda hikayeyi hedefe doğru tekrar yönlendirir. Dünyanın başlangıç durumu ve hedefleri, görev ağına hakim bir Senarist tarafından seçilir. Bu tezde, sunulan GHTN mimarisne Etkileşimli Anlatı Planlama görevi verilmiştir. Anlatıda kullanılacak görev ağı, ""Lala Land"" dünyasından esinlenerek yaratılmış, ve çeşitli başlangıç ve hedef durumları ile sınanmıştır.","Two of the most commonly used AI architectures in digital games are Behavior Tree (BT) and Goal-Oriented Action Planning (GOAP). The BT architecture is script based, highly controllable but barely expandable. On the other hand the GOAP architecture is planner based, barely controllable but highly expandable. This thesis proposes a hybrid AI architecture called Goal-Oriented Hierarchical Task Network (GHTN); combining planner based approach of GOAP with script based approach of BT. GHTN modifies the Hierarchical Task Network (HTN) architecture by replacing its iterative planner with a goal oriented planner, while maintaining the BT-like scripting capabilities of HTN. iii GHTN's iterative-planner hybrid architecture is suitable to be used for Interactive Narrative Planning. Using GHTN with a previously crafted domain, it is possible to obtain a non-repetitive and continuous narrative flow which can also be directed by external goals. The user is presented with choices that are intelligently chosen to push the narrative towards the goal; then, depending on the answers new choices are generated. The initial state of the world and the goals are specified by a Scenarist who has the knowledge of the domain. The proposed architecture is tested on Interactive Narrative Planning task with an example domain set in the Lala Land universe, and the architecture is tested with several initial world states and goals."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok değişkenli dinamik ağları görselleştirmek zorlu bir iştir. Dinamik ağların zaman ekseni içindeki evrimi, ilişkili çok değişkenli niteliklerle birlikte gösterilmelidir. Bu tezde, uzamsal niteliklere sahip çok değişkenli dinamik ağları görüntülemek için görsel keşif analiz aracı önerilmiştir. Önerilen araç, zamansal çok değişkenli alan ve ağ özelliklerinin dağınık görünümlerde dağılımını gösterir. Ayrıca, geçici ağ boyunca tek bir veya bir grup düğümün dinamik ağdaki evrimini açığa çıkarmak için, bir düğümün mahallesi ile beniçinci ağı olarak temsil edildiği beniçinci merkezli bir yaklaşım uygulanmaktadır. Bu yaklaşım, kullanıcıların bir düğümün içinde bulunduğu ortamı zaman ekseni boyunca gözlemlemelerine izin verir. Zaman çizelgeleri gibi geleneksel beniçinci ağ görselleştirme yöntemlerinin yanı sıra, önerilen araç beniçinci ağları, alan ve ağ özelliklerinden oluşan nitelik vektörleri olarak kodlar ve bunları 2B görünümlere yansıtır. Sonuç olarak, yansıtılan beniçinci ağlar arasındaki mesafeler, farklılıkları tek bir gösterimde temsil eder. Önerilen araç bir yıllık kredi kartı işlemlerinden elde edilen ticari ağlar ile gösterilmiştir.","Visualizing multivariate dynamic networks is a challenging task. The evolution of the dynamic network within the temporal axis must be depicted in conjunction with the associated multivariate attributes. In this thesis, an exploratory visual analytics tool is proposed to display multivariate dynamic networks with spatial attributes. The proposed tool displays the distribution of multivariate temporal domain and network attributes in scattered views. Moreover, in order to expose the evolution of a single or a group of nodes in the dynamic network along the temporal axis, an egocentric approach is applied in which a node is represented with its neighborhood as an ego-network. This approach allows users to observe a node's surrounding environment along the temporal axis. On top of the traditional ego-network visualization methods, such as timelines, the proposed tool encodes ego-networks as feature vectors consisting of the domain and network attributes and projects them onto 2D views. As a result, distances between projected ego-networks represent the dissimilarity across temporal axis in a single view. The proposed tool is demonstrated with a real-world use case scenario on merchant networks obtained from a one-year long credit card transactions."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda yaşanan teknolojik gelişmelerin yardımıyla, hastaların sağlık durumlarını uzaktan gözlemleyebilmek kolaylaştı. Hastaların gözlemlenmesi ""biyosensör"" adı verilen ve gövde alan ağında birbirine bağlı düğümler halinde bulunan giyilebilir cihazlar ile yapılmaktadır. Biyosensörlerin en önemli görevleri bağlı bulunulan kişiden hassas ve kritik verilerin toplanması, toplanan verilerin biyosensörler arasında iletişim kurularak analiz edilmesi ve ardından sağlık çalışanlarına gönderilmesidir. Toplanan verilerin hassas veriler olması nedeniyle veriler üzerinde yapılan işlemlerin güvenli olması gerekmektedir. Biyosensörler güvenlik saldırılarına açık olan kablosuz ağ üzerinden iletişim kurmaktadırlar. Bu nedenle, verilerin korunması ve gövde alan ağı içerisindeki iletişimin güvenliğinin sağlanması için bir güvenlik mekanizması gerekmektedir. Buna ek olarak, biyosensörlerin donanımsal kaynak kısıtlamalarının üstesinden gelinebilmesi için oluşturulan güvenlik mekanizması fazla kaynak gerektirmemelidir. Kriptografik anahtar oluşumu ve biyosensörler arası anahtar anlaşmasının rasgele ve güvenli olması, bu güvenlik mekanizmalarının en önemli öğelerindendir. Bu tezde, fizyolojik sinyaller kullanılarak güvenli ve rasgeleliği arttırılmış anahtar anlaşması sistemi (SKA-PSAR) önerilmiştir. Bu sistemin temel amacı biyosensörlerin gövde alan ağları içerisinde güvenli iletişim sağlayabilmesi için rasgeleliği yüksek kriptografik anahtarlar üretmektir. SKA-PSAR sistemi de, öncülü Karaoğlan Altop vd. tarafından önerilen SKA-PS protokolü gibi, fizyolojik sinyalleri (kalp atış hızı, kan basıncı, vb.) girdi olarak kullanmakta ve temel yapı taşı olarak küme uzlaşması mekanizmasından yararlanmaktadır. Yeni nicemleme ve ikilileştirme mekanizmaları ile daha rasgele anahtarlar üretilebilmesi, SKA-PSAR sistemini SKA-PS protolünden ayırmaktadır. Bununla beraber, SKA-PSAR sistemi tarafından oluşturulan anahtarlar ayırt edicilik ve zamansal değişim özelliklerini taşımakta ve aynı zamanda yeterince uzun bit uzunlukları ile kriptografik ataklara karşı dayanıklılık göstermektedir. Buna ek olarak, %100 doğru anahtar oluşturma yüzdesi ve %0 yanlış anahtar oluşturma yüzdesi elde edilmiştir. Son olarak, önerilen protokolün hesaplama karmaşıklığı, iletişim karmaşıklığı and hafıza gereklilikleri SKA-PS protokolüne göre yüksek çıkmıştır; fakat yüksek rasgelelik içeren anahtarlar oluşturulması için bu gereklidir.","With the help of recent technological advancements especially in the last decade, it has become much easier to extensively and remotely observe medical conditions of the patients. This observation is done through wearable devices named ""biosensors"" that act as connected nodes on the Body Area Network (BAN). The main goal of these biosensors is to collect and provide critical and sensitive health data concerning the host individual, communicate with each other in order to make decisions based on what has been captured and relay the collected data to remote healthcare professionals. The sensitive nature of this critical data makes it extremely important to process it as securely as possible. Biosensors communicate with each other through wireless medium that is vulnerable to potential security attacks. Therefore, secure mechanisms for both data protection and intra-BAN communication are needed. Moreover, these mechanisms should be lightweight in order to overcome the hardware resource restrictions of biosensors. Random and secure cryptographic key generation and agreement among the biosensors take place at the core of these security mechanisms. In this thesis, we propose SKA-PSAR (Secure Key Agreement Using Physiological Signals with Augmented Randomness) system. The main goal of this system is to produce highly random cryptographic keys for the biosensors for secure communication in a BAN. Similar to its predecessor SKA-PS protocol by Karaoğlan Altop et al., SKA-PSAR also employs physiological signals, such as heart rate and blood pressure, as inputs for the keys and utilizes the set reconciliation mechanism as basic building block. Novel quantization and binarization methods of the Secure Key Agreement Protocol of the proposed SKA-PSAR system distinguish it from SKA-PS in a way that the former has increased the randomness of the generated keys. In addition, the generated cryptographic keys in our proposed SKA-PSAR system have distinctive and time variant characteristics as well as long enough bit sizes that can be considered resistant against a cryptographic attack. Moreover, correct key generation rate of 100% and false key generation rate of 0% have been obtained. Last but not least, results of the computational complexity, communication complexity and memory requirements of our proposed system are quite higher as compared to SKA-PS, but this is a cost that needs to be paid for achieving high randomness level."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, pekiştirmeli öğrenme yoluyla dinamik sistemlerin kontrolünü öğrenme problemi ele alınmıştır. Dinamik sistemlerin kontrolünün öğrenmesi hususunda iki önemli problem vardır: ilintili örnek uzay ve çok boyutluluğun laneti: İlk problem, öğrenmek için kullanılan ardışık örneklerin, birbiriyle ilintili olmasından dolayı dinamik sistem kontrolünü öğrenmek için yeterli zengin veri setini sunamaması anlamına gelmektedir. İkinci problemse, büyük sayıda durum boyutuna sahip dinamik sistemler için durum uzayını niceliklerine ayırarak betimleme yaparak öğrenmek, öğrenilmesi gereken durum sayısını çok artıracağı için, öğrenmenin imkansız veyahut çok zor hale gelmesi anlamına gelir. Son zamanlarda, bu iki problem, güncel olan en iyi çalışma olan Derin Deterministik Politika Gradyan (DDPG) yoluyla çözülmeye çalışılmıştır. Bu çalışmada, Derin Deterministik Politika Gradyan yönteminin örnekleme yöntemini daha verimli bir yol olarak, Öncelikli Deneyimli Derin Deterministik Politika Gradyanı yöntemi öne sürülmüştür. Bu yöntem Derin Deterministik Politika Gradyanı yöntemine, Öncelikli Deneyim Tekrarı (Prioritized Experience Replay) yöntemindeki örnekleme yönteminin entegrasyonu olarak düşünülebilir. Bu yöntem ile, öğrenmenin her deneyimden eşit derece olmasının yerine, hatalı olan deneyimleri tekrar tekrar örnekleyerek, daha verimli öğrenmenin sağlanması amaçlanmıştır. Öncelikli Deneyimli Derin Deterministik Politika Gradyanı (PE-DDPG) yöntemi öne sürülmüş olup, bu yöntem OpenAI Gym aracındaki Ters Sarkaç problemi üzerinde test edilmiştir. Sonuçlar göstermektedir ki, önerilen yöntem öğrenme zamanını kısaltmış ve öğrenme sırasındaki varyansı da düşürerek daha kararlı bir öğrenme süreci sağlamıştır.","In this thesis, the problem of learning to control a dynamic system through reinforcement learning is taken up. There are two important problems in learning to control dynamic systems under this framework: correlated sample space and curse of dimensionality: The first problem means that samples sequentially taken from the plant are correlated, and fail to provide a rich data set to learn from. The second problem means that plants with a large state dimension are untractable if states are quantized for the learning algorithm. Recently, these problems have been attacked by state-of-the-art algorithm called Deep Deterministic Policy Gradient method (DDPG). In this thesis, we propose a new algorithm Prioritized Experience DDPG (PE-DDPG) that improves the sample efficiency of DDPG, through a Prioritized Experience Replay mechanism integrated into the original DDPG. It allows the agent experience some samples more frequently depending on their novelty. PE-DDPG algorithm is tested on OpenAI Gym's Inverted Pendulum task. The results of experiment show that the proposed algorithm can reduce training time and it has lower variance which implies more stable learning process."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kriptografik algoritmalar günlük hayatımızda yaygın olarak kullanılmaktadır. Bu algoritmalar, olası açıklara karşı, biliminsanları tarafından matematiksel olarak analiz edilmektedir. Bu algoritmalar matematiksel olarak doğrulanmış olmalarına rağmen, özenli bir şekilde gerçeklenmezlerse, güvenlik riskleri barındırmaya devam edebilirler. Yan-kanal analizi ile gerçekleme hatalarından kaynaklı bilgi sızıntıları kullanılarak gizli anahtar elde edilebilmektedir. En çok çalışılmış yan-kanal ataklarından birisi Bernstein'ın atağıdır. Bu atak, başarılı sonuçlar elde etmek için kasıtlı olarak önbellek çakışmaları yaratan bir casus sürece ihtiyaç duymaması ile bilinmektedir. Bununla birlikte, atağı başarıya ulaştıran sızıntı kaynakları net bir şekilde ortaya çıkarılamamıştır. Ayrıca ayrımlama fazı için, hedef sistemin bire bir kopyasına ihtiyaç duyması atağın gerçek hayattaki uygulanabilirliği üzerinde soru işaretleri uyandırmıştır. Bu tezde, bu iki sorun üzerinde çalısmalar yapılmıştır. İlk olarak, bilgi sızıntısının kesin kaynağını bulmak için bir metodoloji öneriyoruz. Önerilen metodoloji, program içerisindeki kod bloklarının maruz kaldığı önbellek ıskalarını, donanım performans sayaçları ile saymaya dayanmaktadır. Program geliştiricileri, metodolojimizi kullanarak kodlarını analiz edebilir ve olası hataları erken bir aşamada düzeltebilirler. İkinci olarak, önbellek zaman-davranışı modellerini analitik olarak çıkarmaya yarayan bir yaklaşım sunuyor ve oluşturulan bu modelleri ayrımlama fazı yerine kullanmayı öneriyoruz. Saldırının bir ayrımlama aşaması olmadan gerçekleştirilebilmesinin, saldırının daha gerçekçi bir tehdit olarak görülmesini sağlayacağını ve kriptografik sistem tasarımcılarını, atağa karşı ek önlemler almaya teşvik edeceğini düşünüyoruz.","Cryptographic algorithms are widely used in daily life in order to ensure data confidentiality and privacy. These algorithms are extensively analyzed by scientists against a theoretical deficiency. However, these theoretically verified algorithms could still posses security risks if they are not cautiously implemented. Side-channel analysis can infer the secret key by using the information leakage due to implementation flaws. One of the most studied side-channel attack is the Bernstein's cache-timing attack. This attack owes its reputation to its ability to succeed without a spy process, which is needed to create intentional cache contentions in other cache attacks. However, the exact leakage sources of the Bernstein's attack remained uncertain to a large extent. Moreover, the need for an identical target system to perform its profiling phase makes the attack unrealistic for real world computing platforms. In this dissertation we address these two problems. Firstly, we propose a methodology to reveal the exact sources of the information leakage. The proposed methodology makes use of hardware performance counters to count the number of cache misses, to which the code blocks in the program are subject. Our methodology can help the developers analyze their implementations and fix their code in the early phases of the development. Secondly, we present an approach to extract simplified cache timing-behavior models analytically and propose to use these generated models instead of a profiling phase. The fact that the attack can be accomplished without a profiling phase will lead the attack to be considered a more realistic threat than the attack originally proposed by Bernstein. We believe that, this improved version of the attack will encourage the cryptographic system designers to take further precautions against the attack."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Anlam temelli görüş madenciliği, bir metindeki tüm tekil mânâları tanımlayan ve çıkaran otomatikleştirilmiş bilimdir. Yıllar içinde bu bilim, tüketici ürünleri ve sosyal-politik olaylar hakkında kamuoyunun analizinin temel taşı olarak ortaya çıkmıştır. İşin verimliliğiyle beraber zorluk derecesi de birden fazla görüşün değişik anlamlarda farklı kişiler üzerinden araştırılmasıyla artar. Literatürdeki farklı yöntemler tek bir koleksiyonda veya birden fazla koleksiyonda teker teker anlamları bulmayı denemiştir. Bu yaklaşımlar, koleksiyonların sayısı arttığında ve dolayısıyla önemli performans sakıncaları olduğunda cazip değildir. Bu çalışmada aynı anda birden fazla karşıtlığı da olan koleksiyon üzerinde anlam temelli fikir (görüş) madenciliği gerçekleştiriyoruz. Birden çok koleksiyonda geçerli olan konuları tanımlamak için mevcut çapraz koleksiyon konu modellerini kullanıyoruz ve bu konuları başarılı bir şekilde semantik olarak uyumlu ve görsel olarak tanımlanabilir anlamlara dönüştüren bir konu iyileştirme algoritması öneriyoruz. Algoritmamız tarafından çıkarılan anlamların başarısını, iki çapraz koleksiyon konu modeliyle döndürülen konularla karşılaştırıyoruz. Son olarak, mânâ puanlarının doğruluğunu iki çapraz koleksiyon konu modeli tarafından elde edilen özellikler üzerinden ölçerek değerlendiriyoruz. Önerilen geliştirmelerle, çapraz koleksiyon konu modellerinin, anlam temelli mânâ analizinde son teknoloji yaklaşımlarını geride bıraktığı sonucuna vardık.","Aspect based opinion mining is the automated science of identifying and extracting sentiments associated to individual aspects in a text document. Over the years this science has emerged to be a cornerstone for analysis of public opinion on consumer products and social-political events. The task is more fruitful and likewise more challenging when comparison of opinion on aspects of multiple entities is of essence. Different methods in literature have attempted to extract aspects in a single collection or collection by collection across multiple collection. These approaches do not appeal when number of collections is large and hence suffer significant performance drawbacks. In this work we perform aspect based opinion mining across contrasting multiple collections, simultaneously. We utilize existing cross collection topic models to identify topics that prevail across multiple collections, we propose a topic refinement algorithm that successfully converts these topics into semantically coherent and visually identifiable aspects. We compare the quality of aspects extracted by our algorithm to topics returned by two cross collection topic models. Finally we evaluate the accuracy of sentiment scores when measured over features extracted by the two cross collection topic models. We conclude that with proposed improvements cross collection topic models outperform state of art approaches in aspect based sentiment analysis."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Beyindeki beyaz cevher lifleri, çeşitli gri cevher bölgelerinin birbiriyle iletişimini sağlar. Difüzyon Manyetik Rezonans Görüntüleme (DMRG), hayatta olan deneklerin beyaz cevher liflerinin oryantasyonlarının kestirilmesini mümkün kılar. Kestirilen oryantasyonlar kullanılarak, liflerin yörüngelerinin 3B eğri temsilleri oluşturulabilir. Bu işlem trakrografi olarak bilinmektedir. Yolak olarak da adlandırılan bu 3B eğri temsillerinin bilinen anatomik lif kümelerine otomatik olarak sınıflandırılması sinirgörüntü işlemede çok önemli bir problemdir. Bu tezde, üç yeni otomatik yolak sınıflandırma yöntemi önerilmiştir. İlk iki metot, siniranatomik önbilginin, yoğunluk tabanlı danışmansız kümeleme metoduyla birleştirilmesine dayanmaktadır. İlk metot, beyinsapına özel buluşsal yöntemler içermekle beraber, ikinci metot daha genel bir metot olup, beyindeki her lif kümesi için uygulanabilir. Ayrıca, ikinci metotta yeni bir lif temsili önerilmiştir. Komşu lif yönleri dağılımı (KLYD) adını verdiğimiz bu temsil, her yolağı, komşuluğundaki lif oryantasyon dağılımını kodlayan histogramlarla temsil etmektedir. Üçüncü metot, KLYD temsilini kullanarak, danışmanlı öğrenme yaklaşımı çerçevesinde, her yolağı, doğrudan, ilgilenilen lif küme sınıflarına ait olma olasılık kestirimlerine haritalar. Pratik bir eğitim ve doğrulama kümesi oluşturma metodolojisi de önerilmiştir. Bunlara ek olarak, tümör çıkarılma ameliyatı öncesi ve sonrası lif yapıları arasındaki değişim ile hastanın klinik bilişsel bulguları arasında istatistiksel olarak anlamlı bir ilişki olup olmadığı araştırılmıştır. Bu bağlamda, bir yolak kümesinden yolak kümesine çakıştırma metodu ve lifler arasındaki değişimi sayısallaştırmaya yönelik çeşitli ölçütler önerilmiştir. Beyinsapında tümör bulunan 30 hastanın DMRG görüntüleri ve klinik değerlendirme puanları üzerinde elde edilen sonuçlar sunulmuştur.","White matter fibers connect and transfer information among various gray matter regions of the brain. Diffusion Magnetic Resonance Imaging (DMRI) allows in-vivo estimation of fiber orientations. From the estimated orientations, a 3D curve representation of the trajectory of fibers can be reconstructed in a process known as tractography. Automatic classification of these ""tracts"" into classes of anatomically known fiber bundles is a very important problem in neuroimage computing. In this thesis, three automatic fiber classification methods are proposed. The first two are based on combining neuroanatomical priors with density-based clustering. The first method includes brainstem heuristics but the second is more general and can be applied to any fiber pathway in the brain. Further, the second method introduces a novel fiber representation, Neighborhood Resolved Fiber Orientation Distribution(NRFOD), that represents a tract as a set of histograms that encode the distribution of fiber orientations in its neighborhood. The third method utilizes the NRFOD representation to directly map a tract to a probability estimate for each bundle class in a supervised classification framework. A practical training and validation set creation methodology is proposed. Additionally, the thesis includes statistical significance tests to investigate whether the structural change between pre-operative and post-operative fiber bundles after a tumor resection operation are related to the change in patient's cognitive performance scores. To this end, a fiber bundle to fiber bundle registration method and various quantitative measures of the structural change are proposed. We present results over DMRI data with clinical evaluations of 30 patients with brainstem tumors."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Karmaşık sistemlerin geliştirilmesinde, test etme en pahalı ve en çok zaman alan evredir. Model tabanlı testler yüksek kaliteli deney kurgusunu otomatik üretmede kullanılan yaklaşımlardan birisidir. Deney kurgusunu otomatik üretme test etmenin en zorlu parçalarından biridir. Sonlu durum makineleri ya da özdevinimler gibi biçimsel modeller, otomatik deney grubunu üretmek için kullanılmaktadır. Sistem belirli bir duruma senkronize edildikten sonra testler uygulanır ve bu belirli duruma gelebilmek için sıfırlama kelimeleri kullanılmaktadır. Daha kısa deney süreleri için en kısa sıfırlama kelimesini hesaplamak önemlidir, ancak en kısa sıfırlama kelimesini hesaplamak NP– hard bir problemdir. Bu nedenle kısa sıfırlama kelimelerini hesaplamak için sezgisel yöntemler kullanılmaktadır. GREEDY algoritması bu alanda bilinen en hızlı sezgisel algoritmadır. Bu tezde, GREEDY algoritmasını hızlandıran yaklaşımlar sunulmaktadır. İlk olarak GREEDY algoritmasının paralelleştirilmesine odaklanılmaktadır. İkinci olarak ise tembel bir yaklaşım önererek sıfırlama kelimesinin üretilmesi için gerekli bilgilerin hazırlanma süreci ertelenmektedir. Aynı zamanda, GREEDY algoritması için benzer algoritmik iyileştirilmeler önerilmektedir. Deney sonuçlarımız özdevinim büyüklügüne bağlı olarak GREEDY algoritmasının 500 kat daha hızlı hale getirilebileceğini göstermektedir. Önerilen geliştirmeler özdevinim büyüklügü arttıkça daha etkili hale gelmektedir.","Testing is the most expensive and time consuming phase in the development of complex systems. Model–based testing is an approach that can be used to automate the generation of high quality test suites, which is the most challenging part of testing. Formal models, such as finite state machines or automata, have been used as specifications from which the test suites can be automatically generated. The tests are applied after the system is synchronized to a particular state, which can be accomplished by using a synchronizing word. Computing a shortest synchronizing word is of interest for practical purposes, e.g. for a shorter testing time. However, computing a shortest synchronizing word is an NP–hard problem. Therefore, heuristics are used to compute short synchronizing words. GREEDY is one of the fastest synchronizing heuristics currently known. In this thesis, we present approaches to accelerate GREEDY algorithm. Firstly, we focus on parallelization of GREEDY. Second, we propose a lazy execution of the preprocessing phase of the algorithm, by postponing the preparation of the required information until it is to be used in the reset word generation phase. We suggest other algorithmic enhancements as well for the implementation of the heuristics. Our experimental results show that depending on the automata size, GREEDY can be made 500⇥ faster. The suggested improvements become more effective as the size of the automaton increases."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kitle-kaynak, veri kümeleri için yüksek kaliteli etiketleri makul maliyetler ile elde etmek için kullanılan popüler bir yöntemdir. Bu kitle-kaynak yöntemiyle etiketlenen veri setleri, sonrasında gözetimli veya yarı-gözetimli sınıflayıcıların eğitimi için kullanılır. Bu da, bu prosedür sonucunda oluşan sınıflayıcı performanslarının kitle çalışanlarının atadığı etiketlerin kalitesi/güvenirliliğine bağlı olduğu anlamına gelmektedir - düşük güvenirlilik genellikle yetersiz çalışan sınıflayıcılara sebep olur. Pratikte, kitle-kaynak veri kümelerin-deki etiket güvenirliliği, eldeki etiketleme işinin zorluğu, katılımcı kitle çalışanlarının özellikleri ve motivasyonu, veya etiketlenecek dokümanların zorluğu gibi birçok faktöre bağlı olarak büyük ölçüde değişkenlik gösterir. Bu bahsedilen faktörlerin etiketlerin kalitesine etkisini hafifletmek için ise, verilen kitle-kaynak görevini tanımına uygun olarak yerine getirmeyen (spammer) çalışanları, etiketleme sürelerine bakarak belirlemek ve gönderdikleri etiketleri silmek gibi farklı yaklaşımlar mevcuttur. Bu tez, kitle-kaynak yönteminden elde edilen etiket güvenirliliğini iyileştirerek mevcut yaklaşımları tamamlamak amacıyla, etiket güvenirliliği konusunu ilk olarak, gerçek bir etiketleme işi süresince kitle çalışanlarının etiket güvenirliliğinin zamanla nasıl geliş-tiği, ve ikinci olarak etiketlerin etiketlenecek dokümanların zorluğundan nasıl etkilendiği olmak üzere iki açıdan incelemektedir. Kitle-kaynak yöntemi ile etiketlenen veri seti üzerinde yaptığımız analizler sonucunda, kitle çalışanlarının etiket güvenirliliğinin belli sayıda dokümanı etiketledikten son-ra arttığını gözlemledik. Bunun sonucunda ve daha zor dokümanlar için etiket güvenirli-liğinin daha düşük olması bulgusundan yola çıkarak, etiket güvenirliliğini iyileştirmek için yeni bir kitle-kaynak yöntembilimi önermekteyiz. Önerdiğimiz bu metodolojide, kitle-kaynak yöntemiyle etiketlenecek olan elimizdeki etiketsiz veri setini kullanarak, öncelikle küçük bir başlangıç seti üzerinde bir zorluk tahmin edici (predictor) eğitip, sonrasında bu tahmin ediciden yararlanarak başlangıç seti dışında kalan dokümanların zorluk derecesini tahmin etmeyi hedefliyoruz. Bu prosedür, eğitilen tahmin edicinin performansı yeterli seviyeye ulaşana kadar birçok kez tekrarlanabilir. Son olarak, bu adımlar sonucunda elde edilen tahmin edici kullanılarak tespit edilen zor dokümanlar, veri setinin geri kalanından ayrılır ve sadece bu veri kümesinde kalan dokümanlar kitle-kaynak yöntemi ile etiketlenir. Deney sonuçlarımız da, bu yöntemin kitle-kaynak yöntemi ile elde edilen etiketlerin güvenirliliği üzerinde etkili olduğunu göstermektedir.","Crowdsourcing is a popular means to obtain high-quality labels for datasets at moderate costs. These crowdsourced datasets are then used for training supervised or semi-supervised predictors. This implies that the performance of the resulting predictors depends on the quality/reliability of the labels that crowd workers assigned -- low reliability usually leads to poorly performing predictors. In practice, label reliability in crowdsourced datasets varies substantially depending on multiple factors such as the difficulty of the labeling task at hand, the characteristics and motivation of the participating crowd workers, or the difficulty of the documents to be labeled. Different approaches exist to mitigate the effects of the aforementioned factors, for example by identifying spammers based on their annotation times and removing their submitted labels. To complement existing approaches for improving label reliability in crowdsourcing, this thesis explores label reliability from two perspectives: first, how the label reliability of crowd workers develops over time during an actual labeling task, and second how it is affected by the difficulty of the documents to be labeled. We find that label reliability of crowd workers increases after they labeled a certain number of documents. Motivated by our finding that the label reliability for more difficult documents is lower, we propose a new crowdsourcing methodology to improve label reliability: given an unlabeled dataset to be crowdsourced, we first train a difficulty predictor on a small seed set and the predictor then estimates the difficulty level in the remaining unlabeled documents. This procedure might be repeated multiple times until the performance of the difficulty predictor is sufficient. Ultimately, difficult documents are separated from the rest, so that only the latter documents are crowdsourced. Our experiments demonstrate the feasibility of this method."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok kullanıcılı analitik oturumlarda, katılımcılar verileri analiz eder ve paylaşılan bir vizyona doğru işbirliği yapar. Bu karar verme süreçleri zorludur ve genellikle çok fazla zaman alır. Bu tezde, çok kullanıcılı analitik oturumlarda karar vermeyi kolaylaştırmak için bir sistem sunuyoruz. Sistemimiz bir masa üstü kurulum ve analitik yardımcıdan oluşmaktadır. Masa üstü kurulum yardımıyla yapılan veri görselleştirme, verileri elle tutulur hale getirir, dolayısıyla daha anlaşılır ve doğal yöntemler ile çalışabilir. Katılımcılar masadaki verilerle eşzamanlı etkileşimde bulunurken, yardımcı aracı devam eden görüşmelerini anlar ve veriler hakkında ek bilgi sunar. Buna ek olarak, analitik yardımcı katılımcıların görselleştirilen veriyle alakalı ya da günlük hayata ait ucu açık soruları cevaplandırabilmekte, gerekçelerini sunarak katılımcıların fikirlerini destekleyebilmekte ya da reddebilmekte, katılımcıların toplantının amacından sapmasına engel olmaya çalısarak toplantının üretebilirliğini verimliliğini korayabilmektedir. Genel olarak, veri görselleştirmesini analitik aracıyla birleştirerek, sistemimiz analitik süreci hızlandırır, keşif sürecini geliştirir ve önceki oturumların özetlerini kullanarak sonraki oturumlara rehberlik eder.","In multi-user analytical sessions, participants analyze data and collaborate toward a shared vision. These decision-making processes are challenging and generally prolonged. In this thesis, we introduce a system for facilitating decision-making in multi-user analytical sessions. Our system is comprised of a tabletop setup and an assistive analytical agent. The tabletop, as a medium for data visualization, makes data tangible, hence more comprehensible and natural to operate with. Simultaneously, while the participants interact with the data on the table, the assistant agent understands their ongoing conversations and offers extra information about the data. In addition, the agent answers the participants' questions either regarding the data or open-domain ones, supports or rejects their ideas by providing its reasoning, and preserves the productivity and the efficiency of the session by confirming that the participants do not deviate from the session's goal. Overall, by combining data visualization with the analytical agent our system accelerates the analytical process, fosters exploration through it, and guides next sessions using previous sessions' summarizations."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"El yazısı tanıma alanında yapılan pek çok çalışma İngilizce, Arapça ve Çince gibi dillerin yazılarını konu almaktadır. Türkçe için yapılmış sınırlı çalışmaların arasında çevrimiçi tanıma konusunda eksiklik vardır. Bu tez çalışmasıyla ilk kez olarak, en gelişmiş teknolojiyi içeren bir yalıtık ve kısıtsız şekilde yazılmış Türkçe kelime tanıma sistemi gerçekleştirilmiştir. Saklı Markov Modelleri kullanılan sistem önişleme, öznitelik çıkarma, optik modelleme ve dil modelleme birimlerinden oluşmaktadır. Sistem, orta ölçekli bir dağarcıkla tasarlanıp daha sonra büyük dağarcıkla çalışır hale getirilmiştir. Türkçe yazının Latin alfabesi kullanan diğer yazı sistemleri ile olan benzerlikleri, literatürde kullanılan pek çok tekniği Türkçe için de kullanılabilir kılar. Ancak Türkçe'ye has bazı özellikler tanıma işlemini güçleştirmektedir. Bunlardan ikisi gecikmiş vuruşlar ve çok fazla sayıda olan dağarcık dışı kelimelerdir. Bu tezde her iki problem de ayrıntılı şekilde ele alınmış ve bazı çözümler üretilmiştir. Gecikmiş vuruşlar için net bir tanım oluşturulmuş ve bu tanım kullanılarak bir dizi önişleme yöntemi arasından Türkçe'ye en uygunu bulunmuştur. İngilizce UNIPEN veri kümesi ve Türkçe verilerden oluşan diğer bir küme üzerinde yapılan testlerde en iyi sonuç, bu vuruşların silinmesi yöntemi ile elde edilmiştir. Bu şekilde yapılan önişleme ile İngilizce'de 1,000 kelimelik dağarcık için %2.23 artışla %86.1 tanıma başarısı gözlenirken Türkçe'de %2.03 artışla %91.7 tanıma oranı yakalanmıştır. Tanıma sisteminin çözümleme aşamasında kelime-altı birimler kullanılarak dağarcık dışı kelimelerin tanıma başarısına olan olumsuz etkisinin giderilmesi sağlanmıştır. Ayrıca, N-gram istatistiksel dil modelleri de kullanılmıştır. Geniş dağarcıklı tanıma için gövde-ekler şeklinde kelime-altı birimlerin kullanılması ile elde edilen %67.9 tanıma başarısı, kelimelerin kullanılması ile elde edilen başarıdan (%63.8) daha fazla olarak ölçülmüştür.","Handwriting recognition in general and online handwriting recognition in particular has been an active research area for several decades. Most of the research have been focused on English and recently on other scripts like Arabic and Chinese. There is a lack of research on recognition in Turkish text and this work primarily fills that gap with a state-of-the-art recognizer for the first time. It contains design and implementation details of a complete recognition system for recognition of Turkish isolated words. Based on the Hidden Markov Models, the system comprises pre-processing, feature extraction, optical modeling and language modeling modules. It considers the recognition of unconstrained handwriting with a limited vocabulary size first and then evolves to a large vocabulary system. Turkish script has many similarities with other Latin scripts, like English, which makes it possible to adapt strategies that work for them. However, there are some other issues which are particular to Turkish that should be taken into consideration separately. Two of the challenging issues in recognition of Turkish text are determined as delayed strokes which introduce an extra source of variation in the sequence order of the handwritten input and high Out-of-Vocabulary (OOV) rate of Turkish when words are used as vocabulary units in the decoding process. This work examines the problems and alternative solutions at depth and proposes suitable solutions for Turkish script particularly. In delayed stroke handling, first a clear definition of the delayed strokes is developed and then using that definition some alternative handling methods are evaluated extensively on the UNIPEN and Turkish datasets. The best results are obtained by removing all delayed strokes, with up to 2.13% and 2.03% points recognition accuracy increases, over the respective baselines of English and Turkish. The overall system performances are assessed as 86.1% with a 1,000-word lexicon and 83.0% with a 3,500-word lexicon on the UNIPEN dataset and 91.7% on the Turkish dataset. Alternative decoding vocabularies are designed with grammatical sub-lexical units in order to solve the problem of high OOV rate. Additionally, statistical bi-gram and tri-gram language models are applied during the decoding process. The best performance, 67.9% is obtained by the large stem-ending vocabulary that is expanded with a bi-gram model on the Turkish dataset. This result is superior to the accuracy of the word-based vocabulary (63.8%) with the same coverage of 95% on the BOUN Web Corpus."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir sıfırlama dizisi, verilen bir özdevinimin tüm durumlarını aynı duruma getirmeye yarayan bir girdi dizisidir. J. Černý n durumlu bir özdevinim için en kısa sıfırlama dizisi boyunun (n-1)^2'den daha uzun olamayacağı varsayımında bulunmuştur. Bu varsayım günümüzde Černý sanıtı olarak adlandırılmaktadır. Bu yarım asırlık eski varsayım hala açıktır ve sonlu durum özdevinim kombinatoryal teorisinde en uzun süre çözülemeyen problem olarak kabul edilmektedir. Literatürde yürütülen çalışmalardan bir tanesi, n durum sayısına sahip tüm özdevinimleri ele alarak ve bu özdevinimlerin hepsinde sanıtın doğru olup olmadığı kontrol ederek, belli bir n durum sayısına sahip özdevimler için Černý sanıtının doğruluğunu kontrol etmektir. Bu, sadece 2 girdili ve durum sayısı 12 veya daha az olan tüm özdevinimler için bile hesaplama açısından yoğun bir işlemdir. Arama işlemlerini hızlandırmak için çok çekirdekli CPU'lar kullanan paralel hesaplama yöntemleri daha önce denenmiştir. Bu tezde, Černý sanıtını yanlışlayan bir özdevinim arayışını hızlandırmak için Alanda Programlanabilir Kapı Dizileri (APKD) kullanımı üzerine çalışılmaktadır. Sonlu bir durum özdevinimin en kısa sıfırlama dizisi boyunu hesaplayan bir tasarım sunulmaktadır. Önerilen tasarım, donanım tasarımlarının paralel hesaplama imkanlarıyla zaman performansını optimize ederek uygulanmaktadır.","A synchronizing sequence for an automaton is a special input sequence that sends all states of the automaton to the same state. J. Černý conjectured that the length of the shortest synchronizing sequence of an automaton with n states cannot be greater than (n-1)^2, which is known today as the Černý conjecture. This half-a-century old conjecture is still open and it is considered to be the most long-standing open problem in the combinatorial theory of finite state automata. One research line that has been pursued in the literature is to check if the conjecture holds for a fixed number of states n, by considering all automata with n states and checking if any of these automata falsifies the conjecture. This is a computationally intensive task, even for automata up to a dozen of states and only two input symbols. To accelerate the search parallel computation approaches using multicore CPUs have been tried before. In this thesis, we study the use of FPGAs to accelerate the search for an automaton falsifying the Černý conjecture. We present a design to calculate the minimum length synchronizing sequence of a finite state automaton. The proposed design is implemented with the parallel computing capability of hardware designs while optimizing the time performance."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hiperçizge parçalama literatürde oldukça popüler bir problemdir. Dağıtık algoritmalar ve VLSI devre tasarımı gibi uygulamaların performasi bu yöntemle büyük ölçüde arttırılabilir. Son 20 yılda, hiperçizgeyi hızlı bir şekilde parçalayabilen araçlar geliştirilmiştir. Ancak bu problem NP-Zor olduğu için, bu araçlar sezgisel yöntemlere dayanmaktadır. Bu yüzden genelde optimal olmayan sonuçları bulmaktadırlar. Optimal hiperçizge problemi üzerine sezgisel yöntemlere dayalı çalışmalara nazaran çok daha az sayıda araştırma bulunmaktadır. Bu tezde, literatürdeki bir çok metriğe göre optimal parçalamayi bulan, PHaraoh isimli koşut hiperçizge parçalama aracı sunulmaktadır. Optimal sonuçların bulunması sayesinde, böyle bir araç, daha önceden geliştirilen hiperçizge parçalama araçlarının gerçek performansını, olası en iyi sonuçile karşılaştırarak ölçmemizi sağlar. PHaraoh herhangi bir parçalama ile başlatılabilir ve bu sonucu sürekli olarak geliştirmeye çalışır. Bu sayede, istenen optimal hiperçizge parçalama islemini verilen sürede tamamlayamasa bile, baslangıçta verilen parçalamanın kalitesini iyileştirebilir. Gerçek hayattaki uygulamalarda karşılaşılan hiperçizge modelleri üzerinde yaptığımız deneylere göre, PHaraoh pratikte en çok kullanılan araçların ürettiği parçalamaların kalitesini dal ve sınır arama yöntemini kullanarak büyük ölçüde iyileştirmektedir. Arama uzayında bulunan optimal parçalamanın bulunma süresini kısaltmak icin, ""usta yamak"" ve ""iş çalma"" yöntemlerine dayalı koşut algoritmalardan faydalandik. Daha önceki çalışmalarımızda ve bu tezde yaptığımız deneylere göre hiperçizge parçalama problemi icin dal ve sınır ağacındaki öğelerin sırası PHaraoh'ın performansını önemli oranda etkilemektedir. Bu tezde, değişik sıralama yöntemleri önerip, bunların PHaraoh'ın çalışma süresini nasıl değiştirdiğini ve bu değişikliğin nedenlerini hiperçizgelerin özelliklerine bağlayarak açıkladık.","Hypergraph partitioning into K parts has many applications in practice such as distributed algorithms and very large scale integrated circuit (VLSI) design. There are various tools proposed in the literature which can partition a given hypergraph very fast. However, since the problem is NP-Hard and the traditional approaches heavily use heuristics, these tools do not provide an optimal partition. There is limited research on partitioning hypergraphs optimally. In this thesis, we proposePHaraoh, a parallel hypergraph partitioner that can provide optimal partitions for many metrics used in the literature. Such a partitioner is important in practice since it enables us to evaluate the true performance of the existing tools. Furthermore, PHaraoh can be started with an initial partition. Thanks to that, even an optimal solution is not found within the given time limit, PHaraoh improves the cost of the provided initial partition. Experimental results on hypergraphs obtained from real life matrices show that the quality of the partitions of existing tools can be improved significantly for most of the hypergraphs. In order to increase the speed up the search-space exploration, we experimented with both master-slave and work-stealing parallelization. It also has been shown that the runtime of the algorithm highly depends on the order of the items in the branch and bound tree. In this study, we propose different ordering strategies which can offer great speed ups depending on the characteristics of the hypergraph."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tek bir etmen için yol bulma problemi, bir başlangıç noktasından hedef noktasına gitmek için hiç bir engelle çarpışmayacak bir şekilde takip edeceği bir patika bulmadır. Çoklu etmenler için yol bulma problemi (MAPF) de her etmen için benzer bir patika bulmayı hedeflemektedir; öyle ki, herhangi iki etmen patikalarını takip ederken birbiriyle çarpışmasın. MAPF hesaplama karmaşıklığı açısından zor bir problemdir. Bu tezde, MAPF probleminin robotikteki uygulamalarından esinlenerek daha genel bir problem (GMAPF) üzerinde çalışılmıştır; bu problemde, her etmen gideceği yere varmadan önce bazı yerlere de uğramak isteyebilir. GMAPF problemini çözmek için çözüm kümesi programlama (ASP) kullanılarak ve hesaplanan yolların robotlar tarafından uygulanabilirliği ile ilgili testler entegre edilerek, yeni bir algoritma geliştirilmiştir. Geniş ortamlarda tanımlanmış ve çok sayıda etmen içeren problemlerin çözümlerinin daha verimli bir şekilde hesaplanabilmesi için, melez GMAPF için geliştirilen bu algoritma temel alınarak yeni hiyerarşik ve fırsatçı yöntemler geliştirilmiştir. Tez kapsamında geliştirilen tüm yöntemlerin, otonom depolama sistemleri bağlamında yapılan deneylerle etkinlikleri gösterilmiştir.","Pathfinding for a single agent is the problem of planning a route from an initial location to a goal location in an environment, without colliding with any obstacles. Multi-agent pathfinding (MAPF) also aims to plan such routes for each agent such that no two agents collide with each other. MAPF is an intractable problem, because agents must avoid the collision with each other. We study a generalized version of MAPF (GMAPF) in the context of robotics (i.e., autonomous warehouses), where multiple robots must visit some locations (e.g., to collect some items) on the way to their destinations without colliding with any obstacles in the environment. In this thesis, we introduce a novel method to solve GMAPF problems using the expressive logic-based language of Answer Set Programming (ASP) and the efficient ASP solvers. Moreover, to ensure that the robots follow collision-free trajectories, we introduce an intelligent method for feasibility checks and their integration to our ASP-based approach to GMAPF. To further improve the scalability of our method to solve hybrid GMAPF problems, we introduce a hierarchical method to handle problem instances over large environments. Based on that, we introduce a greedy algorithm handle instances with large number of robots We experimentally evaluate our methods over randomly generated problem instances, to show the scalability of our hierarchical and greedy methods, and usefulness of ASP-based hybrid pathfinding."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda, veri gizliliği, özel veritabanları hakkında bilgi paylaşan veri sahipleri için büyük bir endişe haline gelmiştir. Bu konuyla ilgilenmek için, veri sahipleri veri kümeleri hakkında kısmi bilgilerin (yani, medyan, histogramlar) ifşa edilmesi veya özel niteliklerin veri gizliliği ile fayda arasında dengeyi koruyacak şekilde gizlenmesi gibi çeşitli etki azaltma stratejileri kullanır. Bununla birlikte, bu gibi yöntemler, bazı olumsuz modellerde gizliliğin korunmasında başarısız olmuştur. Örnek olarak, mesafe koruma dönüşümlerinin, kötü niyetli bir kişinin veritabanındaki bilinen birkaç kayda erişebileceği saldırılara karşı savunmasız olduğu gösterilmiştir. Bu çalışmada, benzer şekilde bir sıralama fonksiyonunun çıktısına dayanarak veri kayıtlarının sıralı yayınlarının gizlilik etkilerini analiz ettik. Sıralama fonksiyonlarının tasarımında birçok araştırma yapılmasına rağmen, veritabanı sıralamasının gizlilik konularını analiz etmek halen üzerinde çalışılmamış bir alandır. Birçok gerçek dünya web sitesi, sıralamanın kendisinin mahremiyete duyarlı olmadığı varsayılarak veri kayıtlarının sıralamasını yayınlamaktadır. Bu sıralamalara örnek olarak üniversite, iş, banka kredisi başvuruları ve hastane istatistiklerinin çeşitli kategorilerdeki değerlendirmeleri verilebilir. Bu çalışmada, sıralamalarla ilgili sorunsuz görünen bilgilerin ciddi gizlilik sızıntılarına neden olabileceğini gösterilmektedir. Özellikle, özel verilerden birkaç bilinen örneğe sahip bir rakibin, sıralama bilgisini kullanarak bilinmeyen bir kaydın gerçek özellikleri hakkında çıkarım yapabileceğini gösteriyoruz.","In recent years, data privacy has become a major concern for data owners who share information on private databases. In order to deal with this issue, data owners employ various mitigation strategies including disclosing partial information on datasets (i.e., mean, median, histograms) or obfuscating the private attributes in a way that keeps a balance between data privacy and utility. However, such methods have failed to preserve privacy under certain adversary models. As an example, distance preserving transforms are found to be vulnerable to attacks in which adversary has access to a few known records in the database. In this work, we similarly analyze the privacy implications of rank publication of data records based on the output of a ranking function. While much research has gone in the design of a ranking function, analyzing privacy issues of database rankings is still a novel problem. Many real-world websites reveal ranking of data records assuming that ranking itself is not privacy sensitive. Examples of such rankings are evaluations of universities, jobs, bank credit applications and hospital statistics on various categories. Our work shows that seemingly naive information about rankings can cause severe privacy leakages. In particular, we show that an adversary with a few known samples from the private data can infer about the actual attributes of an unknown record by utilizing the ranking information."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sınırlı ve düşük kaliteli görüntüler içeren bir çok bölütleme probleminde bölütlenecek nesne ile ilgili istatistiksel şekil ön bilgisini kullanmak bölütleme sonuçlarını önemli derecede iyileştirmektedir. Ancak, şekil uzayında olasılık yeğinlik fonksiyonunun tanımlanması, özellikle şekil çok doruklu bir şekil yeğinlik fonksiyonundan geliyorsa, zorlu ve araştırmaya açık bir problemdir. Literatürde parametrik olmayan şekil ön bilgisinden yararlanarak bir eğitim kümesinden şekil önsel dağılımını öğrenen yöntemler bulunmaktadır. Bu yöntemler, sınırlı ve düşük kaliteli veride bulunan nesneleri sonsal dağılımın en büyüğü kestirimi yöntemi ile bölütler. Ancak bu yöntemler, veriden gelen bilgi ile bulunan bölütleme sınırlarının, sonsal dağılımın en büyüğü kestirimi sonsal dağılımın istenilen doruğuna yakınsayacak şekilde iyi bir ilklendirme olduğu kabullenmesini yapar. Bu kabullenme ile ilgili iki temel problem vardır. Birinci problem, veri kötüleştikçe bu yöntemlerin istenen çözüm olmama ihtimali olan bir yerel en iyi çözümünde takılı kalmasıdır. İkinci problem, ilklendirmenin iyi olduğu durumda istenilen yerel en iyi ¸çözüme gidilse bile, sonsal dağılımın farklı doruklarındaki diğer olası çözümler ile ilgili bir bilgi vermemesidir. Bu tezde, çok doruklu sonsal dağılımlardan gelen şekillerin verinin yeterince iyi olmadığı durumlarda bölütlenmesi için yöntemler önermekteyiz. Önerdiğimiz ilk yöntem bölütleme problemini şekil ve öz nitelik ortak sonsal dağılımı olarak temsil eder. Bir eğitim veri kümesinden öğrenilen ortak şekil ve öz nitelik önsel dağılımı kullanılarak sonsal dağılımın en büyüğü kestirimi yöntemi ile bölütleme sonucu elde edilir. İkinci olarak bölütleme problemine Bayesçi çıkarım bakış açısından bakmaktayız. Bu tezde Markov zinciri Monte Carlo örneklemesi tabanlı, sonsal dağılımdan örnekler üreten iki farklı yöntem önermekteyiz. Bu tezdeki son katkı olarak ikili şekil dağılımlarını, yerel şekil ön bilgisi ve Boltzmann makinasından yararlanarak öğrenen yeni bir şekil modeli önermekteyiz. Bu tezde, üretici modeller bölütleme problemi için kullanılmamış olsa da bu amaçla kullanılabilmeleri mümkündür. Bu tezde tanıtılan yöntemlerin kaynak kodları https://github.com/eerdil adresinde erişime açık olacaktır.","In many image segmentation problems involving limited and low-quality data, employing statistical prior information about the shapes of the objects to be segmented can significantly improve the segmentation result. However, defining probability densities in the space of shapes is an open and challenging problem, especially if the object to be segmented comes from a shape density involving multiple modes (classes). In the literature, there are some techniques that exploit nonparametric shape priors to learn multimodal prior densities from a training set. These methods solve the problem of segmenting objects of limited and low-quality to some extent by performing maximum a posteriori (MAP) estimation. However, these methods assume that the boundaries found by using the observed data can provide at least a good initialization for MAP estimation so that convergence to a desired mode of the posterior density is achieved. There are two major problems with this assumption that we focus in this thesis. First, as the data provide less information, these approaches can get stuck at a local optimum which may not be the desired solution. Second, even though a good initialization directs the segmenting curve to a local optimum solution that looks like the desired segmentation, it does not provide a picture of other probable solutions, potentially from different modes of the posterior density, based on the data and the priors. In this thesis, we propose methods for segmentation of objects that come from multimodal posterior densities and suffer from severe noise, occlusion and missing data. The first framework that we propose represents the segmentation problem in terms of the joint posterior density of shapes and features. We incorporate the learned joint shape and feature prior distribution into a maximum a posteri- ori estimation framework for segmentation. In our second proposed framework, we approach the segmentation problem from the approximate Bayesian inference perspective. We propose two different Markov chain Monte Carlo (MCMC) sampling based image segmentation approaches that generates samples from the posterior density. As a final contribution of this thesis, we propose a new shape model that learns binary shape distributions by exploiting local shape priors and the Boltzmann machine. Although the proposed generative shape model has not been used in the context of object segmentation in this thesis, it has great potential to be used for this purpose. The source code of the methods introduced in this thesis will be available in https://github.com/eerdil."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Robotların insanlara gidecekleri yerler için yardım ettiği büyük ve dinamik ortamlarda(örn. alışveriş merkezleri), kişiselleştirilmiş yollar hesaplamak zorlayıcıdır. Hesaplama zorluğu açısından, kullanıcıların varış yerine gitmeden önce bazı yerleri ziyaret etme kısıtlamaları yüzünden, yol bulma problemi zorlu olur. Üstelik kişiselleştirilmis¸ yollar hesaplanırken, ilgili bilgiler gösterilmeli (örn. sağduyu bilgileri, geçici bilgiler, ortamın haritası), bilgi tabanlarından çekilmeli ve yol bulma sırasında entegre edilmelidir. Sosyal açıdan ise, insan-robot etkileşimi göz önüne alındığında, yol bulma problemleri için soruları/cevapları göstermek, anlaşılabilir bir diyalog sistemi ve uzun yolları kısaltma yöntemleri gerektirir. Bu tezde, kişiselleştirilmiş yol bulma problemleri için her iki çeşit zorluğa da değiniyoruz. Özellikle, kısıtlamalı yol bulma problemlerini (CPF) tanımlayıp, zorlu oldğgunu kanıtlıyoruz. CPF problemlerine çözüm olarak kişiselleştirilmiş yollar bulmak için çözüm kümesi programlama (ASP) ve ilgili bilgi tabanlarını kullanarak, bilgiye dayalı bir yöntem öneriyoruz. Kişiselleştirilmiş yol bulma için insan-robot diyaloglarını göstermek ve ilgili bilgileri çıkarıp soruları/cevapları formal dillere Anlamsal Ağ teknolojileri kullanarak dönüştürmek amacıyla, kontrollü doğal diller öneriyoruz: H2R-CNL, R2H-CNL. CPF problemlerini daha verimli çözmek ve kullanıcıya çözümleri daha doğal sunabilmek için, Hiyerarşik Bilgi-Zengini Anlamsal Haritalar (HSM) adında, ortamı farklı soyut seviyelerde hiyerarşik olarak gösteren bir matematiksel model öneriyoruz. Aynı zamanda, kişiselleştirilmis¸ yolları hesaplamak ve sunmak için yöntemler öneriyoruz. CPF yöntemlerimizin ölçeklenebilirliğini ve faydasını göstermek için gerçek bir alışveriş merkezi ortamında ve bazı rastgele haritalarda oluşturulmuş örnekler üzerinde deneysel olarak değerlendiriyoruz.","In large dynamic environments (e.g., shopping malls) where robots help/guide humans to their destinations, computing personalized routes becomes challenging. From the computational complexity perspective, due to the users' constraints that ensure visiting some locations before their destination, the path finding problem becomes intractable. Moreover, for computing personalized paths, relevant knowledge (e.g., commonsense knowledge, temporary knowledge, map of the environment) should be represented, extracted and integrated within path finding. From the social perspective, considering human-robot interactions, expressing queries/answers regarding path finding problems require an understandable dialogue interface and methods to summarize very long itineraries. In this thesis, we address both sorts of challenges to solve personalized path finding problems. In particular, we formally define the constrained path finding (CPF) problem and prove its intractability. We introduce a knowledge-based method to compute personalized solutions to CPF problems, using answer set programming (ASP) and relevant knowledge bases. We introduce controlled natural languages, H2R-CNL and R2H-CNL, to represent human-robot dialogues for personalized path finding, and methods to extract relevant knowledge and transform queries/answers to/from formal languages using Semantic Web technologies. To solve CPF problems more efficiently and to present solutions to users more intuitively, we introduce a novel mathematical model, called Hierarchical Knowledge- Rich Semantic Maps (HSMs), that hierarchically represents an environment at different levels of abstraction. We also introduce methods for computing and presenting personalized paths over HSMs. We experimentally evaluate our CPF methods over a real-world shopping mall environment and some randomly generated instances, to show their scalability and the usefulness of HSMs."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilginin yorumlanması söz konusu olduğunda veri görselleştirme vazgeçilemez bir yöntem olarak ortaya çıkmakta. Bilinen veri görselleştirme yöntemlerinin asıl amacı, kayıt edilmiş gözlemlerin anlamlı görsellere dönüştürülerek algılanmasının kolaylaştırmaktır. Bir ekran yardımı ile gerçekleştirilen bu pasif sanal görselleştirme yöntemi her ne kadar çeşitlilik sağlamak konusunda esneklik sunsa dahi sadece görsel algımızı kullanmamıza izin vermektedir. Fakat fiziksel görselleştirmeler görsel algımıza ek olarak diğer duyularımızı kullanmamızı da sağlayarak daha etkili bir deneyim yaratmaktadır. Süregelen görselleştirme yöntemlerine kıyasla fiziksel görselleştirmelerin kanıtlanmış faydaları bulunsa da, bu fiziksel görselleştirmeleri geçekleştirmek diğerleri kadar verimli ve hızlı bir şekilde yapılamamaktadır. Bu bağlamda, iyi belirlenmiş tasarım kuralları çerçevesinde oluşturulmuş fiziksel modellerin oluşturulması bir ön koşul olmaktadır. Bunun ardından gerçekleştirilmesi gerekli olan ikinci adım ise üretime hazır katı modellerin oluşturulmasıdır. Ancak küçük bir veri seti için dahi bir kaç tane fiziksel veri modeli oluşturmak oldukça yıldırıcı ve vakit alıcı bir işe dönüşmektedir. Bu ana sorunsal göz önünde bulundurulup tez konusu olarak bir yazılım geliştirilmiştir. Tez dahilinde sunulan yazılım fiziksel model oluşturma sürecindeki zorlukları ortadan kaldırmak amacını taşımaktadır. Kullanıcı tarafından belirlenen değişkenler ve kullanılmak istenilen veri dosyasına göre daha önceden belirlenmiş kurallar çerçevesinde oluşturulan modeller bu yazılım tarafından üretilmektedir. Günümüzde giderek yaygınlaşan ve erişilmesi kolaylaşan dijital üretim yöntemlerinin kullanılması, veri fizikselleştirme konusunda önemli bir rol oynamaktadır. ' Önce genel hatlar, talep edilirse detay' düşüncesi ana fikir olarak alınıp, gerek duyulduğunda daha fazla detayı fiziksellikten ödün vermeden sunabilmek için, üretilen fiziksel modeller ile çalışan bir arttırılmış gerçeklik yazılımı da ek olarak geliştirilmiştir.","Data visualization is an indispensable methodology for interpretation of information. The key purpose of traditional data visualization methods is to convert observed records into meaningful visuals to ease the cognition of trends. This virtual,passive technique on a display o↵ers flexibility to create wide range of di↵erent visualization designs utilizing, however, only visual perception. Physical visualizations, on the other hand, enable sensations other than mere visual input, thus enhancing the experience and the impact. Although physical visualizations have some certain proven benefits over traditional visualizations, generating them is not as e↵ective and quick. In that regard, need of physical models shaped around well-defined design rules are a prerequisite. Moreover, digital construction of the designed solid models for manufacturing is the next step to be achieved. However, even for a small set of data, constructing several models becomes a discouraging and highly time consuming task. This main problem is covered in this thesis by the implementation of an authoring tool. The introduced tool alleviates the burden of physical model generation process. Predefined models under design rules are generated in accordance with both the data input and adjusted parameters by the user. Utilization of digital fabrication techniques that are nowadays becoming widespread and easy to access is the key for physicalization. In order for an ""Overview first, detail on demand"" approach, an augmented reality tool is also introduced to work with designed models so as to retain the physicality while presenting more detailed information such as exact values of data points along with augmented graphics if desired."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Veri her yerdedir. Yazının icadından itibaren, gösterim araçları veriyi insan ve veri arasında bir etkileşim şeklinin doğal olarak kurulmasına neden olan gözlemlenebilir bir duruma getirdi. İnsan-veri etkileşim (İVE) ortamında, veri gösterimleri ve analitik sistemler insan ve veri arasında aracı olarak rol oynarlar. İnsan ve veri arasında bir ortam üzerinden gerçekleşen bir haberleşme modeli olarak etkileşimin kavramsallaştırıldığı yeni bir İVE tanımı öneriyorum. Böyle bir etkileşim, insan ve veriden kaynaklanan mesajların karşılıklı gönderimi ile gerçekleştirilir. Bu mesajların zamanlaması ve içerikleri ise bahse konu analitik sistemin özelliklerinin nesnel bir şekilde hesaplanmasını mümkün kılar. İVE'nin karmaşık yapısını sistematik bir şekilde incelemek için kullandığım metodoloji, İVE'yi içerisinde analitik sistemlerin kendi özelliklerine göre konumlandırılabileceği çok boyutlu bir uzay olarak ele alır. Analitik sistemlerin özellikleri ise bahse konu uzay boyutlarının kesin tanımlarına bağlı olarak yapılır. İsimleri hızlı cevap verebilirlik, haberleşme ortam seviyesi, birim görev çeşitliliği, yakınlık etkeni ve devamlılık seviyesi olan beş veri analitik sistem özelliği tanımlıyor ve bu özelliklerin nesnel olarak nasıl hesaplandığını gösteriyorum. Eksenleri hızlı cevap verebilirlik ve haberleşme ortam seviyesi özelliklerinden oluşan iki boyutlu bir Kartezyen sistem olan ve üzerine tezimde detayları açıklanan veri analitik sistemlerinin yerleştirildiği İVE uzayını görsel olarak keşfediyorum. Bu yerleşimde görsel olarak tespit edilebilen ve alt alanlar olarak adlandırdığım paternler, bahse konu analitik sistemlerle ilgili kullanıcıların yapmış olduğu etkileşimlerden toplanan nesnel, davranışsal ve öznel verilerin nitel ve nicel analizleriyle karakterize edilir.","Data is everywhere. Starting with the invention of writing, representation artifacts brought the data to observable state which led to natural establishment of an interaction form between human and data. In the human-data interaction (HDI) environment, data representations and analytic systems act as an intermediary role. I suggest a new definition for HDI in which this interaction is conceptualized as a communication model over a set of media. The interaction occurs with the exchange of messages originated from both human and data. Timing and content of the messages are employed to facilitate objective evaluation of properties of analytic system in question. To systematically investigate the complex nature of HDI, my methodology postulates the phenomenon as a high-dimensional space in which data analytic systems could be positioned based on their properties. Evaluation of the properties are performed based on solid definitions of the dimensions. I define five properties for data analytic systems, namely, responsiveness, communication media level, unit task diversity, closeness factor, and progressiveness level, and demonstrate how these properties could be objectively calculated. I visually explore the HDI space in which data analytic systems reported in my thesis are plotted on a two-dimensional Cartesian system whose axes are responsiveness and communication media level. Visually identifiable patterns in this plot, which I call realms, are characterized by quantitative and qualitative analysis of objective, behavioral, and subjective data collected during the user interaction with the corresponding analytic system."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda akıllı cihazlar günlük hayatta önemli bir yer edindi. Bu cihazların yaygınlaşması, onlara birçok yeni işlev kazandırmakla beraber, yine de temel amaçları iletişim olarak kaldı. WebRTC (İnternet Tabanlı Gerçek Zamanlı İletişim) teknolojisinin ortaya çıkması ve akıllı cihazlarda kullanılabilir olması, gerçek zamanlı multimedya iletişimine olanak veren uygulamaların artmasına neden olacaktır. WebRTC'nin amacı uçtan uca bilgi taşınması için standartlar ve programcı arayüzleri belirlemek olsa da, işin güvenlik kısmı uygulama geliştiricilere bırakılmıştır. Bu tezde, akıllı kartların sağladığı güvenli depolama ve işlem özelliklerinin yardımı ile, WebRTC için güvenli anahtar üretilmesi ve dağıtımı sorunları ele alınarak güvenli çoklu ortam iletişimi kurulumu hedeflenmektedir. Değişik kriptografik algoritmalar akıllı kartlar üzerinde denenmiş ve sonuç olarak özet zinciri üzerine bir yöntem kullanılmasina karar verilmiştir. Tasarlanan mekanizma değişik marka Java kartlar üzerinde çalıştırılmış ve testlerin sonucları 1 saniyenin altında bir sürede anahtar üretiminin mümkün olduğunu göstermiştir. Buna ek olarak, özet zinciri uzunluğu değiştirilerek çeşitli analizler yapılmış ve bunun sonucunda hedeflenen bir anahtarın mümkün olan en iyi sürede üretilebilmesi için gerekli olan zincir uzunlukları hesaplanmıştır. Devamında, anahtar üretim mekanizmasının WebRTC teknolojisine dayanan Medya Güvenlik Platformu ile entegrasyonuna yer verilmiştir. Mekanizmanın sisteme uyumu için tasarlanan sinyalleşme trafiği göz önüne alınarak, entegrasyon başarı ile tamamlanmıştır. Sonuçlar, daha önce kullanılan açık anahtarlı sisteme göre daha iyi performans alındığına işaret etmektedir.","Recently, smart devices have become more and more prevalent in the daily life. The spread of these devices introduced various use cases; however, communication has always been their primary functionality. With the development of WebRTC (Web Real- Time Communication) and the availability of this technology on smart devices, applications offering real-time multimedia communication features will become more pervasive. Though WebRTC presents a promising set of standards and interfaces for the task of carrying data from one end to another, there are security issues that are left in the hands of the application developers. In this thesis, we aim to achieve secure multimedia communication by tackling the key generation and distribution issue of WebRTC platform using a smart card for secure storage and operations. We tested different cryptographic algorithms on smart cards, and resultantly we designed a mechanism based on hash chains. This mechanism allowed synchronous generation of keys at both sides. The mechanism was implemented and tested on different brands of Java Cards. The results of the tests indicate that it is possible to produce a key under one-second time. In addition, the results were analyzed to optimize generation times of particular keys by adjusting chain length parameter of the mechanism. Consequently, the key generation method was integrated into Media Security Platform of Netas¸ Telecommunications A.S¸ ., which is based on WebRTC. The integration was performed under the guidance of a signaling scheme drafted for the message traffic for the key agreement. In conclusion, the successful integration and better results indicate an improvement over a previously used public key system."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Robotik uygulamalara yönelik melez durumsal planlama için paralel ve çevrimdışı olan yeni bir algoritma (HCP-ASP) öneriyoruz. HCP-ASP, robotun harekete geçiren eylemlerini ve algılama eylemlerini monoton olmayan Çözüm Kümesi Program- lama (ASP) ile modelleyip, durumsal planı tanımlayan ağacın dallarını paralel olarak ASP çözücüsünü kullanarak hesaplamaktadır. Robotun eylemlerinin sürekli uzayda uygulanabilirliğinin testlerini (çarpışma testi gibi), bu eylemlerin ASP'deki formel gösterimine harici atomları kullanarak entegre etmektedir. Robotun, içinde bulunduğu ortamın durumu hakkında kısmi bilgi sahibi olması ve algılama eylem- lerinin deterministik olmayan etkileri, ASP'de monoton olmayan yapılar ve seçici kurallar vasıtası ile biçimlendirilmektedir. Bu şekilde ASP'de gösterimi yapılan eylemlere göre ASP çözücüleri tarafından hesaplanan melez durumsal planın her bir dalı, robotu hedefine ulaştırabilen ve uygulanabilir bir eylem sıralamasını ve icrasını temsil etmektedir. Bu nedenlerle, geliştirdiğimiz melez durumsal plan- lama algoritması, hem gösterimsel olarak hem de hesaplama açısından yenilikçidir.","We introduce a parallel offline algorithm for computing hybrid conditional plans, called HCP-ASP, oriented towards robotics applications. HCP-ASP relies on modeling actuation actions and sensing actions in an expressive nonmonotonic language of answer set programming (ASP), and computation of the branches of a conditional plan in parallel using an ASP solver. In particular, thanks to external atoms, continuous feasibility checks (like collision checks) are embedded into formal representations of actuation actions and sensing actions in ASP; and thus each branch of a hybrid conditional plan describes a feasible execution of actions to reach their goals. Utilizing nonmonotonic constructs and nondeterministic choices, partial knowledge about states and nondeterministic effects of sensing actions can be explicitly formalized in ASP; and thus each branch of a conditional plan can be computed by an ASP solver without necessitating a conformant planner and an ordering of sensing actions in advance. We apply our method in a service robotics domain and report experimental evaluations. Furthermore, we present performance comparisons with other compilation based conditional planners on standardized benchmark domains."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar temelli iletişim, CMC, iki veya daha fazla elektronik aygıtın kullanılmasıyla oluşan bir iletişim türüdür. CMC, teknolojinin gelişmesiyle birlikte insanlar arasında daha çok tercih edilen bir iletişim türü haline gelmeye başladı. Bilgisayar temelli teknolojinin gelişimi ile birlikte, haber merkezleri, arama motorları ve Facebook, Twitter, Reddit gibi birçok sosyal medya platformu ortaya çıktı. Sosyal medya platformlarında, bir kullanıcı kendi görüşünü yayınlayabilir, tartışabilir veya diğer kullanıcıların görüşlerini de okuyabilir ve paylaşabilir. Bu durumun oluşturduğu veri, eğer filtrelenip analiz edilirse, araştırmacılara kamuoyu ve kültür hakkında önemli bilgiler verebilir. Twitter, 2006 yılında kurulmuş ve kısa sürede dünya çapında yaygınlaşan bir sosyal ağ hizmetidir. Bu hizmette 310 milyonun üzerinde aylık aktif kullanıcı bulunmaktadır ve bu kullanıcılar 2016 yılı itibariyle günlük 500 milyondan fazla tweet üretmektedir. Twitter verisi; hacmi, hızı ve çeşitliliği nedeniyle konvansiyonel yöntemler kullanılarak analiz edilememektedir. Analiz yapabilmek için veri miktarını azaltacak kümeleme veya örnekleme yöntemleri gereklidir. Geniş bir anlamda bakıldığında, belgeleri kümelemek için kullanılan benzerlik ölçüleri ikiye ayrılabilir: Sözcüksel ve anlamsal benzerlik. Sözcüksel benzerlik, belgeler arasında sözdizimsel benzerlik arar. Sözcüksel benzerliği hesaplamak genellikle hesaplama olarak hafif bir işlemdir, ancak anlamsal bütünlüğü göz ardı ettiği için kümeleme amaçları için kesin olarak doğru olmayabilir. Öte yandan anlamsal benzerlik, anlamsal değeri ve benzerliği hesaplamak için sözcükler arasındaki ilişkileri araştırır. Anlamsal benzerlik, genel olarak sözcüksel benzerlikten daha doğru olmasına rağmen, hesaplaması daha zordur. Çalışmalarımızda büyük veri özelliklerine sahip kısa verilerin hafif hesaplamalarla doğru bir şekilde kümelenmesini amaçlıyoruz. Sözcüksel ve anlamsal benzerliğin birlikte bulunduğu karma bir yaklaşım öneriyoruz. Yaklaşımımızda, sözcüksel dizim kullanarak kümeler yaratıp, anlamsal vektör sunumlarını kullanarak da kümelerin etkileşimli birleşimini sağlıyoruz.","Computer-mediated communication, CMC, is a type of communication that occurs through use of two or more electronic devices. With the advancement of technology, CMC has started to become a more preferred type of communication between humans. Through computer-mediated technologies, news portals, search engines and social media platforms such as Facebook, Twitter, Reddit and many other platforms are created. In social media platforms, a user can post and discuss his/her own opinion and also read and share other users' opinions. This generates a significant amount of data which, if filtered and analyzed, can give researchers important insights about public opinion and culture. Twitter is a social networking service founded in 2006 and became widespread throughout the world in a very short time frame. The service has more than 310 million monthly active users and throughout these users more than 500 million tweets are generated daily as of 2016. Due the volume, velocity and variety of Twitter data, it cannot be analyzed by using conventional methods. A clustering or sampling method is necessary to reduce the amount of data for analysis. To cluster documents, in a very broad sense two similarity measures can be used: Lexical similarity and semantic similarity. Lexical similarity looks for syntactic similarity between documents. It is usually computationally light to compute lexical similarity, however for clustering purposes it may not be very accurate as it disregards the semantic value of words. On the other hand, semantic similarity looks for semantic value and relations between words to calculate the similarity and while it is generally more accurate than lexical similarity, it is computationally difficult to calculate semantic similarity. In our work we aim to create computationally light and accurate clustering of short documents which have the characteristics of big data. We propose a hybrid approach of clustering where lexical and semantic similarity is combined together. In our approach, we use string similarity to create clusters and semantic vector representations of words to interactively merge clusters."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Olası konfigürasyonların sayısı konfigürasyon seçenekleri sayısıyla üssel olarak katlanarak arttığından, yüksek seviyede konfigüre edilebilir yazılım sistemlerinin tam kapsamlı testleri genellikle uygulanabilir değildir. Kombinatoryal Etkileşim Sınama yöntemleri, yazılım sistemlerinin konfigürasyon uzaylarını sistematik bir şekilde örneklendirip, sadece seçilen konfigürasyonları test ederler. Örneklendirme, tipik olarak, t li kapsayan dizi olarak adlandırılan bir kombinatoryal objenin hesaplanması ile gerçekleştirilir. Her biri ayrık bir kümeden değerler alan konfigürasyon seçenekleri ile bu seçenek değerleri kombinasyonlarının bazılarını geçersiz kılan kısıtlamalar (eğer mevcutsa) da icçeren bir konfigürasyon uzayı verildiğinde, bir t li kapsayan dizi, her bir t li seçenek kombinasyonu için seçenek ayarlarının geçerli kombinasyonlarının en az bir kez göründüğü geçerli bir konfigürasyon dizisidir. Kapsayan dizilerin kullanılmasının temel gerekçesi, t veya daha az seçeneğin ayarlarının neden olduğu sistem davranışlarını etkin bir şekilde kullanabilmeleridir. Sonuç olarak, kapsayan diziler, konfigüre edilebilir sistemlerin, girdi parametre alanlarının, grafik kullanıcı arayüzlerinin, ağ protokollerinin ve yazılım ürünlerinin sistematik testleri de dahil olmak üzere birçok alanda test yöntemi olarak yaygın bir şekilde kullanılmaktadır. Kapsayan diziler, gerçek test maliyetini azaltmak için, seçilen konfigürasyon sayısını azaltmayı hedeflerler. Bunu yaparken aslında her konfigürasyonun test edilme maliyetinin aynı olduğunu varsayarlar. Fakat, bu tezde, pratikte maliyetin bir konfigürasyondan diğerine farklılık gösterdiği ampirik olarak gösterilmiştir ve maliyetler farklı olduğunda, konfigürasyon sayısını azaltmak, gerçek test maliyetini düşürmekle aynı şey değildir. Bu sorunun üstesinden gelmek için, ilk olarak, etkileşim sınama takımlarını hesaplarken test maliyetlerini hesaba katan, t li maliyeti dikkate alan kapsayan diziler adında, yeni bir kombinatoryal nesne tanımlanmıs¸tır. Özetle, gerçek test maliyetini, seçenek ayar kombinasyonlarının seviyesinde modelleyen bir maliyet fonksiyonu ile zenginles¸tirilmis¸ bir konfigürasyon uzay modeli gözönüne alındığında, bir t li maliyeti dikkate alan kapsayan dizi, seçilen konfigürasyonların sayısından ziyade, verilen maliyet fonksiyonunu ""en aza indirgeyen"" bir standart t li kapsayan dizidir. Daha sonra, iki farklı tür mevcut kapsayan dizileri, yani standart kapsayan dizileri ve test durumlarına ba˘glı kısıtları dikkate alan kapsayan dizileri, maliyeti dikkate alan etkiles¸im sınama takımlarına dönüştürmek için özel hesaplama algoritmaları geliştirilmiştir. Büyük yaygın olarak kullanılan ve yüksek yapılandırılabilir yazılım sistemleri üzerinde gerçekleştirilen deneylerin sonuçları, maliyeti dikkate alan kapsayan dizilerin mevcut kapsayan dizilerle karşılaştırıldığında, kapsama özelliklerini olumsuz şekilde etkilemeden, gerçek test maliyetini önemli ölçüde azaltabileceğini kuvvetle önermiştir. Tüm bu çalışmalarda gözlemlenen bir şey doğru ve hassas maliyet fonksiyonlarının gelis¸tirilmesinin zor olduğudur. Maliyet fonksiyonu ne kadar az doğru ve ne kadar az hassas ise, test maliyetini daha fazla azaltma imkani o kadar azalacaktır. Buna çözüm olarak da, konfigürasyon uzaylarındaki maliyet modelini otomatik olarak keşfetmek için verimli ve etkili yaklaşımlar geliştirilmiştir.","Exhaustive testing of highly configurable software systems is generally infeasible as the number of possible configurations grows exponentially with the number of configuration options. Combinatorial Interaction Testing approaches systematically sample the configuration spaces and test only the selected configurations. The sampling is typically carried out by computing a combinatorial object, called a t-way covering array. Given a configuration space model that includes a set of configuration options, each of which takes a value from a discrete domain, together with inter-option constraints (if any), which invalidate certain combinations of option values, a t-way covering array is a set of valid configurations in which each valid combination of option values for every combination of t options appears at least once. The basic justification for using covering arrays is that they can e ectively exercise the system behaviors caused by the values of t or fewer options. Consequently, covering arrays have been widely used for testing in many domains, including the systematic testing of configurable systems, input parameter spaces, graphical user interfaces, network protocols, and software product lines. To reduce the actual cost of testing, covering arrays aim to reduce the number of configurations selected. By doing so, they implicitly assume that the cost of testing each configuration is the same. In this thesis, we, however, empirically demonstrate that, in practice, the cost often varies from one configuration to another and that when the cost varies, reducing the number of configurations is not necessarily the same as reducing the actual cost of testing. To overcome this issue, we first define a novel combinatorial object for testing called, a cost-aware covering array, which takes the cost of testing into account when computing interaction test suites. In a nutshell, given a configuration space model, enhanced with a cost function, which models the actual cost of testing at the level of option value combinations, a t-way cost-aware covering array is a standard t-way covering array that ""minimizes"" the given cost function, rather than the number of configurations selected. We then develop specialized construction approaches to turn two di erent types of existing covering arrays, namely standard covering arrays and test case-aware covering arrays, into cost-aware interaction test suites. The results of our experiments conducted on large, widely-used, and highly-configurable software systems strongly suggest that costaware covering arrays can significantly reduce the actual cost of testing without adversely affecting the coverage properties, compared to existing covering arrays. One thing we observe in all these studies is that it could be diffcult for practitioners to develop accurate and precise cost functions. The opportunity to further reduce the testing cost decreases as the cost function is less accurate or less precise. To address this, we develop effcient and effective approaches to automatically discover the cost model in configuration spaces."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda artan mobil cihazlar sayesinde üretilen ve saklanan verinin miktarında büyük artışlar gerçekleşmektedir. Milyonlarca mobil cihaz (akıllı telefon, tablet ve hatta giyilebilir teknolojiler) GPS çipi ile topladığı verileri konum-zaman verisi ile eşleştirerek saklamaktadır. Yeni nesil uygulamalar konum verisine dayalı geliştirilmekte olup topladıkları bu veriler üzerinden yürütülen analiz çalışmalarıyla ticari fayda sağlamaktadırlar. Toplanan bu veriler, analiz ic¸in üç üncü parti kimselerle de paylaşılabilir. Konum verisi hassas kabul edilerek işlenmesi, başta Avrupa'da olmak üzere kanunlarla belirlenmis¸ olup, veri işleme için öncelikle veri koruma uygulamaları tatbik edilmesi zorunlu kılınmıştır. Paylaşım esnasında kişinin sadece kimlik bilgilerinin çıkarılması mahremiyeti korumaya yetmemektedir. Kamuya açık bilgiler ile eşleştirilerek mahremiyet açıklarına sebebiyet verdiği bilinmektedir. Örneğin kişinin akşam saatindeki konumu ev adresini işaret etmektedir ve buradan kimliğine dair bilgilere erişilebilir. Konum verisinin bu şekilde açıklara yol açmaması için veri dönüşüm teknikleri geliştirilmiştir. Veri dönüşüm teknikleri, veriyi, istatistiksel özelliklerini koruyarak, bir tanım kümesinden başka bir tanım kümesine dönüştüren ve böylece kişinin kimliğini gizlemeyi hedefleyen mahremiyet koruyucu tekniklerden biridir. Bu tez çalışmasında, mesafe koruyan veri dönüşüm tekniklerinin demahremiyeti koruma açısından güvenilir olmadığını göstermekteyiz. Bu çalışmada iki farklı atak yöntemi ortak bir atak senaryosunu icra etmektedirler. Çalışmalarımızı konum verisi alanına yoğunlaştırıp konum ve hareket yörüngeleri üzerinde detaylandırdık. Bu çalışmalarda saldırganın veri tabanına dayalı, erişebildiği tüm kaynaklardan edinebileceği bilgileri de kullanarak gerçekleştireceği ataklar ile mahremiyet açıkları ortaya çıktığını göstermekteyiz. Bu ataklar ile hedef hareket yörüngesinin eldeki bilgiler ışığında benzerlerinin tekrar oluşturulmasının mümkün olduğu gösterilmiştir. Ayrıca bu ataklar ile bir hareket yörüngesinin geçtiği veya geçmediği yerler hakkında yorum yapmak mümkün hale gelmektedir. Konum verisi üzerinde olan diğer çalışmamızda geliştirdiğimiz teknik ile, mesafe koruyan dönüşüm teknikleri ile dönüştürülen bir veri tabanının ilişkileri yayınlandığında, saldırgan bu veriler üzerinden veri tabanındaki diğer konum bilgilerine erişebilmekte ve mahremiyet ihlallerini göstermektedir. Bu çalışmada, saldırgan büyük bir sşehirde toplanan konum veri tabanı hakkında biraz bilgi ile hedef konumları sokak seviyesinde bulabilmektedir.","In recent years, we witness a great leap in data collection thanks to increasing number of mobile devices. Millions of mobile devices including smart phones, tablets and even wearable gadgets embedded with GPS hardware enable tagging data with location. New generation applications rely heavily on location information for innovative business intelligence which may require data to be shared with third parties for analytics. However, location data is considered to be highly sensitive and its processing is regulated especially in Europe where strong data protection practices are enforced. To preserve privacy of individuals, first precaution is to remove personal identifiers such as name and social security number which was shown to be problematic due to possible linking with public data sources. In fact, location itself may be an identifier, for example the locations in the evening may hint the home address which may be linked to the individual. Since location cannot be shared as it is, data transformation techniques have been developed with the aim of preventing user re-identification. Data transformation techniques transform data points from their initial domain into a new domain while preserving certain statistical properties of data. In this thesis, we show that distance-preserving data transformations may not fully preserve privacy in the sense that location information may be estimated from the transformed data when the attacker utilizes information such as public domain knowledge and known samples. We present attack techniques based on adversaries with various background information. We first focus on spatio-temporal trajectories and propose an attack that can reconstruct a target trajectory using a few known samples from the dataset. We show that it is possible to create many similar trajectories that mimic the target trajectory according to the knowledge (i.e. number of known samples). The attack can identify locations visited or not visited by the trajectory with high confidence. Next, we consider relation-preserving transformations and develop a novel attack technique on transformation of sole location points even when only approximate or noisy distances are present. We experimentally demonstrate that an attacker with a limited background information from the dataset is still able to identify small regions that include the target location points."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde, elektronik bankacılık, sağlık ve sosyal hizmetler, ticari uygulamalar ve hukuki uygulamalar gibi güvenlik sağlayan birçok uygulama biyometrik tabanlı kimlik doğrulama kullanmaktadır. Fakat, her bir kişinin biyometrik verisi benzersiz ve değiştirilemez olduğundan, söz konusu biyometrik verinin gizliliği bir kez ifşa edildiğinde, aslında bu biyometrik veri sonsuza dek kullanılamaz hale gelecektir. Bu nedenle, kullanıcıların biyometrik verilere güvenmesi aslında zordur. Bu tez ile, yukarıda bahsi geçen sorunun üstesinden gelmek adına, yeni bir protokol olan SKA-CaNPT protokolünü öneriyoruz: Periyodik Dönüşüm ile Oluşturulan İptal Edilebilir ve Geri Dönüştürülemez Biyometrik Verilerin Kullanıldığı Güvenli Anahtar Anlaşması. Bu çalışmada, biyometrik verileri iptal edilebilir ve geri dönüştürülemez kılmak için periyodik bir dönüşüm fonksiyonu kullanmaktayız. SKA-CANPT protokolünün sonunda, kullanıcı ve sunucu, kullanıcının biyometrik verisinin özellik noktalarına dayanan bir simetrik paylaşılan anahtar üzerinde anlaşırlar. SKA-CANPT protokolünün kavram kanıtı için parmak izlerini kullandık. Protokolde, parmak izlerinin özellik noktaları çıkarıldıktan sonra, öncelikle periyodik dönüşüm fonksiyonu kullanıyoruz ve sonrasında ise eşik tabanlı bir niceleme yöntemiyle daha önceden belirlenmiş komşuluk ilişkilerine göre bu özellik noktalarını kategorize ediyoruz. SKA-CANPT protokolü turlu bir düzende çalışır ve her turda sunucu, parmak izlerinden çıkarılan özellik noktalarının benzerlik puanına bakarak kullanıcının kabul veya reddine karar verir. Buna ek olarak, dönüştürülmüş veriler bir şekilde ifşa edilirse, dönüşüm fonksiyonunun girdilerinden biri değiştirerek yeni bir iptal edilebilir ve geri dönüştürülemez biyometrik veri oluşturulabilir. Ayrıca, protokolümüze farklı güvenlik analizleri uyguladık. İlk olarak, üzerinde anlaşılan anahtarların rasgeleliğini analiz etmek için Shannon'un entropi analizini kullandık ve sonuçlar ilgili anahtarların yeterli ölçüde rasgele olduklarını gösterdi. İkinci olarak, üzerinde anlaşılan anahtarların değişkenliğini analiz etmek için Hamming uzaklığı analizini kullandık ve sonuçlar farklı insanların biyometrik verilerinin kullanımı ile oluşturulan anahtarların birbirlerinden farklı olduklarını gösterdi. Dahası, düşük IKGR (Yanlış Anahtar Üretimi Oranı), yüksek CKGR (Doğru Anahtar Oluşturma Oranı) ve SKA-CANPT protokolünün sahip olduğu yüksek saldırı karmaşıklığına bakarak söyleyebiliriz ki önerdiğimiz protokol kaba kuvvet, yeniden oynatma ve kimliğe bürünme saldırılarına karşı güvenlidir.","Nowadays, many of the security-providing applications use biometric-based authentication, such as electronic banking, health and social services, commercial applications and law enforcement. However, since each person's biometrics is unique and not replaceable, once it is compromised, it will be compromised forever. Therefore, it is indeed hard for the users to trust biometrics. To overcome this problem, in this thesis, we propose a novel protocol SKA-CaNPT: Secure Key Agreement Protocol using Cancelable and Noninvertible Biometrics based on Periodic Transformation. In this research, we use a periodic transformation function to make our biometrics cancelable and noninvertible. At the very end of our SKA-CaNPT protocol, the user and the server make an agreement on a symmetric shared key that is based on the feature points of the biometrics of the user. As a proof of concept, we apply our SKA-CaNPT protocol on fingerprints. In our protocol, after extracting minutiae from the fingerprints, we first employ a periodic transformation function and then we categorize our minutiae points in a predefined neighborhood by using a threshold-based quantization mechanism. Our SKA-CaNPT protocol runs in a round-manner and in each round, the server decides about the acceptance or rejection of the user according to the similarity score of the common minutiae. In addition, if the transformed data is compromised, it can be renewed just by changing one of the inputs of our transformation function. Besides, we apply different security analyses on our protocol. First of all, we use Shannon's entropy to analyze the randomness of the agreed keys, and it shows that the generated keys have enough randomness. Secondly, to analyze the distinctiveness of the agreed keys, we use the Hamming distance metric, results of which show that the keys of different people are distinguishable from each other. Moreover, according to the low IKGR (Incorrect Key Generation Rate), high CKGR (Correct Key Generation Rate) and high attack complexity possessed by our SKA-CaNPT protocol, we can conclude that our scheme is secure against brute-force, replay and impersonation attacks."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Internet ve mobil kullanıcıların finansal kurumların alternatif kanallarını kullanımı gittikçe artmaktadır. Dolandırıcılıktan korunmak için finansal kurumlar telefonlara kısa mesaj olarak gönderilen tek kullanımlık şifreler gibi iki faktörlü kimlik doğrulama yöntemlerini kullanmaktadırlar. _ Işlem doğrulama için kullanılan diğer bir yönelim ise işlemlerin kullanıcılar tarafından imzalandığı kriptograk protokollerdir. Bu tip yaklaşımların gerçeklenmesinde müsteriler ile finansal kurumlar arasındaki uçtan uca güvenliği sağlamak adına her müşterinin bir açık-gizli anahtar ikilisine sahip olması gerekir. Özellikle küçük ölçekli kurumlarda, bu tip bir işlem doğrulama sistemi ve açık anahtarların saklanması Bulut servisi olarak taşeron hizmeti olarak alınabilmektedir. Ancak bu tip bir taşeron modelinde bile kurumlar uçtan uca güvenliği sağlamak içcin kullanıcılarının açık anahtarlarına erişmek isteyebilirler. Bu nedenle, kullanıcıların mahremiyetlerini taşeron veritabanı hizmet sağlayıcısına karşı koruyabilmek için mahremiyeti koruyan açık anahtar deposuna ihtiyaç vardır. Bu tezde Path ORAM mekanizmasını kullanan bu tip bir mahremiyet korumalı açık anahtar deposu geliştirilmiştir. Bu kapsamda sorguların normal SQL sorguları olduğu ve verilerin de Path ORAM'in standart dışı ağaç veri yapısı yerine ilişkisel veritabanlarında saklandığı bir durum için Path ORAM bağdaştırma katmanları geliştirdik. Böylece standart dışı ögeler hem finansal kuruluştan hem de Bulut sağlayıcıdan saklanmış oldu. Sistemimizin başarımını değişik veritabanı boyları, bağlantı modelleri ve sorgu tipleri için analiz ettik. Bunun sonucunda da Path ORAM tabanlı sistemimizin normal bir bilgisayarın sunucu olarak kullanıldığı durumda bile marjinal seviyede ek işlemsel maliyet getirdiğine ve pratik olarak kullanılabileceğine kanaat getirdik.","Internet and mobile users have been using financial institutions' alternative channels for their financial transactions with an increasing rate. In order to avoid frauds, the financial institutions make use of second factor authentication tokens such as one-time passwords sent to mobile phones as text. Another trend of such transaction verification is utilizing fully cryptographic protocols, in which the transactions are signed by the users. In the implementation of such an approach, in order to provide end-to-end security between the financial institution and its client, each client must have a public-private key pair. In some cases, especially for small-scale institutions, such a transaction verification system is fully outsourced as a Cloud service including clients' public keys. However, even in this outsourced model, the institutions need to access their clients' public keys for end-to-end security. In such a case, in order to provide privacy of the clients against the outsourced database, we need a privacy-preserving public key repository. In this thesis, we developed such a privacy-preserving public key repository based on Path ORAM mechanism. We have developed adaptation layers for Path ORAM so that the queries are performed via regular SQL queries and the data is stored in iv a regular relational database, rather than Path ORAM's non-standard data structure. In this way, the non-standard features are hidden from both the financial institutions and the Cloud provider. We analyzed the performance of our system under different database sizes, network connection models and query types. We conclude that such a Path ORAM based system is feasible to be used in a practical system since even with a regular computer used as a server, the computational overhead is at marginal level."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde bir çok uygulama kısmi belirli verilerin saklanması ve yönetimi (XML veritabanları ve belge odaklı veritabanları gibi) üzerine kurulmuştur. Bu veriler çoğu zaman güvenilmeyen üçüncü şahıs ve kurumlarla paylaşılmaktadır. Bu durum bireylerin veri mahremiyetine yönelik temel sorunları da beraberinde getirmektedir. Bu çalışmada, hiyerarşik verilerde kullanılmak üzere geliştirilmiş anonimleştirme teknikleri gösterilmektedir. Ayrıca bu çalışma ile hiyerarşik verilerin anonimleştirilmesi için günümüz tekniklerinin kolaylıkla çözemeyeceği veri mahremiyeti sorunlarına genelleştirme ve anatomlaştırma tekniklerine dayalı yenilikçi çözümler getirilmektedir. Veri genelleştirmesi, verilerin neredeyse düşük seviye değerlerini (ör: grip) daha yüksek seviye kavramlara (ör: solunum yolu hastalığı) dönüşmesini ihtiva eder. Veri değerlerine genelleme ve silme yapılarak, iki önemli mahremiyet standardı $k$-anonimleme (fertleri $k$ tane elemanlı gruplara koyarak saklar) ve $\ell$-çeşitlilik (bir kişinin, herhangi bir mahrem bilgiyle ilişkilendirilebilme ihtimalini limitler) revize edilmiş ve hiyerarşik verilere uygulanmıştır. Bu standartları destekleyen fayda duyarlı algoritmalar sunulmuştur. Algoritmaların ve buluşsal yöntemlerin değerlendirmesi için iki farklı üniversite veri setiyle, biri sentetik diğeri gerçek veri seti olmak üzere, deneyler yapılmıştır. Deney sonuçlarına göre karşılaştırılabilir gizlilik garantileri sağlayan ilgili yöntemlerden önemli ölçüde daha iyi performans elde edilmiş ve gösterilmiştir. Veri anatomlaşlaştırması, belirteç verilerle, mahrem veriler arasındakı bağlantıyı maskeler ve genelleme zorunluluğunu ortadan kaldırır. Bu sayede daha yüksek verim sağlamaya imkan tanır. Hiyerarşik verilerde yüksek boyutluluk sebebiyle verim sağlamanın ciddi endişe kaynağı olmasına rağmen anatomlaştırma avantajı hiyerarşik verilerde bu güne kadar önerilmemiştir. Bu tezde, anatomlaştırma işleminin hiyerarşik verilere nasıl uygulanağını tanımlanmış ve gösterilmiştir. Ayrıca klasik l-çeşitlilik yöntemi geliştirilerek yeni bir mahremiyet standardı (p,m)-gizliliği önerilmiştir. (p,m)-gizliliği, m tane herhangi bir mahrem verinin bir kişiyle ilişkilendirilme ihtimalini p ile limitler. Deneyler sonucunda daha zor mahremiyet standartlarında bile örnek teşkil edecek performans sağladığını gözlemlenmektedir.","Many applications today rely on storage and management of semi-structured information, e.g., XML databases and document-oriented databases. This data often has to be shared with untrusted third parties, which makes individuals' privacy a fundamental problem. In this thesis, we propose anonymization techniques for privacy preserving publishing of hierarchical data. We show that the problem of anonymizing hierarchical data poses unique challenges that cannot be readily solved by existing mechanisms. We addressed these challenges by utilizing two major privacy techniques; generalization and anatomization. Data generalization encapsulates data by mapping nearly low-level values (e.g., influenza) to higher-level concepts (e.g., respiratory system diseases). Using generalizations and suppression of data values, we revised two standards for privacy protection: kanonymity that hides individuals within groups of k members and `-diversity that bounds the probability of linking sensitive values with individuals.We then apply these standards to hierarchical data and present utility-aware algorithms that enforce the standards. To evaluate our algorithms and their heuristics, we experiment on synthetic and real datasets obtained from two universities. Our experiments show that we significantly outperform related methods that provide comparable privacy guarantees. Data anatomization masks the link between identifying attributes and sensitive attributes. This mechanism removes the necessity for generalization and opens up the possibility for higher utility. While this is so, anatomization has not been proposed for hierarchical data where utility is a serious concern due to high dimensionality. In this thesis we show, how one can perform the non-trivial task of defining anatomization in the context of hierarchical data. Moreover, we extend the definition of classical `-diversity and introduce (p,m)-privacy that bounds the probability of being linked to more than m occurrences of any sensitive values by p. Again, in our experiments we have observed that even under stricter privacy conditions our method performs exemplary."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"STEM, öğrencilerin bilim, teknoloji, mühendislik ve matematik alanlarında alacakları eğitimi her seviyede desteklemek için geliştirilmiş bir müfredattır. Son zamanlarda, bilgisayar bilimi ve algoritmik düşünme eğitiminin geleceği sekillendirecek unsurlar olarak kabul görmektedir ve STEM+C |STEM'in hesaplama(computing) ile birleşimi gibi programlar ile bu konular teşvik edilmektedir. STEM+C yalnızca içerdiği alanlara dair konuların daha kolay anlaşılır ve eğlenceli bir şekilde sunulmasını değil, verilecek eğitimin her kesimden insanlar için ekonomik ve ulaşılabilir olmasını da amaçlanmaktadır. STEM+C ideal bir eğitim ortamının öğrencinin aktif bir şekilde derse katılımıyla sağlanabileceğini ve temel kavramların teknoloji ve pratik eğitim teknikleriyle desteklenmesini savunmaktadır. Bu çalışmada, STEM+C konularının daha iyi anlatılabilmesi amacıyla, HandsOn- SEA ismini verdiğimiz, düşük maliyetli, tek serbestlik dereceli, seri elastik eyleyici tahriği ile kuvvet denetimi yapabilen bir eğitim cihazı öneriyoruz. Cihazın özgünlüğü, tutacak ve kasnak bölümleri arasına yerleştirilen çapraz esnek eklem ile sağlanmaktadır. Bu eklemin döner eksende gerçekleştirdiği sapma miktarı ölçülerek tutacak kısmına uygulanan kuvvetler hesaplanıp geri beslenerek kuvvet denetimi yapılmaktadır. HandsOn-SEA, admittans türü bir cihaz olarak, etkileşim sırasında güvenliği ve istenilen seviyede şeffalığı sağlayabilmek için kapalı çevrim kuvvet denetimi kullanmaktadır ve impedans türü eğitim amaçlı kuvvet denetimi cihazlarını tamamlar niteliktedir. HandsOn-SEA ayrıca daha karmaşık, daha fazla serbestlik dereceli kuvvet geri beslemeli cihazlarının yapı taşı olarak kullanılabilir. HandsOn-SEA, STEM+C konularını öğretmekte etkilidir. Sanal ortamlarla ziksel etkileşim, görselliğin dışında ek bir duyusal iletişim yolu oluşturarak ve öğrenim aktivitesinin daha ilgi çekici ve eğlenceli olmasını sağlayarak oğrencinin katılım kalitesini arttırmaktadır. Bunun yanı sıra, HandsOn-SEA, oğrencinin gelişiminin sayısal olarak ölçülebilmesine ve görsel verileri dokunsal hale getirerek görme engelli oğrencilerinde daha çeşitli eğitim olanaklarından faydalanabilmesine imkan sağlamaktadır. Bu bağlamda, HandsOn-SEA'nın STEM+C eğitimine katılımı için, ziksel insan-robot etkileşiminin temel kavramlarını ve algoritmik düşünmeyi anlatmakta kullanılmak uzere yonlendirmeler sunuyoruz. Fiziksel insan-robot etkileşimi eğitimi için kuvvet geri beslemeli cihazların mekanik tasarımlarının ve denetimlerinin sinerjik doğasını anlatmak üzere laboratuvar modülleri sunuyoruz. Bu modüller, özellikle öğrencilerin kuvvet denetimi sistemlerinin başarımlarını etkileyen temel ödünleşimleri laboratuvar çalışmaları ile tecrube etmelerini sağlamak uzere oluşturulmuş ve öğrenciler tarafından değerlendirilmiştir. Bu deneyler öğrencilerin farklı sertliklere sahip elastik parçalar kullanarak mekanik tasarımla birlikte denetleyiciyi değiştirmelerini ve yaptıkları tasarımsal seçimlerinin kapalı çevrim kuvvet denetimi başarımı üzerindeki etkilerini saptamalarını gerektirmektedir. HandsOn-SEA'nın, insanlarla ziksel etkileşime giren robot sistemlerinde kullanılan admittans denetimci yapılarının ve kuvvet denetimi sistemlerinde karşılaşılan temel ödünleşimlerin anlaşılmasındaki etkililiği, lisans seviyesinde verilen bir robotik dersinde kullanılarak gösterilmiştir. Benzer şekilde, algoritmik düşünmeyi desteklemek uzere kuvvet geri beslemeli cihazların öğrencilere uygulamalı ve interaktif bir eğitim sunacak şekilde kullanımını öneriyoruz. Dokunsal geri beslemenin, öğrencileri ikili karşılaştırmalara yönlendirirken aynı zamanda bilgi saklamasına imkan vermesi, sıralama ve arama algoritmalarının temel kavramlarının anlatılmasında destek sağlamaktadır. Bunun yanı sıra, sanal öğrenme ortamları ile ziksel etkileşim; daha esnek, merak uyandıran ve eğlenceli bir tecrübe sunmakta olup, aynı eğitimin ziksel unsurlar veya sadece görselleştirmeye dayanan uygulamalar ile desteklenmesine göre daha üstün sonuçlar vermektedir. Algoritma eğitiminde, kuvvet denetimli cihazlar aracılığıyla dokunsal geri beslemenin kullanılması öğrenci grupları tarafından değerlendirilmiş ve sıralama problemlerinin çözümü için ihtiyaç duyulan temel bilgileri, teknolojiden bağımsız olarak, anlatmada etkin olduğu görülmüştür.","STEM is a curriculum targeted to be used in all educational levels to support the education of students in four speci c disciplines{science, technology, engineering and mathematics{in an interdisciplinary and applied approach. Recently, as computational thinking and strong foundation in computing have been identi ed as de ning features that are likely to strongly shape the future, major research and development e orts have been put together to also promote computing by programs like STEM+C, where \C"" further emphasizes computing. STEM+C not only aims to make the topics concerning these elds more understandable and enjoyable, but also to make them more accessible and a ordable for every group in the society. STEM+C promotes active learning, in other words, direct involvement of the student in class instead of passively listening, as an essential feature of an ideal learning environment and advocates for the use of technology and hands-on experience for strengthening the understanding of fundamental concepts. We propose HandsOn-SEA, a low cost, single degree-of-freedom, force-controlled educational robot with series elastic actuation, to enable physical interactions with educational tools, helping solidify STEM+C concepts. The novelty of the proposed educational robot design is due to the deliberate introduction of a compliant cross- exure pivot between the actuator and the handle, whose de ections are measured to estimate interaction forces and to perform closed-loop force control. As an admittance-type robot, HandsOn-SEA relies on a force control loop to achieve the desired level of safety and transparency during physical interactions and complements the existing impedance-type force-feedback educational robot designs. HandsOn-SEA also serves as a building block of more complex, higher degrees of freedom force-feedback robot designs. HandsOn-SEA is e ective in the education of STEM+C concepts, as physical interaction with virtual educational environments not only ensures a higher level of student engagement by adding new bi-directional sensorimotor pathway for active student perception, but also improves student motivation by enabling more engaging and exciting learning experiences. Furthermore, HandsOn-SEA allows for quantitative measurements of student progress and enables visually impaired students to bene t from a larger range of educational tools, by replacing certain visual presentations with haptic feedback. Along these lines, we present the integration of HandsOn-SEA into STEM+C education, by providing guidelines for the use of the device for teaching fundamental concepts in physical human-robot interaction (pHRI) at the undergraduate level and for teaching algorithmic thinking at both the high school and undergraduate levels. For pHRI education, we provide a set of laboratory modules with HandsOn-SEA to demonstrate the synergistic nature of mechanical design and control of force feedback devices. In particular, we propose and evaluate ecacy of a set of laboratory assignments that allow students to experience the performance trade-o s inherent in force control systems due to the non-collocation between the force sensor and the actuator. These exercises require students to modify the mechanical design in addition to the controller of the educational device by assigning di erent levels of sti ness values to its compliant element, and characterize the e ects of these design choices on the closed-loop force control performance of the device. We have evaluated the ecacy of introducing HandsOn-SEA into engineering education by testing the device in a senior level robotics course and provide evidence that the device is e ective in providing experience on admittance control architectures for pHRI and instilling intuition about fundamental trade-o s in the design and control of force-feedback devices. To promote algorithmic thinking, we propose to use force-feedback educational robotic devices for hands-on teaching of algorithms and present an interactive tool for teaching several sorting and search algorithms with such educational devices. The addition of haptic feedback to teach algorithmic thinking is advantageous as haptic feedback enables an e ective means of enforcing pairwise comparisons while ensuring data hiding, a key component in explaining several core concepts while teaching several sorting and search algorithms. Furthermore, physical interactions with virtual learning environments paves the way for more exible, engaging and exciting learning experiences, surpassing what can be achieved by basic physical elements or applications based on pure visualization. We have evaluated the ecacy of introducing haptic feedback into teaching algorithmic thinking by testing the proposed force-feedback application with several student groups and provide evidence that the approach is e ective in instilling the core principle of formulating a precise sequence of instructions for performing sorting tasks, in a technology independent manner."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, Türkiye'deki trending topics ve 2023 Türkiye Cumhurbaşkanlığı seçimi ile ilgili gönderilen tweet'ler bağlamında, Twitter üzerindeki koordine edilmiş ma- nipülatif aksiyonları ve seçim süresince gerçekleşen olayların duygu durumu skorları üzerindeki etkisini incelemektedir. Bu çalışmanın iki ana amacı bulunmaktadır. İlk amacı manipülatif eylemlerin trending topics'e girmiş hashtaglerde nasıl gerçek- leştiğini anlamak ve benzer eylemlerin seçimle ilgili tartışmalarda da olup olmadığını kontrol etmektir. İkinci amacı ise toplumsal olayların ve cumhurbaşkanı adayları tarafından kullanılan siyasi dilin Twitter'daki duygu durumu üzerine nasıl yan- sıdığını incelemektir. Analizimiz trending topics'lere atılan tweet'ler ile içerisinde cumhurbaşkanı adaylarınının geçtiği tweet'leri içeren iki veri kümesini kapsamak- tadır. Methodoloji olarak manipülatif eylemlerin belirlenmesi için her tweet'in Twitter tarafından sağlanan askıya alınma durumu kullanılmıştır. Duygu anal- izi bölümünde de tweet'ler, türleri, askıya alınma durumları, içerdiği adaylar ve kullanıcıların ilgili adayları takip etme durumu gibi çeşitli faktörler özelinde in- celenmiştir. Analizimiz sayesinde siyasi olayların ve seçim sonuçlarının yukarıda bahsedilen faktörler üzerindeki etkisine kampsa bir bakış sağlıyor ve seçim süresin- deki olayların duygu durumu üzerindeki yansımaları hakkında bilgiler sunuyoruz.","This thesis examines coordinated activities and reflections of public events via sen- timent scores on Twitter, in the context of trending topics in Turkey and tweets sent related to Turkey's presidential election in 2023. There are two objectives of this study. The first one is to understand how manipulative actions take place on Twitter, especially in trending topics, and to check whether similar actions occur in election-related discussions. The second one is to examine how public events and the political language used by presidential candidates are reflected in Twitter data, espe- cially during the election period. Our analysis encompassed two datasets, consisting of tweets related to trending topics and tweets specifically mentioning the presi- dential candidates. To identify manipulative actions, we leveraged the suspension status of each tweet. Additionally, in the sentiment analysis part, we examined the sentiment scores of tweets based on various factors, including their types, suspension status, mentioned candidates, and the followers' status of the respective candidates. Through our comprehensive analysis, we offer profound insights into the impact of political events and electoral outcomes on the aforementioned dimensions, thereby enhancing our understanding and providing valuable insights into the utilization of political language."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde YouTube, çevrimiçi eğitim için en polüler kaynaklarden bir ihaline geldi. Platformda eğitim içerikli video'lar göz önünde bulundurulduğunda, YouTube arama sonuçlarında erkek video anlatıcılarına yönelik bir cinsiyetçi ön yargı olduğu saptandı. Bu ön yargı hem STEM(Bilim, Teknoloji, Mühendislik ve Matematik) hem de NON-STEM ile ilgili içeriklerde mevcut. Erkek anlatıcılar kadın anlatıcılara göre platformda daha fazla temsil ediyor. Bu yanlılığı daha fazla araştırmak için bu tezde kullanıcıların video'lara yaptığı yorumlar kullanılmıştır. İzleyicilerin etkileşimlerini daha iyi anlamak için yorumlardaki duygu analizi davranışlarını incelemek önemlidir. Ek olarak, kullanıcı etkileşimleri video türleri arasında farklılık da gösterebilir. Bu tez, eğitici YouTube videolarındaki yorumlarda ifade edilen duyguyu davranışını keşfetmeyi amaçlamaktadır. Araştırmanın iki amacı vardır. İlk olarak, kullanıcıların erkek ve kadın anlatıcılara karşı duygu analizi davranışlarını anlamak. İkincisi, farklı eğitim konuları arasındaki duygu davranışının araştırılması. Çalışmanın ilk bölümünde, farklı sıralamalara sahip videolar arasındaki, ikinci bölümünde ise farklı sıralamalara sahip yorumlar arasındaki yorum duygu analizi incelenmektedir. Her iki bölüm için de platformdaki yorum duygu analizleri incelenir ve anlatıcıların algılanan cinsiyetleri ile video konuları arasındaki davranış karşılaştırılır. Bu tez, yorumların altında yatan duygu davranışını video anlatıcılarının algılanan cinsiyetleri ve video'nun konusu bağlamında incelemeyi amaçlamaktadır.","In the digital era, YouTube has become one of the most popular resource for online education. A prior study has reported a bias towards male narrators in YouTube search results for educational videos. Videos with male narrators are exposed more on the platform for both in STEM(Science, Technology, Engineering, and Mathematics) and NON-STEM subjects. To further investigate the bias, the user generated comments are used in this thesis. To better understand viewers' interactions with YouTube videos, it is crucial to explore the sentiment patterns in the comments. Moreover, user engagements differ between genres. This thesis aims to explore the sentiment expressed in comments on educational YouTube videos. The research has two objectives. Firstly, understanding the sentiment behavior of users towards male and female narrators. Secondly, investigating the sentiment pattern between different subjects: STEM and NON-STEM. In the first part of the study, video's ranking on YouTube platform is taken into consideration to further investigate the behavioral change between the videos with different rankings. In the second part, the comment's ranking is taken in to account to understand the comment ranking behavior. For both of the parts the comment sentiment patterns are examined and the behavior is compared between perceived genders of the narrators and subjects. By addressing these objectives, this thesis aims to understand the underlying sentiment behavior behind comments and the differences between the perceived genders of video narrators and subjects in the context of educational content on YouTube."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, zayıf etiketlenmiş biyomedikal verileri ve düzensiz/etiketsiz biyometrik verileri etkili bir şekilde kullanmak için yeni derin öğrenme metodolojilerini tanıtır. Tez üç ana bölüme ayrılmıştır. İlk bölümde, hacim bazında etiketlenmiş CT akciğer görüntüleri kullanılarak zayıf denetimle eğitilmiş 2D ve 3D tekniklerini kullanan iki sınıflandırıcı sunulmaktadır. Tezin ana katkısı, varyasyonel yaklaşımla karşılaştırmalı öğrenme çerçevesini genişleten yeni bir temsil öğrenme yöntemidir. Tezin ikinci bölümünde, web'ten toplanan yüz görüntülerinden yüz özelliklerini öğrenmek için uygulanan varyasyonel karşılaştırmalı tasarımı kullanan bir yarı denetimli yaklaşım sunuyoruz. Bu teknik, VCL-PL olarak adlandırılır ve toplanan görüntülerde bulunan doğal gürültüyü karşılamak için özellikle tasarlanmıştır. Çeşitli deneysel kurulumlar aracılığıyla, yöntem denetimli veya güncel öz denetimli yöntemler üzerinde bir doğruluk artışı gösterir. Tezin son bölümünde, varyasyonel karşılaştırmalı öğrenme ile beta-diverjans formülizasyonunu birleştiren dayanıklı bir öz denetimli öğrenme modeli, VCL, geliştirilir. Bu model, etiketsiz, düzensiz/etiketsiz ve gürültülü veri kümeleriyle kullanıldığında güncel modellerden daha iyi performans sergiler. Bu metodolojik ilerlemelerin geliştirilmesi ve yeni veri kümelerinin tanıtılmasıyla, bu tez, tıbbi alanda zayıf etiketlenmiş verilerden öğrenmeye katkıda bulunur ve biyometrik alanda gürültülü verileri ve düşük veri rejimlerini daha iyi ele alan varyasyonel karşılaştırmalı öğrenme yaklaşımını tanıtır.","This dissertation introduces novel deep learning methodologies for effectively leveraging weakly-labeled biomedical data and uncurated/unlabeled biometric data. The thesis is divided into three major parts. In the first part, we present a classifier that combines 2D and 3D classifiers that are trained with weak supervision using volume-wise labeled CT lung images. The main contribution of the thesis is a new representation learning method, extending the contrastive learning framework with the variational approach. In the second part of the thesis, we present a semi-supervised approach using the variational contrastive design, applied to learning face attributes from web-collected face images. This technique, called VCL-PL, is specifically designed to counter the inherent noise found in the collected images. Through various experimental setups, the method demonstrates an enhancement in accuracy over supervised or state-of-the-art self-supervised methods. The last part of the dissertation develops a robust self-supervised learning model, VCL, that combines variational contrastive learning with beta-divergence. This model exhibits better performance than state-of-the-art models when used with unlabeled, uncurated, and noisy datasets. Through the development of these methodological advancements and the introduction of novel datasets, this dissertation contributes to learning from weakly-labeled data in the medical domain and introduces the variational contrastive learning approach that better handles noisy data and low data regimes, in the biometric domain."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, DECOMPL ve ADRMX adında sırasıyla grup etkinlik tanıma ve alan genelleme problemlerini ele alan iki yaklaşım sunuyoruz. Başlangıçta temel odak noktamız voleybol videolarında grup etkinliklerinin tanınması üzerineydi. Önceki çalışmaların, videoların zamansal özelliklerinden ek hesaplama maliyetlerini tazmin edecek kadar büyük performans iyileştirmelerini gösteremediğini savunuyoruz. Videodaki kare sayısıyla doğru orantılı olan ek hesaplama maliyetini performansta önemli ölçüde bir düşüş görmeden gidermek için önerdiğimiz DECOMPL, tek bir karedeki görsel ve koordinat özelliklerini kullanarak sınıflandırma yapıyor. Voleybol videolarında grup etkinliği tanıma problemi için, bazı probleme özgü katkılar sunuyoruz. Bunlar, etkinliklerin simetrisini kullanmak için yatay döndürmelerden yararlanma, etiketleri ayrıştırarak problemi alt-problemlere bölme, ve takım özelliklerini elde etmek için buluşsal bir yöntemle karedeki insanları takımlara atama gibi unsurları içeriyor. Ayrıca, literatürde yaygın olarak kullanılan Voleybol veri kümesini incelerken kullanılan etiketleme yönteminin örneklerdeki grup kavramını azalttığını ve onları bireysel oyuncuların hareketleri seviyesine indirgediğini fark ettik. Bu sorunu ele almak için, veri kümesini grup kavramını vurgulayarak yeniden etiketledik. DECOMPL, Volleyball ve Collective Activity veri kümeleri üzerinde dikkate değer bir performans sergileyerek, grup etkinlik tanıma konusundaki başarısını göstermektedir. Yaklaşımımız, zamansal yöntemlerle aynı seviyede olup bu alandaki potansiyelini vurgulamaktadır. Videoların farklı alanlardan geldiğini gözlemlediğimiz için, grup etkinlik tanıma probleminin yanısıra, alan genelleme problemini de çalıştık. Alan genelleme için önerdiğimiz yöntem ADRMX, alan değişken özellikleri ve alan durağan özelliklerini birleştirerek toplamsal bir ayrıştırmayla birlikte kullanmaktadır. Modelimizin dayanıklılığını artırmak için örtülü uzayda çalışan yeniden birleştirme stratejisi adlı yeni bir veri arttırma tekniği sunuyoruz. DomainBed değerlendirme testi üzerinde, ADRMX, yedi tanınmış veri kümesindeki ortalama doğruluk ölçütüne göre 14 algoritma arasında en iyi performansı sergilemektedir.","In this thesis, we present two novel methods to address the challenges of group activity recognition and domain generalization: DECOMPL and ADRMX, respectively. Our primary focus is on the recognition of group activities in volleyball videos. We argue that previous temporal methods have not shown significant performance improvements that justify their additional computational cost, which scales linearly with the number of frames. To tackle this, we propose DECOMPL, a non-temporal method that leverages both visual and coordinate features from a single frame to classify the activity in a video. For the task of group activity recognition in volleyball videos, we introduce several problem-specific contributions. These include utilizing horizontal flips to exploit the symmetry of activities, decomposing labels to provide additional feedback through sub-tasks, and employing a heuristic to split team features. Furthermore, during our study of the Volleyball dataset, which is widely used in recent literature, we realized that the labeling scheme degrades the group concept, reducing them to the level of individual actions. We correct for this by providing new reannoations that emphasize the group concept. DECOMPL demonstrates remarkable performance on both the Volleyball dataset and the Collective Activity dataset, showcasing its effectiveness in group activity recognition. Our approach is on par with temporal methods, highlighting its potential in this field. In addition to group activity recognition, we also investigate the domain generalization problem, as videos often come from different domains due to variations in camera orientation and background or due to even the team side change in volleyball videos. ADRMX, our proposed method for domain generalization, incorporates domain variant features along with domain invariant ones with an additive disentanglement. To enhance the robustness of our model, we introduce a novel data augmentation technique called remix strategy, which operates on the latent space to generate synthetic instances. On the DomainBed benchmark, ADRMX achieves state-of-the-art performance among 14 algorithms, as measured by average accuracy across seven well-known datasets."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, mobil uygulama kullanıcı arayüzlerinin (UI'ler) otomatik testi için yenilikçi bir yaklaşım olan text2test'i sunuyoruz. Mobil uygulamalar giderek daha yaygın hale geldikçe, kullanıcı dostu kullanıcı arayüzlerinin sağlanması önemli hale geldi ve bu da verimli test metodolojilerine daha fazla ihtiyaç duyulmasına yol açtı. Bununla birlikte, değişen ekran boyutları, sürümler arasında değişen UI öğeleri nedeniyle test durumu revizyonları gereksinimi UI testlerini zorlaştırır. Bu zorlukların üstesinden gelmek için, Varlık İsimleri Tanıma (NER) ve anlamsal benzerlik hesaplamalarını kullanarak doğal dil cümlelerinden test senaryolarını yürüten Android API'lerini kullanan bir yazılım text2test'i sunuyoruz. Doğal dil test senaryolarının açıklamalarından UI öğelerini ve eylemleri tanımlamak için bir NER modeli eğiterek UI öğeleri ve UI etkileşimleri arasındaki boşluğu dolduruyoruz. Bir uygulamanın UI öğelerinin XML meta verilerini içeren DOM yapısını kullanarak, belirlenen eylemle ilişkili uygun UI öğesini doğru bir şekilde tespitini sağlıyoruz. Son olarak, NER modelimiz tarafından çıkarılan bilgileri ve semantik benzerlik ile tespit edilen öğeleri kullanarak, Android uygulamalarında test senaryolarını yürütebilen bir yazılım geliştirdik. Deneylerimiz, text2test'in öğe-eylem çiftlerini belirlemede \%92'lik bir kesinlik oranı ve beklenen UI öğelerini tespit etmede ortalama \%88'lik bir doğruluk oranı ve Android uygulamalarında test senaryolarını tam olarak yeniden oluşturmak için \%76'lık bir başarı oranı elde ettiğini göstermektedir. Yaklaşımımız, manuel müdahaleyi ve komut dosyası güncelleme ihtiyacını azaltır ve verimli ve güvenilir UI testi için bir çözüm olanağı sunar.","In this work, we present text2test, an innovative approach for automated testing of mobile application user interfaces (UIs). As mobile applications become increasingly prevalent, ensuring robust and user-friendly UIs has become essential, leading to a greater need for efficient testing methodologies. However, testing UIs poses challenges due to varying screen sizes, evolving UI elements across versions, and the need for frequent test case revisions. To address these challenges, we propose text2test, which combines named entity recognition (NER) and semantic similarity computations in a framework using Android APIs to execute test cases from natural language descriptions. We bridge the gap between textual input and UI interactions by training a NER language model to identify UI elements and actions from natural language test case descriptions. Using the DOM structure of an application, containing XML metadata of UI elements, we accurately detect the appropriate UI element associated with the action. Finally, using the information extracted by the NER model and the elements detected using semantic similarity we developed a framework that can execute test cases on Android applications. Our experiments show that text2test achieves a 92\% precision rate in identifying element-action pairs and an average accuracy of 88\% in detecting expected UI elements and a 76\% success rate to fully reproduce test cases on Android applications. Our approach streamlines automated UI testing, reducing manual intervention and the need for frequent script updates and promises a solution for efficient and reliable UI testing."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan hareketliliği, toplumların dokusunu şekillendiren önemli bir katalizör olarak durmaktadır. Toplumsal davranışları anlamanın kritik bir unsuru olarak hizmet ederken etkili politikaların oluşturulmasını da şekillendirmektedir. Bu tez, büyük ölçekli insan hareketliliği verilerinden çıkarılan hareketlilik ağlarını kullanarak insan hareketliliği desenleri ile bilgiye dayalı toplumsal politikaların oluşumu arasındaki karmaşık etkileşimi keşfetmekte ve iki farklı vaka çalışması ile bilgi sağlamaktadır. İlk çalışma yerel ekonomilerin ilerlemesi üzerine odaklanırken, diğeri COVID-19 pandemisi sırasında toplumların uyum kabiliyetini etkileyen faktörleri inceler. Bu tezde iki temel araştırma ortaya konmaktadır. Kredi kartı işlemlerinden elde edilen müşteri bir araya gelme ağları kullanılarak işletmelerin finansal performansının tahmini; ve akıllı telefon tabanlı hareketlilik verileriyle pandemi sırasında mahallelerin uyum kabiliyetinin analizi, müdahalelerin çeşitli sosyodemografik gruplar üzerindeki etkilerini ve hareketlilik ağlarındaki değişiklikleri değerlendirir. Bu çalışma, müşteri bir araya gelme ağlarından çıkarılan gizlilik artırılmış ağ tabanlı öznitelikler kullanarak işletmelerin finansal iyilik halini öngörme için yeni bir çerçeve geliştirerek ve pandemi sırasında mahallelerin uyum kabiliyetine dair coğrafi ve sosyodemografik faktörleri, yanı sıra olanak erişilebilirliğini de dikkate alarak bilgi sunmayı amaçlamaktadır. Sonuç olarak, bu çalışma insan hareketliliği verilerinden elde edilen bilgiyle politika yapıcılarına donanımlı, evrilen toplumsal manzaraya uygun, adaptif ve kapsayıcı politikalar oluşturma imkanı sağlamayı hedeflemektedir. Bu tezde sunulan araştırma, dış kaynaklı şokların ardından toplumların uyum kabiliyeti ve yerel ekonomilerin canlılığıyla ilgili bilgi sahibi politika oluşturmayı önemli ölçüde etkileyebilecek potansiyele sahiptir.","Human mobility stands as an indispensable catalyst shaping the fabric of societies worldwide, serving as a critical component in understanding societal behaviors and influencing the formulation of effective policies. This dissertation explores the intricate interplay between human mobility patterns and the formation of impactful societal policies by employing mobility networks extracted from large-scale human mobility data with varying granularities, offering insights for informed policymaking through two distinct case studies. The first case study centers on advancing local economies, while the other scrutinizes the factors influencing community adaptability during the COVID-19 pandemic. Two primary investigations unfold in this dissertation. The prediction of business financial performance using customer co-location networks derived from credit card transactions, employing network modeling techniques rooted in human mobility data; and the analysis of neighborhood adaptability during the pandemic through smartphone-based mobility data, evaluating interventions' impacts on diverse sociodemographic groups and changes in mobility networks. It aims to offer innovative contributions by developing a novel framework for predicting business financial well-being utilizing privacy-enhanced network-based features extracted from customer co-location networks and providing insights into neighborhood adaptability during the pandemic, taking into account geographic and sociodemographic factors, in addition to amenity accessibility. Ultimately, this study aspires to equip policymakers with well-informed insights gleaned from human mobility data, fostering the formulation of adaptive, inclusive policies tailored to address the evolving societal landscape. The research presented in this dissertation holds the potential to significantly influence informed policymaking concerning communities' adaptability in the wake of exogenous shocks and the vitality of local economies."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Evrişimsel Sinir Ağları görüntü işleme uygulamalarında en yaygın olarak kullanılan yöntemlerden biridir. Evrişimsel Sinir Ağları' nın tahminlerindeki belirsizliğin doğru bir şekilde ölçülmesi, bu yöntemin tıbbi görüntü sınıflandırması ve otonom sürüş gibi güvenlik açısından kiritik alanlar da dahil olmak üzere çeşitli uygulamalarda yaygın olarak kullanılması nedeniyle çok önemlidir. Buna rağmen, belirsizlik tahmini hala tam olarak çözülemeyen bir problem olarak kalmaya devam etmektedir. Bu yönde herhangi bir somut kanıt olmamasına rağmen softmax olasılıkları genellikle belirsizliği modellemek için kullanılmaktadır. Güncel araştırmalar belirsizlik ölçümleme problemini, Monte Carlo Dropout, Deep Ensembles ve Evidential Deep Learning (EDL) isimli üç farklı strateji kullanarak ele almıştır. Bu tez öncelikli olarak, belirtilen yaklaşımlar arasında en güncel ve hesaplama açısından en verimli olan EDL' ye odaklanmış olsa da, bu yöntemlerin her birinin belirsizlik ölçümlemedeki performansı ve tahminleme yetenekleri bu çalışmada CIFAR-10 ve CelebA veri setleri kullanılarak karşılaştırılmıştır. Son olarak, LFWA veri seti üzerinde EDL yönteminden yararlanılarak veri seti içerisinde yanlış etiketlenmiş örneklerin otomatik olarak tespit edilmesi için yeni bir yaklaşım sunulmaktadır.","Convolutional Neural Networks (CNNs) is one of the mainstream paradigms in most computer vision tasks. Accurately quantifying the uncertainty in CNN's predictions is crucial as they are being used in various applications, including safety- critical domains such as medical image classification and autonomous driving. Yet, uncertainty prediction remains a challenge. Softmax probabilities are often used to model uncertainty with no solid support. Recent studies have tackled this challenge using three distinct methodologies, namely: Monte Carlo Dropout, Deep Ensembles, and Evidential Deep Learning (EDL). Although this thesis primarily focuses on EDL, the most up-to-date and computationally efficient among these approaches, each of these methods performance in uncertainty estimation along with their predictive capabilities are compared using CIFAR-10 and CelebA datasets in this work. Finally, leveraging the EDL method on the CelebA dataset, a novel approach is presented to automatically detect mislabeled samples within the dataset."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Büyük ölçekli felaketlerin ardından, gerçek zamanlı izleme, kaynak optimizasyonu ve görev planlaması için, arama ve kurtarma çalışmalarında mağdur insanları bulabilmek ve takip edebilmek, kritik bir adımdır. Bu tezde arama ve kurtarma (SAR) çalışmaları için DODAE adında tespit, gözlem, tekilleştirme, eşleştirme ve açıklama adımlarından oluşan çok nesneli bir takip paradigması öneriyoruz. Tespit adımı, afet bölgesinin havadan görüntülerini kullanarak potansiyel mağdurların yerini belirlemeyi amaçlar. Gözlem adımı, vatandaşlardan, gönüllülerden ve kurtarma ekip üyelerinden mağdurların konumlarını açıklayan gözlemleri toplamayı hedefler. Veri tekilleştirme adımının amacı, güvenilir gözlemler yoluyla ortak gözlemleri ve tespit adımında yapılan yanlış pozitif ve yanlış negatif kararları filtrelemektir. Eşleştirme adımı, nesne tespitlerini veya gözlemleri ilgili izleme kimlikleriyle eşlestirir. Açıklama adımı, potansiyel mağdurların yakındaki nesnelere göre konumlarını açıklar. DODAE kapsamında nitel uzaysal ve mesafe ilişkilerini kullanan iki yeni yöntem sunuyoruz. İlişkilere Göre Veri Tekilliştirme (DDR) ve ilişkilere Göre Veri Eşleştirme (DAR). Bu hibrit yöntemleri değerlendirmek için, SAR senaryolarının koşullarını simüle etmek amacıyla düşük kare hızlı bir izleme video veri seti oluşturuyoruz. Değerlendirmeleri dört farklı senaryoda yapıyoruz: mükemmel bir dedektörle, yalnızca tespitlerle, yalnızca gözlemlerle, ve her ikisiyle. Deneysel değerlendirmelerde, QSR'in tespit ve izleme sonuçlarının doğruluğunu iyileştirdiği gözlemlenmiştir.","Locating and tracking potential victims in search and rescue (SAR) missions is a crucial step in real-time monitoring, resource optimization, and mission planning in the aftermath of large-scale disasters. We propose a multi-object tracking paradigm in SAR missions (DODAE) consisting of detection, observation, deduplication, association, and explanation steps. The detection step locates potential victims in aerial images of the disaster region. The observation step collects qualitative spatial relations describing the locations of potential victims relative to landmarks in the disaster area from citizens, volunteers, and rescue team members. The deduplication step filters common observations, and detected false positives and false negatives, via trustworthy observations. The association step links object detections or observations to corresponding track identities. The explanation step describes the locations of potential victims relative to close-by objects. Within DODAE, we introduce two novel methods that utilize qualitative spatial reasoning (QSR): Data Deduplication by Relations (DDR), and Data Association by Relations (DAR). To evaluate these hybrid methods, we build a low frame-rate tracking video dataset to simulate the circumstances of SAR scenarios. We conduct evaluations in four distinct scenarios: with a perfect detector, with detections only, with observations only, and with both detections and observations. The improved accuracy results show the usefulness of QSR for detection and tracking."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma hiperspektral uzaktan algılama görüntü sınıflandırma araştırma alanı içinde, derin öğrenme modellerinin karar verme sürecini açıklamanın zorluklarına odaklanmaktadır. Odak noktası, üç önemli açıklanabilir yapay zeka yönteminin uygulanması üzerinedir; bunlar GradCAM, GradCAM++ ve Yönlendirilmiş Geriye Yayılım'dır. Bu yöntemler, standart bir evrişimli sinir ağı modelinin uzamsal-spektral hiperspektral görüntü sınıflandırma sürecindeki karar verme sürecini anlamak için kullanılmıştır. Gerçekleştirilen deneyler, piksel yama boyutlarının uzamsal dikkat üzerindeki etkisini ve sınıflandırma sürecinde spektral bantların önemini incelemektedir. Bu çalışma, evrişimli sinir ağlarının uzamsal-spektral bağlamdaki davranışını aydınlatarak, bu modellerin hiperspektral verilerdeki değişikliklere nasıl yanıt verdiğine dair daha derin bir anlayış sağlamaktadır. Ek olarak, bu çalışma kullanılan açıklanabilirlik tekniklerinin -GradCAM, GradCAM++ ve Yönlendirilmiş Geriye Yayılım- karar verme süreçlerini açıklama konusundaki göreceli avantajlarını ve sınırlamalarını analiz etmektedir. Özet olarak, elde edilen sonuçlar, hem evrişimli sinir ağlarının davranışıyla ilgili daha derin yorumlar sunmakta hem de karşılaştırmalı olarak açıklanabilirlik tekniklerinin performansını aktarmaktadır.","Within the hyperspectral remote sensing image classification research area, this thesis delves into the challenges of explaining the decision-making process of deep-learning models. The focus is on the integration of three prominent explainable artificial intelligence methods, namely Grad-CAM, Grad-CAM++, and Guided Backpropagation. These methods have been employed in order to comprehend the decision-making process of a typical convolutional neural network model during spatial-spectral hyperspectral image classification. The conducted experiments investigate the impact of varying pixel patch sizes on spatial attention and the significance of individual spectral bands in the classification process. This thesis sheds light on the behavior of convolutional neural networks in the spatial-spectral context, providing a deeper understanding of how these models respond to changes in hyperspectral data. Furthermore, the study analyzes the relative advantages and limitations of the employed explainability techniques —Grad-CAM, Grad-CAM++, and Guided Backpropagation— in explaining the decision-making processes of the convolutional neural network model. In conclusion, the results provide both deeper interpretations of the behavior of convolutional neural networks as well as a comparative performance analysis of explainability techniques."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda, otonom sürüş, uydu görüntüleme ve tıbbi görüntüleme gibi çeşitli alanlarda semantik segmentasyon veri setlerinde büyük bir artış olmuştur. Bu veri setleriyle semantik segmentasyon problemlerini çözmede sayısız ilerleme olmasına rağmen, karmaşık yapıdaki nesnelerin sınırlarının doğru segmentasyonu gibi zorluklar devam etmektedir. Çapraz entropi ve IoU gibi geleneksel yitim fonksiyonları segmentasyon bölgeleri üzerinden integral alınmasına dayanır ve bu senaryolarda genellikle yetersiz kalır. Bu fonksiyonlar nesneleri bölgesel olarak algılarlar, sınırlar ve iç kısımlar gibi tüm nesne konturlarına da eşit önem verirler. Bu yaklaşım, nesne sınırlarındaki segmentasyonun hem daha zorlu hem de daha kritik olduğunu göz ardı eder. Bu tez bu sorunu çözmek için, tahmin edilen sınırlar ve gerçek sınırlar arasındaki hizalamayı artırmak amacıyla tasarlanmış mesafe dönüşüm tabanlı bir yitim fonksiyonu önermektedir. Yaygın olarak kullanılan segmentasyon yitim fonksiyonlarında bu özellik bulunmamaktadır. Önerdiğimiz yitim fonksiyonu, modelden bağımsızdır ve herhangi bir modelinin eğitimine sınır detaylarını geliştirmek için kolayca entegre edilebilir. Yitim fonsiyonumuz, tek sınıflı segmentasyon için CelebAMask-HQ ve çok sınıflı segmentasyon için Cityscapes olmak üzere iki veri seti kullanılarak değerlendirildi. U-Net ve DeepLabv3+ olmak üzere iki model ve ResNet-34, ResNet-50 ve MobileNetV2 olmak üzere üç kodlayıcı kullanılarak, yitim fonksiyonumuzun çeşitli ağ mimarileri arasında adaptasyon yeteneğini ve etkinliğini göstermek için deneyler yapıldı. Cityscapes veri seti için farklı yitim fonksiyonlarının değerlendirmeleri ve karşılaştırmaları sonucunda yitim fonksiyonumuzun sınır IoU (bIoU) açısından U-Net modelleri bazında diğer yaygın olarak kullanılan yitim fonksiyonlarını 0.0561 kadar geride bıraktığını gösterdi. Ayrıca, yitim fonsiyonumuz %2.4 daha az GPU belleği kullanarak üstün performans sergiledi. Bu durum daha büyük sinir ağları ile büyük veri setleri eğitirken önemli bir faktördür.","In recent decades, there has been a tremendous enlargement of semantic segmentation datasets across diverse complex domains, including autonomous driving, satellite imaging, and medical imaging. Despite numerous advancements in solving complex semantic segmentation problems with these datasets, certain challenges, such as the precise segmentation of object boundaries in complexly structured objects, persist. Traditional loss functions like Cross-Entropy and Intersection over Union (IoU), which are typically based on integrals over segmentation regions, often fall short in these scenarios. These functions perceive objects regionally rather than contour-based, assigning equal importance to all object contours such as boundaries and inner parts. This approach overlooks the fact that segmentation at object boundaries is both more challenging and more critical. To address this, this thesis introduces a distance transform-based loss function, specifically designed to enhance the alignment between predicted and ground-truth boundaries during training, a feature not explicitly enforced in commonly used image segmentation losses. This proposed loss function is model-agnostic and can be integrated into the training of any segmentation models to enhance boundary details. Our loss was evaluated using two segmentation datasets: CelebAMask-HQ for single-class, and Cityscapes for multi-class segmentation. Experiments were conducted using two models, U-Net and DeepLabv3+, and three encoders, ResNet-34, ResNet-50, and MobileNetV2, to demonstrate the adaptability and effectiveness of our loss across various network architectures. Our evaluations and comparisons of different loss functions revealed that our loss surpassed other commonly used loss functions by 0.0561 for the Cityscapes dataset with U-Net models in terms of boundary IoU, a metric specifically designed to assess the boundary quality of objects in images. Furthermore, our loss demonstrated superior performance by using 2.4% less GPU memory, a significant factor when training larger neural networks with big datasets."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı sayaçlar, elektrik, gaz veya su gibi hizmetlerin tüketimini ölçer. Hizmet sağlayıcıları, veri üzerinde analiz yaparak araştırma ve inovasyona katkıda bulunmak amacıyla akıllı sayaç verilerini yayınlamaktadırlar. Veri sahipleri, akıllı sayaç verilerini yayınlarken, bireylerin yeniden tanımlanmasına olanak tanıyan bağlantı saldırılarına karşı hassas olan anonimleştirme gibi, sınırlı mahremiyet tekniklerinden yararlanmaktadır. Sonuç olarak akıllı sayaç verilerinin kamuya açık hale getirilmesi mahremiyet endişelerini artırmaktadır. Akıllı sayaç verileri, hane halkının günlük rutinleri, faaliyetleri ve mahrem özellikleri hakkındaki kişisel bilgileri ortaya çıkarmak için kötüye kullanılabilir. Diferansiyel mahremiyet, verinin kullanışlılığı ile bireysel mahremiyetin çatışan hedeflerini dengeleyen bir çerçevedir. Bu tezde, diferansiyel mahremiyetin, etkin veri kullanımı ve bilgi çıkarımı sağlanırken, ev halkının mahremiyetini ne derece etkili bir şekilde dengeleyebileceğinin gösterimini amaçlanmaktadır. Bu amaçla ev elektriği tüketim verileri kullanılmıştır. Veri seti dengesiz olduğundan Sentetik Azınlık Örneklem Artırma Tekniği (SMOTE) kullanılarak dengeleme yapıldı. Öte yandan, veri seti küçük olduğundan, gerçek verilere dayalı sentetik veriler üretmek için Üretken Rekabetçi Ağ (GAN) tekniği kullanıldı. IBM'nin diffprivlib kütüphanesi kullanılarak veriye gürültü eklemek için çeşitli deneyler yapıldı ve gürültülü veri üzerinde makine öğrenimine dayalı sınıflandırma gerçekleştirildi. Orijinal verilere benzer sınıflandırma performansı sağlayan en uygun olanı belirlemek için çeşitli gürültü seviyelerinin değerlendirilmesi yapılmıştır. Diferansiyel mahremiyete sahip Gaussian Naive Bayes modelinin, diferansiyel mahremiyete sahip Lojistik Regresyon modeline göre daha iyi bir diferansiyel mahremiyet düzeyi (daha küçük $\varepsilon$) sağladığı belirlendi. Ayrıca, Gaussian gürültü ekleme mekanizmasının, diferansiyel mahremiyet elde etmek için diğer mekanizmalar arasında en iyisi olduğu gösterilmiştir.","Smart meters measure utility consumption, like electricity, gas, or water. Utility providers publish smart meter data to contribute to research and innovation by performing analysis on the data. Data owners utilize limited privacy techniques when publishing smart meter data, such as anonymization, which is susceptible to linkage attacks that allow for the re-identification of individuals. As a result, making smart meter data publicly available raises privacy concerns. Smart meter data could be misused to reveal personal information about daily routines, activities, and private characteristics of households. Differential privacy is a framework that balances the conflicting goals of data utilization and individual privacy. In this thesis, we aim to show to what extent differential privacy can effectively balance household privacy while providing efficient data utilization and information extraction. For this purpose, we use household electricity consumption data. The data set was unbalanced, so Synthetic Minority Oversampling Technique (SMOTE) was used to balance it. Moreover, since the data set was small, Generative Adversarial Network (GAN) technique was used to generate synthetic data based on the real data. Using IBM's diffprivlib library, conducted various experiments for adding noise to the data and performed machine-learning-based classification over noisy data. We evaluated various noise levels to determine the optimal one that gives a similar classification performance as the original data. It has been determined that the Gaussian Naive Bayes model with differential privacy provides a better differential privacy level (smaller $\varepsilon$) than the Logistic Regression model with differential privacy. Furthermore, it has been shown that the Gaussian noise addition mechanism is the best among the other mechanisms for achieving differential privacy."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hızla gelişen nesnelerin interneti (IoT) alanı, sıradan nesneleri birbirine bağlı akıllı cihazlara dönüştürerek çeşitli sektörlerde veri toplama ve gerçek zamanlı analiz kapasitesini geliştirir, bu da verimliliği ve veri kullanımını artırır. Ancak, nesnelerin interneti sistemlerinin çoğalmasıyla bu cihazların güvenlik tehditleri ve zaafiyetleri de artmıştır. Veri gizliliğini, bütünlüğünü ve kullanılabilirliğini korumak için güvenli veri transferleri ve potansiyel saldırganları tespit etme dahil olmak üzere sağlam güvenlik önlemlerini sağlamak kritik önem taşır. Bu tezde, nesnelerin interneti test ortamlarının önemini ve saldırı tespit sistemlerinin bu riskleri ve zayıflıkları hafifletme rolünü vurgulamaktayız. Güvenlik perspektifinden genel nesnelerin interneti cihazlarını taklit etmek amacıyla düşük maliyetli bir test ortamı oluşturuyoruz.Toplanan ağ verilerini kullanarak, hem zararsız hem de zararlı trafik içeren, 17 tür siber saldırıyı tespit etmek ve sınıflandırmak için makine öğrenmesine dayalı gerçek zamanlı bir saldırı tespit sistemi geliştirildi. 0.9504 F1 skoru ve 0.9524 duyarlılık değeri ile sonuçlar, önerilen gerçek zamanlı siber saldırı tespit sisteminin nesnelerin interneti sistemlerinde çeşitli siber saldırıları tespit edebileceğini göstermektedir.","The rapidly evolving Internet of Things (IoT) systems, which transform ordinary objects into interconnected smart devices, offer numerous advantages such as improved data collection and real-time analysis, leading to enhanced efficiency and resource utilization across various sectors. However, with the expansion of IoT, the security threats and vulnerabilities of these devices have also increased. Ensuring robust security measures, including secure data transfer and detecting potential attackers become crucial for maintaining data privacy, integrity, and availability. In this thesis, we underline the significance of IoT testbeds and the role of intrusion detection systems in mitigating these risks and vulnerabilities. We construct a low-cost IoT testbed in order to emulate generic IoT devices from a security perspective. By the use of collected network data, which include both benign and malicious traffic, a machine-learning-based real-time attack detection system is developed to detect and classify 17 types of cyber attacks. With F1 score of 0.9504 and recall value of 0.9524, the results show that the proposed real-time intrusion detection system can detect various cyberattacks on IoT systems."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sahte haberlerin hızla yayılması, özellikle Kovid-19 pandemisi sürecinde bilginin güvenilirliğini tehdit etmektedir. Bu doktora tezi, sahte haberleri tespit etmenin önemini, haberlerde uyandırılan duygusal ve bilişsel faktörlerin rolleriyle birlikte ele almaktadır. Ayrıca, sahte haberlerin yayılmasına katkıda bulunan bireysel davranışları da incelemektedir. Kovid-19 temalı Twitter veri kümesindeki gerçek ve sahte haberlerin duygu etiketleri sınıflandırılmış ve sözcük ve sözlüklere dayalı duygu analizi ve çıkarım teknikleriyle uyandırılan duygular belirlenmiştir. Her bir tweet için uygun duyguyu seçmek üzere üç farklı duygu sözlüğü test edilmiş ve en etkili olanı uygulanmıştır. Test edilen sözlüklerden Vader duygu sözlüğü en iyi sonuçları vermiştir. Sahte haberlerin olumsuz duygularla, gerçek haberlerin ise olumlu duygularla ilişkili olduğu görülmüştür. Tweetleri daha detaylı analiz etmek için sekiz temel duygu (beklenti, öfke, neşe, özlem, şaşkınlık, korku, güven ve tiksinti) içeren NRC duygu sözlüğü kullanılmıştır. Bulgular, olumsuz duyguların (korku, öfke, iğrenme) sahte haberlerde daha sık ve daha güçlü bir şekilde ifade edildiğini; olumlu duyguların (güven, neşe, beklenti) ise gerçek haberlerde hem sayıca hem de yoğunlukça daha fazla olduğunu ortaya koymuştur. Araştırma sonuçları, duyguların sahte haber tespit modellerinin geliştirilmesinde önemli bir rol oynayabileceğini göstermektedir. Haberlerin paylaşıldığı tweet metinlerinin uyandırdığı duygulara göre sahte ve gerçek haberleri ayırt etmek için SVM, Naive Bayes, Random Forest makine öğrenmesi ve BERT derin öğrenme modelleri kullanılmıştır. Bu bağlamda, modellere duygusal detayların dahil edilip edilmediği durumlarının performansları karşılaştırılmıştır. Sonuçlar, sahte haberleri tespit etmek için modellere duygusal unsurların eklenmesinin performansı iyileştirdiğini göstermiştir. Bu doktora tezi, sahte haberlerin belirlenmesine yönelik araştırmalara katkı sağlamaktadır.","The rapid dissemination of fake news represents an important threat to the accuracy of the information, particularly in considering the COVID-19 pandemic. In this dissertation, the significance of detecting fake news has been studied, with particular attention paid to the impact that sentimental and emotional characteristics can have on the process of identifying it. On a COVID-19 Twitter dataset with labeled classes, the feelings and emotions of fake news against real news are compared. Lexicon-based sentiment analysis and emotion extraction methods are utilized for extracting the sentiments and emotions of the tweets. Three different sentiment lexicons are employed to generate the matching sentiment for each tweet, and the best-performing lexicon is selected using a variety of techniques. Vader sentiment lexicon provides the most effective results. According to the sentiments displayed by Vader, fake news involves a larger quantity of negative emotions than positive emotions. The tweets are evaluated with the NRC emotion lexicon, which allows for the extraction of eight basic emotions, including anticipation, anger, joy, sadness, surprise, fear, trust, and disgust. It has been discovered that negative feelings like fear, anger, and disgust are more prevalent in fake news than they are in real news. These emotions are also expressed, in a more powerful manner, via fake news. On the other hand, feelings such as trust, joy, and anticipation are more prevalent in real news, both in terms of the amount of such feelings and the intensity with which they are expressed. According to the findings, feelings have the potential to play an important role as an element in the development of fake news identification models. The SVM, Naive Bayes, Random Forest machine learning, and BERT deep learning models are implemented in order to validate this hypothesis. Comparisons are made between the performance of the models with and without the inclusion of emotional details. The findings show that incorporating emotional aspects into fake news detection models improves the performance of the detection model. This dissertation introduces novel features and approaches that contribute to the advancement of the field of detecting fake news. The findings highlight the significant emotional and sentimental differences among fake and real news on the COVID-19 Twitter data set and highlight the important role that emotions play in the detection of fake news and provide useful insights into the process of training fake news detection models to recognize and make efficient use of these features."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Soyutlayıcı özetleme nispeten yeni ve zorlu bir araştırma alanıdır. Gerektiğinde yeni cümleler üretmeye dayalı metin özetleme için iki yaklaşımdan biridir. Belge özetlemede iki temel yaklaşım vardır: çıkarımsal ve soyutlayıcı. Çıkarımsal özetleme, verilen belgeden önemli ifadeleri veya cümleleri seçerek veya çıkararak bir özet verir. Bu nedenle, dilbilgisi açısından doğru cümlelerin üretilmesi garanti edilir, ancak ortaya çıkan özet girdi metindeki cümleleri kullanmakla sınırlıdır. Buna karşılık soyutlayıcı özetleme, girdiyi özetlemek için semantik anlamı yakaladığı ve cümleler ürettiğinden dolayı potansiyel olarak daha güçlü bir yaklaşım oluşturur. Bununla birlikte zorluk, doğal ve dilbilgisi açısından da doğru olan aslına sadık özetler üretmekte yatmaktadır. Bu tezde, soyutlayıcı özetlemede iki ana zorluğu ele alıyoruz: iyi bir eğitim hedefi nedir ve performans nasıl ölçülür. Soyutlayıcı özetleme için yeni değerlendirme yöntemleri ve pekiştirici bir öğrenme çerçevesi sunuyoruz. Özetleme için en yaygın kullanılan değerlendirme ölçütü, aralarındaki n-gramlar, kelime dizileri ve kelime çiftleri gibi örtüşen birimleri dikkate alarak otomatik olarak oluşturulan bir özeti insan tarafından oluşturulan özetle karşılaştıran ROUGE'dur. ROUGE yaygın olarak kullanılan bir değerlendirme ölçütü olmasına rağmen, temel gerçek ile oluşturulan özetler arasındaki yüzeysel sözcüksel örtüşmeye dayandığından soyutlayıcı özetleme sistemlerinin değerlendirilmesi için pek uygun değildir. Bu tezde, Türkçe için anlamsal benzerlik modelleri sunuyoruz ve bunları soyutlayıcı bir özetleme görevi için değerlendirme ölçütleri olarak uyguluyoruz. Bunun için İngilizce STSb veri kümesini Türkçe'ye çevirdik ve Türkçe için ilk anlamsal metin benzerliği veri kümesini STSb-TR olarak sunduk. Önerilen değerlendirme ölçütleri, ince ayarlı bir büyük dil modeli tarafından elde edildiği şekliyle girdinin ve karşılık gelen özetin anlamsal benzerliğine dayanmaktadır. Benzerlik puanları, çapraz kodlayıcı veya çift kodlayıcı mimarisi kullanılarak ince ayarlı BERTurk modeliyle elde edilmiştir. İnce ayar, Türkçe Doğal Dil Çıkarımı (NLI-TR) ve Türkçe Anlamsal Metin Benzerliği (STSb-TR) veri kümeleri üzerinde yapılmıştır. Hem Pearson hem de Spearman korelasyonlarına dayalı olarak, bu ölçümlerin ROUGE skorları ve BERTScore ile karşılaştırıldığında insan değerlendirmeleriyle daha iyi korelasyona sahip olduğunu gösteriyoruz. Daha sonra, önerilen anlamsal benzerlik ödüllerine dayalı olarak, temel gerçek özetlere anlamsal olarak daha benzer olan özetler üretmek için bir derin pekiştirmeli öğrenme algoritması sunuyoruz. Algoritma, hedefimizi en üst düzeye çıkarmak ve okunabilirliği açısından daha doğal özetler oluşturmak için pekiştirmeli öğrenme hedefi fonksiyonu ile maksimum olabilirlik hedef fonksiyonumuzun bir kombinasyonu olan karma bir eğitim hedefi fonksiyonu kullanmaktadır. Maksimum olabilirlik eğitim hedefine kıyasla karma eğitim hedefi fonksiyonuna sahip eğitimin benzerlik puanlarını iyileştirdiğini gösteriyoruz.","Abstractive summarization is a relatively recent and challenging research area. It is one of the two approaches to document summarization based on generating new sentences as needed. Document summarization has two primary approaches: extractive and abstractive. Extractive summarization yields a summary by selecting or extracting important phrases or sentences from the given document. As such, it is guaranteed to generate grammatically correct sentences, however the resulting summary is constrained to use sentences in the input text. In contrast, abstractive summarization constitutes a potentially more powerful approach, as it captures the semantic meaning and generates sentences to summarize the input. However, the challenge lies in producing faithful summaries that are also natural and grammatically correct. In this dissertation, we address the two main challenges in abstractive summarization: what is a good training objective and how to measure performance. We introduce new evaluation methods and a reinforcement learning framework for abstractive summarization. The most widely used evaluation metric for summarization is ROUGE which compares an automatically generated summary to the human generated summary, by considering the overlapping units, such as n-grams, word sequences and word pairs, between them. Although ROUGE is a widely used evaluation metric, it is not very suitable for the evaluation of abstractive summarization systems, as it relies on superficial lexical overlap between the ground-truth and the generated summaries. This translates into an unfair evaluation of abstractive summarization systems, where the resulting summary does not always contain the same words in the ground-truth summary. Furthermore, for languages with complex morphology, such as Turkish, the ROUGE metric is even less suitable. In this dissertation, we present semantic similarity models for Turkish and apply them as evaluation measures for an abstractive summarization task. To achieve this, we translated the English STSb dataset into Turkish and presented the first semantic textual similarity dataset for Turkish, called STSb-TR. The proposed evaluation measures are based on the semantic similarity of the input and corresponding summary, as obtained by a fine-tuned large language model. The similarity scores are obtained by the fine-tuned BERTurk model using either the cross-encoder or a bi-encoder architecture. The fine-tuning is done on the Turkish Natural Language Inference (NLI-TR) and Turkish Semantic Textual Similarity benchmark (STSb-TR) datasets. We show that these measures have better correlations with human evaluations compared to ROUGE scores and BERTScore, based on both Pearson and Spearman correlations. We then introduce a deep reinforcement learning algorithm to produce summaries that are semantically more similar to ground-truth summaries, based on the proposed semantic similarity rewards. The algorithm uses a mixed training objective function that is a combination of our reinforcement learning objective function and a maximum likelihood objective function, in order to maximize our objective as well as generate more natural summaries in terms of human readability. We show that training with a mixed training objective function compared to maximum likelihood training objective improves similarity scores."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"MiRNA'lar, hedef mesajcı RNA'ya (mRNA) bağlanarak mRNA bozunumu ve/veya translasyon inhibisyonu yoluyla hedef genin ifadesini post-transkripsiyonel olarak baskılar. Gen ifadesinin önemli düzenleyicileri oldukları için, kanser gibi farklı biyolojik süreçlerde ve patolojilerde rol oynarlar. Çoğu miRNA hedeflerini yalnızca az miktarda baskılayabilirken, bazı miRNA'ların aynı mRNA hedefin ifade düzeyini güçlü bir şekilde modüle etmek için sinerjik olarak hareket ettiği bilinmektedir. miRNA terapötiklerinde bu sinerjizmi kullanmak, tek bir miRNA tedavilerine kıyasla etkinliği artırma ve toksisiteyi en aza indirgeme potansiyeli sunar. Daha önce, miRNA'ların ve mRNA'ların eşleştirilmiş hasta gen ifade verileri üzerinde çekirdek etkileşim testleri kullanılarak potansiyel sinerjik miRNA çiftlerini ve paylaşılan hedef mRNA'larını belirlemek için miRCoop adı verilen bir yöntem geliştirilmiştir. Bu tezde, orijinal yöntemin birçok yönünü geliştiren, miRCoop'un geliştirilmiş bir versiyonu olan miRCoop-v2'yi sunuyoruz. miRCoop-v2, transkripsiyon faktörlerini içeren sinerjistik miRNA etkileşimlerini tanımlayabilir, açıkça miRNA arm bilgisini dahil edebilir, daha geniş bir miRNA-mRNA hedef etkileşim veri kümesini kullanabilir ve önceki sürümüne göre 30 kat daha hızlı çalışabilir. Bu hızlanma sinerjik miRNA çiftlerini ve ortak hedeflerini tahmin etmek için miRCoop-v2'yi 31 farklı kansere uygulamamıza olanak sağlar. miRCoop-v2'nin sonuçları, miRNA, TF (transkripsiyon faktörleri) ve hedef mRNA arasındaki kanserle ilişkili etkileşimlerin tespitinde değerli bir araç olabileceğini kanıtlamaktadır. Bazı önemli örnekler arasında MYC, STAT3, MKI67, miR-19a-3p ve miR-424-5p bulunmaktadır. Özellikle belirli bir kanser türü için doğrudan literatür kanıtları olmayabilecek durumlarda bile, bu miRNA'ların ve mRNA'ların diğer kanser türlerindeki önemi, çeşitli kanser bağlamlarında potansiyel ilgi çekiciliğini ve terapötik değerini göstermektedir. Ek olarak, sonuçları sunmak için bir web uygulaması geliştirdik, böylece kullanıcılar kanser özelinde üçlü ve sinerji modül sonuçlarına, seçilen kanserlerin pan-kanser analizlerine ve bulguların etkileşimli görselleştirmelerine erişebilirler. Umarız miRCoop-v2, sinerjik miRNA etkileşimlerini tespit etme konusundaki deneysel çabaları kolaylaştıracaktır. Uygulamaya aşağıdaki adresten erişilebilir: http://mircoop.sabanciuniv.edu","MiRNAs bind to their target messenger RNA (mRNA) to post-transcriptionally repress the target gene's expression through mRNA degradation and/or translational inhibition. As they are important regulators of gene expression, they take roles in different biological processes and are associated with pathologies such as cancer. While most miRNAs can repress their target only minimally, some miRNAs are known to act synergistically to strongly modulate the expression level of a common mRNA target. Harnessing this synergism in miRNA therapeutics offers the potential to enhance potency and efficacy while minimizing toxicity compared to single miRNA therapies. Previously, a method called miRCoop was developed to identify potential synergistic miRNA pairs and their shared target mRNAs using kernel interaction tests on matched patient gene expression data of miRNAs and mRNAs. In this thesis, we present an improved version of this tool, called miRCoop-v2, which enhances several aspects of the original method. miRCoop-v2 can identify synergistic miRNA interactions involving transcription factors, explicitly incorporates miRNA arm information, utilizes a larger miRNA-mRNA target interaction dataset, and runs 30 times faster than its predecessor. This speed-up allows us to apply miRCoop-v2 to 31 different cancers to predict synergistic miRNA pairs and their shared targets. Results of the miRCoop v2 prove that it can be a valuable tool in the detection of cancer-related interactions between miRNA, TF (transcription factors), and target mRNA. Some significant examples include MYC, STAT3, MKI67, miR-19a-3p, and miR-424-5p. Even in situations where direct literature evidence for specific cancer may be lacking, the importance of these miRNAs and mRNAs in other cancer types suggests their potential relevance and therapeutic value across various cancer contexts. We also have developed a web application to present the results, allowing users to access cancer-specific triplet and synergy module results, pan-cancer analyses of selected cancers, and interactive visualizations of the findings. We hope miRCoop-v2 will facilitate experimental efforts in detecting synergistic miRNA interactions. The application is accessible at http://mircoop.sabanciuniv.edu"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Pekiştirmeli öğrenmenin (RL) doğal dil işleme (NLP) görevlerindeki kullanımı son yıllarda hız kazanmıştır. Bu tezde, dönüştürücüler (transformer) ve büyük dil modelleri (LLM'ler) gibi çeşitli derin öğrenme topolojilerinin, özellik çıkarma sürecine bir pekiştirmeli öğrenme çerçevesi içinde entegre edilmesiyle, metin sınıflandırma problemine geliştirilmiş bir yaklaşım sunuyoruz. Önerilen yöntemde, pekiştirmeli öğrenme politikaları, bir metin bölümünü gözlemlemek ve metni sınıflandırmak veya metnin bir sonraki bölümüne geçmek konusunda karar vermek için eğitilir. Politikalar, REINFORCE (Williams, 1992) algoritmasıyla optimize edilir ve bunun için tasarlanmış bir ödül sinyali kullanılır. Önerilen yöntemin etkinliği, standart metin sınıflandırma veri kümeleri üzerinde, diğer güncel modellerle karşılaştırılarak değerlendirildi ve önerilen yaklaşımın verimlilik açısından üstünlüğü ve tutarlılık açısından küçük bir performans kaybı gösterdiği görülmüştür. Sonuçlar, büyük dil modellerinin özellik çıkarma sürecinde kullanılması ve tasarlanmış ödül sinyali ile pekiştirmeli öğrenme politikalarının birleştirilmesinin etkili ve verimli metin sınıflandırma modellerinin geliştirilmesi için umut verici bir yol sağladığını göstermektedir.","Usage of reinforcement learning (RL) in natural language processing (NLP) tasks has gained momentum in recent years. In this thesis, we present an improved approach to the task of text classification through the integration of various deep learning topologies such as transformers and large language models (LLMs) into the feature extraction process within a reinforcement learning framework. In this proposed method, the RL policies are trained to observe a portion of the text and determine whether to classify the text or to proceed to the next part of the document. The policies were optimized with the REINFORCE (Williams, 1992) algorithm utilizing a designed reward signal. The effectiveness of the proposed method was evaluated and compared against other state-of-the-art models on standard text classification benchmark datasets, demonstrating the superiority of the proposed approach in terms of efficiency while losing little performance in accuracy. The results indicate that the use of the LLMs in the feature extraction process, coupled with RL policies with designed reward signals, provides a promising avenue for the development of effective and efficient text classification models."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Doğal Dil İşleme'nin hayati bir bileşeni olan Varlık İlişkilendirme, belirli bir metindeki adlandırılmış varlıkları bir bilgi tabanındaki karşılığı olan gerçek dünya varlıklarına bağlamayı amaçlar. Bu çalışma, Türk diline uyarlanmış Dönüştürücü tabanlı Sinirsel Varlık İlişkilendirme modellerinin verisetlerindeki yazım tipi ve tür değişimlerindeki performansına odaklanarak bir araştırma sunmaktadır. Orijinal olarak İngilizce için tasarlanmış iki gelişmiş Sinirsel Varlık İlişkilendirme modeli Türkçe'ye uyarlanmıştır. Daha sonra, uyarlanan bu modellerin farklı Türkçe veri setlerinde performansları incelenmiştir. Ayriyetten, EntityBERT adlı geliştirdiğimiz ve karşılaştırma için bir referans noktası işlevi gören yeni bir yöntem ayrıntılı olarak değerlendirilmiştir. EntityBERT, önceden eğitilmiş Türkçe Dönüştürücü modelini ve bu modellerin `bağlamsal öğrenme' (contextual-learning) yeteneklerini kullanan basit bir Sinirsel Varlık İlişkilendirme modelidir. Sistemlerin performans değerlendirmesi tarafımızca yeni oluşturulmuş bir veri seti de dahil olmak üzere üç farklı veri seti üzerinde gerçekleştirilmiştir. Bulgular, Sinirsel Varlık İlişkilendirme modellerinin, dil ve içerik türü geçişlerinde güçlü performans sergilediğini ve çeşitli metin türlerine uyum sağlayabildiklerini ortaya koymuştur. Bununla birlikte, araştırmamız kayda değer bir dezavantajı da vurgulamaktadır: Sinirsel Varlık İlişkilendirme modelleri yazım tipi (Vikipedi metinleri ve Tweetler) değişiklikleri karşısında performans kaybetmektedir. Genel olarak, bu çalışma, Türkçe'deki Sinirsel Varlık İlişkilendirme modellerinin potansiyeline ve dezavantajlarına ışık tutmakta, Türkçe Tweet'lerden oluşan bir değerlendirme seti sunmakta ve son olarak, İngilizce dışındaki dillerde NLP alanında ilerleme sağlamak için değerli bilgiler sunmaktadır.","Entity Linking, a vital component of Natural Language Processing (NLP), aims to link named entities in a given text to their corresponding real-world entities in a knowledge base. This work presents an exploration of transformer-based Neural Entity Linking models adapted to the Turkish language, focusing on their robustness across genre and domain shifts. We take two advanced Neural Entity Linking models originally designed for English and adapt them to Turkish. We then thoroughly assess how well these adapted models perform on different Turkish datasets, along with a new method we developed called EntityBERT, which serves as a reference point for comparison. EntityBERT is a simple Neural Entity Linking model which exploits pretrained Turkish transformer model and contextualized learning capabilities of transformer models. The evaluation was conducted on three distinct datasets, including one newly created dataset, publicly available for further research. The findings revealed that Neural Entity Linking models exhibited robust performance across language and genre shifts, demonstrating their adaptability to Turkish and diverse textual genres. Nonetheless, our investigation also highlights a noteworthy limitation: the susceptibility of Neural Entity Linking models to domain shift challenges. Despite their favorable performance in general settings, adapting to domains with distinctive characteristics poses considerable difficulties. Overall, this study sheds light on the potential and limitations of Neural Entity Linking models in Turkish, provides an evaluation dataset of Turkish tweets, and finally delivers valuable insights for advancing the field of natural language processing in non-English languages."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal medyanın artan kullanımı, fiziksel egzersiz ve sağlık arasındaki ilişkiyi in- celemek için yeni yollar açtı. Egzersizin fiziksel sağlık üzerindeki olumlu etkisi uzun süredir kabul edilirken, zihinsel ve duygusal esenlik üzerindeki etkileri önemli ölçüde dikkat çekmiştir. Bu bağlamda popüler bir sosyal medya platformu olan Twitter, bireylerin günlük yaşamlarındaki düşünce, duygu ve davranışlarını yansıtan gerçek zamanlı değerli bir veri kaynağı sağlamaktadır. Ayrıca, giyilebilir cihazların yük- selişi, araştırmacıların egzersiz verileri de dahil olmak üzere ayrıntılı etkinlik rapor- ları toplamasına olanak sağlamıştır. Twitter verilerinden ve duyarlılık analizinden yararlanarak, egzersizin günlük hayattaki refah üzerindeki etkilerini araştırdık. Egz- ersiz dönemlerinden önce, sırasında ve sonrasında gönderilen tweetlerin duyarlılık puanlarının analizi yoluyla, egzersizin genel duyarlılık üzerindeki etkisine ilişkin içgörüler elde etmek için egzersiz ve egzersiz yapılmayan dönemlerin ortalama du- yarlılık puanlarını karşılaştırdık. Metodolojimiz, eğilim puanı eşleştirme yöntem- lerini kullanarak zaman serisi verilerine nedensel çıkarım modellerini uygulamayı ve egzersiz sürelerinin insanların duygu durumlarını nasıl etkilediğini ortaya çıkar- mayı içeriyordu. Çalışmamızın sonuçları, düzenli fiziksel aktivitenin zihinsel esen- lik üzerindeki yapıcı etkisini vurgulamaktadır. Egzersizin günlük yayınlanan içerik üzerindeki olumlu etkisini, egzersiz dönemlerinde paylaşılan içeriklerin duygu du- rumuna olan pozitif etkisini açığa çıkararak göstermiş olduk. Bu araştırma, liter- atürdeki egzersiz ve günlük yaşam refahı arasındaki ilişki hakkındaki çalışmalara katkıda bulunmaktadır.","The increasing usage of social media has opened up new avenues for studying the relationship between physical exercise and well-being. While exercise has long been recognized for its positive impact on physical health, its effects on mental and emo- tional well-being have gained significant attention. In this context, Twitter, as a popular social media platform, provides a valuable source of real-time data that reflects individuals' thoughts, emotions, and behaviors in their daily lives. Further- more, the rise of wearable devices has allowed researchers to collect detailed activity reports, including exercise data. By leveraging Twitter data and sentiment analysis, we explored the effects of exercise on daily life well-being. Through the analy- sis of sentiment scores of tweets posted before, during, and after exercise periods, we compared the average sentiment scores of exercise and non-exercise periods to gain insights into the impact of exercise on overall sentiment. Our methodology in- volved applying causal inference models to time series data by using propensity score matching methods, revealing how exercise periods influenced people's sentiment sta- tus. The results of our study highlight the constructive influence of regular physical activity on mental well-being. We have identified the positive effect of exercise on the daily posted content in terms of sentiment during the exercise periods. This research contributes to the growing body of knowledge on the relationship between exercise and daily life well-being."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bitcoin, yenilikçi ve açık blok zinciri yapısıyla araştırmacıları büyüleyen öncü finansal dağıtık defter sistemidir. Bu açık dağıtık defterin incelemesi ile anonimlik ve mahremiyet açısından karıştırma protokolleri, halka imzalar, sıfır bilgi kanıtları, homomorfik taahhütler ve zincir dışı depolama sistemlerini kullanan pek çok iyileştirme önerisi yapılmıştır. Diğer yandan diferansiyel mahremiyet, mahrem bilgi sızdırmadan istatistiksel sorgulamaların yapılmasını sağlayan mekanizmalar ile ortaya çıkan bir gizlilik kavramıdır. Bildiğimiz kadarıyla literatürde diferansiyel mahremiyet açısından Bitcoin'in açık defterini inceleyen bir çalışma yoktur. Bununla birlikte, açık blok zinciri yapısı, gerçek değerleri gizleyecek ve dağıtık defter bütünlüğünün kontrol edilebilirliğini koruyacak diferansiyel mahremiyet mekanizmalarından yararlanabilir. Bu tezde öncelikle, Bitcoin açık blok zinciri için diferansiyel mahremiyetin teorik bir incelemesi sunulmaktadır. Diferansiyel gizlilik formülasyonu kullanılarak mevcut Bitcoin blok zinciri yapısı incelenmektedir. Ardından, Bitcoin blok zincirinde uygulamak için iki farklı gizlilik mekanizmasının fizibilitesi sunulmaktadır: (i) işlem miktarlarına gürültü eklenmesi, ve (ii) kullanıcı grafiğinin pertürbasyonu. Ayrıca, bir açık yazılım kütüphanesi kullanılarak işlem miktarlarına gürültü ekleme uygulanmıştır. Uygulanabilir mekanizmalar ile parametreleri tespit edebilmek için değişken parametre değerleri için dört farklı gizlilik mekanizmasının karşılaştırması yapılmıştır. Bu tezin diğer bir katkısı olarak blok zinciri tabanlı diferansiyel mahremiyeti sağlayan federe bir akıllı hizmet ölçüm çerçevesi önerilmektedir. Müşteriler ve hizmet sağlayıcılar arasında adil bir çözüm sunarken gerçek hizmet tüketimini gizlemek için gürültü ekleme yaklaşımı kullanılmaktadır. Özetle bu tezde, gürültü ekleme ve kullanıcı grafiğinin pertürbasyonu yöntemlerinin diferansiyel mahremiyeti ihlal eden vaka oranını azalttığı gösterilmektedir. Dolayısıyla finansal dağıtık defter uygulamalarında mahremiyeti geliştirmek için kullanılabilecekleri önerilmektedir.","Bitcoin is the pioneering financial distributed ledger system, which captivated researchers with its innovative public blockchain structure. Examinations of this public blockchain resulted in many proposals for improvement in terms of anonymity and privacy. Generally used methods include mixing protocols, ring signatures, zero-knowledge proofs, homomorphic commitments, and off-chain storage systems. On the other hand, differential privacy is a privacy notion coming up with mechanisms that enable running statistical queries without leaking any private information. To the best of our knowledge, in the literature, there is no study examining Bitcoin's public blockchain in terms of differential privacy. However, public blockchain structure can benefit from differential privacy mechanisms for improved privacy, by hiding actual values, and preserving checkability of the integrity of the blockchain. In this dissertation, first, we provide a theoretical examination of differential privacy in Bitcoin public blockchain. We examine the current Bitcoin blockchain structure using the differential privacy formulation. Then, we present feasibility of utilization of two differential privacy mechanisms to be applied to the blockchain of Bitcoin: (i) noise addition to the transaction amounts, and (ii) user graph perturbation. Moreover, we implement noise addition to the transaction amounts by using a public software library. We compare four differential privacy mechanisms using varying parameter values in order to determine the feasible ones. As another contribution of this dissertation, we propose a blockchain-based differentially-private federated smart utility metering framework. We utilize noise addition approach to hide the actual utility consumptions while providing fair settlement among the clients and the utility providers. To sum up, in this dissertation we show that noise addition and graph perturbation methods decrease the fraction of the cases violating differential privacy. Therefore, they can be used for improving privacy in financial distributed ledger applications."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Heterojen otonom sualtı araçlarının (OSA'lar) sualtı görev planlaması, izlenmesi ve koordinasyonu önemli miktarda zaman ve finansal kaynak gerektirir. Bu durum gerçek deniz ortamına çıkmadan önce insansız su altı araçları (İSAA'lar) arasındaki haberleşme ağının yanı sıra sistem dinamiklerinin gerçekçi bir şekilde modellenmesi için bir simülasyon ortamı oluşturulması gerekliliğini doğurmuştur. Mevcut çözümler, sualtı araçlarının dinamiklerini modelleme yeteneğine sahip olsa da karmaşıklık nedeniyle, önceki çalışmalarda haberleşme ağlarının entegrasyonu dikkate alınmamıştır. Bu konuyu ele almak için, bu tezde gerçek dünya deniz senaryolarının ayrılmaz bir parçası olan İSAA'ların birbirleriyle iletişim kurmasını sağlamak için Ağ bağlantılı kontrol sisteminin (AKS) yeni bir tasarımı ve gerçekçi benzetimi sunulmaktadır. Sualtı haberleşmesi çoğunlukla akustik haberleşmeye dayanır. Akustik haberleşmede kullanılan kontrol kazançları sınırlı bir veri hızı ile birlikte yayılma gecikmesi nedeni ile kısıtlıdır. Bu tezde, uzun mesafeli haberleşme ve kontrol için akustik bağlantının ve kısa mesafede radyo frekansı (RF) bağlantısının bırlıkte kullanıldığı bir Ağ bağlantılı Kontrol Sistemi kurmak için hibrit bir akustik ve RF haberleşme sistemi önerilmiştir. Ayrıca, kullanılan haberleşme kanallarındaki veri hızlarını iyileştirmek için tam çift yönlü (TÇY) haberleşme kullanılması önerilmiştir. Tam çift yönlü haberleşme, yarı çift yönlü haberleşme ile aynı bant genişliğini kullanırken kablosuz bağlantıların veri aktarım hızlarını ikiye katlama potansiyeline sahiptir. Önerilen su altı hibrit ağ bağlantılı kontrol sistemi için bir uygulama olarak, yanaşma manevralarının OSA'lar tarafından gerçekleştirildiği bir senaryo ele alınmıştır. Önerilen senaryoda, akustik veya RF haberleşme yoluyla OSA'ların konumunu belirleyen bir yerleştirme istasyonu bulunmakta ve haberleşme türüne bağlı olarak araçların iletimini koordine etmek için farklı ortam erişim kontrolü (OEK) protokolleri kullanılmaktadır. TÇY haberleşme kullanılarak, su altı hibrit AKS sisteminin, standart yarı çift yönlü haberleşmeden daha hassas ve hızlı yanaşma manevraları yapması mümkün olabilmekte, gerekli seyir verileri daha yüksek sıklıkla sağlanarak AKS'nin daha yüksek verimlilikte çalışması sağlanabilmektedir. OSA'ler yanaşma manevrası yapmak için iki tür kontrolörle donatılmıştır: Orantılı İntegral Türev (PID) ve Lineer Kuadratik Düzenleyici (LQR) kontolörü. Kontrolörün kazançları ve örnekleme süreleri, su altı hibrit AKS'nin çalışmasına göre belirlenir. AKS'de kullanılan haberleşme protokolüne bağlı olarak, paket gecikmeleri, dolayısıyla örnekleme süreleri farklılık gösterebilir, bu da kontrolörün kazanımlarının optimize edilmesini gerektirir. Bu amaçla, bu tezde, PID kontrolör için Sıralı Model Algoritması Konfigürasyonu (SMAC) yöntemi uygulanarak kontrolörün kazançlarının optimizasyonunu önerilmektedir. LQR kontrolör için de, bir OSA'nin hidrodinamiğini matematiksel olarak modelleyerek, sistemlerin bozulmaları ve nonlineerlikleri üzerinde daha iyi kontrol sağlanması amaçlanmıştır. Önerilen su altı ağ bağlantılı kontrol sisteminin gerçek zamanlı davranışı, OSA'ları kontrol etmek için tüm sistemin bütün dinamikleri göz önüne alınarak, farklı simülatörleri birlikte kullanan entegre bir simülasyon ortamında, gerçekçi bir şekilde değerlendirilmektedir. Performans sonuçları, durgun su koşullarında, LQR kullanan önerilen TÇY hibrit AKS'nin yaklaşık 62 saniyelik en kısa yanaşma süresine ulaştığını, TÇY modunda SMAC ile optimize edilmiş yaklaşımın ise yaklaşık 97 saniye sürdüğünü göstermektedir. Ayrıca, LQR kontrolörü ile akustik bağlantıda TÇY modunun kullanılması yanaşma süresini yaklaşık 78 saniye azaltmaktadır. Buna karşılık, PID tabanlı yöntem için yerleştirme (kenetlenme) süresi neredeyse ikiye katlanarak 148 saniyeye çıkmıştır. Sualtı hibrit AKS, iki kontrolör, farklı OEK protokolleri ve TÇY ve Yarı Çift Yönlü (YÇY) iletişim modları kullanılarak gerçekçi dalgalanan su akımları altında da değerlendirilmektedir. Deneylerimiz, önerilen TÇY hibrit AKS'nin bu tür akımlara maruz kaldığında kenetlenme süresinin 90 saniye olduğunu, SMAC için optimize edilmiş PID'nin ise yaklaşık 175 saniye sürdüğünü göstermektedir. Buna karşılık, gerçekçi akımlar için LQR kullanan geleneksel akustik tabanlı AKS'de TÇY modunun yanaşma süresi yaklaşık 120 saniyeyken, SMAC için optimize edilmiş PID yaklaşık 245 saniye sürmektedir. Hibrit TÇY kullanarak edinilen performanstaki iyileştirmeye karşılık, akustik sistemden %70 daha fazla hareket enerjisi harcanmaktadır. Akıntı hızı 0,3 m/s'yi aşarsa, SMAC için optimize edilmiş PID kullanan iletişim modlarının yanaşma manevralarını tamamlayamadığı görülmüştür. Öte yandan, LQR tabanlı yöntemler 0,7 m/s'ye kadar akıntı hızlarını kaldırabilmektedir. Bu hızda, geleneksel akustik tabanlı sistemlerin yanaşmayı tamamlaması, önerdiğimiz TÇY hibrit sistemimizden yaklaşık %140 daha uzun sürer. Bu sonuçlar, OSA kontrolü için önerilen TÇY hibrit haberleşme yaklaşımının kullanılmasının uygulanabilirliğini ve avantajlarını göstermektedir.","Underwater mission planning, monitoring, and coordination of heterogeneous autonomous underwater vehicle (AUV)s require a considerable amount of time and financial resources. This has led to the requirement of establishing reliable communication networks among unmanned underwater vehicle (UUV)s as well as a simulation environment to realistically model the system's dynamics before actual testing in sea trials. Even though existing solutions can model the dynamics of underwater vehicles, due to complexity, the integration of real-time communication networks has not been considered in the works. To address this issue, this thesis presents an innovative design and realistic co-simulation for a networked control systems (NCS) to achieve navigation of UUVs through communication and control, which is a critical component of real-world marine applications. Traditionally, underwater communication has been based on acoustic communications, characterized by limited data rate and considerably large propagation delay. Taking this issue into consideration, in this thesis, a hybrid acoustic and radio frequency (RF) communication framework is proposed for the underwater NCS where an acoustic link is used for long distance communication and control, and an RF link is employed in the short range. Additionally, to maximize spectrum efficiency, adopting full duplex (FD) communication is proposed for both underwater acoustic and RF links. FD communication enables the feedback signal of the NCS to be transmitted rapidly to several AUVs through simultaneous transmission and reception. For the proposed underwater hybrid NCS, a docking scenario is considered, where AUVs perform maneuvers towards a docking station fixed at the seabed. In this scenario, the docking station determines the position of the nearby AUVs, and acoustic or RF communication links carry the position and navigation information from the docking station to AUVs via different medium access control (MAC) protocols. With the help of FD communication, it can be ensured that the underwater hybrid NCS system operates at maximum efficiency, providing the required feedback signal more frequently than NCS with half-duplex communication, resulting in faster and more accurate docking. The AUVs are equipped with two types of controllers for pursuing and actuating docking maneuver: Proportional Integral Derivative (PID) and Linear Quadratic Regulator (LQR) controller, whose gains and sampling times are determined according to the operation of the underwater hybrid NCS. Depending on the communication protocol used in the NCS, protocol delays may be different which forces a change in the sampling times. The different delays of the control loop require further changes in the controller gains to avoid instability. For this purpose, in this thesis, optimization of the controller gains is proposed for the underwater hybrid NCS by applying Sequential Model Algorithm Configuration (SMAC) method for the PID controller and for the LQR controller, by mathematically modeling the hydrodynamics of the AUV to provide better control over disturbances and nonlinearity. By considering the full dynamics of the entire system for controlling the AUVs, the real-time behavior of the underwater networked control system is evaluated realistically using the proposed integrated co-simulation environment, which includes different simulators working together. The performance results indicate that under calm water conditions, our proposed FD underwater hybrid NCS using LQR achieves the shortest docking time of approximately 62 seconds, while the corresponding SMAC optimized approach in FD mode takes around 97 seconds. Furthermore, using FD mode on the acoustic link with the LQR controller reduces the docking time by about 78 seconds. In contrast, for the PID-based method, the docking time is almost doubled to 148 seconds. The underwater hybrid NCS is also evaluated under realistic fluctuating water currents, using two controllers, different MAC protocols, and FD and HD communication modes. Our experiments indicate that with LQR, the proposed FD underwater hybrid NCS's docking time, when exposed to such currents, is 90 seconds, while the SMAC optimized PID takes approximately 175 seconds. In contrast, the conventional acoustic-based HD mode using LQR for realistic currents has a docking time of around 120 seconds, while the SMAC optimized PID takes about 245 seconds. The penalty to achieve improved performance using FD hybrid is spending 70% more motive energy than the acoustic only system. It is worth noting that communication modes using SMAC optimized PID cannot complete docking maneuvers if the current speed exceeds 0.3m/s, while LQR based methods can handle current speeds up to 0.7m/s. At this velocity, conventional acoustic-based systems take about 140% longer to complete docking than our proposed FD hybrid system. These results demonstrate the feasibility and advantages of using the proposed FD hybrid communication approach for AUV control."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevrimiçi haberlerdeki dijitalleşme, haber yazma endüstrisini hem değiştiriyor hem de demokratikleştiriyor. Son yıllarda haber kaynaklarının sayısındaki büyük artış, ilgili haber makalelerini veya arka plan bilgisi sağlayan ve okuyucunun deneyimini geliştiren varlıkları birbirine bağlayan otomatik yöntemler üzerinde araştırma yapılmasını gerektirdi. Bu çalışmada, haber makaleleri bağlamında üç farklı görevi ele alıyoruz: Vikifikasyon, Varlık Sıralama ve Geçmiş Bağlantısı. Bu görevler üzerinde yapılan çalışma, News Track of Text Retrieval Conference (TREC) görevleriyle uyumludur. Vikifikasyonda, maddelerde adı geçen varlıkların bir listesini tespit eder, bunları ilgili Vikipedi girişlerine bağlar ve varlık listesini maddeyle alakalarına göre sıralarız. Bağımsız Varlık Sıralaması görevi, yalnızca listede belirtilen varlıkların verildiği Vikifikasyonun son sıralama adımı ile ilgilidir. Gemiş Bağlantısında ise görev, bir sorgu haber makalesi için verilen ilgili makalelerin bir listesini almak ve sıralamaktır. Bu görevler için önerilen çözümlerimiz, derin modellemeye ve benzerlik ve alaka düzeyini tahmin etmek için vektör temsillerini kullanmaya yöneliktir. Varlık Sıralaması için, Doc2Vec kullanarak haber makalelerini ve varlıkları kodlarız, ardından varlıkları sıralamak için çift arasındaki yakınlığı kullanırız. Vikifikasyona gelince, varlık ifadelerini tespit etmek ve bahsedenleri ve varlıkları vektör temsillerine kodlamak için dönüştürücü tabanlı mimariler kullanıyoruz. Bu vektörler, varlığı bağlayan sistemin bir parçası olarak aday bulma ve sıralama için kullanılır. Geçmiş Bağlantısında, haber makalelerini kodlamak ve makaleler arasındaki alaka düzeyi sıralaması için ince ayar yapmak için yine dönüştürücü tabanlı bir dil modeli kullanıyoruz. Değerlendirme sırasında, derin karmaşık mimarileri kullanmanın getirdiği kaliteyi veya performans artışını analiz etmek için yaklaşımlarımızı klasik bilgi erişim sistemleriyle karşılaştırıyoruz. Varlık bağlama ortamında alaka düzeyini ölçmek için Doc2Vec ve Kosinüs benzerliğini kullanmanın yüksek performans sağladığı görülmüştür. Vikifikasyon'da, adayların belirlenmesi sırasında bağlamsal kodlamanın ile yoğun vektör araması yapmak, diğer yöntemlerle benzer performans göstermiştir. Bununla birlikte, aday varlık sıralaması için bağlamsal kodlamanın kullanılması, Vikifikasyon performansını önemli ölçüde artırır. Geçmiş Bağlantısında kullanılan dönüştürücü tabanlı yeniden sıralayıcı tam metin arama yöntemini iyileştirmemiştir, ancak ince ayar için daha fazla veri sağlandığında sonuçlarda umut verici gelişmeler gözlenmiştir.","The ongoing digitization of online news has changed and democratized the industry of news writing. The huge increase in the number of news sources has called for research on automated methods that link relevant news articles or entities that provide background information and enhance the reader's experience. In this work, we tackle three different tasks in the context of news articles: Wikification, Entity Ranking, and Background Linking. The work done on these tasks is in alignment with the tasks in News Track of Text REtrieval Conference (TREC). In Wikification, we detect a list of mentioned entities in articles, link them to their corresponding Wikipedia entry and rank the list of entities in terms of relevance to the article. Standalone Entity Ranking task is only concerned with the final ranking step of Wikification where the list mentioned entities are given. As for Background Linking, the task is to retrieve and rank a list of relevant articles given a query news article. Our proposed solutions for these tasks are oriented towards deep modelling and using vector representations to estimate similarity and relevance. For Entity Ranking, we encode news articles and entities using Doc2Vec then use proximity between the pair to rank entities. As for Wikification, we use transformer-based architectures for detecting entity mentions and encoding mentions and entities into vector representations. These vectors are used for candidate retrieval and ranking as part of the entity linking pipeline. In Background Linking, we again use a transformer-based language model to encode news articles and fine-tune it for relevance ranking between articles. For evaluation, we compare our approaches to classic information retrieval systems to analyze the quality or increase in performance brought by using deep complex architectures. Using Doc2Vec and Cosine similarity to measure relevance in a setting of perfect entity linking yields high performances. In Wikification, encoding mentions and performing dense vector search for candidate retrieval performs on-par with baseline. However, using contextual encoding for candidate entity ranking significantly improves the Wikification performance. The transformer-based re-ranker used in Background Linking does not improve over full-text search baseline but shows promising improvements in results when provided with more data for fine-tuning."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal medya platformlarının dünyada yaygınlaşıp daha fazla insana ulaşmasıyla yazılımla kontrol edilen hesapların sayısı giderek arttığı için, bot hesapların normal kullanıcılar üzerindeki manipülatif ve yanıltıcı etkilerini önlemek açısından, bot hesapların doğasını anlama ihtiyacı ortaya çıkmıştır. Bu çalışma, Twitter platformundaki bot ve insan hesaplar arasındaki gizli ve ayrıştırılabilen örüntüleri ortaya çıkarmaya çalışan karmaşıklık analizleri üzerine yoğunlaşmıştır. Twitter API ile toplanan 14 adet erişime açık, daha önce yapılan akademik çalışmalarda kullanılmış verisetleri kullanılmıştır. Bu araştırmadaki karmaşıklık analizi iki aşamadan oluşmaktadır, hesap davranışlarının karmaşıklığının niceliklendirilmesi ve profil özelliklerinin boyutunun azaltılması. Hesap karmaşıklığının değerlendirilmesi; hesap davranışlarının bir metin olarak kodlanıp, bu metin içerisindeki örüntülerin ve tekrarların sıkıştırılması ile örüntüsel davranışlarının derecesinin ortaya çıkarılması ve Varyasyonel otokodlayıcılar kullanılarak hesap profil özelliklerini en az bilgi kaybı ve en çok sıkıştırılabilirlikle ölçen bir yöntem ile yapılmaktadır. Verisetlerinin kendi arasında ve insan ile bot hesaplar arasındaki kıyaslamalar açısından, iki yöntem ile de bulduğumuz sonuçlar çoğunlukla birbirleriyle tutarlı çıkmıştır. Sonuçlarımızı desteklemek ve doğrulayabilmek amacıyla, ayrık zamansal Markov Zincirleri kullanarak hesapların bir sonraki davranışını tahmin etmeye çalışarak, bu tahminlerin doğruluğunu değerlendirdik. Sonuç olarak, insan ve bot hesapların karmaşıklıklarını analiz edip, farklı veri setleri için karmaşıklık seviyeleri elde ettik. Bu çalışmanın bot algılama sistemlerinin sağlamlığını geliştirmek için kullanılabileceğine inanıyoruz.","As the number of automated accounts grew rapidly in parallel with social media platforms gain more users around the world, there is a growing need to understand the nature of bot accounts to prevent their manipulative and misleading effects on ordinary users. This study focused on complexity analysis of users on the Twitter platform to reveal the hidden and differentiating patterns between human and bot accounts, using 14 publicly available datasets collected through the Twitter API and labelled with different annotation methods. The analysis consists of two parts, quantifying the complexity of account behavior and reducing the dimensionality of profile information. In our research, the assessment of account complexity is performed by encoding account activities into sequence of codes and compressing the repetitions and patterns about it. For the profile information, we developed a heuristic method to determine how much of an account's profile features can be compressed with minimal loss of information using variational autoencoders. The results for both parts of our analyzes are largely consistent with each other in terms of comparing complexity with different datasets and between human and bot accounts. We validated and corroborated our findings by predicting the next activity of accounts and calculating the accuracy of the predictions using discrete-time Markov Chains. Consequently, we analyzed the complexity of bot and human accounts and had complexity levels for each bot dataset we used, and we hope this study will lead to develop measures to quantify robustness of bot detection systems."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsanların maruz kaldığı güneş ışığı miktarı ve sosyal saat, Yaz Saati Uygulaması (DST) politikasıyla doğrudan ilgilidir. Bu politikanın çıkış noktasında İş verimliliğini artırmak ve enerji kullanımını azaltmaktı, ancak günümüzde uygulamanın insan psikolojisi ve sağlığı üzerindeki etkileri odak noktası durumunda. Bu çalışma kapsamında, 2011 ve 2021 yılları arasını kapsayan ve Türkçe Tweetler içeren bir veriseti kullanılarak, DST'nin insanlar üzerindeki psikolojik etkilerini gözlemlemek için bir sosyal medya duygu analizi gerçekleştirildi. Türkiye'nin 2016 yılında uygulamadan ayrılması çıkması, DST'nin uygulandığı ve uygulanmadığı dönemleri karşılaştırabilme avantajı sağlıyor. Bu karşılaştırmaya göre, ilkbaharda saatleri bir saat ileri almak, takip eden 15 günde atılan tweetlerin ortalama duygu puanlarında özellikle akşam saatlerinde önemli bir artışa yol açıyor. Ayrıca, politikanın uygulandığı yıllarda, ilkbahar sabahlarının ortalama duygu-durum skorlarının, sonbahar sabahlarının skorlarına göre anlamlı ölçüde yüksek olduğunu gözlemledik. Gün-içi ve mevsimsel analizlerin sonuçları, DST politikası nedeniyle saatlerdeki kaymaların, özellikle günün sabah ve akşam saatlerinde insanların duygularında anlamlı farklılıklar yarattığını göstermiştir.","The amount of sunlight people are exposed to and the social clock is directly related to Daylight Saving Time (DST) policies. Increasing work efficiency and reducing energy consumption were the original motivations for the policy, but nowadays the effects on human well-being and health are controversial topics. We conducted a social media sentiment analysis to observe the psychological impact of DST on people using a random sample of Turkish tweets between 2011 and 2021. Turkey's exit from the policy in 2016 provides us with an opportunity to compare the periods when DST was applied and when it was not. From this comparison, we find that setting the clocks forward by one hour in the spring (spring-forward) leads to a significant increase in the average sentiment scores of tweets posted over the following 15 evenings. We also found that in DST years, average sentiment scores are significantly higher on spring mornings than on fall mornings. The results of the diurnal and seasonal analyses show that the time shifts due to daylight saving time lead to significant differences in people's moods, especially in the morning and evening hours of the day. Our methodology also helps us point to important societal events in this 10-year observed period. We hope that our findings will lead to the design of better policies for Turkey and improve collective well-being."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde, tüketicilerin sosyal medya platformlarına kanalize olması ile birlikte firmaların ve markaların, sosyal medya platformları üzerinden reklam ve tanıtım yapma talepleri de sürekli olarak artmaktadır. Farklı reklam ve tanıtım arayışı içerisine girmiş olan firmalar ve markalar, bir metod olarak da fenomenleri kullanmaktadır. Fenomenlerle, hikaye başı veya paylaşım başı bir ücret üzerinden anlaşarak, ürünlerinin tanıtımını yaptırmaktadırlar. Sosyal medya kullanıcıların giderek artması, fenomen marketi içerisindeki yarışın da büyümesine yol açmıştır. Bazı fenomenler literatürde bahsedilen etkileşim metriklerini olduğundan daha yüksek gösteren çeşitli metodlar kullanmaya başlamışlardır. Bunlardan bir tanesi de bot hesaplara, kendi hesaplarını takip ettirmeleridir. Bunun sayesinde, her ne kadar fenomenlerin etkileşim sayıları yüksek gibi gözüküyor olsa da, organik etkileşim oranını bulanıklaştırmıştır. Bu tezde, literatüre, organik etkileşimleri, kullanılmakta olan etkileşim metriklerine göre daha doğru tespit edebilecek, yeni bir metrik sunuyoruz. Sunduğumuz bu metrik, yapılan değerlendirmeler sonucunda, literatürde kullanılmakta olan metriklere göre daha iyi bir performans sunduğu gözlemlenmiştir. Bunun yanında, bu metriği kullanarak oluşturulmuş bir fenomen tavsiye sistemi tanıtıyoruz. Bu sistem sayesinde, hedef fenomene göre organik etkileşim miktarı daha yüksek ve aynı temayı konu alan başka bir fenomen seçebilmek mümkün kılınıyor.","Today, as consumers are channeled to social media platforms, the demands of companies and brands to advertise and promote on social media platforms are constantly increasing. Companies and brands that have been searching for different advertising and promotion approaches use influencers. They make an agreement with the influencer on a fee per story or per post to promote their products. The increasing number of social media users has led to the growth of the race within the influencer market. Some influencers have begun to use various methods that boost their engagement metrics artificially. Purchasing bot followers or automated engagement are examples of such manipulative efforts. As a result of this, although the engagement numbers of influencer seem high, they have blurred the organic engagement rate and misled the companies that hire influencers. In this thesis, we present a new metric, the CRE (capture-recapture engagement) score, to the literature that can detect organic interactions more accurately than existing interaction metrics used in influencer marketing agencies. As a result of the evaluations made, it has been observed that the metric we presented offers better performance than the metrics used in the literature. In addition to this, we introduce an influencer recommendation system built by using the CRE score. The proposed system can identify influencers that have higher engagements while preserving the similarity of the profile content with the target user. This approach provides opportunities to select highly engaging but less popular influencers."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu makale, hedef sosyal medya hesaplarındaki anormallikleri tespit etmeyi amaçlamaktadır. Bu konu adına yapılan önceki çalışmalar, farklı türde yöntemlerle bot tespit uygulamalarını içermektedir. Bununla birlikte, Anomali tespiti, sosyal robotları kapsayan daha genel bir çerçevedir. Anormalliklerin yakalanması, sosyal medyada görülebilen olası anormallik türlerinin belirlenmesiyle başlar. Bu çalışmada Twitter'ı hedefleyen toplu ve nokta anomali tespit türlerini ele aldık. Algoritmamız, Twitter'dan çıkarılan özellikleri ve diğer iki veya daha fazla özelliğin oranı olan sentetik olarak oluşturulmuş özellikleri içerir. Gerçek dünya örneklerini algılayabilen bir anormallik algılama yaklaşımı oluşturmak için deneyler oluşturuyoruz. Çalışmamız, deneysel bir ortamda yukarıdaki anormallik türlerini yakalayan hem denetimli hem de denetimsiz makine öğrenimi modellerine odaklandı. Bu modeller sınıflandırma algoritmaları içerir. Modelimizin deneysel olmayan bir ortam olan Twitter'da kullanılmasının yararlı olup olmayacağını anlamak için farklı senaryolar kullandık. Bu senaryoları 1%-10% arasında anomali oranı altında test ettik. Sonuç olarak, bu çalışmadaki deneylerin amacı denetimli & denetimsiz anomali tespit tekniklerinin bu anormal hesapları yakalayabildiğini göstermektir.","This paper aims to detect anomalies in target social media accounts. Previous work on behalf of this topic includes bot detection applications with different types of methods. However, Anomaly detection is a more general framework that encapsulates social bots. Capturing anomalies starts with specifying possible anomaly types that can be seen in social media. In this study, we covered collective and point anomaly detection types targeting Twitter. Our algorithm includes features extracted from Twitter and synthetically created features which is the ratio of two or more other features. We create experiments to build an anomaly detection approach that can detect real-world examples. Our study focused on both supervised and unsupervised machine learning models that capture the above anomaly types in an experimental environment. These models contain classifying algorithms. We used several scenarios to understand whether our model will be useful to use in a non-experimental environment, Twitter. We tested these scenarios under an anomaly ratio between 1%-10%.In conclusion, the experiments in this study have the purpose to demonstrate the outcomes of supervised & unsupervised anomaly detection techniques can capture these anomalous accounts."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akademik performansı üretkenlikle ölçmeye yönelik mevcut çalışmalar, doktora öğrencilerinin psikolojik refahlarına dair ciddi endişeler uyandırmaktadır. Bu çalışmalar genellikle araştırmacıların çevresinin etkisini ihmal etmektedir. Tez alt bölümlerinden biri olan Teşekkür, öğrencilerin kendilerini destekleyen kişilere teşekkür etmelerine olanak sağlayarak bu çevreye ışık tutmaktadır. Bu çalışmada, öğrencileri doktora sürecinde destekleyen beş farklı topluluğu ortaya çıkaran bir ""akademik destek ağı"" oluşturmak için 26.236 tezin Teşekkür bölümü analiz edilmiştir: Akademik, Yönetim, Aile, Arkadaşlar \& Meslektaşlar ve Manevi. Kadın öğrencilerin aileleri dışında bu toplulukların her birinden daha az kişiye teşekkür ettikleri ve yayın sayılarına bakıldığında verimliliklerinin erkeklere göre biraz daha düşük olduğu görülmektedir. Bu kritik öneme sahiptir çünkü doktora sürecini incelemenin, kadınların akademik kariyerlerinin başlarında karşılaştıkları olumsuz koşulları daha iyi anlamamıza yardımcı olabileceği anlamına gelmektedir. Ayrıca, teşekkür edilen kişi sayıları disiplinler arasında değişmekte ve bu disiplinlerin ``bireysel bilim'' ya da ``takım bilimi'' olarak kategorize edilmesini sağlamaktadır. Bununla birlikte akademik topluluklarından daha fazla kişiye atıfta bulunan erkek öğrenciler daha yüksek verimlilik seviyeleri ile ilişkilendirilebilmektedir. Üniversite sıralamalarının ise üretkenlik ve akademik destek ağlarının boyutu ile pozitif ilişkili olduğu bulunmuştur. Ancak, ne üniversite sıralamaları ne de öğrencilerin üretkenlik düzeyleri, öğrencilerin teşekkürlerinde ifade ettikleri duyguların pozitifliği ile ilişkilendirilememektedir. Sonuçlarımız, akademik destek ağlarının nasıl farklılık gösterdiklerini ve üretkenliği nasıl etkilediklerini açıklayarak çevresel faktörlerin önemine işaret etmektedir.","Current practices of quantifying academic performance by productivity raise serious concerns about the psychological well-being of graduate students. These efforts often neglect the influence of researchers' environment. Acknowledgments subsections in dissertations shed light on this environment by providing an opportunity for students to thank the people who supported them. We analyzed 26,236 acknowledgments to create an ""academic support network"" that reveals five distinct communities supporting students along the way: Academic, Administration, Family, Friends \& Colleagues, and Spiritual. We show that female students mention fewer people from each of these communities, with the exception of their families, and that their productivity is slightly lower than that of males when considering the number of publications alone. This is critically important because it means that studying the doctoral process may help us better understand the adverse conditions women face early in their academic careers. Our results also suggest that the total number of people mentioned in the acknowledgements allows disciplines to be categorized as either individual science or team science as their magnitudes change. We show that male students who mention more people from their academic community are associated with higher levels of productivity. University rankings are also found to be positively correlated with productivity and the size of academic support networks. However, neither university rankings nor students' productivity levels correlate with the sentiments students express in their acknowledgements. Our results point to the importance of academic support networks by explaining how they differ and how they influence productivity."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir konu hakkında bilgi edinme, bireyin bu konuyla ilgili tüm kavramları aşamalı olarak anlamasını gerektiren karmaşık bir süreçtir. Bireyler için öğrenme deneyimi, öğrenme için bir rehber görevi gören temel özellikleri çizge şeklinde görselleştirerek geliştirilebilir. Öğrencileri, düğümler olarak temsil edilen kavramları, doğrudan kenarlarla gösterilen önkoşul sıralarına göre incelenecek şekilde sıralayan bir kavram haritası ile donatmak, doğru patikada kalmalarına yardımcı olur. Bununla birlikte, otomatik önkoşul tespiti için mevcut algoritmalar çok hatalı sonuçlar verebilmektedir, bu durum önkoşul ilişkisi tamamen güvenilir olduğu varsayıldığından öğrencilerin bu tür kavram haritalarına olan güvenini azaltır. Bu çalışmada, önkoşul yerine bir kavramın diğeriyle ilişkili olduğunu gösteren kapsama ilişkisini kullanmayı öneriyoruz. Belirli bir kavramın önkoşullarının çoğu, kavramın kendisinden daha az zor olduğu için, kapsama ilişkisini kavramın zorluk puanları ile birleştirmenin, önkoşula benzer anlamı kodladığını savunuyoruz. Ancak, önkoşul ilişkisinden farklı olarak kapsama ilişkisinin daha az kısıtlı olması nedeniyle, potansiyel olarak yanlış tespit edilen kapsama ilişkileri öğrenciler tarafından göz ardı edilebilir. Bu tür ilişkiler daha çok tavsiyeler olarak kabul değerlendirilebilir. Buna karşılık, ortaya çıkan kavram haritasındaki kenarların güvenilirliğine ilişkin algıdaki bu değişiklik, öğrenciler için daha az hayal kırıklığı yaratır. Ayrıca, kavram haritasının inşasına özel bir yöntem tasarlamak için iki ek husus, yapılandırılmamış doğası ve öğrenme materyallerinin bolluğu da dikkate alınmalıdır. Bu bağlamda, bu tez ile, yapılandırılmamış metinsel öğrenme materyallerinden, kavram zorluğunu düğüm rengi olarak kodlayan ve kavramları kapsama kenarları aracılığıyla birbirine bağlayan bir kavram haritasını otomatik olarak oluşturmayı amaçlamaktayız. Bu amaçla, problemi iki alt işe ayırıyoruz: yapılandırılmamış metinden kavramların çıkarılması ve bunların arasına kapsama kenarları eklemeden önce çıkarılan her kavramın zorluğunu tahmin ederek kavram haritasının oluşturulması. Özetle kavramları çıkarmak için denetimsiz bir yöntem geliştirildi. Yapılandırılmamış metinsel öğrenme materyalleri kullanan ve yeni bir denetimsiz yöntemle ikinci alt işte tanımlanan kavramların her biri için bir zorluk puanı hesaplandı. Bu yolla kavram çıkarma yöntemimizin mevcut en son teknoloji yöntemlerden daha doğru olduğunu gösterdik. Bildiğimiz kadarıyla, kavramın zorluğunu bulmak için ilk denetimsiz yöntemi bu tezde önermiş olduk. Deneylerimiz, önerilen zorluk tahmin yöntemimizin uygulanabilirliğini göstermektedir. Ayrıca, belirli bir kavramın ön koşullarının kavramın kendisinden daha kolay olma eğiliminde olduğu gerçeği de metodolojimizi uygulanabilir kılan temel varsayımımız için kanıt sağlamaktadır. Bu bulgular, önerilen metodolojimizin, bireylerin pratikte kavramlar arasında daha başarılı bir şekilde yol almasını sağlayan kavram haritalarının oluşturulmasında faydalı olduğunu göstermektedir.","Acquiring knowledge about a topic is a complex process that requires an individual to gradually understand all concepts related to this topic. The learning experience for individuals can be enhanced by visualizing the key characteristics that serve as a guide for learning. Equipping learners with a concept map that orders concepts, represented as nodes, to be studied according to their prerequisite order, indicated by direct edges, helps them stay on track. However, existing algorithms for automatic prerequisite detection are too inaccurate, which reduces learners' trust in such maps as one assumes the prerequisite relation to be completely reliable. In this work we propose to replace prerequisite relations with less authoritative coverage relations, as they indicate only that one concept is broader and related to another one. Since most of the prerequisites of a given concept are less difficult than the concept itself, we argue that combining the coverage relation with concept's difficulty scores encodes similar semantics as the prerequisite relation. However, due to the coverage relation being less authoritative, potentially inaccurately detected coverage relations may be ignored by learners. Such relations are considered more like recommendations instead of facts. In turn, this change in perception about the reliability of the edges in the resulting concept map creates less frustration for learners. Further, two additional aspects, the unstructured nature and the abundance of the learning materials should also be considered for devising a scalable method for concept map's construction. With this in mind, this thesis aims to automatically construct from unstructured textual learning materials a concept map that encodes concept difficulty as node color and connects concepts through coverage edges. To that end, we divide the problem into two subtasks: extracting concepts from unstructured text and constructing the concept map by estimating the difficulty of each extracted concept before inserting coverage edges among them. Specifically, we first develop an unsupervised method to extract concepts from unstructured textual learning materials and then compute a difficulty score for each of the identified concepts in the second subtask with a novel unsupervised method. We find that our concept extraction method is more accurate than existing state-of-the-art methods. To the best of our knowledge, we have proposed the first unsupervised method for finding the concept's difficulty. Our experiments demonstrate the feasibility of our proposed difficulty prediction method. It also provides evidence for our core assumption that prerequisites of a given concept tend to be easier than the concept itself, which renders our methodology viable. These findings imply that our proposed methodology yields concept maps for courses that help individuals navigate concepts more successfully in practice."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir metin belgesinin, özellikle eğitim materyallerinin zorluğunu bilmenin birçok faydası vardır. Bunlardan biri, okuduğunu anlamayı en üst düzeye çıkarmak amacıyla belirli bir hedef gruba yönelik uyarlanmış belgeler önermektir. Doküman zorluğunu etkileyen farklı faktörler mevcut olmakla birlikte, bu faktörler doküman zorluğunun farklı yönlerini yakalarlar. Bunlardan biri, sözdizimsel ve sözcüksel metin özelliklerini yakalayan ve dilbilimsel zorlukla ilgili olan okunabilirliktir. Bir diğeri, okuyucuların belirli bir dokümanı anlaması için gereken bilgi birikimidir, çünkü dokümandaki kavramlar okuyucu için karmaşık olabilir. Her iki faktör de ayrı ayrı analiz edilmiş olsa da, bu faktörlerin karşılıklı etkileşimleri bilinmemektedir. Benzer şekilde, bu faktörlerin doküman zorluğunu tahmin etmekteki önemi birlikte incelenmemiştir. Bu sorunlardan herhangi birinin ele alınması, doküman zorluğunun anlaşılmasını iyileştirebilir ve böylece doküman zorluğunu tahmin etmek için daha güvenilir modellerin yolunu açabilir. Bu nedenle, bu çalışma, bir dokümanın zorluğunu tahmin etmek için gereken bilgi birikimi ve okunabilirliği ile ilgili 20 özniteliği çıkaran gözetimli bir model önererek her iki sorunu da araştırmaktadır. Bu model, doküman zorluğunu tahmin etmek için bu öznitelikleri önemini ve gereken birikim bilgisi ile okunabilirlik arasındaki karşılıklı etkileşimi analiz etmenin temelini oluşturur. Kullandığımız tüm veri kümelerinde okunabilirliğin gereken bilgi birikiminden daha önemli olduğunu gözlemledik. Bildiğimiz kadarıyla, eğitim alanında belge zorluğunu tahmin etmek için mevcut bir veri seti yok, bu nedenle biyolojik kavramlar hakkında bir veri seti oluşturduk. Bu karşılaştırmalı veri setini, daha fazla araştırmayı teşvik etmek ve farklı alanlarda belge zorluklarını tahmin etmeye yönelik yöntemlerin güvenilirliğini değerlendirmek için daha fazla veri sağlamak umuduyla araştırma topluluğuna sunuyoruz.","Knowing the difficulty of a text document, in particular learning materials, has many benefits, such as recommending documents that are tailored towards a specific target group with the goal of maximizing understanding when reading these recommended documents. While different factors exist that affect document difficulty, they capture different aspects of it. One of which is readability, which captures syntactical and lexical text properties and relates to linguistic difficulty. Another one is the background knowledge needed for readers to understand a given document because concepts therein might be more or less complex. Although both factors have been analyzed in isolation, their interplay is unknown. Similarly, the importance of both factors has not been examined, although addressing any of those problems could improve the understanding of document difficulty and thus pave the way towards more reliable models for predicting document difficulty. Hence, this work investigates both problems by proposing a supervised model that extracts 20 features related to background knowledge and readability of a document to predict its difficulty. This model serves as the basis for analyzing the importance of these features and the interplay between background knowledge and readability for estimating document difficulty. We find that linguistic difficulty is more important than background knowledge across all datasets. To the best of our knowledge, there are no datasets in the educational domain available for predicting document difficulty, thus we created one about biological concepts. We release this dataset to the research community in the hope to stimulate more research and provide more data to assess the reliability of methods for predicting document difficulty across different domains."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Birçok ülkede, hastaların temel klinik ve idari verileri artık sistematik olarak toplanıyor, kaydediliyor ve dijital formatlarda saklanıyor. Hastaya özel bu tıbbi verilere elektronik sağlık kayıtları (ESK) adı verilir. ESK'ler birçok farklı veri tipi içerir ve hastanın sağlık sistemi ile sağlık hizmeti sağlayıcısı ile karşılaşmalarındaki etkileşimi yakalar. Tıbbi verilerin sistematik ve dijital olarak toplanması, sağlık hizmetlerini geliştirmeyi hedefleyen, veriye dayalı teknolojiler için önemli bir fırsat sunuyor. Özellikle yoğun bakım üniteleri gibi yüksek belirsizlik ve yüksek risk içeren durumlarda bu sistemler, sağlık hizmeti sağlayıcılarına karar verme süreçlerinde yardımcı olarak tıbbi hataları azaltma potansiyeline sahiptir. ESK'ler sağlık alanındaki çeşitli sorunlara çözüm getirme potansiyeline sahip olsa da doğrudan tahmin modellerinde kullanılamazlar. Bu tezde, elektronik sağlık kayıtlarının makine öğrenim sistemlerinde zorluğa sebep olan özellikleri arasında, seyrek ve heterojen yapısı ile ilgili problemi aşmaya çalıştık. Bu çalışmada, yoğun bakımdaki hastaların farklı türdeki verilerini bilgi çizgesi olarak temsil edip, çizge üzerinde hastaların yoğun gösterimlerini öğrenen bir yöntem sunuyoruz. Sunduğumuz yöntem, sıkça kullanılan bilgi çizge gösterilim öğrenme yöntemlerini kullandık ve öğrenilen gösterimleri farklı yoğun bakım ünitesinde gerçekleşen tahmin görevlerinde kullandık. Bu görevler, yoğun bakım ünitelerinde ölüm tahmini ve kalış süresi tahminini içerdi. Bilgi çizgelerinden öğrenilen hasta gösterimleri, laboratuvar ölçümleri ve yaşamsal belirtileri gösterir veriler ile entegre ettik. Bu alanda örnek gösterilen bir çalışma ile karşılaştırıldığında, önerilen yöntem, dört farklı sınıflandırma görevinin üçünde üstün performans gösterir.","In many countries, key clinical and administrative data of the patients are now systematically collected, recorded, and stored in digital formats. These patient-specific medical data are referred to as electronic health records (EHR). EHR data are rich; they capture patient-health care provider interaction at many encounters over time. This systematic digital collection of medical data presents a significant opportunity for developing data-driven technologies for transforming healthcare. Especially for high-stake situations with high uncertainty, such as in intensive care units (ICUs), these systems have the potential to reduce medical errors by assisting health care providers throughout their decision-making process. While EHRs have the potential to bring solutions to diverse problems in the healthcare ecosystem, their use direct in predictive models is not trivial. Among many properties that yield technical challenges in machine learning systems, we address its sparse and heterogeneous nature. In this study, we propose a strategy where one can unify the heterogeneous data types in a knowledge graph framework and learn a dense patient representation that encodes meaningful information from patient EHRs. Our framework employs widely adapted knowledge graph embedding methods and deploys them in different ICU prediction tasks. These tasks comprise mortality prediction and binarized length of stay prediction tasks. We augment the learned patient representation from the knowledge graphs with lab measurements and vital signs. Compared to a state-of-the-art model, the proposed representation achieves superior performance in three of the four different classification tasks."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Zararlı mobil uygulamalar; devletlere, şirketlere ve son kullanıcılara yönelik ciddi bir tehdit oluşturmaktadır. Siber güvenlik uzmanları da bu tarz zararlı uygulamaları sürekli olarak analiz edip daha iyi bir tespit sistemi ortaya çıkarmaya çalışmaktadır. TRAPDROID ismini verdiğimiz çalışma, zararlı yazılımları dinamik olarak davranışsal analizini gerçek cihazlar üzerinde gerçekleştirebilmektedir. Bu platform, sistem çağrıları ile birlikte uygulamaların süreçler arası iletişimini ve donanımsal performans metrikleri harici herhangi bir bağımlılığı olmadan toplayabilmektedir. Tüm bu toplanan veriler ve metrik değerler, özel olarak yazılmış betikler (UPL - UBF Processing Language) kullanılarak davranışsal bilgiler içeren özel bir formata (UPF - Unified Behavior Format) dönüştürülmektedir. Geliştirdiğimiz zararlı yazılım tespit sisteminin başarısını ölçebilmek için kullanılan tanınmış veri kümeleri, özel olarak geliştirilen zararlı yazılımlar ve henüz daha sınıflandırılması yapılmamış uygulamalar ile zenginleştirilmiştir. Projemiz geliştirilmeye açık olmasının yanı sıra, hızlı ve yüksek bir başarı oranı ile mobil cihazlardaki zararlı yazılımları gerçek zamanlı olarak tespit edebilmektedir.","In the realm of mobile devices, malicious applications pose considerable threats to individuals, companies, and governments. Cyber security researchers are in a constant race against malware developers and analyze their new methods to exploit them for better detection. In this thesis, we present TRAPDROID, a dynamic malware analysis framework mostly focused on capturing unified behavior profiles of applications by analyzing them on physical devices in real-time. Our framework processes events which are collected from system calls, binder communications, process stats, and hardware performance counters. Afterwards, it combines them into a simple, yet meaningful behavior format named UBF (Unified Behavior Format) using UPL (UBF Processing Language) scripts. We evaluated our framework's accuracy and performance on the up-to-date malware dataset, which contains widely-known variants, custom crafted malicious applications, 0-day, and 1-day samples. The framework is easy to use, extensible, fast, and providing high accuracy in malware detection with relatively low overhead."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ATM nakit tahmini, banka sistemlerindeki en yaygın problemlerden biridir. ATM'de yeterli nakit bulunmaması, müsteri memnuniyetini azaltırken, gereginden fazla para olması ise bankanın kar payını negatif etkiler. Bu çalısmada ATM'lerden çekilen para miktarını tahmin eden bir sistem gelistirilmistir. Tahmin asamasında dogrusal regresyon, destek vektör makinesi, yapay sinir agları, derin ögrenme tekniklerinden olan Uzun Kısa Vadeli Hafıza Agları ve istatiksel analiz (ARIMA) methodları kullanılarak modeller olusturulmus ve aynı ATM verisi üzerinde deneyler yapılmıstır. Bu deneyler sonucunda makine ögrenmesi metotlarının, kullanılan istatiksel methoda göre çok daha iyi performans sergiledigi gösterilmistir. Ayrıca, makine ögrenmesi metotları içerisinde de LSTM modelinin çok daha az öznitelik kullanarak daha basarılı tahminler yaptıgı belirlenmistir.","One of the most common problems related to banking systems is the Automated Teller Machine (ATM) cash demand forecasting. Cash shortage adversely affects customer satisfaction, while too much cash reduces bank's profitability. We have developed an ATM cash prediction system using different traditional statistical and machine learning approaches, including linear regression, support vector machines, artificial neural networks, LSTMs and traditional statistical analysis (ARIMA) on the same ATM data. We compared the results of these methods and showed that machine learning methods in comparison with ARIMA have higher accuracy. Also it was shown that among the machine learning models, LSTM gives the most accurate predictions and use less features compared to other models."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin sinir ağları, görüntü anlama da dahil olmak üzere birçok uygulamada karar verme sistemlerinin performansını artırdı. Çeşitli sınıflandırma ve regresyon görevleri için güçlü araçlar olduğu gösterilen topluluk yöntemleri kullanılarak daha fazla performans kazanımı elde edilebilir. Bu tez iki bölümden oluşmaktadır. Birinci bölüm, yüz öznitelikleri sınıflandırma problemini incelemeye ayrılmıştır. CelebA ve LFWA veri kümelerinde en gelişmiş sonuçları elde ederek bu sorun için birkaç yeni yaklaşım sunuyoruz: i) temel öğrenicilerin konuma göre gruplandırıldığı, ölçeklenebilirlik için çoklu öznitelik sınıflandırması için çok görevli öğrenme (MTL) çerçevesini kullanıyoruz yüzdeki özniteliğin ve ağırlıkların paylaşılması. Bir özniteliğin konumu hakkında ön bilgi olarak bilgi verilmesi, öğrenme sürecini hızlandırdığı ve doğruluğun artmasına neden olduğu gösterilmiştir. ii) derin öğrenme modelinin kendisinde (ağ içi topluluk) yeni bir topluluk öğrenme tekniği tanıtıyoruz ve neredeyse aynı anda tek bir modelin karmaşıklığıyla artan performans gösteriyoruz. iii) göreli öznitelik sınıflandırması için (iki fotoğraftaki öznitelik ifadesini karşılaştırarak) DVM formülasyonunu derin sıralı öğrenmeye uyarlayan Deep-RankSVM adlı yeni bir çerçeve öneriyoruz. İkinci bölüm, derin ağ toplulukları oluşturmak için farklı son teknoloji tasarım stratejilerinin uygunluğunu analiz etmeye ayrılmıştır. Hata Düzeltme Çıktı Kodları (ECOC) çerçevesini yeni bir derin öğrenme topluluğu yöntemi olarak öneriyoruz ve keyfi doğruluk-karmaşıklık değiş tokuşu için MTL çerçevesiyle kullanılabileceğini gösteriyoruz. Çeşitli veri setlerinde tanıtılan ECOC tasarımları ile topluluk ortalaması ve gradyan artırma karar ağaçları gibi son teknoloji topluluk teknikleri arasında kapsamlı bir karşılaştırmalı çalışma yürütüyoruz. Tezin geri kalanında, cilt lezyonu sınıflandırmasını ve bitki tanımlamasını içeren önerilen topluluk tekniklerinin genel uygulamalarını tartışıyoruz.","Deep neural networks have enhanced the performance of decision making systems in many applications, including image understanding. Further performance gains canbe achieved by using ensemble methods, which are shown to be powerful tools for various classification and regression tasks. This dissertation consists of two parts.The first part is devoted to studying the face attributes classification problem. We introduce several novel approaches for this problem, achieving state-of-art resultson CelebA and LFWA datasets: i) we use the multi-task learning (MTL) framework for multiple attributes classification for scalability, where base learners are grouped according to the location of the attribute on the face and share weights. Giving information about the location of an attribute as prior information is shown to speed up the learning process and lead to increased accuracy. ii) we introduce a novel ensemble learning technique within the deep learning model itself (within-network ensemble), showing increased performance at almost the same time complexity of a single model. iii) we propose a new framework called Deep-RankSVM for relative attribute classification (comparing the attribution expression on two photographs) adapting the SVM formulation to deep rank learning. The second part is devoted to analyzing the suitability of different state-of-art design strategies for constructing ensembles of deep networks. We propose the Error Cor-recting Output Codes (ECOC) framework as a novel deep learning ensemble method, and show that it can be used with the MTL framework for arbitrary accuracy-complexity trade-off. We carry out an extensive comparative study between the introduced ECOC designs and the state-of-the-art ensemble techniques such as ensemble averaging and gradient boosting decision trees, on several datasets. In the rest of the dissertation, we discuss general applications of the proposed ensemble techniques that include skin lesion classification and plant identification."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ev otomasyon sistemleri (HAS), bir evde bulunan ve İnternet üzerinden erişilebilen birbirine bağlı bir dizi cihazdan oluşan sistemlerdir. Ev sahipleri, akıllı ev aletlerini HMS'i kullanarak izleyebilir ve kontrol edebilir, ancak sistem düzgün yapılandırılmamışsa, izinsiz giriş yapanlar sistemdeki bir veya daha fazla cihaza erişim sağlayabilir. Bu tezde, HMS için gizliliği koruyan bir tanımlama modeli önermekteyiz. Bu modelde öncelikle güvenli bir anahtar paylaşımı ve kimlik bilgisi verme protokolü sunulmaktadır. Bu protokolde Idemix'in Doğrulanabilir Şifreleme şeması uygulanmaktadır. Doğrulanabilir şifreleme şemaları, iletişimi tamamen güvenli tutarken, kimlik atama otoritesinin ve kullanıcının kimliğinin doğrulanmasını sağlar. Bu protokol sırasında, karşılıklı kimlik doğrulama protokolünün ana anahtarı paylaşılır ve kullanıcı için kimlik bilgileri verilir. Ardından, Sağlayıcı Firmalar ve Yenilikçi Ev Ağ Geçidi (IHG)'ler arasındaki iletişimi gizlemek için güvenilir bir taraf olarak HAS Yönetim Sistemini(HMS)'i kullanan karşılıklı kimlik doğrulama protokolünü açıklıyoruz. Ev içindeki aletlerin marka, tip ve kimliklerini maskeleyerek ev sahiplerinin mahremiyeti korunur. HMS, konulardaki UUID'lerin değiştirerek biri Sağlayıcı Firma ve diğeri IHG ile olmak üzere iki farklı görüşme gerçekleştirir. Bunlarda yayınlanan konular ve mesajlar birbiri ile bağlantılı değildir, bu şekilde IHG'ye bağlı IoT cihazlarının kimlikleri gizlenir. Tezde ayrıca 4 farklı senaryo için yapılan testlerin performans sonuçları sunulmuştur. Tezin sonunda hem anahtar paylaşımı hem de kimlik bilgisi düzenleme protokolü ile karşılıklı kimlik doğrulama protokolü için güvenlik analizleri verilmiş ve her ikisinin de OFMC ve ATSE şartnamelerine göre güvenli olduğu kanıtlanmıştır. Sonuç olarak, sistem gerçek uygulama için ölçeklenebilirdir ve önerildiği gibi güvenlik ve gizlilik sağlar.","Home Automation System (HAS) is a set of interconnected devices in a household that are accessible via the Internet. Homeowners can monitor and control the smart home appliances using HAS, but if the system is not structured properly, intruders can gain access to one or more of the devices in the system. In this thesis, we propose a privacy preserving identification model for HAS. In this model, first, a secure key sharing and credential issuance protocol is presented. In this protocol Idemix's Verifiable Encryption scheme is implemented. Verifiable encryption schemes ensure the authenticity of the Issuer and the User, while keeping the communication fully secure. During this protocol, the master key for the mutual verification and authentication protocol is shared and the credentials for the User are issued. Then, we explain the mutual verification and authentication protocol, which also employs the HAS Management System (HMS) as a trusted party to obfuscate the communication between the Vendors and Innovative Home Gateway (IHG)'s. We preserve the privacy of the homeowners by masking the brands, types and id's of the appliances inside the household. HMS carries on two different conversations, one with Vendor and the other with IHG, replacing the UUID's in the topics. The topics and messages published on these are unlinkable, thus masking the identity of the IoT devices connected to the IHG. The performance tests are performed using 4 different scenarios. Moreover, security analysis for both key sharing and credential issuance protocol and for the mutual verification and authentication protocol are given, and they are both proven to be secure according to OFMC and ATSE specifications. In conclusion, the system is scalable for actual implementation, and provides security and privacy as proposed."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım olay kaydı raporları, kullanıcıların bir yazılım ürününü kullanırken karşılaştıkları sorunları anlattıkları belgelerdir. Bu raporları doğrulama ve atama sürecine ise yazılım olay kaydı triyajı denir. Uygulamada, kayıtların triyajı, uzmanlar veya yazılım geliştiriciler tarafından manuel olarak gerçekleştirilir. Büyük ölçekli endüstriyel bağlamlarda yüzlerce yazılım ürünü mevcuttur ve bu ürünleri kullanırken yaşanan sorunlarla ilgili her gün yüzlerce olay kaydı açılmaktadır. Bu raporların triyajı büyük miktarda insan eforu gerektirmektedir ve kayıtların zamanında çözülememesi müşteri memnuniyetsizliğine neden olmaktadır. Bu tezde, veri madenciliği teknikleri kullanarak süreci otomatikleştirdik ve sistemi devreye alarak edindiğimiz tecrübeleri paylaştık. Otomasyonun pratik etkilerini gözlemlemek ve aktarmakla kalmadık, aynı zamanda kullanıcılarla vaka çalışmaları yürüttük. Ayrıca, yapılan tahminler için teknik olmayan, kullanıcılar tarafından kolaylıkla anlaşılabilecek açıklamaların otomatik olarak nasıl oluşturulacağına ve tahminlerin doğruluğundaki bozulmaların çevrimiçi bir şekilde nasıl tespit edileceğine dair yöntemler geliştirerek değerlendirdik. Sistem performansını iyileştirmek için hatalı atanan olay kayıtlarını inceledik. İlgili kayıtlara çoğunlukla ekran görüntüleri de eklendiğini ve sorunla ilgili kısa veya yetersiz açıklamalar girildiğini tespit ettik. Bu gözlemlere dayanarak, otomasyonun performansının artırılması amacıyla, açıklamalarda eksik bilgi olduğunu otomatik olarak nasıl tespit edebileceğimize ve ekli ekran görüntülerini de ek bir bilgi kaynağı olarak nasıl kullanabileceğimize yönelik çalışmalar yürüttük.","Software issue reports are the documents describing the problems users face when using a software product and software issue triage is the process of validating and assigning these issue reports. In practice, issue triage is carried out manually by experts or developers. In large scale industrial contexts, hundreds of software products exist and hundreds of issue reports are filed every day. It takes a great amount of human effort to triage these reports and failure to solve them on time results in customer dissatisfaction. In this thesis, we automate the issue triage process by using data mining approaches and share our experience gained by deploying the resulting system in a large scale industrial setting. Deployment of such a system presented us not only with an opportunity to observe the practical effects of automation, but also to carry out user studies, both of which have not been done before in this context. Furthermore, we developed and empirically evaluated methods on how to create human-readable, non-technical explanations for the predictions made, and on how to monitor and detect deteriorations in accuracies in an online manner. In our efforts to improve the performance, we analyzed the incorrectly assigned issue reports. We realized that many of them have attachments with them, which are mostly screenshots, and such reports generally have short or insufficient descriptions for the problem. Based on these observations, we further carried out studies on how to ensure that we detect the missing information in the descriptions of issue reports automatically and how we can use the attached screenshots as an additional source of information, in order to improve the performance of the automation."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Permanent aynı determinant gibi matrislerin karakterlerini anlamaya yarayan önemli bir sayısal değerdir ve bir çok pratik uygulaması mevcuttur. Örneğin, çizgeler ve seyrek matrisler yapısal olarak birbirine benzediğinden aynı veriyi göstermek üzere kullanılabilirler ve 1 ve 0'lardan oluşan bir simetrik matrisin permanent değeri, o matrise karşılık gelen iki parçalı çizgenin mükemmel eşleme sayısına eşittir. İki parçalı çizgenin mükemmel eşleme sayısı, o çizgenin noktaları arasındaki ilişkisi adına önemli bir bilgidir. Permanent değerini hesaplama #P-tam bir problemdir. Bu yüzden polinom zamanda çalışan bir algoritma bulunmamaktadır. Literatürdeki en hızlı algoritmanın karmaşıklığı O(2^(n-1) * n)'dır. Problem bu yapısı gereği n>40 gibi küçük denilebilecek matrislerin için bile permanentin hesaplanması oldukça yavaştır. Literatürde permanent değerini bilgisayar veya süper bilgisayar ile paralel olarak hesaplamak adına çalışmalar mevcuttur. Bu tezde hem dolu hem seyrek matrisler için birden çok çekirdeki CPU'lar ve birden çok GPU'da çalışan paralel algoritmalar tasarlanıp geliştirilmiştir. Ayrıca dolu ve seyrek matrisler için permanent değerini yakınsayan paralel algoritmalar geliştirilmiştir.","Permanent -just like determinant-, is an important numeric value in order to understand matrix characteristics and multiple applications of permanent exist. For example, because graphs and sparse matrices are structurally similar to each other, they can be used to show the representation of the same data. The Permanent value of a symmetric matrix that is consisted of 1s and 0, is equal to the perfect matching number of the corresponding bipartite graph which is an important information of relationship among bipartite graph's vertices. Calculating exact value of matrix permanent is a #P-complete problem. For that reason, there is not an algorithm that works in polynomial time. The fastest algorithm that calculates an n times n matrix's permanent value has a time complexity of O(2^(n-1) * n). This nature of the problem makes the calculation of even considerable smaller matrices like n>40 very slow. In literature, there exist studies that focuses on computing the exact permanent value in parallel with a computer or a supercomputer. In this thesis, parallel algorithms are designed and implemented that can calculate the exact permanent value of dense and sparse matrices efficiently on multicore CPUs and multiple GPUs. Furthermore, algorithms are developed to approximate the permanent value of a given dense or sparse matrix in parallel."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otonom araçlar, yapay zeka ve robotik alanlarındaki son gelişmelerle günlük hayatımıza giderek daha fazla dahil olmakta. Otonom araçlar tipik olarak simülasyonda ve gerçek hayatta farklı senaryolarda çeşitli testlerle test edilir. Otonom araçların güvenliğini sağlamak için simülasyonda ve gerçek hayatta gerçekçi test senaryoları yürütebilmeliyiz. Bu kapsamda en gerçekçi ve ikna edici testler, gerçek hayattaki kazalardan test senaryolarını içerir. Ancak şu anda bu testler, halen insanlar yardımı ile oluşturuluyor. Bu çalışmada mevcut herhangi bir araba kazası videosundan gerçekçi bir şekilde otomatik test senaryoları oluşturabilen genel ve ölçeklenebilir bir yöntem sunuyoruz. Çalışmamızın esnekliğini göstermek için, değerlendirme aşamasında hakkında önceden bilgi sahibi olmadığımız çeşitli YouTube videolarını kullanıyoruz. Önerilen yöntem, analiz, yeniden sahneyi canlandırma ve test senaryosu oluşturma olmak üzere üç adımdan oluşmaktadır. Geliştirilen yöntem tamamen otomatizedir ve test senaryoları oluşturmak için uçtan uca bir çözüm sunar. Analiz adımında, giriş videolarını altı farklı adımdan oluşan bir görüntü işleme yapısı üzerinden çalıştırıyoruz. Sonrasında kazayı üç boyutlu bir fizik simülasyonunda yeniden oluşturuyoruz. Son olarak, bir dizi otomatik olarak önceden tanımlanmış veya kullanıcı tanımlı parametrelerden çeşitli test senaryoları oluşturuyoruz. Oluışturulan test senaryoları, bir simülasyon köprüsü aracılığıyla iletişim gereksinimlerini karşılayan herhangi bir otonom sürüş sistemi ile kullanılabilir. Sonuçlarımızı bir kullanıcı çalışması ve popüler açık kaynaklı otonom sürüş sistemi olan Apollo üzerinde yürütülen bir dizi test ile değerlendiriyoruz.","Self-driving cars are more and more included in our daily lives with recent advancements in the fields of artificial intelligence and robotics. Self-driving cars are typically tested in simulation and real-life with various types of tests in different scenarios. To ensure the safety of self-driving cars we must be able to conduct realistic test cases in simulation and real life. The most realistic and highly convincing tests include test cases from real-life accidents. However, currently, these tests are generated manually with humans still in the loop. We introduce a generic and scalable way to realistically generate automated test cases from any car accident video that is available. To show the flexibility of our study we use various YouTube videos that we have no prior information about for evaluation. The proposed method consists of three steps, namely analysis, scene reconstruction, and test case generation. Our method is fully automated and an end-to-end solution to generate test cases. In the analysis step, we run the input videos through an image processing pipeline that consists of six internal steps. Then we reconstruct the crash in a 3D physics engine. Finally, we generate various test cases from a set of automatically pre-defined or user-defined parameters. The test cases can be used with any autonomous driving stack that satisfies the communication requirements through a simulation bridge. We evaluate our results with a user study and a set of case study experiments that are conducted on the popular open-source autonomous driving stack, Apollo."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çamaşır makinelerinde denge sorunları titreşim şeklinde kendini gösterir. Yüksek dönüş hızlarında daha belirgin hale gelen bu titreşimler, kalıcı fiziksel hasara neden olarak makinenin performansına ve ömrünü olumsuz şekilde etkileyebilir. Bu titreşimleri yıkama döngüsünün başlarında ve makinenin rezonans frekansının altında tespit edilmesi, uygun önlemlerin belirlenmesi için kritik öneme sahiptir. Bu tezde, çamaşır makinelerinde görülen iki genel denge sorununa odaklanıyoruz. İlki, makinenin dengesizliği,tesviye ayaklarının yanlış ayarlanmasınan kaynaklanan makine dengesizliği; ikincisi ise tambur içindeki yükün eşit olmayan dağılımından kaynaklanan yük dengesizliği. Tamburdan toplanan sensör verileri ile eğitilmiş yapay öğrenme modelleri kullanarak özellikle bu dengesizliklerin olabildiğince erken tespit edilme imkanını araştırmaktayız. Bu amaçla, iki tür dengesizlik senaryosuna ilişkin veri toplamaktayız. Bu ardışık verilerden, farklı özellik çıkarma teknikleri ve farklı makine öğrenimi modelleri kullanarak denetimli ardışık veri sınıflandırma modelleri oluşturmaktayız. Yıkama döngüsünün farklı zamanlarından toplanan kısmı sensor verisi ile kurulan modelleri karşılaştırmaktayız. Sonuçlarımız, yıkama döngüsünün 500 ms'sinden toplanan veri ile %95 F1 skoruna ulaşabildiğini göstermektedir, bu da yıkama döngüsü sırasında bu iki dengesizliğin erken tespitinin mümkün olduğunu işaret eder. Toplanan veriler, araştırmacıların erişimine sunulmuştur.","Balance issues in washing machines manifest themselves in the form of vibrations. These unwanted vibrations become more prominent at high spin speeds. They can be detrimental to the machine's performance and shorten lifespan by causing permanent physical damage. Detecting these vibrations early in the wash cycle and at spin speeds below the machine's resonant frequency is critical in devising proper measures to alleviate their effects. In this thesis, we focus on the two common balance issues observed in washing machines. The first one is machine imbalance, which stems from the improper adjustment of leveling legs. The second balance problem is the load imbalance, which is the result of an uneven distribution of the load inside the drum. We specifically investigate the possibility of detecting these imbalances as early as possible using models trained on sensory data collected from the drum. For this aim, we collect vibration data on the two types of imbalance scenarios throughout the wash cycle. Using these data, we build supervised classification models using different feature extraction techniques on the multivariate times series data and different machine learning models. We compare models that are trained with different partial data collected at different time segments early in the wash cycle. Our results show that we can attain a 95% F1-score with input as short as 500 ms of the wash cycle, indicating that early prediction of these two imbalances during the wash cycle is possible. The collected data are shared for the research community."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, 5G/6G ağları ile etkinleştirilmiş dağıtık uç IoT (Nesnelerin İnterneti) ortamlarında yarı dürüst modele sahip güvenli ve mahremiyeti koruyucu, çok etiketli ve çok çıkışlı makine öğrenimi (ML – Machine Learning) algoritmaları için genel bir çerçeve önerilmiştir. Önerilen çerçeve, ikili, çok sınıflı ve çok etiketli ML algoritmalarının özel durumlarını içerir. Hem yatay hem de dikey olarak bölümlenmiş veri kümeleriyle çalışılmıştır. İlk olarak, (i) özniteliklerin dağıtık ortamlardaki bilgi kazanımlarını homomorfik olarak değerlendiren yeni güvenli öznitelik seçim protokolleri önerilmiştir, (ii) seçilen öznitelikler kümesi üzerinde yeni güvenli eğitim protokolleri ile ilerlenmiştir, daha sonra (iii) ML algoritmalarında yaygın olarak kullanılan yeni güvenli yapı taşları (örn. güvenli toplam, karşılaştırma, argmax, top-K, sıralama, permütasyon, vb.) ile lineer cebir işlemlerini (örn. güvenli iç çarpım, sıralı matris-vektör ve matris-matris çarpımları, matris transpozu, vb.) güvenli hale getirecek yöntemler önerilmiştir ve son olarak (iv) önerilen güvenli yapı taşlarının üzerine, Derin Sinir Ağları (DNN - Deep Neural Networks), Destek Vektör Makineleri (SVM - Support Vector Machines), Karar Ağaçları (DT - Decision Trees), Rastgele Ormanlar (RF - Random Forests), Naïve Bayes (NB)'in değişik varyasyonları, Lojistik Regresyon (LR) ve K En Yakın Komşular (KNN - K Nearest Neighbors) gibi çeşitli ML sınıflandırıcıları için yeni güvenli ML sınıflandırma protokolleri oluşturulmuştur. Ayrıca, önerilen güvenli sınıflandırma protokolleri, keyfi olarak protokolden sapan kötü niyetli kullanıcılarla da baş eder ve güvenli sınıflandırma kaynaklı doğruluk kaybı göstermezler. İşlemler sırasında protokol katılımcıları sıkı güvenlik, mahremiyet ve verimlilik gereksinimlerini karşılamak üzere birbirleriyle etkileşime girerler. Bu amaçla, kriptografik özet fonksiyonundan geçirilen içerikler ilgili katılımcıların özel anahtarıyla imzalanarak her mesajlaşmanın gizliliği, bütünlüğü ve özgünlüğü sağlanmış olur. Mesajlaşmalar arasındaki tutarlılığı, zaman damgaları ekleyerek ve bunları önceki mesajların içerik özetlerine bağlayarak sağlamaktayız. Bu, protokollerimizi blok zincir teknolojisine doğal bir şekilde uyumlu hale getirir. Ayrıca, önerilen kriptografik araçların kuantum bilgisayar saldırılarına karşı dirençli olduğu da kanıtlanmıştır, bu da protokollerimizi kuantum sonrası dünya için kullanışlı kılmaktadır. Teorik analizler ile siber güvenlik ve sağlıkla ilgili karşılaştırmalı veri kümeleri üzerinde kapsamlı deneysel değerlendirmeler yapılmıştır. Bu analiz ve değerlendirmeler, önerilen protokollerin, hesaplama ve iletişim maliyetleri açısından bilinen en iyi duruma göre birkaç kez ila büyüklük kertesine kadar değişen oranlarda avantaj sağladığını göstermiştir. Bu durum da önerilen protokolleri literatürdeki en verimliler arasına sokmaktadır. Ayrıca, önerilen protokoller güvenlik ve gizlilik özellikleri açısından da en iyiler arasındadır ve en son teknolojiye göre yüksek hata toleransı oranı ve veri seti sahiplerinin gizli anlaşma saldırılarına karşı yüksek direnç gösterirler.","We provide a general framework for secure and private multi-label multi-output machine learning (ML) algorithms for the semi-honest model in distributed edge IoT (Internet of Things) environments enabled by 5G/6G networks. The proposed framework includes the special cases of binary, multi-class and multi-label ML algorithms. We deal with both horizontally and vertically partitioned datasets. Initially, (i) we propose novel secure feature selection protocols by homomorphically evaluating features' information gains in distributed environments, we proceed with (ii) novel secure training protocols over the set of selected features, then (iii) we propose novel secure building blocks which are commonly used on ML algorithms (e.g. secure sum, comparison, argmax, top-K, sorting, permutation, etc.), as well as on secure linear algebra (e.g. secure inner product, cascading matrix-vector and matrix-matrix multiplications, matrix transpose, etc.), and finally (iv) on top of proposed secure building blocks we build our novel secure ML classification protocols for various ML classifiers such as Deep Neural Networks (DNN), Support Vector Machines (SVM), Decision Trees (DT) and Random Forests (RF), different flavors of Naïve Bayes (NB), Logistic Regression (LR) and K Nearest Neighbors (KNN). Moreover, our secure classification protocols also deal with malicious users that arbitrarily deviate from the protocol and they show no loss of accuracy due to secure classifications. In the process, our participants interact with each other in order to fulfill strict security. privacy and efficiency requirements. To these ends, we provide confidentiality, integrity and authenticity to each interaction by signing their hashed contents with the corresponding participants' private key. We assure the consistency among interactions by introducing timestamps and linking them with the hashed content(s) of the preceding interaction(s). This makes our protocols a natural fit for blockchain technology. Moreover, the proposed cryptographic tools are proven to be resistant to quantum computer attacks, making our protocols applicable to the post quantum world. We did our theoretical analysis and extensive experimental evaluations over benchmark datasets related to cyber-security and health. They show that our protocols have an advantage ranging from several times to orders of magnitudes with respect to the state-of-the-art in terms of computation and communication costs. This makes our protocols among the most efficient ones in literature. Also, they are among the best in terms of security and privacy properties and allow high rate of fault tolerance and collusion attacks of dataset owners with respect to the state-of-the-art."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"T-KES yaklaşımı, yazılımların test edilmesinde kullanılan kapsayan dizileri oluşturan kombinezon etkileşim sınama (KES) objelerini esnek şekilde tanımlamak ve hesaplamak için bir esnek ve sistematik yöntem sağladı. Bu yaklaşım sayesinde test altındaki yazılım sistemleri ve kapsama kriterleri bir kısıt çözme problemi olarak ifade edilip, hali hazırda kullanılan kısıt çözücüler kullanılarak KES objeleri hesaplanmaktadır. T-KES'in getirdiği bu esnek kapsama kriteri tanımlayabilme rahatlığı, herhangi bir yazılım sistemini test edebilmek için yeni KES objelerinin kolayca tanımlanabilmesine olanak sağlamıştır. Bu çalışmalarda her ne kadar kısıt çözücüler kullanılarak T-KES objeleri üretilse de, karmaşık sistem modellerinin ve kapsama kriterlerinin tanımlanması için daha yüksek seviyede modelleme soyutlaması yapılması gerekebilir. Bu çalışmada, T-KES objelerini bildirimli bir modelleme dili olan ASP kullarak üretmek için geliştirdiğimiz TKES-ASP yaklaşımını sunuyoruz. Ayrıca, bu çalışma kapsamında geliştirilen ASP modelleme kütüphanelerini kullanarak hem hali hazırda olan T-KES objelerini üretip hem de, özellikle çizge tabanlı sistemler için (mobil uygulamalar, multi-threaded sistemler, vs.) için TKES objeleri tanımlıyoruz. Literatürde tanımlanan KES objelerinin TKES-ASP kullanılarak yeniden üretilmesini konu alan vaka çalışmalarında, üretilen KES objelerinin hem akademik hem de endüstride sıkça kullanılan kapsayan dizi üretme yöntemlerinden daha fazla sürede bu dizileri hesaplaması karşılığında daha küçük boyutlu objeler ürettiği gözlemlenmiştir.","U-CIT approach has provided a flexible and systematic method to flexibly define and compute combination interaction testing (CIT) objects generating covering arrays used in software testing. By U-CIT, software systems under test and coverage criteria are expressed as a constraint solving problem, and CIT objects are computed by using appropriate constraint solvers. The convenience of defining flexibly coverage criteria brought by U-CIT has made it possible to easily define new CIT objects to test any software system. Although U-CIT objects are generated by solving constraints with constraint solvers in these studies, a higher level modeling abstraction may be required to define complex system models and coverage criteria. In this study, we present UCIT-ASP approach that we developed to generate U-CIT objects by using Answer Set Programming (ASP) which is a declarative modeling language. In addition, by using ASP modeling libraries that were developed within the scope of this study, we both generated U-CIT objects already defined in the literature (i.e. standard covering arrays, test case aware covering arrays, etc.) and defined new U-CIT objects, specifically for graph-based systems (for the testing of mobile applications, multi-threaded systems, etc.). In our case studies to experience with UCIT-ASP on the generation of well-known CIT objects, we have observed that our approach generated smaller CIT objects than specialized covering array generation methods in the literature at the cost of computation times."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kara-kutu sızma testlerinde yük, bir bilgisayar sistemine, sistemde varolan bir açıktan faydalanarak potansiyel bir yetkisiz erişim sağlayan kod parçasıdır. Yükleri, hedef aplikasyonda tetikledikleri davranışlara göre guruplamak yoğun iş gücü gerektiren bir süreçtir, çünkü her bir yükün ve bu yüklerin hedef aplikasyondaki ilgili davranışlarının bir insan tarafından analiz edilmesi ve anlamlandırılması gerekmektedir. Bu tezde, insan değerlendirmesine katkı sağlayabilmek için WinPen olarak isimlendirilen yeni bir algoritma sunulmaktadır. Mevzu bahis algoritma, yükleri, hedef sistemde neden oldukları davranışlara göre kümelendirmektedir. Bunu yapmak için, her bir yük, hedef sistemden gelen cevabın karakter dizisi uzunluğu olarak nitelendirilir. WinPen, veri kümesindeki her bir eleman için, ilgili elemanın önceki komşularını kıstas alarak, ortalama bazlı karşılaştırmalar yapar. Bu tezde, farklı veri kümeleri için WinPen'in ortalama doğruluk puanı %99.85 olarak hesaplanmıştır. WinPen O(n log n + n)) zaman kompleksliğinde çalışmakta, hatta sıralanmış girdiler için bu komplekslik O(n)'e düşmektedir. WinPen, programlama dillerinden ve kaynak-kodundan bağımsız olup, diğer kümeleme algoritmalarından 46 kata kadar daha hızlıdır. Üstelik zahmetli hiper-parametre ayarlama sürecine gerek yoktur. Bu özellikleri, WinPen'i Siber Güvenlik uygulamaları için ideal bir aday yapmaktadır.","In black-box penetration testing, a payload is a piece of code that potentially enables unauthorized access to a computer system through an exploit. Grouping payloads based on the behavior they trigger in the target application is a labor-intensive process, where each payload and the corresponding behavior of the application to that payload should be analyzed and interpreted by humans. To assist human evaluation, we propose a new algorithm WinPen, which classifies the payloads based on the behavior they are triggering in the system. Each payload is represented as the length of the response strings generated after a payload is submitted in the system. WinPen performs mean-based comparisons for each point in the dataset with respect to the point's previous neighbors. We show on several datasets that WinPen performs with an average 99.85% accuracy score across several datasets. WinPen runs in O(nlogn+n)) and the time complexity is reduced to O(n) for already sorted inputs. WinPen is programming-language and source-code independent, and can be utilized in Cyber Security applications, faster than the other clustering algorithms (e.g., up to 46× faster than kmeans1d), without the need for tedious hyper-parameter tuning procedures."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sonlu Durum Makinesi (FSM) bazlı test yöntemleri, Durum Saptama Dizileri adı verilen, kara-kutu olarak verilen bir makinedeki durumların tasarımdaki durumlarla örtüşüp örtüşmediğini saptamaya yarayan dizileri kullanır. Bilinen farklı durum saptama dizisi çeşitleri vardır. Bu durum saptama dizilerinden bazılarının her tasarım için var olacağı kesin değildir. Ancak, bir durum saptama dizisi çeşidinin - W–kümesi bazlı durum saptama dizileri - indirgenmiş, gerekirci, ve tam belirtimlenmiş tüm sonlu durum makineleri için her zaman bulunduğu bilinmektedir. W–kümesi bazlı durum saptama dizileri uzun süredir bilinmesine karşın, literatürdeki birçok güvenli tekrar başlatma özelliği olmayan makineler için geliştirilen yöntemler tarafından tercih edilmemektedir. Bunun sebebi, W–kümesi bazlı yöntemlerin ürettiği dizilerin uzunluğunun W–kümesindeki eleman sayısına göre üstel olarak artmasıdır. Bazı güncel çalışmalar, W–kümesi bazlı durum saptama dizilerinin uzunluklarının düşürülebileceğini önermektedirler. Aslında bu yöntemler, önayarlı deneylerden oluşan W–kümeleri yerine, uyarlanabilir deneylerden oluşan K–kümelerini de kullanabilmektedirler. K–kümeleri de W–kümeleri gibi her indirgenmiş, gerekirci ve tam belirtimli tüm sonlu durum makineleri için bulunmaktadırlar. Bundan da öte, bu yeni yöntemler W–kümesinin/K–kümesinin tüm elemanları kullanılmadan da bir durum saptama dizisi üretilebileceğini öne sürmektedirler. Bu yöntemlerde, sonlu durum makinesinin bir durumu için hangi W–kümesi/K–kümesi elemanlarının kul- lanılacağını saptamak adına, uyarlanabilir bir yapı olan K–ağaçları kullanılır. Fakat, literatürde bu yeni yöntemlerle alakalı bir deneyli çalışma henüz yapılmamıştır. Buna ek olarak, K–ağaçlarının nasıl üretileceği ile alakalı bir algoritma da verilmemiştir. Bu çalışmada, öncelikle daha iyi W–kümeleri (hem eleman sayısı hem de toplam uzunluk bakımından) oluşturulması için W–kümesi oluşturma algoritmaları sunulmaktadır. Bu W–kümesi algoritmaları literatürdeki diğer algoritmalarla deneysel olarak karşılaştırılmaktadır. Aynı zamanda bu çalışmada, K–kümesi ve K–ağacı üretimi için algoritmalar da önerilmektedir. Son olarak, durum saptama dizileri ile ilgili kapsamlı bir deneysel çalışma sunulmaktadır. Bu deneysel çalışmalar, W– kümesi bazlı durum saptama dizileri tarihsel olarak pratikte kullanışsız gözükse de, K–ağacı yardımıyla oluşturulduğunda, bu durum saptama dizilerinin çok kısa ve kullanışlı sonuçlar ürettiklerini göstermektedir. Ayrıca, K–ağacı üretilirken K–kümelerinin kullanılması da W–kümelerine göre bir avantaj sağlamaktadır.","Finite State Machine (FSM) based testing methods utilize State Identification Sequences which are used to identify the states of a black box implementation as corresponding to states of an FSM given as the specification. There are different types of state identification sequences. Some of these state identification sequences are not guaranteed to exist for all specifications. There is one particular type of state identification sequences, W-set based state identification sequences, which are known to exist for any minimal, deterministic, completely specified FSM. Although W-set based state identification sequences are known for a very long time, most of the works in FSM based testing literature do not prefer to use them when testing for an implementation without a reliable reset feature, since the length of W-set based state identifications sequences in this case are exponential in the cardinality of the W-sets. There are some recent works that suggest to reduce the length of the W-set based state identification sequences. In fact, instead of W-sets, which are sets of preset experiments, these new methods can make use of so called K-sets, which are set of adaptive experiments that again always exist. Furthermore, these new methods suggest to apply not all elements of W–sets/K-sets, but instead an adaptive structure, called a K-tree is used to orchestrate the application of the elements of the K-set. However, there are no extensive experimental studies for these new methods. In addition, no algorithms are given for the construction of K-trees. In this work, we first present some W-set construction algorithms to construct better W-sets, in terms of both the cardinality and the total length of the sequences. We compare our W-set algorithms experimentally to the algorithms that exist in the literature. We also present algorithms to constructs K-sets and K-trees. Finally, we present an extensive experimental study for state identification sequences. The results show that, although W-set based state identification sequences have been considered practically infeasible due to the exponentially long sequences, the usage of K-trees make state identification sequences very short and practically usable. Utilizing K–sets in the generation of K–trees also yields better results than utilizing W–sets."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde çizgeler birçok alanda karşımıza çıkmaktadır, ve çizgelerin boyutu her geçen gün büyümektedir. Çizge gömme, çizgeler üzerinde makine öğrenmesi işlemleri gerçekleştirmek için çizgeleri çok boyutlu bir vektör uzayında temsil etme işlemidir. Fakat bu işlem zaman ve bellek açısından pahalıdır. Birçok çalışma, dağıtılmış sistemler ve ekran kartı kullanarak, çizge gömme işlemini optimize etmek üzerine algoritmalar öne sürmüştür fakat son teknoloji ürünü algoritmalar ekran kartının belleği gömme maliyetini karşılayamadığı takdirde işlemi gerçekleştirememektedir. Bu çalışmada büyük ölçekli çizgeleri, ekran kartının belleği yeterli olmasa da, sadece bir ekran kartı ile işleyebilen bir hibrit CPU-GPU çizge gömme algoritması önermekteyiz. Bu algoritmada gömme matrisi GPU belleğine sığacak parçalara ayrılarak sıralı bir şekilde işlenmektedir. Sistem, global bir senkronizasyon gerekmeden, örnekleri CPU'da yaratarak, GPU'ya gerektikçe göndermektedir. Ek olarak sistem genelleştirilebilir yönlü ve döngüsüz bir çizge modeli kullanarak yan işlerin bir birine bağımlılığını en aza indirgemektedir. Önerilen algoritma 60 milyon nokta ve 1.8 milyar kenar bulunduran bir çizgeyi 17 dakikada işlerken literatürdeki en hızlı algoritmadan 67 kat hızlı olmakta, ve bağlantı tahmini problemi için %97.84 AUCROC skoru elde etmektedir.","Graphs have become ubiquitous in this day and age, and their sizes are only becoming larger and harder to deal with. Graph embedding is the process of transforming graphs into a d-dimensional vector space to carry out machine learning tasks on them. However, time- and memory-wise, it is a very expensive task. Many approaches have been proposed to optimize the process of graph embedding using distributed systems and GPUs, however, state-of-the-art GPU implementations fail to embed graphs unless the total memory of the available GPUs satisfies the cost of embedding. We propose a hybrid CPU-GPU graph embedding algorithm that enables arbitrarily large graphs to be embedded using a single GPU even when the GPU's memory capabilities fall short. The embedding is partitioned into smaller embeddings and the GPU carries out embedding updates on embedding portions that fit the GPU's memory. The system generates samples on the CPU and sends them to the GPU as they become needed without any global synchronization across the system. The system adopts a generalizable DAG execution model to minimize the dependencies between its sub-tasks. We embed a graph with 60 million vertices and 1.8 billion edges in 17 minutes and report a link prediction AUC ROC score of 97.84% making us 67x faster than the state-of-the-art GPU implementation."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nitel uzaysal akıl yürütme, sayısal verilerden ziyade doğal dilin bazı kısımlarını kullanarak yön, mesafe, büyüklük gibi uzaysal ilişkileri formel olarak biçimlendirmeyi ve bu bilgiler üzerinde otomatik akıl yürütmeyi inceleyen bir yapay zeka alanıdır. Nitel modeller, özellikle eksik bilgi veya belirsizlik nedeniyle sayısal verilerin mevcut olmadığı durumlarda faydalıdır. Bununla birlikte, insanların uzaysal ilişkileri nitel terimler aracılığıyla ifade etmeleri, bilginin tam olduğu ve sayısal verilerin mevcut olduğu durumlarda da nitel akıl yürütmenin gerekliliğini göstermektedir. Bu tez kapsamında, bir düzlemdeki uzaysal nesneler arasındaki ana yönler hakkında nitel akıl yürütme için, Ana Yönlerle Hesaplamaya (CDC) dayalı ve Çözüm Kümesi Programlama (ASP) kullanarak (NCDC-ASP olarak adlandırılan) yeni bir hesaplama yaklaşımı sunuyoruz ve bu yaklaşımı üç boyutlu uzayda nitel akıl yürütme yapabilecek şekilde (3D-NCDC-ASP) genişletiyoruz. Her iki yaklaşım, CDC'deki tüm tutarlılık kontrolü problemlerine çözümler sağlamaktadır; bu tutarlılık kontrolü problemlerinin çoğu NP zorlukta olduğu gibi mevcut sistemlerle de çözülememektedir. Dahası, her iki yaklaşım da, CDC'yi yeni kısıtlarla (yani, varsayılan CDC kısıtları ve çıkarım yapılan CDC kısıtları) ile genişleterek diğer akıl yürütme problemlerine de (örneğin sağduyuya dayalı akıl yürütme, varsayılan koşullarla monotonik olmayan akıl yürütme, tutarsızlıklar için açıklama oluşturma ve bilinmeyen ana yön ilişkilerinin çıkarımı) için çözümler sunmaktadır. Tez çalışması kapsamında, hem NCDC-ASP'nin hem de 3D-NCDC-ASP'nin doğruluğunu ispat edip, hesaplama verimliliğini kapsamlı bir şekilde deneylerle test ediyoruz. Ayrıca, bu yaklaşımların uygulanabilirliklerini ve faydalarını su altı robotlarıyla deniz florası araştırmasından adli bilişime kadar farklı alanlarda gerçekçi senaryolarla gösteriyoruz.","Qualitative spatial reasoning studies representation and reasoning with different aspects of space, such as direction, distance, size using parts of natural language rather than quantitative data. Qualitative models are useful in contexts where quantitative data is not available due to incomplete knowledge or uncertainty. Qualitative reasoning is also relevant for contexts with complete information and quantitative data because human agents tend to express spatial relation or configuration by means of qualitative terms for the sake of sociable and convenient communication. We introduce a novel formal framework (called NCDC-ASP) for qualitative reasoning about cardinal directions between spatial objects on a plane, based on Cardinal Directional Calculus (CDC) and using Answer Set Programming (ASP), and extend it further (called 3D-NCDC-ASP) to 3-dimensional space. Each framework provides solutions to all consistency checking problems in CDC (i.e., for a complete/incomplete set of basic/disjunctive CDC constraints over connected/disconnected spatial objects); many of these consistency checking problems are NP-complete and cannot be solved with the existing systems. Furthermore, each framework extends CDC with novel types of constraints (i.e., default CDC constraints and inferred CDC constraints) to offer other types of reasoning as well (i.e., commonsense reasoning, nonmonotonic reasoning with defaults, explanation generation for inconsistencies, and inference of missing cardinal directional relations). We prove the soundness and completeness of both NCDC-ASP and 3D-NCDC-ASP, comprehensively evaluate their computational efficiency, and illustrate their usefulness with applications in different domains ranging from underwater robotics to digital forensics."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günlük derleme süreci, geliştirilmekte olan bir yazılımın en son sürümünün kod havuzundan günlük olarak (genellikle çalışma saatleri dışında) alındığı, yapı- landırıldığı, derlendiği ve bir test paketine göre test edildiği bir süreçtir. Bu sürecin nihai amacı, sistemin en temel işlevlerindeki kusurları kod tabanına dahil edilir edilmez ortaya çıkarmaktır, böylece bunları düzeltmek için geri dönüş süresi mümkün olduğunca kısalır. Bu çalışmada, ilk olarak, günlük bazda sistem parame- treleri arasındaki etkileşimleri sistematik olarak test etmek için bir kombinatoryal nesnenin hesaplandığı kombinatoryal etkileşim testi tabanlı günlük derleme sürecini sunuyoruz. Ardından bir dizi farklı test stratejisi ortaya koyuyoruz ve deneysel olarak önerilen yaklaşımın standart günlük derleme süreçlerinin etkinliğini derinlemesine artırdığını gösteriyoruz.","A daily build process is a process where the latest version of a software under development is obtained from its code repository on a daily basis (typically during off-work hours), configured, built, and tested against a test suite. The ultimate goal of this process is to reveal defects in the most fundamental functionalities of the system as soon as they are introduced into the codebase, so that the turnaround time for fixing them is reduced as much as possible. In this work, we first introduce combinatorial interaction testing-based daily build process where a combinatorial object is computed to systematically test the interactions between system parameters on a daily basis. We then introduce a number of different testing strategies and empirically demonstrate that the proposed approach profoundly improves the effectiveness of the standard daily build processes."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geleneksel tıpta, bir kanser hastasının tedavi kararları tipik olarak hastanın kanser türüne dayanır. Çok sayıda kanser hastasından oluşan geniş bir kohort için moleküler profillerin mevcudiyeti, hastaları moleküler düzeyde karakterize etmek için olanaklar sağlar. Farklı kanser hastalarının benzerlikler taşıdığı vakalar önceki çalışmalarda bildirilmiştir. Bu gözlemlerden motive olarak, bu tezde, özellikle çapraz kanser hastalarını keşfetmek için bir yöntem geliştirmeye odaklanıyoruz. Çapraz kanser hastalarını, farklı bir kanser türü ile teşhis edilen diğer hasta(lar) ile yüksek düzeyde benzerlik taşıyan ve kendi kanser türünü temsil etmeyen moleküler profillere sahip hastalar olarak tanımlıyoruz. Çapraz kanser benzeri hastaları bulmak için, transkriptomik profillerine göre kümelendiğinde sık sık birlikte kümelenen hastaları belirlediğimiz bir çerçeve geliştiriyoruz. Bu kümeleme problemini çözmek için, kümeleme görevinin hastaların kanser türleri ve hayatta kalma süreleri tarafından yönlendirildiği yarı denetimli bir derin öğrenme kümeleme yöntemi öneriyoruz. Bu yöntem ile elde edilen derin temsil, DeepCrossCancer'ın kümeleme modülünde kullanılır. Bu yöntemi, hasta tümör gen ekspresyon verilerinin kullanıldığı Kanser Genom Atlas projesinden dokuz farklı kansere uygulayarak, başka bir kanser türünde bir hastaya veya birden fazla hastaya benzer yirmi hasta keşfediyoruz. Bu hastaları diğer genomik değişikliklerin ışığında analiz ediyoruz. Sonuçlarımız, çapraz kanser hastalarının hem mutasyon hem de kopya sayısı varyasyonlarında önemli benzerlikler bulmaktadır. Çapraz kanser hastalarının tespiti, klinik kararların bir hastadan diğerine aktarılması ve aralarında paylaşılan yeni kanser sürücülerinin araştırılmasını hızlandırmak için olanaklar sağlar.","In traditional medicine, the treatment decisions for a cancer patient are typically based on the patient's cancer type. The availability of molecular profiles for a large cohort of multiple cancer patients opens up possibilities to characterize patients at the molecular level. There have been reports of cases where patients with different cancers bear similarities. Motivated from these observations, in this thesis, we specifically focus on developing a method to discover cross-cancer patients. We define cross-cancer patients as those who have molecular profiles that bear a high level of similarity to other patient(s) diagnosed with a different cancer type and are not representative of their cancer type. To find cross-cancer similar patients, we develop a framework where we identify patients that co-cluster frequently when clustered based on their transcriptomic profiles. To solve the clustering problem, we propose a semi-supervised deep learning clustering in which the clustering task is guided by the cancer types of the patients and the survival times. The deep representation obtained in the network is used in the clustering module of DeepCrossCancer. Applying the method to nine different cancers from The Cancer Genome Atlas project using patient tumor gene expression data, we discover twenty patients similar to a patient or multiple patients in another cancer type. We analyze these patients in light of other genomic alterations. Our results find significant similarities both in mutation and copy number variations of the cross-cancer patients. The detection of cross-cancer patients opens up possibilities for transferring clinical decisions from one patient to another and expediting the investigation of novel cancer drivers shared among them."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İstemciler, hesaplama ihtiyaçları için mobil uygulamalara giderek daha fazla güveniyor. Google Android'in popülaritesi ve Android cihazlara olan ilginin artması ile Android uygulamaları değerli hale geldi ve milyonlarca mobil uygulama, karmaşık sistemlerde test süreçlerinin önemini ve talebini artırdı. Uygulamalar test edilmesi gereken iyi geliştirilmiş güçlü koşullara sahip olduğundan, testteki otomasyon önemli bir rol oynamıştır. Birçok araştırma türü, öncelikle farklı amaçlar için kullanılacak farklı model keşif stratejilerine odaklanmıştır (örneğin, test oluşturma, hata algılama). Ancak, mobil uygulamaların test edilmesinde veya farklı amaçlar için kullanılabilecek olan uygulama modeli sistematik örnekleme ile oluşturulmadı. Farklı kullanımlar için dinamik olarak bir uygulama modeli oluşturmak üzere sistematik örnekleme uygulayarak otomatik bir kara kutu modeli keşfi sağlayan bir araç sunuyoruz. Yaklaşım iki amaç içerir: (1) sistematik örnekleme sağlayarak bir uygulamanın modelini keşfetmek ve (2) keşfedilen modelin koruma koşullarını tahmin etmek. Deneylerimizin sonuçları, yaklaşımın mevcut yaklaşımlardan daha yüksek kod kapsamı ve koruma koşullarının doğruluğunu elde etme yeteneğini doğruladı.","Clients progressively depend on mobile applications for computational needs. With the popularity of Google Android and the rise of interest in Android devices, Android applications have been valuable and millions of mobile applications have increased the importance and demand of test processes in the complex systems. Since the applications had well-developed strong conditions that need to be tested, automation in the testing has played a significant role. Many types of researches have primarily focused on different model discovery strategies to be used for different purposes (e.g., test generation, bug detection). However, they were not used systematically for testing of mobile applications. We present a tool that provides an automated black-box model discovery by applying systematic sampling to build a model of an application dynamically for different uses. The approach includes two purposes: (1) discovering the model of an application by providing systematic sampling, and (2) predicting guard conditions of the discovered model. The results of our experiments have confirmed the ability of the approach to acquire higher code coverage and the accuracy of predicted guard conditions than existing approaches."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gelişimsel disleksi, özgül öğrenme güçlüğünün bir alt grubudur. Dislekside öğrenmeyi kolaylaştırıcı çeşitli yöntemler bulunmaktadır, nörogeribildirim ve çoklu duyulu öğrenme metodları bunlardan ikisidir. Bazı araştırmalarda gösterildiği üzere, nörogeribildirim disleksili çocukların heceleme, okuma ve yazma becerilerini iyileştirebilir, korku ve kaygılarını kontrol etmeyi öğretebilir. Çoklu duyulu öğrenme metodu, disleksili çocukların işitme, okuma, görme ve dokunma duyularını bir arada kullanarak onların öğrenmesine yardımcı olur. Nörogeribildirim, beyindeki sinaps bağlantılarını güçlendirirken, çoklu duyulu öğrenme beynin farklı bölgelerini öğrenme aşamalarında kullanmayı hedefler. Bu tezde, nörogeribildirim ve çoklu duyulu öğrenme deneyimlerinin disleksiye fayda sağlayıp sağlamadığı incelenmiştir. Bu tez kapsamında geliştirilen Auto Train Brain, disleksili çocukların bilişsel performanslarını artırmak için, nöro geribildirim ve çoklu duyu prensiplerine göre hazırlanmış bir cep telefonu uygulamasıdır. Auto Train Brain sisteminde, 14 kanallı EMOTIV EPOC+ EEG başlığından gelen sinyaller okunur, işlenir, görsel ve işitsel olarak disleksili çocuğa geribildirim olarak sunulur. Auto Train Brain, ortalama yaşları 8.56 olan 16 disleksili çocuğa 60 kez 30'ar dakika uygulanmıştır. 4 denek eş zamanlı olarak özel eğitim almıştır. Kontrol grubu, 8.59 yaş ortalamasına sahip 14 disleksili çocuktan oluşmaktadır. Bu çocuklar, Auto Train Brain ile eğitim almamış, sadece özel eğitime devam etmişlerdir. Disleksiyi teşhis etmekte kullanılan yeni bir test olan TILLS testi, deneylerin başında ve 6 ay sonra hem disleksili gruba hem de kontrol grubuna uygulanmıştır. Deney öncesi ve sonrası ölçülen TILLS testi sonuçlarını karşılaştırdığımızda, Auto Train Brain eğitiminin etkili sonuç ürettiği izlenmiştir. Auto Train Brain eğitimi, özel eğitime nazaran okuduğunu anlamayı daha çok artırmıştır. Bu tezin ana katkısı, nörogeribildirim ve çoklu duyulu öğrenmeyi aynı anda kullanan Auto Train Brain'in etkin bir çözüm olduğunu göstermiş olmasıdır.","Developmental dyslexia is a subtype of specific learning disabilities. There are several methods for improving learning abilities, including neurofeedback and multi-sensory learning methods. As past work has shown, applying neurofeedback can improve spelling, reading, writing skills, normalizing fear, and anxiety of children with dyslexia. Multi-sensory learning methods utilize hearing (audition), reading (vision), seeing (vision), and touching (tactile/ kinaesthetic) simultaneously and proven to be useful for children with dyslexia. Neurofeedback focuses on normalizing the synaptic connections in the cortex, while multi-sensory learning focuses on using different parts of the brain to help with the learning process. In this research, the effectiveness of neurofeedback along with multi-sensory learning (MSL) experiences in helping dyslexia was investigated. Auto Train Brain is a neurofeedback and multi-sensory learning based mobile phone software application to improve the cognitive functions of children with dyslexia. It reads electroencephalography (EEG) signals from 14 channels of EMOTIV EPOC+ and processes these signals to provide neurofeedback to a child to improve the brain signals with visual and auditory cues in real-time. The major contribution of this thesis is that it presents the first study that combines neurofeedback with multi-sensory learning principles. Moreover Auto Train Brain has a novel neurofeedback technique from 14- electrode channels. Auto Train Brain was applied to 16 subjects with dyslexia (mean age: 8.56) 60 times for 30 minutes. 4 of them also received special education. The control group consisted of 14 subjects with dyslexia (mean age: 8.59) who did not have remedial teaching with Auto Train Brain, but who did continue special education. The TILLS test, which is a new neuropsychological test to diagnose dyslexia, was applied to both the experimental and the control groups at the beginning of the experiment and after a 6-month duration from the first TILLS test. Comparison of the pre- and post- TILLS test results indicate that applying neurofeedback and multi-sensory learning method concurrently is feasible for improving reading abilities of people with dyslexia. Reading comprehension of the experimental group improved more than that of the control group statistically significantly."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çizgeler protein etkileşim ağlarından sosyal ağlara hemen her yerde bulunmaktadır. Fakat çizgelerin düzensiz veri yapısı, çizgelerin üzerinde bağlantı tahmini, düğüm sınıflama ve aykırılık belirleme gibi makine öğrenmesi görevleri çalıştırmak adına bir engel teşkil etmektedir. Çizge gömme, çizgeleri çok boyutlu bir uzayda tanımlayarak, çizgeler üzerinde makine öğrenmesi görevlerinin kolayca çalıştırılabilmesini sağlamaktadır. Literatürde bir dizi çalışma bu metodun faydalarını göstermiş olsa da, çizge gömme yoğun işlem teşkil eden bir metottur. Güncel gömme uygulamaları, ya büyük ölçekli çizgeleri işleyememekte ya da işlemek için pahalı bir donanım gerektirmektedir. Bu çalışmada orijinal, paralel ve çok katmanlı bir çizge indirgeme metodu ileri sürmekteyiz. Bu metot çizge gömmenin performansını hem zaman hem de doğruluk açısından geliştirmektedir. Bu çalışmada, bahsedilen metot, GOSH adlı büyük ölçekli çizgeleri tek bir ekran kartı ile işleyebilen bir çizge gömme uygulamasına entegre edilmiştir. Çizge indirgeme metodu entegre edildiğinde, GOSH ortalama olarak 14 kat daha hızlı çalışmakta ve orta büyüklükteki çizgelerin çoğunda daha başarılı AUCROC değerleri elde etmektedir. Veri setindeki, 66 milyon düğüm ve 1.8 milyar bağlantı bulunan en büyük çizgeyi, GOSH, %93.4 AUCROC elde ederken işlemi bir saatin altında tamamlamıştır. Bunlara ek olarak bu çalışmada, çizge indirgeme kalitesinin çizge gömme kalitesine etkisini incelemekteyiz. Deneylerimiz indirgeme sürecinin dengeli olması gerektiğini ve ileri sürülen indirgeme metodunun çizge gömme açısından üstün bir performans sergilediğini göstermektedir.","Graphs can be found anywhere from protein interaction networks to social networks. However, the irregular structure of graph data constitutes an obstacle for running machine learning tasks such as link prediction, node classification, and anomaly detection. Graph embedding is the process of representing graphs in a multi-dimensional space, which enables machine learning tasks to be run on graphs. Although, embedding is proven to be advantageous by a series of works, it is compute-intensive. Current embedding approaches either can not scale to large graphs or they require expensive hardware for such purposes. In this work we propose a novel, parallel multi-level coarsening method to boost the performance of graph embedding both in terms of speed, and accuracy. We integrate the proposed coarsening approach into a GPU-based graph embedding tool called GOSH, which is able to embed large-scale graphs with a single GPU at a fraction of the time compared to the state-of-the-art. When coarsening is introduced, the run-time of GOSH improves by 14 times while scoring greater AUCROC for the majority of medium-scale graphs. For the largest graph in our data-set with 66 million vertices, and 1.8 billion edges, embedding takes under an hour, and 93.4% AUCROC is achieved. Moreover, we investigate the relationship between quality of the coarsening on the quality of the embeddings. Our preliminary experiments show that the coarsening decisions must be balanced and the proposed coarsening strategy novel performs well for graph embedding."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Perceptronun icadından bu yana Yapay Sinir Ağları (NN) birçok araştırmacının ilgisini çekmektedir. Teknolojik gelişmeler özellikle son on yılda ilgiyi (dolayısıyla ilerlemeyi) daha da hızlandırmış olan yüksek hesaplama gücünün ve muazzam miktarda verinin önünü açtı. Bugün itibariyle NN'ler, farklı makine öğrenmesi uygulamasının ana motoru olarak merkezi bir rol oynamaktadır. Makine öğrenmesiyle bilgiye dayalı karar vermek değil, aynı zamanda daha önce hiç görülmemiş, yeni bir şey ""yaratmak"" da çok çekici bir araştırma alanıdır. Üretken (Generative) modeller, bu hedefe hitap edebilecek ve sonunda ""hesaplamalı yaratıcılığa"" yol açabilecek en umut verici modeller arasındadır. Son zamanlarda Varyasyonel Otomatik Kodlayıcılar (VAE) ve Generative Adversarial Networks (GAN), yüksek performanslarıyla ilgi çekmektedirler. Bununla birlikte, VAE'lerin geleneksel biçimleri, çıktıların kalitesi açısından sorunlar yaşarken, GAN'lar üretilen çıktıların çeşitliliğini sınırlayan bir sorun, yani mod çöküşü sorunu, açısından sıkıntılar yaşamaktadır. Her iki algoritmanın bu zayıf yönlerini ortadan kaldırmayı hedefleyen bir bakış açısı, bu algoritmaların güçlü yönlerini alırken zayıflıklarından kaçınacak hibrit modeller geliştirmektir. Bu araştırmada, yeni bir üretken model öneriyoruz. Önerilen model, dört adet çekişmeli (adversarial) ağdan oluşmaktadır. Çekişmeli ağlardan ikisi geleneksel GANs'a çok benzerken, diğer ikisi temelinde Wasserstein ölçütünün hesaplanmasının yer aldığı WGAN'dir. Bu dört adet çekişmeli ağın bir araya getirilme şekli, önerilen modele iki tane de örtük otomatik kodlayıcıyı dâhil ederek mod çöküşü sorununu da en aza indirecek şekilde döngüsel bir çerçeve sağlamaktadır. Önerilen modelin performansı MNIST verileri kullanılarak çeşitli yönlerden değerlendirilmiştir. Analiz, önerilen modelin iyi kalitede çıktı ürettiğini ve bu arada mod çöküşü sorununu ortadan kaldırdığını göstermektedir.","Since the day that the Simple Perceptron was invented, Artificial Neural Networks (ANNs) attracted many researchers. Technological improvements in computers and the internet paved the way for unseen computational power and an immense amount of data that boosted the interest (therefore the advance), particularly in the last decade. As of today, NNs seem to take a vital role in all different types of machine learning research and the main engine of many applications. Not only learning from the data with machines in order to make informed decisions but also ""creating"" something new, unseen, novel with machines is also a very appealing area of research. The generative models are among the most promising models that can address this goal and eventually lead to ""computational creativity"". Recently the Variational Autoencoders (VAE) and the Generative Adversarial Networks (GAN) have shown tremendous success in terms of their generative performance. However, the conventional forms of VAEs had problems in terms of the quality of the outputs and GANs suffered hard from a problem that limited the diversity of the generated outputs, i.e., the mode collapse problem. One line of research that targets to eliminate these weaknesses of both algorithms is developing hybrid models which capture the strengths of these algorithms but avoiding their weaknesses. In this research, we propose a novel generative model. The proposed model is composed of four adversarial networks. Two of the adversarial networks are very similar to conventional GANs and the remaining two are basically WGAN that is based on the Wasserstein loss function. The way that these adversarial networks are put together also incorporates two implicit autoencoders to the proposed model and provides a cyclic framework that addresses the mode collapse problem. The performance of the proposed model is evaluated in various aspects by using the MNIST data. The analysis suggests that the proposed model generates good quality output meanwhile avoids the mode collapse problem."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Siber saldırganların yer aldığı yeraltı ekonomisinde siber suç servisleri yaygınlaşmıştır. Bu yeni ekonomik sistemde saldırganların yeni kurbanlar elde etmesinin yanı sıra hali hazırda erişim elde ettikleri kurban sistemler üzerinde erişimlerini korumaları da saldırganlar için son derece önem arz eden bir duruma gelmiştir. Geçmiş dönemde zararlı yazılımların saldırının ilk anında güvenlik ürünleri tarafından tespit edilemez olmaları önemliyken, artık sistemi ele geçirdikten sonra da bu tespit edilemezliklerini korumaları gerekmektedir. Sayıları gitgide artan ve elle (İng. manual) incelenmeleri bir hayli vakit alan bu zararlı yazılımları incelemek için analistler genellikle dinamik analiz platformlarını kullanmaktadırlar. Ancak bu platformlar, saldırganlar tarafından sürekli yenilenen/güncellenen/iyileştirilen atlatma yöntemleri nedeniyle yetersiz kalmaktadırlar. Zararlı yazılımlar, bu platformlar içerisinde analiz edildiklerini tespit edebilmekte ve gerçek amaçlarını gizlemek üzere davranışlarını değiştirebilmektedirler. Bu nedenle dinamik analiz platformları zararlı yazılımları başarı ile sınıflandırabilseler dahi zararlı yazılımın gerçek davranışını gözlemleyemedikleri vakalar oluşmaktadır. Platformların bu yetersizlikleri nedeniyle analistler gün sonunda yine elle analize mecbur kalmaktadırlar. Bu çalışmada sunduğumuz ISKRA isimli hipervizör tabanlı dinamik analiz platformu, fiziksel bilgisayar üzerinde zararlı yazılımlar tarafından tespit edilmeden sistem çağrılarının toplanmasına ve zararlı yazılımların analiz edilmesine imkân sağlamaktadır. Kolay kurulabilir ve değiştirilebilir olan bu platform fiziksel ve sanal sistemlerde çalışabilmesinin yanı sıra hali hazırda çalışan bir sistemi analiz ortamına dönüştürebilmektedir. Böylelikle çalışan bir sistem üzerinde canlı olay müdahalesi yapılmasına imkân sağlamaktadır. Dolayısıyla olay müdahale ekipleri vaka yaşanan sistemi analiz ortamına dönüştürüp zararlı yazılım tarafından tespit edilmeden delil toplama, inceleme ve tedavi yapabilmektedirler. Çalışmamız kapsamında öne sürdüğümüz platformu geliştirdik ve makina öğrenmesi ile yeni zararlı yazılım saldırılarını tespit etmek üzere deneyler gerçekleştirdik. Gerçekleştirdiğimiz deneyler platformumuzun düşük sistem yükü ve yüksek doğruluk oranıyla diğer dinamik analiz platformlarının tespit edemediği güncel zararlı yazılım saldırılarını tespit edebildiğini göstermiştir.","With the proliferation of ''cyber-crime as a service'' economy, besides gaining new victims, providing permanence on them has been one of the key points of profit for attackers. Thus, hiding malicious presence while operating is now more important for malware than being fully undetectable when it is first distributed. Due to the increasing number of malware attacks and prohibitively long hours required for manual inspection, analysts often use dynamic analysis platforms to investigate malware samples. However, these platforms have been repeatedly shown to fail to combat evasion methods that are constantly updated by attackers. Even if malware is correctly classified by the existing dynamic analysis platforms, which are widely deployed in the cyber security industry, it has been frequently observed that the malware detects the analysis environment and behaves differently to evade inspection; consequently the malicious code targeted by the attacker does not execute. In this case, the inspection, which will make the malicious code run and be examined, has to be done by the analyst manually. In this study, we present the bare metal hypervisor-based framework for dynamic analysis, ISKRA, which facilitates system calls to be collected and analyzed without being detected by malware. ISKRA is a portable and easily modifiable framework and not only allows any system to be easily transformed into an analysis environment, regardless of the virtual machine or bare metal; but also allows for forensics to be run without being detected in live systems. This way, incident response specialists can quickly transform the system under inspection into an analysis environment and can collect evidence, examine and remedy the system without being detected by the attacker. We designed, implemented and experimented with the framework, which employs machine learning algorithms to learn from new attack campaigns. Our work shows that the framework leads to negligibly low overhead and provides a high detection rate for the most current malware campaigns that evade dynamic inspection by other frameworks."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hastaların moleküler altgruplara doğru sınıflandırılması, etkili tedavilerin geliştirilmesi ve bu alt gruplarda kansere neyin yol açtığını çözmek için önemlidir. Kanser hastalarının büyük kohortları için çoklu omik veri katologlarının erişilebilir olması, somatik mutasyon ya da farklı ifadelenme gibi hasta genlerinde gerçekleşen değişimleri kataloglayarak tümörlerin moleküler biyolojisine çoklu bakış sağlar. Aynı zamanda, moleküler etkileşim ağları da, bu değişimler için biyolojik bağlam sağlar. Çoklu omik hasta verilerini yolaklardaki mevcut biyolojik bilgi ile birleştiren PAMOGK'u (Yolak tabanlı Çoklu-Omik Çizge Çekirdeği kümelemesi) geliştiriyoruz. Bir yolak bağlamında tek bir moleküler değişim tipine göre hasta benzerliklerini değerlendiren yeni bir çizge çekirdeği geliştiriyoruz. Yüzlerce yol ve moleküler değişiklik kombinasyonları ile değerlendirilen hastaların çekirdek olarak sunulmuş çoklu görüşlerini birleştirmek için çok görüntülü çekirdek kümeleme yöntemini kullanıyoruz. Berrak hücreli böbrek kanseri (KIRC) hastalarına PAMOGK uygulanması, sağkalım süreleri önemli ölçüde farklı olan dört küme ile sonuçlanır (p-değeri = 1.24e-11). PAMOGK'u diğer sekiz en gelişmiş çoklu-omik kümeleme yöntemiyle karşılaştırdığımızda, PAMOGK, KIRC hastalarını farklı sağkalım dağılımları olan gruplara ayırabilme açısından sürekli olarak daha iyi performans gösterir. Bulunan hasta alt grupları ayrıca tümör evresi ve derecesi ve primer tümör ve metastaz tümör yayılımları gibi diğer klinik parametrelere göre de farklılık gösterir. Önemli olarak tanımlanan yolaklar KIRC ile son derece ilgilidir. Analizimizi mutasyon, protein ve gen ifadesi verilerine sahip sekiz farklı kanser tipi ile genişletiyoruz. PAMOGK'a, https://github.com/tastanlab/pamogk adresinden ulaşılabilir.","Accurate classification of patients into molecular subgroups is critical for the development of effective therapeutics and for deciphering the underlining mechanisms for these subgroups. The availability of multi-omics data catalogs for large cohorts of cancer patients provides multiple views into the molecular biology of the tumors and the alterations that take place in patient genes such as mutations and differential expression patterns. At the same time, the molecular interaction networks provide the biological context for these alterations. We develop PAMOGK (Pathway based Multi Omic Graph Kernel clustering) that integrates multi-omics patient data with existing biological knowledge on pathways. We use a novel graph kernel that evaluates patient similarities based on a single molecular alteration type in the context of a pathway. To corroborate multiple views of patients that are evaluated by hundreds of pathways and molecular alteration combinations, we use a multi-view kernel clustering approach. Applying PAMOGK to kidney renal clear cell carcinoma (KIRC) patients results in four clusters with significantly different survival times (p-value = 1.24e-11). When we compare PAMOGK to eight other state-of-the-art multi-omics clustering methods, PAMOGK consistently outperforms these in terms of its ability to partition KIRC patients into groups with different survival distributions. The discovered patient subgroups also differ with respect to other clinical parameters such as tumor stage and grade, and primary tumor and metastasis tumor spreads. The pathways identified as important are highly relevant to KIRC. We also extend our analysis to eight other cancer types with available mutation, protein, and gene expression data. PAMOGK framework is available in https://github.com/tastanlab/pamogk"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde Büyük Veri olarak bilinen verilerin artan hacmi ve hızı, arastırmacıları, analistleri ve sirketleri veritabanı yönetim sistemlerini saglam, ölçeklenebilir, ve veri ile sorunsuz bir sekilde uyum saglayabilecek sekilde olusturmaya tesvik etmektedir. Öte yandan, Merkezi Islem Birimleri olan geleneksel islem birimlerini (PU), Grafik Islem Birimleri gibi ek bilgi islem gücüyle destekleme egilimi vardır. Arastırmacılar, veri yogunluklu uygulamalar için güçlü bilgi islem gücünün potansiyelini kabul etmektedirler. Son yıllarda, GPU'ları eldeki sisteme entegre ederek ve bunları farklı is yükü dagıtım algoritmalarına ve sorgu optimizasyon protokollerine göre kullanarak dikkat çekici DBMS'lerin olusturulmasına neden olan çesitli arastırma çalısmaları yapılmaktadır. Bu nedenle, Çevrimiçi Analitik Isleme altyapısını benimseyen DOLAP adını verdigimiz, hibrit, sütun tabanlı yüksek performanslı bir veritabanı yönetim sistemi olusturarak yeni bir yaklasımı ele almaya çalısıyoruz. Önceki hibrit DBMS'lerden farklı olarak, veritabanımız DOLAP, veriler üzerinde farklı islemler gerçeklestirirken (alma, kontrol etme, degistirme ve silme) Bloom filtreleri kullanmaktadır. Veritabanının veri kayıtlarını kontrol ederken gereksiz bellek erisimlerini önlemek için bu olasılıklı veri yapısını DOLAP'ta uygulamaktayız. Yaptıgımız deneylerde, toplam çalısma süresini %35 azaltarak kullanıslı oldugunu kanıtladık. CPU ve GPU olmak üzere farklı özelliklere sahip iki ana PU üzerinde sistemimizin verimliligini artırmak amacıyla, sorgunun yürütme birimine etkin bir sekilde karar veren bir is yükü dagıtım modeli tanımladık. Rastgele tabanlı, Algoritma tabanlı ve Gelistirilmis Algoritma tabanlı modeller olmak üzere 3 yük is dagıtım modeli önerdik. Testlerimizi Kaggle'dan alınan Chicago Taxi Driver veri kümesi üzerinde gerçeklestirdik, Bu deneylerde 3 yük dengeleme modeli arasında, iyilestirilmis algoritma tabanlı model, sorgu yükünü CPU'lar ve GPU'lar arasında iyi bir sekilde dagıtmadaki etkinligini kanıtlamakta ve neredeyse tümünde diger modellerden daha iyi performans göstermektedir.","The outstanding spread of database management system architectures in the last decade, plus the increasing growth, volume, and velocity of the data, which is known nowadays as ""Big Data"", are continuously urging researchers, businessmen and companies to build robust and scalable database management systems (DBMS) and improve them in a way they adjust smoothly with the evolution of data. On the other hand, there is a tendency to support the conventional processing units (PUs), which are the Central Processing Units (CPUs), with additional computing power like the emerging Graphical Processing Units (GPUs). The research community has accepted the potential of vigorous computing power for data-intensive applications. Several research studies were conducted in the last years that ended up in building remarkable DBMSs by integrating GPUs and using them according to different workload distribution algorithms and query optimization protocols. Thus, we try to address a new approach by building a hybrid columnar-based high performance database management system calling it DOLAP which adopts the Online Analytical Processing (OLAP) infrastructure. Distinctively from previous hybrid DBMSs, our database, DOLAP, depends on Bloom filters while performing different operations on data (ingesting, checking, modifying, and deleting). We implement this probabilistic data structure in DOLAP to prevent unnecessary memory accesses while checking the database's data records. This method is proved to be useful by reducing the total running times by 35%. Moreover, since there exist two main PUs with different characteristics, the CPU and GPU, a workload distribution model that effectively decides the query's executing unit at a time T should be defined to improve the efficiency of our system. Therefore, we suggested 3 load balancing models, the Random-based, Algorithm-based and the Improved Algorithmbased models. We run our tests on the Chicago Taxi Driver dataset taken from Kaggle and among the 3 load balancing models, the improved algorithm-based model demonstrates its effectiveness in well distributing the query load between the CPUs and GPUs where it outperforms the other models in nearly all the test runs."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Klasik OLTP sistemleri analiz sorguları için performans olarak yavaş kalmaktadır. Var olan heterojen mimarili OLAP veri tabanı yönetim sistemlerinde ise makine öğrenmesi kullanarak is dağıtımı yapan bir sisteme rastlanmamıştır. Bu çalışmada paylaşımlı hafıza mimarileri için geliştirilmiş, yüksek başarımlı ve sütun tabanlı bir veri tabanı yönetim sistemi olan DOLAP mimarisi anlatılmıştır. Ayrıca, veri tabanının üzerinde çalıştığı sunucu üzerinde bulunan, CPU ve GPU gibi farklı karakterlerdeki hesaplama donanımları için, buluşsal yöntemlere ve makine öğrenmesi yöntemlerine dayanan is dağıtım algoritmaları geliştirilmiş ve performansları analiz edilmiştir.","Conventional OLTP systems are slow in performance for analytical queries. In the existing heterogeneous architecture OLAP database management systems, no system distributes work using machine learning. In this study, the DOLAP architecture, which is a high-performance column-based database management system developed for shared memory architectures, is explained. Also, job distribution algorithms based on heuristic and machine learning methods have been developed for computing hardware with different characters such as CPU and GPU on the server on which the database is running, and their performance has been analyzed."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sanık ve tanıkların duruşma konuşmaları mahkeme sonuçlarını etkileyen önemli bir faktördür. Mahkeme kararlarının ilgili insanların hayatları üzerinde önemli sonuçlarının olacağı düşünüldüğünde, hakimlerin ve/veya jüri üyelerinin doğru kararları vermelerine yardımcı olabilecek bilgisayımsal modellerin geliştirilmesi önemli bir araştırma alanıdır. Bu tezde, gerçek hayatta geçen mahkeme videolarında aldatmaca saptaması üzerinde çalışılmıştır. Bu amaçla, sonuçlanmış olan kamuya açık mahkemelerin video kayıtlarından oluşan bir verikümesi kullanılmıştır. Verilen bir videodaki kişinin yanıltıcı olup olmadığını kestirmeyi hedefleyen çoklu-modaliteli bir aldatmaca kestirimi sistemi geliştirilmiştir. Aldatmacanın sınıflandırılması için görsel, işitsel ve metinsel olmak üzere 3 farklı modalite ayrı olarak değerlendirilmiştir. Son sınıflandırıcı sistemi, bu 3 farklı modalitenin skor seviyesinde birleştirilmesiyle elde edilmiştir ve 83.05% doğruluk oranıyla aldatmacaları yakalamıştır. Mahkeme videolarının çoklu-modaliteli analizinin çeşitli zorlukları vardır. Son sistemin geliştirilmesinden önce, aldatmaca kestiriminin performansını artırmaya faydalı olabilecek alt-problemler üzerinde çalışılmıştır. Videolardaki yüksek sesli arka-plan sesleri, konuşma özniteliklerinin kalitesini düşürmektedir; ayrıca otomatik sisteminin içerisinde bulunan konuşma tanıma sisteminin hata oranlarını artırmaktadır. Bu doğrultuda, konuşmaları arka-plan seslerinden ayrıştıran bir yapay sinir ağı temelli tek-kanallı kaynak ayrıştırma modeli geliştirilmiştir. Kelime temsil vektörleri, metin verisi içeren problemlerin en gelişkin çözümlerinde kullanılan bir tekniktir. Kelime temsil vektörleri, İngilizce metinsel konuşma kayıtlarından aldatmacanın kestirimi için denenmiş ve iyi sonuçlar alınmıştır. Bunun yanında, kelime temsil vektörlerinin Türkçe üzerindeki başarımının ölçümü üzerine de çalışmalar yapılmış; Türkçe metin kategorizasyonu ve anlambilimsel metin eşleme problemleri için kullanılmıştır. Bu çalışmalar kelime temsil vektörlerinin Türkçe aldatmaca kestirimi probleminde kullanımı için bir ön-çalışma niteliği taşımaktadır.","Hearings of witnesses and defendants play a crucial role when reaching court trial decisions. Given the high-stakes nature of trial outcomes, developing computational models that assist the decision-making process is an important research venue. In this thesis, we address the deception detection in real-life trial videos. Using a dataset consisting of videos collected from concluded public court trials, we explore the use of verbal and non-verbal modalities to build a multimodal deception detection system that aims to classify the defendant in a given video as deceptive or not. Three complementary modalities (visual, acoustic and linguistic) are evaluated separately for the classification of deception. The final classifier is obtained by combining the three modalities via score-level classification, achieving 83.05% accuracy. Multimodal analysis of trial videos involves many challenges. Prior to developing the final deception detection system, we have worked on sub-problems that would be helpful on improving deception detection performance. High volume of background sounds in a video decreases the quality of the speech features, and it results in low speech recognition performance. We developed a neural network based single-channel source separation model to extricate the speech from the mixed sound recording. Word embeddings, is the state-of-art technique in processing of textual data. In addition to evaluating pretrained word embeddings in developing the deception system for English, we have also worked on learning word embeddings for Turkish and used them for categorizing text documents. This work can be applied in future for a deception system in Turkish."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hesaplama cihazlarının gelişmesi ve Internet'in yaygınlaşması ile birlikte işbirlikçi hesaplama için büyük imkanlar doğmuştur. Bir fonksiyon veya algoritma üzerinde ortak hesaplama ihtiyacı, birbirlerine güvenen, kısmen güvenen veya kesinlikle güvenmeyen taraflar arasında olabilmektedir. Literatürde güvenli çok taraflı hesaplama (İng. multi-party computation - MPC) olarak bilinen protokoller, iki veya daha fazla tarafın, güvenilir bir üçüncü tarafa ihtiyaç duymadan ortak bir fonksiyonu birlikte hesaplamalarına imkan sağlar. Ancak MPC için önerilen genel çözümler, fonksiyonun kendisinin de hassas olduğu ve gizli tutulması gerektiği bazı özel durumlar için yeterli değildir. Gizli fonksiyon değerlendirme (İng. private function evaluation - PFE) fonksiyonun yalnızca bir tarafça bilinmesine imkan sağlayan özel bir MPC durumuna karşılık gelir. PFE protokolleri, bir algoritmanın veya bir fonksiyonun gizlilik seviyesi veya fikri mülkiyeti gibi nedenlerle gizli kalmasını gerektiren çeşitli problemler için çözüm sağlar. Son zamanlarda, verimli PFE protokollerinin tasarlanması, kriptografi araştırmacıları için zorlayıcı ve ilgi çeken bir alan haline gelmiştir. Bu tez çalışmasında iki taraflı gizli fonksiyon değerlendirme (İng. two-party private function evaluation - 2PFE) protokollerinin geliştirilmesi hedeflenmiştir. Öncelikli hedefimiz, simetrik ve asimetrik şifreleme kategorilerinde güvenli ve daha verimli PFE protokolleri tasarlayarak literatürü bu alandaki çalışmalarımız ile geliştirmektir. Bu amaçla, ilk olarak simetrik kriptografik yapıtaşlarına dayalı 2PFE protokollerini geliştirmeyi amaçladık. Eurocrypt'13'te Mohassel ve Sadeghian tarafından sunulan ve bu kategorideki en iyi sonuçlar ortaya koyan PFE protokolünü ele aldık. İyi bilinen yarım kapılı karmaşık devreler tekniğinin (Zahur et al., Eurocrypt'15) 2PFE şemasına nasıl uyarlayıp kullanacağını gösterdik. Protokoleri karşılaştırdığımızda, sonuçta elde ettiğimiz optimizasyonumuz, hem kayıtsız genişletilmiş permütasyon (İng. oblivious extended permutation - OEP) hem de güvenli iki taraflı hesaplama (İng. two-party computation - 2PC) alt protokollerinin verimliliğini önemli ölçüde iyileştirmiş ve iletişim maliyetinde % 40'ın üzerinde verimlilik sağlamıştır. Bunun yanı sıra, kararsal Diffie-Hellman (İng. decisional Diffie-Hellman - DDH) varsayımına dayanan yeni ve özgün 2PFE şeması önermekteyiz. Şemamız, literatürdeki çalışmaları önemli ölçüde geliştirmekle birlikte yeniden kullanılabilirlik özelliğini sunarak sonraki hesaplamalar için verimliliği oldukça arttırır. Önerdiğimiz şemamız iki protokolden oluşmaktadır, birincisi fonksiyonunun ilk defa uygulamasında, ikincisi ise sonraki uygulamalarda kullanılır. Bildiğimiz kadarıyla, önermiş olduğumuz bu şema, literatürdeki en verimli ve yeniden kullanılabilirlik özelliğine sahip ilk 2PFE tasarımıdır. Önermiş olduğumuz protokoller lineer iletişim ve hesaplama karmaşıklıklarına sahipken protokollerin mesaj tur sayısı en fazla üçtür.","Development of computing devices with the proliferation of the Internet has prompted enormous opportunities for cooperative computation. These computations could occur between trusted or partially trusted partners, or even between competitors. Secure multi-party computation (MPC) protocols allow two or more parties to collaborate and compute a public functionality using their private inputs without the need for a trusted third-party. However, the generic solutions for MPC are not adequate for some particular cases where the function itself is also sensitive and required to be kept private. Private function evaluation (PFE) is a special case of MPC, where the function to be computed is known by only one party. PFE is useful in several real-life applications where an algorithm or a function itself needs to remain secret for reasons such as protecting intellectual property or security classification level. Recently, designing efficient PFE protocols have been a challenging and attractive task for cryptography researchers. In this dissertation, we mainly focus on improving two-party private function evaluation (2PFE) schemes. Our primary goal is enhancing the state-of-the-art by designing secure and cost-efficient 2PFE protocols for both symmetric and asymmetric cryptography based solutions. In this respect, we first aim to improve 2PFE protocols based on (mostly) symmetric cryptographic primitives. We look back at the seminal PFE framework presented by Mohassel and Sadeghian at Eurocrypt'13. We show how to adapt and utilize the well-known half gates garbling technique (Zahur et al., Eurocrypt'15) to their constant round 2PFE scheme. Compared to their scheme, our resulting optimization significantly improves both underlying oblivious extended permutation (OEP) and secure 2-party computation (2PC) protocols, and yields a more than 40% reduction in overall communication cost. We next propose a novel and highly efficient 2PFE scheme based on the decisional Diffie-Hellman (DDH) assumption. Our scheme consists of two protocols, one is utilized in the initial execution, and the other is in the subsequent runs. One of the novelties of our scheme over the state-of-the-art is that it results in a significant cost reduction when the same private function is evaluated more than once between the same or varying parties. To the best of our knowledge, this is the most efficient and the first 2PFE scheme that enjoys reusability feature. Our protocols achieve linear communication and computation complexities, and a constant number of rounds which is at most three (depending on the size of the inputs of the party that holds the function)."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Özgüdüm dizileri, çeşitli sonlu durum makinesi bazlı testlerde kullanılan ilginç girdi dizilerindendir. Daha kısa özgüdüm dizileri kullanmak, daha kısa test dizileri sağlayacağı için genellikle tercih edilir. En kısa özgüdüm dizisini bulmanın NP-zor bir problem olduğu bilinmektedir. En kısa özgüdüm dizisinin üst sınırı da literatürde çalışılan bir problemdir. n durumlu bir sonlu durum makinesi için sıkı üst sınırın n(n − 1)/2 olduğu bilinmektedir. Bununla birlikte, bu sınıra ulaşan sonlu durum makinelerinin bilinen bütün örneklerinin hepsi n−1 girdi sembolu kullanmaktadır ve bu durum, girdi alfabesi durum sayısı ile birlike büyüyor demektir. Peki bu üst sınıra sabit sayıda girdili bir sonlu durum makinesi ile ulaşılabilir mi? Bu çalışmada deneysel bir analiz yaptık ve soruya negatif bir şekilde cevap verdik. Bütün 2 girdili, 2 çıktılı sonlu durum makinelerini etraflıca sayıp, deneysel olarak 10 ya daha az durumlu sonlu durum makineler için en kısa özgüdüm dizisinin üst sınırını hesapladık. Bu hesaplamayı pratikte uygulanabilir kılmak adına sonucu etkilemeyen sonlu durum makinelerini elemek için çeşitli teknikler uyguladık.","Homing sequences are special input sequences that are used by various techniques of finite state machine based testing. Using a shorter homing sequence is typically preferred since it would yield a shorter test sequence. Finding a shortest homing sequence is known to be an NP–hard problem. The upper bound of shortest homing sequences is also a problem studied in the literature. A tight upper bound for the length of shortest homing sequence for a finite state machine with n states is known to be n(n−1)/2 . However, the known examples of finite state machines hitting to this upper bound also use n−1 input symbols, i.e. the size of the input alphabet also grows with the number of states. Is this upper bound reachable for a finite state machine with a constant number of inputs? In this work, we use an experimental analysis and we answer this question negatively. By exhaustively enumerating all finite state machines with two input symbols and two output symbols, we experimentally compute the upper bound for the length of the shortest homing sequence for finite state machines with 10 or less states. In order to make this computation feasible in practice, we apply several techniques to eliminate from our search those finite state machines which would not affect the result of the computation."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"oşut bir uygulamanın görev etkileşim çizgesi komşu görevlerin farklı renklerle boyandığında birbirleri ile aynı renkteki görevler aynı anda pahalı bir senkronizasyon veri yapısı kullanılmadan aynı anda çalıştırılabilmektedir. Bu tür bir çalıştırmada bir renkteki görevler bitirilmeden, başka bir renkteki görev koşut halde şlenemeyeceğinden boyama esnasında kullanılan renk sayısı koşut uygulamanın çalıştırılması esnasında karşılaşılacak senkronizasyon adım sayısını belirtmektedir. Literatürde çizge boyama problemi ''bir çizgeyi mümkün olan en az sayıda renk kullanarak komşu noktalara farklı renkler vermek'' olarak tanımlanmıştır ve bir optimizasyon problemi olarak görüldüğünde NP-Hard sınıfındadır. Çizge boyama probleminin farklı çeşitleri de paralel hesaplama, özellikle paralel bilimsel hesaplama alanında önemlidir. Problemin yukarıda bahsedilen basit halinde 1-uzaklık kullanılırken, k-uzaklık tanımı da özellikle k = 2 için pratikte kullanılmaktadır. Bu tezde de bu problem üzerine yoğunlaşılmıştır. Problemin genel hali ''bir çizgeyi mümkün olan en az sayıda renk kullanarak birbirinden k ve daha az uzaklıktaki nokta ikililerine farklı renkler vermek'' olarak tanımlanabilir. Literatürde bu problem için az renk kullanan buluşsal yöntemler önerilmiştir ve bu yöntemler k = 1 için oldukça hızlıdır. Fakat k = 2 için özellikle büyük çizgelerde bu buluşsal yöntemler dakikalar mertebesinde zaman alabilmektedirler. Çizge boyamanın bir uygulamanın çalışması için sadece bir ön işlem olduğu düşünüldüğünde bu işlemin getirdiği ekstra zamanın mümkün olduğu kadar az olması işlemin uygulanabilirliği için önemlidir. Bu tezde 2-uzaklık çizge boyama ve bu problemin farklı bir türü olan iki parçalı çizge boyama problemleri için iyimser ve açgözlü buluşsal yöntemler önerilmiştir. Bu yöntemler çok çekirdekli işlemcilerde ve Grafik İşleme Ünitelerinde koşut olarak gerçeklenmiş, ve ölçeklenebilirlikleri analiz edilmiştir. Yapılan deneylerde önerilen yöntemlerin ölçeklenebilir ve 16 çekirdek kullanıldığında literatürdeki yöntemlerden ortalama 25 kat hızlı oldukları görülmüş, özellikle sosyal ağ karakteri taşıyan çizgeler için büyük performans artışı sağladığı saptanmıştır. Yine bu tez çerçevesinde aynı renge sahip nokta kümelerinin eleman sayılarının birbirine yakın olması üzerine de çalışılmıştır. Bu tür dengeli dağılımlı bir boyama, uygulamanın çok çekirdekli işlemciler ve özellikle GİÜ'ler üzerinde çalışması esnasında her senkronizasyon adımında bütün çekirdekleri doyuracak kadar iş yükü olmasını sağlayacağından yüksek performans için önemli olabilmektedir. Bu tezde neredeyse hiç ekstra külfet getirmeden bunu sağlayabilecek iki yöntem önerilmiştir. Yapılan deneylerde bu yöntemlerin başarılı olduğu sonucuna varılmıştır.","In parallel computing, a valid graph coloring yields a lock-free processing of the colored tasks, data points, etc., without expensive synchronization mechanisms. However, the coloring stage is not free and the overhead can be significant. In particular, for distance-2 graph coloring (D2GC) and bipartite graph partial coloring (BGPC) problems, which have various use-cases within the scientific computing and numerical optimization domains, the coloring overhead can be in the order of minutes with a single thread for many real-life graphs, having millions and billions of vertices and edges. In this thesis, we propose a novel greedy algorithm for the distance-2 graph coloring problem on shared-memory architectures. We then extend the algorithm to bipartite graph partial coloring problem, which is structurally very similar to D2GC. The proposed algorithms yield a better parallel coloring performance compared to the existing shared-memory parallel coloring algorithms, by employing greedier and more optimistic techniques. In particular, when compared to the state-of-the-art, the proposed algorithms obtain 25x speedup with 16 cores, without decreasing the coloring quality. Moreover, we extend the existing distance-2 graph coloring algorithm to manycore architectures. Due to architectural limitations, the multicore algorithm can not easily be extended to manycore. Thus several optimizations and modifications are proposed to overcome such obstacles. In addition to multi and manycore implementations, we also offer novel optimizations for both D2GC and BGPC on social network graphs. Exploiting the structural properties of social graphs, we propose faster heuristics to increase the performance without decreasing the coloring quality. Finally, we propose two costless balancing heuristics that can be applied to both BGPC and D2GC, which would yield a better color-based parallelization performance with a better load-balancing, especially on manycore architectures."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Küçük ölçekli rüzgâr türbinlerinin (DERT) enerji çıkışının optimizasyonu, rüzgâr hızını rotor uç hızı oranını optimum değerde tutan bir kontrolör gerektirmektedir. Eğer dinamik model sistemin tamamı bilinir ve rüzgâr hızı tahmin edilebilirse, analitik bir çözüm elde edilebilir. Ancak, sadece yaşlanma değil aynı zamanda modelleme ve rüzgar hızı tahminindeki hatalar basit bir çözümü engeller. Bu tezde, Dikey Eksenli Rüzgar Türbinlerinin enerji çıkış optimizasyonuna, sürekli durum ve aksiyon uzaylarına sahip dinamik sistemleri optimize etmek için tasarlanmış bir Pekiştirmeli öğrenme yaklaşımı uygulaması önerilmektedir. Rüzgar türbininin dinamik modellemesi ve yük kontrolü; tek süreç içinde ele alınmaktadır. Önerilen algoritma bir optimal politikanın parametrelerini elde etmek için Markov Zincirli Monte Carlo kullanarak modelden bağımsız Bayesçi Pekiştirmeli Öğrenmedir. Önerilen yöntem rüzgar hızı profillerini ve sistem modelini öğrenir, bu nedenle, Dairesel Tabanlı Fonksiyon Sinir Ağı (DTFSA) kullanarak optimal kontrol sinyalini hesaplamak için tüm sistem durumlarını ve gözlenen rüzgar hızı profillerini kullanabilir. Önerilen yöntem, klasik Maksimum Güç Noktası Takipçisi (MGNT) ile karşılaştırmak üzere sabit mıknatıslı senkron jeneratör tabanlı DERT Simulink modeli için simülasyon çalışmaları yapılarak doğrulanır. Sonuçlar klasik yöntem ile kıyaslandığında, özellikle rüzgar hızı geçişlerinde, önemli bir gelişme göstermiştir, ayrıca değişken hızlar için umut vadeden enerji çıktısı göstermiştir ki bu Dikey Eksenli Rüzgar Türbinlerini (DERT) için istenilen bir durumdur.","Optimization of energy output of small scale wind turbines requires a controller which keeps the wind speed to rotor tip speed ratio at the optimum value. An analytic solution can be obtained if the dynamic model of the complete system is known and wind speed can be anticipated. However, not only aging but also errors in modeling and wind speed prediction prevent a straightforward solution. This thesis proposes to apply a reinforcement learning approach designed to optimize dynamic systems with continuous state and action spaces, to the energy output optimization of Vertical Axis Wind Turbines (VAWT). The dynamic modeling and load control of the wind turbine are accomplished in the same process. The proposed algorithm is a model-free Bayesian Reinforcement Learning using Markov Chain Monte Carlo method (MCMC) to obtain the parameters of an optimal policy. The proposed method learns wind speed profiles and system model, therefore, can utilize all system states and observed wind speed profiles to calculate an optimal control signal by using a Radial Basis Function Neural Network (RBFNN). The proposed method is validated by performing simulation studies on a permanent magnet synchronous generator-based VAWT Simulink model to compare with the classical Maximum Power Point Tracking (MPPT). The results show significant improvement over the classical method, especially during the wind speed transients, promising a superior energy output in turbulent settings; which coincide with the expected application areas of VAWTs."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son on yılda internet teknolojilerinin hızlı gelişimi bilginin dünyanın her yerine çok kolay bir şekilde yayılmasına izin vermiştir. İnternet ortamındaki bilgi bolluğu sayesinde kullanıcılar kendilerini geliştirmeye fırsat bulmuştur. Günümüzde bir çok akademik kurum herkesin kullanımına açık dersler sunmaya başlamış ve dünyanın bir çok yerinden öğrenciler bunlara katılp yararlanma imkanı elde etmiştir. Neredeyse her konuyla ilgili bir çok farklı kaynaktan yapılan paylaşımlar her ne kadar öğrenciler için bir avantaj gibi gözükse de tüm bu bilgi yığını, öğrenilmek istenilen konunun internette düzensiz ve karmaşık bir şekilde sunulmasına yol açmıştır. Bu yüzden öğrencinin ilgili olduğu konuyu öğrenmeye çalışırken tüm bu karmaşa içinde kaybolması olasıdır. Daha da önemlisi, öğrenilmek istenen konu bir çok teknik kavram gerektirebilir ve bu kavramlardan bazıları, diğer kavramları anlamak için ön koşul olabilir. Bu durumda öğrenci konuyu öğrenmeye hangi kavramlardan başlamalı bilemeyebilir ve dolayısıyla bütün konuyu kavramakta zorluk yaşar. Bu temel problemden yola çıkarak çalışmamızda, öncelikli olarak iki farklı kavramı anlatan yazılı akademik dökümanın arasında olabilmesi muhtemel önkoşul ilişkisini sayısal olarak ifade etmeye çalışıyoruz. Kavramlarla ilgili yazılı dökümanları hemen hemen her konudan bilgi içeren ve çok büyük bir çevrimci ansiklopedi olan Wikipedia'dan makale olarak alıyoruz. Bununla beraber, konuyla ilgili öğrenilmek istenilen kavramlar, Wikipedia makale karşılıkları ile verilirse tüm bu kavramların birbiri ile olan önkoşul ilişkilerini hesaplayıp bunlardan bir önkoşul kavram haritası oluşturarak öğrenciye sunuyoruz. Oluşturduğumuz haritanın yeni bir konuyu çevrimci öğrenmek isteyen bir kimseye öğrenme sürecinde faydalı olmasını umuyoruz.","The growth of internet technologies in the last decade allowed the knowledge to spread out very fast across the globe. Users began educating themselves with huge amounts of online material on the internet. Today many academic institutions offer publicly available courses where students, all around the world can join and benefit from them. The abundance of online material from many different resources created an unorganized content in which it is likely for the learners to get lost. Furthermore, some concepts may require knowledge from other concepts and the learner may not be aware of those prerequisite relations between the concepts, therefore, he or she may have difficulties in understanding them. In our work, we create a metric for calculating a prerequisite score between two text-based educational material. We choose Wikipedia articles to work with since it is a large encyclopedia containing huge amounts of information on lots of different concepts. Furthermore, from a given set of concepts with their corresponding Wikipedia articles, we calculate each concept's prerequisite score with the other concepts and build a prerequisite concept graph for the learner. We hope that our graph model will guide the students in their studies and enhance their learning experience."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Arama platformları hayatımızın her yerinde. İnsanlar popüler arama motorları olan Bing ve Google üzerinden olduğu gibi YouTube gibi diğer arama platformlarından da bilgi arayışı içerisindeler. Bununla birlikte, kullanıcılar arama platformlarını hiçbir ön yargı katmadan yalnızca bilgiyi sunan objektif platformlar olarak görüyorlar. Kullanıcılar farkında olmadıklarında ön yargılara karşı daha da savunmasız kalmaları sebebiyle, arama platformlarından dönen sonuçların ön yargı açısından analiz edilmesi önemli. Bu tez esasen arama motorlarında bulunan ön yargıları tartışmalı konular üzerinden, ve arama platformlarında bulunan cinsiyetçi ön yargıları da çevrimiçi eğitim odağında analiz ediyor. Arama motorlarına özgü ön yargıları analiz etmek için, üç yeni sıralama ve ilgililik tabanlı metrik önerildi. Bu metrikler kullanılarak Bing ve Google'ın arama sonuçları web dokümanlarının içeriği üzerinden tutumsal (destekliyor veya karşı) veya ön yargı ve ideolojik (muhafazakar veya liberal) ön yargı olarak iki kısımda incelendi. Ek olarak, lokasyonun bu ön yargı sonuçlarına olan etkisi incelendi. Son olarak, arama motoru sonuçları ön yargının kaynağı -- ön yargının veri setinden mi yoksa sıralama algoritmasından mı geldiğinin anlaşılması için incelendi. Cinsiyetçi ön yargının çevrimiçi eğitimde değerlendirilmesi için, bu kapsama uygun iki yeni sıralama ve ilgililik tabanlı metrik önerildi. Sonrasında YouTube'un STEM ve NON-STEM alanları ile ilgili sorgulara karşılık döndürdüğü video arama sonuçları video'daki anlatıcının bilgileri kullanılarak incelendi. Son olarak, video arama sonuçlarındaki cinsiyetçi ön yargının kaynağı bu amaca özgü bir şekilde adapte edilmiş metriklerle araştırıldı.","Search is ubiquitous. People continue to seek information through popular search engines, Bing and Google as well as online search platforms, YouTube. Nonetheless, they tend to think that these platforms are objective by only displaying information without injecting any bias. Since users are more susceptible to bias when they are unaware of it, it is important to evaluate the retrieved search results of the aforementioned platforms with respect to bias. This thesis analyses two main things as search engine bias towards controversial issues and gender bias in the context of online education. For evaluating specifically search engine bias, three novel rank and relevance-based measures have been proposed and search results of two widely-used search engines Google and Bing have been analysed through web documents' content with respect to stance (in support or against), and ideological bias (conservative or liberal). Then, the impact of geolocation on the bias has been investigated. Lastly, in the scope of search engine bias, the source of bias has been tracked, to check whether the bias (if exists) comes from the input data, or the ranking algorithm. For assessing gender bias in online education, two new rank and relevance based measures that are more suitable in the scope of gender bias have been proposed. Further, video search results returned by YouTube towards the queries in STEM and NON-STEM fields have been analysed using narrators' information. Lastly, the source of gender bias has been investigated by proposing the specifically-curated gender bias measures."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biz bu çalışmada çevrimdışı el yazısı tanıma problemi için eğitim ve test sırasında veri artırma tekniklerinden yararlanan bir derin öğrenme modeli önerdik. Bu alandaki en sık kullanılan el yazısı veri kümesi olan IAM veri kümesi üzerinde derin öğrenme ağının her bir bileşenini değerlendirmek için CNN-BiLSTM ağımızı kullanarak kapsamlı bir analiz yaptık. Derin öğrenme ağı mimarisi ile deneyler yaptık; veri kıtlığı problemini hafifletmek için eğitim zamanı veri artırma ve ağı sentetik veriler ile ön eğitimden geçirmenin etkilerini değerlendirdik. El yazısı görüntüsüne ait eksik ya da hatalı tahmin edilen çıktılardan doğru çıktıyı elde etmek için bir son işleme yöntemi olarak iki farklı test-zamanı veri artırma metotu önerdik. Bu test zamanı veri artırma yöntemi sistemin zaman ve çalışma karmaşıklığını artırsa da hata oranlarını %2.5 oranında düşürmüştür ve bu sebeple gerçek zamanlı tanıma gereksinimlerinin olmadığı, veriyi yığın olarak işleme durumlarında kullanılabilir. Ayrıca, Türkçe dili için çevrimdışı el yazısı tanımanın ilk adımlarını atıyoruz. Bu amaçla 73 farklı kişiden toplanan 2600'den fazla satır görüntüsünden oluşan ilk, satır düzeyinde Türkçe el yazısı veri kümesini oluşturduk. Geliştirdiğimiz derin öğrenme yöntemini bu küme üzerinde de uygulayarak gelecek çalışmaların temel alabilecekleri sonuçlar sağladık; ayrıca, IAM kümesinden bizim topladığımız Türkçe el yazısı veri kümesine öğrenme aktarımı ve her iki veri kümesi ile ortak eğitim gibi yaklaşımları araştırdık. Katkılarımız her iki küme için de yöntemlere ve kümelere dair daha iyi içgörüler sunan itinalı bir hata analizini de kapsar. Bu çabanın bir parçası olarak da bilimsel tekrarlanabilirliği teşvik etmek için önerilen modelimiz ile birlikte değerlendirme kriterlerimizi açık ve eksiksiz bir şekilde sunuyoruz.","We have proposed a deep learning model leveraging train and test time data augmentation approaches for the problem of offline handwriting recognition. We made a comprehensive analysis using our CNN-BiLSTM network to provide evaluation results of each component of the network for the IAM dataset, which is the most commonly used handwriting dataset. We experimented with the deep learning network architecture; evaluated the effects of train time data augmentation and pretraining the network with synthetic handwriting images to alleviate the data sparseness problem. We proposed two different test time augmentation methods as post-processing approaches to obtain the correct transcription of the handwriting image out of the partly correct predicted transcriptions. While the test time augmentation increases the time and computational complexity, it reduced the error rate by 2.5% points and thus could be preferred for batch processes when there are no real-time recognition requirements. Furthermore, we attempt the initial steps of offline handwriting recognition for the Turkish language. To this end, we crafted the first, line-level Turkish handwriting dataset, consisting of more than 2600 line images collected from 73 different people. We applied our deep learning method to this dataset to provide baseline results for future studies; besides, we explored approaches including transfer learning from the IAM to the Turkish dataset and joint training with both datasets. Our contributions include an extensive error analysis for both datasets, revealing better insights into methods and datasets. As part of this effort, we provide our evaluation criteria clearly and completely along with our proposed model to encourage scientific reproducibility."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otonom sistemler, işlem sırasında, beklenmedik olaylara karşılık olarak davranışlarını değiştirebilen sistemlerdir. Sürücüsüz araçlar ve ev temizleme robotları bu tarz sistemler için 2 yaygın örnektir. Otonom ve tahmin edilemez yapılarından dolayı bu sistemlerin test edilmesi bilhassa zor bir işlemdir. Örneğin, otonom aracın adaptif hız sabitleyici modülünün test edilmesi için hazırlanmış statik bir test durumu, eğer araç uygulama sırasında beklenmedik bir hareket yaparsa (önceden karar verilen şeriti değiştirme gibi) boşa düşebilir. Bu tezde, otonom sistemlerin testi için, dinamik ve program durum tabanlı bir test yaklaşımı önermekteyiz. Önerilen yaklaşım, girdi olarak bir grup test senaryosu alır, test edilen sistemin durumunu sürekli monitor eder, geçerli durumun test senaryolarına uyup uymadığını ya da geçerli durumdan tanımlanmış bir grup aksiyon ile ulaşılabilen bir test senaryosu olup olmadığını anlar, şayet varsa, sistemi senaryoya yönlendirmek için dinamik olarak aksiyonları alır(gerekirse yapay zeka planlama ile), sistem istenen duruma gelince testi koşar ve sonuçları onaylar. Biz, sistemin durumunu, test senaryolarını, olası aksiyonları ve test beklentilerini modellemek için deklaratif mantıksal programlama, bilhassa, çözüm kümesi programlama kullanmaktayız. Önerilen yaklaşımı değerlendirmek için bir grup deneysel çalışma gerçekleştirmekteyiz: otonom araçların adaptif hız sabitleyici modüllerinin test edilmesi ve bir bilgisayar oyunu, Pacman. Deneylerimizin sonuçları önerilen yaklaşımın değişik alanlardan farklı test senaryolarının ifade edilebilmesi için oldukça yeterli olduğu göstermektedir.","Autonomous systems are systems that can change their behavior in response to unanticipated events during operation. Driverless cars and house cleaning robots are two common examples of such systems. Testing these systems is, indeed, a difficult task due to their autonomous and unpredictable nature. For example, a static test case for testing the adaptive cruise control system (ACC) of an autonomous car in a quite specific scenario may be rendered useless, if the autonomous car makes an unexpected move during the execution (such as, changing the lane, rather than staying on the predetermined lane). In this thesis, to do a better job of testing autonomous systems, we propose a dynamic, program state-based testing approach. At a very high level, the proposed approach takes as input a set of test scenarios to be executed, continuously monitors the current state of the system under test, figures out whether the current state matches with some of the test scenarios or whether some of the test scenarios can be reachable from the current state with the help of a predefined set of actions, if so, takes the actions to dynamically steer the system into the scenario (by using AI planning, if necessary), runs the tests once the system is in the expected state, and validates the results. Our approach is, indeed, a generic approach, which can be applied not only for testing autonomous systems, but also for testing other types of systems. We, in particular, use a declarative logic programming language, namely Answer Set Programming (ASP), to model the state of the system under test, the test scenarios to be executed, the actions to be taken as well as the test oracles. To evaluate the proposed approach, we carried out a number of empirical studies in two different application domains: testing the ACC of autonomous cars and testing a computer game, namely Pacman. The results of our experiments strongly suggest that the proposed approach is flexible enough to address different testing scenarios in various domains."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Uyku, hayvanlar aleminde evrimsel olarak korunmuş, elzem bir davranış biçimidir. Uykunun işlevlerini anlamak için, Drosophila Melanogaster gibi numune organizmalarda, uyku esnasında gözlemlenen davranışların ve fizyolojik değişikliklerin başarılı bir şekilde nitelendirilmesi gerekmektedir. Makine öğrenmesi alanındaki gelişmeler, vücut bölümlerinin otomatik olarak takip edilebilmesini, yüksek başarımlı konum ve duruş tahmini yapılabilmesini sağlamıştır. Ancak, davranışların tespit ve tasnif edilmesi, duruşların ve duruşlarda meydana gelen değişiklerin hangi davranış sınıflarına karşılık geldiğini hesaplamayı gerektirir.Uyku esnasında sergilenen davranışların tespit ve tahlil edilmesi, kendine özgü zorluklara sahiptir. Mevcut yöntemler ve veri işleme yaklaşımları, uyku sırasında meydana gelen fark edilmesi zor hareketlerden ziyade, büyük ölçekte gerçekleşen hareketlere ve duruş değişikliklerine odaklanarak geliştirilmiştir. Uykuda meydana gelen davranışları tahlil etme hedefimiz, uzun uyku döngüleri sırasında seyrek olarak meydana gelen asgarî değişiklikleri yüksek başarım ile saptamayı ve sınıflandırmayı gerektirir. Bu hedefle açık kaynaklı ve kullanımı kolay bir yazılım olarak sunduğumuz bir veri işleme uygulaması olan basty'i geliştirdik. Yaklaşımımız, anlamlı davranış temsillerini hesaplama, uzun uyku deneylerinde (14-16 saat) faâliyetleri tespit etme ve düşük boyutlu gömme uzaylarında en yakın komşu çözümlemesi gibi çeşitli aşamalardan oluşmaktadır. basty'i, beş davranış sınıfına odaklanarak, uyku yoksunluğu ve vahşi tip uyku deneylerinin verileri ile değerlendirdik. Sonuçlar, geliştirdiğimiz yaklaşımın davranış sınıflarını başarılı bir şekilde tasnif ettiğini ve 0,8 AUC puanı elde edebildiğini göstermektedir. Üstelik, yöntemimizin daha önce gözlemlenmeyen davranışları ve davranış repertuvarlarındaki farklılıkları tespit edebildiğini de ortaya koyduk. Ayrıca, hem vahşi tip uyku hem de uyku yoksunluğu deneylerinde, davranışların uzam-zaman eksenindeki niteliklerini ve uyku esnasındaki tertiplerini inceleyerek uyku sırasında sergilenen davranış repertuvarın bir incelemesini de sunuyoruz.","Sleep is a highly conserved behavior program across the animal kingdom, hinting at its essential value. In order to decipher the functions of sleep, careful characterization of the underlying changes in behavior and physiology is needed in powerful genetic model systems such Drosophila Melanogaster. Recent advances in machine learning have enabled tracking of body parts and robust pose estimation in videos; however, automated quantification of behaviors requires mapping from a pair of spatial coordinates to behavioral categories. Detection and successful mapping of behaviors exhibited during sleep come with unique challenges. Existing methods and pipelines are developed by focusing on behaviors defined by macro postural changes ignoring subtle movements during sleep. On the other hand, our task of phenotyping sleep requires tackling unobtrusive changes that sparsely occur during long sleep cycles. To this end, we develop basty (Automated Behavioral Analysis of Asleep Fruit Fly), a novel, end-to-end pipeline made public as a configurable, open source, and easy-to-use software package. Our pipeline enables several analyses, such as computing meaningful behavioral representations, detecting activities in long sleep experiments (14-16 hours), and nearest neighbors analysis in a low-dimensional behavioral space. We evaluate our pipeline with a dataset of sleep deprivation and wild-type sleep experiments, focusing on five behavioral categories. Results show that our pipeline successfully maps behavioral categories, achieving an AUC score of 0.8, and it can also discover unobserved behaviors and differences in behavioral repertoires. Furthermore, we present an analysis of the behavioral repertoire exhibited during sleep by examining spatio-temporal characteristics of the behaviors and their temporal organization; in both wild-type sleep and sleep-deprivation experiments."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Farklı alanlarda Makine Öğrenimini (ML) içeren çok sayıda uygulama kullanılmaktadır. Sağlık ve iş dünyası gibi birçok sektör, makine öğrenimi tabanlı tahmin hizmetleri sunmaktadır. Öte yandan, veri gizliliği ndişeleri makine öğrenimi hizmetlerinin tam potansiyeliyle kullanılmasını engelleyebilir. Makine öğrenmesi algoritmalarının yüksek güvenlikli şifreleme şemaları altında çalışmasını sağlamak, veri gizliliği sorununun üstesinden gelinmesine olanak tanıyacaktır. Makine öğrenimi algoritmalarını homomorfik olarak şifrelenmiş veriler üzerinde çalıştırmak, veri gizliliği sorunlarını ortadan kaldırmanın oldukça etkili bir yoludur. Bu nedenle, mevcut makine öğrenimi modellerinin homomorfik şifreleme ile kullanılabilirliği veri gizliliği için çok önemlidir. Sorgu veri sahipleri için kuantum sonrası bir güvenlik seviyesi sağlamak amacıyla yaygın olarak kullanılan XGBoost çıkarım algoritması ile homomorfik şifrelemeyi birleştirme üzerine çalışmayı seçtik. Bu çalışma, şifrelenmiş veriler üzerinde işlem yapabilen, gizliliği koruyan bir XGBoost çıkarım yöntemi önermekte ve gerçeklemektedir. Yöntemin tahmin ve zaman performansı çeşitli XGBoost modelleri kullanılarak değerlendirilmiştir. Ayrıca, hem sorgu sahipleri hem de model sahipleri için güvenlik ve gizlilik analizleri sunulmaktadır. Özet olarak, XGBoost çıkarımı için pratik ve etkili bir homomorfik şifreleme çözümü sunulmuştur.","There is a plethora of applications that incorporate Machine Learning (ML) in a wide variety of fields. Many sectors, such as healthcare and business, provide MLbased prediction services. However, data privacy concerns may prevent using machine learning services at their full potential. Enabling ML algorithms to perform under highly secure encryption schemes would grant the chance to overcome the data privacy issue. Running ML algorithms on homomorphically encrypted data is a promising way to eliminate data privacy issues. Thus, the compatibility of existing machine learning models with homomorphic encryption is crucial for data privacy. We chose to work on combining widely used XGBoost inference algorithm and homomorphic encryption to provide a post-quantum security level for query data owners. This work proposes and implements a privacy-preserving XGBoost inference method that performs operations on encrypted data. The prediction and time performance of the method is evaluated using various XGBoost models. Moreover, security and privacy analysis are provided for both query owners and model owners. In conclusion, a practical and effective homomorphic encryption solution for XGBoost inference is presented."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"SUMOlanma, SUMO'ların (küçük ubikuitin benzeri değiştiriciler) hedef proteinin spesifik bir lizin aminoasidine kovalent olarak bağlandığı, tersine çevrilebilir protein çeviri sonrası modifikasyonudur. SUMOlanma, hücre içi taşıma, DNA onarımı ve hücresel sinyalleşme gibi birçok hücresel olay için önemlidir. SUMOlanma sürecindeki bozukluklar, Alzeimer, kanser ve diyabet dahil olmak üzere çeşitli hastalıklarla bağlantılıdır. Bu nedenle, SUMOlanma bölgelerinin doğru tanımlanması, hücresel süreçleri ve onların aksaması sonucu ortaya çıkan patolojileri anlamak için elzemdir. Bu tezde, peptit dizisini girdi olarak alıp, bu bölgenin SUMOlanıp, SUMOlanmayacağını tahmin eden üç derin öğrenme mimari, SUMOnets, sunuyoruz. SUMOnet-1, -2 ve -3 adını verdiğimiz modellerin her biri biGRU'lar ve CNN'ler gibi derin sıralı öğrenme mimari birimlerinin farklı bileşimine dayanır. Girdi peptid dizilerin farklı gösterimleri ile bu modelleri eğitip, kıyaslama verisinde değerlendirdik. SUMOnet-3 %75,8 AUPR ve %87 AUC sonucu ile en iyi tahmin edici oldu ve bu performans değerleri literatürdeki, en iyi SUMOlaşma tahmini araçlarından yaklaşık %5'lik iyileşmeye denk geliyor. Ayrıca bilinen SUMOlanma motiflerinin var olup olmadığına göre oluşturulan, zor sınama kümesinde, ayrıca bir değerlendirme yaptık. Bu kümede tüm yöntemlerin performansı düşerken, SUMOnet-3 hala bu zorlu durumlarda en iyi tahmin edici olarak performans gösterdi ve literatürdeki diğer yöntemlerin performansı ise ciddi olarak düşüş gösterdi. SUMOnet-3 açık kaynak projesi ve bir Python kütüphanesi olarak https://github.com/berkedilekoglu/SUMOnet adresinde mevcuttur.","SUMOylation is a reversible post-translational protein modification in which SUMOs (small ubiquitin-like modifiers) covalently attach to a specific lysine residue of the target protein. This process is vital for many cellular events such as protein binding, subcellular transport, DNA repair, and cellular signaling. Aberrant SUMOylation is linked with several diseases, including Alzheimer's, cancer, and diabetes. Therefore, accurate identification of SUMOylation sites is essential to understanding cellular processes and pathologies that arise with their disruption. In this thesis, we present three deep neural architectures, SUMOnets, that take the peptide sequence centered on the candidate SUMOlylation site as input and predict whether the lysine could be SUMOylated. Each of these models, SUMOnet-1, -2 and -3, relies on different compositions of deep sequential learning architectural units, such as Bidirectional Gated Recurrent Units(biGRUs) and convolutional layers. We evaluate these models on the benchmark dataset with three different input peptide representations of the input sequence. SUMOnet-3 achieves 75.8% AUPR and 87% AUC scores, corresponding to approximately 5% improvement over the closest state-of-the-art SUMOylation predictor. We also create a challenging subset of the test data based on the absence and presence of known SUMOylation motifs. Even though the performances of all methods degrade in these cases, SUMOnet-3 remains the best predictor in these challenging cases, and the current methods' predictive abilities decrease significantly. The SUMOnet-3 framework is available as an open source project and a Python library at https://github.com/berkedilekoglu/SUMOnet."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda, mikromimari yan kanal saldırıları, bir bilgi işlem donanımından bilgi sızdırmak için en yeni ve merak uyandıran saldırılardan biri olarak ortaya çıkmıştır. Bu saldırılar, belirli mimari tasarımlar altında, hesaplamaların yan etkileri olarak üretilen istenmeyen yapay olgulardan yararlanırlar ve ciddi performans ek yüklerine maruz kalmadan etkin bir şekilde engellenmeleri genellikle zordur. Ayrıca, bu tür saldırılar birbirlerinden yalıtılmış işlemler, sanal kaplar ve sanal makineler arasında da çalışabilirler. Bu tez bilgisayar sistemlerine yönelik mikromimari yan kanal saldırılarına karşı alınabilecek önlemler üzerine yoğunlaşmaktadır. Bu tür saldırıların kökenleri, mevcut karşı önlem yaklaşımlarının etkinliği ve bu saldırılara karşı geleceğin güvenli sistemlerini oluşturmak için öğrenilebilecek dersler araştırılmaktadır. Bu amaç̧ için tez çalışmaları kapsamında geliştirilen bir sınıflandırma şeması kullanılarak son yıllardaki literatürün sistematik bir haritası çıkarılmakta ve bu haritalama kullanılarak yine tez çalışmaları kapsamında belirlenen araştırma soruları için elde edilen cevaplar sunulmaktadır. Bütün bu çalışmaların yanında mikromimari zamanlama saldırılarını, sistemlerin çalışmaları ile eş zamanlı olarak tespit eden, izole eden ve önleyen Detector+ adlı yeni bir yaklaşım sunulmaktadır. Sunulan yaklaşımın temeli, bahse konu saldırıların genellikle çok kısa süren işlemlerin çalışma sürelerini ölçtükten dolayı zararsız yazılımlara göre daha farklı bir zaman ölçüm karakteristiği gösterdiği gözlemine dayanmaktadır. Şüpheli zaman ölçümlerinin varlığı durumunda saldırganın anlamlı bilgiler elde etmesini önlemek için döndürülen ölçümlere gürültü eklenir. Ayrıca, şüpheli zamanlama ölçümleri kötücül işlemlerin sistemlerin çalışmalarıyla eş zamanlı olarak saptanması için analiz edilir. Sunulan yaklaşımın etkinliği ve sistemler üzerine getirdiği ihmal edilebilir düzeydeki ek çalışma yükü maliyeti hem bağımsız sunucu ortamlarında hem de sanallaştırılmış bulut ortamlarında yapılan deneysel çalışmalarla gösterilmiştir. Bu tez çalışması kapsamında siber güvenlik alanında gelecekteki araştırmalara ışık tutabilecek nitelikte potansiyel araştırma konuları da tartışılmaktadır.","Over the course of recent years, microarchitectural side-channel attacks emerged as one of the most novel and thought-provoking attacks to exfiltrate information from a computing hardware. They leverage the unintended artefacts produced as side-effects to computation, under certain architectural design choices and they prove difficult to be effectively mitigated without incurring significant performance penalties. Moreover, such attacks could operate across isolated processes, containers and virtual machines. In this thesis, we focus on countermeasuring microarchitectural side-channel attacks on computing systems. We investigate the origins of such attacks, effectiveness of existing countermeasure approaches, and lessons that can be learned to build secure systems of future against these attacks. To this end, we perform a systematic mapping of existing literature from recent years under a classification scheme that we developed for this purpose, and provide sought-after answers from the curated set of primary studies through systematic mapping. Furthermore, we present a novel approach called Detector+ to detect, isolate and prevent microarchitecture timing-attacks at runtime. We observe that time measurement behavior of timing attacks differ from benign processes, as these attacks need to measure the execution times of typically quite short-running operations. Upon presence of suspicious time measurements, noise is introduced into the returned measurements to prevent the attacker from extracting meaningful information. Subsequently, the timing measurements are analyzed at runtime to pinpoint malicious processes. We demonstrate the effectiveness of our approach and its incurred negligible performance overhead both in the standalone server environment as well as virtualized cloud environment. Lastly, we discuss some potential avenues for future research in this area of computer and cybersecurity."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gerçek hayattaki otonom depo uygulamalarından ilham alarak, çok etmenli yörünge bulma probleminin toplama ve dağıtma operasyonlarını dahil eden bir versiyonu olan kapasiteli çok etmenli toplama ve dağıtma problemine (MAPDC) yenilikçi bir çözüm öneriyoruz. Çok etmenli yörünge bulma probleminin zorluklarına (örneğin, etmenlerin birbirleriyle çarpışmayacak şekilde en kısa yörüngeleri hesaplaması) ek olarak , MAPDC probleminin verilen toplama-dağıtma işlerinin etmenlerin kapasiteleri dahilinde en makul şekilde dağıtılması gibi, kendine has zorlukları bulunmaktadır. Bu tezde MAPDC problemini matematiksel olarak bir çizge problemi olarak modelleyip, çözüm kümesi programlama teknikleriyle çözüm yöntemleri sunuyoruz. Tekli-deneme, çoklu-deneme, herhangi-zaman, artımlı veya hiyerarşik olan bu yöntemleri rastgele yarattığımız örnekler üzerinde deneysel olarak test edip karşılaştırıyoruz.","Motivated by autonomous warehouse applications in the real world, we study a variant of Multi-Agent Path Finding (MAPF) problem where robots also need to pick and deliver some items on their way to their destination. We call this variant the Multi-Agent Pick and Delivery with Capacities (MAPDC) problem. In addition to the challenges of MAPF (i.e., finding collision-free plans for each robot from an initial location to a destination while minimizing the maximum makespan), MAPDC asks also for the allocation of the pick and deliver tasks among robots while taking into account their capacities (i.e., the maximum number of items one robot can carry at a time). We mathematically model this problem as a graph problem, and introduce novel methods using Answer Set Programming with different computation modes: single-shot, anytime, incremental, and hierarchical. We compare these methods empirically with randomly generated instances over various sizes and types of environments."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, iki ana veri mahremiyeti problemine Bayesci çıkarım yöntemlerini kullanarak odaklanmaktadır. Bayesci çıkarım yöntemleri arasından özellikle Markov chain Monte Carlo (MCMC) ve bu metodu temel alan yaklaşımlar incelenmektedir. Bahsedilen problemlerden ilki, veri mahremiyeti uygulamalarında kullanıcıya sunulacak olan gizli verinin seçilmesi ile ilgilidir ve bunun için Fisher information yöntemi önerilmektedir. Bu noktada bilgilendiricilik ile çıkarım metodlarının başarısının yakından ilişkili olduğunu gösterilmiştir. Ardından, veri mahremiyetini gözeten doğrusal regresyon için bilinen yöntemlerden daha başarılı olan yeni bir üretici model önerilmiştir. Bu çalışmada, MCMC algoritmaları, çeşitli veri mahremiyeti senaryoları için özel olarak geliştirilmiştir. Bazı senaryolar basit ve verimli Metropolis-Hastings (MH) ile çalışmayı mümkün kılarken, diğerleri Pseudo-Marginal Metropolis-Hastings (PMMH), Metropolis-Hastings with Averaged Acceptance Ratios (MHAAR) veya Gibbs örnekleme gibi daha gelişmiş örnekleme yöntemleri gerektirmektedir. Daha ayrıntılı olarak, istatistik seçimi için MH, PMMH, MHAAR gibi algoritmalar uygulanırken, doğrusal regresyon problemi için Gibbs örnekleme ve türevlerinin kullanılması tercih edilmiştir. Sonunda, farklı durumları kapsayan sayısal deneyler gerçekleştirilmiştir. İstatistik seçimi bölümünde, her bir senaryo üzerinde titizlikle durulmuş ve Fisher information yönteminin hemen hemen tüm olası problem tanımlarında diferansiyel mahremiyet uygulamaları için faydalı bir araç olduğu gösterilmiştir. Doğrusal regresyon için hem simüle edilmiş hem de gerçek veri kümeleri kullanılmış ve önerilen yöntemlerin verimlilik ve etkinlik açısından mevcut algoritmaları geride bıraktığı gözlemlenmiştir.","This thesis focuses on data privacy applications with Bayesian inference, particularly Markov chain Monte Carlo (MCMC) methods for two main data privacy problems. Firstly, we focus on statistic selection with a Fisher information, and we show that informativeness and efficiency are closely related in the differential privacy setting. Then, we propose a novel generative model for the private linear regression that outshines state-of-art methods. In this work, MCMC algorithms are specifically developed for several data privacy settings. While some of the settings enable to work with simple and efficient Metropolis-Hastings (MH), others require more advanced sampling methods such as Pseudo-Marginal Metropolis-Hastings (PMMH), Metropolis-Hastings with Averaged Acceptance Ratios (MHAAR) or MH-within-Gibbs sampling. In detail, we prefer using versions of MH, PMMH, MHAAR for the statistic selection, and derivatives of the MH-within-Gibbs for the linear regression problem. At the end, we conduct several numerical experiments for evaluation purposes. In the statistic selection part, we rigorously deal with each problem setting and we obtain that Fisher information is actually a useful tool for the differential privacy applications for almost all possible problem definitions. For the linear regression, both simulated and real datasets are tested, and we observe that proposed methods beat existing algorithms in terms of efficiency and effectiveness."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çalışmasında, sıralamaların eksik olabileceği (yani bazı partnerlerin tercih edilmediği) veya denklik içerebileceği (yani bazı partnerlerin eşit tercih edildiği), SMTI (eksik ve denklik içeren sıralamalarla istikrarlı evlilik problemi) adı verilen bir SM varyantını ele alıyoruz. Farklı adalet ölçülerine göre optimum istikrarlı eşleşmeleri hesaplamayı amaçlayan üç SMTI varyantını araştırıyoruz: Cinsiyet Eşitlikçi SMTI (cinsiyetler arasında memnuniyet eşitliğini maksimize eder), Eşitlikçi SMTI (tüm kişilerin tercihlerinin toplam memnuniyetini maksimize eder) ve Maksimum Kardinalite SMTI (çiftlerin sayısını maksimize eder). Çözüm kümesi programlaması, kısıtlı programlama ve önermesel gerçeklenebilirlik kullanarak SMTI'ın bu zor türevlerini çözmek için yeni bildirimsel yöntemler sunuyoruz. Yöntemlerin rastgele oluşturulmuş örnekler üzerinde ölçeklenebilirliğini deneysel olarak analiz ediyoruz. Maksimum Kardinalite SMTI için, bu yöntemleri aynı zamanda mevcut tamsayılı doğrusal programlama ve yerel arama yaklaşımlarıyla karşılaştırıyoruz. Problemler daha fazla denklik ve eksiklik içerdiğinde, bildirimsel yöntemlerin yerel arama algoritmalarına göre hesaplama açısından diğer yaklaşımlardan genel olarak daha iyi olduğunu gözlemliyoruz.","Matching problems have been studied in economics, starting with the seminal paper of Gale and Shapley, which has led to a Nobel Prize in 2012, utilizing game theory methods with the goal of a mechanism design. One of the well-known matching problems is the Stable Marriage Problem (SM). In SM, for a set of n men and n women, we are given the preferences of individuals: for each man, a complete ranking of the women is specified as preferred partners; similarly, for each woman, a complete ranking of the men is specified as preferred partners. The goal is to marry all men and women (i.e., to find n couples) in such a way that marriages are stable: no man and woman in different couples prefer each other to their partners. We consider a variant of SM, called SMTI, where rankings may be incomplete (i.e., some partners are not acceptable) or may include ties (i.e., some partners are preferred equally). We investigate three hard variants of SMTI, that aim to compute optimal stable matchings with respect to different measures of fairness: Sex-Equal SMTI (maximizes the equality of satisfaction among sexes), Egalitarian SMTI (maximizes the total satisfaction of the preferences of all agents), and Max Cardinality SMTI (minimizes the number of singles). We introduce a suite of novel declarative methods to solve these hard variants of SMTI, using Answer Set Programming (ASP), Constraint Programming (CP), and Propositional Satisfiability (SAT). We empirically evaluate the scalability of methods over randomly generated instances, as the probability of incompleteness and probability of ties change. For Max Cardinality SMTI, we also compare these methods with the existing approaches based on Integer Linear Programming (ILP) and Local Search (including Hill-Climbing and Genetic Algorithms). We observe that the declarative methods (ASP, ILP, CP, SAT) are more promising compared to the local search algorithms as the problems get harder with more ties and incompleteness."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Siber saldırıların yaygınlaşması ve daha karmaşık hale gelmesiyle, izinsiz giriş tespiti sistemlerini tasarlamak giderek daha zor bir hale gelmektedir. Makine öğrenmesi tabanlı saldırı tespit sistemleri, izinsiz girişlerin hızlı, uyarlanabilir ve doğru tespiti için bir çözüm sunmaktadır. Ancak bu, sınıflandırıcıyı kimin değerlendirdiğine bağlı olarak, saldırı tespit sistemi sağlayıcısının ve kullanıcının, gizli ağ verilerini ve değerlendirme modelini paylaşmasını gerektirir. Sonuç olarak, her iki taraf için de bir gizlilik ihlali riski ortaya çıkar. Homomorfik şifreleme tekniği, şifrelenmiş verilerin bir şifre çözme anahtarı gerektirmeden işlenmesine izin vererek, bu tür gizlilik sorunlarının üstesinden gelmek için bir çözüm sunmaktadır. Bu tekniği kullanarak taraflar, değerlendirme için güvenilmeyen bir tarafla paylaşmadan önce bilgilerini şifreleyebilir. Bununla birlikte, homomorfik şifreleme tekniği maliyeti çok yüksek olabilecek işlemsel ek bir yüke yol açar. Bu nedenle asıl sınıflandırıcıların tespit yeteneklerinden ödün vermeden, toplam işlemlerin ve sınıflandırıcı devrelerin çarpma derinliğinin en aza indirilmesi hedeflenerek homomorfik sınıflandırıcılar tasarlanmaktadır. Bu tez, izinsiz ağa giriş tespiti için farklı makine öğrenme tabanlı sınıflandırıcıların performanslarını karşılaştırmakta ve ayrıca farklı şifreleme senaryolarını değerlendirmektedir. Farklı uygulamaların genel tespit doğruluğu, zamanlama performansı ve güvenlik endişeleri değerlendirilmekte ve tartışılmaktadır.","As cyberattacks have become more prevalent and sophisticated, designing and developing intrusion detection systems (IDS) has turned out to be an increasingly challenging task. Machine learning-based intrusion detection systems offer a solution for fast, adaptable and accurate detection of intrusion incidents. However, depending on who is evaluating the classifier, this requires the IDS provider and the user to share the confidential network data and the evaluation model, putting both parties at risk of privacy violations. The homomorphic encryption technique proposes a solution to overcome such privacy issues, by allowing manipulation of encrypted data without requiring a decryption key. Using this technique, the parties may encrypt their private input (e.g., network data or evaluation model) before sharing it with an untrusted party for evaluation. As the homomorphic encryption technique may impose a prohibitively high computational overhead, the homomorphically executed classifiers must be designed to retain the detection abilities of the actual classifiers while minimizing the total computation overhead and multiplicative depth of the circuit that implements the classifiers. This thesis compares the performance of different machine learning-based classifiers for network intrusion detection and also evaluates different encryption scenarios. The overall detection accuracy, time performance, and security and privacy concerns of different implementations are assessed and discussed."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hesaplama sistemleri çok kompleks ve çeşitli donanım ve yazılım bileşenlerinin bir araya gelmesiyle oluşur. Bu standart olmayan ortam, aynı girdi verisiyle en iyi ve en kötü tamamlama süreleri arasında %100'e kadar farka neden olabilir. Bunun yanı sıra, girdi verisi şekli ve çalıştırılan algoritmalar da bu eşitsizlikteki varyansı daha da artırır. Ancak, bu zorlukların yanısıra, söz konusu sistemler aynı zamanda çeşitli gözlemlenme yeteneklerine de sahiptir. Tipik bir Linux sistemi, hem donanımından hem de yazılım bileşenlerinden binlerce gerçek zamanlı çalışma ve performansla ilgili metrik raporlayabilir. Dijital İkizler, endüstriyel uygulamalarda geniş uygulama alanları bulmasına rağ- men, literatürde süper bilgisayar bağlamında araştırılmamış bir konsept olarak dur- maktadır. SuperTwin, çeşitli hesaplama ortamı ve performans verisi araçlarını otomatikleştirerek kullanan, bu araçların ve performans verilerinin bilgi temsil oluş- turucusu ve yöneticisidir. SuperTwin, detaylı bir taramayla bir hesaplama sistem- inin dijital ikizini oluşturup, performans metrik örnekleyicilerini yapılandırma ve dinleme, edinilen farklı tiplerdeki bilgiyi bağlantılı hale getirme kabiliyeti ile gerçek zamanlı görselleştirme ileri analiz için anlamlı sorgulara izin verir. Bu çalışmada, SuperTwin tasarım ve gerçeklemesi ayrıntılı olarak sunulmuş, per- formans ölçümü etkisinin hesaplama sistemlerine etkisi araştırılmış ve performans incelemelerinin tutarlılığı incelenmiştir.","Computational systems are extremely complex and the composition of their hard- ware and software components greatly vary from machine to machine. This non- standardized environment can cause up to 100% difference between the best and worst completion times with the same input data. On top of that, the shape of the input data and executed kernels add even more variance to the situation. However, computational systems are not completely hostile environments. These systems are also equipped with diverse observability capabilities. A typical Linux system can report thousands of real-time execution and performance-related metrics from both its hardware and software components. Digital Twins are knowledge management systems that have vast application areas in the industry, however, digital twins of computational systems remain a gap in the literature. SuperTwin is a knowledge representation generator and manager of the tools and performance data that interact with it. It creates a digital twin of a computational system via detailed probing, configures and listens to performance metric samplers, creates real-time visualizations, links the acquired information, and enables semantic queries for advanced analysis. In this work, design and implementation choices for SuperTwin are thoroughly pre- sented. The effect of profiling on remote systems is analyzed and the accuracy of the readings is investigated."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hata kaynağının tespiti endüstriyel ürünlerde önemli bir konudur. Buzdolapları ile ilgili olarak yapılan analizlere göre müşteri şikayetlerinin büyük çoğunluğunun gürültü tabanlı şikayetlerden kaynaklandığı belirlenmiştir. Bu nedenle, gürültü problemine neden olan kök kaynağın belirlenmesi ve hızlı bir şekilde düzeltilmesi çok önemlidir. Bu çalışmanın amacı, buzdolaplarında fan kaynaklı hataların ses sinyalleri kullanılarak tespit edilmesidir. Hataya neden olan kaynağın tespiti için uygulanan yöntemin veriye dayalı olması tercih edilmiş ve bu nedenle çalışmanın veriden öğrenen bir algoritma yardımıyla gerçekleştirilmesi hedeflenmiştir. Bu çalışma ve gelecek çalışmalarda kullanılmak üzere veri altyapısının güçlendirilmesi amacıyla kuvvetli ve detaylı veri seti oluşturulması da çalışmanın ikincil amacını oluşturmaktadır. Bu tezde, buzdolabına ait 3 fan kaynağından birinin hatalı olduğu ve hepsinin düzgün çalıştığı durumlarda, ISO 3745 uyumlu tam yansımasız ölçüm ortamında ses verileri toplanarak bir ses veri seti oluşturulmuştur. Ses sinyaline ait istatistiksel öznitelikler çıkarılarak eğitilen bir makine öğrenmesi modeli ile, ses sinyalinin görsel ifadesi olan mel spektrogramları kullanılarak eğitilen CNN (Evrişimsel Sinir Ağı) mimarisi bir arada kullanılarak bir topluluk sınıflandırma modeli önerilmiştir. Önerilen model, hatasız olma durumunu dahil etmediğimizde %93, hatasız olma durumunu da dahil ettiğimizde %89 oranında doğruluk değeri ile sınıflandırma yapar.","Detection of the source of the fault is an important issue in industrial products. According to the analyses regarding refrigerators, it has been determined that the majority of customer complaints are caused by noise-based complaints. Therefore, it is very important to identify the main source causing the noise problem and correct it as fast as possible. The aim of this thesis is to classify fan-related faults in refrigerators using sound signals. The method applied to diagnose the source causing the fault was preferred to be data-based, and for this reason, it was aimed to carry out the study with the help of a suitable algorithm that learns from the dataset. Creating a reliable and detailed dataset in order to improve the data infrastructure for use in this thesis and future studies is the secondary aim of the study. In this thesis, in the case of only one of the 3 fan sources of the refrigerator is faulty and all of them are working properly, a sound dataset is created by acquiring sound data in ISO 3745 compliant full anechoic measurement environment. An ensemble classification model is proposed by using a machine learning model trained by extracting the statistical features of the sound signal and a CNN (Convolutional Neural Network) architecture trained using mel spectrograms, which are the visual representation of the sound signal. The proposed model classifies with an accuracy of 93% when the non-faulty class is not included and 89% when the non-faulty class is included."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Adlandırılmış Varlık Tanıma (AVT), kişi ve konum adları gibi adlandırılmış varlıkları algılamayı ve sınıflandırmayı amaçlayan, bilgi çıkarımının temel görevlerinden birisidir. Bu görevin kullanım alanlarından bazılarına haberlerin kategorize edilmesi, metinlerin gizliliğin sağlanması için anonimleştirilmesi, tıp alanında elektronik sağlık kayıtlarından hastalık ve ilaçların tespit edilmesi örnek olarak verilebilir. Bununla birlikte, her alanın kendine ait zorlukları ve bilgi gereksinimleri vardır. AVT'deki zorlu alanlardan birisi, gürültülü doğası ve bağlam eksikliği nedeniyle sosyal medya verileridir. Ayrıca, kitap veya film başlıkları gibi belirsiz ve karmaşık varlıkları kapsayan yeni adlandırılmış varlık sınıflarının da bu alana dahil edilmesi görevi daha da zorlaştırmıştır. Bu sorunlar nedeniyle modeller, haber makaleleri gibi iyi yazılmış metinlere kıyasla sosyal medya verilerinde daha düşük performans göstermektedirler. Bu çalışmada, Vikipedi gibi bir bilgi tabanından gelen harici bilgileri denetimsiz bir şekilde dönüştürücü tabanlı bir modele entegre ederek modellerin özellikle karmaşık varlıklarda ve bağlam eksikliğinde performanslarını iyileştirmeyi amaçladık. Dış bağlamı seçmek ve BERT modeline eklemek için iki ayrı yöntem önerdik. İlk yaklaşımımızda, EL_BERT ve EL_MultiBERT adlı iki yöntemimiz ile Vikipedi'den olası adlandırılmış varlıkları bulmaya çalıştık ve tespit edebildiğimiz sayfalardan harici bilgi olarak yararlandık. Ancak Vikipedi'de adlandırılmış her varlığı tespit etmek her zaman mümkün olmadığı için ikinci yaklaşımımız olan EL_Semantic'te bağlamsal olarak daha yakın sayfaları vurgulayarak önceki yaklaşımımızı geliştirdik. EL_BERT ve EL_MultiBERT modellerimiz ile çok sayıda kısa örnek ve karmaşık varlıklar içeren MultiCoNER veri setinde dönüştürücü tabanlı modellere kıyasla önemli bir gelişme sağladık. Ayrıca, EL_Semantic yöntemimizde anlamsal olarak yakın içerikleri eklemeyerek, gürültülü metinlerden oluşan veri setlerinde BERTurk modelinden daha iyi performans elde etmeyi başardık. Öncelikle Türkçe AVT'deki sosyal medya veri setleri eski ve yetersiz olduğu için yeni bir Twitter veri seti oluşturduk. Dahası, mevcut sosyal medya veri kümeleri daha önce dönüştürücü tabanlı modellerle değerlendirilmediği için bu modellerin varyasyonlarını eğittik ve BiLSTM-CRF mimarisi ile bu veri setleri üzerinde karşılaştırdık. Daha sonra dönüştürücü tabanlı modellerin üzerlerine etiketler arasındaki ilişkileri yakalayarak performanslarını iyileştirmek için CRF ve BiLSTM katmanları uyguladık. BERT-CRF modeli, harici bilgi eklemeyi önerdiğimiz metodlardan daha iyi performans göstermiştir, ancak kısa örnekler ve karmaşık adlandırılmış varlıklarla dolu olan MultiCoNER veri setinde, yöntemimizle karşılaştırıldığında oldukça kötü bir sonuç elde etmiştir. BiLSTM katmanı eklemek ise hiçbir gelişme göstermemiş ve diğer dönüştürücü tabanlı yaklaşımların gerisinde kalmıştır.","Named Entity Recognition (NER) is a core component in extraction information that aims to detect and classify named entities, such as person and location names. Applications of this task include the detection of named entities in raw texts from various domains. Categorizing news articles, anonymizing texts to ensure privacy, and identifying diseases and drugs from electronic health records in the medical field are some of the usage areas of this task. However, each domain has its own challenges and knowledge requirements. One of the challenging domains in NER is social media because of its noisy nature and context deficiency. In addition, newly named entity classes are included in this domain, covering ambiguous and complex entities such as book or movie titles. Because of these issues, models perform poorly in this domain compared to well-written texts such as news articles. In this work, we aim to improve the performance of models, particularly in complex entities and lack of context, by integrating external information from a knowledge base, like Wikipedia, into a transformer-based model in an unsupervised manner. To select the external context and add it to the BERT model, we proposed two different methods. In the first approach, the two pipelines called EL_BERT and EL_MultiBERT attempted to find possible named entities on Wikipedia and utilized the pages they found as external information. Our second method, EL_Semantic, improved the previous approach by emphasizing the contextually closer pages since detecting every named entity in Wikipedia is not always possible. With EL_BERT and EL_MultiBERT, we achieved significant improvement on the MultiCoNER dataset, which contains many short samples and complex entities, compared to vanilla transformer-based models. Moreover, by incorporating semantically similar content in the EL_Semantic, we outperformed the BERTurk model on all datasets with noisy text. Since the social media datasets in Turkish NER are either old or insufficient, we first constructed a new Twitter dataset. Moreover, since the existing social media datasets have not been evaluated with transformer-based models, we trained variations of these models and compared them with BiLSTM-CRF architecture on social media datasets. We also implemented CRF and BiLSTM layers on top of transformer-based models to improve their performances by capturing relations among labels. The BERT-CRF model outperformed our pipelines with external knowledge, however, it performed poorly compared to our pipelines for the dataset full of short samples and complex entities, namely MultiCoNER. The BERT-BiLSTM-CRF model, on the other hand, performed poorly and lagged behind other transformer-based approaches."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Uzaydaki yüksek radyasyon seviyesi nedeniyle arızaya dayanıklı işlemciler uzay araçları için elzemdir. Gerekli güvenilirlik seviyesi radyasyona dayanıklı özel işlemciler tarafından sağlanabilir, ancak bu işlemcilerin maliyeti yüksektir. Küp uyduların yaygınlaşması ile birlikte, düşük maliyetli uzay araçlarında ticari kullanıma hazır komponentlerin kullanımı artmıştır. Hazır işlemci tasarımları, üçlü modüler yedekleme sayesinde radyasyona dayanıklı ASIC prosesleri ve FPGA'ler gibi maliyetli unsurlar kullanılmadan daha güvenilir hale getirilebilir. Bu tezde, açık kaynaklı PicoRV32 çekirdeğine kaba taneli TMR uygulayarak hataya dayanıklı konsept bir RISC-V işlemci tasarımı sunulmaktadır. Kaba taneli TMR uygulamasını gerçekleştirmek için, word oylayıcılar işlemcinin iç yapısında değişiklik yapılmadan bellek anayoluna bağlanmıştır. Geleneksel bit-by-bit oylayıcılar yernine word oylayıcıların kullanılması, birden çok modülde aynı anda gerçekleşebilecek hataları ortaya çıkartarak hata tanılama kapasitesini arttırmaktadır. Bunların yanında, yazılımın oluşan hatalardan haberdar olmasını sağlayan ve işlemcileri yeniden başlatabilen bir TMR kontrol modülü tasarlanmıştır. Bu modül yazılımın hata kurtarma prosedürlerini başlatmasına yardımcı olabilir. Son olarak sistemin sentez çıktıları, ince taneli TMR kullanan benzer uygulamalarla karşılaştırılmıştır. Ön sonuçlar, tasarlanan kaba taneli TMR mimarisinin, hazır IP bloklarının daha düşük geliştirme eforu sarf edilerek korunmasında kullanılabileceğini göstermektedir. Bu tasarımlar düşük bütçeli uzay uygulamaları için faydalı olabilir.","Fault-tolerant processors are essential for spacecraft because of the high-radiation environment of space. While the required reliability can be achieved by using specialized radiation-hardened processors, the cost is prohibitive. With the advent of CubeSats, low-cost spacecraft started to increasingly rely on non-radiation-hardened commercial-off-the-shelf components. Triple-modular redundancy can be applied to existing processor designs to increase reliability without using costly radiation-hardened ASIC processes or FPGAs. In this thesis, we demonstrate a conceptual fault-tolerant RISC-V processor by applying coarse-grain TMR to the open-source PicoRV32 core. To implement coarse-grain TMR, we attached word voters to the memory bus without modifying the internal structure of the processors. Using word voters increases error detection capability by revealing multi-module errors which can be masked by conventional bit-by-bit voters. Moreover, we propose a TMR controller module that can relay fault conditions to software and reset the CPUs. The module can help software to facilitate fault recovery procedures. Finally, we compare the synthesis results of our demonstration system with similar applications that use finer-grain TMR implementation. Our preliminary experiments show that the proposed coarse-grain TMR architecture can be used to protect ready-made IP cores with less development effort, which can be useful for low-cost space applications."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kimlik doğrulama ve kara liste mekanizmaları dijitaller kanallar üzerinde çalışan servis sağlayıcılarının doğru kullanıcılara hizmet ulaştırmasında anahtar bir rol sahibidir. Öte yandan, bir kullanıcı servis süresince mahrem verilerini açığa çıkarabilir ve kullanıcıyı gerçek hayattaki kimliğini ortaya çıkaran bir kimlik doğrulama/kara liste mekanizması bu verilerin kullanıcıyla ilişkilendirilmesine sebep olabilir. Bu nedenle, bu sistemlerde kullanıcı mahremiyeti üzerine kaygılar bulunmaktadır. Literatürdeki çalışmalar kullanıcılara koşulsuz gizlilik sağlayan sistemler önerse de bu şemalar kötü niyetli kullanıcıları kara listeye alma imkanı tanımaz. Koşullu gizlilik konsepti bu noktada çözüm olarak önerilmektedir. Koşullu gizlilik için literatürdeki önerilen konseptlerden biri kara listelenebilir gizli kimliklerdir. Bu şema servis sağlayıcıların kullanıcıyı bir kimlik doğrulama oturumu için kullanıcı hakkında bilgi edinmeden kara listeye almasına imkan sağlar. Bu tezde, koşullu gizli şemalardaki kullanıcı gizliliği iki mekanizma önererek geliştirilmektedir. İlk olarak kara listelenebilir gizli kimlikler için beyaz liste özelliği tanımlanmakta ve bu özelliğe sahip bir şema sağlanmaktadır. Beyaz liste özelliği bir kullanıcının dürüst davranış sergilediği bir kimlik doğrulama oturumuyla ilişkisini kaldırır. İkinci olarak, bu şemanın daha özel bir kullanım senaryosu olan paylaşım ekonomisi için bir uzantısı önerilmektedir. Bu şemada, bir servis sağlayıcısı bir kullanıcıyı yalnızca paylaşılan bir varlığı teslim zamanında getirmezse kara listeye alabilir. İki şemanın da performansı literatürdeki çalışmalarla karşılaştırılarak değerlendirilmiştir. Bu değerlendirmeler hesaplama ve iletişim maliyetleri açısından ilk şemanın literatürdeki çalışmalarla kıyaslanabilir performansa sahip olduğunu, ikinci şemanınsa daha avantajlı performansa sahip olduğunu göstermiştir.","Authentication and blacklisting mechanisms have a key role for service providers to deliver the service to correct users through digital channels. On the other hand, a user may reveal private data through the service, and an authentication/blacklisting mechanism that identifies the user may be used to link such private data to the user herself. Thus, there always have been concerns about privacy of the users. While there are previous works in the literature that provide unconditional anonymity to users, these schemes prevent service providers from blacklisting misbehaving users. At this point, the conditional anonymity concept is proposed as a remedy. A recent approach in the literature for conditional anonymity is blacklistable anonymous credentials, which allows service providers to blacklist users for an authentication session without identifying the user. In this thesis, we improve user anonymity in conditionally anonymous schemes using two complementary mechanisms. First, we define a property, whitelisting property, for blacklistable anonymous credentials and give a construction of this scheme. The whitelisting property can be used to unlink an honestly behaved authentication session from the user. Secondly, we propose an extension of this scheme for a more specific use case, sharing economy services. This scheme allows a service provider to blacklist a user only if the user have not returned the shared asset in due time. We benchmark the performance of our schemes by comparing them with the rival schemes. For communication and computation metrics, our experiments show that our first scheme has comparable performance to previous works, and our second scheme is advantageous compared to a rival one."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Uzaklık sorguları ağ analiz işlemlerinin önemli ve temel bir parçasıdır. Bu sorgular sosyal ağlarda kullanıcıların yakınlığının öğrenilmesi, internet üzerinde sitelerin ilişkilerinin karşılaştırılması, biyolojik ağlarda moleküllerin birbiriyle etkileşimlerinin incelenmesi gibi alanlarda kullanılabilir. Dolayısıyla, bu sorguların hızlı bir şekilde cevaplanabilmesi ağ analizi alanına genel olarak yarar sağlamaktadır. PLL (Pruned Landmark Labeling) adı verilen algoritma, bu sorguların çok daha kısa sürede cevaplanabilmesini sağlayan yer işaretleri oluşturmak için literatürde sıklıkla kullanılmaktadır. PSL (Parallel Shortest-distance Labeling) algoritması PLL tabanlı paralel hesaplama yapılabilen ortamlarda kullanılmak üzere tasarlanmış ve özellikle sosyal ağlarda kullanılan bir algoritmadır. Fakat PLL tabanlı algoritmaların hafıza karmaşıklığı oldukça fazladır. Örneğin, orta boyutlu çizgeler için bile oluşturulan yer işaretleri hafızada 300GB üzerinde yer kaplayabilmektedir. Bununla beraber, orta boyutlu çizgelerde, modern bir CPU çekirdeği ile yer işaretlerini oluşturmak için 12 günden uzun süre harcayabilmektedir. Bu tez PSL algoritmasının dağıtık bir ortamda uygulanmasının çizgenin bölünmesi ve dağıtılması aracılığı ile uygulanması üzerinedir. Bu teknik ile hem zaman, hem kullanılan hafıza açısından önemli kazanımlar sağlanmıştır. Ek olarak, bu tez, PSL algoritmasının performansının artırılmasına yönelik deney ve teknikler de içermektedir.","Distance queries are a fundamental part of many network analysis applications. Distances can be used to infer the closeness of two users in social networks, the relation between two websites in a web graph, or the importance of the interaction between two proteins or molecules. As a result, being able to answer these queries rapidly has many benefits to the area of network analysis as a whole. Pruned landmark labeling is a technique used to generate an index for a given graph that allows the shortest path queries to be completed in a fraction of the time when compared to a standard BFS (Breadth First Search) based algorithm. PSL (Parallel Shortest-distance Labeling) is a pruned landmark labeling algorithm that is designed to be implemented in a multithreaded environment and works particularly well on social networks. Unfortunately, even for a medium-size, 50 million vertex graph, the index size can be as large as 300GB. On the same graph, a single CPU core takes more than 12 days to generate the index. This thesis aims to implement PSL in a distributed environment by partitioning the input graph and distributing the partitions to the nodes. Our method can provide improvements in both the execution time and the memory consumption by distributing both across multiple nodes of a cluster. Furthermore, we develop techniques and conduct experiments that can help increase the performance of the PSL algorithm."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son zamanlarda, Nesnelerin İnterneti (IoT) endüstride olduğu kadar akademide de popüler bir araştırma alanı olmuştur. IoT teknolojisi, çeşitli uygulamalarla endüstride yaygın olarak kullanılmaktadır. Ev sahiplerinin cihazlarını uzaktan yönetmelerine yardımcı olan ev otomasyon sistemleri (HAS) bu uygulamalardan biridir. Ancak akıllı evler, ağ tabanlı saldırılara karşı güvenlik açısından zayıftır. Ev otomasyon sistemlerindeki bir diğer önemli tehdit ise ev sahiplerinin kişisel bilgilerinin sızdırılmasının mümkün olmasıdır. Bu tezde, ev otomasyon sistemleri için gizliliğe duyarlı bir anonim tanımlama ve kimlik doğrulama modeli önerilmektedir. Önerilen modelde, IoT cihazları ve dış kullanıcılar arasında güvenli bir iletişim platformu oluşturmak amacıyla yenilikçi bir ev ağ geçidi (IHG - Innovative Home Gateway) sunulmaktadır. Ayrıca, önerilen sistem, kullanıcıların kişisel bilgilerini korumayı amaçlayan sahte kanıtlar ile gizliliğe duyarlı hale getirilmiştir. Kullanıcıların gerçek kimliğinin gizlendiği Idemix tabanlı anonim ehliyet sistemi önerilen modele anonimlik sağlamaktadır. Modelin uygulamasının ayrıntıları ve yukarı yönlü ve aşağı yönlü iletişim senaryoları için yürütülen testlerin sonuçları sunulmaktadır. Sonuçlar, önerilen modelin ev otomasyon sistemleri için verimli ve ölçeklenebilir olduğunu göstermektedir.","Lately, the Internet of Things has been a popular research area within academia as well as in the industry. IoT technology has been widely adopted to industry with a variety of applications. Home automation systems (HAS) which helps \mbox{homeowners} to manage their devices remotely is one of these applications. However, smart homes are vulnerable to various network based attacks. Another important threat in HAS is that it is possible to leak private information of homeowners. In this thesis, we propose a privacy-aware anonymous identification and authentication model for HAS. In the proposed scheme, an innovative gateway is presented to build a secure intercommunication platform between IoT devices and the outside users. Besides, the proposed system is privacy-aware with the introduction of fake proofs which aims to protect users' private information. Anonymity is provided by the Idemix based anonymous credential system where the real identities of the users are \mbox{hidden}. We give implementation details and the results of conducted experiments with \mbox{downstream} and upstream traffic scenarios. Our results suggest that the proposed model is efficient and scalable for home automation systems."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Uzun kodlamayan RNA'lar (lncRNA'lar), kodlamayan RNA'ların (ncRNA'lar) en büyük sınıfıdır. Bununla birlikte, son deneysel kanıtlar, bazı lncRNA'ların, fonksiyonel mikropeptidlere çevrilen küçük açık okuma çerçeveleri (sORF'ler) içerdiğini göstermiştir. Yanlış yorumlanmış lncRNA'ları tespit etmek için mevcut yöntemler, pahalı ve hücre tipine bağlı olan ribozom profili oluşturma (ribo-seq) deneylerine dayanır. Ek olarak, kodlama yapan ve kodlamayan dizileri ayırt etmek için çok hassas makine öğrenimi modelleri eğitilmiş olsa da, temel eğitim veri kümelerinde bazı lncRNA'ların yanlış yer-gerçeği etiketleri hakkında artan kanıtlara çok az ilgi gösterilmiştir. Belirli bir lncRNA transkriptinin yanlış yorumlanıp işaretlenmediğini belirlemek için derin öğrenme modellerinin eğitim dinamiklerinden yararlanan bir çerçeve sunuyoruz. Modellerimiz, veri kümesinde bulunan olası yanlış yorumlanmış lncRNA'ları belirlememize izin verirken, kodlama yapmayan ve kodlama dizilerini sınıflandırmada AUC puanları >91% ve AUPR >93% elde eder. Sonuçlarımız, bir ribo-seq veri kümesi tarafından bulunan lncRNA'lar içindeki sORF'leri kodlamanın yanı sıra, deneysel olarak doğrulanmış yanlış yorumlanmış bir dizi lncRNA ile önemli ölçüde örtüşmektedir. Burada uygulanan genel çerçeve, potansiyel tahmin edicileri kodlamak için kullanılan veri kümelerinin küratörlüğünde kullanım için umut verici bir potansiyel sunar ve yanlış yorumlanmış lncRNA'lar tarafından kodlanan gizli proteomun karakterize edilmesinde deneysel çabalara yardımcı olur.","Long non-coding RNAs (lncRNAs) are the largest class of non-coding RNAs (ncRNAs). However, recent experimental evidence has shown that some lncRNAs contain small open reading frames (sORFs) that are translated into functional micropeptides. Current methods to detect misannotated lncRNAs rely on ribosome-profiling (ribo-seq) experiments, which are expensive and cell-type dependent. In addition, while very accurate machine learning models have been trained to distinguish between coding and non-coding sequences, little attention has been paid to the increasing evidence about the incorrect ground-truth labels of some lncRNAs in the underlying training datasets. We present a framework that leverages deep learning models' training dynamics to determine whether a given lncRNA transcript is misannotated. Our models achieve AUC scores >91% and AUPR >93% in classifying non-coding vs. coding sequences while allowing us to identify possible misannotated lncRNAs present in the dataset. Our results overlap significantly with a set of experimentally validated misannotated lncRNAs as well as with coding sORFs within lncRNAs found by a ribo-seq dataset. The general framework applied here offers promising potential for use in curating datasets used for training coding potential predictors and assisting experimental efforts in characterizing the hidden proteome encoded by misannotated lncRNAs."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Siber teknolojilerin hızlı gelişimi hayatımızı kolaylaştırdı. İnternet bankacılığı, e-ticaret ve sosyal medya gibi faaliyetler hayatımızın bir parçası olmaya başladı, ancak saldırganların yararlanabileceği daha fazla tehdit yüzeyi ortaya çıktı. Oltalama saldırıları, saldırganların en çok tercih ettiği ve en bilinen siber suçlardır birisidir. Saldırganlar, sosyal mühendislik teknikleri uygulayarak kurbanların kişisel bilgilerini oltalama web siteleri aracılığı ile ele geçirirler. Araştırmacılar, çeşitli yaklaşımlar kullanarak oltalama sitelerini tespit etmeye çalışıyorlar. Fakat, oltalama sitelerinin tespit edilmesinden sonra zararı en aza indirmek için gerekli olan bir diğer adım ise bu tür sitelerin mümkün olan en kısa sürede engellenmesidir. Bu çalışmada, Türkiye'deki oltalama sitelerini gerçek zamanlı olarak tespit etmek için hibrit Evrişimli Sinir Ağları+Çift Yönlü Uzun Kısa Süreli Bellek ve Rassal Orman sınıflandırıcıları kullandık, ardından tespit edilen oltalama sitelerini hedeflenen barındırma sağlayıcılarına bildirmenin etkisini Türkiye'deki Bilgisayar Acil Müdahale Ekibi, USOM ile karşılaştırdık. Ayrıca üç tane Türk İnternet Servis Sağlayacısının USOM'un kara listesinde görüntülenen oltalama tehdidine karşı engelleme sürelerini ölçtük. Çalışmamız, USOM'a kötüye kullanım bildirimleri göndermek ile barındırma sağlayıcılarına kötüye kullanım bildirimleri göndermek arasında istatistiksel olarak önemli bir fark olmadığını göstermektedir. Öte yandan, bir İnternet Servis Sağlayısının engelleme süresinin bir diğerinden daha yavaş olduğunu bulguladık.","The rapid development of cyber technologies has made our life easier. Activities such as online banking, e-commerce and, social media have started to become a part of our lives; however, more threat surface has also emerged for attackers to leverage due to them. Phishing attacks are one of the most preferred and well-known cybercrimes by attackers. Attackers use social engineering techniques to obtain victims' personal information through phishing websites. To remedy this, researchers, on the other hand, have been trying to detect phishing websites by using several approaches. However, after detecting a phishing website, a significant step is to remediate phishing websites as soon as possible to minimize the damage. In this study, we used hybrid CNN+BiLSTM and Random Forest classifiers to detect Turkish phishing websites in real-time. We measured the impact of notifying phishing websites to targeted hosting providers compared to Turkish CERT, USOM. Additionally, we measured phishing website blocking time for three Turkish ISPs. Our work shows no statistically significant difference between sending abuse notifications to USOM and sending abuse notifications to hosting providers. On the other hand, we found that one ISP's blocking time is slower than another."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nesnelerin İnterneti (ing. IoT) cihazlarının yaygın olarak kullanılmaya başlanması ve donanımsal kısıtlara sahip olmaları, saldırganlar tarafından kolay hedef haline gelmerine sebep olmaktadır. Bu yüzden, güvenlik mekanizmalarının daha az uygulanabildiği bu sistemlerin, saldırı tespit sistemleri kullanılarak izlenmesi ve saldırılara karşı doğru zamanda gerekli adımların atılması büyük önem arz etmektedir. Saldırı tespit sistemleri, bilgisayar ağlarını sürekli olarak gözlemleyerek herhangi bir güvenlik kazası durumunda ilgili raporların sistem yöneticilerine iletilmesini sağlar. Bu alanda yapılan son çalışmalara bakıldığında, makine öğrenimi tabanlı sistemlerin saldırı tespit etmede oldukça başarılı olduğu gözlemlenmiş, farklı protokol ve saldırı tipleriyle çeşitli çalışmalar gerçekleştirildiği görülmüştür. Ancak, önerilen modellerin çoğu simülasyon verileri ya da geçerliliğini yitirmiş IoT saldırı ve zafiyetlerini içeren veri setleri kullanılarak geliştirilmiştir. Ayrıca, bu çalışmaların saldırı çeşitliliği nispeten düşük olmakla birlikte, birden çok saldırıyı zararsız trafikle beraber sınıflandırabilen çok sınıflı sınıflandırıcılar yerine çoklu saldırı senaryoları için ölçeklendirilebilir olmayan ve sadece tek tip saldırıyı zararsız trafikten ayırt edebilen ikili sınıflandırma modelleri önerilmiştir. Bu tezde, 6LoWPAN ve RPL protokolleriyle çalışan IoT cihazlarından elde edilen trafik verileriyle bir saldırı veri seti oluşturulmuş ve veri setinin içerdiği 6 saldırı tipini zararsız trafikle birlikte sınıflandırabilen bir makine öğrenimi tabanlı çok sınıflı sınıflandırıcı önerilmiştir. Veri setini oluştururken, RPL yönlendirme (ing. routing) saldırılarına ek olarak IoT cihazlarını sıkça hedef alan Mirai botnet saldırısı da kullanılmıştır. Bunun yanında, önerilen cihaz bazlı öznitelik çıkarma ve saldırı tespit etme yöntemi sayesinde her cihazın trafik özellikleri kayan bir zaman penceresi üzerinde modellenebilmekte, bu sayede de saldırgan cihazların konumları tespit edilebilmektedir. Sonuçlara göre, önerilen saldırı tespit sistemi 6 saldırı tipini %79 ile %100 arasında değişen duyarlılık skorlarıyla başarılı bir şekilde tespit edebilmektedir.","Wide adoption of Internet of Things (IoT) devices and their limitations in terms of hardware causes them to be easy targets for attackers. Therefore, it is important to monitor these systems, where security mechanisms are less applicable, by using intrusion detection systems, and take the necessary actions against insider and outsider attackers promptly. Intrusion detection systems monitor computer networks continuously and ensure that relevant reports are forwarded to the system administrators in case of a security incident. Recent studies have explored that machine learning based intrusion detection systems are quite successful in detecting different types of attacks. However, most of the models proposed in the literature were developed using simulation based or previously published testbed data that contain the samples of outdated IoT attacks and vulnerabilities. Furthermore, the variety of the attacks aimed to be detected are relatively low and the proposed models are binary classifiers which are not scalable for multi-attack scenarios. Binary classifiers can distinguish an attack type from benign traffic in contrast to multi-class classifiers, which can classify different types of attacks together with benign traffic. In this thesis, we propose a machine learning based multi-class classifier that can classify 6 attack types together with the benign traffic. Our node based feature extraction and detection methodology allows to pinpoint the exact locations of the attackers by modelling their traffic characteristics over a sliding time window. For training and testing our models, we also propose an intrusion detection dataset generated using the traffic data collected from real IoT devices working over the 6LoWPAN and RPL protocols. Besides having RPL routing attacks in the dataset, we leverage Mirai botnet, used frequently to target IoT devices. The results show that the proposed intrusion detection system can detect 6 attack types with high recall scores ranging from 79% to 100%."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dünyanın süregelen dijitalleşmesi ile her saniye çok büyük miktarlarda veri üretilmektedir. Bu nedenle, kullanıcılara ilgili öğeleri önermek, birçok sistemde daha da önemli bir görev haline gelmiştir. Bu amaçla, öneri sistemlerinde altta yatan kullanıcı ilgilerini anlamak için işlem veri setlerinden yararlanılabilir. Yaygın olarak kullanılan öneri sistemleri, kullanıcıların geçmiş etkinliklerine dayalı bir kullanıcı öğe matrisinden faydalanan işbirlikçi filtrelemeye dayalı yaklaşımları benimsemektedir. Ancak bu yöntemler seyreklik ve ölçeklenebilirlik sorunları yaşayabilirler. Bu tezde, işlem veri setleri için grafik temsili öğrenme algoritmalarını ve gradyan artırıcı sınıflandırıcıları birleştiren, bağlantı tahmini tabanlı bir öneri sistemi, ölçeklenebilir bir çözüm olarak önerilmiştir. Önerilen sistem, düğümlerin kullanıcılara ve öğelere karşılık geldiği, bağlantıların aralarındaki etkileşimleri temsil ettiği bir ağ oluşturur. Bir kredi kartı işlem veri seti üzerinde, kullanıcıların bir sonraki ay içerisinde alışveriş yapabilecekleri işyerlerini tahmin eden bir üye işyeri tahmin görevi, bir kullanım senaryosu olarak bağlantı tahmini bağlamında incelenmiştir. Yaygın olarak kullanılan ağ gömme çıkarımı teknikleri ve sınıflandırıcı modellerinin performansları, deneyler yapılarak değerlendirilmiş ve bu değerlendirmelere dayalı olarak önerilen sistem oluşturulmuştur. Önerilen model ile matris çarpanlarına ayırma tabanlı alternatif bir ölçeklenebilir öneri yöntemi karşılaştırılmıştır. Önerilen yöntem, alıcı çalışma karakteristik eğrileri, eğri altında kalan alan ve ortalama kesinlik değerlerinin ortalaması metrikleri açısından alternatif yönteme göre daha üstün bir performans göstermiştir.","With the continuous digitalization of the world, massive amounts of data are produced every second. Therefore, recommending relevant items to users has become a more important task in many systems. For this purpose, transaction data sets can be exploited in recommendation systems to understand underlying user interests. Commonly used recommendation systems adopt collaborative filtering based approaches that utilize a user-item matrix based on users' past activity. However, these methods may suffer from sparsity and scalability issues. In this thesis, a link prediction based recommendation system combining graph representation learning algorithms and gradient boosting classifiers for transaction data sets is proposed as a scalable solution. Proposed system generates a network where nodes correspond to users and items, and links represent the interactions between them. A use case scenario is examined on a credit card transaction data set as a merchant prediction task which is predicting the merchants where users can make purchases in the next month, in a link prediction context. Performances of common network embedding extraction techniques and classifier models are evaluated by conducted experiments, and based on these evaluations; the proposed system is constituted. A matrix factorization based alternative scalable recommendation method is compared with the proposed model. Proposed method has shown a superior performance than alternative method in terms of receiver operating characteristic curves, area under the curve, and mean average precision metrics."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Önermiş olduğumuz Tümleşik Kombinezon Etkileşim Sınama (T-KES) yöntemi, mevcut Kombinezon Etkileşim Sınama (KES) yöntemleri ile verimli ve etkili bir şekilde çözülemeyen KES problemleri için özel hesaplama yöntemleri geliştirme gerekliliğini ortadan kaldırarak, KES'in esnekliğini arttırmayı amaçlamaktadır. T-KES kapsanması gereken test edilebilen isterleri ve test havuzunun (yani T-KES objesinin) oluşturulacağı test durumları uzayını kısıt olarak ifade etmektedir. Böylece bir T-KES objesi oluşturma problemi (yani, belirli bir kapsama kriteri altında tam kapsama elde eden test durumları kümesi) bizim cov-CSP olarak adlandırdığımız ilginç bir kısıt çözme problemine dönüşmektedir. cov-CSP kapsanması gereken her isteri temsil eden kısıtları minimum sayıda kümelere bölmeyi hedeflemektedir. Öyle ki, bu kümelerin her birisi daha sonra bir test durumunu ifade edecek olup, üretilen tüm bu test durumlarından (her kısıt kümesi için bir tane) oluşan test havuzu ise T-KES objesini oluşturmaktadır. Böylece T-KES objesi her isterin en azından bir test durumu tarafından kapsandığını garanti etmektedir. Tez kapsamında, cov-csp problemini çözmek ve dolayısıyla T-KES objelerini üretebilmek için iki tane hesaplama yöntemi önerilmektedir. Bu hesaplama yöntemlerinden biri, bir test durumu oluşturulmadan önce bir kümede mümkün olduğunca çok fazla isteri kapsamaya çalışırken, diğer yöntem ise önce bir test durumu oluşturur ve ardından bu test durumunun kapsadığı tüm isterleri kapsanmış olarak işaretlemektedir. Akabinde, bu hesaplama yöntemleri kullanılarak her biri farklı KES problemini çözmeye çalışan 3 farklı çalışmada T-KES yaklaşımı test edilmiştir. İlk çalışmada, karar kapsaması tabanlı yapısal T-KES objeleri üretilmiştir. İkinci çalışmada, çizge tabanlı modellerin getirdiği erişilebilirlik kısıtlarını dikkate alarak bir takım sıralama tabanlı kapsama kriteri geliştirilmiş ve bu kapsama kriterleri ile sıralama tabanlı T-KES objeleri üretilmiştir. Üçüncü çalışmada ise, standart kapsayan dizilerin çok sayıda test durumları üretmesinden ötürü kullanılamadıklarından, sahadan toplanan kullanım istatistiklerine göre kapsanması gereken isterler seçilerek kullanıma dayalı T-KES objeleri geliştirilmiştir. Sonrasında, yeni önerdiğimiz ipucu kavramının T-KES'in etkinliğini daha da arttırdığını göstermek adına bir takım deneysel çalışmalar yapılmıştır. Son olarak T-KES'i daha ileri düzeyde değerlendirebilmek için saha çalışmaları da yapılmıştır. Bu çalışmaların sonuçları, T-KES'in mevcut KES yaklaşımlarından daha esnek olduğunu göstermektedir.","We present Unified Combinatorial Interaction Testing (U-CIT), which aims to improve the flexibility of combinatorial interaction testing (CIT) by eliminating the necessity of developing specialized constructors for CIT problems that cannot be efficiently and effectively addressed by the existing CIT constructors. U-CIT expresses the entities to be covered and the space of valid test cases, from which the samples are drawn to obtain full coverage, as constraints. Computing a U-CIT object (i.e., a set of test cases obtaining full coverage under a given coverage criterion) then turns into an interesting constraint solving problem, which we call cov-CSP. cov-CSP aims to divide the constraints, each representing an entity to be covered, into a minimum number of satisfiable clusters, such that a solution for a cluster represents a test case and the collection of all the test cases generated (one per cluster) constitutes a U-CIT object, covering each required entity at least once. To solve the cov-CSP problem, thus to compute U-CIT objects, we first present two constructors. One of these constructors attempts to cover as many entities as possible in a cluster before generating a test case, whereas the other constructor generates a test case first and then marks all the entities accommodated by this test case as covered. We then use these constructors to evaluate U-CIT in three studies, each of which addresses a different CIT problem. In the first study, we develop structure-based U-CIT objects to obtain decision coverage-adequate test suites. In the second study, we develop order-based U-CIT objects, which enhance a number of existing order-based coverage criteria by taking the reachability constraints imposed by graph-based models directly into account when computing interaction test suites. In the third study, we develop usage-based U-CIT objects to address the scenarios, in which standard covering arrays are not desirable due to their sizes, by choosing the entities to be covered based on their usage statistics collected from the field. Then, we empirically demonstrated that the performance (i.e., the construction times) of U-CIT constructors can be significantly improved by using hints. We also carry out user studies to further evaluate U-CIT. The results of these studies suggest that U-CIT is more flexible than the existing CIT approaches."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda bal arısı tozlaşma hizmetlerine olan bağımlılığımız arttı, ancak arı sağlığı küresel ölçekte düşüyor. Arı sağlığındaki düşüş, karmaşık çok faktörlü bir sorundur ve bir dizi etkileşimli stres etkeninden kaynaklanır. Stresörler temel olarak pestisit maruziyetinden, paraziter enfeksiyonlardan, yetersiz beslenmeden ve yiyecek arama habitatının kaybından kaynaklanmaktadır. Bununla birlikte, bu stres etkenlerinin arı sağlığında sinerjik bir düşüş meydana getirmek için tam olarak nasıl etkileşime girdiği belirsizliğini koruyor çünkü önceki çalışmalar, laboratuvarda geleneksel deneysel testler kullanılarak aynı anda bir veya iki stres etkenine odaklanmıştı. Burada, hipotez dışı veri odaklı bir analiz olan bir sistem biyolojisi yaklaşımı kullanıyoruz. Arı sağlığındaki düşüşten sorumlu spesifik etkileşimleri belirlemek için kırsal alanlardan kentsel alanlara örneklenen 87 bal arısı kovanının açıklayıcı profilini en yaygın 20 arı hastalığının bolluk veri setleriyle bütünleştiriyoruz. Bu analizden, bir kovanın enfekte olup olmadığını tahmin edebilen arı hastalıklarının 13'ü için kimyasal biyobelirteç kütüphaneleri geliştirdik. Biyobelirteç kitaplıkları, kimyasal biyobelirteç kitaplıklarımızın bir kovana belirli bir hastalık bulaşıp bulaşmadığını kabaca %85 doğruluk, kesinlik, duyarlılık, seçicilik ve geri çağırma ile tahmin edebildiğini tutarlı bir şekilde gösteren beş farklı makine öğrenme tekniği kullanılarak doğrulandı. Ek olarak, entegre veri setleri arasında bir ağ analizi kullanarak, arı hastalıkları boyunca, bal arısının birden fazla enfeksiyona duyarlılığının artmasından sorumlu olan veya nasıl olduğunu açıklayabilen potansiyel hedefler olduğundan şüphelenilen beş metabolit merkezi olduğunu bulduk. çoklu enfeksiyonlar, mekanik olarak arı sağlığında sinerjik bir düşüşe yol açar. Ayrıca, arı hastalıkları ile ilişkili ve detoksifikasyon ve oksidatif stres tepki genleriyle bağlantılı, insanlar için oldukça toksik olan bir dizi çevresel kirletici belirledik. Bulgularımız, arıların sadece insan sağlığı için çevre kalitesini izlemek için bir biyoindikatör veya gözcü olarak kullanılabileceğini değil, aynı zamanda bal arılarına maruz kalmanın da onların sağlığına zarar verme olasılığının yüksek olduğunu göstermektedir. Kirli ortamlardan kaynaklanan bu çevresel maruziyetler, muhtemelen arı sağlığını olumsuz etkileyen başka bir stres faktörüdür ve bunların etkileri, arı sağlığındaki en son düşüşte henüz tam olarak anlaşılmamıştır. Sistem biyolojisi analizinden, olası bir hızlı teşhis aracı olarak kullanılabilecek kimyasal biyobelirteçler sağlıyoruz, öyle ki arıcılar, koloni parazit enfeksiyonlarından çökmeden önce bal arısı sağlığını iyileştirmek için yönetim uygulamalarını değiştirebilirler. Arı sağlığını muhtemelen olumsuz yönde etkileyen yeni stres faktörleri tanımlanmıştır ve bunlar, bal arısı kovanındaki hastalık prevalansındaki artışla bağlantılı çok sayıda maruziyetle etkileşime girer. Toplu olarak, bulgularımız, Tek Sağlık paradigmasının, azalan arı sağlığının karmaşıklığını ele almak ve ilerlemeyi iyileştirmek için muhtemelen en etkili strateji olduğu fikrini desteklemektedir.","In recent years, we have increased on our reliance upon honey bee pollination services yet bee health has been declining on a global scale. The decline in bee health is a complex multifactorial problem and it is caused by a number of interacting stressors. The stressors are mainly stemming from pesticide exposure, parasitic infections, poor nutrition, and loss of foraging habitat. However, how these stressors exactly interact to produce a synergistic decline in bee health remains elusive because previous studies have mainly focused on one or two stressors at a time using traditional experimental testing in the laboratory. Here we utilize a systems biology approach that is a non-hypothesis data driven analysis. We integrate the exposome profile of 87 honey bee hives, sampled from rural to urban areas, with the abundance datasets of the 20 most common bee diseases to determine the specific interactions responsible for a decline in bee health. From this analysis, we have developed chemical biomarker libraries for 13 of the bee diseases that are able to predict whether a hive is infected or not. The biomarker libraries were validated using five different machine learning techniques that consistently demonstrated our chemical biomarker libraries can predict whether a hive is infected with a particular disease or not with roughly 85% accuracy, precision, sensitivity, selectivity, and recall. In addition, using a network analysis across the integrated datasets, we found that across the bee diseases there are five metabolite hubs that are suspected to be potential targets that are responsible for an increase in susceptibility of the honey bee to multiple infections or can explain how multiple infections lead to a synergistic decline in bee health mechanistically. Moreover, we identified a number of environmental pollutants that are highly toxic to humans, which are also associated with bee diseases and are linked to detoxification and oxidative stress response genes. Our findings suggest that not only can bees be used a bioindicators or sentinels for monitoring environmental quality for human health, but the exposures themselves to the honey bees are likely to be a detriment to their health as well. These environmental exposures from polluted environments are likely another stressor that is negatively impacting bee health and their implications have yet to be fully recognized in the most recent decline in bee health. From the systems biology analysis we provide chemical biomarkers that can be used as a possible rapid diagnostic tool such that beekeepers can change management practices to improve honey bee health before the colony collapses from parasitic infections. Novel stressors have been identified that are likely negatively impacting bee health and these are interacting with a multitude of exposures that are linked to an increase in disease prevalence in the honey bee hive. Collectively, our findings support the notion that the One Health paradigm is likely to be the most effective strategy for addressing the complexity of declining bee health and for improving it moving forward."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda bal arısı tozlaşma hizmetlerine olan bağımlılığımız arttı, ancak arı sağlığı küresel ölçekte düşüyor. Arı sağlığındaki düşüş, karmaşık çok faktörlü bir sorundur ve bir dizi etkileşimli stres etkeninden kaynaklanır. Stresörler temel olarak pestisit maruziyetinden, paraziter enfeksiyonlardan, yetersiz beslenmeden ve yiyecek arama habitatının kaybından kaynaklanmaktadır. Bununla birlikte, bu stres etkenlerinin arı sağlığında sinerjik bir düşüş meydana getirmek için tam olarak nasıl etkileşime girdiği belirsizliğini koruyor çünkü önceki çalışmalar, laboratuvarda geleneksel deneysel testler kullanılarak aynı anda bir veya iki stres etkenine odaklanmıştı. Burada, hipotez dışı veri odaklı bir analiz olan bir sistem biyolojisi yaklaşımı kullanıyoruz. Arı sağlığındaki düşüşten sorumlu spesifik etkileşimleri belirlemek için kırsal alanlardan kentsel alanlara örneklenen 87 bal arısı kovanının açıklayıcı profilini en yaygın 20 arı hastalığının bolluk veri setleriyle bütünleştiriyoruz. Bu analizden, bir kovanın enfekte olup olmadığını tahmin edebilen arı hastalıklarının 13'ü için kimyasal biyobelirteç kütüphaneleri geliştirdik. Biyobelirteç kitaplıkları, kimyasal biyobelirteç kitaplıklarımızın bir kovana belirli bir hastalık bulaşıp bulaşmadığını kabaca %85 doğruluk, kesinlik, duyarlılık, seçicilik ve geri çağırma ile tahmin edebildiğini tutarlı bir şekilde gösteren beş farklı makine öğrenme tekniği kullanılarak doğrulandı. Ek olarak, entegre veri setleri arasında bir ağ analizi kullanarak, arı hastalıkları boyunca, bal arısının birden fazla enfeksiyona duyarlılığının artmasından sorumlu olan veya nasıl olduğunu açıklayabilen potansiyel hedefler olduğundan şüphelenilen beş metabolit merkezi olduğunu bulduk. çoklu enfeksiyonlar, mekanik olarak arı sağlığında sinerjik bir düşüşe yol açar. Ayrıca, arı hastalıkları ile ilişkili ve detoksifikasyon ve oksidatif stres tepki genleriyle bağlantılı, insanlar için oldukça toksik olan bir dizi çevresel kirletici belirledik. Bulgularımız, arıların sadece insan sağlığı için çevre kalitesini izlemek için bir biyoindikatör veya gözcü olarak kullanılabileceğini değil, aynı zamanda bal arılarına maruz kalmanın da onların sağlığına zarar verme olasılığının yüksek olduğunu göstermektedir. Kirli ortamlardan kaynaklanan bu çevresel maruziyetler, muhtemelen arı sağlığını olumsuz etkileyen başka bir stres faktörüdür ve bunların etkileri, arı sağlığındaki en son düşüşte henüz tam olarak anlaşılmamıştır. Sistem biyolojisi analizinden, olası bir hızlı teşhis aracı olarak kullanılabilecek kimyasal biyobelirteçler sağlıyoruz, öyle ki arıcılar, koloni parazit enfeksiyonlarından çökmeden önce bal arısı sağlığını iyileştirmek için yönetim uygulamalarını değiştirebilirler. Arı sağlığını muhtemelen olumsuz yönde etkileyen yeni stres faktörleri tanımlanmıştır ve bunlar, bal arısı kovanındaki hastalık prevalansındaki artışla bağlantılı çok sayıda maruziyetle etkileşime girer. Toplu olarak, bulgularımız, Tek Sağlık paradigmasının, azalan arı sağlığının karmaşıklığını ele almak ve ilerlemeyi iyileştirmek için muhtemelen en etkili strateji olduğu fikrini desteklemektedir.","An enormous collection of documents is digitally available in text, images, and other representations for cultural heritage (CH). The availability of such extensive data creates a need for various approaches that allow users and archivists to understand latent relationships in collections. However, one of the biggest challenges of documents in cultural heritage is that it takes a long time and is difficult for archivists to analyze and process documents. Due to this manual process, there may be situations where the person, place, and events mentioned in these documents are not expressed in the same linguistic terms and words, or they contain ambiguous concepts that make it difficult to understand; as a result, it is challenging to uncover these relationships without careful examination by a professional. Therefore, there is a need for an archivist who will re-analyze these terms to capture similar events, persons, and places between the documents and thus reveal the latent relationship. To fill this gap, we proposed a system that combines various NLP algorithms and graph representation learning methods using only the textual summary of the documents and the documents' metadata. The system automatically extracts substantial terms in the documents, then produces embedding for the documents themselves and these terms. Finally, the proposed system has been used to explore the document collection and perform document recommendations by utilizing calculated document embeddings. We evaluated and compared the performance of the proposed work with alternative methods through an experiment we conducted with archive experts."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Etki Eniyileme (EE), bir sosyal ağda etkisinin bir yayılma modeline göre maksimum erişilebilirliğe ulaştığı bir düğüm alt kümesi bulma problemidir. Çözümün NP-Zorolması nedeniyle, bu problem için genellikle açgözlü yaklaşım algoritmaları uygulanır. Düzensiz bellek erişim kalıpları ve sorunun olasılıksal doğası, onu zorlu ancaködüllendirici bir optimizasyon hedefi haline getirmektedir.Bu tez, üç yüksek performanslı EE yöntemi önermekte ve gerçekleme için perfor-mans değerlendirmelerini araştırmaktadır; ilk olarak, özüt tabanlı, yön bağımsız rasgele sayı üreteci ve örneklem birleştirme kullanarak, yönlemdirilmemiş bağları örnekleyen bir EE algoritması olan InFuseR-MG'yi öneriyoruz. İkinci olarak, yönlendirilmiş ağlar için, büyük erişilebilirlik kümelerinin boyutlarımı tahmin etmekiçin değiştirilmiş Flajolet-Martin eskizleri kullanan bir EE yönetemi olan Hyper-FuseR'ı anlatacağız. Son olarak, akıllı örneklem-uzay bölümlenmesi ile birden fazla Grafik İşleme Ünitesi kullanmak için özel olarak tasarlanmış, eskiz tabanlı bir EE algoritması olan SuperFuseR önerilmiştir. Bu tezde algoritmaların her adımının performans değerlendirmeleri de tartışılmakta ve önerilen algoritmaların yüksek performanslı gerçeklemeleri de verilmektedir. Her algoritma için, literatürdeki en iyi yöntemler ile performans, kalite ve ölçeklemekarşılaştırmaları da dahil olmak üzere ayrıntılı deney sonuçları bulunmaktadır.","Influence Maximization (IM) is the problem of finding a subset of vertices in a social network whose influence reaches the maximum reachability according to a diffusion model. Due to the NP-Hardness of the solution, often, greedy approximation algorithms are applied. However, irregular memory access patterns and the probabilistic nature of the problem make it a challenging yet rewarding optimization target. This thesis proposes three high-performance IM methods and explores their performance considerations for implementation; first, we propose InFuseR-MG, an IM algorithm that uses a hash-based, direction-oblivious pseudo-random number generator and fused sampling to sample edges in undirected networks. Second, we propose HyperFuseR for directed, generic networks; HyperFuseR uses modified Flajolet-Martin sketches to estimate the cardinality of large reachability sets efficiently. Finally, we propose SuperFuseR, a sketch-based IM algorithm that is specifically designed for the multi-GPU setting. SuperFuseR uses a sampling-aware sample-space split mechanism to distribute the graph to multiple devices. Also in this work, we discuss performance considerations at each step of the proposed algorithms and provide their high-performance implementations. For each algorithm, we provide detailed experimental results, including performance, quality, and scaling benchmarks"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Siber saldırıların sayısı ve doğal olarak bu saldırılardan etkilenen insanların sayısı her geçen gün artmaktadır. Bu nedenle şirketler ve kullanıcılar siber saldırılar sonucu oluşabilecek kayıp ve hasarı en aza indirgemek ve önlem alabilmek amacıyla bu saldırılardan olabildiğince çabuk bir şekilde haberdar olmaları gerekir. Bu tezde, siber saldırılardan Twitter paylaşımları kullanılarak haberdar olabilmek için bir çerçeve çalışma sunulmuştur. Bu çerçeve çalışma, tweet sınıflandırması ve bilgi çıkarımı olmak üzere iki ana görevden oluşmaktadır. Bu görevler için derin öğrenme modelleri olan dönüştürücülerden (BERT ve RoBERTa) faydalanılmıştır. Sınıflandırma görevi için SUCyber ismi verilen, varlık ismi tanıma görevi için ise SUCyberNER ismi verilen iki yeni veri seti oluşturulmuştur. Ayrıca başka bir çalışmanın veri seti de sınıflandırma modellerini değerlendirmek amacıyla kullanılmıştır. Sunmuş olduğumuz modelin tweet sınıflandırma performansı iki farklı veri seti üzerinde ortalama %90.1 F1-Skoru olarak ölçülmüştür. Ayrıca, varlık ismi tanıma görevi için sunmuş olduğumuz model seçilen etkiket için %92.29 F1-Skoru vermiştir. Tüm bunlara ek olarak, gerçek zamanlı olarak tweet toplayıp geliştirilen model ile analiz eden ve yayınlayan bir websitesi de hayata geçirilmiştir. Sonuç olarak bu çalışma bize tweetler kullanılarak devam eden siber saldırıların belirlenebileceğini göstermiştir.","The number of cyber attacks increases every day, so the number of people affected by these attacks is also increasing. For this reason, companies and users need to be aware of the attacks as fast as possible to take precautions and to minimize the loss and effects caused by the attacks. In this thesis, a framework is proposed to detect cyber attacks from Twitter so that entities can act accordingly. The framework consists of two main tasks: tweet classification and information extraction. Two different deep learning based transformers, namely BERT and RoBERTa, are used for our tasks. Two new datasets, one is for binary classification named SUCyber, and the other is for named entity recognition named SUCyberNER, are created. Moreover, an additional dataset from another work is used to evaluate the approaches for the classification. The model that we propose for tweet classification yields average F1-score of 90.1% on two different datasets. Also, the NER model achieves F1-score of 92.29% for the selected tag. In addition, the proposed model has been incorporated into a website that collects and analyzes tweets in real-time to identify DDoS attacks. Finally, this study shows that tweets can be a good source of information to identify ongoing cyber attacks."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"21. yüzyılın küreselleşen dünyası, birçok çeşitli göç hareketlerine ev sahipliği yap-maktadır. Göçün etkileri ekonomik sonuçlardan farklı toplulukların sosyal ente-grasyonuna kadar çeşitlilik gösterdiğinden, bu hareketleri ve bu hareketlere nedenolan koşulları anlamak çok önemlidir. Bu nedenle, bu olguya veriye dayalı çalış-malarla yaklaşmak yaygındır. Birçok çalışma, göç hareketlerini ve bunların de-mografik ve sosyo-ekonomik etkenlerini incelemek için istatistiksel ve idari veri kay-naklarını kullanır. Ancak, mevcut veri kaynaklarında farklı göç tanımları ve veritoplama dönemleri arasındaki boşluklar gibi faktörler, veriye dayalı çalışmalarınbaşarısını sınırlandırmaktadır. Bu sorunları ele almak için, son çalışmalar yenilikçibüyük veri kaynaklarını kullanmaktadır. Bu tezde, çeşitli göç tanımları için yeni-likçi veri kaynaklarıyla iki farklı çalışma öneriyoruz. İlk çalışma, özel bir bankanınmüşterilerinin kredi kartı harcama veri seti üzerinde oluşturulmuştur. Bu coğrafikonumlu işlemler, Türkiye'deki olası iç göç hareketlerini anlamak için kullanılmak-tadır. İkinci çalışma, küresel göç modellerinin daha iyi anlaşılmasına katkıda bu-lunmak için Facebook'tan elde edilen verileri kullanır. Facebook'tan elde edilen veriseti, uluslararası kuruluşlardan gelen göç stok veri setleri ile görsel bir keşif aracındabirleştirilmiştir. Bu şekilde görsel araç, kullanılan yenilikçi veri kaynağının doğru-lanabileceği bir ortam yaratmaktadır. Araç ayrıca, işlemsel veri kaynağıyla vakaçalışmasının sonuçlarını görselleştirmek için de kullanılmıştır. Kullanılan yenilikçiveri kaynaklarının avantajları ve eksiklikleri kapsamlı bir şekilde tartışılmıştır.","The globalized world of the 21st century hosts various types of migration movementsas a common phenomenon. Understanding these movements and the conditions thatcause these movements is crucial as the effects of migration range from economicoutcomes to the social integration of different communities. Because of this, itis common to approach this phenomenon with data-driven studies. Many studiesutilize statistical and administrative data sources to study migration patterns andtheir demographic and socio-economic drivers. However, factors such as varyingdefinitions of migration in available data sources and gaps between data collectionperiods limit the success of data-driven studies. To address these, recent studies uti-lize innovative big data sources. In this thesis, we propose two different studies withinnovative data sources for various definitions of migration. The first study adoptsa transactional data source of credit card expenditures of customers of a privatebank. These geo-located transactions are employed to infer possible internal migra-tion movements in Turkey. The latter study utilizes data obtained from Facebook tocontribute to a better understanding of global migration patterns. Obtained datasetfrom Facebook is combined with migration stock datasets from international orga-nizations in a visual exploratory tool. This way, the visual tool creates a mediumwhere the innovative data source utilized can be validated. The tool is also usedfor visualizing the results of the case study with the transactional data source. Theadvantages and shortcomings of utilized innovative data sources are thoroughly dis-cussed."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Görsel-ataletsel eş zamanlı haritalama ve konumlandırma sistemleri ve görsel odometri artırılmış gerçeklik, otonom arabalar, GPS bağımsız ortamlarda hava araçlarının navigasyon sistemleri gibi çeşitli alanlarda yaygın olarak kullanılmak- tadır. Literatürde görsel-ataletsel eş zamanlı haritalama ve konumlandırma sistemleri ve görsel odometri sistemlerinin sensör tipleri, platformun durumlarını hesaplamak için kullanılan yöntemler, sensör füzyon yöntemleri, sistemin önyüz ve arkayüz yapıları konularında farklı konfigürasyonlar bulunuyor. Bu tezde odak noktası monoküler poz grafiği optimizasyonu üzerine görsel-ataletsel eş zamanlı haritalama ve konumlandırma sistemleri olacaktır. Bu amaçla uçtan uca görsel ataletsel eş zamanlı haritalama ve konumlandırma sistemi oluşturuldu ve poz sonuçları Euroc-Mav veri seti kullanılarak değerlendirildi. Ayrıca, mevcut çalışmalara katkı olarak, görsel-ataletsel navigasyonun sağlamlığını artırmak için çevredeki dinamik nesnelerin elimine edilmesi üzerine bir çözüm önerilmiştir.","Visual Inertial Simultaneous Localization and Mapping (VI-SLAM) and Visual Inertial Odometry (VIO) systems are widely used in various areas such as augmented reality, autonomous cars and aerial vehicles' navigation systems where there is need for navigating the platform in the absence of the GPS information. There are many different configurations of the VI-SLAM and VIO systems in the literature in terms of the sensor types, methods that are used in estimating the states of the platform, sensor fusion methods and the front and back end structures of the visual-inertial systems. In this thesis, the focus will be on monocular graph optimization based VI-SLAM and VIO systems. For this purpose, end-to-end VI-SLAM and VIO structures have been built and the trajectory results have been evaluated using the Euroc-Mav dataset. Moreover, as a contribution to the current studies, a solution to the prob lem of neglecting dynamic objects in the environment has been proposed to increase the robustness of the visual-inertial navigation systems."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"In the process of software development, software testing is an important part that makes a product satisfied by all expectations and requirements. Existing software testing tools need software testing knowledge to be used, and they are not literally readable by non-technical stakeholders. The use of Behavior Driven Development (BDD) techniques has been rapidly increasing since it uses Gherkin syntax which is similar to natural language and extremely easy to understand. In our tool, we aim to create a code-free framework for non-technical personnel can implement their own test suite in BDD and implement the middle layer by using Google Blockly. We suggest testers, to use TestProject Capture\&Replay, which is a free web application, to capture a script and import it to our tool for locating elements in Android or iOS devices. Moreover, users either are able to use the subset of actions in the captured list generated by TestProject or all actions in their test cases. Our tool enables users to modify the test suite in Google Blockly to have additional blocks such as loops, if-then-else statements, which make our tool more flexible and unique from other existing testing tools.","Yazılım denemeleri, yazılım geliştirmede bir ürünün bütün gereksinimleri ve beklentileri karşılamasını sağlar. Var olan yazılım deneme araçları, yazılım deneme bilgisinin kullanımı gerektiriyor ve bunlar teknik bilgiye sahip olmayan kişiler tarafından okunamıyor. Davranış odaklı geliştirme teknikleri (BDD) doğal dile çok benzeyen ve kolay anlaşılır Gherkin sentaksını kullandığından çok hızlı bir şekilde artıyor. Biz aracımızda, teknik bilgiye sahip olmayan çalışanların BDD ile kendi testlerini hazırlayabileceği ve orta katmanı Google Blocky ile uygulayabileceği teknoloji harikası bir sistem kurmayı amaçladık. Kullanıcılara senaryolarını kaydetmek ve bizim aracımıza yollamaları için bedava bir internet uygulaması olan TestProject Capture\&Replay kullanmalarını öneriyoruz. Bunun dışında, kullanıcılar TestProject tarafından oluşturulan dizilerin bir kısmını ya da tamamını kullanabilirler. Bizim aracımız kullanıcıların test odasını Google Blockly'de fazladan döngüler ve if-then-else ile değiştirmesine izin verdiğinden var olan deneme araçlarından daha esnek ve özel."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çoklu sınıflandırıcı sistemlerinin, çok sınıflı sınıflandırma problemlerinde karmaşık fakat doğruluk oranı yüksek bir sınıflandırma yöntemi olduğu, örüntü tanıma literatüründe sıkça işlenmiştr. Sınıflandırıcı birleştirme, verilen bir sınıflandırıcı kümesini nasıl birleştirilmesi gerektiği problemini çözmeye çalışır ve yığıtlı genelleme, başka bir deyişle yığıtlama, çok güçlü sınıflandırıcı birleştiricilerden biridir. Bu tezde yığıtlamanın performansını hem doğruluk oranı açısından, hem de karmaşıklık açısından artırıyoruz. Katkılarımız dört ana başlıkta toplanabilir. Öncelikle, birleştiriciyi öğrenirken sınırı en-büyükleyen menteşe kayıp fonkiyonu kullanmanın, literatürde daha önce kullanılan en küçük kareler kayıp kestiriminden daha iyi sonuçlar verdiğini gösterdik. İkinci olarak, düzenlileştirme için grup seyrekliği kullanarak otomatik sınıflandırıcı seçmeyi kolaylaştııyoruz. Üçüncü olarak, sınıf-bilinçli doğrusal birleştiricilerin doğrusal olmayan sürümlerini elde etmek için, veritabanı dönüştüren bir yöntem geliştiriyoruz. Son olarak, doğrusal bir sınıflandırıcı birleştirme yöntemi için MM algoritmalarını kullanarak bir çözüm buluyoruz.","Multiple classifier systems are shown to be effective in terms of accuracy for multiclass classification problems with the expense of increased complexity. Classifier combination studies deal with the methods of combining the outputs of base classifiers of an ensemble. Stacked generalization, or stacking, is shown to be a strong combination scheme among combination algorithms; and in this thesis, we improve stacking's performance further in terms of both accuracy and complexity. We investigate four main issues for this purpose. First, we show that margin maximizing combiners outperform the conventional least-squares estimation of the weights. Second we incorporate the idea of group sparsity into regularization to facilitate classifier selection. Third, we develop non-linear versions of class-conscious linear combination types by transforming datasets into binary classification datasets; then applying the kernel trick. And finally, we derive a new optimization algorithm based on the majorization-minimization framework for a particular linear combination type, which we show is the most preferable one."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan yapımı dinamik sistemlerinin güvenilir ve gürbüz olmasına gittikçe artanihtiyaç var. Eğer bir hata çabuk bir şekilde bulunur, gerekli önlemler alınırsa sis-tem kritik kazalardan, yüksek maliyetli hasarlardan ve de daha büyük hatalardankurtarılabilir. Hata teşhisinde tesisin iyi bir matematiksel modelinin varlığı büyükönem taşır. Non-Lineer dinamik bir sistemin matematiksel modellemesinin bulun-ması zor ve zaman alıcıdır. Bu nedenle, yapay sinir ağı (YSA), bulanık mantık vegenişletilmiş yapay sinir ağları (GYSA) gibi yapay zeka ile öğrenme yöntemleri dahaavantajlı olabilir.Dinamik sistemlerin modellemesi yapay zeka ile öğrenme yöntemleri ile yapılsabile, sistemde kullanılan, ölçülemeyen durumlar olabilir. Bunlar matematiksel olarakhesaplansalarda, zamanla hesaplanan değerler kayabilir. Sını ? andırma yöntemleritamamen veya hesaplamayı doğru noktaya çekebilmek için kullanılabilir. GYSAumut veren bir sını ? andırma yöntemidir ama veri noktalarının dağılımına hassasiyetiolmadığı için bazen kötü sonuçlar verebilir. GYSA, kabul edilebilir bir hataya ulaşanakadar kullandığı kaydırma ve güncelleme özelliği, diğer karşılaştırılabilir metodlaragöre daha uzun sürer.","There is an increasing demand for man-made dynamical systems to be reliable and safe. If a fault can be detected quickly, appropriate actions should be taken to prevent critical accidents, high cost malfunctions or failures. The key point in fault diagnosis is the assumption of the availability of good mathematical model of the plant. Mathematical modeling of non-linear dynamical systems may be computationally hard and time consuming. Therefore, modeling the plant using machine learning methods such as Neural Networks (NN), fuzzy logic, extension neural networks (ENN) can be more advantageous.Although a dynamical system is modeled via machine learning methods, there can be non-measurable states which are used in the system. Even though they are estimated with mathematical approaches, they can drift in time. Classification methods can be applied totally or to initialize the mathematical estimation. Although ENN is one of the promising classification methods, it sometimes gives poor results due to insensitivity to scatter of data-points. Its shifting and updating property takes more iterations than comparable methods to give an acceptable error rate.In this thesis, we propose improved extension neural networks (IENN) which improve on ENN's linear clustering method by using quadratic clustering and generating clustering criteria which depend on statistical properties of the training set. Rechargable Lead-Acid Battery is modeled via feed-forward NN approach and its state of charge is classified via proposed IENN method. The proposed method produces more accurate classifying results than ENN."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"GSM ağlarındaki güvenlik açıkları, kötü niyetli kişilerin cep telefonları ile baz istasyonları arasında yapılan bütün iletişimi izlemesine sebep olmaktadır. Bu tezde mevcut güvenlik sorunlarının önüne geçmeyi hedefleyen bir güvenlik altyapısı önerilmektedir. Bu altyapının bir parçası olarak Eliptik Eğriler Diffie Hellman (ECDH) metoduyla bir güvenli anahtar değişimi protokolü geliştirilmiştir. Ayrıca çift özet zincirleri yardımıyla bir oturum boyunca kullanılan simetrik anahtarlar oluşturulur. Bunun sebebi aşırı güç tüketen ECDH operasyonlarının sıklıkla tekrarlanmaması ve oturum sırasında kullanılan anahtarlardan birinin ele geçirilmesi durumunda, önceki ve sonraki anahtarların ele geçirilen anahtar yardımıyla üretilememesidir. Söz konusu protokol ses iletişiminde ve kısa mesaj iletişiminde kullanılmak üzere geliştirilmiştir. Bir uygulama örneği olarak geliştirilen protokol Android işletim sistemi üzerinde gerçeklenmiştir. Tezde aynı zaman uygulamanın değişik donanım gücündeki mobil cihazlarla performans ölçümleri de yer almaktadır. Ses iletişimi için ek olarak mobil şebekenin veri bağlantı hızı şehrin değişik yerlerinde ölçülmüştür.Anahtar Kelimeler: Güvenli Anahtar Değişimi, GSM Güvenliği, Mobil Güvenlik Altyapısı, Mobil İletişim Güvenliği","The security vulnerabilities in current GSM networks allow eavesdroppers to monitor entire communication between the mobile device and the base station over the air. In this thesis, a security framework for mobile communication is proposed. Within this framework, we develop a secure key exchange protocol using Elliptic Curve Diffie Hellman (ECDH). We further employ double hash chains for session key generation in order not to repeat resource-hungry ECDH operations too often and in order to provide forward and backward secrecy. We adopt this key exchange and generation protocol to short message service (SMS) and voice communication in mobile environment. As a proof of concept, we also implement our framework on Android platform. Moreover, we analyzed the performance of our framework using different mobile equipments. For the voice communication protocol, we also measure the data network performance for various places in the city.Keywords: Secure Key Exchange, GSM Security, Mobile Security Framework, Mobile Communication Security"
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet devrimi ve bilgisayar teknolojisinin ilerlemesi ile birlikte, kurumların dahaönce benzeri görülmemiş miktarda kişisel veri toplaması mümkün olmuştur. Yaygınlaşanveri toplama aktiviteleri, artan veri paylaşma ihtiyacı ile birleştiğinde veri mahremiyetiile ilgili endişeleri tetiklemiştir. Ayrıca kurumların oldukça büyük veri setlerindenönceden bilinmeyen ancak stratejik olarak faydalı bilgileri bulmasını sağlayan veri madenciliği tekniklerinin yaygınlaşması da mahremiyetle ilgili endişeleri arttırmıştır.Veri paylaşımı esnasında mahremiyeti sağlamanın bir yolu gizlenmesi gereken verialanlarının tek tek saklanması ya da genellenmesidir. Ancak, veri madenciliği teknikleri ile kötü niyetli kullanıcıların verinin geri kalanını kullanarak,saklanmış ya da genellenmiş veri alanlarını tahmin etmesi mümkün olmaktadır.Bu tez kapsamında popüler tahminsel veri madenciliği tekniklerinden biri olansınıflandırmaya odaklanılarak, verilen bir veri setini gerek veri alanlarını silerek gereksegenelleyerek güncelleyen, olasılıksal ve karar ağacı kökenli sınıflandırma tekniklerinedayalı çıkarımları önleyen algoritmalar önerilmektedir.Önerilen algoritmaların performansları gerçek veri setleri kullanılarak test edilmiştir.Test sonuçları, önerilen algoritmaların veri setlerini başarı ile baskıladığını ve hem olasılıksalhem de karar ağacı kökenli sınıflandırma tekniklerine dayalı çıkarımları engellediğini göstermiştir.Algoritmalarınaynı anda hem olasılıksal hem de karar ağacı kökenli sınıflandırma tekniklerine dayalıçıkarımları önleyen melez sürümleri, gizli verileri çok daha az yan etki ile saklamayıbaşarmıştır. Benzer şekilde, algoritmaların birden fazla gizli veri alanını saklamayıhedefleyen gelişmiş sürümlerinin, yan etkileri %50 civarında azalttığı gözlenmiştir.","The revolution of Internet together with the progression in computer technologymakes it easy for institutions to collect unprecedented amount of personal data. Thispervasive data collection rally coupled with the increasing necessity of sharing of itraised a lot of concerns about privacy. Widespread usage of data mining techniques,enabling institutions to extract previously unknown and strategically useful informationfrom huge collections of data sets, and thus gain competitive advantages, has alsocontributed to the fears about privacy.One method to ensure privacy during disclosure is to selectively hide or generalizethe confidential information. However, with data mining techniques it is now possiblefor an adversary to predict hidden or generalized confidential information using the restof the disclosed data set. We concentrate on one such possible threat, classification,which is a data mining technique widely used for prediction purposes, and proposealgorithms that modify a given microdata set either by inserting unknown values (i.e.deletion) or by generalizing the original values to prevent both probabilistic and decisiontree classification based inference.To evaluate the proposed algorithms we experiment with real-life data sets. Resultsshow that proposed algorithms successfully suppress microdata and prevent bothprobabilistic and decision tree classification based inference. The hybrid versions of thealgorithms, which aim to suppress a confidential data value against both classificationmodels, block the inference channels with substantially less side effects. Similarly, theenhanced versions of the algorithms, which aim to suppress multiple confidential datavalues, reduce the side effects by nearly 50%."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz duyarga ağları küçük, pille çalışan, sınırlı kaynaklara sahip aygıtlardan oluşur. Duyarga düğümleri çevreden veri toplar ve bu verileri radyo iletişim ortamı üzerinden baz istasyonuna iletirler. Kablosuz duyarga ağı uygulamalarının çoğunluğu statik duyarga düğümlerini kullansa da duyarga düğümleri kendiliğinden, ya da rüzgar, hava gibi çevresel etkenlerden, ya da duyarga düğümlerinin hareketli nesneler üzerine konuşlandırılmasından dolayı mobil olabilir. Genelde gözetimsiz olduğundan dolayı, duyarga düğümleri bu tezin odağını oluşturan solucan deliği saldırısı gibi fiziksel saldırılara açık hale gelirler. Solucan deliği saldırısında, saldırgan ağın bir bölgesinde alınan mesajları düşük gecikmeli solucan deliği bağlantısı üzerinden gönderir ve bu mesajları ağın başka bir bölgesinden tekrar yayınlar. Düşük gecikmeli tünel, ağ trafiğini solucan deliği bağlantısı üzerine çekerek saldırganın çeşitli saldırılar yapabilmesine zemin hazırlar.Bu tezde, mobil duyarga ağlarında solucan deliği saldırısını tespit etmek için dağıtık bir şema önerdik. Bu şemada lokal komşuluk bilgilerinini kullanarak iki farklı ağ özelliğinin (ağ düğüm yoğunluğu, ağ düğüm yoğunluğunun standart sapması) hesaplanmasında duyarga düğümlerinin mobilitesinden yararlanıldı. Solucan deliği saldırısı, hesaplanan ağ özellikleri ve komşuluk bilgileri baz alınarak, komşu düğümlerin davranışlarındaki anormalliklerin gözlemlenmesi yoluyla tespit edilir. Önerilen şemanın performansını simülasyonlarla analiz ettik. Sonuçlar, sistem parametreleri uygun bir şekilde seçildiğinde şemamızın %100'e varan bir doğru tespit oranına eriştiğini gösterdi. Bununla birlikte, hatalı tespit oranı %1.5 gibi çok düşük bir düzeyde kaldı.","Wireless sensor networks are composed of sensor nodes which are small, battery-powered devices having limited resources. Sensor nodes collect data from environment, and transmit them via their radio communication medium towards a base station. Although majority of wireless sensor applications use static sensor nodes, sensor node can be mobile either by itself, or due to environmental factors such as wind, water, or deployment of sensor nodes on moving objects. Due to mostly being unattended, sensor nodes become open to physical attacks such as wormhole attack, which is our focus in this thesis. In wormhole attack, an attacker tunnels messages received in one part of the network over a low-latency wormhole link and replays them in a different part of the network. The low-latency tunnel attracts network traffic on the wormhole link which can empower the attacker to perform various attacks.In this thesis, we propose a distributed wormhole detection scheme for mobile wireless sensor networks in which mobility of sensor nodes is utilized to estimate two network features (i.e. network node density, standard deviation in network node density) through using neighboring information in a local manner. Wormhole attack is detected via observing anomalies in the neighbor nodes? behaviors based on the estimated network features and the neighboring information. We analyze the performance of proposed scheme via simulations using different system parameters. The results show that our scheme achieves a detection rate up to 100% with very small false positive rate (at most 1.5%) if the system parameters are chosen accordingly."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda İnsansız Hava Araçları (İHA) giderek daha yaygınlaşmaya başlamıştır. İHA'ların etkileyici kabiliyetleri ve verilen görevi tamamlamadaki başarıları, bu hava araçlarını birçok sivil ve askeri uygulamada vazgeçilmez hale getirmiştir. İleri üretim teknikleri ve elektronik ekipmanlardaki dikkat çekici gelişmeler küçük boyutlu, akıllı ve düşük maliyetli İHA'ların yapımını mümkün kılmıştır. Sonuç olarak, önemli derecede araştırma çabası akıllı navigasyon ve kontrol sistemlerine sahip İHA'ların tasarımına adanmıştır.Bu tez çalışması döner kanat mekanizmasına sahip bir insansız hava aracı olan SUAVI'nin (Sabancı University Unmanned Aerial Vehicle) doğrusal olmayan kontrolüne odaklanmaktadır. Bu hava aracı döner-kanat mekanizması sayesinde dikine iniş-kalkış ve yatay uçuş özelliklerine sahiptir. Aracın değişik uçuş modları için doğrusal olmayan dinamik modeller elde edilmiş; dikey, geçiş ve yatay mod uçuş kontrolörlerini içeren bir hiyerarşik kontrol sistemi geliştirilmiştir. Bu kontrolörleri tasarlamak için araç dinamiği pozisyon ve yönelim olmak üzere iki alt sisteme ayrılmıştır. Hava aracının her üç uçuş modu için çeşitli doğrusal olmayan pozisyon kontrol yaklaşımları geliştirilmiştir. Aracın dikey uçuş modu için integral kayan kipli ve PID tabanlı pozisyon kontrol algoritmaları dinamik evirme methodu ile tasarlanmıştır. Bunun yanı sıra geri besleme ile doğrusallaştırma ve integral kayan kipli yönelim kontrolörleri aracın dikey, geçiş ve yatay uçuş modlarında yönelim stabilizasyonu için önerilmiştir. Geliştirilen kontrol yaklaşımlarının başarısı benzetim ve deney sonuçları ile doğrulanmıştır.","Unmanned aerial vehicles (UAVs) have become increasingly more popular over the last few decades. Their fascinating capabilities and performance in accomplishing a specific task have made them indispensable for various civilian/commercial and military applications. The remarkable progress in advanced manufacturing techniques and electronic components have rendered development of small, intelligent and low-cost UAVs possible. Consequently, a significant amount of research effort has been devoted to design of UAVs with intelligent navigation and control systems.This thesis work focuses on nonlinear control of a quad tilt-wing unmanned aerial vehicle (SUAVI: Sabanci University Unmanned Aerial Vehicle). The aerial vehicle has the capability of vertical takeoff and landing (VTOL), and flying horizontally due to its tilt-wing mechanism. Nonlinear dynamical models for various flight modes are obtained. A hierarchical control system that includes vertical, transition and horizontal modes flight controllers is developed. In order to design these controllers, the dynamics of the aerial vehicle is divided into position and attitude subsystems. Several nonlinear position control methods are developed for different flight modes. For the vertical flight mode, integral sliding mode and PID based position controllers via dynamic inversion method are designed. Feedback linearization and integral sliding mode attitude controllers are also proposed for the attitude stabilization of the aerial vehicle in vertical, transition and horizontal flight modes. Simulations and several real flight experiments demonstrate success of the developed flight controllers."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşbirlikli haberleşme, kablosuz algılayıcı ağlarda güvenilir, yüksek veri hızlı haberleşmeye ulaşmak için kullanılan ve algılayıcı düğümlerin enerji harcamasını düşüren ve algılayıcı ağın yaşam süresini artıran bir teknik olarak önerilmektedir. İşbirliğinin faydaları, uygun ortam erişim kontrol (MAC) protokolü dizaynı ile elde edilebilir. Bu tezde, çok sayıda rölenin dağınık bir yapıda işbirliğini sağlayan bir işbirlikçi MAC protokolü önerilmektedir. Protokolün enerji verimliliğinin önemli derecede işbirlikçi seçimi ve güç atamasına bağlı olduğu gösterilmiştir. İlk olarak, işbirlikçi düğümlerin erişimini koordine eden rastgele ve akıllı zamanlayıcı mekanizmaları önermekteyiz. Ardından, işbirlikçi seçimi süresinde görülen çekişme kanalını dikkate alarak bir çakışma çözümlemesi mekanizması önermekteyiz. İşbirlikçi iletimde kod bölmeli ve zaman bölmeli yaklaşımları da incelemekte ve bu iki alternatifin performanslarını kıyaslamaktayız. İşbirlikçi sistemlerin en büyük enerji kaybı kaynaklarının boşta dinleme ve istem dışı dinleme olduğunu dikkate alarak, işbirlikçi MAC protokolünü uyuma özelliği ile geliştirmekteyiz. Bu çalışmada, işbirlikçi MAC protokolünü, tüm önerilen geliştirmelerle birlikte, enerji verimliliği, verim, ortalama gecikme ve MAC paket ek yükü açısından değerlendirmekte ve performans iyileşmelerini göstermekteyiz.","Cooperative communication has been recently proposed for wireless sensor networksfor achieving reliable, high data rate communication, eventually decreasing energyconsumption at the nodes and extending the lifetime of the sensor network. Thebenefits of cooperation can be obtained by appropriate design of the medium accesscontrol (MAC) protocol. In this thesis, we present a cooperative MAC protocolthat enables cooperation of multiple relays in a distributed fashion. It is shown thatenergy effciency of the protocol signicantly depends on cooperator selection andpower assignment. We propose random and intelligent timer models for coordinatingaccess of the cooperating nodes. Next, we consider the contention channel observedduring the cooperator selection period and we propose a collision resolution mechanism.We consider two alternatives for cooperative transmissions, and compare theperformances of code division based and time division based approaches. The cooperativeMAC protocol is further improved by introducing sleep feature for the relaynodes, since the major sources of wasted energy for the cooperative system are idlelistening and overhearing. We evaluate the cooperative MAC protocol with all theproposed enhancements in terms of energy eciency, throughput, average delay andMAC overhead cost and demonstrate the performance improvements."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kimlik-temelli kriptografik sistemin 1984'te Shamir tarafından ortaya atılmasıyla, araştırmacılar için yeni bir kapı aralanmış oldu. Kimlik-temelli şifreleme işlemi için uygulanabilir bir algoritma önermeyen Shamir, imzanın geçerliliğinin imzalayanın herkese açık bilgileriyle, örneğin kimliği, doğrulanabildiği uygulanabilir bir elektronik imzalama sistemi geliştirdi. Kimlik-temelli şifrelemenin ilk uygulanabilir örneğinin Boneh ve Frankin tarafından eliptik eğriler üzerinde tanımlanmış eşleme (pairing) işlemi ile verilmesinden bu yana, kriptografi alanında eşleme temelli pek çok çalışmalar yapılıp, yayınlar çıktı. Günümüzde eşleme operasyonu pek çok kriptografik uygulamada kullanılmaktadır, kimlik temelli kriptografik sistemler, anahtar değişim protokolleri, kısa imzalar, anonim imzalar ve yeni gelişen pek çok protokol ve uygulama bunların arasındadır. Özet olarak kriptografik eşleme, içerisinde çözülmesi gereken birçok problemi barındıran ve halen gelişen bir araştırma alanıdır.Bu tezde, programlanabilir donanım cihazlarında gerçekleştirilmek üzere, her türde eşleme operasyonları için çok esnek, genel ve kompakt bir yardımcı-işlemci tasarımı sunulmaktadır. Geliştirilen tasarım, değişik parametre sınıflarında her eşleme operasyonu türevini desteklemektedir. Bunu yaparken sadece eşleme operasyonu için değil, diğer birçok asimetrik anahtarlı şifreleme sistemlerinde de kullanılan temel aritmetik operasyonları gerçekleyen son derece optimize edilmiş donanımsal işlevsel birimler kullanmaktadır. Tasarımda ortaya koyduğumuz yaklaşım, yazılım ve donanımın ortak kullanımıdır. Eşleme operasyonunu hızlandırmak için en çok zaman harcayan operasyonlar parametrik ve oldukça optimize donanımsal birimler olarak gerçeklenirken, karmaşık operasyonlar (kısıtlı donanım kaynaklarını verimli olarak kullanamayan) mikro-operasyonlar vasıtasıyla yazılımsal olarak gerçeklenmiştir. Tasarımda her ne kadar eş zamanlı çalışan ve aritmetik işlemleri gerçekleyen iki-çekirdek kullanılsa da, dikkatli tasarım ve esnek yapı sayesinde tasarım karşılaştırmalı olarak az yer kaplamaktadır.","Proposal of Identity-Based cryptography by Shamir in 1984 opened a new area for researchers. Failing to provide a feasible implementation of identity based encryption (IBE), Shamir developed a signature scheme, whereby signatures can be verified by publicly available information such as signer?s identity. Since the first efficient implementation of IBE realized using pairing operation on elliptic curves due to Boneh and Franklin a plethora of papers has been published and many studies have been conducted covering different aspects of pairing-based cryptography. Today, pairing is used in many cryptographic applications including, identity based cryptography, key exchange protocols, short signatures, anonymous signatures and in many other newly emerging protocols and schemes. Also, pairing is still a developing research field yielding important challenges for the research community.In this thesis, we propose a very generic, flexible and compact hardware co-processor for all kinds of pairing implementations intended for implementation on reconfigurable devices (e.g. FPGA). Our co-processor supports all types of pairing operations with different parameter classes via making use of highly-optimized hardware implementations of basic arithmetic operations common not only to pairing operations, but also to elliptic curve cryptography and other public key cryptography algorithms. Our design utilizes the idea of hardware-software co-design concept. To accelerate pairing computation we implement some units responsible for performing the most time-consuming operations as a generic, but highly optimized hardware circuits, whereas we prefer to implement some complex parts (unworthy of hardware resources) in low-level software of micro-instructions. Although we use two arithmetic cores running concurrently, our design still manages to be compact thanks to its careful and generic design."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez ile, kripto-analitik saldırıların gerçeklenmesi ve kriptografik operasyonların hızlandırılması için tasarlanmış, SPKD'lerden (Sahada Programlanabilir Kapı Dizileri) oluşan bir küme altyapısı sunuyoruz. Bahsi geçen küme altyapısı, SPKD cihazı, yerel depolama, KPMC (Karmaşık Programlanabilir Mantıksal Cihaz) ve ağ bağlantısı içeren ucuz ve kullanıma hazır SPKD çevrim kartlarından oluşmaktadır. Küme oluşturma işleminin basit olmasının yanısıra hesaplamalar için gerekli olan donanım tasarımı hariç herhangi bir donanım geliştirme gerektirmemektedir. SPKD'lerde gerçeklenebilen bir işlemci çekirdeği sayesinde, SPKD cihazlarını dinamik olarak yapılandırmak ve hatta yapılandırma ayarlarını, işlem sırasında bile, uzaktaki bir bilgisayar üzerinden değiştirmek mümkündür. Aynı zamanda bu işlemci çekirdeği, karmaşık programları SPKD'nin kaynaklarını kullanmaksızın yürütülebilmektedir. Ek olarak, bu tez ile dinamik yapılandırma değişim tekniği de öneriyoruz. Uygulamasını gerçeklediğimiz bu teknik özellikle kripto-analitik saldırılarda hızlı ve verimli bir şekilde kullanılabildiğinden, SPKD tabanlı geleneksel kripto-analitik makinalara göre daha uygun maliyetli bir alternatif oluşturmaktadır.","In this thesis, we propose an FPGA cluster infrastructure which can be utilized in implementing cryptanalytic attacks and accelerating cryptographic operations. The cluster can be formed using simple and inexpensive, off-the-shelf FPGA boards featuring an FPGA device, local storage, CPLD, and network connection. Forming the cluster is simple and no effort for the hardware development is needed except for the hardware design for the actual computation. Using a softcore processor on FPGA, we are able to configure FPGA devices dynamically and change their configuration on the fly from a remote computer. The softcore on FPGA can execute relatively complicated programs formundane tasks unworthy of FPGA resources. Finally, we propose and implement a fast and efficient dynamic configuration switch technique that is shown to be useful especially in cryptanalytic applications. Our infrastructure provides a cost-effective alternative for formerly proposed cryptanalytic engines based on FPGA devices."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal Ağlar günümüz internet kullanıcıları tarafından kişisel bilgilerin paylaşımı amacıyla yaygın olarak kullanılmaktadır. Bu tür ağların, bilgi içerikleri çok zengin olduğundan, diğer üçüncü partiler ile paylaşımı kamusal ve ticari fayda getirmektedir. Ancak, sosyal ağlarda saklanan bilgiler çoğun- lukla kişiye özeldir ve gizlilik endişelerine tabidir. Gizlilik sorunlarını gider- menin bir yolu, kullanıcılara kendi verilerinin kontrolü vermek ve istedikleri verileri bastırarak üçüncü kişilerden gizlemelerini sağlamaktır.Ne yazık ki yukarıda bahsedilen tercihe dayalı bastırma teknikleri gi- zliliği sağlamaya yetmemektedir. Bunun temel sebebi, bu tür koruma sis- temlerinin kullanıcılarına, bağlantılı oldukları diğer kullanıcıların paylaştık-ları veriler üzerinde kontrol izni vermemeleridir. Aralarında bağlantı bulu-nan kullanıcılar arasında veri benzerliği açısından ilişki mevcuttur; bu ilişkide iki komşu kullanıcı arasında veri çıkarsama kanalı oluşturur. Bu tezde bastırılmış sosyal ağlarda komşu kullanıcıların verilerine bakarak kişilerin bastırılmış bilgilerini bulabilen olasılıksal bir çıkarsama saldırısı öneriyoruz.Bu saldırı algoritması sosyal ağdaki etiketler arası bağıntıyı ve bağlantılarıbilen gerçekçi bir düşmana göre tasarlanmıştır. Yüksek derecede bastırılmış sosyal ağlarda bile kullanıcıların bastırılmış etiketlerinin çoğunluğunu çıkarsamanın mümkün olduğunu deneysel olarak göstermekteyiz.","Social Networks (SNs) are now widely used by modern time internet users to share any personal information. Such networks are so rich in information content that there is public and commercial benefit in sharing them with other third parties. However, information stored in SNs are mostly person specific and subject to privacy concerns. One way to address the privacy issues is to give the control of the data to the users enabling them to suppress data that they choose not to share with third parties.Unfortunately, above mentioned preference-based suppression tech- niques are not sufficient to protect privacy mainly because they do not allow users to control data about other users they are linked with.Information about neighbors becomes an inference channel in an SN when there is known correlation between the existence of a link be- tween two users and the users having the same sensitive information. In this thesis, we propose a probabilistic inference attack on a sup- pressed social network data, that can successfully predict a suppressed label by looking at neighboring users? data. The attack algorithm is designed for a realistic adversary that knows, from background or ex- ternal sources, the correlations between labels and links in the SN. We experimentally show that it is possible to recover majority of the suppressed labels of users even in a highly suppressed SN."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Wireless Sensor Network is a network type that consists of small sensor devices. The communication between these devices must be secured in case of an attack. Sensor devices have to share a secret key for secure communication. There are several key distribution schemes for wireless sensor networks in the literature. The most common key distribution scheme is the basic scheme which is proposed by Eschenauer and Gligor. Basic scheme has three phases; \emph{Key Predistribution}, \emph{Shared Key Discovery} and \emph{Path-key Establishment}. Ergun proposed an alternative phase to \emph{Path-key Establishment}, called \emph{Key Transfer} phase. To the best of our knowledge, there is no real node implementation of the basic scheme. In this thesis, we implemented all three phases of the basic scheme and Ergun's Key Transfer phase on a real sensor device. We use TelosB devices, which have 10kB RAM, 1 MB flash memory, a microcontroller and RF interface. We design flowcharts for each phase, create packet structures, implement in NesC programming language and test the implementation. We analyze the results using processing time, code space and memory usage metrics. We show that \emph{Key Transfer} phase is more efficient than \emph{Path-key Establishment} phase.","Kablosuz Duyarga Ağları, içerisinde küçük duyarga aygıtları barındıran bir ağ tipidir. Bu aygıtlar arasındaki haberleşme bir saldırı olma ihtimaline karşılık güvenli yapılmalıdır. Duyarga aygıtları güvenli haberleşme için gizli anahtarlar paylaşırlar. Literatürde bir çok anahtar dağıtım şeması vardır. Bunlardan en bilineni Eschenauer ve Gligor'un sunduğu basit şemadır. Basit şemanın üç evresi vardır: Anahtar Öndağıtım, Ortak Anahtar Keşfetme ve Yol Anahtarı Kurma. Ergun, Anahtar Transferi adında, Yol Anahtarı Kurmaya alternatif bir evre önermiştir. Bildiğimiz kadarıyla, literatürde basit şemanın gerçek aygıtlar üzerinde gerçeklenme çalışması yoktur. Bu tezde basit şemanın üç evresini ve Ergun'un Anahtar Transferi evresini gerçek bir duyarga aygıtında gerçekledik. Bunun için 10 kB RAM, 1 MB flash bellek, mikroişlemci ve RF arayüzü olan TelosB isimli aygıtları kullandık. Her evreyi tasarladık, paket yapılarını oluşturduk, NesC programlama dilinde kodladık ve gerçeklemeyi test ettik. Sonuçları işlem zamanı, kod boyutu ve bellek kullanım oranı metriklerini kullanarak analiz ettik. Anahtar Transferi evresinin Yol Anahtarı Kurma evresinden daha verimli olduğunu gösterdik."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, arttırılmış gerçeklik ortamlarında ortak bir sorun olan, çevresel ışıkların analizive sahneye konulacak cisimlerin bu ışık bilgisine göre ışıklandırılmasına uygun birmetod sunuyor.Bu metodun temelinde arttırılmış gerçeklik uygulamalarında şekli belirlicisimlerden, özellikle insan yüzü, çevresel ışıkların analizini yapan bir yapı mevcuttur.Metod özellikle dış mekan kullanımı için düzenlenmiş ve doğrudan güneş ışığı tarafındanaydınlatılan objeleri gerçeklemek için ayarlanmıştır.Tezin ilk kısmında, mobil cihaza doğrudan bakan bir insanın yüzünden çevresel ışıkbilgisinin nasıl çıkarılacağı anlatılmaktadır. Bu teknik ön kameradan gelen resimlerimuhtemel ışık kaynaklarına bakarak analiz etmektedir.Tezin ikinci kısmında ise ilk aşamada elde edilen ışık yön bilgisini kullanarak gerçekzamanlı ve görsel kalitesi yüksek bir biçimde sanal cisim görsellenme tekniği anlatılmaktadır.Bu model Küresel Harmonik Işıklandırması adında matematiksel bir teknik kullanmaktadır.","In this thesis, we propose a method to solve a common problem in augmented realitydomain; estimating light sources in an outdoor scene and lighting virtual objectsaccordingly. As a basis of our method we developed a framework based on estimation ofenvironmental lighting from well defined objects, specifically human faces. The methodis tuned for outdoor use, and the algorithm is further enhanced to illuminate virtual objectsexposed to direct sunlight.In the first part of this thesis, we propose a novel lighting estimation technique wherewe assume a user is looking straight to mobile devices camera. This technique extractsinformation from input images to calculate possible light sources to pass to the renderingstage.In the second part of this thesis, we propose a lighting model which uses the outputfrom our lighting estimation in order to make objects appear as they are lit correctly by thesun light. This model uses a mathematical technique called Spherical Harmonics Lightingfor real-time realistic rendering."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Rota analizleri, büyük miktarlarda hareket verilerinin toplanmasıyla önem kazanmaktadır. Bu verilerde saklı bilgileri ortaya çıkarmak için farklı analiz amaçlarına yönelik çok farklı görselleştirme metodları önerilmiştir. Bu tezdeki analiz, rota sapmalarının görselleştirmesini konu alır. Rota sapmaları; trafik sıkışıklığı, trafik kazaları, hava koşulları ya da işletme ile ilgili bir çok nedenden ötürü oluşabilir. Bu tezde önerilen sistem, çoklu rota sapmaların görselleştirilmesinde iki teknik sunar: daire-glif gösterimi ve rota boyama. Rota boyama, sapmaları genel şekilde ifade ederken, daire-glif gösterimi sapmaları detaylı bir şekilde gösteren bir tekniktir. Bazı görselleştirme kısımlarında detay seviyeleri tekniği kullanılmıştır. Önerilen yaklaşımların başarılarını ölçmek için istatistiksel yöntemler kullanarak kullanılabilirlik testleri yapılmıştır.","With the collection of excessive amounts of movement data, the analysis of routes has become very important in the exploration of these datasets. To reveal the hidden information in the data, many visualization approaches are proposed according to analysis type. The analysis in this thesis involves visualization of route deviations which occur due to several reasons such as traffic congestion, accidents, weather conditions, or operational issues. The proposed system integrates two visualization techniques for multiple routes visualization: circle-glyph representation and route coloring. While route coloring emphasizes deviations on general trends, circle-glyph visualization concentrates on the detailed analysis of deviations. Level of detail is applied in some visualization parts. A usability study with statistical analysis of its results is performed to evaluate the success of the proposed approaches."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"G-protein ile eşleşmiş reseptörlerin (GPER) sınıflandırılması, fonksiyonubelirlenememiş ancak amino asit dizilimi belirlenmiş çok sayıdaki reseptörünfonksiyonunu tahmin edebilmeyi mümkün kılması açısından çok önemlidir.GPER proteinleri arasında A sınıfı reseptörlerin çok sayıda ilaç tarafındanhedef alınıyor olması sebebiyle, A sınıfı reseptörlerin aktivasyon mekanizmalarınınderinlikli şekilde anlaşılabilmesi ise ayrıca önem teşkil etmektedir.Bu tezde, reseptörlerdeki amino asit dizilimi verisinden üretilmiş motiflerkullanılarak A sınıfındaki reseptör ailelerinin sınıandırılmasını sağlayan, ürettiğimotifler yoluyla da A sınıfı reseptörlerinin aktivasyon mekanizmalarınaışık tutan bir yöntem sunulmaktadır. Alt-sınıfları en iyi şekilde tanımlayanmotifleri seçebilmek için Ayrıştırı Güç Değerlendirmesi tekniğini sunuyoruz.Yapılan deneyler, geliştirdiğimiz yöntemin halıhazırda bulunan GPER proteinleriA sınıfı reseptörlerinin sınıflandırması tekniklerine kıyasla daha yüksekbaşarı oranları yakaladığını göstermiştir. Bu tezin bir diğer katkısı da ilaçtasarımında faydalı olabilecek, reseptör aktivasyonunda rol oynayan anahtarbölgelerin bulunmasıdır.","The classication of G-Protein Coupled Receptor (GPCR) sequences isan important problem that arises from the need to close the gap between thelarge number of orphan receptors and the relatively small number of annotatedreceptors. Equally important is the characterization of GPCR ClassA subfamilies and gaining insight into the ligand interaction since GPCRClass A encompasses a very large number of drug-targeted receptors. In thisthesis, a method for Class A subfamily classication using sequence-derivedmotifs which characterizes the subfamilies by discovering receptor-ligand interaction sites is proposed. The motifs that best characterize a subfamilyare selected by the proposed Distinguishing Power Evaluation (DPE) technique.The experiments performed on GPCR sequence databases show thatthe proposed method outperforms state-of-the-art classication techniquesfor GPCR Class A subfamily prediction. An important contribution of thisthesis is to discover key receptor-ligand interaction sites which is very importantfor drug design."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde üç farklı anahtar ön dağıtım şeması teklif edilmiştir. İlk şemada, iki sıradan anahtarın (tek anahtar) bit bazında XORlanmısıyla (dışlamalı ya da işlemine tabi tutulması) oluşan XORlu anahtar kavramını sunuyoruz. Duyarga düğümlerinin belleklerine tek ve XORlu anahtarların oluşturduğu bir karışım yüklenir. Düğümler ilk olarak XORlu anahtarları kullanarak güvenli bağlantı kurarlar. Eğer hiç ortak XORlu anahtar bulunmuyorsa tek anahtarları kullanmayı denerler. Eğer düğüm çifti arasında ortak herhangi bir XORlu veya tek anahtar bulunmuyorsa çeşitli yöntemlerle güvenli komşularından anahtar transfer eder ve XORlu anahtarlarıyla eşleştirmek için kullanırlar. XORlu anahtarları kullanmamızdaki amaç kötü niyetli faaliyetlere karşı daha dayanıklı bir ağ elde etmektir, çünkü bu durumda bir saldırganın ya XORlu anahtarı oluşturan iki tek anahtarı ya da XORlu anahtarın kendisini bilmesi gerekmektedir. Şemamızın çeşitli simülasyonlarını çalıştırdık ve temel şema [4] ile karşılaştırdık. Şemamız temel şemayla karşılaştırıldığında %50'ye kadar daha bağlantılıdır. Ayrıca düğüm ele geçirme saldırısının başında daha iyi performans sergilemekte ve kötüleşme durumunda temel şema ile arasındaki fark %5'i geçmemektedir.Önerdiğimiz ikinci şema aslında çoğu şemaya uygulanabilecek bir eklentidir. Komşu düğümler arasında paylaşılan anahtarların keşfinden hemen sonra çalıştırılabilecek ek bir evre teklif ediyoruz. Komşu düğüm çiftlerinin belli bir olasılık ile ortak bir anahtar paylaştığından yukarıda bahsedildi. Açıkçası bazı komşu düğüm çiftleri herhangi bir ortak anahtar bulmakta başarısız olurlar. Teklif edilen yeni evremizde bir a düğümü, daha önceden bağlantı kurduğu güvenli komşularının belleğinde tutulan anahtarları gerekli görürse kendisine transfer edebilir ve ortak anahtar paylaşmayan komşularıyla bağlantı kurmak için kullanabilir. Bu yolla geleneksel şemalardaki aynı yerel bağlantı değerlerini düğüm belleklerinde önemli ölçüde daha az anahtar tutarak sağlayabilmekteyiz. Şemamızın performansını paylaşılan anahtar keşfi evresinden sonraki temel şema [4] ile karşılaştırdık ve sonuçlarımız gösteriyor ki şemamız, temel şema ile aynı yerel bağlantıyı elde etmektedir. Daha fazlası, bunu yaparken şemamızdaki düğümler, temel şemadaki düğümlerden dörtte üç oranında daha az anahtar ile yüklenmektedir. Ayrıca şemamız, düğüm ele geçirme saldırılarında paylaşılan anahtar keşfi evreli temel şemadan %50'ye kadar daha dayanıklı kalmaktadır.Önerdiğimiz son şema çoklu evreli kablosuz duyarga ağlarında kullanılmak üzere tasarlanmıştır. Tasarımımızda düğümler, ölenlerin yerini almak üzere nesil adı verilen zaman aralıklarının başında yerleştirilirler. Her neslin kendisine ait tamamen farklı bir anahtar havuzu vardır. Farklı nesillere ait havuzlardan rastgele seçilmiş anahtarlar düğümlere, o nesillerde yerleştirilmiş düğümlerle güvenli iletişim kurabilmeleri için önceden yüklenir. Başka bir deyişle, şemamızda anahtarlar nesil çiftlerine özgüdür. Bu saldırganın işini zorlaştırır ve şemamızın dayanıklılığını artırır. Şemamızı çoklu evreli kablosuz duyarga ağları için tasarlanmış başka bir anahtar ön dağıtım şemasıyla karşılaştırdık. Sonuçlarımız gösterdi ki, şemamız yoğun saldırılarda bile kararlı durumdayken %35'e kadar daha dayanıklıdır.","In this thesis, we proposed three different key predistribution schemes. In the first scheme, we introduce the concept of XORed key, which is the bitwise XOR of two regular (a.k.a single) keys. Sensor nodes are preloaded with a mixture of single and XORed keys. Nodes establish secure links by shared XORed keys if they can. If no shared XORed key exists between two neighboring nodes, they try single keys loaded in their memory. If node pairs do not have any shared XORed or single keys, they transfer keys from their secure neighbors in a couple of ways, and use them to match with their XORed keys. In this scheme, we aim to have a more resilient network to malicious activities by using XORed keys since an attacker has to know either both single key operands or the XORed key itself. We performed several simulations of our scheme and compared it with basic scheme [4]. Our scheme is up to 50% more connected as compared to basic scheme. Also it has better resilience performance at the beginning of a node capture attack and when it starts to deteriorate the difference between the resilience of our proposed scheme and basic scheme is not greater than 5%.The second scheme that we proposed is actually an extension that can be applied to most of the schemes. We propose an additional phase that is performed right after shared keys between neighboring nodes are discovered. As mentioned above, neighboring node pairs share a common key with a certain probability. Obviously some neighboring node pairs fail to find any shared key. In our proposed new phase, keys preloaded in memories of secure neighbors of a node a are transferred to a, if necessary, in order for a to establish new links with its neighboring nodes that they do not share any key. In this way, we achieve the same connectivity with traditional schemes with significantly fewer keys. We compared the performance of our scheme with basic scheme [4] after shared-key discovery phase and our results showed that our scheme achieved the same local connectivity performance with basic scheme, moreover while doing that, nodes in our scheme are loaded with three fourth of keys fewer than the keys loaded in nodes in basic scheme. In addition to that, our scheme is up to 50% more resilient than basic scheme with shared-key discovery phase under node capture attacks.The last scheme that we proposed is designed to be used for multi-phase wireless sensor networks. In our model, nodes are deployed at the beginning of some time epochs, called generations, in order to replace the dead nodes. Each generation has completely different key pool. Nodes are predistributed keys drawn uniformly random from key pools of different generations in order to have secure communication with nodes deployed at those generations. In other words, in our scheme keys are specific to generation pairs. This makes the job of attacker more difficult and improves the resiliency of our scheme. We compared our scheme to another key predistribution scheme designed for multi-phase wireless sensor networks. Our results showed that our scheme is up to 35% resilient in steady state even under heavy attacks."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Elektroensefalogram (EEG) tabanlı Beyin-Bilgisayar arayüzü (BBA) sistemleri uygulamalı nörozyoloji alanındaki yeni gelişmelerden biridir. Bu sistemler EEG analiz yöntemleri ve bilgi teknolojileri alanındaki gelişmeler ile EEG sinyalinin psikofiziksel özelliklerinin daha iyi anlaşılmasıyla mümkün hale gelmektedirler. BBA sistemleri beyinden dış dünyaya, çevresel sinir sistemini kullanmadan, doğrudan bir bilgi akışı sağlamayı amaçlar. Bu amaca ulaşılabilmesi için etkili sinyal işleme ve örüntü tanıma tekniklerine gerek vardır.Bu tezde, saklı Markov modelleri (HMM) üzerine kurulu bir yaklaşım önerdik ve yaklaşımımızın etkinligini genel kullanıma açık bir veri kümesi ve kendi laboratuvarımızda topladığımız veriler üzerindeki deneysel sonuçlar ile gösterdik.Hareketin zihinde canlandırılması deneylerinden elde edilen iki ve dört sınıflı EEG verilerden kestirilen özbağlanımlı parametrelere (AR) dayalı öznitelikleri temel bileşen analizi (PCA) tabanlı boyut indirgeme ile birlikte kullandık ve elde ettiğimiz boyutu indirgenmiş öznitelikleri HMMler kullanarak sınıflandırdık. Elde ettiğimiz sonuçlar daha önce yapılmış HMM tabanlı BBA sınıflandırıcıları ve Mahalanobis mesafesi sınıflandırıcısı ile karşılaştırdık.","Electroencephalography (EEG) based Brain-Computer Interface (BCI) systems are a new development in the field of applied neurophysiology. This new approach has been made possible thanks to progress in EEG analysis and in information technology which has led to a better understanding of psychophysical aspects of the EEG signals. BCI systems enable information flow from the brain directly to the outside world. For widespread use of brain signals for such objectives, effective signal analysis and pattern recognition techniques are needed.In this thesis, we have developed a new technique based on hidden Markov models, and have demonstrated the effectiveness of our algorithms both on a standard dataset and on the data that we have collected in our laboratory.We have used HMMs with AR features combined with PCA to classify two and four class single trial EEG data recorded during imagination of motor actions type of BCI experiments. Results were compared with previous HMM based BCI classifiers and Mahalanobis distance classifier fed with two different state-of-theart EEG features."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gerçek zamanlı önplan tanıma ve ayrıştırma uygulamalarında, önplan ve arkaplan modelleme önemli bir yer teşkil etmektedir. Stauffer ve Grimson metodu, önplan çıkarımında yaygın olarak kabul görmüş başarılı bir metottur. Bu mettota, her piksel ayrı ve bağımsız bir Gauss karışımı ile modellenir. Piksellerin önplan olma olasılıkları doğrudan kullanılmaz. Zamansal ve mekansal süreklilik göz ardı edilir. Bu çalışmada, Stauffer ve Grimson metodundan hareketle, piksellerin önplan olma olasılıklarını belirleyip, histeresiz eşikleme yaparak mekansal sureklilik bilgisini kullandık. Aynı amaçla, Markov Rasgele Alanları temelli modelleme ve optimizasyon uyguladık. Zamansal devamlılık bilgisini kullanabilmek için de; ortalama kaydırma metodu ile nesne takibini, önplan ayrıştırmaya dahil ettik. Uygun olan durumlar için birkaç metodu birlikte kullandık.Çalışmamızda, önplan belirleme başarımını önemli derecede arttırdık.","For real-time foreground detection on videos, probabilistic modeling for background andforeground colors are widely used. Stauer and Grimson's model is very successful forforeground segmentation. In this method, each pixel is modeled independently withGaussian mixtures. Explicit foreground probabilities for pixels are not calculated. Spatialand temporal continuity of pixels are omitted.In this thesis, we obtain foreground probabilities for the pixels using Stauer and Grimson'smodel and apply hysteresis thresholding to utilize spatial continuity of pixels. Forthe same purpose, we also use Markov Random Field modeling and optimizations. Toleverage the temporal continuity of pixels, mean-shift tracking is integrated into thesegmentation to increase accuracy. Wherever applicable, we combine some of theseimprovements together. Our work shows that using the probabilistic approach withdierent enhancements results in much higher segmentation accuracy."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Türlerin tarihsel evrim ilişkileri filogenetik ağaç olarak modellenebilir. Buağacların yaprakları türleri, aradaki düğümleri ataları ve kenarları genetik ilişkileri temsil eder. Türler arasında ödünç alma olduğu durumda, filogenetikağaçlara bu tür ilişkileri gösteren az sayıda kenar eklenerek, filogenetik ağlaradönuştürülebilirler. Ancak verilen bir tür ailesi için oldukça fazla olası ağaçve ağ olabilir ve bu ağaçları otomatik olarak analiz edebilecek bir sistemmevcut değil. Bu tez, çözüm kümesi programlama (ASP) kullanarak ağırlıklıfilojeni ve filogenetik ağ hesaplamak amacıyla yeni hesaplama yöntemlerive yazılım sistemleri geliştirerek filogenetik çalışmalarındaki bu ihtiyacıkarşılamaktadır. Ağırlıklı filojeni hesaplamasının arkasındaki genel fikir, birfilojeninin ve filogenetik ağin ne kadar makul olduğunu gösteren bir ağırlıkfonksiyonu kullanarak belirli bir ağırlığın üzerindeki filojenileri ve filogenetikağları ASP çözücülerini kullanarak hesaplamak.Bu tez kapsamında, uyumluluk kriterine göre ağırlıklı filojeni ve filogenetikağaç çıkarımı ile ilgili hesaplama problemlerini inceledik, bu problemlerinhesaplama karmaşıklığını analiz ettik. Ağırlıklı filojenileri ve filogenetikağları hesaplamak için iki tip (gösterime dayalı ve aramaya dayalı) ASP'ye dayalı hesaplama yöntemi geliştirdik. Bu yöntemlerden yararlanarak,büyük veriler üzerinde filojeni çıkarımı yapmak için böl-ve-yönet yönteminedayanan yeni bir algoritma geliştirdik. Bu algoritmaya dayalı yazılım sistemlerigeliştirdik: ağırlıklı filojeni çıkarımı ve analizi yapan Phylo-ASP,ve ağırlıklı filogenetik ağ çıkarımı yapan PhyloNet-ASP. İki gerçek veriüzerinden (Hint Avrupa dilleri ve Türkiye'deki meşe ağaçları) yaptığımıztestler ile yöntemlerimizin ve yazılım sistemlerimizin etkinliğini gösterdik.Bunların yanında, yöntemlerimizi ASP'de ağırlıklı çözümler bulacak şekildegenelleştirdik ve bir ASP çözücüyü (clasp-w) bu yöntemlere uygun bir şekildedeğiştirerek birçok ASP uygulaması için yararlı bir araç sağladık.","Evolutionary relationships between species can be modeled as a tree(called a phylogeny) whose nodes represent the species, internal vertices representtheir ancestors and edges represent genetic relationships. If there areborrowings between species, then a small number of edges that denote suchborrowings can be added to phylogenies turning them into (phylogenetic)networks. However, there are too many such trees/networks for a given familyof species but no phylogenetic system to automatically analyze them. Thisthesis fulfills this need in phylogenetics, by introducing novel computationalmethods and tools for computing weighted phylogenies/networks, using AnswerSet Programming (ASP). The main idea is to define a weight functionfor phylogenies/networks that characterizes their plausibility, and to reconstructphylogenies/networks whose weights are over a given threshold usingASP solvers.We have studied computational problems related to reconstructing weightedphylogenies/networks based on the compatibility criterion, analyzed theircomputational complexity, and introduced two sorts of ASP-based methods(representation-based and search-based) for computing weighted phyloiiigenies/networks. Utilizing these methods, we have introduced a novel divideand-conquer algorithm for computing large weighted phylogenies, and implementeda phylogenetic system (Phylo-ASP) based on it. We have alsoimplemented a phylogenetic system (PhyloNet-ASP) for reconstructingweighted networks. We have shown the applicability and the efectiveness ofour methods by performing experiments on two real datasets: Indo Europeanlanguages, and Quercus species in Turkey. Moreover, we have extended ourmethods to computing weighted solutions in ASP and modified an ASP solveraccordingly, providing a useful tool (clasp-w) for various ASP applications."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Anahtar Kelimeler: On Odemeli Sistemler, Guvenlik, Mikro Odeme, Kablosuz OrguAğlarKablosuz Orgu Ağlar cok sekmeli, erisimin her yerden sağlanabildiği, yuksekhızlı ve gelismekte olan bir ağ teknolojisidir. Bu tezde kablosuz orgu ağlarda ağ erisimiicin guvenli bir mikro odeme sistemi teklif edilmistir. Semamızdaki ana motivasyon,operatorlerin tamamen guvenilir birimler olmadığı yonundedir; buna gore musterileroperatorlerle olan hesaplarını kendileri kontrol altına almaktadır. Bu sayede, sistemelemanlarının hic birisi sağlanan veya alınan hizmet karsısında durust olmayan birdavranıs sergileyememektedir.Onerdiğimiz odeme sistemi on odemeli bir semadır. Kullanıcılar bağlantı kartlarısayesinde servis alırlar. Bağlantı kartları duzenleyicisi, guvenilir bir ucuncu partikurulustur ve bağlantı kartlarının yaratılmasından sorumludur. Her bir bağlantı kartıjetonlardan olusur. Bu jetonlar ozet zinciri olarak yaratılır. Ozet zinciri baslangıcdeğerinin bir kac defa ozetlenmesi ile olusur. Ozet fonksiyonları tek yonlu ve gerialınamayan kriptografik fonksiyonlardır. Jetonlar ise geriye doğru tuketilir. Bu sayedekullanılmıs jetonlardan kullanılmamıs jetonların uretilmesi mumkun değildir. Bu ozelliksemamızdaki guvenliği sağlayan ana ozelliktir.Onerdiğimiz semanın performans değerlendirmesi icin simulasyonlargerceklestirdik. 300 musteri ile elde ettiğimiz sonuclar tum musteriler bağlantı isteğiniaynı anda gonderdiğinde ortalama kimlik doğrulama suresinin 1 saniyenin altındaolduğunu gostermistir.","Keywords: Prepaid Payment Systems, Security, Micropayments, Wireless MeshNetworksWireless Mesh Network (WMN) is an evolving multi-hop, ubiquitous and highspeed networking technology. In this thesis, we proposed a secure micropaymentscheme for network access in WMNs. The main motivation is that the operators are notconsidered as fully trusted entities in our scheme; the clients control their balance withtheir operators. In this way, none of the system entities can behave dishonestly about theamount of services provided and obtained.Our proposed payment scheme is a prepaid one. The users obtain connectioncards for getting service. Connection card issuer, which is a trusted third party,generates the connection cards. Each connection card includes tokens. These tokens aregenerated as a hash chain which is obtained by hashing an initial value (IV) severaltimes. Hash functions are one way and irreversible cryptographic functions. The tokensare consumed backwards. Therefore, it is not feasible to generate unused tokens from analready used token. This property is the main enabler for the security of our scheme.We have conducted simulations for performance evaluation of the proposedscheme. Our results show that in a network with 300 clients, the average authenticationcompletion time becomes less than 1 second even if all the clients send their connectionrequest at the same time."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez elyazısı matematik ifadelerin tanınmasında çizge grameri kullanımını sunmaktadır. Bu problemin zorluğu normal optik ifade tanıma işleminin sahip olduğu problemlerin üzerine matematik ifadelerin 2 boyutlu yapısının anlamlandırılmasından gelmektedir.Çözümleme işlemi sırasında mümkün olduğunca çok veriyi ifade edebilmek için çizge gramerlerini kullanıyoruz. Yöntemimizin bir diğer yönü de alternatif çözümlemelerin korunup bunlar arasında ön yüksek olabilirliğe sahip olanın kastedilen ifade olarak belirlenmesidir. Olabilirlik değerleri ifadelerin yapısal istatistiklerinden yaklaşık olarak hesaplanmaktadır.Sistemin bölütleme adımı zaman bilgisi ile çizgileri ayırmakta, mesafe bilgini kullanarak gruplandırmaktadır. Daha sonra semboller zaman boyutunda esneklik sağlayabilmek için çevrimdışı özelliklerin kullanıldığı tanıma motorunda tanımlanmaktadır. Tanıma motoru bir destek vektör makinesi ve yapay sinir ağının bir araya getirilmesi olup en iyi 3 tanıma sonucunu döndürmektedir.Çözümleme süreci gramer içerisinde tanımlanmış kuralların ardı ardına uygulanması ile girdiyi temsil eden çizgeye yeni düğümler eklemektedir. İşlem tamamlandığında bir ya da daha fazla düğüm tanımlamış ifadeyi teslim etmektedir.Kullanıcı arabirimimiz karakter tanıma hatalarının düzeltilebilinmesine olanak veren araçları da içermektedir. Arabirim LaTeX MathML ve girdi ifadenin makine yazısı çizimini üretebilmektedir.15 kullanıcıdan 57 farklı ifadeyi ve 70 karakterli bir alfabe için örnek ifadeler ve bir başına karakterler toplanmıştır. Toplam 1710 matematik ifade ve 10500 bir başına karakter bulunmaktadır. Tüm bu örnekler kullanıcıların doğal el yazıları şeklinde toplanmıştır.","This thesis presents a graph grammar approach for the recognition of handwritten mathematical expressions. The problem is challenging, as it includes the sub-problems of character recognition (OCR) on top of 2-dimensional structure understanding of mathematical expressions.We use graph grammars for structural understanding of the expressions in order to represent as much information as possible in the parse process. Another important aspect of our system is the fact that all alternative parses are evaluated and the one with maximum likelihood is selected as the intended expression. The likelihoods are estimated according to structural relationships statistics.The segmentation step segments and groups strokes according to timestamps and distance in space respectively. Then, symbols are recognized by the OCR engine which uses offline features to allow for flexibility in time dimension. The extracted features are used in an ANN and SVM combination engine returning top-3 character alternatives and confidence values.The parse process expands the graph by generating new tokens with repeated application of grammar rules. At the end, one or more tokens contain the full expression.Our user interface gives tools to the user to correct OCR errors and it can generate LaTeX and MathML codes and graphical rendering of the input handwritten mathematical expression.An extensive collection of mathematical expression and isolated symbols are collected from 15 users for 57 different expressions from a 70-character alphabet. There are, in total, 1710 mathematical expressions and 10500 isolated characters. All samples are in the natural writing styles of the users."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Verinin birden fazla partiye bölünmüş olduğu dağıtılmış veri madenciliği uygulamaları yüksek miktarda ağ üzerinden haberleşme gerektirir. Bu yükten kurtulmak için önerdiğimiz modelde, uzaktan yapılan hesaplamaları güvenli bir donanım üzerinde yerel hesaplamalara dönüştürüyoruz. Partilerin çalışması için vekil ortam olarak Cell BE seçildi. Modelin performansını ölçmek amacıyla, daha önceden oluşturduğumuz güvenli iki-partili hesaplama protokolü üzerinde uygulamalar tasarladık. Hesaplamadki her parti kendi uygulamasını yazdıktan sonra, imzalayıp şifreleyerek vekil ortama yollamakla yükümlü. Yolladıkları uygulamalar Cell BE işlemcisi üzerinde kendileri için ayrılmış izole durumdaki SPE çekirdeğine yollanır. Uygulamanın çalışması öncesinde, esnasında ve sonrasında herhangi bir bilgi açığa çıkması Cell BE işlemcisinin sunmuş olduğu güvenlik özelliklerinden dolayı çok zordur. Yapmış olduğumuz deneyler, sunmuş olduğumuz modelin büyük hızlanma sağladığı sonucunu ortaya koymuştur. Cell BE platformu içinde yeterli çekirdek olduğu sürece hesaplamadaki parti sayısını arttırmak mümkündür.","Distributed privacy preserving data mining applications, where data isdivided among several parties, require high amounts of network communication.In order to overcome this overhead, we propose a scheme that reducesremote computations in distributed data mining applications into local computationson a trusted hardware. Cell BE is used to realize the trustedhardware acting as a proxy for the parties. We design a secure two-partycomputation protocol that can be instrumental in realizing non-colludingparties in privacy-preserving data mining applications. Each party is representedwith a signed and encrypted thread on a separate core of Cell BErunning in an isolated mode, whereby its execution and data are secured byhardware means. Our implementations and experiments demonstrate that asignicant speed up is gained through the new scheme. It is also possible toincrease the number of non-colluding parties on Cell BE, which extends theproposed technique to implement most distributed privacy-preserving datamining protocols proposed in literature that require several non-colludingparties."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mobil ve yaygın bilişimdeki ilerlemeler, hayatımızın her alanına giren kullanıcıbazlı uygulamaların sayısını artırmıştır. Bu durum kişisel gizliliğimizi tehdit etmekteve kişisel gizliliğe duyarlı uygulamaların geliştirilmesi konusunda büyük bir talepoluşturmaktadır. Kapsayıcı kişisel gizliliği koruyucu mekanizmaların data işlemenintüm fazlarını kullanıcılardan datanın toplanması, datanın merkezi sunucularda korunmasıve üçüncül şahıslarla paylaşılmasını da kapsayacak şekilde göz önüne almasıgerekmektedir. Bununla birlikte literatürdeki kişisel gizlilik çalışmaları çoğunluklatoplanmış bilginin üçüncül şahıslarla paylaşılması konusunda çözümler getirmiştir.Bu tezde, kişisel gizliliği sağlanmış bir data toplama anaçatısı önerilmiştir. Önerilenanaçatı, kişisel gizliliği data toplayıcıya giderken sağlamaktadır. Anonimleştirmesırasında k-anonimlik ve l-farklılık konseptlerini kullanan genel bir aşağıdan yukarıyakümeleme metodu önerilmiştir. Performans değerlendirmelerinde, entropi bazlı bilgikaybı ve anonimlik seviyesi belirleme metrikleri kullanılmıştır. Anaçatımız, birdenfazla her biri farklı kişisel gizlilik seviyelerine sahip olan data toplayıcılarına sahipağlar için de uyarlanmıştır.Anaçatımız, iki çeşit data toplama uygulamasında denenmiştir: (i) kablosuzsensör ağlarında kişisel gizliliği sağlanmış data toplanması, (ii) farklı organizasyonlardansaldırı tespit kayıtlarının toplanması sırasında organizasyonel gizliliğinsağlanması.Kablosuz sensör ağlarında geleneksel kişisel gizlilik & data yararlılığı ikilemineek olarak bir boyut daha vardır. Bu boyut, küçük sensör düğümlerinin sınırlamalarınedeniyle band genişliği ve enerjinin minimize edilmesi gerekliliğidir. Analizlerimizgöstermektedir ki önerilen anaçatı, bir ya da birden çok data toplama merkezi içerenkablosuz sensör ağlarında enerji tüketiminin minimize edilmesi, data yararlılığı vekişisel gizliliğin sağlanması arasında uygun bir denge mekanizması oluşturmaktadır.Anaçatımızın, organizasyonlarla merkezi güvenlik izleme birimi arasında organizasyonelgizliliği sağlayacak şekilde saldırı tespit kayıtlarının paylaşıllması için etkinbir mekanizma oluşturduğu da gösterilmiştir.","Advances in mobile and ubiquitous computing increased the number of usercentric applications that comes into all aspects of our lives. This situation hasstarted to threaten our privacy and created a huge demand for development ofprivacy-aware applications. Comprehensive privacy protection mechanisms haveto take all phases of data processing into considerations including data collectionfrom users, storage of data in central servers, and sharing them with third parties.However, privacy studies in the literature generally bring solutions for sharing ofcollected information with third parties.In this thesis, a privacy preserving data collection framework is proposed foruser centric network applications. Framework provides privacy of data en route todata collector(s). We propose a generic bottom-up clustering method that utilizesk-anonymity or l-diversity concepts during anonymization. Entropy based metricsfor information loss and anonymity level are de¯ned and used in performanceevaluations. Framework is adapted for networks having di®erent data collector partieswith different privacy levels.Our framework is applied for two types of data collection applications: (i) privacypreserving data collection in wireless sensor networks, (ii) preservation of organizationalprivacy during collection of intrusion detection logs from different organizationsTraditional data utility vs. privacy trade-o® has one more dimension in wirelesssensor networks. This dimension is minimization of bandwidth or energy consumptiondue to the limitations of tiny sensor nodes. Our analyses show that the proposed framework presents a suitable trade-o® mechanism among energy consumption minimization, data utility and privacy preservation in wireless sensor network applications with one or multiple sinks.It is also demonstrated that our framework brings e®ective solution for preservingorganizational privacy during sharing of intrusion detection logs among organizationsand central security monitoring entity."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telsiz Izgara Aglar gelismekte olan bir arastırma alanıdır ve kullanıcılara hem ucuz hem de hızlı servis saglamaktadırlar. Öte yandan, anahtar tesis etme mekanizması, her türlü agda oldugu gibi Telsiz Izgara Aglar için de çok önemli ve kritik bir güvenlik kaygısıdır. Ancak, anahtar tesis etmek için kullanılan geleneksel yöntemler Telsiz Izgara Aglar'ın benzersiz özelliklerine ve kısıtlamalarına uymamaktadır.Bu tez ile, Telsiz Izgara Aglar'a özel tasarlanmıs iki verimli ve güvenli anahtar tesis etme mekanizması sunuyoruz. Güvenlik modelimiz Kimlik Tabanlı Kriptografi ve Esik Sır Paylasımına dayalı. Kimlik Tabanlı Kriptografi kullanımı güvenlik gerekliliklerini saglamakla birlikte geleneksel sistemlerin gerektirdigi sertifikaları da ortadan kaldırmaktadır. Diger yandan, Esik Sır Paylasımı agın daha esnek olmasına olanak vermekle birlikte kendi kendine düzenlenen bir anahtar tesis etme mekanizmasının olusturulabilmesini saglamaktadır.Sundugumuz iki mekanizmada da agın ana sifresi kullanıcılar tarafından paylasılmaktadır ve kullanıcıların sifrelerinin hesaplanması ancak yeterli sayıda kullanıcının - esik degerini saglayacak sekilde - biraraya gelmesi ile gerçeklesmektedir. Esik degerini arttırdıgımızda agın saldırılara karsı olan esnekligi de artar ama bu durum sistemin performansını kötülestirmektedir. Toplam kullanıcı sayısının ve esik degerinin performans üzerindeki etkilerini görebilmek için bir takım similasyonlar yaptık: 8'den küçük esik degerleri için kullanıcıların en az %90'ı kendi sifrelerini en fazla 70 saniyede olusturabilmektedir. Esik degerini 8'e sabitleyerek, kullanıcı sayısını 40'dan 100'e yükseltirsek, kullanıcı sifrelerinin olusturulabilme yüzdesi de %75'den %100'e yükselmektedir ve islemler 80 saniyede tamamlanmaktadır. Esik degerini 8'in üstüne çıkardıgımızda ise, kullanıcı sayısındaki aynı artıs en kötü durumda bile agın %42 daha verimli oldugunu göstermektedir ve islemler bu kosullarda en fazla 90 saniyede son bulmaktadır.","Wireless Mesh Networks (WMNs) are an emerging research area that provide low-cost and high-speed network services for the end users. Key establishment, on the other hand, is the most important and critical security concern for WMNs as all the other types of wireless networks. However, the conventional solutions for key establishment do not fit in the unique constraints and requirements of WMNs.In this thesis, we propose two efficient and secure key establishment protocols elaborated at the sake of WMNs. Our security model is based on Identity-based Cryptography (IBC) and Threshold Secret Sharing (ThSS). By the utilization of IBC, we eliminate the necessity of certificates used in infrastructure based schemes along with meeting the security requirements. With the utilization of ThSS, we provide a more resilient network working in a self-organizing way to provide the key establishment service, without the assumption of a trusted authority.In the schemes we propose, master private key of the network is distributed among the mesh nodes. The user private key generation service is handled with collaboration of k mesh nodes, where k is the threshold value. A high threshold value increases the resiliency of the network against attacks; however, this negatively affects the system performance. We performed simulative performance evaluation in order to show the effect of both the number of mesh nodes in the network and the threshold value k on the performance. For the threshold values smaller than 8, at least 90% of the mesh nodes compute their private keys within at most 70 seconds. When we increase the number of mesh nodes in the network from 40 to 100, the rate of successful private key generations increase from 75% to 100% at the threshold value 8 where the latency of the key establishment is around 80 seconds. Considering the same increase in the number of mesh nodes, network performs up to 42% better at worst case, for the threshold values larger than 8, and the latency becomes at most 90 seconds on the average."
Sabancı Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada Sonlu Durum Makinaları (SDM) bazlı sınamada yeni bir kontrol dizisi üretim yöntemi verilmektedir.Bu yöntem, yakın geçmişte öne sürülen ve problemin yaklaşık yarım asır önce ortaya konuluşundan berikullanılan tüm yöntemlerden farklı bir yaklaşıma sahip yeni bir yöntemi temel almaktadır.Yenilik olarak, agresif bir şekilde durum belirleme dizileriyle durumların tanınması yerine,kontrol dizisine daha sonra yapılacak eklentilerin bu sorunu çözeceği öngörülmektedir. Ancak bu yöntemin kontrol dizisi üretememeihtimali bulunmaktadır. Bu nedenle yine bu çalışma içerisinde verilen bir dizinin kontrol dizisi olup olmadığını kontrol edenbir yöntem de geliştirilmiştir. Eğer üretilen dizinin bir kontrol dizisi olmadığı anlaşılırsa, dizi ikinci bir aşamada tekrar ele alınıp yapılan eklentilerle bir kontrol dizisı haline getirilmektedir. Bu çalışmada yeni yöntemin mevcut yöntemlere göre daha kısa kontrol dizileri ürettiğini gösteren deneysel çalışmalar da sunulmaktadır. Bu deneysel çalışmalarda kullanılan Sonlu Durum Makinaları yine bu çalışma süresinde gerçekleştirilmiş bir rastlantısal SDM üretme aracı kullanılarak üretilmiştir.","A new method for constructing a checking sequence for finitestate machine (FSM) based testing is introduced. It is basedon a recently suggested method which uses quite a differentapproach than almost all the methods developed since theintroduction of the checking sequence generation problem aroundhalf a century ago. Unlike its predecessor which aggressively triesto recognize the states by applying identification sequences,our approach relies on yet to be generated parts of the sequencefor this. The method may terminate without producing a checkingsequence. We also suggest a method to check if a sequence is achecking sequence for this purpose. If it turns out not be a checkinga sequence, a post processing phase extends the sequence further. Wepresent the results of an experimental study showing that our two phaseapproach produces shorter checking sequences than the previouslypublished methods. This experimental study is performed on FSMs thatare randomly generated by using a tool implemented within this work tosupport this and other FSM based testing studies."
