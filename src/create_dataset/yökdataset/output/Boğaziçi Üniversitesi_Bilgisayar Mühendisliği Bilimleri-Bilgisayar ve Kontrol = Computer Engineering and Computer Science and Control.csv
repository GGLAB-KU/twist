university,konu,tr,en
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çocukların sosyal etkileşimi ve zeka gelişiminin yaygın gelişsel hastalıklar (YGH) tarafından etkilendiği bilinmektedir. Bu hastalıkların erken yaşta teşhis edilmesinde vezinsel ve dilbilimsel ipuçları kullanılabilir. YGH'li çocukları uzaktan izlemek ve/veya eğitmek için hesaplamasal paralinguistik uygulanabilir. Hastalıkları daha iyi anlamak için, oldukça bilgi verici özniteliklerin küçük bir altkümesine ihtiyaç vardır. Makine öğrenimi perspektifinden bakıldığında, öznitelik seçimi (ÖS) öğrenicinin genelleme kabiliyeti için ve altta yatan problemler hakkında çıkarımlar yapmak için çok önemli bir aşamadır. Çünkü, yüksek boyutlu veriler bağıntısız ve artık özniteliklerden oluşmaya eğilimlidir. Ortak bilgiye dayalı en popüler öznitelik seçim yöntemleri, özniteliklerin ayrıklaştırılmasına başvurur. Literatürde farklı ayrıklaştırma yöntemlerinin etkisi incelenmiş olmasına rağmen, bildiğimiz kadarıyla eşit genişlikte z-skor ayrıklaştırma için farklı sayıda aralığın etkisi ortak bilgiye dayalı öznitelik seçimi için çalışılmamıştır. Ortak Bilgi (OB) hesaplaması ayrık bölümlerin sayısına bağlı olduğundan, öznitelik dizimi ve dolayısıyla performans yörüngesinin değişeceğini varsaymaktayız. INTERSPEECH 2013 Otizm alt müsabaka veri kümesinde ortak bilgiye dayalı öznitelik seçim yöntemleri kullanarak kapsamlı deneyler yaptık. Karşılaştırmalı sonuçlar varsayımımızı doğrulamakta olup gelecek çalışmalar için ilgi çekici yorumlara yol açmaktadır. Ek olarak bu tezde, OB normalizasyonu için şans faktörü düzeltmesi önerilmiş ve yeni bir OB temelli ÖS kriteri elde edilmiştir. Son olarak ayrıklaştırmanın etkisini dikkate alarak aday sıralı öznitelikleri seçiyor ve özniteliklerin sadece \%2'sini kullanarak test kümesinde \%70.68 Ağırlıksız Ortalama Tanıma (AOT) performansı elde ediyoruz. Bu sonuç, yarışma protokülüne bağlı kalarak test kümesi üzerinde alandaki en iyi performansı iyileştiriyor.","Pervasive Developmental Disorders (PDD) are known to affect children's social interactions and mental development. Prosodic and linguistic cues can be used to diagnose the disorders at early ages. Computational paralinguistics can be applied for tele-monitoring and/or educating the children with PDD. For better understanding the disorders, a small subset of highly informative features is needed. From machine learning perspective, feature selection (FS) is an important step for generalization ability of the learner and drawing inferences about the underlying problems. Since, the high dimensional data are vulnerable to comprise redundant and irrelevant features. The most popular FS methods depend on Mutual Information (MI), that resort to discretization of features. Though the effect of different discretization schemes are studied in literature, to the best of our knowledge the effect of different number of bins for equal width z-score discretization is not studied for MI based FS. Since MI computation depends on the number of discrete categories, we hypothesize that the feature ranking and therefore performance trajectory also changes. We carry out extensive experiments using eight MI based FS methods on the INTERSPEECH 2013 Autism sub-challenge corpus. The comparative results verify our hypothesis and lead to interesting remarks for future studies. Also in this thesis, adjustment for chance factor is proposed for normalizing MI measures, therefore obtaining a new MI based FS criterion. Finally, we choose the candidate ranked features by considering the effect of discretization, and achieve 70.68\% Unweighted Average Recall (UAR) performance on the test set using only 2\% of the feature set. This result advances state-of-the-art performance on the test set adhering to the challenge protocol."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir markanın itibarını incelemek ve anlamak, onun çevrimiçi reklamcılığına, bilgi yayınına ve sosyal müşteri ilişkilerinin yönetimine yardımcı olabilir. Sosyal medyanın yaygınlaşmasıyla birlikte marka itibarı, duygu analizi yöntemleriyle sayısallaştırılabilir hale geldi. Bu ölçüm tekniklerinden biri, bir markanın çevrimiçi itibarını ve müşteri sadakatini sosyal medya aracılığıyla ölçmek için kullanılan Net Marka İtibarıdır. Ancak sosyal medyayla birlikte ortaya çıkan yeni popülerlik kavramı, tüketicilerin marka itibarı üzerindeki etkisini değiştirdi. Bu çalışmada, Twitter'daki marka incelemelerinin popülerlik etkisini de dahil ederek marka itibarını ve müşteri sadakatini ölçmek için yeni bir yöntem olan Ağırlıklandırılmış Net Marka İtibarı önerilmektedir. Bu yeni yöntemde kullanılan katsayılar, Twitter'daki popülerlik metrikleri hakkında sistematik bir literatür taraması sonrasında önerilen Popülerlik Katsayısı (PC) adı altında yeni bir formülle elde edilmiştir. Ağırlıklandırılmış Net Marka İtibarı formülü öncelikle literatürde mevcut olan popülerlik metrikleri (Popülerlik puanı ve Takipçi Sıralaması) ve ardından yeni PC formülü ile hesaplandı. PC ile hesaplanan Ağırlıklı Net Marka İtibarı, Popülerlik puanı ve Takipçi Sıralaması katsayılarıyla hesaplanana göre daha rasyonel ve daha az çarpıktı. Çalışmanın son bölümünde Tweetlerin Popülerlik Katsayısı ile hesaplanan Ağırlıklı Net Marka İtibarı, Prophet Time Series modeli kullanılarak haftalık olarak tahmin edilmiştir. Marka itibarının hesaplanması için, şirketlerin pazarlama ve sosyal medya departmanlarına önerilen yeni metriklerin (Tweetlerin Popülerlik Katsayısı ve ağırlıklı Net Marka İtibarı) kullanılmasını tavsiye ediyoruz.","Studying and understanding a brand's reputation can help in its online advertising, information broadcasting, and management of social customer relationships. With the spread of social media, brand reputation can be quantified with the help of sentiment analysis methods. One of these quantification techniques is Net Brand Reputation, used to measure a brand's online reputation and customer loyalty through social media. However, the new concept of popularity that emerged with social media changed the influence of consumers on a brand's reputation. In this study, a new method, Weighted Net Brand Reputation is proposed to measure brand reputation and customer loyalty by including the popularity effect of brand reviews on Twitter. The coefficients used in this new method were obtained with a new formula under the name of Popularity Coefficient (PC) which was proposed after a systematic literature review about popularity metrics on Twitter. The Weighted Net Brand Reputation formula was calculated first with popularity metrics that already exists in the literature (Popularity score and Follower Rank), then with the new PC formula. The results with PC were more rational and less skewed than the ones calculated with the coefficients of Popularity score and Follower Rank. In the last part of this study, the Weighted Net Brand Reputation calculated with the Popularity Coefficient was weekly forecasted using the Prophet Time Series model. For the calculation of brand reputation, we recommend using the proposed new metrics (Popularity Coefficient and Weighted Net Brand Reputation) by companies in their marketing departments as well as social media."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, derin sinir ağı mimarilerinin yüksek boyutlu vektörleri işlemedeki avantajları ile klasik yapay zeka arama tekniklerini birleştirerek robot öğrenimi için yeni bir yöntem sunmaktadır. Bu yöntem, robotun sürekli gösterimdeki duyudevinimsel verileri ile sonlu sayıda nesneler içeren ortamlar arasında bir köprü kurmak için tasarlanmıştır. Önerilen yöntemin amacı ortam ile etkileşimler yoluyla toplanan verileri uygun sembolik yapılara çevirerek bu semboller üzerinden ağaç arama yöntemleri ile istenilen bir hedef durumu bulmaktır. Yöntemin genel yapısında gizyazıcı-gizçözücü tipinde bir sinir ağı bulunmaktadır. Sinir ağının darboğaz katmanında türev akışına izin veren i-kili etkinleştirme hücreleri bulunmaktadır. Ortamdaki nesnelerin öznitelikleri ile temsil edilen ortam durumu, gizyazıcıya girdi olarak verilmektedir. Gizyazıcı her nesne için ayrık bir vektör üretir, ve bu vektörler nesnelerin sembolleri olarak kullanılır. Nesne sembolleri eylem vektörü ile birlikte gizçözücüye girdi olarak verilir, ve gizçözücü robotun eyleminin yol açtığı etkiyi tahmin eder. Tüm yapı eğitildikten sonra sürekli bir şekilde gösterilen ortamın tanımı gizyazıcı kullanılarak sembolik hale dönüştürülebilir. Bu sayede ortamdaki geçişler semboller üzerinden kurallar tanımlanarak gösterilebilir. Bu kurallar planlama alan tanım diline çevrildiğinde çeşitli planlama yöntemleri kullanılarak hedef bir durum aranabilir. Masaüstü nesne etkileşimi deney düzeneklerinde yaptığımız deneyler bu sistemin ortama dair uygun semboller öğrendiğini göstermiştir. Gözetimsiz bir şekilde öğrenilmiş bu semboller üzerinden tanımlanan kurallar kullanılarak çeşitli yüksekliklerde nesne kuleleri ve nesneler arası ilişkilerin modellenmesini gerektiren karmaşık nesne yapıları kurulmuştur. Bu yöntem türevlenebilir yapı taşları ile kurulduğu için derin öğrenmedeki yenilikler ile çeşitli yönlerde genişletilebilir.","This thesis presents a novel framework for robot learning that combines the advantages of deep neural architectures in processing high-dimensional vectors with classical AI search techniques to bridge the gap between continuous sensorimotor data of the robot and domains consisting of finite entities. The aim is to convert information about the environment collected through interactions into an appropriate symbolic form on which a search tree can be built to reach a desired state. The framework consists of an encoder-decoder type of network with binarized activations in the bottleneck layer. The state of the environment, represented as a set of object features, is given to the encoder as input. The output is a discrete vector, treated as the object's symbol, given to the decoder together with the action vector. The decoder predicts the effect observed by the agent due to the executed action. Once the network is trained, we can transform the continuously represented environment definition into symbolic vectors using the encoder. This allows us to build rules defining the transitions in the environment defined over these symbols. These rules can be translated into planning domain definition language (PDDL), allowing domain-independent off-the-shelf planners to be used to search for a goal state. Our experiments on tabletop object manipulation setups show that the system can learn appropriate symbols of the environment that allow it to build object towers with desired heights and complex object structures that require modeling the relations between objects by reasoning through the rules defined over the symbols learned in an unsupervised manner. As the framework is built with differentiable blocks, it affords appending recent advances in deep learning with ease, allowing it to be extensible in multiple directions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"En sık görülen primer kötü huylu beyin tümörleri olan gliomalar, genomik gelişmelere dayalı olarak yeniden sınıflandırılarak spesifik moleküler alt sınıflar için kişiselleştirilmiş tedavilere olanak sağlanmıştır. Gliomaların teşhisi ve tedavi plan- lamasındaki genetik belirteçlerin önemi, 2016 ve 2021 Dünya Sağlık Örgütü (WHO) merkezi sinir sistemi tümörleri sınıflamasında vurgulanmıştır. Özellikle isositrat de- hidrogenaz (IDH) ve telomeraz ters transkriptaz promotörü (TERTp), gliomalarda tedaviye yanıtı, nüks ve sağkalım oranını etkileyen genetik belirleyiciler olarak gös- terilmiştir. Bu mutasyonların operasyon öncesi ve girişimşel olmayan bir şekilde tespiti büyük önem taşımaktadır ve bu amaçla yapılan çalışmalarda manyetik rezonans spek- troskopisinin (MRS) kilit bir rol üstlendiği görülmektedir. Bu çalışma, kısa eko zamanlı tek-voksel proton MRS ile elde edilen farklı glioma alt gruplarının MRS profillerini inceleyerek, bu genetik değişikliklerle ilişkili olabilecek moleküler belirteçleri ortaya çıkarmaktadır. Bu tezin ilk bölümünde, gliomalardaki IDH ve TERTp mutasyonlarının tespiti için geleneksel makine öğrenimi algoritmaları ve bir boyutlu evrişimsel sinir ağı (1D-CNN) kullanılan bir sınıflandırma sistemi geliştirilmiştir. 1D-CNN modeli, IDH mutasyonunun tespitinde %90'ın üzerinde bir doğruluğa ulaşırken, TERTp mutasy- onunu tespitinde %75'lik bir doğruluk elde etmiştir. Bu çalışmada ayrıca en agresif glioma türü olan, IDH mutasyonu bulunmayan TERTp mutant gliomaların, sağkalım süreleri ile ilişkili metabolik korelasyonları analiz edilmiştir. Glutamin-glutamat kom- pleksi (Glx) ve glutatyon (GSH), sağkalımı etkileyen önemli metabolik korelasyonlar olarak bulunmuştur. Sonuç olarak, MRS, glioma moleküler alt gruplarının preoperatif tanısına yardımcı olabilir ve glioma biyolojisi hakkında bilgi sağlayabilir.","Gliomas, the most common primary malignant brain tumors, have been reclassi- fied based on genomic advancements, providing new insights into oncogenic mechanisms and enabling individualized treatments for specific molecular subclasses. The impor- tance of genetic markers in glioma diagnosis and treatment planning was emphasized in both 2016 and 2021 revisions of the World Health Organization (WHO) classifica- tion of central nervous system (CNS) tumors. Specifically, isocitrate dehydrogenase (IDH) and telomerase reverse transcriptase promoter (TERTp) have been indicated as genetic biomarkers, impacting treatment response, and survival rate in gliomas. Preop- erative and noninvasive detection of these mutations has been drawing great interest, and proton magnetic resonance spectroscopy (1H-MRS) has been important for this purpose. This study delves into MRS profiles of 225 glioma patients, unraveling dis- tinct molecular signatures associated with these genetic alterations utilizing short echo time (TE) single-voxel 1H-MRS. A classification approach was developed integrating conventional machine learning algorithms and a one-dimensional convolutional neural network (1D-CNN) to identify IDH and TERTp mutations in gliomas. The 1D-CNN model showed exceeding 90% accuracy in identifying IDH mutation and 75% accu- racy in detecting TERTp mutation. This study also analyzed the metabolic correlates of survival outcomes in the IDH wildtype (IDH-wt), TERTp mutant (TERTp-mut) gliomas, known as the most aggressive form of gliomas. Glutamine-glutamate complex (Glx) and glutathione (GSH) have emerged as significant metabolic correlates influenc- ing patient survival in these patients. To conclude, 1H-MRS could aid in preoperative identification of glioma molecular subgroups, offering insights into glioma biology."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyomedikal literatürün hızlı gelişmesi nedeniyle, doğal dil işleme ve metin madenciliği teknikleri kullanılarak biyomedikal metinlerden yararlı bilgilerin çıkarılması büyük talep görmektedir. En önemli metin madenciliği görevlerinden biri, varlıklar arasındaki ilişkilerin tanımlanmasını içeren ilişki çıkarmadır. Büyük Dil Modellerinin (BDM) çeşitli doğal dil işleme görevlerindeki başarısından esinlenerek, biyomedikal metinlerden protein-protein etkileşimlerini çıkarmak ve bu etkileşimleri açıklamak için BDM tabanlı bir yaklaşım kullanılmasını öneriyoruz. İlişki çıkarımı için BioBERT, SciBERT ve PubMedBERT maskeli dil modellerine beş farklı kıyaslama veri kümesinde ince ayar yaptık ve bunların belirli bir metinde bahsedilen protein-protein etkileşimlerini etkili bir şekilde tanımlayabildiklerini gösterdik. Daha sonra, nedensel BDM'leri kullanarak çıkarılan protein-protein ilişkilerini daha ayrıntılı analiz etmek için yeni bir yaklaşım geliştirdik. Bir protein çifti arasındaki etkileşimi ortaya çıkaran metindeki anahtar kelimeleri belirlemek için, Llama-2 sohbet modellerine bağlam içi öğrenme ve parametre verimli talimat ince ayarı gibi farklı öğrenme stratejileri uyguladık. Sonuçlarımız, parametre açısından verimli ince ayarın, yeni bir eğitim alanında bile model performansında artış sağladığını gösteriyor. Daha küçük ince ayarlı modeller, çok daha büyük modellerin sıfır atış performansından daha iyi performans gösterdi. Çalışmamız, ilişki çıkarımı için maskeli ayarla ilişki çıkarımı ve ilişki açıklaması için nedensel BDM'den oluşan sistemin, gerçek dünya senaryolarında protein-protein ilişkilerinin analizinde kullanmak için etkili bir strateji olabileceğini öne sürüyor.","Due to the rapid growth of biomedical literature, the extraction of useful information from biomedical texts using natural language processing (NLP) and text mining techniques is in high demand. One of the most important text mining tasks is relation extraction (RE), which involves identifying relationships between entities. Inspired by the success of Large Language Models (LLMs) in various NLP tasks, we propose an LLM-based approach to extract and explain protein-protein interactions (PPIs) from biomedical texts. For relation extraction, we fine-tuned the masked language models BioBERT, SciBERT and PubMedBERT on five PPI benchmark datasets and showed that they can effectively identify PPIs mentioned in a given text. Next, we developed a novel approach to further analyze the extracted PPIs using causal LLMs. We applied different learning strategies, namely in-context learning and parameter-efficient instruction fine-tuning for the Llama-2 chat models, to identify keywords in the text that reveal an interaction between a protein pair. Our results show that parameter-efficient fine-tuning leads to a performance gain even when the domain is new. The smaller fine-tuned models outperformed the zero-shot performance of much larger models. Our study suggests that a pipeline consisting of a masked LLM for relation extraction and a causal LLM for relation explanation can be an effective strategy for building a PPI analyser in real-world scenarios."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım sorunları, geliştirme sırasında düzeltmek, iyileştirmek veya yeni iş parçacıkları oluşturmak ve ekip üyeleri arasındaki iletişimi kolaylaştırmak için iş birimleri içerir. Bir sorunu en alakalı ekip üyesine atamak ve bir sorunun kategorisini belirlemek sıkıcı ve zorlu bir iştir. Yanlış sınıflandırmalar, projede gecikmelere, yeniden çalışmalara ve ekip üyeleri arasında sıkıntıya neden olur. Bu makale, sığ makine öğrenimi yöntemleri için özenle derlenmiş bir dizi dilsel özellik önermekte ve sığ ve topluluk yöntemlerinin performansını derin dil modelleriyle karşılaştırmaktadır. Son teknolojiden farklı olarak, çözümümüzün genelliğine katkıda bulunmak için sorunları belirli kişiler veya ekipler yerine dört role (tasarımcı, geliştirici, testçi ve lider) atıyoruz. Çözüm formülasyonumuzdaki endüstriyel uygulamaları yansıtmak için geliştiricilerin deneyim düzeyini de dikkate alıyoruz. Sorunları, hata, yeni özellik, iyileştirme ve diğer gibi farklı sınıflara ayırmak için bir sınıflandırma yaklaşımı kullanıyoruz. Ek olarak, gereken özel değişiklik türüne göre hataları daha fazla sınıflandırmaya çalışıyoruz. Tasarımızı değerlendirmek ve derin dil modelleriyle karşılaştırmak için en büyük üç küresel televizyon üreticisinden birinden beş endüstriyel veri seti topluyor ve bunları etiketliyoruz. Veri setlerimiz toplamda 5324 sorun içermektedir. Sığ tekniklerin bir topluluk sınıflandırıcısının, en gelişmiş derin dil modelleriyle istatistiksel olarak karşılaştırılabilir olan hatırlama ve doğrulukta sorun ataması için 0.92 ve sorun sınıflandırması için 0.90'a ulaştığını gösteriyoruz. Katkılarımız, beş adet etiketlenmiş endüstriyel sorun veri setinin kamuya açık paylaşımını, açık ve kapsamlı bir özellik setinin geliştirilmesini, yeni bir etiket setinin tanıtılmasını ve sığ makine öğrenme teknikleriyle oluşturulan bir topluluk sınıflandırıcının etkinliğinin doğrulanmasını içermektedir.","Software issues contain units of work to fix, improve or create new threads during the development and facilitate communication among the team members. Assigning an issue to the most relevant team member and determining a category of an issue is a tedious and challenging task. Wrong classifications cause delays and rework in the project and trouble among the team members. This thesis proposes a set of carefully curated linguistic features for shallow machine learning methods and compares the performance of shallow and ensemble methods with deep language models. Unlike the state-of-the-art, we assign issues to four roles (designer, developer, tester, and leader) rather than to specific individuals or teams to contribute to the generality of our solution. We also consider the level of experience of the developers to reflect the industrial practices in our solution formulation. We employ a classification approach to categorize issues into distinct classes, namely bug, new feature, improvement, and other. Additionally, we endeavor to further classify bugs based on the specific type of modification required. We collect and annotate five industrial data sets from one of the top three global television producers to evaluate our proposal and compare it with deep language models. Our data sets contain 5324 issues in total. We show that an ensemble classifier of shallow techniques achieves 0.92 for issue assignment and 0.90 for issue classification in accuracy which is statistically comparable to the state-of-the-art deep language models. The contributions include the public sharing of five annotated industrial issue data sets, the development of a clear and comprehensive feature set, the introduction of a novel label set and the validation of the efficacy of an ensemble classifier of shallow machine learning techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, soru-cevap modellerinin performansını artırmak için bir soru üretim sistemi kullanma üzerine odaklanmaktadır. Önerdiğimiz model çok dilli Transformer tabanlı bir kodlayıcı-çözücü mimarisi üzerine inşa edilerek, birden fazla görev için aynı anda eğitilmiştir. Bu model sayesinde yalnız paragraflar girdi olarak alınarak soru cevap ikilileri üretilebilir. Çok dilli bir model kullanmamız sayesinde soru üretim sistemini çeşitli dillere uyarlayabildik. İlk olarak, Türkçe Vikipedi sayfalarını ve bu soru üretim sistemi kullanarak Türkçe Soru Yanıt veri kümesini oluşturduk. Deneylerimiz, üretilen veri kümesinin insan tarafından işaretlenmiş Soru Yanıt veri kümesiyle birleştirildiğinde, Türkçe XQuAD setindeki performansın \%3 arttığını ortaya çıkardı. İkinci olarak, modelimizi birçok dil ve düşük kaynak ortamında kapsamlı bir şekilde test ettik. Soru üretim modelini eğitmek için İngilizce, Almanca, Fransızca ve Türkçe gibi farklı dillerden soru-yanıt veri kümesinden sınırlı sayıda işaretlenmiş veri kullandık. Daha sonra bu modeli işaretlenmemiş paragraflardan yapay soru-cevap çiftleri oluşturarak; soru cevaplama modelinin eğitimine ek veri olarak kattık. Deneylerimiz, özellikle düşük veri ayarlarında, arttırma stratejimizin, insan tarafından işaretlenmiş veriye dayalı temel soru-yanıt modellerinin farklı boyutta ve dilde veri kümeleri üzerinde daha iyi performans gösterdiğini ortaya koydu.","This thesis focuses on employing a question-generation system to improve the performance of question-answering models. We propose a multitask-trained question-generation module that is built on a multilingual encoder-decoder architecture and can produce question-answer pairs over plain text passages. We were able to adapt the question-generation system to several languages by using a multilingual model. First, we created a Turkish Question Answering dataset utilizing the Turkish Wikipedia pages and this question-generation system. Our experiments revealed that the performance on the Turkish XQuAD set was enhanced by 3\% when the generated dataset was combined with the human-annotated dataset for question-answering model training. Second we also extensively test our model in many languages and low-resource environments. We used limited annotated data from the question-answering datasets from different languages like English, German, French, and Turkish; to train the question generation model. We then utilized this model to create artificial question-answer pairs from the unannotated paragraphs. Our experiments revealed that, especially in the lower data settings, our augmentation strategy consistently outperformed the baseline question-answering models that are trained on human-annotated data across a range of dataset sizes and languages."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet ortamında bulunan belge sayısındaki yoğun artış, aranan bilgiye ulaşımı zorlu, sıkıcı ve zaman alıcı bir faaliyet haline getirmiştir. Bu doğrultuda otomatik metin özetleme, araştırmacıların büyük ilgisini çekerek önemli bir çalışma alanı haline gelmiştir. Derin öğrenme alanındaki son gelişmeler, metin özetleme alanındaki araştırmaları çıkarımsal yöntemlerden daha soyut yaklaşımlara doğru kaydırmıştır. Araştırmalar ve mevcut kaynaklar çoğunlukla İngilizce diliyle sınırlıdır, bu da özellikle biçim bilimsel açıdan zengin diller gibi yapısı ve özellikleri bakımından farklılık gösteren diğer dillerde ilerlemeyi engellemektedir. Bu tezde, ağırlıklı olarak Türkçe ve Macarca soyut metin özetleme üzerine odaklandık ve önemli zorluklarını inceledik. İlk olarak, Türkçe (TR-News) ve Macarca (HU-News) için metin özetleme alanında kullanımı amaçlayan, ancak konu sınıflandırması, başlık oluşturma ve anahtar kelime öbeği çıkarma gibi diğer görevler için de uygun olan iki büyük ölçekli veri kümesini oluşturarak kaynak kıtlığı sorununu ele aldık. Daha sonra, bu dillerin biçim bilimsel özelliklerini metin özetlemeye uyarlayarak mevcut modeller üzerine iyileştirmeler gerçekleştirdik. Bir sonraki aşamada, önden eğitilmiş çok dilli diziden diziye modellerden yararlanarak, soyut metin özetleme ve başlık oluşturma görevleri için son teknoloji modeller oluşturduk. Biçim bilimsel açıdan zengin diller için metin özetleme değerlendirmesi çalışmaları oldukça sınırlıdır. Bu nedenle, ön işlemenin değerlendirme sonuçlarını nasıl büyük ölçüde etkileyebileceğini Türkçe bir çalışmayla gösterdik. Son olarak, metin özetleme değerlendirmesi için morfosentaktik yöntemler önerip buna ek olarak bir insan yargısı veri kümesi derledik. Değerlendirme sırasında morfosentaktik yöntemlerin insan yargıları üzerindeki korelasyonu artırdığını gözlemledik. Tez kapsamında yapılan tüm çalışmalar ve veri kümeleri açık kaynak olarak kullanıma sunulmuştur.","The exponential growth in the number of documents available on the Web has turned finding the relevant piece of information into a challenging, tedious, and time-consuming activity. Accordingly, automatic text summarization has become an important field of study by gaining significant attention from the researchers. Recent progress in deep learning shifted the research in text summarization from extractive methods towards more abstractive approaches. The research and the available resources are mostly limited to the English language, which prevents progress in other languages which especially differ in terms structure and characteristics such as the morphologically rich languages (MRLs). In this thesis, we mainly focus on abstractive text summarization on two MRLs, Turkish and Hungarian, and address their important challenges. Firstly, we tackle the resource scarcity problem by curating two large-scale datasets for Turkish (TR-News) and Hungarian (HU-News) aimed for text summarization, but are also suitable for other tasks such as topic classification, title generation, and key phrase extraction. Then, we utilize the morphological properties of these languages and adapt them to summarization where we show improvements upon the existing models. Later, we make use of pretrained multilingual sequence-to-sequence models and provide state-of-the-art models for abstractive text summarization and title generation tasks. Evaluation of text summarization for MRLs is very limited. Thus, we show how preprocessing can drastically influence the evaluation results through a case study in Turkish. Finally, morphosyntactic methods are proposed for text summarization evaluation and a human judgement dataset is curated. It is shown that morphosyntactic tokenization processes during evaluation increase correlation with human judgements. All the work and the curated datasets are made publicly available."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kullanıcı yorumları, hata raporları, özellik istekleri ve uygulama hakkında övgü veya eleştiri nedenleri gibi mobil uygulamalar için değerli bilgiler içermektedir. Yorumların manuel analizi, bir uygulama için alınan çok sayıda yorum nedeniyle maliyetli olabilmektedir. Kullanıcı yorumlarını etiketlemek için gereken çabayı azaltmak için, literatür derin dil modellerini araştıran birkaç çalışma dışında, genellikle sığ makine öğrenme yöntemlerine odaklanmaktadır. Bu tez i. uygulamaların kalitesini ve iş stratejisini eleştiren yorumları ayırt etmek için yeni bir etiket tanımlar, ii. 2230 adet manuel etiketlenmiş kullanıcı yorumları verisi sunar ve iii. kullanıcı yorumları sınıflandırılması için BERT, RoBERTa, DeBERTa, GPT-3 (ada) ve GPT-3 (curie) modellerinin performansını inceler. Sonuçlarımız, GPT-3 (curie)'nin BERT modelinden önemli ölçüde daha iyi performans gösterdiğini göstermektedir, ancak F1-puanı açısından geri kalan arasında anlamlı bir fark yoktur. Ayrıca, sınıflandırma sürecinden elde edilen yorumlardan yaygın konuları ve tartışmaları belirlemek ve yakalamak için konu çıkarımı yaparak pipeline'imizi genişletiyoruz. Bu ek adım, kullanıcı geri bildirimleri içinde yaygın olan konuları daha derinlemesine anlamamızı sağlar.","User reviews include valuable information for mobile applications such as bug reports, feature requests, and rationale for praising or criticising about the application. Manual analysis of the reviews is costly due to the vast number of reviews received for an application. To reduce this manual effort, the literature mainly focuses on shallow machine learning methods with few studies investigating the deep language models to assign labels to the reviews. This thesis i. defines a new label to distinguish reviews criticising the quality and business strategy of applications, ii. presents a new manually annotated dataset of application reviews of size 2230, and iii. studies the performance of BERT, RoBERTa, DeBERTa, GPT-3 (ada), and GPT-3 (curie) models for review classification. Our results indicate that GPT-3 (curie) significantly outperforms the BERT yet there is no significant difference among the rest considering the F1-score. Additionally, we extend our pipeline by performing topic extraction to identify and capture common themes and topics from the reviews resulting from the classification pipeline. This additional step allows us to gain deeper insights into the prevalent subjects and discussions within the user feedback."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevrimiçi sosyal ağlar gibi birçok yazılım sistemi, kullanıcılarının çevrimiçi olarak kendileri hakkında bilgi paylaşmasına olanak tanır. Ancak kullanıcılar, içerik paylaşmanın mahremiyetle ilgili sonuçlarından endişe duyarlar. Bu kararları vermek zahmetli bir süreçtir ve mahremiyet yönetimini zorlaştırır. Kullanıcıların mahremiyetlerini yönetmelerine yardımcı olan son yaklaşımlar, bir kullanıcının içeriğinin mahrem olup olmadığını önerebilen kişisel asistanlar inşa etmeyi kapsar. Ancak mahremiyetin muğlak doğası ve asistanların karar verme sürecini açıklamadaki güçlükler, kullanıcıların bu sistemlere olan güvenini ve bu nedenle yaygın bir şekilde benimsenmesini engelleyen zorluklardır. Bu tezde, her iki zorluğun da üstesinden gelmeye yardımcı olabilen güvenilir mahremiyet asistanları tasarlıyoruz. İlk olarak, kullanıcının mahremiyet kararları almasına yardımcı olan PURE isminde bir kişisel asistan öneriyoruz. PURE'ün önemli bir özelliği, kararlarındaki belirsizliği açıkça modelleme yeteneğidir. Belirsizlik yüksek olduğunda, tahmin yapılmaz ve karar kullanıcıya bırakılır. PURE, kullanıcının mahremiyet anlayışını dikkate alarak önerilerini kişiselleştirebilir. Kişisel asistanlara duyulan güveni artırmada ikinci önemli faktör, karar verme süreçlerini açıklama yetenekleridir. İkinci mahremiyet asistanımız PEAK, gizli konuları ve tanımlanan açıklama kategorilerini kullanarak önerileri için açıklamalar üretebilmektedir. Bir kullanıcı çalışması, kullanıcıların PEAK'in açıklamalarını yararlı ve kolay anlaşılır bulduğunu göstermektedir. Ayrıca, mahremiyet asistanları, açıklamaları kendi karar süreçlerini iyileştirmek için kullanabilir; bu, PEAK'i PURE'e entegre ederek gösterilmiştir ve bu durumda belirsizlik içeren resimler kullanıcıya devredilirken model performansı etkilenmez. Genel olarak, çalışmamız, kullanıcıların mahremiyetini koruyabilen güvenilir kişisel asistanların geliştirilmesine önemli bir katkı sağlamaktadır.","Many software systems, such as online social networks, enable their users to share information about themselves online. However, users worry about the privacy implications of sharing content. It's a tedious process to make privacy decisions and it makes managing privacy difficult. Recent approaches to help users manage their privacy involve building personal assistants that can recommend whether a user's content is private or not. However, privacy's ambiguous nature and difficulties in explaining assistants' decision-making are challenges hampering users' trust in these systems and therefore also widespread user adoption. In this dissertation we design trustworthy privacy assistants that can help tackle both challenges. We first propose a personal assistant called PURE that integrates machine learning to make predictions on whether a user would identify an image as private or not. An important characteristic of PURE is its ability to model uncertainty in its decisions explicitly. When uncertainty is high, no prediction is made and the decision is delegated to the user. By factoring in user's own understanding of privacy, PURE is able to personalize its recommendations. A second crucial factor in fostering trust in personal assistants is their ability to explain their decision-making processes. Our second assistant PEAK is capable of generating such explanations for its recommendations, using latent topics and predefined explanation categories to do so. A user study shows users find PEAK's explanations useful and easy to understand. Additionally, privacy assistants can use the explanations to improve their own decision-making, with the incorporation of PEAK into PURE resulting in less uncertain images delegated to the user whilst model performance is not compromised. Overall, our work makes an important contribution towards the development of trustworthy personal assistants capable of preserving users' privacy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İlaç-protein etkileşimi tahmini için yapılan fiziksel deneyler pahalı olduğundan ve önemli ölçüde zaman gerektirdiğinden hesaplamalı yöntemler deneylerin ön aşamaları için alternatif olabilir ve araştırmanın gidişatına kılavuzluk edebilirler. Son zamanlarda moleküllerin temsilini bulmak için doğal dil işleme yöntemlerinin kullanılması yaygınlaştı ve bu yöntemlerle başarılı sonuçlar elde edildi. Biz bu çalışmada protein ve ligantların doğal diller gibi kendilerine özgü dillerinin olduğunu varsayıp, kelime olarak adlandırdığımız küçük anlamlı parçalarının da olduğunu öne sürüyoruz. Protein ve ligantların kelimelerini bir alt kelime belirleme yöntemi yardımıyla protein ve ligantların tek boyutlu dizilimlerini kullanarak elde ediyoruz. Girdiyi heterojen ağ çizgesi olarak gösterip, ağ çizgesindeki dört farklı çeşite (protein, ligant, protein kelimesi, ligant kelimesi düğümleri) sahip her düğümün temsilini öğreniyoruz. Protein ve ligantlar arasındaki bağlanma kuvvetini tahmin etmek için öğrendiğimiz temsilleri tahmin modeline besliyoruz. Sonuç olarak, bilinmeyen protein ve/veya ligantların temsilleri için onların kelimelerinin temsillerinin kullanılmasının, kelimelerin kullanılmadığı duruma göre daha iyi sonuçlar verdiğini gösteriyoruz. Yeni moleküllerin temsillerini öğrenmek için girdi ağ çizgesini tekrar eğitmediğimizden, önceden eğitilmiş kelime temsillerinin daha önce görülmemiş moleküller için kullanılması hesaplama karmaşıklığı açısından da verimlidir.","Wet-lab experiments to predict the affinity of drugs for their targets are costly and time consuming. Computational methods can provide an alternative to early stage experiments and guide the research process. Recently, the use of natural language processing techniques to represent molecules has become popular and has led to successful results. In our work, we assume that proteins and ligands, like human languages, have their own languages and that these languages consist of meaningful smaller parts that we call words. We identify protein and ligand words based on their 1D sequences using a subword tokenization method and represent protein-ligand interactions with a heterogeneous graph consisting of four different node types corresponding to proteins, ligands, protein words, and ligand words. A graph-based approach is used to learn embeddings for the nodes in the graph. These embeddings are fed into a deep learning model for predicting protein-ligand binding affinity. We show that using their word embeddings to represent novel proteins and/or ligands not present in the training set improves the results compared to the case where no words are used. Using pre-trained word embeddings for previously unknown molecules is also efficient in terms of complexity, as we do not need to re-train the input graph to learn the embeddings for these new molecules."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Morfolojik, yani biçimbirimsel çözümleme, kelimelerin bilgisayarca kökleri ile eklerine ayrılması işidir. Türkçe için çeşitli çözümleyiciler vardır; bunlar başarılı bir şekilde, özellikle çekim eklerinin yapısını çözümleyebilirler. Fakat literatürde kimi yabancı kökenli kelimelerin bükümlü yapısının analizi, ön eklerin desteklenmesi, yapım eklerinin geniş bir şekilde kapsanması yönünden kimi eksiklikler vardır. Bu eksikliklere çözüm aramak için bu tezde Türkçe için yeni birtakım normlara dayanan bir hesaplamalı morfolojik işleme çerçevesi tanımlanıp uygulanmıştır. Bu ilkeler, doğal dil işleme alanındaki güncel olanaklar ile gereksinimlere dayanır. Bunların başında dönüştürücü (transformer) tabanlı, önceden eğitilmiş büyük dil modelleri ile ince ayarlama yaklaşımları gelir. Çerçeve, dil kaynakları yapısının açıklamasını, kelimelerin tüm olası çözümlemelerini inceleyen bir morfolojik analizciyi, analizci çıktıları arasından doğru hipotezi seçen bir morfolojik muğlaklık gidericiyi ve bu araçlar için hata analizi modüllerini içermektedir.","Morphological parsing is the computational task of breaking down words into their roots and affixes. There are several successful morphological parsers for Turkish, especially for inflectional morphology. However, there is a gap in the literature concerning the analysis of fusional properties of foreign-origin words, support for prefixes, and comprehensive derivational suffix coverage. To address this gap, this thesis describes and implements a new computational morphological processing framework for Turkish with novel principles. These principles are based on the recent opportunities and requirements in the natural language processing field, namely the transformer-based pre-trained large language models and fine-tuning approaches. The framework contains a description of language resources structure, a morphological analyzer that examines all possible parses of a word, a morphological disambiguator that picks the correct hypothesis among analyzer outputs, and error analysis modules for these tools."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yeni nesil mobil haberleşme ağları, yeni hizmet ve ihtiyaçları karşılamak için, milimetrik dalga kullanımları, bulut tabanlı mimariler ve yeni akıllı algoritmalar gibi kritik kolaylaştırıcı teknolojiler üzerine kurulmaktadır. RRM (""Radio Resource Management"" - Radyo Kaynakları Yönetimi) uygulamaları bu yeni nesil ağlar için önemli bir araştırma alanıdır. Bu tezde, CMAB (""Contextual Multi-Armed Bandit"" - Bağlamsal Çok Kollu Haydut) algoritması konsepti ve O-RAN (""Open Radio Network"" - Açık Radyo Ağı) mimarisi dikkate alınarak pekiştirmeli öğrenmeye dayalı bir HO (""Handover"" - aktarım) mekanizması tasarlanmıştır ve algoritmaya CHARM (""CMAB-Based Handover Algorithm in Reinforcement Mechanism"" - Pekiştirme Mekanizmasında CMAB Tabanlı Aktarım Algoritması) ismi verilmiştir. Kullanıcı ekipmanlarının hareket hızı ve hizmet veren baz istasyonunun sinyal-parazit artı gürültü oranı (SINR), algoritma için bağlam bilgisi olarak değerlendirilmektedir. Önerilen algoritma, 3. Nesil Ortaklık Projesinin (3GPP) geleneksel algoritması ve literatürdeki rakip bir pekiştirmeli öğrenme algoritması ile UMa (""Urban Macro"" - Şehiriçi Makro), UMi (""Urban Micro"" - Şehiriçi Mikro) yayılımı ve harita üzerindeki farklı yoğunluklardaki baz istasyonu ile engel sayıları gibi kanal koşulları altında karşılaştırılmıştır. Sonuçlar, önerdiğimiz algoritmanın ortalama bilgi iletim hızı için her kanal koşulunda geleneksel 3GPP aktarım algoritmasından ve rakip algoritmadan daha iyi performans ile çalıştığını göstermektedir. Ayrıca simülasyon sonuçlarından önerdiğimiz algoritmanın ortalama aktarım sayıları için de oldukça rekabetçi bir algoritma olduğu görülmektedir.","Next-generation mobile communication networks have been established on critical enabling technologies such as millimeter-wave usage, cloud-native architectures, and new intelligent algorithms to meet the increasing demands of new services and requirements. One important research area for the new generation of networks is Radio Resource Management (RRM) applications. In this thesis, a reinforcement learning-based handover (HO) mechanism is designed by the concept of Contextual Multi-Armed Bandit (CMAB) algorithm named CHARM (CMAB-Based Handover Algorithm in Reinforcement Mechanism) and considering Open-Radio Access Network (O-RAN) architecture. The speed of user equipment (UE) and Signal-to-Interference-plus-Noise Ratio (SINR) of the serving Base Station (BS) parameters are evaluated as the context information for the algorithm. The proposed algorithm is compared with the traditional algorithm of 3rd Generation Partnership Project (3GPP) and a rival reinforcement algorithm in the literature under different channel conditions such as Urban Macro (UMa), Urban Micro (UMi) propagation, and different intensities of BS and obstacles on the map. The results show that our algorithm outperforms the traditional 3GPP HO algorithm and the rival algorithm for average information rate under every channel condition. According to the simulations, it is also highly competitive for average HO numbers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevik metodolojiler, son yıllarda giderek daha popüler hale gelmiştir. Doğası gereği çevik metodolojiler, geniş bir uzmanlık yelpazesine sahip paydaşları içerir ve aralarında işbirliğine ve müşteri katılımına dayanan etkileşim gerektirir. Bu nedenle çevik metodolojiler, daha verimli ve etkili süreçlerin sürdürülmesi için tüm ekip üyeleri arasındaki işbirliğini teşvik eder. Gereksinimlerin oluşturulması projenin çeşitli yönlerini tanımlayan ve önemli kavramlar hakkında ortak bir anlayışa sahip birden fazla paydaşın katılımını gerektirdiğinden işbirlikçi ortamlarda zor bir görev olabilir. Doğal dil ile gereksinimleri oluşturmanın basit bir yöntemi, bir projenin üzerinde uzlaşılan özelliklerini belgeleyen kullanıcı hikayeleridir. Paydaşlar, kullanıcı hikayeleri oluştururken bütünlük için çaba sarf ederler, ancak oluşturulan kullanıcı hikayesi seti yine de kusurlu olabilir. Bu sorunu ele almak için, doğal dil işleme metodları ile kullanıcı hikayelerinden anahtar kavramları çıkartan ve çıkarttığı bu kavramlar arasındaki ilişkileri kullanarak bir bilgi çizgesi oluşturan SCOUT'u öneriyoruz. SCOUT, oluşturulan bilgi çizgesi ve farklı buluşsal yöntemleri kullanarak paydaşlar için öneriler üreterek kullanıcı hikayesi setlerinin kalitesinin ve eksiksizliğinin arttırılmasını sağlar. SCOUT'u değerlendirmek ve kullanıcı hikayeleri oluşturma konusundaki performansını göstermek için bir kullanıcı çalışması gerçekleştirdik. Niceliksel ve niteliksel sonuçlar, SCOUT'un kullanıcı hikayesi setlerinin kalitesini ve eksiksizliğini önemli ölçüde artırdığını göstermektedir. Sağladığımız katkı üç yönlüdür. İlk olarak, hem bireylerin hem de diğer ekip üyelerinin katkılarını kullanarak kullanıcı hikayelerine dahil edilecek yeni kavramlar önermek için buluşsal yöntemler geliştirdik. İkinci olarak, kullanıcı hikayeleri yazmayı ve kalitelerini sağlamayı desteklemek için açık kaynaklı bir ortak çalışma aracı geliştirdik. Üçüncüsü, deney düzeneğini ve materyallerini paylaştık.","Agile methodologies have become increasingly popular in recent years. Due to its inherent nature, agile methodologies involve stakeholders with a wide range of expertise and require interaction between them, relying on collaboration and customer involvement. Hence, agile methodologies encourage collaboration between all team members so that more efficient and effective processes are maintained. Generating requirements can be challenging, as it requires the participation of multiple stakeholders who describe various aspects of the project and possess a shared understanding of essential concepts. One simple method for capturing requirements using natural language is through user stories, which document the agreed-upon properties of a project. Stakeholders try to strive for completeness while generating user stories, but the final user story set may still be flawed. To address this issue, we propose SCOUT: Supporting Completeness of User Story Sets, which employs a natural language processing pipeline to extract key concepts from user stories and construct a knowledge graph by connecting related terms. The knowledge graph and different heuristics are then utilized to enhance the quality and completeness of the user story sets by generating suggestions for the stakeholders. We perform a user study to evaluate SCOUT and demonstrate its performance in constructing user stories. The quantitative and qualitative results indicate that SCOUT significantly enhance the quality and completeness of the user story sets. Our contribution is threefold. First, we develop heuristics to suggest new concepts to include in user stories by considering both the individuals' and other team members' contributions. Second, we implement an open-source collaborative tool to support writing user stories and ensuring their quality. Third, we share the experimental setup and materials to evaluate the SCOUT."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Temsil öğrenimi, derin öğrenme görevlerinin önemli bir parçasıdır. Tanıma, oluşturma ve sınıflandırma modellerinde iyi performans elde etmek, büyük ölçüde anlamlı ve güvenilir temsilleri öğrenmeye bağlıdır. Gereksiz ayrıntılardan etkilenmeyen bilgilendirici temsiller toplamak, her koşulda önemlidir. İşaret Dili Tanıma (İDT), derin öğrenme modellerinin başarıyla kullanıldığı alanlardan biridir. İşaret dili, işitme ve konuşma engelli insanlarla iletişimde kullanılan birincil iletişim aracıdır. İşaret dilini bilenler ve bilmeyenler arasında bilgi alışverişini sağlamak için kullanılan işaret dili tanıma modelleri vardır. İşaret dili tanıma modellerinin girdileri videolar olduğundan, Evrişimsel Sinir Ağları, tanıma modellerinin temel parçalarından biridir. Bununla birlikte, Evrişimsel Sinir Ağları tabanlı tanıma modelleri, yüz özellikleri, el ve vücut şekli ve ten rengi gibi kimlik ilintili özellikleri yakalama ve kodlama eğilimindedir. Bu, yüz tanıma modelleri, yürüyüş tanıma modelleri, görüntü manipülasyonu modelleri veya kişi yeniden tanımlama modelleri gibi görsel derin öğrenme modellerinde yaygın rastlanan bir sorundur. Bu tezde, İDT modellerinin işaretçi özelliklerinden etkilenmemesi için işaret ve işaretçi temsillerindeki gizli faktörleri ayırmak ve işaretçi özelliklerinden kaynaklanan ilgisiz bilgilerini ortadan kaldırmak için işaretçi bilgisinden ayıklanmış bir temsil öğrenme yöntemi önerilmiştir. Düzenlileştirilmiş hasmane eğitim de dahil olmak üzere çeşitli ayıklanmış öğrenme teknikleri araştırılmıştır. Deneyler, izole edilmiş iki Türk işaret dili veri kümesi üzerinde yapılmıştır. Özellik ayıklamanın etkisi ve tanıma performansını iyileştirme potansiyeli, niteliksel ve niceliksel analizlerle tartışılmıştır.","Representation learning is an essential part of all deep learning tasks. Achieving good performance in recognition, generation, and classification heavily depends on learning meaningful and reliable representations. It is important to gather informative representations that are not affected by unnecessary details in all cases. Sign Language Recognition is one of the areas where deep learning models have been successfully used. Sign Language Recognition (SLR) is essential to exchange information between those who know sign language and those who do not. The input of an SLR model is a video in which an individual performs a sign or multiple signs. Therefore, Convolutional Neural Networks (CNN) are commonly a part of deep learning-based SLR frameworks. However, CNN-based recognition frameworks tend to capture the characteristics of the identity in the foreground, such as face attributes, hand and body shape, and skin color. This challenge is often encountered in problems such as face and gait recognition, image manipulation, and person re-identification problems. In this thesis, a disentangled representation learning framework is proposed to separate the latent factors in the sign and signer representations and eliminate the irrelevant identity information to improve sign recognition performance. Various disentanglement techniques, including regularized adversarial training, are investigated. Experiments are conducted on two isolated Turkish sign language benchmark datasets. The effect of feature disentanglement and its potential to improve recognition performance are discussed with qualitative and quantitative analysis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Birçok ülke küresel iklim değişikliğinin sonuçlarına farklı derecelerde maruz kalmaktadır ve bu ülkelerin etkilenebilirlikleri sosyoekonomik ve çevresel faktörlere göre değişmektedir. Bireyler, toplumlar ve ülkeler iklim değişikliğinin etkilerinin farkında olmalıdır. Tehlikelere ne kadar maruz kaldıklarının, etkilenebilirlik düzeylerinin ve ne yapılması gerektiğinin bilinmesi ve anlaşılması, temel yaşamsal faaliyetlerin devamı için kritik önem taşımaktadır. Gelecekte bir ülkenin iklim değişikliğinden ne kadar etkileneceğinin veya hangi yaşamı destekleyen sektörlerinin ne kadar zarar göreceğinin doğru tahmin edilmesi, ülkelerin önlem alabilmesi açısından büyük önem taşımaktadır. Bu nedenle bu çalışmada, ülkelerin iklim değişikliğine karşı etkilenebilirliklerini tahmin etmek için Notre Dame Küresel Uyum İnisiyatifi (ND-KUİ) Ülke İndisi verileri kullanılmıştır. ND-KUİ ülkelerin iklim bozulmalarından ne kadar etkilenebilir olduğunu gösteren açık kaynaklı bir indistir. Bu indisin verileri, 1995'ten 2020'ye kadar 26 yıllık bir dönemde 182 ülke için etkilenebilirlik puanlarını ve gıda, su, sağlık, ekosistem hizmetleri, insan yaşam alanı ve altyapı olmak üzere yaşamı destekleyen altı alanı içermektedir. Uzun kısa süreli bellek (LSTM) ağ tabanlı model yedi ülkenin 2021'den 2026'ya kadar olan altı yıllık verilerini tahmin etmek için oluşturulmuştur. Bu ülkeler Türkiye, Avustralya, Almanya, Portekiz, Sudan, Gürcistan ve Kırgistan'dır. Sonuçlar, modelin 2021 yılı için Sudan hariç tüm ülkelerin etkilenebilirlik puanlarında artış, 2021 sonrasında ise Almanya ve Avustralya'da hafif bir düşüş, Türkiye, Portekiz ve Kırgızistan'da düşüş öngördüğünü göstermiştir. Model tüm yıllar için Sudan'da düşüş, Gürcistan'da ise artış öngörmüştür. Modelin başarısı 2010'dan 2020'ye kadar olan veriler kullanılarak test edilmiştir. Zaman serisi tahmini zor olsa da tahmin edilen değerler gerçek değerlere yakındır. Başka hiçbir çalışma ülkelerin gelecek yıllardaki iklim değişikliğine karşı etkilenebilirliklerini tahmin etmediği için bu çalışma yenidir.","Many countries are subject to the consequences of global climate change at varying degrees, and their vulnerability varies according to socioeconomic and environmental factors. Individuals, societies, and countries must be aware of the effects of climate change. Knowledge and understanding of how exposed they are to hazards, their level of vulnerability, and what must be done are critical for the continuation of basic vital activities. Accurately predicting how much a country will be affected by climate change in the future or which life-supporting sectors will suffer is crucial for countries to take precautions. Therefore, in this study, The Notre Dame Global Adaptation Initiative (ND-GAIN) Country Index's data is used for predicting countries' vulnerability to climate change. It's an open-source index that displays how vulnerable a nation is to climate disruptions. The data for this index includes scores for vulnerability and six areas that support life, including food, water, health, ecosystem services, human habitat, and infrastructure, for 182 nations during a 26-year period from 1995 to 2020. Long short-term memory (LSTM) network-based model is built to predict seven countries' six years of data from 2021 to 2026. These countries are Turkey, Australia, Germany, Portugal, Sudan, Georgia, and Kyrgyzstan. The results showed that the model predicts an increase in the vulnerability scores of all countries except Sudan for 2021, a slight decrease in Germany and Australia, and a decrease in Turkey, Portugal, and Kyrgyzstan after 2021. The model predicts a decrease in Sudan and an increase in Georgia for all years. The model's successes are tested using data from 2010 to 2020. Although time series forecasting is challenging, forecasted values are close to actual values. This study is novel since no other studies have predicted countries' future years' vulnerability to climate change."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Finansal piyasalardaki volatilite tahmini, risk yönetimi ve varlık fiyatlandırma gibi alanlarda büyük önem taşır. Bu çalışmada, BIST 100'ün 1 gün, 5 gün ve 10 gün sonrası getiri volatilitesi incelenmiştir. GARCH ailesi modellerinin tahminlerini iyileştirmek için iki tür hibrit model kullanılmıştır. İlk hibrit model, GARCH ailesi modellerinin volatilite tahminlerini girdi olarak kullanırken ikinci hibrit model ise sinir ağlarının öğrenme sürecini yürütmesi için girdi olarak volatilite tahminleri yerine GARCH ailesi modellerinin spesifikasyonlarını almıştır. Hibrit sinir ağları ayrıca bir dizi değişkenle beslenmiştir. Bu değişkenler yabancı fiyat endeksleri, teknik analiz ve kukla değişkenlerden oluşmuştur. Ana sonuçlardan biri, her iki hibrit modelin de GARCH ailesi modellerinin tahmin kesinliğini arttırdığı, ikinci hibrit modelin ise bu çalışmada kullanılan tüm hata ölçütleri için daha iyi volatilite tahminleri sağladığıdır. Eşit tahmin doğruluk testi ayrıca hibrit modellerin örneklem dışı tahminlerinin GARCH ailesi yöntemlerinden istatistiksel olarak anlamlı ölçüde daha iyi olduğunu göstermiştir. Tahmin ufku genişledikçe tüm model performansları kötüleşirken, en keskin düşüş GARCH ailesinden ziyade hibrit modellerde yaşanmıştır. Son olarak, sinir ağı mimarisinin karmaşıklığı arttıkça hibrit modellerin sonuçları genel olarak iyileşirken, gizli katman başına kullanılan nöron sayısı en yükseğe çıktığında modellerin örneklem içi gözlemleri ezberlemeye başladığı görülmüştür.","Volatility forecasting in the financial markets is important in the areas of risk management and asset pricing, among others. In this study, BIST 100's 1-day, 5-day, and 10-day-ahead return volatilities are examined. Two types of hybrid models are utilized to improve individual GARCH-family models' predictions. For the first hybrid model, a group of GARCH-family models is constructed to produce volatility estimates which were then fed into neural network to increase the predictive power. The second hybrid model received GARCH-family models' specifications instead of volatility estimates as inputs for ANN to conduct the learning process. Hybrid neural networks were also fed a set of exogenous, endogenous, and dummy variables. One of the main conclusions is that both hybrid models increased the forecasting precision of individual GARCH-family models while the second hybrid model provided better volatility forecasts for all error measures used in this study. Equal forecast accuracy test also showed that the hybrid models' out-of-sample predictions were significantly better than GARCH-family methods. All model performances deteriorated as forecast horizon was extended, although the steepest decline happened for hybrid models rather than the GARCH-family. Lastly, as the complexity of the neural network architecture was increased, the loss measures for the out-of-sample forecasts improved except on the last case where the network overfitted using the highest number of neurons per hidden layer among the searched hyperparameter grid."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaret dili, kavramları iletmek için elleri, kolları ve yüzleri kullanan görsel bir dildir. Son on yılda, işaret dili tanıma (SLR) araştırmaları önemli ilerleme kaydetmiştir, ancak işaretleri tanımak için hala büyük miktarda veri gerekmektedir. İşaret dilleri için işaretlenmiş büyük işaret dili veri kümeleri oluşturulması için harcanan kaynaklara rağmen, günlük kullanıcılar için çeviri yapabilen uygulamalar henüz üretilebilmiş değildir. Buna ek olarak, işaret dili tanıma araştırmalarının çoğu birkaç popüler işaret diline odaklanmakta ve Türk İşaret Dili (TİD) de dahil olmak üzere işaret dillerinin çoğu gelişen işaret dili teknolojileri için yetersiz kaynaklara sahip diller olarak kalmaktadır. Bu tez, TİD için işaret dili tanıma teknolojilerinin geliştirilmesiyle ilgili bir dizi açık araştırma sorusunu ele almaktadır. Bu kapsamda, 22 bin video içeren izole bir TİD SLR veri seti olan BosphorusSign22k oluşturulmuş ve bu veri setinde literatürdeki en başarılı yöntemleri kullanarak tanıma sonuçları kıyaslanmıştır. İkinci olarak, işaretleri dinamik ve statik alt birimler olarak modellemek için hizalanmış zamansal birikimli öznitelikler (ATAF) yöntemi önerilmiştir. Geliştirilen yöntem, diğer kipleri kullanan yöntemlerle birleştirildiğinde literatürde BosphorusSign22k veri kümesinde elde edilen en yüksek sonucu elde etmektedir. Ardından, düzenlileştirilmiş regresyona dayalı çoklu görev öğrenme ile SLR yapmak için kanonik zaman hizalama adı verilen, farklı kaynaklar arasındaki tutarsızlıkları en aza indiren ve sınıf farklılıklarını vurgulayan bir işaret hizalama ve guruplama yöntemi önerdik. Son olarak, mevcut iki TİD tanıma veri kümesi kullanarak çapraz veri-kümesi öğrenme transferi için bir kıyaslama veri kümesi oluşturulmuştur. Bu veri kümeleri üzerinde, zamansal çizge sinir ağları tabanlı SLR yöntemleri kullanarak beş denetimli transfer öğrenme algoritması değerlendirilmiş ve dayanak teknikler üzerinde önemli bir gelişme sağladığı ortaya koyulmuştur.","Sign languages are visual languages that use hands, arms, and faces to communicate concepts. In the last decade, sign language recognition (SLR) research has made significant progress but still requires massive amounts of data to recognize signs. Despite efforts to create large annotated sign language datasets, applications that can translate for ordinary users in daily settings are yet to be produced. Most SLR research focuses on a few popular sign languages, leaving most sign languages, especially Turkish Sign Language (TID), under-resourced for sign language technology development. This dissertation addresses several open research questions about the development of SLR technology for TID from several perspectives. We generated BosphorusSign22k, an isolated SLR dataset for TID with 22k videos, and benchmarked state-of-the-art techniques on it. We proposed aligned temporal accumulative features (ATAF) to efficiently model sign language movements as dynamic and static subunits. Combined with methods using other modalities, the method achieves state-of-the-art performance on BosphorusSign22k. We then used regularized regression-based multi-task learning and presented task-aware canonical time warping for isolated SLR. The technique aligned and grouped signs to minimize discrepancies across different sources and emphasize class differences. Finally, we established a benchmark for cross-dataset transfer learning in isolated SLR. We evaluated supervised transfer learning algorithms using a temporal graph convolution-based SLR method. Experiments with closed and partial-set cross-dataset transfer learning reveal a substantial improvement over combined training and fine-tuning-based baseline techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Doğal dil (NL), daha az zaman ve enerji gerektirdiği için kullanıcı gereksinimlerini ifade etmek için kullanılır. Gereksinimleri toplamanın çeşitli yolları vardır ve kullanıcı hikayeleri yarı yapılandırılmış formata bir örnektir. Öğrenme ve anlama kolaylığı nedeniyle çevik yöntemlerde kullanıcı ihtiyaçlarını yakalamak için yaygın olarak kullanılırlar. Bununla birlikte, kullanıcı hikayeleri yeterince geniş olabilir ve bu da aralarındaki ilişkilerin okunmasını ve anlaşılmasını zorlaştırır. Bu tür ilişkiler, geliştiricilerin projenin yapısını anlamasını kolaylaştırır. Öte yandan hedef modelleri, hedefler arasında üst düzey bir perspektif ve açık ilişkiler sağlar, ancak oluşturulması zaman ve çaba gerektirir. İlk olarak, hedef modellerinin veri setini okumak ve anlamak için kullanışlılığını göstermek üzere bir deney gerçekleştiriyoruz. Bu tez, doğal dil işleme (NLP) tekniklerini uygulayarak bir dizi kullanıcı hikayesinden otomatik olarak bir hedef modeli oluşturmak için bir hedef modeli oluşturma aracı önermektedir. İlk olarak, kullanıcı hikayeleri kümesinde belirtilen roller, eylemler ve faydalar arasındaki ilişkileri korumak için bir dizi kullanıcı hikayesinden çıkarılan bilgileri bir grafik veritabanında ayrıştırıp saklıyoruz. Çizge veritabanındaki bilgileri kullanarak hedef model stratejilerini oluşturuyoruz, bu da düğümler ve kenarlar arasındaki bağlantıları görmemizi sağlıyor. NLP teknikleri ve çeşitli sezgisel yöntemler uygulayarak, insan yapımı modellere benzeyen hedef modelleri üretiyoruz. İkinci olarak, ArTu aracının hedef modellerin oluşturulmasını hızlandırıp hızlandırmadığını belirleyen hedef model oluşturma aracı için bir değerlendirmeye katkıda bulunuyoruz. Araçlı çizilmiş bir hedef model ile araçsız çizilmiş bir hedef model arasındaki zaman farkını değerlendirmek için çapraz bir deney gerçekleştiriyoruz. Bu deney bulgularını karşılaştırmak için çeşitli hipotezler ortaya koyduk. Deneysel veriler üzerinde yapılan çeşitli istatistiksel analizlerin sonuçlarını incelediğimizde, ArTu aracının hedef modelleri oluşturmak için gereken süreyi önemli ölçüde azalttığını görmekteyiz.","Natural language (NL) is used to express stakeholder requirements since it requires less time and energy. There are several ways to collect requirements, and user stories are an example of a semi-structured format. They are commonly used to capture user needs in agile methods due to their ease of learning and understanding. However, user stories can be large enough which makes it difficult to read and understand the relations among them. Such relations make it easier for developers to understand the structure of the project. Goal models, on the other hand, provide high-level perspective and explicit relations among goals but they require time and effort to build. First, we conduct an experiment to show the usefulness of the goal models for reading and comprehending the data set. This thesis proposes a goal model builder tool to automatically generate a goal model from a set of user stories by applying natural language processing (NLP) techniques. We first parse and store the extracted information from a set of user stories in a graph database to maintain the relations among the roles, actions, and benefits mentioned in the set of user stories. We create the goal model strategies using the information in the graph database, which enables us to see the connections between the nodes and edges. By applying NLP techniques and several heuristics, we produce goal models that resemble human-built models. Second, we contribute an evaluation of the goal model builder tool that determines whether the ArTu tool speeds up the creation of goal models. A cross-over experiment has been carried out to evaluate the time difference between a goal model with the tool and one without the tool. We put out a variety of hypotheses to contrast experiment findings. The results of several statistical analyses run on the experimental data show that the ArTu tool significantly reduced the time needed to build goal models."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tavsiye sistemleri; milyarlarca öge arasından, onlar ile ilgili ögeleri kullanıcılara önermeye yardımcı olan teknoloji temelli çözümlerdir. Bu; bir film, yemek, tatil yeri, ayakkabı veya bir müzik parçası gibi herhangi bir şey olabilir. Sıralı ve oturum tabanlı tavsiye sistemleri, geleneksel tavsiye sistemlerinden farklı olarak kullanıcıların öğelerle etkileşim sırasına dikkat ederek öneriler yaparlar. Bu tür sistemlerin avantajı değişen zevkleri dikkate almalarıdır. Ayrıca, bazı yasal gereklilikler nedeniyle zaman zaman kullanıcıların verileri toplanamamaktadır ve tavsiye sistemi o oturumda elde edilen bilgilerle öneri yapmak zorunda kalmaktadır. Bu gibi nedenler, sıralı ve oturum tabanlı tavsiye sistemlerinin önemini oluşturur. Bu tezde, Transformers4rec framework kullanarak sıralı ve oturum tabanlı tavsiye sistemleriyle deneyler yapılmıştır. Transformatör mimarilerinin kısa etkileşim serilerinde daha iyi çalıştığı gözlemlenmiştir. Özellikle zaman tabanlı öznitelikler olmak üzere, ek özniteliklerin sonuçları iyileştirdiği gösterilmiştir. Ayrıca, sonuçların veri boyutu, şekli ve türüne göre değiştiği incelenmiş ve yorumlanmıştır.","Recommender systems are technology-based solutions that assist users by suggesting relevant items among millions of items. It could be anything like a movie, a meal, a vacation spot, shoes, or a piece of music. Unlike traditional recommender systems, sequential and session-based recommender systems make recommendations by paying attention to the order of items that users interact with. The advantage of such systems is that they take into account varying tastes. Additionally, due to some legal requirements, the users' data cannot be collected from some platforms, and the recommender system has to suggest the session's information without having any previous knowledge. It may only have to recommend products according to a few interactions in that session. These reasons constitute the importance of sequential and session-based recommender systems. In this thesis, we have experimented with sequential and session-based recommender systems using the Transformers4rec framework, which allows us to use transformer architectures in recommender systems. We observed that transformer architectures work better in short interaction sequences than long ones. We showed that additional features enhance the model's performance, particularly time-based features. Additionally, we examined and interpreted that the importance of features changes according to the size, shape, and type of data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Enfeksiyonlar, dünya çapında büyük bir sorundur. Konak ve patojenler arasındaki protein etkileşimlerini belirlemek, enfeksiyon mekanizmalarını anlamak, önleme ve tedavi stratejileri geliştirmek için kritiktir. Bu etkileşimleri belirlemek için kullanılan laboratuvar deneyleri pahalı ve zaman alıcıdır. Bu nedenle, bilgisayar tabanlı yaklaşımların geliştirilmesi zaman ve maddi masrafları azaltabilecek umut verici bir çözümdür. 3 boyutlu protein yapılarına dair veriler, protein fonksiyonları hakkında yararlı bilgiler içerirken, dizileme teknolojisindeki ilerlemelerle 1 boyutlu dizi verileri yaygın olarak mevcuttur ve daha az bilgisayar gücü kullanılarak işlenebilirler. Bu tezin ana amacı patojen-konak protein etkileşimlerini öngörmede sadece dizi tabanlı bir yaklaşım geliştirmektir. Protein dizilerinin cümle olarak görülebileceği, dolayısıyla parçalara ayrılabileceği hipotezine dayanarak, patojen-konak etkileşimlerini tahmin etmek için dizi tabanlı bir yaklaşım geliştirilmiştir. Byte Pair Encoding (BPE) tokenize etme yöntemi protein dizilerine uyarlanmış, Metapath2Vec algoritması kullanılarak dizilerin temsillerini öğrenmek için grafik tabanlı bir yaklaşım geliştirilmiştir. Sonuçlar, proteinlerin kelime tabanlı temsillerini kullanmanın grafik tabanlı yaklaşımın performansını arttırdığını göstermektedir. Ayrıca, metin temsilleme öğrenme yöntemleri SeqVec ve ProtBERT de değerlendirilmiş ve grafik methodu ile karşılaştırılmıştır. Üç farklı veri kümesinde elde edilen sonuçlar, geliştirilen yaklaşımın umut verici olduğunu ve mevcut ileri seviye yöntemlere benzer performans elde ettiğini göstermektedir.","Infections caused by pathogens are a significant problem around the world. Determining protein interactions between pathogens and hosts is critical to understanding infection mechanisms and developing prevention and treatment strategies. Wet-lab experiments to identify protein interactions are expensive and time-consuming. Therefore, computational approaches have been proposed as a promising complementary solution. While 3D structures of proteins contain helpful information about protein functions, with advances in sequencing technology, 1D sequences of proteins are widely available and are often utilized because they are easier to process with less computational power. The main goal of this thesis is to develop a sequence-based approach for predicting pathogen-host protein interactions based on the hypothesis that protein sequences can be viewed as sentences, therefore, can be decomposed into chunks, which we refer to as protein words. We first adapt the Byte Pair Encoding (BPE) tokenization method from the field of natural language processing to protein sequences and then apply a graph-based approach using the Metapath2Vec algorithm to learn representations of sequences. The results show that incorporating a word-based representation of proteins improves the performance of the graph-based approach. In addition, two other methods for learning text representations, SeqVec and ProtBERT, are evaluated for predicting pathogen-host protein interactions. The results on three virus-host protein interaction datasets show that the sequence-based protein representation approaches are promising and achieve comparable performance to the state-of-the-art methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Küresel kamyon taşımacılığı endüstrisi, yüksek karbon emisyonları, şoför bulma sorunları, ve uzun ödeme süreleri gibi kronik sorunları uzun süredir yaşamaktadır. Bu çalışmada, kamyon taşımacılığı endüstrisi raporlarında bahsedilen daha yenilikçi teknoloji çözümlerine duyulan ihtiyaca dikkat çekiyoruz. Bu noktada, blokzincir teknolojisinin kamyon taşımacılığı operasyonlarında aracıların rolünü nasıl ortadan kaldırabileceğini veya azaltabileceğini ve yük verenler ile taşıyıcılar arasındaki işbirliğini nasıl geliştirebileceğini araştırıyoruz. Çalışmamızda, literatürde bulunan ulaşım kontrol kulesi konseptini genişleterek, konsorsiyum ve halka açık blokzincir mimarileri üzerinde merkezi olmayan bir şekilde çalıştırmayı öneriyoruz. Tasarım önerilerimizin teknik fizibilitesini deneyimli blokzincir mühendisleri ile değerlendiriyoruz. Ayrıca, yük verenler ve taşıyıcılar arasındaki işbirliklerinin önündeki engelleri kaldırmada, tasarım önerilerimizin ne kadar başarılı olacaklarını endüstrisinden ilgili profesyoneller ile değerlendiriyoruz. Yük verenler,ve orta ve büyük ölçekli taşıyıcılar, daha işbirlikçi nakliye operasyonları yürütmek için blokzincir teknolojisini kullanmaya istekli gözükmektedirkler. Bireysel küçük taşıyıcılar, rekabet endişeleri nedeniyle konsorsiyum çözümlerine daha sıcak baksalar da, yük verenlerin halka açık blokzincir çözümlerini tercih etmeleri durumunda, onlar da halka açık blokzincir çözümlerini kullanmak istemektedirler. Öte yandan, gelişmekte olan bir teknoloji olarak, blokzincirilerde kimlik yönetimi, ölçeklenebilirlik, işlemlerin gizliliği ve veri koruma düzenlemelerine uyum gibi kritik sorunların çözümleri için halen zamana ihtiyacı vardır.","The global trucking industry has been suffering from chronic problems for a long time, such as high levels of carbon emissions, driver shortages, and extended payment wait times. This study acknowledges the need for more innovative technology solutions to address those problems based on trucking industry reports. We investigate how blockchain technology can eliminate or reduce the role of intermediaries in trucking operations and improve collaboration among shippers and carriers. In our design constructs, we extend the transportation control tower concept from the literature by operationalizing it in a decentralized fashion on the consortium and public blockchain architectures. We evaluate the technical feasibility of our design constructs with experienced blockchain engineers. In addition, we review our design constructs with trucking industry professionals to assess how successful they would be in removing the barriers to collaboration among shippers and carriers. The evaluation results show that shippers and medium and large carriers are interested in using blockchain technology to eliminate trust-related concerns and execute more collaborative trucking operations. Even though owner-operators prefer consortium blockchains over public blockchains due to competition concerns, they are still willing to join public blockchains for finding loads and managing trucking operations if shippers prefer using public blockchains over consortium blockchains. On the other hand, as an emerging technology, blockchain needs time to address critical problems such as identity management, scalability, the privacy of transactions, and compliance with data protection regulations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Federe öğrenme, küresel bir model elde etmek için her istemci modelini bir sunucuda toplayan dağıtılmış bir makine öğrenimi tekniğidir. Ancak, bazı istemciler modellerini veya verilerini zehirleyerek küresel modeli istenenden alakasız hale getirebilir ve sisteme zarar verebilir. Bu tez, sunucu için koordinat tabanlı istatistiksel karşılaştırma yoluyla zehirli modelleri tespit etmesi ve bunları birleştirme öncesinde sistemden uzaklaştırması için bir yaklaşım sunmaktadır. Koruma mekanizmasından kaçınmak için zararlı istemcilerin modelin daha az bir kısmını zehirlediği saldırı türü olan Katman Zehirlemesi de tanıtılmıştır. Farklı saldırı türlerine ve ağlara karşı koruma mekanizmasının sağlamlığını teyit etmek için uyarlanabilir eşik değeri uygulanmıştır. Önerilen yöntemin başarımını ölçmek için dağınık bir test ortamı tasarlanmıştır. Bazı istemciler, diğerlerinden daha yavaş öğrense veya enerji sınırlamaları nedeniyle nicelenmiş model parametreleri gönderse bile kötü niyetli cihazları başarılı bir şekilde belirleyebildiğini göstermek için farklı küme boyutlarına sahip, rastgele örneklenmiş bağlantılı veri kümelerini kullanan deneyler yapılmıştır. Ayrıca, koruma sisteminin detaylı analizi için farklı kötü niyetli cihaz sayıları, model türleri ve veri kümeleri ile denenmiştir. Sonuç olarak, sunulan korumanın, zararlı cihazların tüm istemcilere oranı %45'e kadar olduğunda zararlı modelleri tespit edebildiği ve sistemden uzaklaştırabilmeyi başarabildiği görülmüştür. Sunulan çözümün, literatürden alınmış diğer koruma mekanizmalarıyla kıyaslaması yapılmış; bu sistemler ile aynı veya daha fazla koruma sağladığı gözlemlenmiştir.","Federated learning is a distributed machine learning technique aggregating every client model on a server to obtain a global model. However, some clients may harm the system by poisoning their model or data to make the global model irrelevant to its objective. This thesis introduces an approach for the server to detect adversarial models by coordinate-based statistical comparison and eliminate them from the system prior to aggregation. A new attack type, layer poisoning, where the malicious nodes prefer poisoning selected small size layers of the model to deceive the detection system, is also introduced. Adaptive thresholding is adopted for preserving the robustness of the detection mechanism for various network against different attack types. A simulation framework is developed to benchmark and realize tests as a distributed system. Experiments that use random sampling of independent and identically distributed (iid) datasets with different batch sizes have been carried out to show that the proposed method can identify the malicious nodes successfully even if some of the clients learn slower than others or send quantized model weights due to energy limitations. The proposed approach is extensively tested with malicious-benign client ratios, model types, and datasets to present its versatility. The results show that the proposed system successfully eliminates the malicious models when their generating clients constitute at most 45% of the network. Comparison with the approaches from the literature shows that the proposed method performs the same as or better than the state of art solutions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin öğrenme ağlarının hasmane ataklara karşı hassas ve kırılgan olduğuna dair bulgular derin öğrenmede bu ataklara karşı güçlü modellere ihtiyacı ortaya koymuştur. Hasmane eğitim, bu tür saldırılara karşı savunmada en etkili yaklaşımlardan biri olarak kabul edilir. Ancak, dayanıklılık ve genelleme arasında bir denge sağlamak, hasmane eğitimin temel bir zorluğudur. Ayrıca hasmane eğitiminde genelleme yeteneği, atakların belirli örüntülere ezberlemesine sebep olabileceğinden kullanılan atakların çeşitliliğinden etkilenir. Öte yandan daha güçlü saldırılar sağlamlığı arttırsa da, temiz görüntülerin sınıflandırılmasında performans düşüşüne neden olabilir. Bu tezde hasmane eğitiminin başarısını etkileyen faktörler incelenerek bu faktörleri destekleyecek çözümler önerilir. Bu bağlamda atak yönünü birden fazla yönde çoğaltan ve fazladan geri yayılım operasyonu gerektirmeyen bir hasmane eğitim yöntemi önermekteyiz. Bu hasmane eğitim yaklaşımı, öz nitelik saçılma olarak bilinen hasmane eğitimden esinlenilerek, atak yönü eğitim kümesindeki atağa uğramış örnekler arasındaki mesafeye dayanarak belirlenir. Ana hasmane yönden maksimum 45 derece olacak şekilde yeni hasmane yönleri elde edilir. Çeşitli popüler veri kümelerinde yapılan deneysel sonuçlar, bu yöntemin doğal doğruluğu kaybetmeden hasmane dayanıklılık doğruluğunu tutarlı bir şekilde artırdığını göstermektedir. Ayrıca, bu tezde litarütürde genelleşme konusunda başarı sağlamış yöntemler hasmane eğitim yönteminin geliştirilmesi amacıyla incelenmiştir. Bu bağlamda, mixup ve kaydırmaya dayanıklılık yaklaşımlarının önerilen hasmane eğitim yöntemi ile birleştirilmesi önerilmektedir. Önerilerimiz, hasmane eğitimde veri temsilinin kalitesini arttırmayı ve modelleri küçük kaydırmalara karşı duyarsız hale getirerek genelleme performansının yanı sıra hasmane dayanıklılığını da art- trmayı amaçlamaktadır. Önerilerimizin etkinliği beyaz kutu saldırılarına karşı değerlendirilmiştir.","In light of recent discoveries regarding adversarial attacks, the necessity for robust models in deep learning has become increasingly critical. Adversarial training is considered one of the most effective approaches to defending against such attacks. However, a key challenge of it is the trade-off between adversarial robustness and generalization. The generalizability of robust models in adversarial training is affected by the diversity of perturbations, as they can overfit if the model only learns a limited attack pattern. Although stronger attacks can enhance robustness, their use may cause performance drops when classifying natural images. This thesis investigates the factors that affect the success of adversarial training and proposes solutions to mitigate some of these factors by utilizing new attack augmentation and generation methods. In that regard, we propose an adversarial training method that enhances adversarial directions by augmenting them from a one-step attack. The proposed framework is inspired by the feature scattering adversarial training and generates a principal adversarial direction based on the distance of the inter-sample relationships in a perturbed mini-batch. The principal direction is augmented by sampling new adversarial directions in a 45-degree region from it. The proposed method does not necessitate additional backpropagation steps than feature scattering. Experimental results on popular benchmark datasets indicate that the method consistently improves adversarial robustness without sacrificing natural accuracy. Furthermore, in this thesis, we propose integrating generalization-boosting techniques, namely mixup and shift-invariance, into the adversarial training framework. The proposed techniques aimto improve the data representations and robustness of models through convex data augmentation and by making the models invariant to small shifts. The effectiveness of our proposals is evaluated under white-box attacks on benchmark datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İstenen özelliklere sahip yeni ilaç benzeri kimyasalların keşfi, ilaç endüstrisinde zorlu ve maliyetli bir süreçtir. Klinik öncesi aşamada bu süreci kolaylaştırmak adına, farklı görevler için birçok farklı sinir ağı modeli önerilmiştir (örneğin, ilaç-hedef afinite tahmini, moleküler özellik tahmini, hedefe özel molekül üretimi). Başarılı sonuçlar üretmelerine rağmen, bu modeller genellikle yorumlanabilirlikten yoksundurlar. İlgili bileşiklerdeki her bir parçanın önemini belirleyebilmek için Dikkatli Özçağrılı Ağaç (AR-Tree) modelini kullandık. Göreve özgün dikkat mekanizması sayesinde AR-Tree, bileşiklerdeki önemli parçaları ağaç yapısında köke daha yakın yerleştirerek vurgular. Bu şekilde, belirlenen önemli fragmanlar gelecekteki araştırmalarda istenen özelliklere sahip yeni bileşikler tasarlamak için kullanılabilir. Denek görevleri olarak MoleculeNet'in beş farklı sınıflandırma ve dört farklı regresyon görevini denedik. Deneylerin sonuçları, önerilen mimarinin ilgili görevler için kimyasal olarak anlamlı parçalar bulmayı başardığını göstermektedir.","The discovery of new drug-like chemicals with desired properties is a challenging and costly process in the pharmaceutical industry. To facilitate this process in the preclinical phase, many different neural network models have been proposed for different tasks (e.g., drug-target affinity prediction, molecular property prediction, target-specific molecule generation). Despite producing successful results, they usually lack interpretability. To comprehend the significance of each fragment in the relevant compounds, we employed the Attention Recursive Tree (AR-Tree) model. Thanks to its task-specific attention mechanism, AR-Tree highlights the significant fragments of compounds by positioning them closer to the root of the tree structure. In this way, the identified significant fragments can be used to design new compounds with desired properties in future research. We experimented with five different classification and four different regression tasks of the MoleculeNet as benchmark tasks. The results of the experiments show that the proposed architecture succeeded in finding chemically meaningful fragments for the corresponding tasks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"̇İnsan hatasından kaynaklanan önemli miktarda kaza nedeniyle sürücü davranış izleme sistemlerine olan ihtiyaç artmıştır. Bu sistemler, sürüş davranışının gerçek zamanlı izlenmesini ve analizini sunarak kaza oranlarını düşürme ve genel yol güvenliğini artırma potansiyeline sahiptir. Yolcuların telefonlarından toplanan verilere dayanan çalışmamızda, sürüş davranışını sınıflandırmak için yeni bir analiz çerçevesi önerdik. Veriler, akıllı telefonlara yüklenen, geliştirdiğimiz mobil uygulama kullanılarak toplandı ve Makine Öğrenimi (ML) algoritmalarını kullanarak işledik. Çalışmamız, doğruluk oranını artırmak ve sekans bazında sonuçlar çıkarmak için Uzun Kısa Süreli Bellek (LSTM) algoritması geliştirmeye özellikle vurgu yaparak, birkaç makine öğrenimi sınıflandırma tekniği kullandı. Sonuçlar, yöntemin akıllı telefon uygulamalarından elde edilen verileri kullanarak sürüş davranışını ne kadar başarılı bir şekilde sınıflandırdığını göstermektedir. LSTM algoritmasının başarılı olması sonrasında, kullanıcılardan verileri alarak tek bir merkezde toplamadan, öğrenme ve analiz gerçekleştirebilmek amacıyla federe öğrenme algoritması geliştirdik. Çalışmamız federe öğrenme algoritmamızın sürüş davranışı sınıflandırılmasında başarı oranını da artırdığını göstermektedir.","The need for driver behavior monitoring systems has increased due to the significant amount of accidents that are brought on by human mistakes. These systems have the potential to lower accident rates and increase overall road safety by offering real-time monitoring and analysis of driving behavior. Based on the data collected from passengers' smartphones, we propose a novel analysis framework for classifying driving behavior in this thesis. Our mobile phone application was used to collect the data, which was then subjected to machine learning algorithms for processing. We utilized several Machine Learning (ML) classification techniques, with a particular emphasis on developing a Long Short Term Memory (LSTM) algorithm for increased accuracy and sequence-based prediction. The outcomes show how successfully the suggested method classifies driving behavior using the data obtained from smartphone applications. After having a successful result with LSTM, instead of collecting all data from users into one area, we developed a federated learning algorithm to train and test each data on users' phones. The results of the study show that federated learning is useful for the classification of driver behavior and thus increases accuracy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin Kenar Zeka, derin öğrenme algoritmalarının kenar bilişimde kullanımını amaçlar. Derin ağ eğitimi, güçlü hesaplama kaynakları gerektirirken kenar cihazlar genelde bu kapasitede değildir. Federe öğrenme gibi dağıtık öğrenme yöntemleri, kenar cihazlardan sınırlı bilgiyi alarak işbirliği ile tahmin başarımını arttırmayı hedefler. Genellikle ağ iletişim seferlerinin fazlalığından dolayı iletişim zamanı artmaktadır. Aynı zamanda iletişimde olası hataların artmasına da yol açmaktadır. Bir diğer dezavantaj ise tüm uç cihazlarda genelde aynı model mimarisinin kullanılmasından kenarda belli bir hesaplama kapasitesinin üstündeki cihazların kullanımına izin verilmesidir. Bu tezde, aynı boyutlu seçilmiş bir tam bağlı katman hariç tamamen farklı model mimarilerini destekleyen ve evrişimsel özelliğe sahip melez bir topluluk öğrenmesi çerçevesi önerilmektedir. Öncelikle, sığ sinir ağları kenar cihazlarda belli bir performansa kadar eğitilir. Kenar cihazlardaki her ağda, belli boyutta bir tam bağlı katman bulunması esastır. Bu katmana ait özellikler, modellerin eğitiminden sonra sunucudaki topluluk modeline giriş olarak aktarılır. Önerilen evrişimsel topluluk modeli sistemin kestirim başarımını arttırmak için eğitilir. Bu yöntem, sistemin öğrenmesinin sadece cihazdan sunucuya tek-yönlü iletişim ile yapılmasını sağlamaktadır. Gerekli öznitelik temsillerinin kenar cihazlardan sunucuya iletilememesi halinde, sunucudaki varyasyonel otomatik kodlayıcılar istatistiksel bir şekilde uygun vektörleri topluluk modeline sunmaktadır. Kapsamlı deneyler, önerilen yöntemin kestirim başarımının güncel yöntemlerden üstünlüğünü göstermektedir. Ayrıca, bazı öğrenme senaryolarında daha az iletişim ve veri aktarımı sağlanmaktadır.","Deep Edge Intelligence targets the deployment of deep learning algorithms in the edge network. While training deep networks requires computational resources, edge devices frequently lack high computational power. Decentralized learning methods such as federated learning provide a solution for gathering limited information from edge devices and collectively improving prediction performance. However, a drawback of such methods is that they often require multiple rounds of network communication, which increases communication time and the risk of communication errors. Another drawback is that the same model architecture is often used on all edge devices, which makes it mandatory to work with devices above a level of computational capacity. This thesis proposes a hybrid learning approach that employs ensemble learning with a convolutional scheme for different edge model architectures, except for a selected fully connected layer of the same dimensionality. Initially, shallow neural networks are trained on edge devices until a certain level of performance is achieved. Next, the feature representations obtained by the shallow models are transferred to an ensemble model. Subsequently, the proposed convolutional ensemble model is trained to boost the prediction performance. This method facilitates the completion of the system training with a one-way data transfer between edge devices and the server. Variational auto-encoders are also utilized to generate feature vectors in case transferring the required representations from the edge devices fails. Extensive experiments demonstrate that the suggested method outperforms state-of-the-art techniques in terms of accuracy while requiring fewer communications and a lower amount of data in various training scenarios."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Moleküler iletişim, geleneksel iletişim paradigmalarının yetersiz olduğu sualtı gibi ortamlarda iletişimi sağlayabilecek, akışkan ortamlarda bilginin moleküllerle taşındığı bir iletişim paradigması türüdür. Öte yandan moleküler iletişim moleküllerin difüzyonu ile gerçekleşmesi, vericinin yerini bulma gibi problemlerin çözümünü geleneksel yöntem- lerle çözebilmemizi engeller. Özellikle verici sayısının birden fazla olduğu durumlarda çözüm daha karışık hale gelmektedir. Bu tezde anlatılan çözüm ise çoklu vericilerin ve küresel, üzerine çarpan molekülleri tamamen emen bir alıcının olduğu akışkan bir ortamda alıcıya çarpan moleküllerin koordinatlarını kullanarak vericilerin yerlerini bulacak bir çözüm önerilmiştir. Bu yer bulma çözümü için, önce çarpan moleküllerin koordinatları K-ortalama, Gauss ve Bayes karışım modelleri gibi kümeleme modelleri ile kümelenir. Kümelenen verilerin ortalama değerleri hesaplanarak her kümeye ait ilgili vericinin yönü tespit edilir. Aynı zamanda herbir kümeye ait verinin sayısı, ve moleküllerin alıcıya çarpma olasılığından yola çıkarak mesafe tespit edilir. Sonuçlar, en umut verici küme algoritmasının K-Means olduğunu göstermektedir. Lokasyonların yönünü ve mesafesini kümelenmiş verilerle hesaplayarak verici konumlarını tahmin edebiliriz.","Molecular communication is a type of communication that provides communication in mediums such as underwater, where traditional communication paradigms are insufficient, and in which information is carried by molecules in fluid environments. However, the fact that the information particles in molecular communication propagates by diffusion prevents us from solving problems such as finding the location of the transmitter with traditional methods. Especially, when the number of transmitters is more than one, the solution becomes more complicated. The solution described in this thesis is to find the locations of the transmitters by employing the coordinates of the molecules hitting the receiver in a fluid environment where there are multiple transmitters and a spherical receiver that absorbs the hitting molecules completely. For this localization solution, first the coordinates of the hitting molecules are clustered with models such as Gaussian, Bayesian mixture models, and K-means. By calculating the average values of the clustered data, the direction of the corresponding transmitter is determined. At the same time, the distance is determined based on the number of data belonging to separate clusters and the probability of the particles hitting the receiver. The results show that the most promising cluster algorithm is K-Means. By calculating the direction and the distance of the locations via clustered data, we can estimate the transmitter locations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,Bilgisayarların kullanımı bilimin değişik alanlarındaki birçok çalışmada çeşitli faydalar sağlamıştır. Bilgisayarların hızındaki ve elimizdeki verinin miktarındaki artış dikkate alındığında bu durumun daha da yaygınlaşacağı beklentisi kuvvet kazanmaktadır. Bu çalışma bilgisayarları bilimin en ilginç alanlarından birisi olan Genetik'te kullanmak üzerinedir. İnsan genlerini oluşturan nükleotit dizilerindeki yapıyı modellemek için birçok farklı tekniğin kullanıldığı bu çalışmada elde edilen modeller görülmemiş bir nükleotit dizisinin bir insan genine ait olup olmadığını tahmin edebilme özelliğini sahiptir. Ayrıca yeni nükleotit serilerini üretme görevini de yerine getirebilmektedirler. Kullanılan tüm metodlar Makine Öğrenmesi isimli bir yaklaşım tabanlı olup hedef bilgisayara her aşamada ne yapması gerektiğini tek tek izah etmek yerine veriyi kullanarak öğrenmesini sağlamak şeklinde açıklanabilir. Eskiden beri kullanılan N-gram tarzı tekniklerin yanında son zamanlarda çok popüler hale gelen Derin Öğrenme tabanlı Recurrent Neural Networks ve Transformer dil modellerinden de faydalanılmıştır. Geliştirilen sistemler klasik başarı ölçütlerinin yanında gerçek hayata daha yakın olan ve Genetik ile alakalı bazı görevlerdeki başarıları ile de değerlendirilmiştir. Sonuçlar Doğal Dil ile bazı farkları barındıran bir problemde farklı tekniklerin kıyaslanması adına ilginçtir. Ayrıca N-gram tarzı basit modellerin bazı problemleri çözmede Transformer gibi karmaşık modellerden daha iyi olmalarının mümkün olduğu görülmüş olmuştur. Son olarak modelleri ölçerken gerçek görevlerde testin çok mühim olduğu öğrenilmiştir çünkü transformer modeli perplexity dikkate alındığında N-gram'dan daha iyi iken gerçek testte daha kötü sonuç vermiştir.,"The use of computers for different fields of science has provided tremendous benefits. This phenomenon is expected to be more common as the speed of computers and the amount of data available for different kinds of scientific problems increase. This study focuses on genomics, one of the most exciting areas of science. We have applied several techniques to obtain a model for nucleotide sequences of genes that are found in human beings so that the model can learn the general pattern in these nucleotide sequences and predict how likely it is that an unseen sequence is a gene that belongs to human beings. They can even generate new nucleotide sequences. All of the methods used are examples of machine learning, where the programs are designed to learn from data for a specific task, rather than explicitly programming what to do at each step. Traditional approaches such as N-grams and more recent deep learning-based techniques such as recurrent neural networks and transformer architecture language models are used. In addition to the classical metrics, the strength of the methods is measured using a real-world task from the field of genomics. Finally, the results show an interesting comparison of how all these models perform on a task that is inherently different from classical natural language processing tasks, and how sometimes simple models like N-grams can be as good as, if not better than, more sophisticated techniques such as transformer for solving certain types of problems. Furthermore, the significance of evaluating obtained models on real-life tasks is seen because the transformer model was superior to the N-gram model according to perplexity, although it performed worse on real-world task."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, negatif olmayan tensör ayrıştırma (NOTA) yöntemlerinin gözetimli öğrenmenin değişik alanlarında kullanılmasına odaklanmaktadır. Teze, birçok modelleme varsayımını, çıkarımda algoritmik verimlilikle birleştirerek hayata geçirebilen olasılıksal bir NOTA çerçevesini tanıtarak başlamaktayız. Ardından bu çerçevenin sağladığı esneklik, farklı gözetimli öğrenme problemlerinde çıkarım, model seçimi ve analiz için kullanılmaktadır. Bu uygulamaların ilkinde bu yaklaşımdan çok seviyeli, karmaşık mevsimsellik gösteren zaman serilerini yorumlanabilir ve doğru bir şekilde modellemek için faydalanılmaktadır. Ardından, bir sınıflandırma probleminde, bir yapay öğrenme modelinin çıktısına bağlı olarak son kararın ne zaman bir uzmana bırakılması gerektiğinin belirlenmesi için yeni bir yöntem önerilmekte ve NOTA modellerinin bu yöntemi daha karmaşık senaryolara genellemekte kullanılabileceği gösterilmektedir. Sonrasında, derin öğrenme yöntemlerinin parametrelerinin ne zaman ve neden sıkıştırılabilir olduğu incelenmekte ve yukarıda bahsedilen NOTA çerçevesinden bu eğilimlerin gösterim uzayındaki karışılıklarının incelenmesinde yararlanılmaktadır. Tezdeki çalışmalar, gözetimli öğrenmenin değişik alanlarına bağımsız katkılar yapmanın yanı sıra, esnek bir modelleme yaklaşımıyla birleştirildiğinde, NOTA yöntemlerinin birçok gözetimli öğrenme problemini kolaylaştıracak şekilde kullanılabileceğini göstermektedir.","This thesis focuses on utilizing nonnegative tensor factorization (NTF) methods in various areas of supervised learning. We start with the introduction of a probabilistic NTF framework that can accommodate a wide range of modeling assumptions while maintaining algorithmic efficiency during inference. The flexibility provided by this framework is then utilized for inference, model selection, and analysis in various supervised learning problems. In the first of these scenarios, we use this approach to effectively model time series with nested, complex seasonalities, ensuring accuracy and interpretability. We then propose a novel method for learning to defer to an expert based on the output of a machine learning model in classification problems, and show that NTF can be utilized to extend this method to arbitrarily complex settings. Afterwards, we investigate when and why deep neural networks' parameters become compressible, and use the aforementioned NTF framework to help analyze how these dynamics are reflected in the representation space. In addition to making independent contributions to various areas of supervised learning, our work shows that, coupled with a convenient modeling approach, NTF can be beneficial for a wide range of supervised learning problems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hızla yaygınlaşmakta olan ve performansı artan bacaklı robotlar, yakın gelecekte hayatlarımıza dahil olacak. Mevcut robotlarda halihazırda çeşitli kontrol algoritmaları kullanılmakta ve yeni kontrol metotları geliştirilmektedir. Bacaklı robotların yaygın kullanımlarını sağlamak ve geliştirme sürecini kolaylaştırmak için robotun güvenliği dikkatle ele alınmalıdır. Özellikle makine öğrenmesi kullanan kontrol yöntemlerinde güvenlik için model-temelli kısıtların da hesaba katılmasına ihtiyaç vardır. Bu tez, bacaklı bir robotun güvenliğini sağlamak, i.e., düşme olasılığını azaltmak, için modüler bir güvenlik filtresi sunmaktadır. Hareket edebilen bir robotun mevcut olduğu kabul edilmiştir, başka bir deyişle, bir nominal kontrolcü mevcuttur. Hareketli robotun çevresindeki arazi özellikleri, sadece propriyoseptif sinyaller kullanan makine öğrenimi yoluyla tahmin edilmiştir. Derin öğrenmede hızla yaygınlaşan verimli transformer mimarisi ile geliştirilen özgün bir derin öğrenme modeli, arazi özelliklerinin tahmini için kullanılmıştır. Karesel programlama ile arazi tahminleri, ters dinamikler ve özgün bir kontrol set fonksiyonu kısıtıyla birleştirilmiştir. Ortaya çıkan optimal kontrolcü bir filtre görevi görerek nominal kontrol sinyallerinin güvenli olduğunu sertifikalar, aksi halde kontrol sinyalini güvenliği ihlal etmeyecek şekilde değiştirir. Filtrelenmiş kontrol sinyali, robotun güvenli hareketiyle sonuçlanacaktır. Ortaya konan yaklaşım geneldir ve az bir çabayla diğer herhangi bir bacaklı robota aktarılabilir.","With recent performance improvements, legged robots will soon enter our lives to stay. Various control algorithms are already employed in deploying existing robots, and many more algorithms are still in the making. Safety concerns during the operation of legged robots must be addressed to enable their widespread use and ease their development. Especially machine learning-based control methods would benefit from model-based constraints to improve their safety. This thesis presents a modular safety filter to improve safety, i.e., reduce the chance of a fall of a legged robot. The availability of a robot capable of locomotion is assumed, i.e., a nominal controller exists. During locomotion, terrain properties around the robot are estimated through machine learning which uses a minimal set of proprioceptive signals. A novel deep-learning model utilizing an efficient transformer architecture is used for terrain estimation. A quadratic program combines the terrain estimations with inverse dynamics and a novel control barrier function constraint to filter and certify nominal control signals. The result is an optimal controller that acts as a filter and the filtered control signal allows the safe locomotion of the robot. The resulting approach is general and could be transferred with low effort to any other legged system."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma, radyomik ve klinik veriler kullanılarak BT görüntülerinden böbrek tümörü tipinin (berrak hücreli veya berrak hücreli olmayan) tespit edilmesinde makine öğrenimi algoritmalarının performanslarını karşılaştırmayı hedeflemektedir. Çalışmada TCIA'nın KiTS-19 Yarışması'nda bulunan 192 malign böbrek tümörü BT görüntüsü (142 berrak hücreli, 50 diğer tip) kullanılmıştır. Özellikler 3 boyutlu görüntü kesitlerinin tümü kullanılarak çıkarılmıştır. Başlangıçta çıkarılan özellik sayısı, 1130 radyomik ve 27 klinik olmak üzere toplam 1157'dir. Kruskal Wallis - ANOVA testi ardından Lasso Regresyon metodu uygulanarak modellerde kullanılacak 8 özellik seçilmiştir. Bu aşamada tüm klinik özellikler elenmiştir. Eğitim kümesi sınıfları SMOTE metodu kullanılarak dengelenmiştir. Seçilen özellikler için eğitim kümesi verileri kullanılarak Coarse Gaussian SVM ve Subspace Discriminant algoritmaları eğitilmiştir. Coarse Gaussian SVM için eğitim süresi 0.47 sn ve tahmin hızı yaklaşık 11000 göz/sn iken; Subspace Discriminant için bu değerler sırasıyla 4.1 sn ve yaklaşık 960 göz/sn olarak gözlemlenmiştir. Coarse Gaussian SVM için ROC puanı 0.86 bulunurken, Subspace Discriminant için 0.85 olarak hesaplanmıştır. İki model de çalışmanın amacı olan böbrek tümörü tipi sınıflandırması için umut verici sonuçlar sağlamıştır.","This study aims to evaluate the performance of machine learning methods in predicting the subtype (clear-cell vs. non-clear-cell) of kidney tumors using clinical patient and radiomics data from CT images. CT images of 192 malignant kidney tumor cases (142 clear-cell, 50 other) from TCIA's KiTS-19 Challenge were used in the study. There were several different tumor subtypes in the other group, most of them being chromophobe or papillary RCC. Patient clinical data were combined with the radiomic features extracted from CT images. Features were extracted from 3D images and all of the slices were included in the feature extraction process. Initial dataset consisted of 1157 features of which 1130 were radiomics and 27 were clinical. Features were selected using Kruskal Wallis - ANOVA test followed by Lasso Regression. After feature selection, 8 radiomic features remained. None of the clinical features were considered important for our model as a result. Training set classes were balanced using SMOTE. Training data with the selected features were used to train the Coarse Gaussian SVM and Subspace Discriminant classifiers. Coarse Gaussian SVM was faster compared to Subspace Discriminant with a training time of 0.47 sec and 11000 obs/sec prediction speed. Training duration of Subspace Discriminant was 4.1 sec with 960 obs/sec prediction speed. For Coarse Gaussian SVM was found as 0.86 while for Subspace Discriminant AUC was 0.85. Both models produced promising results on classifying malignant tumors as ccRCC or non-ccRCC."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ağ akışı pek çok sahada uygulaması olan aktif bir araştırma alanıdır. Birçok ağ akışı problemi ya azami akış ya da asgari maliyet akışı problemine indirgenmektedir. Azami akış problemi kenarlarında akış kapasitesi olan bir ağ üzerindeki belirlenmiş iki düğüm arasında olası azami akışı belirlemek üzerinedir. Asgari maliyet problemi arz ve talep düğümleri olan bir ağ üzerinde asgari maliyetli akışı belirlemeye çalışır. Biz bu tezde azami akış ve asgari maliyet akışı problemleri için sırayla iki paralel algoritma sunduk. Birinci olarak azami akış problemi için paylaşımlı hafıza bir paralel itme-etiketleme algoritması sunuyoruz. Eş zamanlı itme ve etiketleme işlemleri için iş parçacıkları arasındaki çarpışmaları önlemek amacıyle çizge renklendirme kullanılmaktadır. Ek olarak hedef düğümlerdeki fazlalık değerleri yarışma durumlarını engellemek için atomik komutlarla güncellenmektedir. Deneyler bizim algoritmamızın geniş ve düşük çaplı ağlarda rekabetçi olduğunu göstermektedir. İkinci olarak asgari maliyet akış probleminin çözümü için ağ simpleks algoritmasının paralel bir uygulamasını sunuyoruz. Genellikle çalışma süresinin çoğunu aldığı için giriş kenarını paralel bir şekilde bulmayı öneriyoruz. Bütün kenarları taramak oldukça vakit alabilir, bu yüzden sadece sabit sayıda kenarı düşünmek yaygındır ki bu da blok arama eksen kuralı olarak adlandırılır. Hesaplamalar birbirinden bağımsız olduğundan kenar taramaları en iyi adayı bulmak için kolaylıkla paralel yapılabilir. Paylaşımlı hafıza paralellik için OpenMP ve bununla beraber vektörleştirme için AVX komutları kullandık. Ayrıca algoritmanın paralel miktarını arttırmak için blok büyüklüklerini ayarlamayı denedik. Deneyler hızlanmanın 4 kata kadar mümkün olduğunu fakat genellikle daha düşük olduğunu göstermektedir.","Network flows is an active area of research that has applications in a wide variety of fields. Several network flow problems are reduced to either the maximum flow problem or the minimum cost flow problem. Maximum flow problem involves finding the maximum possible amount of flow between two designated nodes on a network with arcs having flow capacities. Minimum cost flow problem tries to determine a flow with the minimum cost on a network with supply and demand nodes. In this thesis, we propose two parallel algorithms for the maximum flow and the minimum cost flow problems respectively. First, we present a shared memory parallel push-relabel algorithm for the maximum flow problem. Graph coloring is used to avoid collisions between threads for concurrent push and relabel operations. In addition, excess values of target nodes are updated using atomic instructions to prevent race conditions. The experiments show that our algorithm is competitive for wide graphs with low diameters. Second, we contribute a parallel implementation of the network simplex algorithm that is used for the solution of minimum cost flow problem. We propose finding the entering arc in parallel as it often takes the majority of the execution time. Scanning all arcs can take quite some time, so it is common to consider only a fixed number of arcs which is referred as the block search pivoting rule. Arc scans can easily be done in parallel to find the best candidate as the calculations are independent of each other. We used shared memory parallelism using OpenMP along with vectorization using AVX instructions. We also tried adjusting block sizes to increase the parallel portion of the algorithm. Our experiments show speedups up to 4 are possible, though they are typically lower."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Birçok makine öğrenmesi algoritması maliyet duyarsız kayıpları azaltmaya çalışsa da, birçok gerçek dünya uygulaması yanlış sınıflandırmanın sınıflara bağlı olarak farklı maliyetler oluşturduğu, maliyet-duyarlı yöntemlerin kullanılmasını gerektirir. Yanlış sınıflandırma maliyetlerine ek olarak, veri setleri içindeki örnekler aynı olmayan maliyetlere sahip olabilir, bu da örnek-bağımlı maliyet duyarlı öğrenme problemidir. Örneğin kredi skorlamada, yanlışlıkla reddedilen iyi bir müşteri ile onaylanan finansal durumu kötü olan bir müşterinin yaratacağı maliyetler farklıdır. Buna ek olarak, farklı miktarlarda kredilerin başvuranlara sağlanması, kredi skorlamayı örnek-bağımlı hale getirir. Diğer bir deyişle, 100M$'lık bir kredi ile 1M$'lık bir kredinin yaratacağı maliyetler eşit değildir. Bu problemi çözmek için, tezde örnek-bağımlı maliyet-duyarlı bir kayıp fonksiyonu öneriliyor. Önerilen kayıp fonksiyonu ile maliyet duyarlılık öğrenme sürecinde çözülüyor. Bu çözüme, Gradyan Artırma Makineleri'nin geleneksel kayıp fonksiyonunu, önerilen kayıp fonksiyonu ile değiştirerek ulaşıyoruz. Bu değişim ile Gradyan Artırma Makineleri'ni örnek-bağımlı maliyet-duyarlı hale getiriyoruz. Öerdiğimiz algoritmayı kredi miktarlarını içeren iki gerçek dünya veri setinde ve sentetik veri setlerinde deniyoruz. Algoritmayı, maliyet-duyarsız algoritmalarla, daha önce önerilen maliyet duyarlılığı öğrenme sürecinde halletmeye çalışan örnek-bağımlı maliyet-duyarlı sınıflandırma algoritmalarıyla, maliyet duyarsız algoritmaları maliyet-duyarlı hale getiren Thresholding isimli ön-işleme ve Oversampling isimli son-işleme yöntemleri ile karşılaştıyoruz. Sonuçlar gösteriyor ki, finansal tasarruf açısından yöntemimiz bu dört yöntemden daha iyi çalışıyor.","Although most of machine learning algorithms try to minimize cost-insensitive losses, many real world applications require cost-sensitive approaches where misclassification costs among classes differ from each other. In addition to misclassification costs, examples in data sets may have nonidentical costs which is a case of example-dependent cost-sensitive learning. For example in credit scoring, mistakenly rejecting a good borrower and approving a bad client with financial distress result in different costs. Additionally, providing variety of credit amounts to applicants makes the credit scoring example-dependent. In other words, falsely approving 100M$ and 1M$ loans produce unequal costs. To overcome this problem, this thesis proposes an example-dependent cost-sensitive loss function. With the introduced loss function, cost sensitivity is handled during the learning process. This is achieved by changing the traditional loss function of Gradient Boosting Machines with the proposed one to make it Example Dependent Cost-Sensitive Gradient Boosting Machines. The proposed algorithm is tested on two real world data sets that include credit amounts and synthetically generated data sets. The algorithm is compared with cost-insensitive learners, previously proposed example-dependent cost-sensitive classifiers that handles cost-sensitivity during learning, a post-processing method called Thresholding and a pre-processing method Oversampling to make cost-insensitive classifiers cost-sensitive. Results show that our method outperforms those four methods in terms of financial savings."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dönüştürücü dil modelleri, çok çeşitli doğal dil işleme görevlerinde olağanüstü başarıların yolunu açmıştır. Dönüştürücü dil modellerinde ilk adım, girdiyi jetonlara bölmektir. Yıllar boyunca, çeşitli bölümleme yaklaşımları ortaya atılmıştır. Bu yaklaşımlar, karakter ve kelime seviyesindeki temsillerden alt kelime seviyesindeki temsillere doğru daha da gelişmiştir. Bununla birlikte, özellikle morfolojik olarak zengin diller için, kelime bölümleme algoritmalarının model performansı üzerindeki etkisi tam olarak tartışılmamıştır. Bu tezde, çekimli ve morfolojik açıdan oldukça zengin bir dil olan Türkçe için alt kelime bölümleme algoritmalarının kapsamlı bir şekilde analizi yapılmıştır. Bölümleme algoritmalarının Türkçenin morfolojisini ne kadar iyi kodladığını değerlendirmek için çeşitli metrikler tanımlanmıştır. Ayrıca, sözcük dağarcığı ve derlem boyutu gibi farklı belirteç parametrelerinin belirteçlerin özelliklerini nasıl değiştirdiği incelenmiştir. Ek olarak, sondan eklemeli ve morfolojik olarak zengin diller için yeni bir bölümleme algoritması önerilmiştir. Önerilen kelime bölümleme algoritmasının daha iyi genelleme performansı sağladığı gösterilmiştir. Doğal dil işleme deneyleri, kelime bölümlemede morfoloji denetiminin model performansını iyileştirdiğini göstermektedir.","Transformer language models have paved the way for outstanding achievements on a wide variety of natural language processing tasks. The first step in transformer models is dividing the input into tokens. Over the years, various tokenization approaches have emerged. These approaches have further evolved from character and word-level representations to subword-level representations. However, the impact of tokenization on models performance has not been thoroughly discussed, especially for morphologically rich languages. In this thesis, we comprehensively analyze subword tokenizers for Turkish, which is a highly inflected and morphologically rich language. We define various metrics to evaluate how well tokenizers encode Turkish morphology. Also, we examine how the tokenizer parameters like vocabulary and corpus size change the characteristics of tokenizers. Additionally, we propose a new tokenizer for agglutinative and morphologically rich languages. We demonstrate that our tokenizer reduces overall perplexity and enables better generalization performance. Downstream task experiments show that morphology supervision in tokenization improves model performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Matematiksel kelime problemlerini (MWP) çözmenin, doğal dil metinleri ve matematiksel denklemler arasındaki anlamsal boşluk nedeniyle zorlu bir görev olduğu söylenebilir. Görevin temel amacı, yazılı bir matematik problemini girdi olarak almak ve bu problemi çözmek için çıktı olarak uygun bir denklem üretmektir. Bu tez, metindeki semantik anlamlarına dayalı olarak MWP'leri otomatik olarak çözmek için diziden diziye (seq2seq) bir sinir modelini açıklamaktadır. Seq2seq modeli, eğitim verilerinde mevcut olmayan denklemleri üretebilme avantajına sahiptir. Giriş sırasını kodlamak ve problem semantiğini kavramak için çift yönlü bir kodlayıcı ve çıkış sembollerinin semantik anlamlarını izlemeye ve denklemi çıkarmaya yarayan bir kod çözücü içerir. Bu tezde, geçitli tekrarlayan birimler (GRU) ve uzun-kısa vadeli bellek (LSTM) seq2seq modelleri dahil olmak üzere, önceden eğitilmiş çeşitli dil modelleri ve nöral modellerin başarılarını araştırıyoruz. Araştırmamız, önceden eğitilmiş dil modellerini ve nöral modelleri kullanan bu doğal dil işleme (NLP) görevi hakkında Türkçe'de herhangi bir çalışma olmaması açısından yenidir. MWP görevi için nöral modelleri uygulamak için tasarlanmış bir Türkçe veri seti de bulunmamaktadır. Veri eksikliğinden dolayı, iyi bilinen İngilizce MWP veri setlerini makine çeviri sistemi kullanarak Türkçe'ye çevirdik. Literatüre katkı sağlamak için manuel ayarlamalar yaptık ve bir derlem oluşturduk. Türkçe sondan eklemeli ve gramer açısından üzerinde çalışılması zor bir dil olmasına rağmen, sistemimiz derlemdeki soruların %71'ini doğru yanıtlar.","It can be argued that solving math word problems (MWP) is a challenging task due to the semantic gap between natural language texts and mathematical equations. The main purpose of the task is to take a written math problem as input and produce a proper equation as output for solving that problem. This thesis describes a sequence-to-sequence (seq2seq) neural model for automatically solving MWPs based on their semantic meanings in the text. The seq2seq model has the advantage of being able to generate equations that do not exist in the training data. It comprises a bidirectional encoder to encode the input sequence and comprehend the problem semantics, and a decoder with attention to track semantic meanings of the output symbols and extract the equation. In this thesis, we investigate the successes of several pre-trained language models and neural models, including gated recurrent units (GRU) and long short-term memory (LSTM) seq2seq models. Our research is novel in the sense that there exist no studies in Turkish on this natural language processing (NLP) task that utilize the pre-trained language models and neural models. There is also no Turkish dataset designed to implement the neural models for MWP task. Due to the lack of data, we translated the well-known English MWP datasets into Turkish using a machine translation system. We performed manual adjustments, and built the corpora to contribute to the literature. Although Turkish is an agglutinative and grammatically challenging language to work on, our system correctly answers 71% of the questions in the corpora."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sürücüsüz araçlar trafiğin önemli bir parçası olma yolunda ilerliyorlar. İnsanların çoğunlukta olduğu bir trafikte sürücüsüz araçların kullanılması bazı zorluklar getiriyor. Trafikte araç sürdüğümüz her hangi bir deneyim bize gösteriyor ki, her sürücü kendi sürüş stilinde farklıdır. Bu sürüş zenginliği trafik simülasyonlarındaki modellere henüz aktarılmamıştır. Bu trafik modelleri, testlerden anlık davranış tahminine, sürücüsüz araç çalışmasının önemli bir noktasıdır. Dolayısıyla, trafiğin gerçekçi bir modelini oluşturmak çok önemli bir problemdir. Bu çalışmada, problemin kökenine inen bir analiz mevcuttur. Sonra, farklı sürüş metodlarını kapyasan bir model önerilmiştir. Öncelikle, veri seri üzerinde derin bir sürücü davranış modeli çalışması yapılarak belirgin davranış örüntüleri belirlenmiştir. Sonra bu belirgin özellikler pekiştirmeli öğrenme kullanılarak modellenmiştir. Değerlendirme zamanında, bir trafik sahnesi gözlemlenmiş, her bir araç önceden modellenen araçlarla eşleştirilmiştir. Sonuç olarak bir trafik sahnesi veri ile doğrulanmış modeller kullanilarak yeniden yaratılmıştır. Araç davranışını simülasyona entegre eden bu yeni yaklaşım trafiğin daha gerçekçi modellenmesi için bir adım oluşturmaktadır. Bu gerçekçi trafik modeli sürücüsüz araç test ve validasyonu için önemli bir adım oluşturmaktadır.","Autonomous vehicles are set to be a part of everyday traffic. Their presence in traffic dominated by humans possesses some challenges. Any experience with driving in traffic shows us that each driver is unique in their driving style. So far, this richness in differences in human behavior has not been projected into the models used in traffic simulations. These models are an essential part of the development of autonomous vehicles; from the inference of other vehicle intentions to virtual testing. Therefore creating a more realistic traffic environment is a very important task. In this work, a deep dive into the state of the problem is given. Then, a framework that accounts for different driving styles, as well as different vehicle types, is introduced. Firstly, an in-depth analysis of distinct patterns of driving is carried out in the dataset. Then these distinct patterns are modeled with simulated agents using reinforcement learning. In inference time, a traffic scene is observed, each vehicle is assigned to the pre-trained driver model and a simulation is carried out. As a result, a traffic scene is reconstructed with data-validated models. This new approach that incorporates previous driver modeling work with a behavioral component, paves the way for a more realistic model of the traffic. This realistic traffic model can be used in AV testing and validation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın amacı, Z sistemleri olarak da bilinen ana bilgisayarlar üzerinde çalışan uygulama sunucularının makine öğrenmesi algoritmaları kullanarak kaynak tüketimi için bir kapasite planlama aracı tasarlamaktır. Bu araç, mevcut ve gelecekteki iş yükü taleplerini karşılamak için yeterli kaynakların mevcut olmasını sağlamayı amaçlamaktadır. Arzu edilen sistemin, artan taleplere göre ne kadar ek kapasiteye ihtiyaç duyulacağını belirleme ve daha sonra tahmin etme yeteneğine sahip olması amaçlanmıştır. Bu çalışmada, platform tarafından sağlanan veri analizi, veri mühendisliği, veri yönetişimi ve Yapay Zeka modelleme hizmetlerini kullanarak kapasite planlama modeli oluşturmak için IBM Cloud Pak for Data as a Service kullanılmıştır. Veriler, platform dışında hazırlanıp analiz ve iyileştirme yapmak için platforma aktarılmıştır. Veri iyileştirme adımı tamamlandıktan sonra, makine öğrenme modelleri çeşitli algoritmalar kullanılarak eğitilmiştir. Ardından, platformun test arayüzü kullanılarak modellerin doğruluğunu ve performansını kontrol etmek için fonksiyonel testler yapılmıştır. Bu testlerin sonuçları, yorumlar ve daha fazla araştırma fırsatları da paylaşılmıştır. Tasarlanan kapasite planlama aracının kabul edilebilir hata oranları ile tutarlı tahminler yapabildiği gözlemlenmiştir.","The goal of this study is to design a capacity planning tool for resource consumption of application servers which are running on mainframes, also known as Z systems, by using machine learning algorithms. This tool is aimed to ensure adequate resources are available in order to meet current and future workload demands. The desired system is intended to have capability to determine and then forecast how much additional capacity will be needed based on increasing demands. In this study, IBM Cloud Pak for Data as a Service is used to create capacity planning model by using data analysis, data engineering, data governance and Artificial Intelligence modeling services which are provided by the platform. The data is prepared outside of the platform and imported to the platform in order to perform analysis and refinement. After the data refinement step is completed, machine learning models are trained by using several algorithms. Then, functional tests are performed in order to check accuracy and performance of the models by using the test interface of the platform. Results of these tests, comments and further research opportunities are also provided. It is observed that the designed capacity planning tool is capable of making consistent predictions with acceptable error rates."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geçtiğimiz iki yılda Covid-19 salgını dünya çapında milyonlarca insanın hayatını kaybetmesine sebep olup, milyarlarca insanı olumsuz etkiledi. Yetkililer uzaktan çalışma, uzaktan eğitim ve sokağa çıkma yasağı gibi önlemler almak zorunda kaldılar. Bilim adamları olası olumsuz etkileri azaltmak amacıyla tahminleme ve ağlar üzerinde simülasyon çalışmaları ile salgının geleceğini öngörmeye çalıştılar. Bu çalışmalarda kullanılan ağlar ya yapay ağlar, ya da gerçek ama belli bir alana spesifik, sınırlı boyuta sahip ağlar oldu. İlk grubun yapay oluşu, ikinci grubunsa sınırlı boyutta ve belli bir alana spesifik olması sebebiyle bu ağların gerçek hayatı her yönden temsil etme yeteneği kısıtlıydı. Literatürdeki bu ihtiyaca cevap olması amacıyla şehir hayatını her yönüyle yüksek çözünürlükte temsil edebilmek için parametrik çok katmanlı yönsüz ağırlıklı ağ modelini sunuyoruz. Bu modelde çizge kuramından faydalanıp bireyleri düğümler ile temsil ediyoruz. Bireyler bulundukları bölgede yerel etkileşimler yapıyorlar, ve bu etkileşimler hastalık bulaştırma ihtimalini gösteren ağırlıklı kenarlar ile temsil ediliyorlar. Ağdaki her katman kendi kenar ağırlığına sahip olup ev, iş ve okul gibi günlük hayattan etkileşimleri temsil ediyor. Bu ağ üzerinde yaptığımız salgın simülasyonları gösteriyor ki hastalığı yaymada en etkili katman arkadaşlık katmanı. Literatüre katkılarımız iki başlıktan oluşuyor. Önce gelecekteki araştırmalarda kullanılabilecek parametrik bir ağ modeli sunuyor, ardından SIR simülasyonu ile farklı katmanların salgındaki etkilerini ortaya koyuyoruz.","The last two years have been an extraordinary time with the Covid-19 pandemic killing millions, affecting and distressing billions of people worldwide. Authorities took various measures such as turning school and work to remote and prohibiting social relations via curfews. In order to mitigate the negative impact of the epidemics, researchers tried to estimate the future of the pandemic for different scenarios, using forecasting techniques and epidemics simulations on networks. Networks used in these research are either synthetic networks or real networks with limited size and domain speciﬁc interactions. Hence, their ability to represent the world is limited. Intending to represent real-life in an urban town in high resolution, we propose a parametric multi-layer undirected weighted network model, where vertices are the individuals of a town that tend to interact locally, and edges represent transmission probability. Each layer corresponds to a different interaction that occurs daily, such as household, work or school, with their own transmission probability. Our simulations indicate that locking down friendship layer has the highest impact in slowing down epidemics. Hence, our contributions are twofold, ﬁrst we propose a parametric network generator model; second, we run SIR simulations on it and show the impact of layers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Klasik veri artırma teknikleri, yeterli eğitim verisinin olmadığı birçok görüntü sınıflandırma uygulaması tarafından yaygın olarak kullanılmaktadır. Bu veri artırma teknikleri, yansıtma, rastgele kırpma, mevcut görüntülerin yeniden ölçeklenmesi ve dönüşümlerden oluşur. Bu teknikler yardımıyla gerçek veri kümelerinin artırılmış halinin sınıflandırıcıların eğitimi sırasında kullanılması günümüzde popülerdir. Gerçek-çi sentetik verilerle veri kümesi boyutunu artırmak, veri kümesine yeni ve gerçekçi varyasyonlar katılması vesilesiyle bu veri kümesi üzerinde eğitilen sınıflandırıcıların doğruluğunu artırmamızı sağlamaktadır. GAN'ların temsil gücü ile birlikte gerçek verilerin dağılımını tutarlı bir çeşitlilik düzeyiyle öğrenmesi, neredeyse gözlemlenmeyen ayırt edici özelliklere sahip örnekler oluşturmamızı sağlar. Yaklaşımımızda, StyleGAN2-ADA şeklinde adlandırılan GAN veri artırma yöntemini kullanarak GAN'ların yukarıda bahsedilen yaratıcı yeteneklerinden faydalandık. Sınıf koşullu SytleGAN2ADA eğiti-minden sonra, başarım ve veri artırma miktarı arasındaki korelasyonu gözlemlemek için veri kümesini farklı miktarlarda oluşturulan ek örneklerle genişlettik. Ayrıca GAN vasıtasıyla veri kümelerini güçlendirme alanında yeni bir yaklaşım olan ayrıştırılmış özelliklere yönelik veri artırma yöntemini denemek için StyleCLIP'i kullandık. Style-CLIP'ten daha iyi faydalanabilmek amacıyla CLIP modelini x-ray görüntüleri ve raporlardan ayıklanmış anahtar cümleciklerle tekrar eğittik. GAN veri artırma yöntemlerinin performansını test etmek için CheXpert yarışması birincisi olan DeepAUC yöntemini kullandık. Yaklaşımımızda sınıflandırma başarımlarının GAN veri artırma yöntemleri-nin kullanılmadığı durumlara göre daha yüksek olduğunu gözlemledik.","Classical data augmentation techniques are widely used by many image classification applications in the absence of adequate training data. These data augmentation techniques consists of but not limited with reflection, random cropping, re-scaling existing images and transformations. These techniques are widely used in practice during training classifiers with extended versions of real-world datasets. Increasing dataset size with realistic synthetic data allows us to improve the classification accuracy by making use of additional realistic variety. With the great representational power of GANs, learning the distribution of real data with a consistent level of variety allows us to generate samples with nearly-unobserved discriminative features. In our approach we used the aforementioned generative capability of GANs by utilizing state of the art GAN augmentation framework titled as StyleGAN2-ADA. After the training SytleGAN2-ADA in class conditional setting, we extended the dataset with different numbers of additional generated samples in order to observe the correlation of accuracy and augmentation strength. We extended our approach by using StyleCLIP to experiment disentangled feature augmentations which is a novel approach in the field of GAN augmentation. To make use of StyleCLIP more efficiently, we fine-tuned CLIP with x-ray images and modified entities which are extracted from corresponding medical reports. We used the DeepAUC framework which is proven to be efficient for multi-disease labelled x-ray classification tasks to test the performance of the GAN augmentation. In our approach, we observed that the classification accuracies were improved compared to without text-manipulated GAN augmented setting."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Doğal dil işleme (NLP), yapay zeka içerisindeki ilgi çekici bir alandır. Doğal dil aracılığıyla insanın makinelerle etkileşimini sağlar. NLP model mimarilerinde iki ana kavram vardır; girdi vektörleştirme ve girdinin bağlamsal temsil edilmesi. Girdi vektörleştirme işleminde üç tokenizasyon yaklaşımı bulunmaktadır: karakter düzeyi, kelime düzeyi ve kelime parçaları düzeyi. Kelime düzeyinde tokenizasyon yönteminde, sözcük dağarcığının geniş olması problemi yaşanmaktadır. Ayrıca Türkçe gibi eklemeli dillerde, aynı kökten türeyen sözcüklerin birbirinden tamamen farklı sözcükler olarak ele alınmasına neden olmakta ve modelin bu sözcükler arasındaki ilişkileri ve morfolojik eklerin anlamlarını öğrenmesini zorlaşmaktadır. Ayrıca, tüm NLP modellerin ortak bir sorun vardır: veride bulunan yazım hataları. Yazım hataları ile girdi kelimeleri tamamen farklı hale gelir ve model bunları anlayamaz. Bu tezde, yazım hatalarının düzeltilmesi için karakter düzeyinde bir seq2seq dönüştürücü modeli geliştirilmiştir. Model için doğru yazılmış Türkçe cümleler toplanmış ve toplanan cümlelere farklı türdeki yazım hataları sistematik olarak eklenerek Türkçe yazım düzeltmesi için bir veri seti oluşturulmuştur. Seq2seq modelleri tekrarlanan kod çözme yönteminden dolayı yüksek bir tahmin süresine sahiptir. Bu sorunu çözmek için, transformer modelinin çıktıları tek seferde tahmin ettiği, yeni bir model mimarisi önerilmiştir, tek adımlı seq2seq transformer modeli. Önerilen modeller, tam eşleşme kriterleri ile test edilmiştir. Standart seq2seq modeli ve tek adımlı seq2seq modeli sırasıyla \%68.64 ve \%42.69 doğruluk oranı elde etti. Son olarak, standart seq2seq modeli 160 giriş karakteri için 8.47 saniyede tahminleme yaparken, tek adımlı seq2seq modeli 160 giriş karakteri için CPU'da 73 milisaniyede ve GPU'da 28 milisaniyede tahminleme yapar.","Natural language processing (NLP) is a fascinating area of artificial intelligence. It allows humans to interact with machines through natural language. There are two main concepts in NLP model architectures, namely input vectorization and contextual representation. The input vectorization process starts with tokenization, where there are three approaches: character-level, word-level, and subword-level. Word-level tok- enization results in a large vocabulary, and in agglutinative languages such as Turkish, words derived from the same stem are treated as different words. This makes it difficult for NLP models to understand their relationships and the meaning of the morphological affixes. Furthermore, all NLP models suffer from a common problem: spelling errors in the data. In case of spelling errors, the misspelled tokens become completely different and the models cannot understand them. In this thesis, a character-level seq2seq trans- former model is developed for spelling error correction. To train the model, a dataset for Turkish spelling correction is created by collecting correctly spelled Turkish sen- tences and systematically adding spelling errors to them. Seq2seq models suffer from multiple decoding iterations and have high prediction time. To address this problem, a novel model architecture, one-step seq2seq transformer model, is proposed in which the transformer model predicts the outputs in one iteration. The proposed models are tested with the exact match criteria. The standard seq2seq model and the one-step seq2seq model achieved 68.64% and 42.69% accuracy, respectively. Finally, the stan- dard seq2seq model makes predictions for 160 input characters in 8.47 seconds, while the one-step seq2seq model makes predictions for the same number of characters in 73 milliseconds on CPU and 28 milliseconds on GPU."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaret dilleri, sağır bireylerin esas iletişim dilidir. Bu diller el şekilleri, üst vücut hareketleri ve yüz ifadeleri gibi birden fazla kip kullanarak iletişim kurulmasını sağlayan görsel dillerdir. İşaret dili tanıma modelleri, sağır ve duyma engeli bulunmayan insanlar arasında iletişimi kolaylaştırma potansiyeline sahiptir. Derin öğrenme alanındaki ilerlemeler ve erişime açık veri kümelerinin sayısının artması daha fazla araştırmacıyı işaret dili tanıma alanına yönlendirmiştir. Derin öğrenme alanındaki ilerlemeler ile işaret dili tanıma çalışmalarında kullanılan manuel öznitelik çözümlerinin yerini 2 boyutlu Evrişimsel Sinir Ağları (2B ESA) almaya başlamıştır. 2B ESA'nın zamansal modellemedeki yetersizliği ve 3B ESA'nın uzam-zamansal modelleme kabiliyeti 3B ESA'yı çok kullanılan bir çözüm haline getirmiştir. 3B ESA'ların başarılı sonuçlarına rağmen hesaplama maliyetinin ve hafıza ihtiyacının yüksek olması alternatif mimariler aranmasına sebep olmuştur. Bu tezde 2B ESA tabanlı zamansal kayma ile dikkat modellemesi yapan bir işaret dili tanıma modeli önerdik. 2B ESA kullanılması, karşılığı olan 3B ESA'ya göre parametre sayısını ve gerekli hafıza boyutunu azaltmıştır. Diğer veri kümeleri ile uygulanabilirliğini artırmak ve eğitim sürecini kolaylaştırmak için işaretçinin belirli vücut bölümlerine odaklanan görüntü kesimleri yerine tam çerçeve RGB görüntüler kullanılmıştır. İşaret dilinde iletişim birden çok görsel kipin aynı veya farklı zamanlarda kullanılması ile sağlandığı için model bu kiplerin birbirleri ile nasıl etkileşime girdiğini öğrenmelidir. Zamansal kayma modülleri 2B ESA tabanlı modele zamansal modelleme kabiliyeti verirken, dikkat modülleri ise videolarda neye, nereye ve ne zamana odaklanacağını öğrenmektedir. Modelimizi, Türkçe izole işaret dili veri kümesi olan BosphorusSign22k ile test ettik. Önerilen model %92.97 sınıflandırma başarımı elde etmiştir. Çalışmamız, izole işaret dili tanımada 2B ESA tabanlı zamansal kayma ile dikkat modellemesi yaparak rekabetçi sonuçlar alınabileceğini göstermiştir.","Sign languages (SLs) are the main communication language of deaf people. They are visual languages that establish communication through multiple cues including hand gestures, upper-body movements and facial expressions. Sign language recognition (SLR) models have the potential to ease communication between hearing and deaf people. Advancements in deep learning and the increased availability of public datasets have led more researchers to study SLR. These advancements shifted solution methods for SLR from hand-crafted features to 2 Dimensional Convolutional Neural Network (2D CNN) models. Inadequacy of 2D CNNs on temporal modeling and 3D CNNs' ability of spatio-temporal modeling made 3D CNNs a popular choice. Despite its successful results, high computational costs and memory requirements of 3D CNNs created a need for alternative architectures. In this thesis, we propose an SLR model that uses 2D CNN as backbone and attention modeling with temporal shift. Usage of 2D CNN decreases the number of parameters and required memory size compared to its 3D CNN counterpart. In order to increase adaptability to other datasets and simplify the training process our model uses full frame RGB images instead of cropped images that focus on specific body parts of signers. Since communication in SL is established by using multiple visual cues at the same time or at different moments, the model must learn how these cues are collaborating with each other. While temporal shift modules give our 2D CNN backbone model the ability of temporal modeling, attention modules learn to focus on what, where and when in videos. We tested our model with BosphorusSign22k dataset which is a Turkish isolated SLR dataset. The proposed model achieves 92.97% classification accuracy. Our study shows that attention modeling with temporal shift on top of 2D CNN backbone gives competitive results in isolated SLR."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bağlılık ayrıştırma, otomatik soru cevaplama ve makine çevirisi gibi birçok doğal dil işleme (DDİ) sistemi için önemli bir adımdır. Zengin morfolojisi ve karmaşık gramer yapısıyla Türkçe dili otomatik işlenmesi oldukça zor bir dildir. Türkçe DDİ araçlarının ve kaynaklarının kısıtlı olması bu işi daha da zorlaştırmaktadır. Veri güdümlü derin öğrenme modelleri, bağlılık ayrıştırma alanında etkili performans göstermektedir. Veri güdümlü bir bağlılık ayrıştırıcıyı eğitmek için gereken verinin miktarı ayrıştırıcının performansını doğrudan etkilemektedir. Ayrıca, derin öğrenme tabanlı sistemlerin yüksek başarı göstermesi için büyük miktarlarda veriye ihtiyaç duyduğu gözlemlenmiştir. Bu tezde, Türkçe bağlılık ayrıştırmadaki zorlukların üstesinden gelmek için iki tip çözüm önerdik. İlk olarak, Türkçe metinleri ayrıştırmak için gereken veri miktarını ve kalitesini artırdık. Bu bağlamda, 9.761 yeni cümleyi manuel olarak etiketleyerek BOUN ağaç yapılı derlemini oluşturduk. Aynı etiketleme şemasıyla IMST ve PUD ağaç yapılı derlemlerini de yeniden etiketledik. Bu sayede Türkçe için dil bilgisi kurallarına göre tutarlı en büyük ağaç yapılı derlem koleksiyonunu kullanıma sunduk. İkinci olarak, Türkçe ve diğer az kaynaklı diller için özgün ve son teknoloji bağlılık ayrıştırıcılar geliştirdik. Önce, Türkçe dil bilgisi kurallarının ve kelimelerin morfolojik özelliklerinin derin öğrenme modeline entegre edildiği bir hibrit bağlılık ayrıştırma mimarisi önerdik. Sınırlı eğitim verisine rağmen, hibrit ayrıştırıcıyla Türkçe bağlılık ayrıştırmada mevcut yöntemlerden daha yüksek başarı elde ettik. Ayrıca, yarı denetimli geliştirmeye dayalı bir derin öğrenme tabanlı bağlılık ayrıştırıcı önerdik. Türkçe'nin yanı sıra kaynak yetersizliği olan başka dillerde de deneyler yaparak son teknoloji sonuçlar elde ettik. Derin öğrenme tabanlı modellerin yalnızca fazla miktarda eğitim verisiyle değil, aynı zamanda akıllıca çıkarılan bilgilerin entegrasyonuyla da geliştirilebileceğini gösterdik.","Dependency parsing is an important step for many natural language processing (NLP) systems such as question answering and machine translation. Turkish, being a morphologically rich language and having a complex grammar, is challenging for automatic processing. Limited NLP tools and resources for Turkish make the task even more challenging. Data-driven deep learning models show promising performance in dependency parsing. Yet, the amount of data to train a data-driven dependency parser directly affects performance, and deep learning-based systems require extensive data to achieve good performance. In this thesis, we focused on Turkish dependency parsing and proposed two solutions to the challenges this task poses. First, we increased the size and quality of labeled data for Turkish dependency parsing. In this respect, we created the BOUN Treebank by annotating 9,761 sentences. In addition, we re-annotated the IMST and PUD treebanks using the same annotation scheme. As a result, we presented the largest collection of Turkish treebanks with consistent annotation. Second, we developed novel state-of-the-art dependency parsing models for Turkish as well as other low-resource languages. As our first parsing approach, we introduced a hybrid dependency parser where Turkish grammar rules and morphological features of words are integrated into the deep learning model. Despite the limited training data, the hybrid parser achieved higher success than the current methods for Turkish dependency parsing. As our second parsing approach, we proposed a deep dependency parser with semi-supervised enhancement. By conducting experiments on a number of low-resource languages besides Turkish, we achieved state-of-the-art results on all datasets. We have shown that deep learning-based models can be improved not only by additional training data, but also by integrating intelligently extracted information."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Konu modelleri, bir belge koleksiyonunu analiz etmek için kullanılan olasılıksal üretken modellerdir. İnsanlar, belgelerden gizli yapıları çıkarmak için uzun yıllardır konu modellerinden yararlandı. Ancak, Gizli Dirichlet Tahsisi (LDA) gibi klasik konu modelleri, kullanıcı tarafından oluşturulan sosyal medya içeriğinde tipik olan kısa metinlerle ilgili sorunlar yaşar. Kısa metinlerin sınırlı bağlamı nedeniyle, onları iyi temsil etmeyen kelime temsilleri çantasıyla geniş kelime dağarcığından yorumlanabilir konular öğrenemezler. Bu tez, belgelerin, bilgi grafiği olarak Wikidata kullanılarak, varlığa özel ilişkilere sahip çizgeler olarak temsil edildiği, Çizge Sinir Ağlarına (GNN) dayalı bir konu modeli önermektedir. Bir çizge dikkat ağı, bu belgelerin yerleştirmelerini ve kendi çıktılarını, olasılıksal üretken konu modeli olan Varlık Gömülü Konu Modellemesi'ne (EETM), konuları elde edebilmesi için, olasılıksal dağılım parametreleri şeklinde geçirerek öğrenir. Modelimizi Twitter'dan siyaset, spor, pandemi ve trend olan haberlerle ilgili çeşitli kısa metin koleksiyonları ile değerlendirdik. Modelimizden sağladığı konuların öğrenilen yerleştirmeleri ve nitelikleri ile ilgili gözlemlerimizle ilgili ayrıntılı bir tartışma sunduk.","Topic models are probabilistic generative models used to analyze a collection of documents. People have leveraged topic models for many years to extract hidden structures from documents. However, classical topic models such as Latent Dirichlet Allocation (LDA) have issues with short texts typical in user-generated social media content. Due to the limited context of short texts, they fail to learn interpretable topics from extensive vocabularies with the bag of word representations that do not represent them well. This thesis proposes a topic model based on Graph Neural Networks (GNN) where documents are represented as graphs with entity-specific relations using Wikidata as a knowledge graph. A graph attention network learns the embeddings of these documents whose outputs are passed to the probabilistic generative topic model Entity Embedded Topic Modeling (EETM) as probability distribution parameters to yield the topics. We evaluate our model with various short text collections fetched from Twitter related to politics, sports, pandemics, and trending news events. We provide a detailed discussion regarding our observations related to the learned embeddings and qualities of topics resulting from our model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar grafikleri, 3B bilgisayarlı görü ve robotik komüniteleri 3B şekilleri ifade etmek, modellemek ve jenere etmek için pek çok yöntem geliştirmiş ve kullanım alanı oluşturmuştur. Bu kullanım alanlarının bazıları 3B şekilleri kodlama ve sıkıştırma ve kısmi 3B şekillerin tamamlanması olup; 3B şekil manipülasyonu ve tek resimden 3B şekil üretme hala görece az çalışılmış konulardır. 3B şekil manipülasyonu ve tek resimden 3B şekil üretme konuları birbirleriyle ilişkili olup, bu konular üzerindeki çalışmalar yeni dizayn metodolojilerini mümkün kılacaktır. Bu tezde 3B şekil manüpülasyonu için bir çerçeve geliştirip, baz model olarak Deep Implicit Templates'i kullandık. Bu model 3B şekil üretmenin haricinde, aynı kategoriye ait şekiller için topolojik benzerlik haritaları çıkarabilmektedir. Bunun için öncelikle 3B şekil temsil formatlarını ve ilgili araştırmaları anlatmakla başlayıp, daha sonra geliştirdiğimiz metodları ve çerçeveyi anlattık. Tezimizde ana veriseti olarak ShapeNetV2'yi kullanarak Deep Implicit Templates katmanları içinde denetimli ve denetimsiz yönler bulduk. Deneylerimiz sonucunda, PCA uygulayarak bulduğumuz denetimsiz yönlerin pek çok lokal ve global özelliği temsil ettiğini gördük: sandalye yüksekliği, araba uzunluğu, dizayn trendleri ve şekil alt kategorileri gibi. Ek olarak, ShapeNetV2 meta verisini ve öğrenilmiş şekil kodlarını kullanarak eğitilmiş lineer SVM modelleriyle başarılı şekilde denetimli manipülasyon yapabileceğimizi gösterdik. Son olarak, eğitilmiş bir Vision Transformer (ViT) modelinin ve eğitilmiş bir birleşik resim-yazı temsili modeli olan, CLIP'in ara katmanlarını kullanarak gerçek zamanlı ve efektif bir tek resimden 3B şekil üretme metodu geliştirdik. Geliştirdiğimiz metod, ViT ve CLIP'in ara katmanlarıyla DIT'in ara katmanları arasında köprü görevi görmekte olup, poz ve perspektiften bağımsız olarak gerçek zamanlı ve yüksek kalitede resimleri 3B şekillere dönüştürebilmektedir.","Computer graphics, 3D computer vision and robotics communities have produced multiple approaches to represent and generate 3D shapes, as well as a vast number of use cases. These use cases include, but are not limited to, data encoding and compression, shape completion and reconstruction from partial 3D views. However, controllable 3D shape generation and single-view reconstruction remain relatively unexplored topics that are tightly intertwined and can unlock new design approaches. In this work, we propose a unified 3D shape manipulation and single-view reconstruction framework that builds upon Deep Implicit Templates, a 3D generative model that can also generate correspondence heat maps for a set of 3D shapes belonging to the same category. For this purpose, we start by providing a comprehensive overview of 3D shape representations and related work, and then describe our framework and proposed methods. Our framework uses ShapeNetV2 as the core dataset and enables finding both unsupervised and supervised directions within Deep Implicit Templates. More specifically, we use PCA to find unsupervised directions within Deep Implicit Templates, which are shown to encode a variety of local and global changes across each shape category. In addition, we use the latent codes of encoded shapes and metadata of the ShapeNet dataset to train linear SVMs and perform supervised manipulation of 3D shapes. Finally, we propose a novel framework that leverages the intermediate latent spaces of Vision Transformer (ViT) and a joint image-text representational model, CLIP, for fast and efficient Single View Reconstruction (SVR). More specifically, we propose a novel mapping network architecture that learns a mapping between the latent spaces ViT and CLIP, and DIT. Our results show that our method is both view-agnostic and enables high-quality and real-time SVR."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sağlarlıklar, bir nesnenin bir aktör tarafından kapasitelerine dayalı olarak doğrudan algılanan eylem olanaklarıdır. Sağlarlıklar, aktörün kapasitelerini hedefsiz keşfetmesi sırasında nesneler üzerindeki aksiyonlarının etkilerini gözlemlemesinden öğrenilir. Aktör daha sonra, belirli bir nesne üzerinde hangi eylemlerin mümkün olduğunu ve hangilerinin istenen etkiyle sonuçlandığını bildiğinden, bir hedefe ulaşmak için planlar yapmak için öğrenilen sağlarlıkları kullanabilir. Bir robotun repertuarındaki hangi eylemlerin çevresindeki bir nesneye uygulanabilir olduğu ve hangi etkiye sahip olduğunu ayırt etmeyi öğrenmek için robotikte de sağlarlık ilkesi izlenir. Bu bilgi daha sonra, doğrudan veya olası çözümler için arama alanını daraltmak amacıyla hedefe yönelik planlamada kullanılabilir. Bu çalışmada, sürekli alanda nesne manipülasyonu için çok adımlı tahminler yapma problemi incelenmiştir. Bir robotun repertuarında çeşitli eylem türleri tanımlanır ve robotun bir masa üstü ortamında farklı niteliklere sahip bir dizi nesneyle etkileşimleri kaydedilir. Nesnenin yukarıdan ortalanmış derinlik görüntüsünün yanı sıra genelleştirilebilirliğe izin veren eylemleri ve etkileri temsil etmek için göreceli mesafe miktarları kullanılır. Bu veriler, etkileri tahmin etmek için eylemler üzerinde, uygulanan eylemleri tahmin etmek için etkiler üzerinde veya eylemleri ve etkileri tahmin etmek için her ikisi üzerinde koşullandırılabilen bir modeli eğitmek için kullanılır. Bu modelin üzerinde bir planlayıcı kullanarak, bir nesnenin istenen hedef konumuna ulaşması için doğru bir eylem dizisini zincirleme kapasitesi elde edilir. Model, deneylerle doğrulanmıştır, makul planları verimli bir şekilde üretir ve yürütür. Daha önceki çalışmalardan farklı olarak, sürekli etki ve eylemlerin kullanılması, planlayıcının, eylemlerin kısmen uygulandığı ve eğitimlerde görülmeyen konfigürasyonlara da çözüm bulmasını sağlar.","Affordances are action possibilities of an object, directly perceived by agents based on their capabilities. Affordances are learned from goal-free exploration of the agent's capabilities through observing the effects of their actions on objects in an environment. The agent can then use the learned affordances to make plans to reach a goal since the agent knows which actions on a certain object are possible and which action results in the desired effect. The affordance principle is also followed in robotics to learn to distinguish which actions in the repertoire of a robot are applicable to an object in its environment. This information can then be utilized in goal-directed planning, either directly or with the aim of reducing the search space for possible solutions. In this work, the problem of making multi-step predictions for object manipulation is investigated in the continuous domain. Several types of actions are defined in a robot's repertoire, and the interactions of the robot with a number of objects possessing differing qualities in a tabletop setting are recorded. Relative distance quantities are used for representing actions and effects which allow generalizability, alongside a top-down centered depth image of the object. This data is used to train a model which can be conditioned on actions to predict the effects, conditioned on effects to predict the applied actions, or conditioned on both to predict the actions and effects. By using a planner on top of this model, the capacity to chain together a correct sequence of actions for an object to reach the desired goal position is achieved. The model is verified in experiments, generating and executing reasonable plans efficiently. Setting it apart from previous work, using continuous effect and actions enables the planner to find solutions to configurations that were not observed in training using partial action executions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Stres, günümüz dünyasında ciddi zihinsel ve fiziksel sağlık sorunlarına ana katkıda bulunanlardan biri haline gelmiştir. Literatürdeki mevcut çalışmalar, psikofizyolojik önlemleri kullanmış ve stresi tespit etmek ve kullanıcıların stresi düzenlemesine yardımcı olmak için geri bildirimi yönetmek için çok sayıda mekanizma önermiştir. Göze batmayan giyilebilir cihazların popülaritesi giderek artıyor, dijital sağlık kavramlarıyla iç içe geçiyor ve onları verimli, ucuz ve kolay erişilebilir etkili kendi kendine yardım teknolojileri yapıyor. Bu tez ilk olarak laboratuvar ve günlük ortamlarda stres algılama mekanizmalarını araştırmayı ve uygulamayı amaçlamaktadır. Bu bağlamda, laboratuvarda ve gerçek yaşam ortamlarında kullanılan farklı türde giyilebilir cihazlardan gelen çok modlu verileri verimli bir şekilde kullanabilen stres ölçüm modellerinin nasıl tasarlanacağı ve konuşlandırılacağı gibi çeşitli yolları araştırdık. Ayrıca günlük yaşamın stresli koşullarında duygu düzenleme için düşük maliyetli ve pratik yöntemler üzerinde çalışdık. Bir sonraki adımda, karma yöntemli bir çalışma yürütüldü. Bunun için birden fazla giyilebilir cihazdan gelen sinyaller ve kullanıcıların giyilebilirliğin farklı yönlerine ilişkin öznel görüşleri nicel ve nitel olarak analiz edildi. Bir sonraki adım, dokunsal geribildirimin duygu düzenleme üzerindeki etkilerini gösterdiğimiz derinlemesine bir çalışmadır. Kullanıcıların doğru cihazı seçmelerine yardımcı olmak için, farklı teknolojilerle giyilebilir cihazlarda stres algılama kalitesini karşılaştırmak için birkaç giyilebilir cihazı tamamen aynı koşullar altında değerlendirdik. Son olarak, modellerimizi son kullanıcılar ve özellikle psikologlar ve klinik uzmanlar için daha anlaşılır kılmak için Açıklanabilir Yapay Zeka'yı kullanıyoruz. Çalışmalarımızın sonuçları, günlük yaşamda stresi düzenlemek için güvenilir bir sistem sağlamak için entegre bir tespit, bildirim ve müdahale döngüsünün gerekli olduğunu göstermektedir.","Stress has become one of the main contributors to serious mental and physical health issues in today's world. Existing works in the literature have used Psychophysiological measures and proposed numerous mechanisms to detect stress and administer feedback to help users regulate it. Unobtrusive wearables' popularity is increasingly growing, intertwined with digital health notions, making them efficient, inexpensive, and easily accessible affective self-help technologies. This thesis first aims to investigate and implement stress detection mechanisms in the laboratory and everyday environments using unobtrusive wearable devices. In this regard, we investigate various scenarios, such as how to design and deploy stress measurement models that can efficiently use multi-modal data coming from different types of wearables used in the laboratory and real-life settings. We also study low-cost and practical methods for emotion regulation in stressful conditions of everyday life. In the next step, a mixed-methods study is conducted. For this, signals from multiple wearables and users' subjective opinions regarding different aspects of wearability were analyzed quantitatively and qualitatively. The next step is an in-depth study in cooperation with HCI researchers, in which we demonstrate the effects of haptic feedback on emotion regulation. As a next step for helping users choose the right device, we evaluate several wearables under completely identical conditions to compare the stress detection quality in wearables with different technologies. Finally, we utilize Explainable AI (XAI) to make our models more understandable for the end users, and in particular for the psychology and clinical experts. The results of our studies indicate that an integrated detection, notification, and intervention cycle is required to ensure a reliable system for regulating stress in daily life."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaret dilleri, Sağırlar için ana iletişim aracıdır. Ancak, Sağırların bilgiye erişimi için gerekli geri getirme sistemleri henüz geliştirilmemiştir. Bu sorunun çözümüne yönelik, bu tezde işaret dilinde anahtar sözcük arama sorunu ele alınmıştır. Anahtar sözcük arama, konuşma işleme gibi alanlar için detaylıca çalışılmış bir problem olsa da, işaret dili bağlamında kapsamlı bir şekilde çalışılmamıştır. Bu tezde, mevcut bir işaret dilinde anahtar sözcük arama sisteminde yapılan iyileştirmelerin yanı sıra yeni bir yinelemeli eğitim yaklaşımı önerilmiştir. Çizge Dikkatli Sinir Ağları (GAT) işaret dili alanına uyarlanıp, öğrenilebilir maske ve ayrık bir zamansal dikkat mekanizması kullanılarak geliştirilmiştir. Ayrıca, Sözde-İlişiklik Geri Bildirimi (PRF) tekniğinin geri getirme performansına olan etkisi incelenmiştir. Bunun yanı sıra, mevcut modelin benzerliğe dayalı yöntemlerle, kosinüs ve üçüz kayıpları kullanılarak eğitilebileceği ve daha sonra performansı artırmak için diğer modellerle birleştirilebileceği gösterilmiştir. Son olarak, tahminlerini kademeli olarak iyileştiren Beklenti-Enbüyütme (EM) tekniğine benzer yinelemeli bir eğitim yöntemi önerilmiştir. Bu yöntem, incelikli video-sorgu etkileşimlerini keşfetmek için bir sorgu kodlayıcının yanı sıra medyumlar arası bir dikkat mekanizması kullanır. Deneyler, RWTH-Phoenix2014T veri kümesi üzerinde gerçekleştirilmiş olup önerilen yöntemlerin başarımı gösterilmiştir. Sonuçlar, poz modellerinin GAT tabanlı kodlayıcılarla, yinelemeli bir şekilde eğitildiğinde geri getirme başarımını önemli derecede iyileştiğini göstermiştir.","Sign languages are the main medium of communication for the Deaf. However, insufficient retrieval tools for sign languages restrict the Deaf's access to information. To address this issue, we tackle the problem of keyword search in sign language. Although keyword search is a well-studied task for domains like speech processing, it has not been extensively studied in the context of sign language. To this end, we introduce improvements to an existing keyword search system for sign language and a new iterative training approach. We adapt Graph Attention Networks (GAT) to the sign language domain and extend its capabilities by employing a learnable mask and a separate temporal attention mechanism. Moreover, we investigate the effectiveness of the Pseudo-Relevance Feedback (PRF) technique in improving retrieval accuracy. Additionally, it is demonstrated that the existing model can also be trained with similarity-based methods using cosine and triplet losses, which can later be fused with other models to boost performance. Finally, we introduce an iterative training method similar to Expectation-Maximization (EM) that gradually improves its predictions. This method employs a cross-modal attention mechanism and a query encoder to discover subtle video-query interactions. The experiments are carried out on the RWTH-Phoenix2014T dataset, where the effectiveness of the proposed methods is verified. The results show that the pose models trained with a GAT-based encoder and in an iterative way significantly improve the retrieval performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yenilenebilir enerji kaynaklarına yönelimin artmasıyla birlikte rüzgar enerjisi birçok araştırmaya konu olmuştur. Rüzgar enerjisi, atmosferik koşullardaki, özellikle rüzgar hızındaki belirsizlikler nedeniyle, doğru bir şekilde tahmin etmeyi zorlaştıran stokastik bir yapıya sahiptir. Bu problemi çözmek için literatürde Sayısal Hava Tahmini modellerini girdi olarak kullanan istatistiksel yöntemler önerilmiştir. Rassal Orman, rüzgar enerjisi tahmininde sıklıkla kullanılan başarısı kanıtlanmış istatistiksel bir modeldir. Rassal Orman, veriyi her düğümde tek bir değişken üzerinden bölen karar ağaçlarını bir araya getirmektedir. Ancak tek bir değişken üzerinden yapılan bölünmeler doğru bir ayrım sağlamayabilir. Bu nedenle literatürde, özellikle sınıflandırma problemlerinde uygulanan ve veriyi doğrusal değişken kombinasyonları üzerinden bölen eğik karar ağacı algoritmaları önerilmektedir. Literatürde zaman serisi regresyon problemlerinde uygulanan eğik karar ağacı tabanlı yöntemler ile ilgili sınırlı sayıda çalışma bulunmaktadır. Bu tez, eğik karar ağaçlarını bir araya getiren bölgesel rüzgar enerjisi tahmin probleminde uygulanacak yeni bir strateji önermektedir. Önerilen yöntem, üç rüzgar enerjisi tahmin probleminde tek bir değişken üzerinden bölmeler yapan muadilleri ile karşılaştırılmıştır. Hesaplanan sonuçlara göre önerilen yöntem üç veri setinin hepsinde daha iyi performans göstermektedir.","With the increasing trend towards the use of renewable energy sources, wind power has been the subject of many researches. Wind power has stochastic nature due to uncertainties in atmospheric conditions, especially in wind speed, which makes it hard to forecast accurately. To solve the problem, statistical methods using Numerical Weather Prediction (NWP) models as inputs are proposed in the literature. Random Forest is a statistical model frequently used in wind power forecasting with proven success. Random Forest ensembles decision trees that partition the feature space over a single variable at each node. However, partitions based on a single variable may fail to provide a proper distinction. Thus, oblique decision tree algorithms evaluating the partitions over linear combinations of variables are proposed in the literature, especially on classification problems. There are a limited number of studies in the literature on oblique decision tree-based methods applied in time series regression problems. This thesis proposes a novel strategy to be applied in regional wind power fore- casting tasks that ensembles oblique decision trees. The proposed method is compared with its univariate counterparts in three wind power forecasting tasks. Computational results show that the proposed method performs better on all tasks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Küreselleşme, tedarik zincirlerinin daha karmaşık hale gelmesine sebep oldu ve şeffaflık, izlenebilirlik ve kontrol eksikliği sorunlarını yarattı. Doğal kaynakların uygunsuz bir şekilde kullanılması ve alt seviyelerdeki opak tedarik zincirlerinde insanların ve çevrenin sömürülmesi söz konusudur. Şirketler, tedarikçilerinin alt kademelerinde bu yanlış uygulamalardan sorumlu tutulmalıdır. Tüketiciler ve hükümetler, kuruluşların ürünlerinin ve tedarik zinciri faaliyetlerinin çevresel ve sosyal etkilerini açığa çıkarmalarını talep etmektedir. Bu yüzden, geleneksel tedarik zincirlerinin radikal bir değişime ihtiyacı vardır. Şirketler, operasyonlarının çevresel ve sosyal sürdürülebilirliğini ve şeffaflığını ön planda tutacak şekilde iş modellerini değiştirmelidirler. Blokzincir teknolojisi, tedarik zinciri katılımcıları arasında şeffaflık, izlenebilirlik, güvenlik ve gerçek zamanlı bilgi paylaşımını sağlayan özellikler sunar. Sürdürülebilir tedarik zinciri yönetimindeki zorlukların üstesinden gelme potansiyeline sahiptir. Bu tezde, tedarik zincirlerinin çevresel ve sosyal sürdürülebilirliği için nicel bir sürdürülebilirlik ölçüm modeli sunulmaktadır. Sonrasında, tedarik zinciri boyunca ürünleri izlemek ve tedarik zinciri aktörlerinin çevresel ve sosyal sürdürülebilirliğini değerlendirmek için bir blokzincir tabanlı karar destek sistemi geliştirilmiştir. Şirketler, tedarik zinciri faaliyetleri hakkında daha fazla bilgi edinmek ve sürdürülebilirlik performanslarını ölçmek için bu sistemi kullanabilirler.","Globalization has caused supply chains to become more complex and has created problems of misinformation, lack of transparency, traceability, and control. There is an inappropriate use of natural resources and exploitation of people and the environment at lower-tier levels of opaque value chains. Companies are pressured to be held accountable for these malpractices at the lower-tier levels of their suppliers. Consumers and governments demand that organizations reveal the environmental and social impacts of their supply chain activities. It is expected from companies to transform their business models to prioritize transparency and the environmental and social sustainability of their operations. Blockchain technology offers the essential properties that can make this transformation possible, it enables transparency, traceability, security, and real-time information sharing across supply chain participants. It has the potential to overcome the challenges in sustainable supply chain management. In this thesis, a quantitative sustainability measurement model for the environmental and social sustainability of supply chains is presented. Subsequently, a blockchain-based decision support system is developed to track and trace products throughout the supply chain and assess the environmental and social sustainability of the products and supply chain actors. Companies can use this system to gain more information about their supply chain activities and measure their sustainability performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin öğrenme uygulamalarının çalışma süresi, kaynak kullanımı ve enerji maliyeti bu uygulamalar arttıkça daha önemli bir duruma gelmiştir. Uzun bir süredir çalışılan sabit matris çarpımı, derin öğrenmede de kullanılmaktadır. Bu uygulamaların hesaplama maliyetinin düşürülmesi yaygın bir araştırma konusudur. Ağırlıklar istenen doğruluk oranı gözetilerek budanır veya nicelendirilir. Budanan matrisler veri kaybı olmadan tek boyutlu dizilerin içine sıkıştırılır. Matris çarpımı bu dizileri geri açmadan işleyerek gerçekleştirilir. Matris çarpımını gerçekleştirmek için tek boyutlu dizilerin işlenmesi Merkezi İşlem Birimi, Görüntü İşlem Birimi ve Alanda Uyarlanabilir Kapı Dizini çalıştıran çeşitli donanımlara uygulanır. Bu uygulamalar toplama ve çarpma sayıları ile depolama boyutunu düşürmek için ortak alt ifade eleme yöntemleri ile de desteklenebilir. Ancak, son yöntemler büyük sabit matrisler için ölçeklenebilir değildir çünkü hesaplama süreleri 200x200 boyutlu bir matris için saatleri bulmaktadır. Bu tezde algoritmanın hesaplama süresini azaltmak için rastgele arama tabanlı bir ortak alt ifade eleme yöntemi inşa edilmiştir. Bu algoritma 1000x1000 boyutlu bir matris için toplama ağacını bir dakikada üretmektedir. Önerilen yönteme uygun bir sıkıştırma gösterimi Sıkıştırılmış Seyrek Satır biçimini genişleterek geliştirilmiştir. Tek çekirdekli gömülü sistem simülasyonları, 100x100 boyutlu bir matris çarpımı için işlem süresinin son yöntemlere göre \%80 azaldığını göstermektedir. Deneylerde seyrek matrislerin depolama boyutu da Sıkıştırılmış Seyrek Satır biçimiyle elde edilenin yarısından azdır.","The execution time, resource and energy costs of deep learning applications become much more important as their popularity grows. The Constant Matrix Multiplication has been studied for a long time and takes place in deep learning applications. Reducing the computation cost of those applications is a highly active research topic. The weights are pruned or quantized while satisfying the desired accuracy requirement. The pruned matrices are compressed into one-dimensional arrays without data loss. Matrix multiplication is performed by processing those arrays without decompression. Processing one-dimensional arrays to perform matrix multiplication is deployed on various hardware platforms that employ Central Processing Unit, Graphics Processor Unit and Field-Programmable Gate Array. The deployments can also be supported with common subexpression elimination methods to reduce the number of multiplications, additions and storage size. However, the state-of-the-art methods do not scale well for the large constant matrices as they reach hours for extracting common subexpressions in a 200x200 matrix. In this thesis, a random search-based common subexpression elimination method is constructed to reduce the run-time of the algorithm. The algorithm produces an adder tree for a 1000x1000 matrix in a minute. The Compressed Sparse Row format is extended to build a one-dimensional compression notation for the proposed method. Simulations for a single-core embedded system show that the latency is reduced by 80\% for a given 100x100 matrix compared to the state-of-the-art methods. The storage size of the sparse matrices is also reduced by more than half in the experiments compared to the Compressed Sparse Row format."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, zaman serileri çerçevesinde kısa vadeli trafik akışı tahmin stratejileri üzerine vaka çalışmaları sunmaktadır. Geleneksel, makine öğrenimi ve derin öğrenme yöntemlerini tartıştıktan sonra, ana hedeflerden biri hibrit yöntemlerin kullanımları üzerinde de testler gerçekleştirmektir. Trafik akışı literatüründe halihazırda kullanılan yaklaşımları analiz etmenin yanı sıra, farklı yöntemleri de tanıtıyor ve test ediyoruz. Ayrıca, nokta tahmin sonuçlarımızı aralık tahminleri de kullanarak destekliyoruz. Tez içerisinde, kantil regresyon ortalaması ve kantil regresyon sinir ağı gibi kantil regresyona dayalı aralıklarla özel olarak ilgilenilmektedir. Hem nokta hem de aralık tahminleri, çeşitli değerlendirme ölçütleri aracılığıyla değerlendirilmektedir ve incelenen metodolojiler arasında kapsamlı bir karşılaştırma sağlanmaktadır.","This thesis gives case studies on short-term traffic flow forecasting strategies within a time series framework. After discussing the traditional, machine learning and deep learning methods, one of main goals is to experiment on the uses of hybrid methods. Besides analyzing approaches that were already used in the traffic flow literature, we also introduce and test distinct strategies. Further, we supplement our point forecast results with interval forecasts. In particular, quantiles regression based intervals such as quantile regression averaging and quantile regression neural network are implemented. Both point and interval forecasts are evaluated via several evaluation metrics, and an extensive comparison is provided among the methodologies studied."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Etnik kökenlere, milliyetlere, dini kimliklere ve belirli gruplara yönelik nefret söylemi sadece sosyal medyada değil, yazılı basında da artmaktadır. Bu artış basılı medyada okuyuculara sunulmadan önce nefret söylemi açısından hızlıca gözden geçirip filtreleyebilen otomatik nefret söylemi tespit sistemlerine ihtiyacı oluşturmaktadır. Ancak mevcut otomatik nefret söylemi tespit modellerinin çoğu haber metinlerinde sıklıkla kullanılan hedef grubuna özgü söylemi dikkate almadan nefret söylemini tespit etmekle sınırlıdır. Ayrıca nefret söylemi alanında Türkçe yazılı basın makalelerini içeren az sayıda veri seti bulunmaktadır. Bu çalışmada nefret söylemi tespiti için birçok hedef grup odaklı dilbilimsel özelliklerle zenginleştirilmiş BERT tabanlı yeni bir model önerilmiştir. Klasik yaklaşım olan BERT kodlayıcının sadece ilk gizli vektörünü kullanmak yerine farklı BERT gizli vektörlerini ağırlıklandırmanın etkileri de araştırılmıştır. Gizli vektörleri birleştirmek için farklı dikkat katmanı tekniklerini kapsayan BERT tabanlı modeller önerilmiştir. Nefret söylemi etiketi ile birlikte nefret söylemi olarak etiketlenen haberlerin hedef kitlesinin de belirtildiği önceden işlenmiş yeni bir Türkçe nefret söylemi veri kümesi de yayınlanacaktır. Bu kapsamlı Türkçe yazılı basın veri seti üzerinde yapılan deneyler, önceki yaklaşımlara kıyasla doğruluk ve F1 puanı açısından rekabetçi bir performansın elde edildiğini göstermektedir.","Hate speech directed at ethnicities, nationalities, religious identities, and specific groups has increased not only in social media, but also in print media. This creates a need for automated hate speech detection systems that can quickly review and filter print media content before it is provided to readers if it contains hate speech. However, most of the existing automatic hate speech detection models are limited to detecting hate speech without considering the hate speech target group-specific discourse that is often used in news articles. Moreover, there are few datasets that include Turkish print media articles in the hate speech domain. In this study, a new BERT based model enriched with a set of target-oriented linguistic features for hate speech detection is proposed. The effects of weighting different BERT hidden vectors are also investigated, instead of using only the first hidden vector of the BERT encoder, which is the classical approach. New BERT based models that integrate different attention techniques are proposed for combining hidden vectors. A new preprocessed Turkish dataset for hate speech is also published, in which the target group for all hate speech articles is annotated. Experiments on a comprehensive Turkish dataset of news articles labeled for hate speech show that competitive performance in terms of accuracy and F1-score is achieved compared to previous approaches."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Stres günümüzün en önemli problemlerinden biridir. Modern insan yaşamının bir parçası gibi görünse de ciddi sağlık sorunlarına neden olduğu bilinmektedir. Farklı disiplinlerden birçok araştırmacı bireysel ve sosyal etkileri olan bu konu üzerine uzun yıllardır çalışmaktadır. Psikologlar, davranış bilimciler ve psikiyatristler klinik ortamda araştırmalarını sürdürmektedir. Fakat stres faktörü günlük hayatın bir parçası olarak düşünülünce klinik ortamlar veya kontrollü deney alanları stres tanılama açısından yetersiz kalabilmektedir. Gelişen sensör teknolojileri, giyilebilir cihazlar ve makine öğrenmesi metodları sayesinde stres tanılama konusu bilgisayar bilimcilerinde ilgi alanı haline gelmiştir. Giyilebilir sensörler, yaygın bilişim ve makine öğrenimi konularında gelişmeler devam etse de bu alan yeni zorlukları beraberinde getirmektedir. Veri etiketleme yükü bu zorluklardan biridir. Özellikle stres problemi yaşayan deneklere günlük hayat içerisinde düzenli aralıklarla anket doldurtmak, veriler ile bu anket sonuç-larını senkronize etmek önemli efor ve kaynak gerektirmektedir. Biz de bu etiketleme yükünün farkında olarak günlük hayatta topladığımız çok tipli sensör fizyolojik veriseti içerisinden az miktarda etiketli veri kullanarak yeni bir çözüm yolu bulmayı hedefledik. Bu nedenle tez çalışması yarı-gözetimli öğrenme teknikleri kullanılarak eldeki az miktardaki etiketli veri kullanılarak nasıl sonuçlar elde edilebileceğine odaklanmaktadır.","Stress is one of the most important problems of today. Although it seems to be a part of modern human life, it is known to cause serious health problems. Many researchers from different disciplines have been working on this subject, which has personal and social effects, for many years. Psychologists, behavioral scientists, and psychiatrists continue their research in the clinical setting. However, when the stress factor is considered as a part of daily life, clinical environments or controlled experimental areas may be insufficient in terms of stress classification. Thanks to developing sensor technologies, wearable devices, and machine learning methods, stress classification has become an area of interest for computer scientists. Although developments in wearable sensors, ubiquitous computing, and machine learning continue, they bring new challenges to this field. The data labeling burden is one of these challenges. It requires significant effort and resources to have the subjects who have stress problems fill out questionnaires periodically in their daily life and to synchronize the physiological data with the questionnaire results. Being aware of this labeling burden, we aimed to find a new solution by using a less amount of labeled data from the multi-sensor physiological dataset that we collect in daily life. For this reason, this thesis focuses on what will be the performance of a system using a less amount of labeled data and semi-supervised learning techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda, resim, metin ve zaman serileri gibi çeşitli veri kümeleri için ayırt edici bölgelerin saptanması gelişmekte olan bir kavramdır. Gelişen veri depolama teknikleri ile birlikte, modellenebilecek zaman serilerinin büyüklüğü ve boyutu da arttı. Bilgisayarların hesaplama kapasiteleri de geliştirilmesine rağmen artan depolama ve hesaplama maliyetleri araştırmacıları daha optimum yöntemleri keşfetmeye zorlamaktadır. Zaman serisi sınıflandırma problemlerinde modellerin karmaşıklığını ve hesaplama maliyetlerini azaltmak için ham verinin tamamını kullanmak yerine zaman serilerindeki ayırt edici alt serileri kullanarak yeni öznitelik gösterimi oluşturulmaktadır. Bu öznitelik gösterimi de serinin ait olduğu sınıfı temsil etmektedir. Zaman serilerinde ayırt edici alt seriler, şekilcikler olarak adlandırılır. Birçok zaman serisi veri kümesinde, şekilcik kullanılarak kurulan sınıflandırma modelleri üstün performans göstermektedir. Ayrıca, şekilciklerin kolaylıkla açıklanabilir ve yorumlanabilir olması da kullanımını arttıran en önemli özelliklerindendir. Bu tezde, zaman serileri üzerinde ayırt edici bölgelerin zaman-gözlem uzayı üzerinde keşfedilmesi ve bu uzay kullanılarak şekilcik çıkarımıyla zaman serisi sınıflandırma akışı sunulmuştur. Uzayın tanımlanması için model seçiminin esnek olması da sunulan akışın bir avantajıdır. Ayırt edici bölgeler elde edildikten sonra, yeni bir öznitelik gösterimi oluşturmak için zaman-gözlem uzayında sınıflara ait, bir sınıflandırma modeliyle tahminlenen olasılık değerleri eşik değer ile filtrelenerek şekilcikler çıkarılır. Yeni öznitelik gösterimi oluşturulduktan sonra sınıflandırma modeli eğitilerek, zaman serisi sınıflandırma problemi çözülür. Deney sonuçlarına göre, önerilen olasılıksal ayırt edici bölge bulucu (PDRD) kullanılarak şekilcik çıkarma yöntemiyle yapılan sınıflandırma, referans veri setleri üzerinde rekabetçi sonuçlar sağlar.","Detecting discriminivative regions is a recent promising concept in many different domains for various dataset types such as image, text and time series. In time series domain, time series might be large and high dimensional because of the developing storage capacities. Although computational capacities are improved, storage and computation costs are increased. Therefore recent attempts are focused on the decreasing the computational and run time complexities. To decrease the complexity of the models, instead of using raw data, construction of the new feature representation by using the distinctive sub-sequences of the time series is the most common approach. Discriminative sub-sequences are called as shapelets in time series reflect the characteristics of the class of time series. Shapelets provide interpretable results and shapelet-based classifiers have superior accuracy on many time series datasets. Many researchers have proposed shapelet extraction methodologies for classification purpose. This study proposes a novel local feature extraction framework for time series and shapelet-based time series classification pipeline. Proposed framework provides model selection flexibility to describe the time-observation space to find local discriminative regions. After obtaining the discriminative regions, shapelets are extracted on the time-observation space by thresholding the class probability estimates to construct a new feature representation. New feature representation is calculated by the Euclidean distance between shapelets and time series. Finally, a classifier is trained by the new feature representation. Experimental results show that shapelet-based time series classification by using proposed Probabilistic Discriminative Region Descriptor (PDRD) provides competitive results on benchmark datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Modern dijital sistemlerde, kişiselleştirilmiş içerik sunan algoritmalar kullanıcı deneyimini şekillendirmekte; kullanıcı memnuniyetini ve kullanıcının sistemle uzun süreli ilişkisini etkilemektedir. Sistemin kullanıcıya gösterdikleri, erişilebilirlik için görünürlük çok önemli olduğundan, sisteme içerik sağlayan diğer partileri de etkilemektedir. Bu algoritmalar, kişiselleştirilmiş içerik sunmayı kullanıcı tercihleri için bir gösterge olarak geçmiş davranışlarından, örneğin, seçimlerinden, tıklamalarından, oylarından öğrenirler. Bu çalışmanın ilk kısmında kullanıcıların gösterilen içeriğe verdiği geribildirimden öğrenen yaygın modeller, katkılarımızı da içerecek şekilde incelenmektedir. Bu veri sürekli büyüdüğünden, öğrenme algoritmalarının hesaplama yönüne, ölçeklenebilir gerçekleşmeleri için yazılım kütüphanelerine ve bu alandaki katkımıza odaklanılmaktadır. Çalışmanın ikinci kısmı kullanıcıların algoritmik kişiselleştirme sistemleri ile etkileşimine odaklanmaktadır. Yararlı olsa da, davranış verisi, algoritmalara sorun teşkil edecek şekilde birçok bilişsel önyargı ve örnekleme yanılgısı içermektedir. Kullanıcılar sistemle ilişkide olduğu sürece sorun kötüleşir (algoritma gelecek gösterimlerini yanlı veriden yapar). Dahası algoritma, kullanıcı tercihleri ile ilgili yanlış inancını pekiştirir. Çalışmamız, kullanıcı önyargılarının bazılarını özetlemekte ve biriyle ilgilenmektedir: kullanıcının kendisine sunulan seçeneklerden birini seçme eğilimi. Bu eğilimi gözeten, kullanıcı tercihlerinin çıkarsanmasında onların tüm içeriğin sınırlı bir alt kümesine maruz kaldıklarını hesaba katan, Bayesçi bir seçim modeli geliştirilmiştir. Bu model, kullanıcı tercihlerini sistemle etkileşimlerinden öğrenen etkin bir çevrimiçi algoritmaya olanak vermektedir.","In modern digital systems, algorithms that deliver personalized content shape the user experience and affect user satisfaction, hence long-term engagement with the system. What the system presents also influences the parties providing content to the system since visibility to the user is vital for reachability. Such algorithms learn to deliver personalized content using data on previous user behavior, \eg, their choices, clicks, ratings, etc., interpreted as a proxy for user preferences. In the first part of this work, we review prevalent models for learning from user feedback on content, including our contributions to the literature. As such data is ever-growing, we discuss computational aspects of learning algorithms and focus on software libraries for scalable implementations, including our contributions. The second part is on learning from user interactions with algorithmic personalization systems. Albeit helpful, human behavior is subject to cognitive biases, and data sets comprising their item choices are subject to sampling biases, posing problems to learning algorithms that rely on such data. As users interact with the system, the problem worsens---the algorithms use biased data to compose future content. Further, the algorithms self-reinforce their inaccurate beliefs on user preferences. We review some of the biases and investigate a particular one: the user's tendency to choose from the alternatives presented by the system, putting the least effort into exploring further. To account for it, we develop a Bayesian choice model that explicitly incorporates in the inference of user preferences their limited exposure to a systematically selected subset of items by an algorithm. The model leads to an efficient online learning algorithm of user preferences through interactions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım testinin değerini hafife almanın yakın tarihte yıkıcı sonuçları olmuştur. Otomatik Test Yaratımı (OTY) test için gereken insan eforunun en aza indirilmesini amaçlayan bir yaklaşımdır. Bu tez OTY etkililiği ve performansını Makine Öğrenmesi (MÖ) tabanlı yönlendirme ile artırmayı amaçlamaktadır, ve spesifik olarak Takviyeli Öğrenme (TÖ) kullanan Android Grafiksel Kullanıcı Arayüzü (GKA) testine odaklanmaktadır. Önerdiğimiz dört çözüm; Q-öğrenme Tabanlı Keşif (QTK), Test Durumu Mutasyonu (TDM), Tam Otomatik Takviyeli Öğrenme Güdümlü (TOTÖG), ve TOTÖG2 test yaratıcılarıdır. QTK bir dizi uygulamada TÖ kullanarak gezinir ve keşif sırasında bir eylem yaratma ilkesi öğrenir. Sonra, bu öğrendiği ilkeyi yeni uygulamalarda ya daha fazla özgün çökme bulmak ya da daha fazla aktivite kapsamak için kullanır. TDM, QTK ile yaratılan testleri alır ve içlerindeki iyi huylu eylemleri daha da fazla çökme tespit edebilmek için kötü huylularla değiştirir. TOTÖG ise TÖ kullanarak izlenebilir kurallı belirtimler formundaki yüksek seviyeli test senaryoları olarak verilen fonksiyonel davranışları nasıl doğrulayacağını öğrenir. TOTÖG, QTK gibi deneme-yanılma ile öğrenir ama uygulama-spesifik kalıplar öğrenmektedir. Bildiğimiz kadarıyla, TOTÖG, GKA uygulamalarının tam otomatik fonksiyonel testini mümkün kılan ilk motordur. Son olarak, TOTÖG2, TOTÖG'ü Genellenmiş Deneyim Tekrarı (GDT) ve insan-okuyabilir Aşamalı Test Senaryosu (ATS) diliyle geliştirmektedir. Deneyler QTK'nın en gelişkin test yaratıcılarından çökme tespiti ve kapsamada daha performanslı olduğunu göstermektedir. Önce QTK çalıştırıp sonra TDM'ye geçmek ise bundan da daha fazla eşsiz çökme bulmaktadır. TOTÖG, otomatik testin kapsamını fonksiyonel davranış doğrulanmasına genişletmektedir. Sonuç olarak, bu test yaratıcıları otomatik GKA testini elle testin yerine geçmeye yakınlaştırmaktadır.","Underestimating the value of software testing had catastrophic results in recent history. Automated Test Generation (ATG) is an approach that aims to minimize the manual effort required for testing. This thesis aims to improve the effectiveness and performance of ATG approaches via Machine Learning (ML) based guidance, and focuses on Android Graphical User Interface (GUI) testing using Reinforcement Learning (RL), specifically. We propose four solutions, Q-learning Based Exploration (QBE), Test Case Mutation (TCM), Fully Automated Reinforcement LEArning Driven (FARLEAD), and FARLEAD2 test generators. QBE uses RL to crawl a set of applications and learns an action generation policy while exploring. Then, it uses this learned policy to either detect more unique crashes or cover more activities in new applications. TCM takes the tests QBE generates and replaces the well-behaving actions in those tests with bad-behaving ones to detect even more crashes. FARLEAD uses RL to learn how to verify a functional behavior that is given as a high-level test scenario in the form of a monitorable formal specification. FARLEAD learns by trial-and-error like QBE but it learns app-specific patterns instead of QBE's app-generic patterns. To the best of out knowledge, FARLEAD is the first engine fully automating the functional testing of GUI applications. Finally, FARLEAD2 improves FARLEAD with Generalized Experience Replay (GER) and human-readable Staged Test Scenario (STS) language. Experimental results show that, QBE outperforms state-of-the-art test generators in crash detection and coverage. Furthermore, executing QBE first and then switching to TCM detects even more unique crashes. FARLEAD and FARLEAD2 expand the scope of automated testing to verifying functional behavior. Overall, these test generators elevate automated GUI testing closer to replacing manual GUI testing."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir alt ekstremite dış iskelet kullanıcısının metabolik enerji tüketiminin çoğu, alt vücut pasif olarak kabul edilebileceğinden, üst vücudun harcadığı efordan gelir. Ancak literatürde alt uzuv dış iskelet kullanıcılarının üst vücut eforu hesaba katılmamaktadır. Bu tez çalışmasında, bastonların yer tepki kuvvetlerini (YTK) optimize eden bir hareket kontrolcüsü geliştirmek için derin pekiştirmeli öğrenme kullanılmıştır. Yer reaksiyon kuvvetlerini minimize etmenin amacı kullanıcının üst vücut eforunu en aza indirmektir. Bastonlar ve insan-dış iskelet sisteminin modeli URDF ve XML formatlarında oluşturulmuştur. Düşmeden ve aşırı eklem torkları olmadan kütle merkezinin ileriye doğru yer değiştirmesini teşvik eden ödül fonksiyonları şekillendirilmiştir. Son teknoloji yöntemler olan Twin Delayed Deep Deterministic Policy Gradient (TD3) ve Proximal Policy Optimization (PPO), RaiSim ve MuJoCo simülatörleri ve çeşitli parametre setleriyle uygulanmıştır. Kullanılan sinir ağları, eklem açısı ve hızları ile ayaklar ve baston uçlarındaki zemin reaksiyon kuvvetlerine dayalı olarak eklem torklarını üretir. Oluşturulan bu eklem torkları doğrudan dış iskelet modeline gönderilir ve derin PÖ çerçevesinin sağladığı aksiyon uygulandıktan sonra yeni bir durum gözlemlenir. TD3 ve PPO yöntemleriyle RaiSim'de eğitilen politikaların, dengeli ve doğal görünümlü bir yürüyüş için uygun kontrol komutları üretemediği gözlemlenmiştir. Genel olarak RaiSim'de PPO yönteminin TD3 yöntemine göre daha yüksek ödül değerlerine ulaştığı görülmektedir. RaiSim ile istenen tarzda bir robot politikası elde edemedikten sonra MuJoCo simülatör olarak kullanılmıştır. Sonuç olarak, uygun baston hareketlerini de içeren ve istenen tarzda lokomosyonu yer tepki kuvvetlerini %35 oranında azaltarak sağlayan bir robot politikası geliştirilmiştir.","The majority of the metabolic energy consumption of a lower-limb exoskeleton user comes from the upper body effort, since the lower body can be considered to be passive. However, the upper body effort of lower limb exoskeleton users is ignored during motion controller development process in the literature. In this thesis study, deep reinforcement learning is used to develop a locomotion controller that minimizes the ground reaction forces (GRF) on crutches. The rationale for minimizing the ground reaction forces is to minimize the upper body effort of the user. A model of the human-exoskeleton system with crutches is created in URDF and XML formats. Reward functions that encourage the forward displacement of the center of mass of the exoskeleton-human system without falling and extreme joint torques are shaped. The state-of-the-art methods, Twin Delayed Deep Deterministic Policy Gradient (TD3) and Proximal Policy Optimization (PPO), are employed with the RaiSim and MuJoCo physics simulators and with different algorithm specific parameters in multiple training trials. The employed networks generate the joint torques based on the joint angle and velocities along with the ground reaction forces on feet and crutch tips. These generated joint torques are directly sent to the exoskeleton model and a new state is observed after implementing the action that the deep RL framework provides. Policies trained by the TD3 and PPO methods on RaiSim are observed to fail to generate proper control commands for a stable and natural looking gait. In general, it is observed that the PPO method generated higher rewards than the TD3 method on RaiSim. After failing to develop a desired policy with RaiSim, MuJoCo is employed as the simulator. Eventually, a policy that can generate a reasonable gait with a desired crutch usage and with 35% minimization in GRFs with respect to the baseline policy is developed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yeni nesil kablosuz hücresel ağlardaki son gelişmeler, hücresel teknolojinin endüstriyel ağlar gibi daha ağır gereksinimleri olan ve geleneksel olarak kablolu ağlar kullanan sistemlerde uygulanmasını mümkün kılan yeni bir dönem getirdi. Yeni nesil hücresel teknolojiler (ör. 5G ve Ötesi), aşırı güvenilir düşük gecikmeli iletişim (URLLC) konseptini ortaya çıkardı. Bu tezde, URLLC'yi elde etmek için yeni nesil hücresel ağlarda programlanabilir veri düzlemleriyle Yazılım Tanımlı Ağ (SDN) mimarisini öneriyoruz. Tasarımımız, veri trafiğini hat hızında kontrol etmek için hücresel çekirdek ile Radyo Erişim Ağı (RAN) arasında programlanabilir ağ anahtarları kullanıyor. Önceden yetkilendirilmiş ağ içi cihazların çekirdek ağa sinyal göndermesi gerekmeden iletişim kurmasını sağlamak için bir gevşetme olan hücreler arası eniyileme (eng. intra-cellular optimization) kavramını tanıtıyoruz. Ayrıca, programlanabilir anahtarlar arasında bilgi dağıtımı için tasarladığımız Birleştirilmiş Kontrol Düzlemi (eng. Unified Control Plane (UCP)) protokolünü sunuyoruz. Mimarimizi Open5Gs uygulaması, bir UE/RAN simülatörü ve P4 programlama dili kullanarak uygularken sistemimizin çoklu anahtar topolojilerindeki performansını geliştirdiğimiz Python simülatörü ile değerlendiriyoruz. Kapsamlı değerlendirmemiz, geleneksel mimariye kıyasla hücreler arası eniyileme ile gecikme süresinin iki kata kadar azaldığını gösteriyor.","Recent advancements in wireless technologies towards the next-generation cellular networks have brought a new era that made it possible to apply cellular technology on traditionally-wired networks with tighter requirements, such as industrial networks. The next-generation cellular technologies (e.g., 5G and Beyond) introduce the concept of ultra-reliable low-latency communications (URLLC). This thesis presents a Software-Defined Networking (SDN) architecture with programmable data planes for the next-generation cellular networks to achieve URLLC. Our design deploys programmable switches between the cellular core and Radio Access Networks (RAN) to monitor and modify data traffic at the line speed. We introduce the concept of intra-cellular optimization, a relaxation in cellular networks to allow pre-authorized in-network devices to communicate without being required to signal the core network. We also present a control structure, Unified Control Plane (UCP), containing a novel Ethernet Layer control protocol and an adapted version of link-state routing information distribution among the programmable switches. Our implementation uses P4 with an 5G implementation (Open5Gs) and a UE/RAN simulator. We implement a Python simulator to evaluate the performance of our system on multi-switch topologies by simulating the switch behavior. Our evaluation indicates latency reduction up to 2x with intra-cellular optimization compared to the conventional architecture. We show that our design has a ten-millisecond level of control latency, and achieves fine-grained network security and monitoring."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Böbrek hücresi kanseri (BHK) tüm böbrek kanserlerinin %85 ila %90'ını oluşturur ve berrak hücreli böbrek kanseri (BHBK) en yaygın alt tipidir. 2020 yılında 430,000 yeni vaka teşhis edilmiş ve bunların 179,000'i hayatını kaybetmiştir. Tedavi sürecinin daha verimli bir şekilde yürütülebilmesi için tümör derecesinin girişimsel olmayan ve yüksek doğruluk oranına sahip yöntemlerle belirlenmesi önemlidir. Son zamanlarda yapılan çalışmalar CT görüntülerinden elde edilen radiomics özelliklerinin tümör derecelendirme işlemlerinde kullanılabileceği yönünde ama klinikte kullanılabilmesinin önünde verilerin standart olmaması ve kullanıma uygun olmaması gibi engeller var. Biz bu çalışmada 3B ve 2B radiomics özellikleri kullanarak ensemble makine öğrenmesi modelleri oluşturmayı, mevcut engellerin üstesinden gelmeyi ve daha yüksek başarımla tümör derecelendirmeyi amaçladık. Çalışmaya görüntüleri The Cancer Imaging Archive'dan alınmış 143 hasta dahil edildi. Veri setindeki sınıflar arası dağılım eşitsizliğini gidermek için veri artırma yöntemlerine başvuruldu ve her hastadan çıkarılan binlerce radiomics özelliği sadece en değerli olanlar kalacak şekilde elendi. Asıl tümör alanına ek olarak 5 farklı alan daha segmente edildi ve segmentasyonda yapılacak yanlışların sonuçları ne derecede etkileyeceği araştırıldı. En yüksek başarım olan 0.89 ± 0.02 AUC, SMOTE ve Light Gradient Boosting Method (LightGBM) algoritması kombinasyonunda elde edildi. Sonuç olarak, BHBK tümör derecesini, bir veri setinin yetersizliğine rağmen yüksek güvenilirlikle tahmin edebildik ayrıca en iyi modelimizin segmentasyondaki küçük hatalara rağmen performans kaybı olmadan çalışabildiğini gözlemledik.","Renal cell carcinoma (RCC) constitutes %85 to %90 of all kidney malignancies. In 2020, 430,000 new cases were diagnosed and 179,000 of them lost their lives. Clear cell renal cell carcinoma (ccRCC) is the most common sub-type of RCC with approximately %80 occurrence rate. Accurate, non-invasive and preoperative determination of the International Society of Urological Pathology (ISUP) based tumor grade is important for the effective management of patients with ccRCC. Recent studies showed that CT radiomics can offer the means to predict this grade but there are some problems about data such as scarcity, unbalancing and standardization. In this study, we aimed to improve discrimination power between grades via using 3D and 2D radiomics features and ensemble machine learning methods. Radiomics features were extracted from 143 CT images obtained from the publicly available data set from The Cancer Imaging Archive. Over sampling methods and series of feature selection methods were applied to reduce the number of features. Besides the actual tumor volume, 5 additional VOIs were created to consider peritumor regions and test the robustness of the model against variations in segmentation for three ensemble machine learning algorithms. The best result was found when SMOTE was used in combination with Light Gradient Boosting Method (LightGBM) AUC of 0.89 ± 0.02. As a result, ccRCC tumor grade can be predicted from 3D CT images with a high reliability despite the inadequacy of a dataset. The algorithm is moderately robust against deviations in segmentation by observers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Blokzincirinin finans sektöründeki önemi giderek artıyor. Sabitkoinler geleneksel finans ekosistemleri ile blokzincir ekosistemi arasında bir köprü oluşturuyor. Büyük ödeme işlemcileri kripto para çözümlerini benimseyip bu çözümleri sistemlerine entegre ediyor. Blokzincir işlem analizi kripto para düzenlemelerini uygulamak, dolandırıcılık faaliyetlerini izlemek ve iş zekası çözümleri oluşturmak için gereklidir. Blokzincirlerinin işlem hacminin, hisse ispatı (PoS) konsensüs mekanizmasına geçiş ve sıfır bilgi ispatlarının kullanımı ile artması bekleniyor. Büyük işlem çizgelerini işlemek için yeni araçlara ihtiyaç var. Bu tezde, blokzincir işlem çizgelerinin analizini yapmak için paralel bir blokzincir işlem çizge sistemi öneriyoruz. Sistem dağıtık veri yapılarını ve dağıtık çizge algoritmalarını kullanıyor ve mesaj aktarma arayüzü (MPI) kullanılarak C++ programlama dilinde yazıldı. Sistem, önerilen paralel çizge oluşturma algoritmamızı kullanarak blokzincir verilerinden işlem çizgesini oluşturur. İşlem çizgesi daha sonra dağıtık ve paralel işlem izleme ve izleme ormanı algoritmalarımız kullanılarak çözümlenir. Ayrıca PageRank, bağlantılı bileşen hesaplama, derece dağılımı hesaplama algoritmalarını da kodlayıp sistemimize ekledik. Sistemimizi test etmek için 12 yıllık Bitcoin ve 5 yıllık Ethereum blokzinciri işlem verilerini ve çeşitli web sitelerinden bazı kara listeye alınmış blokzincir adreslerini topladık. Sistem, Amazon Bulut üzerinde 16 düğümlü yüksek başarımlı hesaplama (HPC) kümesi kullanılarak değerlendirildi. Testlerimiz için elde edilen zamanlamaları ve en iyi 10 pagerank adresi, adreslerin derece dağılımı, izleme görselleştirmeleri gibi analiz sonuçlarını raporladık. Kümemizde Ethereum ve Bitcoin işlem verilerimiz için işlem çizgesini sırasıyla 4 dakika ve 32 dakikadan daha kısa sürede oluşturabildik.","Blockchain is more prominent in the finance sector than ever. Stablecoins build a bridge between traditional finance ecosystems and the blockchain ecosystem. Major payment processors adopt cryptocurrency solutions and integrate them into their systems. Blockchain transaction analysis is needed to enforce cryptocurrency regulations, trace fraudulent activities, and create business intelligence solutions. Transaction throughput of blockchains is expected to rise with the transition to proof-of-stake (PoS) consensus mechanism, sharding, and the use of zero-knowledge proofs. New tooling is needed to handle massive transaction graphs. In this thesis, we propose a parallel blockchain transaction graph system for analyzing blockchain transaction graphs. The system utilizes distributed data structures and graph algorithms and is implemented in C++ using message passing interface (MPI). The system constructs the transaction graph from blockchain data using our proposed parallel graph construction algorithm. The transaction graph is then analyzed using our distributed and parallel transaction trace and trace forest algorithms. In addition, we implemented PageRank, connected component calculation, degree distribution calculation algorithms. We collected 12-year Bitcoin and 5-year Ethereum blockchain transaction data as well as some blacklisted blockchain addresses from various websites to test our system. The system is benchmarked using a 16-node high performance computing (HPC) cluster on Amazon Cloud. We report timings obtained for our tests and analysis results like top 10 pageranked addresses, the degree distribution of addresses, trace visualizations. We were able to construct the transactions graph for our Ethereum and Bitcoin transaction data on our cluster in less than 4 minutes and 32 minutes, respectively."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda derin öğrenme teknikleri müthiş gelişme göstermektedir. Ekonomi, askeri, sağlık ve birçok alanda uygulamalarını görebiliriz. Özellikle sağlık alanı en kritiklerinden birisidir. Dünya nüfusu her gün hızla artarken, sağlık çalışanları işleri hızlandırabilmek için teknolojiye daha fazla ihtiyaç duymaktadır. Bu sebeple üretilen yeni yöntemler ciddi katkılar sağlamakta ama veri yetersizliği fazlasına engel olmaktadır. Modelleri daha fazla eğitmek için kullanılacak veriler kişisel verilerin gizliliği sebebiyle toplanamamaktadır. Örneğin, göğüs X-ray'leri patoloji sınıflandırması için sıklıkla kullanılmaktadır. Bunun üzerine çalışılan derin öğrenme yöntemleri ise sınırlı kalmaktadır çünkü çok az verikümesi bulunmaktadır. Bu problemi çözmek için göğüs X-ray'lerindeki patoloji sınıflandırma sonuçlarını arttırmak amacıyla veri çoğaltma konusuna odaklandık. Sunduğumuz ilk yöntem ısı haritası tabanlı imge tamamlama yöntemi. Bu, X-ray'lerdeki sağlıklı bölgenin büyük bir bölümünün tamamlanmasıyla yeni X-ray'ler oluşturmuş oluyor. Böylece, X-ray'in etiketi de korunmuş oluyor. İkinci yöntemde ise, koşullu üretici StyleGAN2-ADA eklenmiş GANSpace modeli ile imge sentezleme üzerine çalışma yaptık. Son olarak, sağlıklı ve gerçek X-ray'leri vektörlere dönüştürerek GANSpace ile manipüle etme çalışmasını gösterdik. Sayısal sonuçlara bakıldığı zaman imge tamamlama yöntemi orjinal dataset ile elde edilmiş sınıflandırma sonucunu \%86.1'den \%87.7'ye yükseltmiştir. Koşullu GANSpace yöntemi deneylerine bir taban oluşturmak için StyleGAN2-ADA modeli ile X-ray'ler ürettik ve çoğalttığımız verilerin sınıflandırılması bize \%87.36 sonucunu verdi. Sunduğumuz Koşullu GANSpace methodu ise bunu da geliştirerek en yüksek sonuç olan \%88.5'i elde etti.","In recent years, deep learning techniques have made great progress. We can see applications of it in many fields such as economics, military, healthcare, and so on. Healthcare, in particular, is one of the most critical of these areas. While the world population is growing every day, healthcare professionals need more computerized technologies to make things faster. Proposed new methods are making important contributions to the healthcare system, but the lack of data is limiting development. Privacy issues prevent more patient data from being collected to use for training models. For example, chest X-rays are commonly used in pathology classification. However, studies are limited due to the lack of public datasets. To solve this problem, we focus on data augmentation on chest X-rays to improve pathology classification results. To this end, we demonstrate three methods. In the first, we propose a heatmap based image inpainting that uses X-ray images with observations and inpaints the large healthy areas to create new X-rays while preserving the labels. The second proposed method synthesizes images using an extended version of GANSpace by adding a conditional generator StyleGAN2-ADA. Finally, we demonstrate the manipulation of real and healthy X-ray images using latent space manipulation and GAN inversion. Our quantitative experiments show that heatmap based inpainting improves classification results from 86.1\% to 87.7\%. To provide a basis for our Conditional GANSpace method, the results of X-ray image generation experiments using StyleGAN2-ADA are also provided. The classification result of the dataset augmented using StyleGAN2-ADA is 87.36\% and our Conditional GANSpace improves this result with the highest result of 88.5\%."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dünya genelinde milyonlarca insanın her saniye ziyaret ettiği ve alışveriş yaptığı online pazaryerlerinin ortaya çıkmasıyla birlikte, bu platformlar arasındaki rekabet ve alışveriş deneyimi önemli ölçüde değişmiş, öneri sistemleri bu platformların kritik bir parçası haline gelmiş ve literatürde popülerlik kazanmıştır. Tavsiye sisteminin kilit rol oynadığı bu online pazar yerlerinden biri de ikinci el platformlardır. Genel öneri sorunlarına ek olarak, bu platformların, sorunu diğer alanlara göre zorlaştıran, birbirine benzemeyen öğeler kümesinden oluşması gibi bu alana özgü çeşitli sorunları vardır. Bu çalışmada, ölçeklenebilir bir yapı içinde kişiselleştirilmiş ürün önerileriyle bu sorunları ele almak için son teknoloji doğal dil işleme tekniklerinden word2vec ve paragraf2vec kullanan iki aşamalı bir model öneriyoruz. Model performansı, hem popüler bir ikinci el platformundan toplanan geçmiş kullanıcı akışı veri kümesi üzerinde gerçekleştir- ilen çevrimdışı deneylerde, hem de canli sistem üzerinde yapılan A/B testinde değer- lendirilir. Bu deneylerin sonucu olarak, önerilen model, seçilen metriklere göre temel işbirlikçi filtreleme tabanlı modellerden daha iyi performans gösterir ve ayrıca, ürün sistemindeki çeşitli iş metriklerinde önemli artış sağlar.","With the advent of online marketplaces which millions of people worldwide visit and make purchase every second, the shopping experience and competition between these platforms have been significantly changed and recommendation systems have become a more critical part of these platforms and gained popularity in the literature. One of these online marketplaces, in which the recommendation system plays a key role, is second hand platforms. In addition to general recommendation problems, these platforms have several problems which are specific to this domain such as compromising extremely unique item sets that makes the problem difficult with respect to other domains. In this study, we propose two staged model pipelines using state-of-the-art NLP techniques word2vec and paragraph2vec to address these problems with high quality personalized product recommendation in a scalable architecture. The model performance is evaluated on both offline experiments which are conducted on historical user clickstream dataset that is gathered from a popular second hand platform and A/B test on a production system. As a consequence of these experiments, the proposed model outperforms the baseline collaborative filtering-based models with respect to selected metrics, in addition, provides significant uplifts on several business metrics in the product system."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İlaç-hedef bağlılık ilgisi tahmini, bilgisayar destekli ilaç tasarımında, ilaç geliştir- \\me sürecini hızlandırmaya ve çok sayıda bulunan yanlış pozitif oranlarının neden olduğu deneysel doğrulama maliyetlerini düşürmeye yardımcı olabilecek kritik bir aşamadır. Bu nedenle, ilaç-hedef bağlılık ilgisi değerlerini tahmin etmek için bilgisayar ortamında hesaplama algoritmaları geliştirmek ilgi çekici bir araştırma alanı haline gelmiştir. Güncel çalışmalar bu görev için, kolayca bulunabilen biyomolekül dizilerini ve ilaçlarla ve hedeflerle alakalı bilgilerle zenginleştirilmiş heterojen ağları kullanan modeller de dahil olmak üzere, makine öğrenimi yaklaşımlarını kullanır. Bu tezde, hem metin tabanlı hem de ağ tabanlı yaklaşımlardan yararlanan ve ilaç-hedef bağlılık ilgisi değerlerini tahmin eden ilk çalışma olan WideDeepDTA'yı sunuyoruz. WideDeepDTA içerisinde birden fazla biyolojik varlık türü, bu varlıklar arasındaki ilişkiler ve biyomoleküler dil için önceden eğitilmiş dil modellerini içeren homojen ve heterojen ağları barındırır. Tüm bunlar göz önüne alındığında, WideDeepDTA önce ağlarda bulunan tüm düğümler için bir vektör gösterim öğrenme yöntemi olan Metapath2Vec'i kullanarak ilaçların ve hedeflerin düşük boyutlu vektör temsillerini öğrenir. Ardından, öğrenilen temsillere dayanarak ilaç-hedef bağlılık ilgisi değerlerini tahmin eder. WideDeepDTA, BDB veri kümesindeki en başarılı yöntemlerden biri olan DeepDTA'ya kıyasla ilaç-hedef bağlılık ilgisi tahmini görevinde uyumluluk indeksi ve ortalama kare hata başarı metriklerinde iyileşme göstererek zengin temsiller oluşturmayı başarmıştır. Yapılan deneyler, ilaçlar ve proteinler için önceden eğitilmiş dil modellerini heterojen ağlarla birlikte kullanmamın model performansını geliştirdiği göstermektedir. Ayrıca sonuçlar, metin tabanlı temsillerden elde edilen bilgilerle heterojen ağlar güçlendirildiğinde model performansının arttığını göstermektedir.","Predicting drug-target binding affinity is a critical phase in computer-aided drug design, which can help accelerate the drug development process and reduce experimental validation costs caused by the significant false-positive rates. Hence, developing in-silico computational algorithms to predict drug-target binding affinity values has become an important research area. Machine learning approaches have been proposed for this task, including models that use readily available biomolecule sequences and heterogeneous networks enriched with drug and target-related information. We present WideDeepDTA, the first study that leverages both text-based and network-based approaches and predicts drug-target binding affinities. Given homogeneous and heterogeneous networks containing multiple types of biological entities, relationships between these entities, and pre-trained language models for biomolecular language, WideDeepDTA first learns the low-dimensional feature representation of drugs and targets using the node embedding technique Metapath2Vec. Then, it predicts affinity values based on the learned features. WideDeepDTA demonstrates its ability to create rich representations in the drug-target affinity prediction task compared to one of the state-of-the-art methods, DeepDTA, on the BDB dataset in terms of concordance index and mean squared error. Experiments indicate that integrating pre-trained language models with heterogeneous information improves model performance, especially while predicting the affinity values between proteins and unseen ligands. Moreover, the results show that the model performance improves when heterogeneous graphs are empowered with the information extracted from text-based representations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ethereum ve akıllı sözleşmelerin popülerliği artmaktadır. Bu nedenle, her geçen gün daha fazla işlem hacmine ihtiyaç duyulmaktadır. Ethereum Sanal Makinesi, akıllı sözleşmelerin Ethereum-baytkoduyla kodlanmış talimatlarını yürüten bir Turing tam bilgisayarıdır. Her talimat, giriş ve çıkış işlenenleri olarak 256 bit genişliğinde yığın öğeleri kullanır. Yığından gerekli girdileri çıkarırlar ve bir yürütmeden sonra sonucu yığına geri koyarlar. Durdurma sorununu engellediği için talimatın karmaşıklığına göre onlara bir gaz tüketim maliyeti atanır. Tüketilen gazın, gaz fiyatıyla çarpımı, işlemi gönderen tarafından işlem ücreti olarak harcanır ve bu şekilde Hizmet Reddi (DoS) saldırıları önlenebilir. Mevcut desteklenen komut kümesinin bazı zayıf yönleri vardır. Bunlardan birincisi, büyük boyutlu vektör işlemleri içeren işlemlerde aşırı miktarda gaz maliyeti gerektirmesidir. İkincisi, yürütmede paralellik olmaması nedeniyle saniye başına yapılabilen işlem sayısı sınırlıdır. Bu nedenle, veri seviyesi paralelliğinden yararlanmak için Tek Komutlu Çoklu Veri (SIMD) işlemleriyle komut kümesini genişletiyoruz. Gaz tüketimini azaltarak ve işlem hacmini artırarak EVM'nin SIMD komutlarından nasıl yararlanabileceğini gösteriyoruz.","Ethereum and its smart contracts have been growing their popularity. Therefore, there is a need for higher transaction throughput in every other day. Ethereum Virtual Machine is a Turing-complete computer which executes Ethereum bytecode encoded instructions of smart contracts. Every instruction uses 256-bit wide stack items as input and output operands. They pop required inputs from the stack and push the result into it after an execution. A gas consumption cost is assigned to them relative to the complexity of the instruction as it prevents halting problem. Consumed gas multiplied by gas price is charged as transaction fee by the transaction sender, so that Denial of Service (DoS) attacks can be avoided. Current supported instruction set has some weaknesses. Firstly, transactions containing large size of vector operations require excessive amount of gas cost. Secondly, transaction throughput is limited because of no parallelism in execution. Therefore, we extend the instruction set by Single Instruction Multiple Data (SIMD) operations to benefit from data level parallelism. We show how EVM can benefit from the SIMD instructions by lowering gas consumption and increasing transaction throughput."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilimsel literatürün büyük hacmi dolayısıyla, araştırmacıların, makalelerin içlerinde gömülü olan bilgileri tanımlaması ve kullanması zorluk teşkil etmekte ve otomatik çıkarma ve işlemeyi gerekli kılmaktadır. Otomatik işleme, çıkarılan bilgi ontolojilerle temsil edilen bağlantılı veri kaynaklarıyla birleştirilebileceği düşünüldüğünde özellikle önemli hale gelmektedir. Bağlı Açık Veri (LOD) kaynaklarında temsil edilen geniş bilgi alanı, anlamsal arama ve çıkarım yoluyla çok sayıda bilgi keşfi fırsatı sunar. Bu tez, bilimsel makalelerde gömülü biyomedikal varlık ilişkilerini çıkarmayı ve bunları makine tarafından işlenebilir bir şekilde anlamsal olarak temsil etmeyi amaçlamaktadır. Bu amaçla, biyomedikal varlık ilişkilerini ve bunların bilimsel makalelerdeki kökenini temsil eden Biomedical Entities Evidences (BEE) adlı bir ontoloji önerdik. Yaklaşımın uygulanabilirliğini ifade etmek için kimyasal-protein çok sınıflı ilişkileri ve kimyasal-hastalık ikili ilişkilerini çıkardık. Bu ilişkileri BEE ontolojisi aracılığıyla temsil ettik. Ontoloji tabanlı semantik temsilin faydalarını göstermek için, birkaç LOD kaynağını ve ontolojilere ve özel kurallara dayalı çıkarsanan verileri kullanan bir semantik uygulama prototipi geliştirdik. Bu prototip, değişen karmaşıklıklarda bilgi alma görevlerini gerçekleştirerek anlamsal temsilin faydalarını değerlendirmek için kullanıldı.","The sheer volume of scientific literature challenges researchers to identify and utilize the knowledge embedded in them and makes automated extraction and processing necessary. Automated processing becomes especially significant when the extracted information is combined with the linked data resources represented with ontologies. The vast knowledge space represented in Linked Open Data sources provides numerous knowledge discovery opportunities through semantic searching and inference. This thesis aims to extract biomedical entity relations embedded in scientific articles and semantically represent them in a machine-processable manner. For this purpose, we proposed an ontology named Biomedical Entities Evidences (BEE) that represents biomedical entity relationships as well as their provenance in scientific articles. To express the approach's feasibility, we extracted chemical-protein multiclass relations and chemical-disease binary relations. These relations are represented based on BEE ontology. To demonstrate the benefits of ontology-based semantic representation, we have implemented a semantic application prototype that utilizes several Linked Open Data sources and inferred data based on ontologies and custom rules. This prototype was used to evaluate the benefits of the semantic representation by performing information retrieval tasks of varying complexities."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüksek bağlılık ilgisi gösteren protein-kimyasal çiftlerinin tespiti ilaç keşfinin önemli bir adımıdır. Ancak, mevcut protein ve kimyasal sayısı deneysel olarak taranamayacak bir kombinasyon uzayı oluşturmakta ve hesaplamalı yöntemler gerektirmektedir. Bu aşamada ilaç-hedef bağlılık ilgisi tahmini modelleri sahne alır ve yüksek bağlılık ilgisi gösteren çiftleri hızla tespit ederler. Bu tez, en üst düzey başarımlı ilaç-hedef bağlılık ilgisi tahmini modelleri ve model eğitim stratejileri önerir. Önerilen yaklaşımlar protein ve kimyasal dizilerini biyomoleküler dildeki dökümanlar olarak gören biyomoleküler dil işleme tekniklerini kullanırlar. Biyomoleküler dilin birimleri, veya biyomoleküler kelimeler, büyük biyomolekül derlemlerinde keşfedilmiştir ve farmakolojik olarak değerli bulunmuştur. Biyomoleküler kelimeler özgün bir ilaç-hedef bağlılık tahmini sistemi, ChemBoost, geliştirmek için kullanılmıştır. ChemBoost biyomoleküler kelime tabanlı vektör temsilleri sayesinde en üst düzey başarıma ulaşmıştır. Deneyler ayrıca eğitim kümesinde olmayan biyomoleküllerin bütün ilaç-hedef bağlılık ilgisi tahmini modellerini zorladığını göstermiştir. Bu probleme çözüm olarak, doğal dil işlemeden ilham alan bir model eğitim stratejisi, DebiasedDTA, geliştirilmiştir. Değelendirmeler DebiasedDTA stratejisinin tahmin modellerini hem eğitim kümesininde bulunan hem de bulunmayan biyomoleküllerde güçlendirdiğini göstermiştir. ChemBoost ve DebiasedDTA pydta adında açık kaynak kodlu bir python kütüphanesi olarak yayımlanmıştır.","Finding high-affinity protein-chemical pairs is a prominent stage of the drug discovery pipeline. However, the number of available proteins and chemicals forms an experimentally insurmountable combination space and necessitates computational approaches. Drug-target affinity prediction models come into play here and rapidly highlight the high-affinity pairs. This thesis introduces state-of-the-art drug-target affinity prediction models and training strategies to facilitate drug discovery studies. The introduced approaches leverage biomolecular language processing techniques which interpret the chemicals and proteins as documents formed in biomolecular languages. The units of bimolecular languages, named biomolecular words, are discovered in large corpora and pharmacologically verified as meaningful substructures. The biomolecular words are used to develop a novel drug-target affinity prediction framework: ChemBoost. ChemBoost models leverage the biomolecule word-driven representations and achieve state-of-the-art prediction performance. The experiments also demonstrate that unseen biomolecules challenge all drug-target affinity prediction models and reveal a generalizability problem. A language-inspired model training framework, DebiasedDTA, is introduced to target the problem. The evaluations indicate that DebiasedDTA boosts models on seen and unseen biomolecules, especially when the target pair is dissimilar to training biomolecules. ChemBoost and DebiasedDTA are published as an open-source python package, pydta."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Trafik dalgalanmaları, kapsama sorunları, çok düşük gecikme gereksinimleri veya güvenlik endişeleri gibi zorlu operasyonel koşullar altında, karasal hücresel ağlar, kullanıcılara ve uygulamalara beklenen hizmet düzeylerini sağlamada yetersiz kalabilir. Ayrıca, doğal afetler veya fiziksel felaketler sırasında, mevcut ağ altyapısı çökebilir ve hizmet verilen alanda ilk müdahale ve acil durum iletişimi için ciddi zorluğa sebep olabilir. Saha müdahale ekipleri için düşük gecikmeli hizmetler ve herkese açık temel internet bağlantısı sağlamak ve ayrıca geçici yüksek hizmet yükü durumlarında kapasite artırmayı kolaylaştırmak için yedek veya yardımcı olma görevinde, hızlıca kurulabilir bir ağ gereklidir. İnsansız Hava Aracı (İHA) ağları, hızlı ve esnek hareket kabiliyetleri sayesinde bu tür ihtiyaçlar için oldukça uygundur. Bu tez, uçtan buluta süreklilik ortamında gecikmeye duyarlı iş yüküne sahip olan mobil kullanıcılara hizmet veren, Wi-Fi erişim noktası monte edilmiş İHAlardan oluşan yazılım tanımlı bir ağı ele almaktadır. İsteğe bağlı hava ağı aracılığıyla öncelikli hizmetler sağlamak için görev atama paradigmasını araştırır. Hizmet verilen alandaki kullanıcılar için temel bağlantıya ek olarak, bu bilgi işlem-iletişim altyapısı esas olarak karasal birimlere araçtan araca (V2V) ve araçtan buluta (V2C) görev atama hizmetleri sağlar. Çalışmamızda, görev işleme ve görev atama yönetimi, hizmet kalitesi gereksinimlerinin karşılanmasının değerlendirilmesinde ana kriter olarak görev süreleri dikkate alınmaktadır. Buna göre, görev önceliğine göre ağırlıklandırılmış gecikme sürelerinin toplamını en aza indirmek için bir atama yönetimi optimizasyon modeli tanımlanır. Tanımlanan atama problemi NP-hard olduğundan, sistemin farklı çalışma koşullarında nasıl performans gösterdiğini incelemek için uyarlanmış buluşsal modeller önerilmiş ve değerlendirilmiştir.","Under demanding operational conditions such as traffic surges, coverage issues, very-low latency requirements, or security concerns, terrestrial cellular networks may become inadequate to provide the expected service levels to users and applications. Moreover, when natural disasters or physical calamities occur, the existing network infrastructure may collapse, leading to formidable challenges for the first response and emergency communications in the served area. In order to provide low-latency services for first-responders and baseline connectivity for the public as well as facilitate a capacity boost under transient high service load situations, a substitute or auxiliary fast-deployable network is needed. Unmanned Aerial Vehicle (UAV) networks are well suited for such needs thanks to their high mobility and flexibility. This thesis considers a software-defined network consisting of Unmanned Aerial Vehicles (UAVs) mounted with Wi-Fi access points, which serve mobile users with the latency-sensitive workload in an edge-to-cloud continuum setting. It investigates the task offloading paradigm to provide prioritized services via this on-demand aerial network. In addition to baseline connectivity for users in the deployed area, this computing-communication infrastructure essentially provides Vehicle-to-Vehicle (V2V) and Vehicle-to-Cloud (V2C) task offloading services to terrestrial units. In our work, task processing, and offloading management, task deadlines are taken into account as the key criterion for meeting service quality requirements. Accordingly, an offloading management optimization model is defined to minimize the overall penalty due to delay weighted with task priorities. Since the defined assignment problem is NP-hard, tailored heuristic models are proposed and evaluated to study how the system performs under different operating conditions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, sosyal olarak uyumlu bir şekilde hareket edebilen bir sosyal robotun tasarımı ve geliştirilmesi amaçlanmıştır. Günlük hayatta ve insanların bulunduğu ortamlarda robotların gittikçe daha fazla kullanılmaya başlanması bu problemi daha önemli hale getirmektedir. Bu tezde, bu problem iki ayrı bölümde ele alınmıştır. İlk bölümde SempRob adı verilen robotun tasarımına ve gerçeklenmesine odaklanılmıştır. Robot tasarlanırken, görünüşünün insanlara sempatik gelecek şekilde olmasına ve sensör\linebreak lerin en uygun şekilde konumlandırılmasına dikkat edilmiştir. İkinci bölümde, robotun hareket planlama algoritmalarının geliştirilmesine odaklanılmıştır. İlk olarak, robotun karmaşık ortamlarda güvenli ve etkili hareketini sağlayan pekiştirmeli öğrenmeli yapay potansiyel fonksiyonlar (APF-RL) yöntemi önerilmiştir. Bunu sağlamak için elips tabanlı yeni bir engel modelleme yöntemi de geliştirilmiştir. Ayrıca, öğrenme senaryolarının tüm karmaşık ortamları kapsaması için yeni karma şıklık seviyesi metrikleri tanımlanmıştır. Hareketin modelinin eğitimi önce simülasyonda yapılmış sonrasında fiziksel robota aktarılmıştır. Sonrasında, APF-RL yöntemi modifiye edilerek sosyal navigasyon yöntemi olan sosyal APF-RL geliştirilmiştir. Bu yöntem APF-RL'den farklı olarak ortamdaki insanların konfor alanlarına girmemeye özen gösterir. Sosyal navigasyon ortamdaki insanların algılanmasını ve uzamsal olarak takip edilmesini gerektirir. Bunun için bir derin öğrenme temelli insan algılama yöntemi Kalman filtresiyle birleştirilerek kullanılmıştır. Son olarak geliştirilen hareket yöntemleri insan takibi uygulamasında kullanılmak için de uygun haline getirilmiştir. Önerilen yöntemler geliştirilen robot üzerinde gerçek hayatta başarıyla test edilmiştir.","This thesis is concerned with the design and development of a social robot that can navigate around in a socially compliant manner. The importance of this problem is due to the growing demand of using robots in human-populated environments. In this thesis, this problem is addressed in two concurrent parts. The first part has focused on the physical design and development of a social robot - named as SempRob. SempRob is aimed to have a sympathetic appearance while also having a design in which its visual sensors are located appropriately for environmental sensing. In the second part, the social navigation capability of the social robot is developed. First, a novel navigation method referred to as artificial potential function with reinforcement learning (APF-RL) method. In addition, an ellipse-based representation of obstacles is developed for efficient obstacle representation. Furthermore, environmental complexity measures are defined in order to ensure that learning scenarios incorporate a range of maneuvering difficulties. Both simulation and experimental results with SempRob demonstrate that APF-RL method enables the robot to move safely and efficiently in complex environments. Following, APF-RL method is extended to Social APF-RL method so that the robot additionally respects the comfort zones of the humans while navigating. This requires the robot to detect the humans in its surroundings and to track them spatially. A deep learning based human detection algorithm is combined with a Kalman filter for this purpose. Finally, Social APF-RL method is modified to be applicable in human following as well. All the proposed methods are tested on the developed robot successfully."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Video görüntülerinden otomatik olarak etkileşimli grupları tanıma, videolardan aktivite algılama ve insan-robot ilişkilerini geliştirmek için oldukça kullanışlı bir araştırma konusu olmuştur. Bu sebeple, etkileşimli grupların algılanma doğruluğunu iyileştirmek, insan robot ilişkilerini kuvvetlendirmek için doğan ciddi bir ihtiyaçtır. Bu tezde, Çizge Evrişimli Sinir Ağları kullanarak etkileşimli grup tespit problemine özgün bir katkı yapılmıştır. Topluluk tanıma alanında kullanılan Deep Modularity Networks (DMoN) adında bir yöntem baz alınarak yeni bir grup tanıma sistemi geliştirilmiştir. Bu zamana kadar olan teknoloji grup tanıma metotlarında en ileri teknoloji yöntemlerin tanıma kalitesi yükseltilmiştir. Buna ek olarak, insanların yakınlığını görüş konileri kullanarak gösteren bir çizge inşa algoritması geliştirilmiştir. Problemin zaman boyutunu da hesaba katan bir art işleme adımı sisteme entegre edilerek tanıma sonuçları daha ileriye taşınmıştır.","Automatically detecting conversational groups from video footage is a very intriguing and practical research area with applications in video activity recognition and human-robot interaction. Therefore, there is a critical need for improved detection of groups to enhance the relationship between humans and robots. In this thesis, we use Graph Convolutional Networks for the group detection problem as the main novel contribution. We base our approach on a method from the community detection domain called Deep Modularity Networks. Our approach improves the group detection quality over state-of-the-art group detection methods. Additionally, we develop a graph construction algorithm using the view frustums, which indicates the individuals' affinities. As a post-processing step, we utilize temporal information in our system and improve our detection results further."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde hızla yükselen hesaplama gücü ve gelişiminin doruklarında olan sekanslama teknolojileri hesaplamalı biyoloji alanındaki en önemli sorunlardan olan proteinlerin hücre içi fonksiyonlarının tahminlenebilmesi için yüksek işlem hacmi ile ileri seviye algoritmaların kullanılabilmesine olanak sağlamaktadır. Proteinlerin hücre içi işlevleri aslen üç boyutlu katlanmış yapıları sayesinde ortaya çıkmaktadır. Bu yapılar bir çizge olarak yorumlandığında çizge sinir ağları bu yapılara uygulandığında umut verici sonuçlar ortaya çıkmaktadır. Fakat çoğu protein için üç boyutlu katlanmış yapılar henüz yeterince bilinmediğinden bu yaklaşımlar kısıtlı kalmaktadır. Bununla birlikte proteinlerin amino asit dizilerinin doğal dillere benzer niteliklere sahip olması ve büyük miktarlarda dizi verisi bulunması bu dizilerin doğal dil işleme yöntemleri ile de işlenebileceğini ve işlevsel tahmin yapılabileceğini işaret etmektedir. Bu tezde, protein dizisi verisinin üç boyutlu katlanmış yapıyı da hücre içi fonksiyonu da tahmin etmek için yeterli bilgiyi içerdiği varsayımı ile iki farklı doğal dil işleme yöntemi probleme uyarlanmıştır: (i) çift yönlü dönüştürücü temelli BERT modeli (ii) çizge sinir ağları temelli heterojen çizge evrişimsel sinir ağı modeli. Sonuçlar, proteinleri çizge şeklinde yorumlamanın daha avantajlı olduğunu ortaya koymuştur. Çizge evrişimsel sinir ağları modeli BERT modelinden daha başarılı sonuçlar üretmiş ve üç boyutlu katlanmış yapıların bilgisini de kullanan son teknoloji çizge temelli modele yakın bir performans göstermiştir. Ayrıca, dizideki her amino asidin tek tek kullanılması yerine gruplandırılmış şekilde kullanılmasının daha başarılı sonuçlar ürettiği gözlemlenmiştir.","Rapidly increasing computational power and sequencing technologies, which are at the peak of their development, enable the use of advanced algorithms with high processing volume to predict the intracellular functions of proteins, which is one of the most important problems in computational biology. The functionalities of proteins emerge primarily through their three-dimensional folded structures. When these structures are interpreted as graphs, the application of graph neural networks leads to promising results. However, these approaches are limited as the three-dimensional folded structures are not yet known for most proteins. The fact that the amino acid sequences of proteins have properties similar to natural languages and the large amounts of sequence data suggest that these sequences can be processed using natural language processing (NLP) methods. In this thesis, two different NLP methods are adapted to the problem of protein function prediction, assuming that the protein sequence data contain necessary and sufficient information to predict both three-dimensional folded structure and intracellular function: (i) Bidirectional Transoformer BERT model (ii) Heterogeneous Graph Convolutional Network (GCN) model. The results show that it is more advantageous to treat the proteins as graphs. The GCN model performs better than the BERT model and achieves performance close to the state-of-the-art model that uses three-dimensional folding information. In addition, we find that tokenizing the sequences instead of using the individual amino acids as tokens increases the performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda, özellikle Covid-19 salgını sonrasında, uzaktan oylama sistemleri önem kazanmaya başlamıştır. Blokzincir teknolojisinin merkeziyetsizlik, güvenlik ve şeffaflık gibi faydaları, uzaktan seçim sistemlerini de bu teknolojiyi kullanmaya teşvik etmektedir. Mevcut araştırmalar üzerine yapılan analizler; anonimlik, sağlamlık ve ölçeklenebilirliğin blokzincir tabanlı seçim sistemlerinde yaygın sorunlar olduğunu ortaya koymaktadır. Bu tezde, anonimlik, sağlamlık ve ölçeklenebilirliğe odaklanan blokzincir tabanlı, tercihli oylama protokolü olan ElectAnon'u önermekteyiz. Protokol, anonimliği sağlamak için sıfır bilgi ispatlarını kullanır. Protokol, sağlamlığı arttırmak için seçim yetkililerinin seçime doğrudan müdahele etmesini engeller. Protokol, sıralı oy listelerini verimli bir kodlama algoritmasıyla saklayarak ölçeklenebilirliği arttırmayı amaçlar. Ayrıca protokol aday önerme sistemini de içerir. Ayrıca tezin içersinde üç farklı eklenti de ele alınmıştır. Çoklu Seçim eklentisi, aynı seçmen grubunu birden fazla seçimde kullanmak için bir mekanizma sağlar. Merkle Ormanı eklentisi, bir miktar ekstra maliyet karşılığında seçim yetkilileri üzerindeki güven varsayımını en aza indirir. Destekli Merkle Ağacı eklentisi, yetkililerden ek bir yardım gereksinimi karşılığında ölçeklenebilirliği artırmayı hedefler. ElectAnon, Borda Count ve Tideman olmak üzere iki farklı oy sayma yöntemi içerir. ElectAnon, Ethereum akıllı sözleşmeleri ve sıfır bilgi ispat uygulaması olan Semaphore kullanarak geliştirilmiştir. Test sonuçları, önerdiğimiz protokolün 100.000'e kadar seçmenle uygulanabilir bir şekilde çalışabileceğini ve daha önceki çalışmalara göre gaz tüketimini %89'a varan oranlarda azalttığını göstermiştir.","Remote voting has become more critical in recent years, especially after the Covid-19 outbreak. Blockchain technology and its benefits like decentralization, security, and transparency have encouraged remote voting systems to use blockchains. Analysis of existing solutions reveals that anonymity, robustness, and scalability are common problems in blockchain-based election systems. In this thesis, we propose ElectAnon, a blockchain-based, ranked-choice election protocol focusing on anonymity, robustness and scalability. ElectAnon achieves anonymity via zero-knowledge proofs. Robustness is realized by removing the direct control of the authorities in the voting process. Scalability is ensured by treating each ranked-choice ballot as a permutation list, then encoded into a single integer that can be efficiently stored. The proposed protocol includes a candidate proposal system to provide an end-to-end election solution. We also discuss three different extensions in this thesis. The Multiple Elections extension provides a mechanism to use the same set of voters for multiple elections. The Merkle Forest extension minimizes the trust assumption on election authorities in exchange for a decrease in scalability. The Assisted Merkle Tree extension offers just the opposite tradeoff by increasing scalability in favor of requiring external assistance from authorities. ElectAnon is implemented using Ethereum smart contracts and a zero-knowledge gadget, Semaphore. The implementation includes two different sophisticated tallying methods, Borda Count and Tideman. Results show that ElectAnon is capable of running feasibly with up to 100,000 voters and reduces the gas consumption up to 89% compared to previous works."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bulanıklık görsellerdeki hatları ve detayları dağıtır, dolayısıyla netliği düşürür. Bazen sanatsal değeri için istense de genelde bir noksan olarak görülür. Literatürde bulanık tespiti, segmentasyonu, ölçümü ve bulanıklığın giderilmesi gibi bulanık ile alakalı çeşitli problemler bulunur. Videolar ve fotoğraflar gibi görsel medyalarda bolca rastlanmasına karşın bulanıklık ile alakalı işaretlenmiş veri oldukça azdır. Bu durum eğitilmeleri için çok miktarda veri gerektiren derin öğrenme modellerinin kullanım olanaklarını kısıtlamaktadır. Bu modelleri kullanmayı mümkün hale getirecek kadar veri işaretlemek oldukça maliyetlidir. Biz bu tez çalışmasında, bulanıklık içeren/içermeyen görsellerin sınıflandırılması problemi üzerine çalışıyoruz. Ayrıca bulanıklığın derecesinin belirlenmesi ve görselde yerinin tespit edilmesi problemlerinde veri eksikliğine bir çare olarak zayıf gözetimin kullanımı ile ilgili araştırma ve deneylerde bulunuyoruz. Elde ettiğimiz sonuçları literatürde bulunan klasik metodlarınkilerle karşılaştırıyoruz. Üç tanesi işaret dili videolarından oluşan ve bir diğeri eylem tanıma videolarından meydana gelen toplam dört veri setinden alıp işaretlediğimiz kareleri bu çalışmalarımızda kullanıyoruz. Çalışmalarımızı bulanıklığın sık sık gözlendiği işaret dili videolarına yönlendirdik. İşaret dili, duyma engellilerin esas iletişim yöntemidir ve işaret dili tanıma çalışmaları bu sebeple büyük önem arz ediyor. Bulanıklığın veride bulunup bulunmadığının, eğer bulunuyorsa ne miktarda ve nerede bulunduğunun tespit edilmesi, işaret dili tanıma çalışmalarına da katkı sağlayabilecektir.","Blur impairs the sharpness of visual features and the clarity of details. It may sometimes be desired for artistic effect. However, in general, it is regarded as a defect. There are different problems studied about blur, such as blur detection, segmentation, estimation, and deblurring, but despite its abundance in visual media such as photographs and videos, there is limited annotated data about blur. This lack of data inhibits the usage of deep learning models because they require a lot of annotated data. Annotating that much data is expensive and cumbersome. In this thesis, we investigate blur-vs-sharp classification using deep learning, also we experiment with weak supervision as a remedy against the lack of data for blur assessment and localization. We compare our results with the classical approaches found in the literature. We use the data we annotated from four different datasets, three of which are sign language datasets and the other one is an action recognition dataset. We focus our research on sign language videos where motion blur is frequently encountered. Sign languages are the primary communication method of Deaf community and for that reason sign language recognition (SLR) is an important task. Determining the intensity of blur and its location may be beneficial for SLR research."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dünyadaki kablosuz hücresel ağ, teknolojideki birçok ilerlemenin yardım için kendilerini sunma fırsatı bulduğu muazzam bir yapısal değişimden geçiyor. Şu anda uygulanmakta olan en yeni nesil kablosuz ağ olan 5G hücresel ağ, yeni ağ veri analitiği işlevi (NWDAF) ile yapay zekayı memnuniyetle karşılıyor. NWDAF, 5G'nin diğer bileşenlerinin kendi operasyonlarını iyileştirmek için bilgi talep edebileceği bir veri analizi mekanizmasıdır. Bu tezde, NWDAF'ın yapısı ve protokolleri anlatılmaktadır. 3. Nesil Ortaklık Projesi (3GPP) tarafından sağlanan teknik şartname dokümanlarından elde edilen alanlar kullanılarak 5G ağ veri seti oluşturulmuştur. Yapay veri setini gerçeğe yaklaştırmak için rastgele oluşturulmuş anomaliler eklenir. Birkaç makine öğrenimi (ML) algoritması, NWDAF'nin iki yönünü, yani ağ yükü tahmini ve anormallik algılamayı incelemek için eğitilmiştir. Doğrusal regresyon (LR), tekrarlayan sinir ağı (RNN) ve uzun kısa süreli bellek (LSTM) algoritmaları, ağ yükü tahmini için yapay veri seti ve gerçek bir kurumsal ağdan elde edilen bir veri seti kullanılarak uygulanmıştır ve eğitilmiştir [1, 2]. Ortalama mutlak hata ve yüzdesel ortalama mutlak hata performans ölçümleri, RNN ve LSTM'nin hem oluşturulan hem de gerçek hayattan toplanan veri setlerinde LR'den daha iyi performans gösterdiğini göstermiştir. LSTM, gerçek hayattan toplanan veri seti için en iyi performans gösteren algoritmadır. Lojistik regresyon ve ağaç tabanlı bir sınıflandırıcı olan XGBoost, anormallik tespiti için uygulanır ve alıcı işletim karakteristikleri eğrisi altındaki alanı en üst düzeye çıkarmak için yapay veri seti kullanılarak eğitilmiştir. Sonuçlar, ağaç tabanlı sınıflandırıcı XGBoost'un lojistik regresyondan daha iyi performans gösterdiğini ortaya çıkarmıştır. Bu tahminlerin, performansını artırmak için NWDAF aracılığıyla 5G hizmet tabanlı mimariye yardımcı olması bekleniyor.","Wireless cellular networking in the world goes through a tremendous structural change where many advances in technology find an opportunity to present themselves for assistance. 5G cellular network, the most recent generation wireless network currently undergoing implementation, welcomes artificial intelligence with the novel network data analytics function (NWDAF). NWDAF is a data analytics mechanism where other components of 5G can request information from in order to utilize their operations. In this thesis, the structure and protocols of NWDAF are described. A 5G network data set is generated by using the fields obtained from the technical specification documents provided by 3rd Generation Partnership Project (3GPP). To bring the generated data set closer to reality, randomly created anomalies are added. Several machine learning (ML) algorithms are trained to study two aspects of NWDAF, namely network load prediction and anomaly detection. Linear regression (LR), recurrent neural network (RNN) and long-short term memory (LSTM) algorithms are implemented and trained using the generated data set and a data set obtained from a real enterprise network for network load prediction [1, 2]. Mean absolute error and mean absolute percentage error performance metrics indicate that RNN and LSTM outperform LR in both generated and real life data sets. LSTM is the best performing algorithm for the real life data set. Logistic regression and a tree-based classifier, XGBoost are implemented for anomaly detection, and trained using the generated data set to maximize the area under receiver operating characteristics curve. The results indicate that tree-based classifier XGBoost outperforms logistic regression. These predictions are expected to assist 5G service-based architecture through NWDAF to increase its performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İlişki Çıkarma (İÇ), düz bir metinden varlıklar arasındaki ilişkiyi bulma görevidir. Verilen metnin uzunluğu arttıkça ilişkiyi bulmak da gittikçe zorlaşmaktadır. Metnin bağlılık ağacında iki varlık arasındaki terimleri izleyerek oluşturulan en kısa bağlılık yolları, metindeki gürültü yaratan kelimeleri budayarak varlıklara odaklanmış bir gösterim sunar. İlişki Çıkarma konusunun denetimli versiyonu olan İlişki Sınıflandırma'da, çoğu son teknoloji metod yaklaşımlarına ön eğitimli dil modellerini entegre etmektedir. Ancak şu ana kadar ön eğitimli dil modelleri, varlıklar arası en kısa bağlılık yolları ile birlikte kullanılmamıştır. Bu tez, ön eğitimli modellerin varlıklar arası en kısa bağlılık yolları ile beraber kullanılmasının etkilerini incelemektedir. Bu inceleme için R-BERT ilişki sınıflandırma modeli temel model olarak alınmış ve üzerine geliştirmeler yapılmıştır. Sunduğumuz yeni yaklaşımda, temel modeli geliştirmek amacıyla, iki varlık arasındaki en kısa bağlılık yolunun ön eğitimli dil modellerinden geçirilmesi ile elde edilmiş genel temsili, ek bir vektör olarak temel modele eklenir. Deneylerde, temel model, Stanford, HPSG ve LAL bağlılık ayrıştırıcılarının XLNet ve BERT ön eğitimli dil modelleri ile kombinasyonları SemEval-2010 Task 8 ve TACRED veri kümelerinde değerlendirilmiştir. Deney sonuçlarında, önerilen modelin temel modelden SemEval-2010 Task 8 veri kümesinde 1.41%, TACRED veri kümesinde 3.6% daha iyi sonuç verdiği görülmektedir.","Relation Extraction (RE) is the task of finding the relation between entities from a plain text. As the length of the text increases, finding the relation becomes more challenging. The shortest dependency path (SDP) between two entities, obtained by traversing the terms in the text's dependency tree, provides a view focused on the entities by pruning noisy words. In RE's supervised form Relation Classification, the state-of-the-art methods generally integrate a pre-trained language model (PLM) into their approaches. However, none of them incorporates the shortest dependency paths into their calculations to our knowledge. In this thesis, we investigate the effects of using shortest dependency paths with pre-trained language models by taking the R-BERT relation classification model as our baseline and building upon it. Our novel approach enhances the baseline model by adding the sequence representation of the shortest dependency path between entities, collected from PLMs, as an additional embedding. In experiments, we have evaluated the proposed model's performance for each combination of SDPs generated from Stanford, HPSG, LAL dependency parsers, and baseline with BERT and XLNet PLMs in two datasets, SemEval-2010 Task 8 and TACRED. We improve the baseline model by absolute 1.41% and 3.6% scores, increasing the rankings of the model from 8th to 7th and 18th to 7th in SemEval-2010 Task 8 and TACRED, respectively."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kenar hesaplamada Nesnelerin İnterneti teknolojisinin önünü açacak ilerlemeler kaydedilmektedir. Firmalar ve geliştiriciler, kenar ağların heterojen yapısında çalışmayı kolaylaştırmak için yeni teknikler araştırmaktadırlar. Uygulama teslimi, kaynak tahsisi, hata toleransı ve güvenlik sorunları henüz kenarda tüketicilere pürüzsüz bir deneyim sunacak şekilde çözülmüş değildir. Soyutlama ve hafif konteynır yönetim platformları ile sağlanan sanallaştırmayla aynı uygulamayı farklı mimarilere sahip cihazlara dağıtmak ve tekdüzelik sağlamak mümkün olmuştur. Bu tezde önerilen çerçeve, tamamıyla merkezî olmayan bir kenara doğru, dinamik konteynır orkestrasyonu için temelleri ortaya koymaktadır. Dağıtık bir dosya sistemi olan Gezegenler Arası Dosya Sistemi (IPFS) üzerindeki bir kayıt sistemi aracılığıyla konteynır uygulamaları, güncellemeleri ve kaynak özellikleri için blokzincir tabanlı bir dağıtım platformu sağlamaktadır. Çerçeve kaynak tahsisini, ölçeklendirmeyi ve konteynır kullanılabilirliğini işletim sistemi sanallaştırmasıyla yönetmektedir. Ana bilgisayardan ve Docker sanallaştırma platformundan alınan metrikler üzerinde çalışan, kendi kendini uyarlayan bir kaynak yöneticisi konteynırlara tahsis edilen kaynakları dinamik olarak optimize etmektedir. Birden fazla cihaza genişletilmeyi desteklemek üzere tasarlanmış çerçeve, heterojen bir ortamın değişken iş yüklerinin aynı kenar cihazda bir arada var olmasını sağlar. Hafif bir mesajlaşma protokolü olan MQTT üzerinde yayınla/abone ol modelinin zaman uyumsuz ve dağıtılmış yapısından yararlanan olay güdümlü bir mimari oluşturularak tamamıyla dağıtık bir sistem elde edilebilmiştir.","Persistent advancements are being made at a rapid pace on enabling edge computing for the Internet of Things technology to capitalize on. Vendors and developers are exploring new techniques to smooth out the process of navigating through the inherent heterogeneity of the edge networks. However, application delivery, resource allocation, fault tolerance, and security issues are yet to be fully solved while also providing a seamless experience for consumers. With virtualization and lightweight container management platforms providing an abstraction layer, it is possible to deploy the same application on devices with different architectures and achieve uniformity. Towards a fully decentralized edge, the framework proposed in this thesis lays down the groundworks for dynamic container orchestration. It provides a blockchain-based delivery platform for container applications with their updates and resource specifications through a registry on a distributed file system, namely InterPlanetary File System (IPFS). Then, enabled by the operating system virtualization, the framework handles resource allocation, container availability and scaling. A self-adaptive resource manager running on the metrics scraped from the host and the virtualization platform, i.e. Docker in our implementation, dynamically optimizes the resources allocated to each container. The framework ensures that variable workloads of a heterogeneous environment can co-exist on an edge device that is designed to be further extended to multiple devices. To achieve a truly distributed system, an event-driven architecture is built over a lightweight messaging protocol, MQTT, capitalizing on the asynchronous and distributed nature of the publish/subscribe pattern."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Duygu Analizi, metinden öznel bir bilgiyi elde etmeyi amaçlayan bir Doğal Dil İşleme görevidir. İnternetin, ve dolayısıyla sosyal medyanın, ulaşılabilirliğinin artması insanların büyük miktarlarda metinsel veri üretmesine olanak sağladı. Bu veriler içlerinde çıkarılmayı bekleyen değerli bilgiler barındırıyor olabilir. Duygu analizi bu bilgiyi çıkarmaya odakalanan ve zamanla da popüler olan bir alandır. Bütün metnin duygusunun, o metinde geçen bir hedefe karşı olan duyguyu yansıtmadığı durumlar söz konusu olabilir. Hedef Odaklı Duygu Analizi verilen bir metinden verilen bir hedef kelimeye yönelik olan duyguyu çıkarmayı amaçlar. İngilizce metinlerde duygu analizi çokça çalışılan bir alandır ve çoğunlukla eğitim için insan eliyle işaretlenmiş veriler gereklidir. Türkçe gibi dillerde böyle işaretlenmiş verilerin eksikliği görülür. Bu çalışmanın kapsamında, duygu analizi ve hedef odaklı duygu analizi için işaretlenmiş bir veri kümesi sunuyoruz. Bu veri kümesi yaklaşık 4 bin adet hem duygu analizi hem de hedef odaklı duygu analizi görevlerine göre işaretlenmiş cümle içeriyor. Bu önerilen veri kümesi Türkçe metinlerde hedef odaklı duygu analizi modeli eğitmemize olanak sağlıyor. Önerilen BERT tabanlı modellerimizden bir tanesi temel model olarak, diğerleri ise bu temel modeli geliştirmek üzere eğitilmiştir. Farklı BERT tabanlı model mimarilerinin bu görev için performansını inceliyoruz. Geleneksel duygu analizi modellerinin performansının hedef odaklı duygu analizi görevinde düştüğünü gözlemliyoruz. En iyi sonuç veren hedef belirteçli ve maksimum havuz katmanlı modellerimiz geleneksel BERT tabanlı duygu analizi modellerinden %13 daha iyi F1 skoru verdiğini gözlemliyoruz.","Sentiment Analysis (SA) is one of the Natural Language Processing (NLP) tasks whose goal is to understand subjective information from a piece of text. The increased accessibility to the Internet and thus to social media leads people to create an enormous amount of textual data. This data can store valuable information that waits to be extracted. Targeted Sentiment Analysis (TSA) specifically aims to extract sentiment towards a particular target from a given text. Sentiment analysis in English texts is a well-studied area and mainly requires human-annotated data for training. For languages such as Turkish, there is a lack of such annotated data. In the context of this study, we introduce an annotated dataset that consists of Twitter data in Turkish. It contains almost 4K sentences that are labeled for both sentiment analysis and targeted sentiment analysis. The proposed dataset allows us to train a TSA model on Turkish texts. We propose BERT-based models with different architectures, one of which is to be used as our baseline for TSA and the others are to improve this baseline. We observe that the performance of conventional SA models degrades when used for TSA data. We investigate the performance of several BERT-based architectures for this task. Our best performing model with target markers and max-pooling layer outperforms the F1-score of conventional BERT-based SA models by 13%."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin evrişimli sinir ağları, imge sınıflandırma probleminde yüksek performansları nedeniyle en gelişmiş çözümler olarak kabul ediliyor. En belirgin dezavantajları, tek bir girdiyi işlemek için gereken yüksek işlem gücü ihtiyaçları. Gerekli iş gücünü azaltabilmek için, bir girdiyi sinir ağının hesaplama birimlerinin yalnızca belli bir alt kümesini kullanarak işlemeyi öğrenen koşullu hesaplama yöntemleri bulunmakta. Girdileri yönlendirerek derin bir sinir ağının yalnızca bir bölümünü kullanmayı öğrenmenin birçok avantajı var. İlk olarak, işlem yükünü azaltmanın büyük bir fayda sağlayacağı aşikardır. Ayrıca, benzer özelliklere sahip imgeler aynı yola yönlendirilirse, ağın belli bir kısmı bu sınıflar arasındaki daha ince farklılıkları ayırt etmeyi öğrenir ve bu da daha az parametre ve işlem gücü ile daha iyi sınıflandırma başarımı sağlar. Yapay sinir ağının belli bir girdi karşısındaki aktivasyonlarını inceleyebilmek, sinir ağının tahminlerini yorumlamaya yardımcı olabilir. Son zamanlarda bazı çalışmalar, ağaç şeklindeki ağları kullanan veya bir düğümün belirli bir çocuğunu seçerek ağın bazı parçalarını es geçmeyi öğrenen koşullu öğrenim modelleri önerdi. Bu tezde, derin bir sinir ağında belirli yolları kullanmayı öğrenmek için kafes yapısı temelli yeni bir yaklaşım izledik. Ayrıca, bir imge için bir katman bloğundaki birimlerin hangi alt kümesinin kullanılacağını öğrenen denetimsiz türevlenebilir bilgi kazanımı tabanlı bir yitim fonksiyonu kullanan yeni bir mekanizma tasarladık. Yöntemimize Koşullu Denetimsiz Bilgi Kazanımı Kafesi (CUTE) diyoruz. Denetimsiz bilgi kazanımı tabanlı yitim fonksiyonumuzun kümeleme başarımını farklı senaryolarda teste tabi tuttuk. Son olarak, Fashion MNIST veri kümesi üzerinde CUTE mimarimizi denedik. İşlem gücünün yalnızca bir kısmını kullanan koşullu öğrenim mekanizmamızın, koşullu öğrenme kullanmayan referans modellere karşı karşılaştırılabilir veya onlardan daha iyi başarım sağladığını gösterdik.","Deep convolutional neural networks are considered state-of-the-art solutions due to their high classification performance in image classification tasks. The apparent drawback is the amount of computing power required to process a single input. To deal with this, this thesis proposes a conditional computation method that learns to process an input using only a subset of the network's computation units. Learning to execute only a part of a deep neural network by routing individual samples has several advantages. Firstly, it is beneficial to lower the computational burden. Furthermore, if images with similar semantic features are routed to the same path, that part of the network learns to discriminate finer differences among this subset of classes, resulting in improved classification accuracy with fewer parameters and computational resources. Investigating the network's activation on a single sample can also help interpret the neural network's prediction. Several works have recently exploited this idea using tree-shaped networks or taking a particular child of a node and skipping parts of a network. In this thesis, we follow a trellis-based approach for generating specific execution paths in a deep neural network. We have also designed a routing mechanism that uses unsupervised differentiable information gain-based cost functions to determine which subset of units in a layer block will be executed for a sample. We call our method Conditional Unsupervised Information Gain Trellis (CUTE). We tested the clustering performance of our unsupervised information gain-based objective function under different scenarios. Finally, we tested the classification performance of our trellis-shaped CUTE network on the Fashion MNIST dataset. We show that our conditional execution mechanism achieves comparable or better model performance than unconditional baselines, using only a fraction of the computational resources."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda geniş bant kablosuzla birlikte Wi-Fi, kablosuz iletişimin merkezinde oldu. Mobil bağlantılar dizüstü bilgisayar, tablet ve cep telefonu sahibi son kullanıcıların hayatını kolaylaştırdı. Mobil cihazlara olan bu uyum artan miktarlarda bant genişliği ihtiyacını beraberinde getirdi. Bu beklentiyi karşılamak amacıyla IEEE 802.11 standardına zaman içinde yenilikler getirildi. IEEE 802.11ac versiyonuyla beraber gigabit bariyerinin aşılmasıyla ana odak Wi-Fi'ın verimliliğini arttırma ve enerji tüketimini azaltma üzerine kaydı. Son Wi-Fi versiyonu olan IEEE 802.11ax, özellikle kalabalık bölgelerdeki plansız erişimden kaynaklanan sinyal çakışmalarını azaltmayı hedefliyor. Bu sayede kullanıcılara daha iyi bir deneyim ve çevre koruması sunmaya odaklanan Wi-Fi 6, bu amaçla belirli cihazların antenlerini belirlenmiş bir süre boyunca uyutmayı hedefleyen Hedef Uyandırma Zamanı (TWT), sinyallerin bir arada var olmasını daha iyi değerlendiren Kesişen Basit Servis Seti Başlangıç Tespiti (OBSS/PD) ve Dikey Frekans Bölümlemeli Çoklu Erişim (OFDMA) temelli planlı erişim ile plansız erişimin terki ve kaynak birimi düzeyinde paralelizm ve çoklu erişim yöntemleriyle erişim noktası cihazının (modem) ağ trafiğini yönetmesini sağlayan mekanizmaları getiriyor. Çalışmamız uygun zamanlama mekanizmalarını araştırmakta ve geliştirdiğimiz yeni zamanlayıcıyı önermektedir. Zamanlayıcılarımız çift yönlü çalışmakta ve maksimum internet hızı sağlamaktadır. Gelişmiş NS-3 ağ simülatörü ile yapılan testlerde iki kata varan performans artışı sağlanmış ve bu sayede daha az enerji tüketen ve daha yeşil bir Wi-Fi elde edilmiştir.","In recent years, Wi-Fi, along with Broadband Wireless, has been at the center of wireless communication. End-users owning laptops, tablets, and mobile phones enjoyed connected mobility. This massive adaptation brought more bandwidth demands. Consecutive IEEE 802.11 standard amendments were developed to overcome these requirements. Since hitting the gigabit barrier in IEEE 802.11ac, the main focus has shifted to increasing efficiency and reducing power consumption. Motivated by this, the latest amendment, IEEE 802.11ax, aims to minimize channel contention among network devices due to the very nature of random access, especially in dense areas. In this respect, IEEE 802.11ax, or Wi-Fi 6, brings several improvements focusing on these demands for better user experience and environment protection. In this regard, it introduces Target Wake Time (TWT) to make certain nodes sleep a definite amount of time to preserve power, Overlapping Basic Service Set Preamble Detection (OBSS/PD) to exploit co-existence better, and finally, Orthogonal Frequency Division Multiple Access (OFDMA) based scheduled access to abandon previously used random access mechanisms by replacing it with scheduled access that allows an Access Point (AP) to schedule and manage traffic by making use of resource level parallelism and multiple spatial streams. This thesis investigates proper scheduling mechanisms and develops novel scheduler that work downlink and uplink directions. Our scheduler ensures maximum throughput delay. We tested our scheduler on state-of-the-art NS-3 network simulator and doubled the performance, leading to better power saving and greener Wi-Fi."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin Sinir Ağları (DNN), bilgisayar görüşü, doğal dil işleme ve konuşma tanımadaki zorlu sorunları çözmek için yaygın olarak kullanılmaktadır. Bununla birlikte, rakip saldırılar gibi son araştırmalar, DNN'lerin performansını sağlamak için yüksek doğruluğun yeterli olmadığını göstermektedir. Ek olarak, uç cihazlarda DNN modellerinin kullanılması, DNN modelindeki bit hatalarına karşı yüksek dayanıklılık gerektirir. Bu nedenle, sağlamlık ve esneklik iyileştirme yöntemleri gereklidir. Ancak bu yöntemleri bir arada ele alan bir çalışma bulunmamaktadır. Bu tezde, sağlamlık ve dayanıklılık iyileştirme yöntemlerinin dayanıklılık ve sağlamlık üzerindeki etkisini karşılaştırıyor ve analiz ediyoruz. Sağlamlık ve dayanıklılık iyileştirme yöntemlerinin temsilcileri olarak rakip eğitim ve bit hatası eğitimini kullanıyoruz. Ayrıca rakip eğitimi ve bit hatası eğitimini birleştirip yeni bir öğrenme yöntemi, rakip ve bit hatası eğitimi sunuyoruz. Sağlamlık için, eğitilmiş dört DNN modelinin test doğruluğunu ve sağlam doğruluğunu karşılaştırıyoruz. Dayanıklılık için, dört eğitimli DNN modelinin farklı bit hata oranlarıyla rastgele bit hatalarına karşı performansını karşılaştırıyoruz. Sonuçlar, dayanıklılık geliştirme yöntemlerinin sağlamlığı iyileştirdiğini, sağlamlık geliştirme yönteminin ise rakip eğitim ile eğitilen modellerin test doğruluğundaki düşüş nedeniyle dayanıklılığın azalmasına neden olabileceğini göstermektedir. Eğitim sırasında kayıp fonksiyonu içinde birden fazla bit hata oranı kullanan bir dayanıklılık iyileştirme yöntemi olan çoklu bit hata eğitimi (MBET) sunuyoruz. MBET'i normal eğitim ve bit hatası eğitimine karşı iki veri kümesinde dört farklı DNN modeliyle test ediyoruz. Sonuçlar, MBET'in normal eğitime kıyasla dayanıklılığı ve sağlamlığı geliştirdiğini göstermektedir.","Deep Neural Networks (DNN) are used extensively to solve challenging problems in computer vision, natural language processing, and speech recognition. However, recent studies such as adversarial attacks show that high accuracy is not enough to ensure the performance of DNNs. Additionally, deployment of DNN models on edge devices requires high resilience against bit errors in the DNN model. Therefore, robustness and resilience improvement methods are necessary. However, there is no study that discusses these methods together. In this thesis, we compare and analyze the effect of robustness and resilience improvement methods on resilience and robustness, respectively. We use adversarial training and bit error training as representatives of robustness and resilience improvement methods. We also introduce adversarial and bit error training, a combined training method of adversarial training and bit error training. For robustness, we compare test accuracy and robust accuracy of four trained DNN models. For resilience, we compare the performance against random bit errors with different bit error rates of four trained DNN models. The results show that resilience improvement methods improve the robustness, while the robustness improvement method can cause a decrease in resilience due to the test accuracy drop of models trained with adversarial training. We propose multiple bit error training (MBET), a resilience improvement method that utilizes more than 1-bit error rates inside the loss function during the training. We test MBET with four different DNN models on two datasets against normal training and bit eror training. The results show that MBET improves resilience and robustness compared to normal training."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Event is a fuzzy term that refers to bounded spatio-temporal units, which guide behavior to allow adaptation to complex environments. The study of event segmentation investigates mechanisms behind detecting these spatial-temporal units. Event segmentation theory states that people predict ongoing activities and monitor their prediction errors for segmentation. In this study, the mechanism underlying the event segmentation ability was enlightened with computational models and psychological experiments. Firstly, inspired by event segmentation theory and predictive processing, a computational model of event segmentation and learning was introduced. The performance of the model was compared with humans in point-light displays-based psychological experiments to verify that it can segment ongoing activity into meaningful units, learn them via passive observation, and represent them in its internal representational space. Results indicated that the computational model reached a comparable performance to humans in event segmentation and event representation experiments. Secondly, focusing on the role of prediction errors in event segmentation, several psychological experiments were conducted with the aim of revealing the effect of sensory information (bottom-up processes) and expectation (top-down influence) on perceived event boundaries. Results of psychological experiments were discussed in light of possible implications and future directions.","Olay sınırlı uzaysal ve zamansal bir birime işaret eden belirsiz bir terimdir ve davranışları yönlendirerek karmaşık ortamlara uyumu sağlar. Olay ayırma çalışmaları uzaysal ve zamansal birimlerin tespitinin altında yatan mekanizmaları araştırır. Olay ayırma teorisi ise insanların süregelen aktiviteleri tahmin ettiğini ve olayları birbirinden ayırmak için öngörü hatalarını sürekli olarak izlediğini öne sürer. Bu çalışmada, olay ayırma yeteneğinin altında yatan mekanizma hesaplamalı modeller ve psikoloji deneyleri yoluyla aydınlatılmaya çalışılmıştır. İlk olarak, olay ayırma teorisinden ve öngörülü işlemeden ilham alınarak, olay öğrenme ve ayırmanın hesaplamalı bir modeli geliştirilmiştir. Modelin süregelen aktiviteyi anlamlı bütünlere ayırdığını, onları pasif gözlem ile öğrendiğini ve içsel temsil uzayında temsil ettiğini kanıtlayabilmek için, modelin performansı nokta-ışık görüntülerinden yararlanılarak oluşturulan psikoloji deneyleriyle test edilmiştir. Sonuçlar hesaplamalı modelin olayları ayırma ve temsil etme performansının insanlarla kıyaslanabilir düzeyde olduğunu göstermektedir. İkinci olarak, tahmin hatalarının olay ayırmadaki rolü dikkate alınarak, duyusal bilginin (aşağıdan-yukarıya işleme) ve beklentinin (yukarıdan-aşağıya etki) algılanan olay sınırları üzerindeki etkisi incelenmiştir. Bu kısımdaki araştırmaların sonuçları olası çıkarımlar ve gelecekte yapılacak çalışmalar açısından tartışılmıştır."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sinir ağlarının doğal dil işlemedeki başarısı, hızla makine çevirisinde ana yaklaşım haline gelen sinirsel makine çevirisinin (SMÇ) yolunu açmıştır. Kodlayıcı-kod çözücü (encoder-decoder) ağları, dikkat (attention) mekanizması ve Transformer mimarisi gibi atılımlarla çeviri performansında muazzam bir gelişme sağlanmıştır. Bununla birlikte, bir SMÇ sistemini eğitmek için büyük miktarda paralel verinin gerekmesi ve çeviri derlemlerinde kullanılan az rastlanmış kelimeler, henüz üstesinden gelinmemiş sorunlardır. Bu çalışmada, düşük kaynaklı Türkçe-İngilizce dil çiftinin sinirsel makine çevirisi ele alınmaktadır. Son teknoloji SMÇ mimarileri ve tek dilli derlemlerden yararlanılan veri artırma yöntemleri kullanılmıştır. Morfolojik açıdan zengin Türk dili için girdi temsilinin önemine dikkat çekilmiş ve dilbilimsel güdümlü ve dilbilimsel güdümlü olmayan girdi bölümleme yaklaşımlarının kapsamlı bir analizi yapılmıştır. Farklı girdi varyasyonları üzerinde yapılan deneyler, zengin bir morfoloji taşıyan Türkçe için morfolojik güdümlü girdi bölümlemenin önemini kanıtlamıştır. Ayrıca, Türkçe-İngilizce dil çifti için Transformer mimarisinin dikkat mekanizmasına sahip kodlayıcı-kod çözücü (attentional encoder-decoder) modellere göre üstünlüğü gösterilmiştir. Kullanılan veri artırma yaklaşımları arasında geri çevirinin en etkilisi olduğu kanıtlanmıştır ve paralel veri miktarındaki artışın çeviri kalitesine faydası doğrulanmıştır. Bu tez, farklı hiperparametrelerle eğitilen SMÇ mimarileri, veri büyütme yöntemleri ve girdi temsil teknikleri üzerine kapsamlı bir analiz sunmakta ve Türkçe-İngilizce SMÇ'nin düşük kaynak sorunu ile mücadele etmenin yollarını önermektedir.","Success of neural networks in natural language processing has paved the way for neural machine translation (NMT), which rapidly became the mainstream approach in machine translation. Tremendous improvement in translation performance has been achieved with breakthroughs such as encoder-decoder networks, attention mechanism and Transformer architecture. However, the necessity of large amounts of parallel data for training an NMT system, and rare words in translation corpora are issues yet to be overcome. In this study, neural machine translation of the low-resource Turkish-English language pair is approached. State-of-the-art NMT architectures are employed and data augmentation methods that exploit monolingual corpora are used. The importance of input representation for the morphologically-rich Turkish language is pointed out, and a comprehensive analysis of linguistically and non-linguistically motivated input segmentation approaches has been made. Experiments on different input variations have proven the importance of morphologically motivated input segmentation for the Turkish language that carries a rich morphology. Moreover, superiority of the Transformer architecture over attentional encoder-decoder models has been shown for the Turkish-English language pair. Among the employed data augmentation approaches, back-translation has proven to be the most effective, and the benefit of increasing amount of parallel data on translation quality is confirmed. This thesis demonstrates a comprehensive analysis on NMT architectures with different hyperparameters, data augmentation methods and input representation techniques, and proposes ways of tackling the low-resource setting of Turkish-English NMT."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Aktif olarak kontrol edilebilen kapsül robotlar, endoskopik incelemelerde kullanılmak üzere geliştirilen yeni bir teknolojidir. Bu teknoloji sayesinde sindirim sisteminde meydana gelen çeşitli kanser türleri, Crohn hastalığı, ülseratif kolit ve kanama gibi birçok mide ve bağırsak hastalıkları teşhis edilmektedir. robotik kapsüller ile kapsamlı bir taramanın sağlanması, bu tür kritik hastalıkların tespiti açısından büyük önem arz etmektedir. Bu ̧calışmada, aktif kapsül robotlar için insan gastrointestinal yolunu en yüksek seviyede görüntülemeyi amaclayan bir otonom alan tarama yöntemi önerilmektedir. Çalışma kapsamında geliştirilen simülasyon ortamı sayesinde, kapsül robotları manyetik alan ile otonom olarak yönlendirebilmeyi öğrenen bir derin takviyeli öğrenme modeli eğitilmiştir. Metodumuzun hem fiziksel hem de görsel olarak gerçekçiliği sağlanan kapsül endoskopi koşullarında başarılı bir şekilde hareket edebildiği ve temel alan tarama yöntemlerine kıyasla daha iyi sonuçlar verdiği gösterilmiştir. Ayrıca, kapsül robotlara yer tayini ve üç ̧ boyutlu haritalama yeteneklerini kazandırmak için bir görsel odometri ve derinlik öğrenme yaklaşımı sunulmaktadır. Bu yaklaşımda, simülasyon ortamında elde edilen sentetik endoskopi verileri kullanılarak birden fazla evrişimli sinir ağı herhangi bir referans verisine ihtiyaç duymaksızın eğitilmiştir. Eğitilen bu modellerin hem sayısal hem de niteliksel değerlendirmeleri poz ve derinlik kestirimi ile beraber üç boyutlu yüzey oluşturma işlemi üzerinde sunulmuştur. Sonuçlar, önerdiğimiz yer tayini ve haritalama yöntemlerinin eşlik ettiği öğrenmeye dayalı otonom alan tarama konseptinin, mevcut ve gelecek nesil kapsül robotların önemli yazılım bileşenleri olması ve ileride endoskopik sistemlerin geliştirilmesinin önünü açması bakımından yüksek bir potansiyele sahip olduğunu göstermektedir.","Endoscopic examination with actively steerable capsule robots is an emerging technology for the diagnosis of various cancer types and many other gastrointestinal diseases such as Crohn's disease, ulcerative colitis, and hemorrhage. Ensuring a comprehensive screening with these robotic capsules is of paramount importance in the detection of such critical diseases. In this work, we propose a novel autonomous area coverage method for active capsule endoscopes, which aims to maximize the amount of monitored area in the human gastrointestinal tract in a time-efficient manner. We introduce a simulation environment and train a deep reinforcement learning model that learns to autonomously navigate magnetically-driven capsule robots for the area coverage task based on visual feedback provided by an on-board monocular camera. Under both physically and visually realistic capsule endoscopy circumstances our method performs successful reasoning and outperforms baseline coverage path planning approaches on human stomach organ models. Besides, we develop both localization and depth estimation methods for capsule robots by jointly training multiple convolutional neural networks in a self-supervised fashion through utilizing large-scale synthetic endoscopy data recorded in the simulation environment. Numerical assessments of the pose estimation network are presented in comparison with similar studies and the depth estimation method is qualitatively assessed on real endoscopy images and dense surface reconstruction task. Results demonstrate that the proposed learning-based coverage path planning approach in company with the monocular localization and surface reconstruction methods have the potential to become key software elements of the current and next-generation capsule robots and to pave the way for the development of future endoscopic systems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, robotların nokta bulutu verilerini kullanarak haritalandırma yapması amaçlanmıştır. Bu zorlu işlem için gelen verilerin bölütlenmesi, kapsayıcı şekilde tanımlanması ve üretilen bilginin öğrenmede ve karar vermede kullanılması gerekmektedir. Bölütleme robota aday nesnelerin tanımlanmasını sağlar. Robot bu bilgileri öğrenme ve karar verme aşamalarında kullanır. LİDAR gibi derinlik algılayıcı sensörler robotların çevresel bilgi edinmeleri için önemlidir. Fakat, genellikle ayrık verili ortam taramaları üretirler. Bu yüzden, bu sensörlerin verilerinin işlenmesi özel olarak ele alınmalıdır. Bu çalışmada bölütleme işlemi için küresel koordinat düzleminde çalışacak yoğunluk esaslı bir yöntem önerilmiştir. Devamında, oluşan bölütleri betimleme amaçlı yamulmuş küre yaklaşıklık betimleyicisi önerilmiştir. Elde edilen deneysel sonuçlar tanımlayıcının nesneleri kategorilere ayırmada başarılı çalıştığı görülmüştür. Robot hareket ederken oluşan veri akışının anlık olarak değerlendirilmesi sahne anlamlandırmada çok önemli olsa da genellikle bu veriler üzerinden zamansal muhakeme yapılmaz. Fakat, robot hareketiyle oluşan bilgi akışında nesneler üzerinden bir devamlı olarak bir bilgi akışı gerçekleşmektedir. Bu bilgi akışını kullanmak adına zamansal yamulmuş küre yaklaşıklık betimleyicisi önerilmektedir. Nesnelerin takibi için Kalman filtreleme ve konum ve şekil benzerliğinin aynı anda kullanıldığı çoklu nesne eşleştirme yöntemi önerilmiştir. Böylece, robot hem anlık, hem de zamansal verileri kullanarak etrafındaki nesneleri tanıyabilmekte ve ortama ait anlambilimsel harita oluşturabilmektedir. Nesne sınıflandırmasına yönelik deneylerde, robotlarda zamansal yamulmuş küre yaklaşıklık betimleyicisinin anlık oluşturulmuş betimleyicilere göre performans artışı sağladığı gözlemlenmiştir.","This thesis is concerned with scene mapping by a mobile robot using point cloud data. It is a complex process that requires the robot to segment the incoming data, represent it compactly and efficiently, and then use the resulting knowledge in its learning and decision-making. Segmentation enables the robot to determine the point cloud object candidates. The robot bases its learning and reasoning on the detected segments. Range sensors, such as LIDAR, are essential for a robot to extract environmental information. However, they generally create sparse data. For this reason, the sparse data should be considered specially. A novel approach to segmentation is proposed based on an extension of density-based clustering in the spherical coordinate system. We present the deformable sphere approximation (DSA) descriptor as a novel 3D descriptor that encodes point cloud objects. Experimental results show that our representation method is capable of classifying the objects. Finally, we consider how the robot can use all knowledge available to it. We propose an approach in which the robot also considers the knowledge accumulated through tracking the objects' temporal continuity. For this, we propose the temporal deformable sphere approximation (T-DSA) descriptor. Its construction requires the robot to track object candidates. For this, we propose a novel multi-tracking approach based on combining Kalman Filtering and multi-object matching considering position and shape similarity. We then compare the various schemes the robot can use in order to utilize the resulting knowledge. Our experimental results show that the T-DSA descriptor improves the classification performance compared to only the instantaneous DSA descriptors. As such, the robot is able to build and evolve a scene map as it is navigating in it."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Varlık ismi tanıma (VİT), doğal dil işleme (DDİ) alanınındaki önemli bir görevdir. VİT etiketleyicileri verili bir cümledeki varlıkları etiketlemek için sinir ağı tabanlı modellerin yeniden doğuşuna kadar geleneksel yapay öğrenme yöntemleri veya sınırlı durumlu dönüştürücüleri kullanmaktaydı. Dizi tabanlı modelleri veya sözcük temsillerini kullanan sinir ağları o zamana kadar elde edilmiş en iyi başarımları ilerletti. Bu yaklaşımlar sözcüklerin yüzey biçimlerindeki biçimbilimsel anlam ifade eden bilgiyi görmezden gelmiştir. Bu tezde, biçimbilimsel bilgiyi kullanan iki VİT etiketleyicisi sunulmakta ve bu tür bilginin kullanılmasının biçimbilimsel açıdan zengin dillerdeki başarıyı önemli derecede artırdığı gösterilmektedir. Bu etiketleyiciler kullanılarak Türkçe, Çekçe, Macarca, Fince ve İspanyolca VİT görevinde o zamana kadar elde edilmiş en iyi başarımlar ilerletilmiştir. Modelin çeşitli kesimlerini etkin veya devredışı kılarak yaptığımız deneylerle bu ilerlemenin biçimbilimsel bilginin modele dahil edilmesinden kaynaklandığı gösterilmiştir. Bunlara ek olarak, olası tüm biçimbilimsel çözümlemelerden doğru olanı seçme işinin her zaman elde edilmesi mümkün olmayan harici çözümleyiciler kullanmadan sinir ağının bir parçası olarak yapılabileceği gösterilmiştir. Tezin ikinci kısmında, bilinen bir öznitelik ilişkilendirme yöntemi temel alınarak herhangi bir model türüne özgü olmayan bir açıklama getirme yöntemi geliştirilmiştir. Bu yöntemin ürettiği açıklamaların ikna ediciliği ilk kısımda geliştirilen VİT etiketleyiciler kullanılarak çeşitli özgün deneylerle gösterilmiştir.","Named entity recognition (NER) is an important task in natural language processing (NLP). Until the revival of neural network based models for NLP, NER taggers employed traditional machine learning approaches or finite-state transducers to detect the entities in a given sentence. Neural models improved the state-of-the-art performance with sequence-based models and word embeddings. These approaches neglect the morphological information embedded in the surface forms of the words. In this thesis, we introduce two NER taggers that utilize such information, which we show to be significant for morphologically rich languages. Using these taggers, we improve the state-of-the-art performance levels for Turkish, Czech, Hungarian, Finnish, and Spanish. The ablation studies show that these improvements result from the inclusion of morphological information. We also show that it is possible for the neural network to also learn how to disambiguate morphological analyses, thereby, eliminating the dependence on external morphological disambiguators that are not always available. In the second part of this thesis, we propose a model agnostic approach for explaining any sequence-based NLP task by extending a well-known feature-attribution method. We assess the plausibility of the explanations for our NER tagger for Turkish and Finnish through several novel experiments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyomedikal literatürdeki hızlı artış göz önünde bulundurulduğunda, Protein-Protein Etkileşimleri ile bilgilerin el ile çıkarılması zorlu bir iştir. Bu sebeple bilimsel yayınlardan otomatik ilişki çıkarma yöntemlerinin geliştirilmesine ihtiyaç vardır. Bu çalışmada, biyomedikal metinlerden Protein-Protein Etkileşimlerini çıkarmak için iki aşamalı yeni bir sistem sunulmaktadır. İlk aşamada, cümlelerde geçen protein çiftlerinin birbirleriyle etkileşime girip girmediklerini belirlemek için BioBERT adlı transformatör tabanlı bir model kullanılmaktadır ve dolayısıyla ikili ilişki çıkarma işlemi uygulanmaktadır. İkinci aşamada ise, ilk aşamadan gelen yanlış-pozitif tahminleri ayıklamak için birbiriyle yarışan iki sinir ağından oluşan Çekişmeli Üretici Ağ modeli kullanılmaktadır. Her iki aşamanın performansı AIMed, BioInfer, HPRD50, IEPA ve LLL adlı beş Protein-Protein etkileşimi veri kümesinde ayrı ayrı değerlendirilmektedir. Ardından, sistemin başarısı bu beş veri kümesi birleştirilerek elde edilen genel bir Protein-Protein Etkileşimi veri kümesinde incelenmektedir. Son olarak sistemimiz, COVID-19 yayınlarından Konak-Patojen Etkileşimlerini çıkardığımız örnek çalışmada denenmiştir. Deneysel sonuçlar, ilk aşamamızın AIMed veri kümesinde \%79.0 F1 puanıyla önceki çalışmaları geçtiğini, diğer veri kümelerinde ise önceki çalışmalarla benzer sonuçlar elde ettiğini göstermektedir. İkinci aşama sonuçlarımız ise birleştirilmiş veri kümesi üzerinde Çekişmeli Üretici Ağ modelinin, ilk aşama sonuçlarını iyileştirdiğini göstermektedir. Örnek çalışmadan elde ettiğimiz sonuçlar ise, önerilen sistemin gerçek dünya uygulaması olarak faydalı olabileceğini ortaya koymaktadır.","Considering the rapid increase in the biomedical literature, manual extraction of information regarding Protein-Protein Interactions (PPIs) becomes an exhausting task. Therefore, there is a strong need for the development of automatic relation extraction techniques from scientific publications. In this study, we introduce a novel two-stage system to extract PPIs from biomedical text. Our approach contains two cascaded stages. In the first stage, we utilize a transformer-based model, BioBERT, to determine whether pairs of proteins appearing in a sentence interact with each other; therefore, we perform a binary relation extraction task. In the second stage, we adopt a Generative Adversarial Network (GAN) model that consists of two contesting neural networks to eliminate false-positive predictions of the first stage. We evaluate the performance of both stages separately on five benchmark PPI corpora: AIMed, BioInfer, HPRD50, IEPA, and LLL. Later on, we combine the five corpora into a single source to examine the system performance on a general PPI corpus. Finally, we apply our system to a case study for Host-Pathogen Interaction extraction from the COVID-19 literature. The experimental results show that our first stage achieves the state-of-the-art F1-score of 79.0\% on the AIMed corpus and obtains comparable results to previous studies on the other four corpora. Moreover, our second stage results reveal that the GAN model improves the first stage results when our BioBERT model is trained on the combined corpus. Our case study results demonstrate that the proposed system can be useful as a real-world application."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Radyo Frekansı ile Tanımlama (RFID), nesnelerin otomatik olarak tanımlanmasını sağlayan umut verici bir teknolojidir. Ancak, ölçeklenebilirlik gibi bazı zorlu sorunları vardır. Mevcut çözümlerin neredeyse tamamı, tek bir etiketi tanımlamak için sunucunun etiket sayısında doğrusal çalışmasını gerektirir. O($1$) veya O($\log$ n) tanımlama karmaşıklığı sağlayan bazı çalışmalar vardır. Ancak bunların çoğu, RFID etiketi bozma saldırıları da dahil olmak üzere ciddi saldırılara açıktır. Ayrıca, sadece birkaç çalışmada okuyucu tarafına yönelik saldırılar düşünülmüş. Yine de hem etiket tarafında hem de okuyucu tarafında ele geçirme saldırılara karşı direnç sağlamak için istenilen gizlilik düzeyine sahip değiller. Bu araştırmada, mevcut RFID protokollerini analiz ederek ölçeklenebilirlik ve gizlilik endişelerine neden olan açık noktaları belirlendi. Vaudenay'ın önceden tanımlanmış gizlilik modelini, okuyucu tarafı saldırılarını dikkate alarak genişletildi ve ardından arkayüzde herhangi bir arama işlemi gerektirmeyen, gizliliği koruyan bir RFID kimlik doğrulama protokolü önerildi. Sistemin sırlarını saklamak için Fiziksel klonlanamayan fonksiyonlar (PUF'ler) güvenli depolama olarak kullanılarak, etiket ve okuyucu bozma saldırılarına karşı direnç sağlar. Protokolümüz, herhangi bir koşul olmaksızın okuyucu bozma saldırıları durumunda etiket sahipleri için yıkıcı gizlilik sağlar. Ek olarak, protokolümüz okuyucuların gerekli veritabanı kayıtlarını onlara aktararak çevrimdışı çalışmasına izin verir ve çevrimdışı okuyucuların bozulması durumunda yine de yıkıcı gizlilik sağlar. Bildiğimiz kadarıyla, protokolümüz, arama özelliği olmadan bu kadar yüksek bir gizlilik seviyesi sağlayan ilk protokoldür.","Radio Frequency Identification (RFID) is a very promising technology that enables the automatic identification of objects. However, it has some challenging issues such as scalability. Almost all of the existing solutions require the back end server to work linear in the number of tags in order to identify a single tag. There are some proposals providing O($1$) or O($\log$ n) identification complexity, yet, most of them are susceptible to serious attacks including RFID tag corruption attacks. Besides, only a few of them take attacks into consideration for the reader side. Nevertheless, they do not have the desired level of privacy to provide resistance against compromising attacks on both the tag side and the reader side. In this research, we analyze the existing RFID protocols and specify the open problems that cause scalability and privacy concerns. We extend the predefined privacy model of Vaudenay by considering reader side attacks, and then propose a privacy-preserving RFID authentication protocol that does not require any search operation in the back end. It provides resistance against tag and reader corruption attacks by using Physically Unclonable Functions (PUFs) as secure storage to keep secrets of the system. Our protocol provides destructive privacy for tag holders in case of reader corruption attacks without any conditions. Additionally, our protocol allows readers to work offline by transferring the necessary database records to them and still provides destructive privacy in case of corruption of offline readers. To the best of our knowledge, it is the first protocol providing such a high privacy level without lookup property."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hareketli Bluetooth düşük-enerji (BLE) alıcı-verici takip problemini saklı Markov modeliyle modelliyoruz ve örtülü konum bilgisini ardışıl Monte Carlo ile süzgeçliyoruz. Yaklaşımımızın sağladığı yeni bakış açısı, alınan işaret şiddeti göstergelerinden oluştu-rulmuş parmak izleri için özel olarak biçilmiş bir gözlem modelidir: Wasserstein uzaklı-ğının en iyi taşıma modeliyle çözümüne dayalı bir histogram arakestirimi. Bütün sistemin takip sonuçları, en yakın komşu ve yapay sinir ağları gibi alternatif temel tahminleme yöntemleriyle karşılaştırılmaktadır. Sonuçlarımız gürültülü veriden yüksek kesinlikli tahminlemenin mümkün olduğunu göstermektedir. Başka bir yenilik, tümleşik bir durum ve parametre tahminini sağlayan üç seviyeli saklı Markov modelidir. Bir BLE vericisinin hareketi hakkında bilgimiz olmadığını varsayarak, geçiş yoğunluk fonksiyonunu normal dağılım olarak tasarlıyoruz. Dağılımın gürültü kovaryansının temelini oluşturan yayılım parametresini konumlarla beraber tahminliyoruz. Önce, bu yöntemin geçerliliğini sabit, azalan ve uyarlamalı yayılım parametresi tahminleme yaklaşımıyla gösteriyoruz. Sonrasında canlı parametre örneklemesinin gözlenen veriye uyum sağladı-ğını ve düşük hata ortalamaları ve orta değerleri ortaya koyduğunu gösteren gerçek veri sonuçlarını elde ediyoruz. Bundan önemlisi, geniş bir parametre değer kümesi için istikrarlı hata dağılımlarına ulaşıyoruz. Üçüncü olarak, kablosuz iç ortam konumlama algoritmalarının değerlendirmesi için yeni bir yordam ve bağlantılı bir veri kümesi tanıtıyoruz. Yordamımız, sinyal verilerini yüksek hassasiyetli konum verileriyle eşlemek için bir artırılmış gerçeklik temelli konumlama sistemiden faydalanmaktadır. Kameralardan sağlanan görüntü akışları bir sıra işaretçi algılama, alt küme seçimi ve süzgeçleme operasyonlarına tabi tutulmaktadır. Sonucunda kesin referans konumları olarak kullanılabilecek yüksek hassasiyetli poz verileri elde edilmektedir.","We model the tracking of a Bluetooth Low-Energy (BLE) moving transceiver as a hidden Markov model, and filter the latent positions using sequential Monte Carlo. A novel aspect of our approach is the development of an observation model, specifically tailored for received signal strength indicator fingerprints: a histogram interpolation based on the optimal transport model of Wasserstein distance. The tracking results of the entire system are compared with alternative baseline estimation methods, such as nearest neighboring fingerprints and an artificial neural network. Our results show that highly accurate estimation from noisy data is practically feasible. Another novelty is a three layered hidden Markov model with joint state and parameter estimation. Assuming that a BLE transmitter does not provide any other motion related information, the transition density is designed to be a normal distribution whose noise covariance depends on a parameter, namely the diffusion factor, that is to be estimated alongside the positions. We first show an experimental proof of concept using synthetic data by comparing three parameter estimation approaches: static, decaying and adaptive diffusion factors. We then obtain the results on real data which show that online parameter sampling adapts to the observed data and yields lower error means and medians, but more importantly steady error distributions with respect to a large range of parameters. Thirdly, we introduce a novel technique and an associated dataset for evaluation of wireless indoor positioning algorithms. The technique makes use of an augmented reality based positioning system to annotate the signal data with high precision positions. Video streams captured by the cameras are subjected to a series of marker recognition, subset selection and filtering operations to yield highly precise pose estimations, hence, they can be used as the ground truth positions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Web, herkesin erişimine açık bir platform olma vizyonu ile 1989 yılında tasarlandı. Bu vizyon, Web'in temel amaçlarından biri olan herkesin erişiminin sağlanması ile ilgilidir. Bu maksatla, esas olarak fiziksel erişim engellerine sahip insanların Web'e erişimini iyileştirebilmek adına Web Accessibility Initiative (WAI) 1997 yılında faliyete geçirildi. Bu çalışmalar her ne kadar büyük önem arz etse de erişilebilirlik konusunu bütünüyle ele almak konusunda yeterli gelmemektedir çünkü bilgiyi anlamak konusunda daha öte engeller de bulunmaktadır. Bunlar, bilgiyi anlama konusundaki yeterlilik ile ilişkili olan, kişinin dili, eğitimi, kültürü ve uzmanlığı gibi meselelere dair engellerdir. Bu çalışma bu tür engelleri aşmak için yeniden anlatım (renarration) yöntemini, önceden var olan bir web dokümanının alternatif kişilere erişmek amacıyla alternatif varyantını biçimlendirme işlemi, kullanmaktadır. Dolayısıyla, bu çalışma, yeniden anlatımları, web dökümanlarını, ve yeniden anlatımları oluşturan kişiler ve yeniden anlatımlar arasındaki sosyal etkileşimleri, ve bütün bunlar arasındaki bağlantıları, ontoloji temelli sosyal yeniden anlatım platformu oluşturabilmeyi desteklemek adına, temsil edebilen bir ontoloji öne sürmektedir. Sosyal yeniden anlatım yaklaşımının uygulanabilirliğini ve ontolojinin, kaynağın ve gizliliğin korunduğu merkezi olmayan sosyal yeniden anlatım platformunu gerçekleştirebilmeyi destekleme konusundaki, kullanılabilirliğini gösteren bir prototip, Web'in merkezsizleştirilmesi projesi olan Solid'den faydalanılarak, geliştirilmiştir.","The Web was proposed in 1989 with the vision of being an open platform that everyone can access. This vision of providing accessibility to all people is one of the primary goals of the Web. To this end, the Web Accessibility Initiative (WAI) was launched by W3C in 1997 mainly to improve the accessibility of Web for the people facing physical accessibility barriers. While such work is crucial, it falls short in delivering true accessibility, since further barriers to understanding the information exist. Such barriers are associated with the ability of a person to understand the information that reaches them, such as language, literacy, culture, and expertise. To overcome such barriers, this work utilizes the renarration method, the process of forming an alternative version for a pre-existing web document to reach alternative audience. Accordingly, this work proposes an ontology that represents renarrations, web documents, and social interactions of renarrators and renarrations, and interconnections between them to support creation of an ontology driven social renarration platform. A prototype that utilizes Solid, a web decentralization project, has been created to demonstrate the feasibility of the social renarration approach and the suitability of the ontology for supporting the realization of a decentralized social renarration platform that protects the provenance and privacy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, sinirbilimindeki temel bir soru üzerinde çalışılmıştır. Fiziksel çevremizden kaynaklanan duyusal uyaranların algıyı nasıl oluşturduğu ve değişken nöral temsillerin nasıl motor davranışa dönüştürüldüğü incelenmiştir. Bu konuda bulunan geniş literatürde, nöral aktiviteyi kullanarak uyaran parametrelerini, motor yanıtları ve davranışsal örüntüleri kestiren modeller yer almaktadır. Özellikle son yıllarda bu araştırma konusu duyu-motor protezlerinin ve beyin-bilgisayar arayüzlerinin (BBA) gelişmesiyle daha da önem kazanmıştır. Ancak, bu uygulamalarda kullanılan gerçek zamanlı algoritmaların birçok kısıtlamaları vardır. Tezin ana amacı, beyinde duyu-motor bilgi işlemeyi daha iyi anlayabilmek ve gelecekteki BBA'lar için yeni bir yöntem kazandırmak adına Bayesçi modeller geliştirmektir. Özel olarak, psikofiziksel evet/hayır algılama görevi sırasında ayık, davranış halindeki sıçanların duyu-motor korteksinden aksiyon potansiyeli verileri toplanmıştır. Genel bir Bayesçi yaklaşımla, görevle ilgili önsel dağılımlar, kanıya ait sonsal dağılımlar ve hayvanın gözlenen seçimine uyması için amaç fonksiyonu hesaplandı. Uyaran varlığı, popülasyon nöral aktivitesi ve motor yanıtları için oluşturulan rastlantı değişkenleri olasılıksal bir grafik ağında birleştirildi. Tezde ilk olarak bir beden duyusu nöroprotezi uygulaması sunulmuştur. Daha sonra, psikofiziksel görevdeki her bir deneme cevaplarını çevrimdışı tahminlemek için Bayesçi bir model kullanıldı. Elde edilen sonuçlar, psikofiziksel olarak düşük performanslı sıçanların Bayesçi yaklaşımla daha iyi modellenebileceğini göstermiştir. Ayrıca, simülasyon sonuçları diğer güdümlü öğrenme algoritmalarının (lineer diskriminant analizi, karar ağaçları vb.) tahminleriyle karşılaştırmıştır. Yine Bayesçi tahmin, düşük performanslı sıçanlar için bu algoritmalar arasında en iyilerden biri olarak bulunmuştur. Son olarak, nöral aktivite yanısıra geçmiş denemelerdeki motor cevapları da kullanan kademeli bilgi içeren Bayesçi modeller oluşturulmuştur. Bu sonuçlar ise, nöron popülasyondaki ortalama ateşleme oranlarının motor cevabı yüksek hassasiyet ve düşük yanlılık ile tahmin edebildiğini göstermiştir. Tezdeki yöntemlerin ve sonuçların, BBA kullanan rehabilitasyon uygulamalarında ve nöroprotezlere alışma sürecinde faydalı olması beklenmektedir.","In this thesis, we studied the fundamental question in neuroscience: how perception is built based on the sensory stimuli from the physical world and turned into motor actions in the face of uncertain neural representations. The vast body of literature contains models using neural activity to decode stimulus parameters, motor responses, and behavioral patterns. In particular, this line of research became more important as sensorimotor neuroprostheses and brain-computer interfaces (BCI) were made possible by recent advances in technology. The real-time algorithms used in those applications have many limitations. The main goal of the thesis is to use Bayesian models to understand sensorimotor processing and develop a novel approach for future BCIs. Specifically, spike data were collected from awake behaving rats during psychophysical yes/no detection task. Within a Bayesian framework, task-related priors, posterior beliefs, and the objective function to match the observed choice of the animal were calculated. The random variables for stimulus presentation, population neural activity, and motor responses were combined in a probabilistic graph network. First, a somatosensory neuroprosthesis application is demonstrated. Next, the Bayesian model was used to predict trial-by-trial responses offline. It was found that psychophysically low-performing rats could be modelled better with the Bayesian approach. The simulation results were compared to predictions of other supervised learning algorithms (such as linear discriminant analysis, decision trees, etc.). The Bayesian prediction was one of best among those algorithms for low-performing rats. Finally, behavioral responses from previous trials and neural activity from the current trial were included in various Bayesian models, which studied the effects of incremental information to predict the behavioral response in the current trial. The results showed that the average firing rates in a population of neurons are mostly adequate to predict lever presses in the psychophysical task with high sensitivity and low bias. This thesis provides new insights into computational modeling to understand sensorimotor processing and development of future BCIs. Bayesian modeling can be particularly useful in rehabilitation and during the training period of neuroprostheses."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"HTTP üzerinden dinamik uyarlamalı akış (HDUA), son on yılda multimedya içerik dağıtım mekanizmalarının temel direği haline geldi. Değişen ağ koşulları göz önüne alındığında, üst düzey içerik platformları yüksek deneyim kalitesi ve kesintisiz oynatma oturumları sağlamakta zorlanıyor. Video servis sağlayıcılar bu zorlukların üstesinden gelmek için, aynı içeriğin birden çok kalite düzeyini parçalı şekilde oluştururlar. Bu yöntem, video kalitesini değişen ağ koşullarına uyarlamaya olanak sağlar. Literatürde, umut verici sonuçları olan uyarlamalı video bit hızı algoritmaları yer almaktadır. Fakat, bu çözümlerin çoğu, paylaşılan darboğaz bağlantısında birden çok HDUA istemcisinin varlığını hesaba katmazken, aynı ağda birden çok HDUA oynatıcısını ele alan mevcut çalışmalar ise, parça süresinin çeşitliliğini, arka plan trafiğini ve kullanıcıların gizliliğini dikkate almamaktadır. Bu boşluklar, gerçek hayatta uygulanabilirlik endişeleri ile birlikte birden fazla istemci arasında QoE dengesi ve sürekliliği sorunlarına neden olur. İlk olarak, bu sorunları çözmek için, bir Yazılım Tanımlı Ağ (YTA) entegrasyonuna sahip, merkezi modül destekli bir mekanizma öneriyoruz. İkinci olarak, HTTP üzerinden deneyim kalitesi odaklı canlı etkinlik yayını için YTA destekli mekanizmamızdan yararlanıyoruz. Üçüncüsü, eski sistemlere herhangi bir ekstra bileşen gerektirmeden yeni bir bant genişliği ölçüm yöntemiyle, gerçek etkinlik anı ile o anın kullanıcıların ekranlarında gösterilmesi arasındaki gecikmeyi 1 saniyeye kadar azaltan bir HDUA istemcisi geliştiriyoruz. Son bir katkı olarak, canlı etkinlik yayınlarındaki deneyim kalitesini artırmak için oynatma hızını ve video kalitesini uyarlayan derin pekiştirmeli öğrenme ortamı sunuyoruz.","Dynamic Adaptive Streaming over HTTP (DASH) became the pillar of multimedia content delivery mechanisms in the last decade. Given fluctuating network conditions, over-the-top content platforms struggle with delivering a high quality of experience (QoE) and uninterrupted playback sessions. To overcome this difficulty, they keep multiple quality levels of the same content in a fragmented way. This mechanism enables players to adapt the video quality to varying network conditions by changing the video bitrate at the fragment boundaries. To maximize the QoE, adaptive bitrate algorithms have been widely studied in the literature with promising results. However, the majority of the state-of-the-art solutions do not take into account the presence of multiple DASH clients on the shared bottleneck link, whereas the existing studies considering multiple DASH players in the same network do not consider the diversity of fragment durations among different video titles, background traffic and users' privacy. Those gaps cause QoE fairness and stability problems along with feasibility concerns. First, to address these problems, we propose a centralized module-assisted adaptation mechanism with a lightweight Software-Defined Networking (SDN) integration for on-demand video streaming. Second, we leverage our proposed SDN-assisted mechanism to deliver QoE-driven low-latency live event streaming over HTTP. Third, we implement a live streaming DASH client with a novel bandwidth measurement heuristic without requiring any extra component to the legacy systems. It reduces the live delay between the actual event to users' screens down to 1s. As a final contribution, we present a deep reinforcement learning framework to adapt the playback speed and video bitrate to maximize QoE in live streaming."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım isterlerinin sınıflandırılması, sistemlerin ve isterlerin organize edilmesinde önemli bir sorundur ve büyük yazılım isterleri veri setlerinin işlenmesinde yaygın olarak kullanılır. Yazılım isterlerinin sınıflandırma probleminin temel bir örneği, işlevsel ve işlevsel olmayan (kalite) isterler arasındaki ayrımdır. Son nesil sınıflandırıcılar, metin n-gramları veya sözcük türleri n-gramları gibi geniş kelime özellikleri kümesi kullandıklarında en etkilidir. Bununla birlikte, özelliklerin sayısı arttıkça, yaklaşımı yorumlamak daha zor hale gelir çünkü gereksinimlerin anlamını yakalayamayan birçok gereksiz öz niteliğin de araştırılması gerekir. Bu çalışmada, yazılım gereksinim mühendis- liği için yorumlanabilir makine öğrenimi sınıflandırıcılarının oluşturulmasında bağlılık türleri gibi daha genel özniteliklerin kullanılmasını öneriyoruz. Sınıflandırıcıların nasıl çalıştığını grafiksel olarak yorumlayan araçlarla desteklenen bir öznitelik mühendisliği ile bir dizi dilsel öznitelik türetiyoruz. Önerilen öznitelikleri kullanan sınıflandırıcılar eğitim setine yüksek boyutlu öznitelik setlerini kullananlara göre biraz daha kötü performans gösterse de, bu yaklaşım genellikle doğrulama veri setlerinde daha iyi performans gösterir ve daha yorumlanabilirdir. Çalışmamızda sektör veri setlerini kullaniyoruz ve öznitelik setimizin daha da optimize edilip edilemeyeceğini keşfetmek için birkaç otomatik öznitelik seçim algoritması kullanarak deneysel çalışmalar gerçekleştiriyoruz. Bazı veri setlerinde etkileyici sonuçlar elde edilmesine rağmen otomatik seçim algoritmaları önemli bir gelişme göstermedi ve hatta ortalama olarak sonuçlar, dil öznitelikleri- ne dayalı seti kullanarak elde ettiğimiz sonuçlardan daha kötüydü.","Requirements classification is an important problem in organizing the systems and requirements, and it is widely used in handling large requirements data sets. A basic example of a requirements classification problem is the distinction between the functional and non-functional (quality) requirements. The state-of-the-art classifiers are most effective when they use a large set of word features such as text n-grams or part of speech n-grams. However, as the number of features increases, it becomes more difficult to interpret the approach, because many redundant features have to be explored that do not capture the meaning of the requirements. In this study, we propose the use of more general linguistic features, such as dependency types, for the construction of interpretable machine learning classifiers for requirements engineering. Through a feature engineering effort, assisted by tools that interpret graphically how classifiers work, we derive a set of linguistic features. While classifiers that use the proposed features fit the training set slightly worse than those that use high-dimensional feature sets, this approach performs generally better on validation data sets and is more interpretable. We use industry data sets, and we perform experimental runs using several automated feature selection algorithms to explore whether our feature set can be optimized further using one of the automated selection algorithms. Although in some data sets, impressive results were obtained. the automated selection algorithms did not prove a significant improvement, and even, on average, the results were worse than the results we obtained using the set based on linguistic features."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin Öğrenme (DÖ), son yıllarda birçok karmaşık problemin çözülebilme başarısının arkasındaki güçtür. DÖ sistemlerinin güvenlik açısından kritik uygulamalarda kullanılması ile, bu sistemleri düşman saldırılarına karşı sağlam kılmak önem kazanmıştır. Hasım veri üretimi, hasım eğitimin yardımıyla DÖ sistemlerini bu tür saldırılara karşı sağlamlaştırmak için etkili bir araçtır. Son çalışmalar, gradyan temelli hasım ataklara odaklanmaktadır. Başarılı bir şekilde hasım örnekleri oluşturabilmelerine rağmen, bu atakların yüksek hesaplama maliyetine sahip olmaları ve girdi oluşturma sürecinde yeterince esnek olamamaları, verimli ve esnek bir hasım atak metodolojisine olan ihtiyacı ortaya koymaktadır. Bu tezde, bu açığı kapatmaya yönelik hızlı ve özelleştirilebilir bir hasım veri üretme çerçevesi sunuyoruz. Özel kayıp fonksiyonlarına sahip evrişimli otomatik kodlayıcılar, PGD adı verilen son teknoloji saldırı yöntemine kıyasla çok daha kısa sürede, kullanıcı tarafından yapılandırılabilir veri üretimine olanak tanıyor. Geleneksel yazılım mühendisliğinden gelen şüphelilik metriğini ve bir özellik önemi metriğini, özel kayıp fonksiyonlarımıza entegre ediyoruz. Deneylerimiz gösteriyor ki, tekniğimiz hasım örnekleri PGD'den daha hızlı üretebilmektedir. Ayrıca, üretilen hasım örnekleri hasım eğitimde kullanmak, hasım saldırılara karşı kıyaslanabilir bir sağlamlık sağlamaktadır.","Deep Learning (DL) is the force behind the success of solving many complicated tasks in recent years. With the use of DL systems in safety-critical applications, it has become of great importance to make these systems robust against adversarial attacks. Adversarial data generation is an effective tool to make DL systems robust against such attacks, with the help of adversarial training. Recent studies focus gradient-based adversarial attacks. Although they can successfully generate adversarial samples, high computation cost and lack of flexibility over input generation arise the need for an efficient and flexible adversarial attack methodology. In this thesis, we present a fast and customizable adversarial data generation framework towards bridging this gap. Convolutional autoencoders with custom loss functions, enable user-configurable data generation within a much shorter time compared to the state-of-the-art attack method called PGD. We integrate suspiciousness metric from traditional software engineering and a feature importance metric into our custom loss functions. Experiments show that our technique produces adversarial samples faster than PGD and using these samples in adversarial training, allows comparable robustness against adversarial attacks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ortaöğretimde bilgi ve iletişim teknolojilerinin (BİT) kullanımı son on yılda sürekli olarak artmaktadır. Önceki araştırmalar eğitimde BİT adaptasyonu konusunu kullanıcı beyanı usulüne göre ele almışlardır. Bu araştırmanın amacı Türk lise öğrencilerinin mobil çevrimiçi ders notu (MÇDN) kullanımının teknolojiye uyum düzeylerini ölçümlemektir. Bu kapsamda, MÇDN platformu Lideno'nun aktif 8,000 öğrencisi arasından 283 lise öğrencisi çalışmaya katılmış ve çevrimiçi anketi tamamlamıştır. MÇDN platformunun teknoloji benimseme düzeyini ölçmek için Venkatesh vd. tarafından yayınlanan Birleştirilmiş Teknoloji Kabul ve Kullanım (BTKK) modelinin bir uyarlaması kullanılmıştır. Kullanıcı davranışlarını incelemek için kullanıcıların gerçek erişim sıklıkları kaydedilmiştir. Bulgular BTKK yapılarının beşinin (1) performans beklentisi, (2) çaba beklentisi, (3) sosyal etki, (4) kolaylaştırıcı etkenler ve (5) alışkanlığın MÇDN platformunu kullanma niyetini etkilediğini göstermektedir. İlaveten, MÇDN platformunu kullanma niyeti, platformun hem gerçek hem de algılanan kullanımını etkiler. Sonuçlar öğrenciler arasındaki yaş ve sınıf düzeyi farklılıklarının gerçek kullanım üzerinde bir etkisi olduğunu, ancak algılanan kullanım üzerinde önemli bir etkisi olmadığını da göstermektedir. Bu tez, Türkiye'de orta öğretimde ilk kez MÇDN kullanıcılarının beyan ettiği ve gerçekleştirdiği kullanım davranışını karşılaştırarak literatüre ve uygulamaya katkıda bulunacak ve konuyla ilgili daha fazla araştırma için bir temel oluşturulacaktır.","The use of information and communication technology (ICT) in education has been consistently increasing in the last decade. Prior research mainly examined the self-declared usage behavior of the adoption of ICT in education. The purpose of this study is to measure the technology adoption levels of mobile online class notes (MOCN) of Turkish high school students. Two hundred eighty-three high school students amongst 8,000 monthly active users of a MOCN platform, Lideno, participated in the study and completed the online survey. An adaptation of Venkatesh et al.'s Unified Theory of Acceptance and Use of Technology (UTAUT) model is used to measure the level of technology adoption of the MOCN platform. Actual access frequencies are recorded to examine user behavior. Findings show that five of the UTAUT constructs, (1) performance expectancy, (2) effort expectancy, (3) social influence, (4) facilitating conditions, and (5) habit, influence the intention to use the MOCN platform. Moreover, the intention to use the MOCN platform was found to both the platform's actual and perceived use. Results also indicate that age and grade level differences amongst students impact the actual use but have no significant effect on perceived use. The dissertation contributes to the literature and the practice by comparing the self-declared and actual use behavior of MOCN for the first time in secondary education in Turkey and provides a basis for further research on the topic."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Artan çoğul ortam içerik talebi, kablosuz ağ sistemlerini daha önce benzeri görülmemiş bir biçimde ağır bir enerji tüketim yükü altında bırakır. Ayrıca, kablosuz ağlar, kullanılan zengin çoğul ortam hizmetleri nedeniyle servis kapasitesi sınırlarına zorlanırlar. Tüm bu gerçeklere göre bu tezde içerik merkezli kablosuz ağları, dengeleme özellikli enerji ve servis kapasitesi perspektiflerinden analiz etmekte ve özellikle spektrum paylaşımlı heterojen ağ yaklaşımı üzerine ayrıntılı olarak inceleme yapmaktayız. İlk olarak uydu ağı, bilişsel radyo ve cihazdan cihaza iletim yaklaşımları ile zenginleştirilmiş bileşik bir spektrum paylaşımlı heterojen ağ modeli sağlamakta ve bu modeli tüm yönleriyle titizlikle incelemekteyiz. Çoğul ortam içeriğinin araştırmamızın yapıtaşı olması sebebiyle, yeni bir içerik modeli önermekteyiz. Ağ içi önbellekleme hem sistem kapasitesi hem de enerji tüketimi açısından içerik aktarımlarının performansını geliştirmede etkili bir yöntem olduğundan, yeni içerik modelimize dayanan önbellekleme yöntemleri önermekteyiz. Önbellek değerlendirmemizi i) işbirliği, ii) en iyileme yönlerinde genişletmekteyiz. Tüm önbellekleme çalışmalarımızı farklı sistem dinamikleri açısından derinlemesine analiz etmekte ve önerdiğimiz teknikleri alternatifleri ile karşılaştırmaktayız.","The surging multimedia content demand has put wireless network systems under heavy energy consumption burden in an unprecedented manner. Besides, wireless networks are urged to the limits of service capacity due to the adopted enriched multimedia services. According to these facts, in this thesis we analyze content-centric wireless networks from trade-off natured energy and service capacity perspectives and specifically elaborate on the spectrum sharing heterogeneous networking paradigm. First, we provide a compound spectrum sharing heterogeneous network model enriched with satellite networking, cognitive radio and device-to-device paradigms and investigate this model rigorously in all aspects. Owing to the fact that multimedia content is the building block of our research, we propose a new content model. We propose caching methods based on our new content model due to the fact that in-network caching is an instrumental method to improve the performance of content transmissions in terms of both system capacity and energy consumption. We enhance our caching evaluation in two direction i) cooperation, ii) optimization. We profoundly analyze all caching verticals with respect to different system dynamics and compare our proposals to alternative techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İlişki sınıflandırması, bilgi tabanları oluşturmak ve soru cevaplama sistemleri için faydalı bilgiler sağlamak için kullanılabilen bilgi çıkarımındaki önemli konulardan biridir. İlişki sınıflandırmasındaki mevcut yaklaşımlar, temel olarak İngilizce dilinde gerçekleşmektir ve çok sayıda işaretli eğitim verisi gerektirir. Az kaynaklı diller için bu miktarda işaretli eğitim verisi oluşturmak pratik değildir ve yüksek maliyetlidir. Bu sorunun üstesinden gelmek için iki farklı çapraz dilli ilişki sınıflandırma modeli öneriyoruz: Çok Dilli BERT'e (mBERT) dayalı temel bir model ve temel modeli önemli ölçüde iyileştiren Çok Dilli Boşlukları Eşleştirme (MTMB) adını verdiğimiz, uzak denetim kullanılarak özgün bir ön eğitim aşamasına sahip olan çok dilli bir dönüştürücü modeli. Çapraz dilli ilişki sınıflandırması için RELX adını verdiğimiz, İngilizce, Fransızca, Almanca, İspanyolca ve Türkçe dillerinden verilere sahip olan yeni bir değerlendirme veri seti sunuyoruz. Ayrıca, bu diller için Wikipedia ve Wikidata'dan uzak denetim yöntemiyle toplanan yüz binlerce cümle içeren RELX-Distant ilişki sınıflandırma veri kümesini de sağlıyoruz. Sonuç olarak çapraz dilli ilişki sınıflandırmasında MTMB'nin mBERT temel modeline göre sunulan dillerde önemli ölçüde daha iyi performans gösterdiğini ve ortalama olarak F1 puanında %2,14 iyileşme sağladığını gözlemliyoruz. Eğitim verisinin %10'unun kullanıldığı az kaynaklı ortamda da MTMB'nin etkinliğinin daha iyi olduğunu ve mBERT'e göre ortalama F1 puanını %10,58 iyileştirdiğini gözlemliyoruz.","Relation classification is one of the key topics in information extraction, which can be used to construct knowledge bases or to provide useful information for question answering. Current approaches for relation classification are mainly focused on the English language and require lots of training data with human annotations. Creating and annotating a large amount of training data for low-resource languages is impractical and expensive. To overcome this issue, we propose two cross-lingual relation classification models: a baseline model based on Multilingual BERT (mBERT) and a new multilingual pretraining setup called Matching the Multilingual Blanks (MTMB), which significantly improves the baseline with distant supervision. For evaluation, we introduce a new public benchmark dataset for cross-lingual relation classification in English, French, German, Spanish, and Turkish, called RELX. We also provide the RELX-Distant dataset, which includes hundreds of thousands of sentences with relations from Wikipedia and Wikidata collected by distant supervision for these languages. We observe that MTMB significantly outperforms the mBERT baseline in presented languages by 2.14% absolute improvement of F1-score on average. We further investigate MTMB's effectiveness in low-resource settings, and when 10% of the training data is used, 10.58% absolute improvement of F1-score on average over mBERT is observed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"This thesis is a part of documentation and revitalization efforts of the endangered Laz language, a member of South Caucasian language family mainly spoken on the northeastern coastline of Turkey. It introduces the implementation of the first automatic language analysis tool for Laz, specifically for Pazar dialect designed as a rule-based morphological analyzer developed with two-level morphology using finite-state networks. Additional language resources such as lexicon and corpus were collected for the purposes of increasing the coverage power and evaluating the performance of the analyzer. Morphologically rich languages create many challenges for natural language processing (NLP) tasks. In order to develop high or low-level NLP systems such as lemmatization, part-of-speech-tagging, spelling correction and machine translation, in any NLP pipeline, the first aim is usually to do some sort of morphological analysis on text or speech. Among different approaches to the computational study of morphology, for this study, due to the low amount of language and computational resources, I chose a rule-based approach that is highly accepted and used for formalizing morphotactics and morphophonemics, namely two-level morphology and finite-state transducers. The evaluation is based on naïve coverage of the analyzer over text data and error analysis. The results show 78.2% of coverage over the unique tokens in Pazar Laz corpus (PLC), 92.1% of coverage over Laz Treebank and 74.3% on Fındıklı Laz corpus (FLC). Error analysis on PLC results indicates that most of the word forms that could not be analyzed are due to missing word stems.","Bu tez, ağırlıklı olarak Türkiye'nin kuzeydoğu kıyı şeridinde konuşulan ve Güney Kafkas dil ailesi üyesi nesli tükenmekte bir dil olan Lazca'nın, hesaplamalı dilbilim perspektifinden belgelenmesi ve yeniden canlandırılması çalışmalarının bir parçasıdır. Sonlu durum teknolojisi ve iki seviyeli morfoloji kullanılarak Lazca'nın Pazar lehçesi üzerine geliştirilen, kural tabanlı bir morfolojik çözümleyici olarak tasarlanan ilk otomatik dil analiz aracının uygulamasını sunar. Sırasıyla kapsam gücünü artırmak ve çözümleyicinin performansını değerlendirmek amacıyla sözlük ve derlem gibi ek dil kaynakları toplanmıştır. Herhangi bir ardışık işleme yapan NLP boru hattında kök çözümleme, sözcük türü etiketleme, yazım hataları düzeltme ve makine çevirisi gibi yüksek veya düşük seviyeli NLP sistemleri geliştirmek için, ilk amaç genellikle metin veya konuşma üzerinde bir tür biçimbilim analizi yapmaktır. Biçimbilim hesaplamalı çalışmasına yönelik farklı yaklaşımlar arasında, bu çalışma için, dil ve hesaplama kaynaklarının azlığı nedeniyle, biçim bilgisi ve biçimbilimsel ses bilgisini tanımlamak için yüksek oranda kabul gören kural tabanlı bir yaklaşımla iki düzeyli biçimbilimi ve sonlu durum dönüştürücüleri kullandım. Değerlendirme, metin verileri üzerinde çözümleyicinin naïve kapsamına ve hata analizine dayanmaktadır. Sonuçlar, çözümleyicinin Pazar derleminde bulunan özgün kelimelerin %78.2'sini, Laz Treebank'in %92.1'ini ve Fındıklı lehçesi derleminin (FLC) %74.3'ü üzerinde kapsamı olduğunu göstermektedir. PLC sonuçlarındaki hata analizi, analiz edilmeyen kelime biçimlerinin çoğunun eksik kelime köklerinden kaynaklandığını göstermektedir."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Donanım olarak tasarlanmış hızlandırıcıların büyük bir kısmı, işlemciyle özel komutlar aracılığıyla iletişim kurar. Özel talimatlar standart olmadığından, her hızlandırıcı farklı bir derleyici ve kullanıcı kodu gerektirir ve bu da kullanıcı için zorlu bir süreç olabilir. Kullanıcı yükünü azaltmak amacıyla, tek komut çoklu veri (SIMD) komutlarını kullanmadan SIMD işlemcileri üreten SIMDify adlı paralel bir programlama çerçevesi sunuyoruz. SIMDify, skaler RISC-V komut kümesi mimarisi (ISA) için derlenen makine kodunu alır ve SIMD işleme bölgelerini belirlemek için simüle eder. Ardından, SIMD veri yolunda skaler RISC-V komutlarını eşzamanlı yürüten ve uygulamaya özel olan SIMD işlemcisini yapılandırır. Üretilen SIMD işlemcisi, bir ana ve birden çok köle işlem öğesinden oluşur. Köleler, SIMD işlemlerine odaklanırken, ana işlem öğesi kontrolden sorumludur. Önerilen mimari, yüksek seviyeli sentez (HLS) araçlarında tasarlanan ilk SIMD özellikli RISC-V işlemcisidir. Mimarinin mevcut tek komut tekli veri (SISD) RISC-V HLS çekirdeklerinden daha hızlı bir frekansta çalıştığı gösterilmiştir. SIMDify, kullanıcıyı esnek olmayan programlama modelleriyle özel komutları kullanmaktan kurtarır ve esnek bir çözüm sunar. İşlemci Vivado HLS 19.2'de tasarlanmış ve test edilmiştir. Zynq Zedboard alanda programlanabilir kapı dizisi (FPGA) üzerinde 78 MHz'de çalışır. Ana öğe, FPGA kaynaklarının %5 ini kullanır ve her köle kaynak kullanımını %3,5 arttırır. Test sonuçları, işlem süresinin 9 köle ile 8,5 kat ve 29 köle ile 19 kat hızlanabileceğini göstermektedir.","Most of the hardware accelerators communicate with the processor via custom instructions. Since custom instructions are not standardized, each accelerator requires a different compiler and user code, which can be a tedious process for the user. To reduce the user burden, we propose a parallel programming framework called SIMDify, which generates single-instruction-multiple-data (SIMD) processors that can achieve SIMD processing without using custom instructions. SIMDify takes an application machine code compiled for scalar RISC-V ISA and simulates it to determine the SIMD processing regions. Then, SIMDify configures and generates the application-specific SIMD processor that executes scalar RISC-V instructions concurrently on the SIMD datapath. SIMD processor consists of a single master and multiple slave processing elements (PE). Slaves focus on SIMD level tasks, whereas the master is responsible for the central control. Proposed architecture is the first SIMD capable RISC-V processor designed in HLS and can operate with a faster clock frequency than the existing SISD RISC-V HLS cores. SIMDify relieves the user from using custom instructions with rigid programming models and offers a flexible solution. The processor is designed and tested in Vivado High Level Synthesis 19.2. It operates at 78 MHz on Zynq Zedboard FPGA. Master PE uses 5% and each slave uses 3.5% of FPGA resources. Test results show that execution time can be improved by 8.5x with 9 slaves and 19x with 29 slaves."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, karmaşık ağların temsillerini öğrenme üzerine yazılmış, ilk ikisi yeni yöntemler geliştiren ve üçüncüsü bu yöntemleri bir gerçek hayat problemine uygulayan üç makale içermektedir. İlk makale, doğası itibarıyla yoğun ağların temelindeki işaretli ağ omurgalarını ayırıp çıkaran yöntemler sağlamaktadır. İstatistiksel tekniklere dayalı bir sıfır modeli kullanarak, bağ işaretlerini ve ağırlıklarını çıkaran önem ve dinçlik filtrelerini tasarlıyoruz. Dört gerçek hayat ağı üzerindeki deneysel incelemeler, önerilen filtrelerin bir ağın çok ölçekli yapısını da göz önünde bulundurarak, sıklıkla işaretli ağlarla ilişkilendirilen niteliklere sahip, anlamlı ve seyrek işaretli omurgalar elde edebildiğini göstermektedir. İkinci makale, zamana bağlı ağ temsillerini öğrenmedeki hizasızlık problemiyle ilgilenmektedir. Hizalanma ve kararlılık için ilk muntazam tanımları sağlıyoruz, bunları ölçümlemek için özgün ölçüler tasarlıyoruz ve yapay ve gerçek hayat deneyleriyle tüm bunların kullanışlılığını gösteriyoruz. Hizalanmayı sağlayarak, zamana bağlı ağ çıkarım problemlerindeki performansın önemli ölçüde artırıldığını gösteriyoruz. Üçüncü makale, ilk iki makalede geliştirilen özgün yöntemleri ve ağ analizi kaynaklarındaki diğer yöntemleri, Türkiye'deki iç göçlerin yapısını ve hareketlerini incelemek için kullanmaktadır. Özgün ve belirli içgörüler sağlamaya ek olarak, büyük ekonomik etkinliğe sahip şehirler haricinde çoğu göç bağının coğrafi olarak kısıtlandığını, göçlerin çizgileri belli güzergahlar üzerinde gerçekleştiğini, önemli göç akışları için karşıt göç akışlarının geliştiğini, göç sisteminin genel olarak kararlı olduğunu ve tüm bunların klasik göç ilkeleriyle uyumlu olduğunu gösteriyoruz.","This thesis contains three essays in learning representation of complex networks, the first two of which develop new methods and the third utilizes these methods in a real-world application. The first essay provides methods for extracting underlying signed network backbones from intrinsically dense weighted networks. Utilizing a null model based on statistical techniques, we propose significance and vigor filters that enable inferring edge signs and weights. Empirical analysis on four real-world networks reveals that the proposed filters extract meaningful and sparse signed backbones that exhibit characteristics typically associated with signed networks while respecting the multiscale nature of the network. The second essay deals with the misalignment problem in dynamic representation learning. We provide the first formal definitions of alignment and stability, propose novel metrics for measuring them, and show their suitability through a set of synthetic and real-world experiments. We show that, by ensuring alignment, the performance of dynamic network inference tasks improves by a remarkable amount. The third essay applies the novel methods developed in the first two essays as well as other methods from the network analysis literature to investigate the structure and dynamics of internal migration in Turkey. In addition to providing unique and specific insights, we find that most migration links are geographically bounded with exceptions of cities with large economic activity, migration takes place in well-defined routes, counter-streams develop for major migration streams, and the migration system is largely stable over time; which are generally in line with classical migration laws."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Öneri sistemleri, kullanıcılarının tercihlerini doğru şekilde tahminlemeyi amaçlayan etkileşimli sistemlerdir. Bu sistemlerin bir sınırlaması, zamanla tavsiyelerin kapsamının daralmasıdır. Bu ise, popüler seçeneklerin daha çok önerildiği, daha az ziyaret edilenlerin adeta sansürlendiği, böylece kullanıcıların yeni alternatifleri keşfetmesinin engellendiği bir ortam yaratır. Filtre balonu adı verilen bu durum, tercih tahminlemelerinin kullanıcı geri bildirimlerine bağlı olduğu kendi kendini güçlendiren geri bildirim döngülerinin kaçınılmaz sonucudur. Kendini güçlendiren geri bildirim döngüleri, etkileşimli öneri sistemlerinde bazı içeriklerin gereğinden fazla ve/veya az sunulmasının hem nedeni hem de sonucudur. Bu durum, yanlış kullanıcı tercihi tahminlemelerine, yani fazlaca sunulan içeriklerin fazla tercih edildiği ve aynı şekilde az sunulan içeriğin ise daha az tercih edildiği yanılgısına sebep olur. Daha hassas bir tercih tahminlemesi için kendi kendini güçlendiren geri bildirim döngülerini ortadan kaldırmaktan ise öneri sisteminin kendisi sorumludur. Bu bağlamda, kendi kendini güçlendiren geri bildirim döngülerinin olumsuz etkilerini göz önünde bulundurarak etkileşimli bir öneri sistemi için ``adil'' olma kriterlerini tanımlıyoruz. Ayrıca, akıllı bir sunum mekanizması tasarlamanın bu kriterleri sağlamak için gerekli olduğunu savunuyoruz. Bu savı kanıtlamak için, sırasıyla alternatiflere sistematik ve sınırlı maruz kalmayı açıkça içeren ve görmezden gelen iki modeli ele alıyoruz. Gerçek dünyadaki yanlılıkları simüle ederek, sistematik sunumları görmezden gelmenin teşvik edilen seçenekleri olduğundan fazla, sansürlenmiş alternatifleri ise olduğundan az tahminlediğini gösteriyoruz. En basit şekilde sınırlı maruz kalma üzerine koşullandırmanın bu yanlılıkları hafifletebileceğini gösteriyoruz.","Recommendation engines are interactive systems aiming to predict users' top preferences according to their choices. A limitation of the recommender systems is that over time the recommendations get narrower in scope. That means the popular items are favored and the less frequently visited ones are censored. Consequently, users are prevented from exploring new alternatives. The so-called filter bubble is the inevitable outcome of the self-reinforcing feedback loops where the preference estimations depend on the user choices. Self-reinforcing feedback loops are both cause and effect of over- and under-presentation of some content in interactive recommender systems. That results in inaccurate user preference estimates, namely, overestimation of over-presented content and vice versa. The burden is on the recommender system to eliminate the self-reinforcing feedback loops for a more accurate preference estimation. In this regard, we define the ``fairness'' criteria for an interactive recommender system considering the adverse impacts of these self-reinforcing feedback loops. We also claim that designing an intelligent presentation mechanism is essential to meet those criteria. To prove the claim we address two models that explicitly incorporate or ignore the systematic and limited exposure to alternatives. By simulating real-world biases, we demonstrate that ignoring systematic presentations results in overestimation of promoted options and underestimation of censored alternatives. Simply conditioning on the limited exposure is a remedy for these biases."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Blokzinciri çözümleri yaygınlaştıkça, Solidity dilinde yazılmış akıllı sözleşmelerdeki potansiyel hataların tespit edilmesi, bu çözümlerin doğru çalışabilmesi için hayati önem taşıyacaktır. Bu hataları düzgün bir şekilde tespit etmek için, geliştiricinin son teknoloji ürünü hata algılama araçlarını kullanması ve bu araçların rapor ettikleri olası hataları incelemesi gerekmektedir. Bu tezde akıllı sözleşmelerdeki olası yaygın hataları araştırdık ve olası hataları tespit edebilmek için akıllı sözleşmelerin Solidity kaynak kodunu girdi olarak alan bir statik analiz aracı SA-Solidity'i geliştirdik. SA-Solidity, Solidity kaynak kodunu ayrıştırma ağacına dönüştürür ve bu ağacı sorgulayarak hataları bulur. Ayrıca, tek bir aracın tüm hataları tespit etmek için yeterli olmadığını ve bilinen SmartCheck ve Securify araçlarının da SmartEmbed'in deneysel akıllı sözleşme kümesindeki farklı hataları tanımlayabildiğini gösterdik. Bunlardan sonra, Solidity için önceki tüm hata algılama araçları tarafından ortak olarak rapor edilen dosyalardaki hataları tahmin eden makine öğrenmesi tabanlı hata tahmin aracını (MLBP-Solidity) geliştirdik. MLBP-Solidity, büyük olasılıkla hata içeren dosyaların bir alt kümesine odaklanmasını sağlayarak geliştiricinin daha az efor sarfetmesini sağlayacaktır. Deneysel sonuçlarımız, tahmin edilen hatanın türüne bağlı olarak MLBP-Solidity'nin \%90-99 doğruluğa ulaştığını göstermektedir.","As blockchain solutions are becoming increasingly common, identifying potential bugs in smart contracts written in Solidity language is vital for these solutions to work accurately. To precisely detect these bugs, developers must use several state-of-the-art bug detection tools and examine the potential bugs the tools report. In this thesis, we investigate common errors in smart contracts and developed a static analysis tool SA-Solidity, which takes Solidity codes of smart contracts as input, to detect possible bugs. SA-Solidity converts Solidity source code into parse a tree and detects the erros by querying it. In addition, we demonstrate that one tool alone is not sufficient to detect all the bugs as SA-Solidity, and the known SmartCheck, and Securify tools identify different types of bugs in SmartEmbed's experimental set of smart contracts. Furthermore, we develop Machine Learning-based Bug Predictor for Solidity MLBP-Solidity, which predicts files that would be reported by all the previously mentioned bug detection tools and facilitates the efforts of developers by allowing them to focus on a subset of files that are most probably buggy. Our experimental results show that MLBP-Solidity achieves 90-99\% accuracy depending on the type of predicted bug."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Öneri sistemleri, kullanıcı tercihlerini baz alarak kullanıcının ilgilisini çekebilecek öneriler yapmayı amaçlayan yazılım araçlarıdır. Önerilecek öğe okuyabileceği bir makale olabilir, satın alabileceği bir ürün olabilir ya da izleyebileceği bir film olabilir; kullandığı platforma göre çeşitlilik gösterebilir. Günümüzde şirketler tarafından büyük ölçüde tercih edildiğinden, akademik olarak çeşitli çalışmalar yürütülmüş ve iyi sonuçlar alınmıştır. Derin öğrenme ağlarının öneri sistemlerinin performansını arttırdığı birçok çalışmada kanıtlanmıştır. Buna rağmen, hala performans geliştirmeleri devam etmekte; bu amaç için özellikle derin öğrenme sistemleri tercih edilmektedir. Bu çalışmada, film öneri sistemlerindeki performans sorunları, derin öğrenme yöntemleri kullanılarak ele alınmaktadır. Film açıklama metinleri bu sistemin kullandığı ana içerik olduğu için bu çalışma doğal dil işleme yöntemlerini de içermektedir. Öneri kalitesini arttırmak amacıyla iki katmanlı derin sinir ağı tabanlı bir sistem kurulmuştur. İlk katman evrişimsel sinir ağları tabanlıdır, amaç film açıklamalarından filme ait matematiksel vektörler çıkarmaktır. İkinci katman tekrarlayan yapay sinir ağı tabanlıdır; ilk katmanda çıkarılmış olan vektörleri kullanarak kullanıcıya film önermeyi amaçlamaktadır. Sistem geliştirmesi tamamlandıktan ve gerekli testler yapıldıktan sonra iki katmanlı derin sinir ağı tabanlı sistemlerin performansları makine öğrenmesi yöntemlerinden çok daha iyi sonuçlar verdiği görülmüştür. Dahası, bu çalışmanın sonuçlarına göre, öneri sistemlerinde örtük öznitelik çıkarımının öğe soğuk başlatma sorununun üstesinden gelebileceği çıkarılabilir.","Recommendation systems are software tools that seek to suggest relevant items regarding user preferences. Preference might be any; text to read, product to buy, or anything depending on the industry. Since it's vastly preferred by companies nowadays, it has been studied extensively. However, there are still open research areas based on performance improvements. In this thesis, a movie recommendation system is built using deep learning methods in order to see the effect of deep learning on the performance of recommendation systems. Moreover, this study incorporates natural language processing methods since movie description texts are the main metadata used by the system. To increase the quality of recommendation, a two-layered system is built and each layer is a deep neural network-based. The first layer acts as a complex embedding layer built on convolutional neural network architecture which takes movie descriptions as input, gives the predicted genres as output, and uses network parameters as embedding vectors of the second layer's input. This way, each movie has more complex representation on the second layer, making system's recommendations elaborated. The second layer is a recurrent neural network architecture, which takes embedding vectors of user's pre-interacted movies and user ratings to that movie as sequential input and outputs the next items to be recommended. Hence, the system can promote any movie even though it has never been interacted with a user before. After having completed the implementation and testing the system's recommendation performance, we have shown that such architecture which fuses two DNNs for both feature extraction and recommendation purposes produces better results than the baseline method."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Travma gibi çeşitli sebeplerle meydana gelebilen ampütasyon bir uzvun cerrahi olarak kesilmesi anlamına gelir. Protez, eksik olan uzvun yerine geçen bir cihazdır. Efor gerektiren görevler esnasında, ayak bileği eklemi vücut ağırlığının 10-13 katı kadar yüke maruz kalabilir. Enerji kullanımı açısından pasif olan protezler net güç çıktısı üretemedikleri için, aktif protezler efor gerektiren hareketler için gerekli hale gelmektedir. Yüzeyel elektromiyografi (EMG) nöromüsküler aktiviteyi ölçen ve invaziv olmayan bir metoddur. Bu çalışma, merdiven inme ve çıkma sırasında ayak bileği pozisyonu ve momentinin kontrolü amacılı algoritmalar için yapay sinir ağları geliştirilmesini hedefliyor. Özellik çıkarma çalışması EMG sinyallerini en iyi temsil eden özellikleri gösteriyor. Bu hedef için zaman gecikmeli yapay sinir ağı ve uzun-kısa süreli bellek yöntemleri karşılaştırıldı. Alt bacakta kullanılacak kas sayısının azaltılması protezi farklı durumlar için esnek, toplam gerekli kas sayısının azaltılması ise ekonomik hale getirir. Performans kriteri olarak tahmin edilen değerlerle gerçek değerler arasında 0.90 korelasyon katsayısı hedeflendi. Uzun-kısa süreli bellek temelli algoritmalar daha başarılı sonuçlar verdi. Merdiven inme ve çıkma görevlerinde pozisyon ve moment için sırasıyla 0.91 ve 0.93 isabetlilik elde edildi. Başarılı pozisyon tahmini için en az 3, moment tahmini için ise 2 kastan veri gerekti. Gerekli alt bacak kas sayısı pozisyon için en az 2, moment için ise 1'dir. Çalışmanın sonuçları, hedeflenen çıktılar için başarılı ve umut vadeden EMG sensör kombinasyonları olduğunu gösteriyor.","Amputation is the surgical removal of a limb due to various reasons, e.g trauma. Prosthesis is a device which is a replacement for the missing part of the limb. Ankle joint can have loads of 10-13 times of the body weight during power demanding activities. Since energetically-passive prostheses cannot generate net power output, powered ones become essential for demanding tasks. Surface electromyography (sEMG) is a non-invasive method which measures neuromuscular activity. The aim of this study was to develop artificial neural network models to predict ankle moment and position using only sEMG input for control algorithms of stair ascending and descending tasks. Time delay neural network and long short-term memory were compared for this aim. Features that represent sEMG signals better were investigated. Minimizing the number of sEMG signals from lower leg muscles can make prosthesis flexible while reducing the number of sEMG sensors required can make the prosthesis economic. Correlation of 0.90 between the predicted and actual values was set as the performance threshold. Long short-term memory based algorithms achieved significantly higher performances. 0.91 and 0.93 correlations were achieved for both motion tasks' position and moment, respectively. The minimum number of sEMG sensors was 2 for moment and 3 for position estimation. The minimum number of lower leg muscles required was 1 for moment and 2 for position estimation. The results show that there are promising EMG sensor combinations for the specified targets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"SARS-CoV-2 ile birlikte dezenfektan tüketimi artmıştır. Piyasadaki çoğu dezenfektan formülasyonunun aktif bileşenininde yaygın olarak dördüncül amonyum bileşikleri (DAB'ler) grubuna dahil olan benzalkonyum klorürler (BAK'ler) kullanılmaktadır. Laboratuvarımızdaki önceden yapılmış bir çalışmada, BAK'leri tamamen mineralize edebilen bir Pseudomonas suşu olan BIOMIG1BAC izole edilmiş ve genomu parçalı olarak dizilenmiştir. Ayrıca, BAC'lerin biyotransformasyonunda anahtar gen olan oxyBAC, genetik deneylerle tanımlanmış ve doğrulanmıştır. Bu araştırmanın temel amacı, BIOMIG1BAC suşunun ve oxyBAC geninin genomik düzeyde ekolojik öneminin belirlenmesidir. Pseudomonas sp. BIOMIG1BAC'in tüm genomu Illumina kısa dizileme ve Oxford Nanopore uzun dizileme teknolojilerini birleştiren hibrit bir yöntemle oluşturuldu. Pseudomonas sp. BIOMIG1BAC 7,675,262 bp uzunluğunda tek bir kromozomdan oluşan bir genoma sahiptir. Filogenetik analizler sonucunda BIOMIG1BAC suşunun Pseudomonas protegens alt grubunda yer alan yeni bir tür olduğu ve Pseudomonas alexanderii olarak adlandırılabileceği gösterildi. Yapılan analizler sonucunda oxyBAC da dahil olmak üzere BAK parçalamadaki anahtar genlerin transpozonlarla ilişkili olduğu görüldü. Ek olarak, oxyBAC ve beraberindeki genleri taşıyan iki transpozon motifi, diğer (DAB parçalayıcı) mikroorganizmaların oxyBAC içeren genomlarında da yer almaktadır. Bu çalışma oxyBAC'ın filogenetik olarak çeşitli bakteri gruplarında bulunduğunu ve dezenfektanların stresi altında plazmitler ve faj genomları aracılığıyla yatay olarak diğer bakterilere transfer olma potansiyeline sahip olduğunu göstermektedir.","Disinfectant consumption has increased with the pandemic of SARS-CoV-2. Benzalkonium chlorides (BACs), which are a group of quaternary ammonium compounds (QACs), are widely used as active ingredients in many of those disinfectants in the market. Previously, a strain of Pseudomonas, i.e. BIOMIG1BAC, that can completely mineralize BACs was isolated, and its draft genome was sequenced. Moreover, the oxyBAC, which is the key gene in the biotransformation of BACs, was identified and verified through genetic experiments. The main objective of this research was to understand the ecological significance of the strain BIOMIG1 and its oxyBAC gene at genomic level. The complete genome of the Pseudomonas sp. BIOMIG1BAC was obtained with a hybrid method that combines Illumina short-read sequencing and Oxford Nanopore long-read sequencing technologies. Pseudomonas sp. BIOMIG1BAC has a genome composed of a single circular chromosome with a 7,675,262 bp length. Phylogenomic analysis showed that the strain BIOMIG1BAC is a new species classified under Pseudomonas protegens subgroup, which is tentatively named as Pseudomonas alexanderii sp. nov. The key genes of the BAC biodegradation pathway, including oxyBAC, are associated with transposons therefore they can be horizontally transferred among bacteria. Two transposon motifs that carry the oxyBAC and its accompanying genes, were identified in the oxyBAC containing genomes of other (QAC degrading) microorganisms. The outcomes of this study suggest that oxyBAC is present in phylogenetically diverse group of bacteria and has a potential to horizontally transfer within bacteria via transposition to plasmids and phage genomes in communities under the stress of disinfectants."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yaşanan teknolojik gelişmeler, müşteri ihtiyaçlarındaki sürekli değişim ve iş hedeflerinden doğan baskılar bankacılık endüstrisindeki inovasyonun temel itici gücü olmaktadır. Monolitik yapıdaki eski nesil mimariler bankaların yeni nesil iş modellerini uygulamalarının önünde engel oluşturmaktadır. Bankalar rekabetçi kalabilmek için daha modüler ve genişleyebilir mimarilere göç etmek durumundadırlar. Bu tür bir göç, bankaların sahip olduğu mevcut teknik ve organizasyonel yapıya ciddi bir etki yaratmaktadır, bu sebeple böyle bir dönüşüm için uçtan uca bir göç stratejisinin oluşturulması ve planlanması kaçınılmazdır. Bu tez 2014 ve 2020 yılları arasında eski nesil sistem mimarilerinden böyle bir dönüşüm yolculuğuna çıkmış olan üç büyük perakende bankanın taşınma süreclerini değerlendirme kriterlerini, taşınacak olan uygulama portföylerini nasıl önceliklendirdiklerine yönelik gözlemlerimizi karşılaştırmalı olarak raporlamaktadır. Çalışmamızda bankaların motivasyonları, göç stratejlerini ve göç önceliklendirme metodlarını karşılaştırıyor ve bu tür büyük çaplı dönüşüm projeleri için önemli olacak unsurları tartışıyoruz. Eski nesil teknoloji mimarileri, iş operasyonlarının en öncelikli sorunları ve dönüşüm programlarının başladığı dönemlerdeki teknoloji akımları yeni nesil mimarilerin şeçimini etkilemektedir. Kurum kültürü ve mimari karar otoriteleri, çözüm mimarisi ekipleri gibi kuvvetli yönetişim yapıları uygulama göçlerinin yapılış şekillerini belirlemektedir. Uygulama taşıma planları ne şekilde yapılırsa yapılsın, değer odaklı program yönetişim yapıları en etkin önceliklendirmelerin yapılmasını sağlayan metod olarak ortaya çıkmaktadır. Dönüşüm programları uygulamaları yeni mimariye taşıdıkça, taşıma ve önceliklendirme kriterleri dinamik olarak değişmektedir. Bu kriterlerin program motivasyonları ve hedefleri ile sürekli olarak hizalanması programlar açısından önemli bir başarı kriteri olarak çıkmaktadır.","Advances in technology, changing customer requirements, and pressure from business goals are the main drivers for innovation in the banking industry. Legacy architectures with monolithic structures prevent banks from implementing new generation banking models. To stay competitive, banks migrate to modular and scalable architectures. This migration has a significant impact on banks' technical and organizational infrastructures, so it is crucial to devise an end-to-end migration strategy and plan the transformation. This thesis reports our observations on the legacy system migration of three large retail banks between 2014 and 2020, focusing on the evaluation and prioritization criteria for their application portfolio to be migrated. We compare and contrast the motivations, migration strategies, and migration prioritization methods and discuss key takeaways from these high scale migration projects. The existing legacy architecture, most urging issues of the current operations and industry trends at the time of the transformation program, define the target architecture for legacy migration. The culture and availability of strong governance structures such as architecture boards, solution architecture teams, and target architecture patterns play an essential role in how migration planning is conducted. Regardless of the planning approach selected, value-driven program management practice would provide the most optimized prioritization. A robust migration project management is required to ensure the continuity, progress, and quality of the transformation. As transformation programs migrate the applications to the new platform, migration evaluation and prioritization criteria are subject to change. Continuous alignment of these criteria with program objectives is essential to succeed in the application migration during legacy modernization programs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir sistem için çevresindeki olası eylemleri tanımlayabilmesi, başka ifadeyle sağlarlık algısı hayatta kalabilmesi açısından önemlidir. Sistemin, çevrede var olan bazı değişmeyen parametreleri üzerinde değişiklik yapmak sistemin sağlarlık algısını da değiştirmektedir. Geçilebilirlik sağlarlığı sistemin algıladığı aralık ile kendi beden algısı arasındaki ilişkiye bağlıdır. Gerçek hayatta beden algısının değişikliği tekerlekli sandalye veya uzun bir çubuk kullanımına bağlı olarak değiştirilebilmektedir. Bu tez çalışmasında ise, vücut ölçeklendirmenin geçilebilirlik ve uzanabilirlik sağlarlığı üzerindeki etkilerini anlamak için bir sanal gerçeklik ve simulasyon çalışması gerçekleştirilmiştir. Katılımcılar, gerçek omuz büyüklüklerine göre ölçeklendirilmiş farklı sanal omuz genişliklerine (dar, normal ve geniş) atanmıştır. Deneyde, bir aralıktan doğal bir şekilde çarpmadan geçerek bir masa üzerindeki hedefe sağ elleri ile ulaşmaları istenmiştir. Tüm deney durumlarında aralıktan devirmeden geçme oranları ile aralıktan geçerkenki hızlar benzer bulunmuştur. Bu sonuç, katılımcıların atanan sanal bedenlerine uyumlandığının bir göstergesi olmuştur. Ayrıca, katılımcıların normal durumlarına göre daha dar omuz atandıklarında hedefe daha yakın bir mesafede durduğu gösterilmiş, bu sonuç katılımcıların vücutlarının sanal ortamda küçüldüğünü düşündüklerine işaret etmiştir. Koşullara uyumu kontrol etmek için yapılan algısal yargı kontrol deneyi de dar sanal omuz durumundaki katılımcıların daha küçük omuz genişliğine sahip olduklarını düşünerek karar aldıklarını, geniş omuz koşulundakilerde ise bir etki olmadığını, sanal bedene uyumda bir asimetri olduğunu göstermiştir.","Perceiving affordances, the action-possibilities of a system in an environment, is a survival key for the system (Gibson, 1966). Changing invariants for the system shapes its affordance perception (Warren & Whang, 1987). Pass-through-ability of an aperture, as a perceived affordance, is determined by the fit between the apparent aspects of the environment (e.g., perceived gap) and the perceived body scale. Changing body perception in real life depends on using tools such as a wheelchair or a long stick (Higuchi, Cinelli, Greig, & Patla, 2006; Higuchi, Cinelli, & Patla, 2009). Here, in order to understand the effects of body scaling on the affordance of pass-through-ability and reachability, we conducted a virtual reality and a simulation study. Participants were assigned to different virtual shoulder widths scaled to their real size (narrow, normal and wide). In the experiment, they were asked to walk naturally to pass through an aperture without colliding and reach a target on a table. The success rate of passing through an aperture and the speed were similar in all conditions, which implied that participants adapted their virtual bodies. We also showed that participants were closer to the target when assigned narrow compared to a normal-size shoulder, suggesting that participants thought their body became smaller, so they moved closer to the target. In order to control the adaptation for conditions, we also conducted a perceptual judgement experiment. Also reflected in the perceptual judgements, participants with narrow virtual shoulders thought that they had smaller shoulder width, an effect not observed in the wide shoulder condition, which together demonstrate an asymmetry in the effects of body scaling."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yeni nesil hücresel ağlar ve geleneksel ağ servislerine yönelik girişimlerin yanı sıra, akıllı cihazlar ve yapay zekâ teknikleri ile geliştirilen özgün servislere yönelik talepte çok büyük bir artış olmaktadır. Çeşitli başarım ve fonksiyonel gereksinimleri talep eden yaygın sağlık hizmeti, çevrimiçi oyunlar, artırılmış gerçeklik, akıllı şehir ve birçok başka servis tipleri son kullanıcı cihazları tarafından üretilen veriler aracılığı ile beslenmektedir. Böylesine dinamik bir ortamda, eski ağ altyapısı ve operasyonları kullanıcıların beklentilerini ve servislerin gereksinimlerini, özellikle gerçek zamanlı etkileşim talep edenlerin, karşılamakta yetersiz kalmaktadır. Dolayısı ile, bu tezde, servis merkezli yapıyı olanaklı kılmak, operatörlerin ve son kullanıcıların beklentilerini karşılamak amacıyla çok katmanlı uç hesaplama sistemlerinde görev atanması ve ağ dilimleme problemlerinin eniyilenmesine odaklanılmıştır. Bu doğrultuda oldukça geniş bir literatür taraması yapılmış, gereksinimler belirlenmiştir ve her bir problem tanımı için bir eniyileme modeli geliştirilmiştir. Ölçeklenebilirlik sorununa değinmek ve problemlere kısa süre içerisinde kaliteli bir çözüm bulabilmek için sezgisel yöntem önerileri de sunulmuştur. Bütün bunların yanı sıra, servis merkezli yapının gerçekleştirilmesi için programlanabilir ağ paradigmalarını kullanarak kısa ve uzun vadeli olmak üzere iki farklı çözüm önerisi sunulmuştur. Yazılım-tanımlı ağ yapısı üzerine kurulan kısa vadeli çözüm önerisi gerçek veri ile desteklenmiş bir düşme riski analizi servisi ile ayrıca değerlendirilmiştir. Önerilen çözüm önerileri özgün olup, operatörlere ve servis sağlayıcılara çok katmanlı uç hesaplama sistemlerinde servis merkezli davranışın gerçekleştirilmesi ve operasyonların eniyilenmesi konusunda kapsamlı bir yol gösterici olmaktadır.","In addition to the efforts in the next-generation cellular networks and traditional network services, the demand for a novel set of services leveraged through smart devices and artificial intelligence (AI) techniques increases tremendously. Pervasive healthcare, online gaming, augmented reality, smart city and many other service types with various performance and functional requirements are supplied with data generated by end-user devices. In this highly dynamic environment, the legacy network infrastructure and operations remain incapable of satisfying the expectations of the users and requirements of the services, especially those demanding real-time interaction with ultra-low latency. Therefore, this thesis focuses on the task offloading operations in a multi-tier edge environment and network slicing optimization problems to enable service-oriented behavior and address the demands of both operators and end-users. In this direction, an extensive literature review is carried out, the requirements are determined, and we provide a formal optimization model for each problem definition. In order to address the scalability issues and finding good quality solutions in a short time, heuristic solutions are proposed. Besides efforts in optimization purposes, two different solution proposals using programmable network paradigms are provided as short-term and long-term for implementing the service-centric behavior. The short-term solution based on Software-defined Networking (SDN) is further evaluated by implementing a fall-risk assessment service with real sensory data. The proposed solutions are novel and provide comprehensive guidance for operators and service providers on implementing a service-centric behavior and optimizing the operations in multi-tier edge systems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Soyutlamalı metin özetleme, doğal dil işlemede önemli bir alandır. Dijital dünyada daha önce eşi görülmemiş bir hızla çok fazla metin materyalleri oluşturulduğundan, insanlar bu tür metinlerden yalnızca gerekli bilgileri içeren bir biçimde özet elde etmek için otomatik metin özetleme sistemlerine ihtiyaç duymaya başladılar. Derin öğrenme metotlarındaki son gelişmelerle birlikte, soyutlamalı metin özetleme araştırmacılar tarafından daha da fazla ilgi görmeye başlamıştır. Dikkat temelli diziden diziye modeller bu alana uyarlanabilmekte ve bu tip modeller oldukça başarılı sonuçlar vermektedir. Bunlarla beraber, işaretçi/üretici ve kapsam gibi birkaç ek mekanizma sıklıkla kullanılmaktadır. Bu mekanizmalar, başarılarından dolayı soyutlamalı özetleme modelleri için birer standart haline gelmiştir. Bu tezde söz konusu teknikler ile kelime bağlılık ilişkileri kullanımı bütünleştirilmiş ve modellere olan etkileri analiz edilmiştir. Bağlılık ilişkilerini entegre etmenin performansı artırdığı gösterilmiştir. Doğal dil işleme görevleri için tasarlanmış birçok yeni model, alt sözcükler kullanmakta ve oldukça başarılı sonuçlar elde etmektedir. Bu tezdeki modellerde üç farklı alt sözcük modeli kullanılarak soyutlamalı özetleme alanındaki etkileri incelenmiştir. Alt sözcük kullanımının da bu tür soyutlamalı özetleme modellere dahil edilebilecek uygun bir seçenek olduğu gösterilmiştir.","Abstractive text summarization is an important task in natural language processing. As there are too many textual materials becoming available in the digital world at an unprecedented speed, people begin to need automated text summarization systems to summarize such bulk data in a condensed form that only holds the necessary information. With recent advances in deep learning techniques, abstractive text summarization has gained even more attention. Attention-based sequence-to-sequence models are adapted for this task and achieved state-of-the-art results. On top of it, several additional mechanisms like pointer/generator and coverage were proposed and have become the standard mechanisms to be used for abstractive summarization models. Using these approaches, we integrated word dependency relations and analyzed their effects on the models. We showed that integrating dependency relations increases performance. Recent models for many natural language processing tasks use subwords and achieve state-of-the-art results. We utilized three different subword models in our models and analyze their effectiveness in the abstractive summarization task. We found that subword usage is another viable option to be included for abstractive summarization models as well."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kimyasallar ve proteinler arasındaki etkileşimlerin (CPI) bilimsel topluluklar ile paylaşılması, hastalık mekanizmalarının anlaşılmasında, ilaç keşfindeki ve ilaçların yeniden kullanılmasındaki çalışmaların kolaylaştırılmasında önemli rol oynar. CPI hakkında önemli miktarda bilgi, düzenli yapısı olmayan dokümanlarda yayınlanmaktadır. Bu tezin amacı cümlelerde verilen bilgilerden kimyasallar ve proteinler arasındaki ilişkileri çıkarmaktır. Bu amaç için, biyomedikal dokümanlardan ikili ilişki çıkarma ve çok sınıflı ilişki çıkarma olmak üzere iki göreve odanlanmaktayız. İlk görevin amacı, bir cümlenin bir çift biyokimyasal arasındaki ilişkiyi ifade edip etmediğinin belirlenmesidir. İkinci ise görev bir çift biyokimyasal arasındaki ilişkinin tipini de belirlemeyi amaçlayarak ilk görevi genişletir. İki görevde de, BioBERT ve SciBERT mimarilerinden yararlanarak Dönüstürücü tabanlı modeller geliştiririz. Ek olarak, tüm cümle tabanlı ve bağlılık ağacı tabanlı temsillerinden oluşan farklı girdi temsilleri yaklaşımlarımızın etkisini araştırıyoruz. Bizim sonuçlarımız, ChemProt test veri seti üzerinde ikili ilişki çıkarma görevinde %77.8 F1 ölçütü ve çok sınıflı ilişki çıkarma görevinde %76.1 mikro-ortalamalı F1 ölçütü elde eden tüm cümle girdi temsilimiz ile eğittiğimiz BioBERT tabanlı modelimizin her iki görevde de en iyi performansı elde ettiğini göstermektedir. İlginç bir şekilde, önemli ölçüde daha kısa olan bağlılık ağacı tabanlı girdi temsilleri, tüm cümle girdi temsiline yakın F1 ölçütü elde eder. Son olarak, KOVID-19 ile ilgili bilimsel yayınlardan protein-kimyasal etkileşimleri çıkaran bir arama motoru olan Vapur'u tanıtıyoruz. Vapur, ilişki çıkarma modellerimizin gerçek yaşamdaki biyomedikal uygulamalarda etkin bir şekilde kullanılabildiğini göstermektedir.","The sharing of chemical-protein interactions (CPI) with the scientific communities plays a crucial role in understanding the mechanisms of diseases, as well as in facilitating drug discovery and drug repurposing studies. Significant amount of knowledge on CPI is published in unstructured documents. The goal of this thesis is to extract relations between chemicals and proteins from information provided in sentences. For this purpose, we focus on two tasks: (i) binary relation extraction and (ii) multi-class relation extraction from biomedical documents. The aim of the first task is to identify whether a sentence states a relation between a pair of biochemicals or not. On the other hand, the second task extends the first one by also aiming at identifying the type of the relation between the pair of biochemicals. For both tasks, we develop transformer-based models by utilising the BioBERT and SciBERT architectures. Furthermore, we investigate the effectiveness of different input representation approaches such as sentence and dependency tree-based representations. Our results demonstrate that BioBERT based model with whole sentence input representation achieves the best performance for both tasks on the benchmark ChemProt test data set with an F1-score of 77.8% for binary relation extraction and micro-averaged F1-score of 76.1% for multiclass relation extraction. Interestingly, the significantly shorter dependency tree-based input representations achieve close F1-scores to whole sentence input representation. Finally, we introduce Vapur, which is a search engine for protein-chemical interactions extracted from COVID-19 related scientific publications. Vapur shows that our relation extraction models can be effectively used in real-world biomedical applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İlgilenilen bir proteini hedefleyen yeni moleküllerin üretilmesi, farmasötik endüstrisindeki zorlayıcı görevlerdendir. Derin üretici modeller, hedef odaklı molekül tasarımı problemine uygulanmış ve umut verici sonuçlar elde edilmiştir. Fakat, genellikle dayandıkları protein yapısı veya protein-ligand bağlılık ilgisi verilerinin miktarı bu tür modellerin başarısını sınırlamaktadır. Bununla birlikte, büyük miktarlarda etiketlenmemiş protein dizileri ve moleküller mevcuttur ve bu verileri kullanarak faydalı temsiller öğrenen modeller eğitilmiştir. Bu tezde, bu bilgiyi hedef odaklı ilaç tasarımına aktarmak için, önceden eğitilmiş modellerin ağırlıklarını, sıcak başlangıç (warm-start) stratejisi ile hedef odaklı modelleri başlatmak için kullanmayı önerdik. İki sıcak başlangıç stratejisini araştırdık: (i) başlatılan modelin hedeflenen molekül üretimi üzerinde eğitildiği bir aşamalı strateji (ii) moleküler üretim üzerinde bir ön ince ayar ve ardından hedefe özel eğitim içeren iki aşamalı strateji. Molekülleri oluşturmak için kullandığımz iki kod çözme stratejisi ışın araması (beam search) ve örneklemedir (sampling). Sonuçlar, sıcak başlangıçlı modellerin, farklı veri miktarları ve kod çözme stratejilerinde sıfırdan eğitilmiş bir modelden daha iyi performans sergilediğini göstermektedir. Sıcak başlangıç stratejileri, yaygın kullanılan karşılaştırma metrikleri açısından benzer sonuçlar elde etmektedir; bununla birlikte, bir dizi yeni protein için üretilen moleküllerin kenetlenme değerlendirmesi, bir aşamalı stratejinin iki aşamalı stratejiden daha genellenebilir olduğunu önermektedir. Ek olarak, ışın aramasının hem kenetlenme değerlendirmesinde hem de moleküllerin kalitesini değerlendiren kıyaslama ölçütlerinde örneklemeden daha iyi performans gösterdiği gözlemlenmiştir.","The generation of novel compounds targeting a protein of interest is a compelling task in the pharmaceutical industry. Deep generative models have been applied to targeted molecular design and have shown promising results. However, such models are often limited by the availability of the data they rely on such as protein structure or protein-ligand binding affinity. Notwithstanding, vast amounts of unlabeled protein sequences and chemical compounds are available and have been used to train models which learn useful representations. To transfer this knowledge to targeted drug design, we propose using warm start strategy to initialize models with those pretrained models. We investigate two warm start strategies: (i) one-stage strategy where the initialized model is trained on targeted molecule generation (ii) two stage strategy containing a pre-finetuning on molecular generation followed by target specific training. We also use two decoding strategies to generate compounds: beam search and sampling. The results show that the warm-started models perform better than a baseline model trained from scratch on different percentages of data and decoding strategies. The proposed warm starting strategies obtain similar results in terms of widely used metrics from benchmarks. However, docking evaluation of the generated compounds for a set of novel proteins suggests that the one stage strategy generalizes better than the two stage strategy. Additionally, we observe that beam search outperforms sampling in both docking evaluation and benchmark metrics assessing the quality of compounds."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşlevsel doğrulama, dijital tasarımların işlevsel doğruluğunu sağlamak için çok önemli bir süreçtir. Modern dijital tasarımların artan karmaşıklığı ile doğrulama sırasında tasarım spesifikasyonlarının hatalarının ayıklanması ve doğrulanması son derece zaman alıcı hale gelmiştir. Bildirime dayalı doğrulama, tasarım özelliklerinin hatalarının ayıklanması ve doğrulanması için harcanan zamanı azaltmanın etkili bir yoludur. Bu tezde, destekli öğrenme güdümlü girdi oluşturma algoritması ile bildirime dayalı doğrulama için bir çerçeve sunuyoruz. Girdi oluşturma algoritmamız, bildirimlerden öğrenmek ve verilen bildirimleri daha hızlı karşılayan girdiler oluşturmak için Q-Learning'i kullanır. Çerçevemizi 5 aşamalı 64-bit RISC-V çekirdeğiyle test ettik ve rastgele girdi üretimine göre önemli performans artışı sağladık.","Functional verification is necessary to ensure the functional correctness of digital designs. Debugging and validating design specifications during verification becomes extremely time-consuming with the increased complexity of modern register-transfer-level designs. Assertion-based verification is an effective way to reduce time spent on debugging and validation of design specifications. In this thesis, we present a framework for assertion-based verification with a reinforcement learning-guided input generation algorithm. Our input generation algorithm uses Q-Learning to learn from the assertions and generate inputs that satisfy the given assertions faster. We have tested our framework with a 5-stage 64-bit RISC-V core and achieved significant performance improvement over random input generation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin üretici modeller, verileri ürettiği varsayılan süreçleri öğrenmeyi amaçlar. Bu amaçla, derin üretici modeller, veriler ve verilerin düşük boyutlu gizli değişkenleri üzerindeki ortak olasılık dağılımını modeller. Sıralı veriler üzerindeki karmaşık olasılık dağılımlarını gözetimsiz biçimde öğrenmek derin üretici modeller için zorlu bir görevdir. Adi Diferansiyel Denklem Değişimsel Otokodlayıcı (ADDDO) yüksek boyutlu sıralı verilerin kompleks üretici dağılımlarını öğrenmeyi amaçlayan bir derin üretici modeldir. ADDDO modeli düşük boyutlu gizli değişkenleri ve değişkenlerin sürekli gizli dinamiklerini modellemek için sırasıyla değişimsel otokodlayıcı ve sinirsel adi diferansiyel denklem modellerini kullanır. Bu tezde, üç farklı fiziksel hareket veri setinde öğrenilen dinamik gizli temsilleri analiz ederek ADDDO modelinin sahip olduğu model varsayımının etkilerini incelenmiştir. Ardından verilerdeki farklılaşan statik özelliklerin öğrenilmesini kolaylaştırmak amacıyla bu model esnek düzenlileştirilme için yeniden formüle edilmiş ve ayrıca model mimarisi genişletilmiştir. Deneyler sonucunda ADDDO modelinin model varsayımının öğrenilen dinamik gösterimler üzerindeki etkileri ortaya çıkarılmış ve bu modelin, değişken statik özelliklere sahip dizileri modellemek için kullanıldığında yetersiz kaldığı gösterilmiştir.","Deep generative models aim to learn processes that are assumed to generate the data. To this end, deep latent variable models use probabilistic frameworks to learn a joint probability distribution over the data and its low-dimensional hidden variables. A challenging task for the deep generative models is learning complex probability distributions over sequential data in an unsupervised setting. Ordinary Differential Equation Variational Auto-Encoder (ODE2VAE) is a deep generative model that aims to learn complex generative distributions of high-dimensional sequential data. The ODE2VAE model uses variational auto-encoders (VAEs) and neural ordinary differential equations (Neural ODEs) to model low-dimensional latent representations and continuous latent dynamics of the representations, respectively. In this thesis, we aim to explore the effects of the inductive bias in the ODE2VAE model by analyzing the learned dynamic latent representations over three different physical motion datasets. Then, we re-formulate the model for flexible regularization, and we extend the model architecture to facilitate the learning of the varying static features in the sequential data. Through the experiments, we uncover the effects of the inductive bias of the ODE2VAE model over the learned dynamical representations and demonstrate the ODE2VAE model's shortcomings when it is used for modeling sequences with varying static features."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Epilepsi, dünya üzerinde en yaygın nörolojik hastalıklardan biridir ve hastaların günlük yaşamlarını yakından etkilemektedir. Epileptik nöbetlerin önceden tahmininin yapılabilmesi sağlık çalışanları ve epilepsi hastaları için ciddi önem taşımaktadır. Epilepsinin teşhisi ve izlenmesinde genellikle kafa derisi üzerine yerleştirilen elektrotlar yardımıyla beyin aktivitesinin izlenmesini sağlayan Elektroensefalografi (EEG) yöntemi kullanılmaktadır. Bu çalışmada, Boston Çocuk Hastanesinde kayıt altına alınan EEG verilerini içeren CHB-MIT verisi kullanılarak otomatik nöbet tahminlemesi yapılmıştır. Çalışma kapsamında birincil yöntem olarak bir makine öğrenmesi türü olan SVM seçilmiş ve bununla beraber üç farklı derin öğrenme yöntemi kıyaslanmıştır. Bu yöntemlerin ilki, herhangi bir öznitelik çıkarmaya ihtiyaç duymayan Evrişimli Otokodlayıcı girdili LSTM sınıflandırıcıdır. İkincisi, EEG verisinin ön işlenmesi ile spektrogramlarının elde edilip daha sonrasında Evrişimsel sinir ağı (CNN) temelli bir sınıflandırıcı ile ele alındığı yöntemdir. Denenen son metod ise, EEG verilerine kaynak yerelleştirme uygulayarak üç boyutlu kayıtlara dönüştürmek ve bunlar üzerinden CNN ile sınıflandırma gerçekleştirmektir. Kullanılan yöntemler arasında en iyi sonuç 89.06% özgüllük, 92.58% duyarlılık ve 90.41% doğruluk ile kaynak yerelleştirme bazlı CNN Sınıflandırma kullanılarak elde edilmiştir. Çalışma kapsamında ayrıca yöntemlerin çalışma süreleri kıyaslanmış ve 74.07% doğruluk ile en düşük sonucu veren SVM'in diğer yöntemlere kıyasla ciddi oranda hızlı çalıştığı görülmüştür.","Epilepsy is one of the most common neurological diseases in the world which negatively affects the daily life of a patient. Predicting epileptic seizures is of great importance for healthcare professionals and patients. The electroencephalography (EEG), which allows for registering brain activity with the help of electrodes placed on the scalp, is generally used to diagnose and monitor epilepsy. In this study, automatic seizure prediction was performed using CHB-MIT dataset which contains EEG data recorded at Boston Children's Hospital. Support Vector Machines (SVM), a common machine learning algorithm chosen as the primary method within this thesis's scope, and three different deep learning methods were compared. The first of these methods was long short term memory (LSTM) classifier with convolutional autoencoder which did not need any feature extraction. The second method used the spectrograms obtained by preprocessing the EEG data which were fed into a convolutional neural network (CNN) based classifier. The last method was based on converting the EEG data into three-dimensional images by applying source localization and performing classification with CNN. Among the methods used, the best result was obtained using source localization based CNN classification with 89.06% specificity, 92.58% sensitivity and 90.41% accuracy. Computational cost of three methods in terms of runtime efficiency were also compared, and it was observed that the SVM, which yielded the lowest classification performance with 74.07% accuracy, worked significantly faster than other methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yapay zeka alanında olan gelişmeler, hareketi destekleyici cihazlar için sonuçlar doğurmaktadır. Güçlendirilmişş ayak bileği protezleri (GABP), ampute hareketlerini desteklemeyi amaçlayan mekanizmaları kullanır. Yüzey elektromiyografisi (sEMG), algoritmaya kasların katkısına izin verir ve sensör kaynağı olarak kullanımları yenidir. Ham sEMG verilerinin işlenmesi için farklı teknikler mevcuttur, ancak bunların bir GABP kontrol algoritmasında optimal kullanımları üzerinde ayrıntılı olarak durulmamıştır. Yararlarına rağmen, sEMG verilerini normalleştirme ve kayan pencere gerçek uygulamada sorunlu olabilir. Bu tezin temel amacı, yalnızca sEMG kullanarak sağlıklı popülasyonun yukarı-adım ve aşağı-adım görevlerini başarıyla ayırt eden bir GABP için kontrol algoritmaları geliştirmek ve test etmektir. Spesifik bir amaç, sEMG verilerinin normalleştirme ve pencereleme prosedürlerinin, geliştirilen algoritmaların tahmin başarısı üzerindeki etkilerini değerlendirmekti. 50 katılımcının sEMG verilerini içeren bir veritabanı kullanıldı. (i) ANN, (ii) LSTM, (iii) LightGBM ve (iv) RF olmak üzere 4 yapay öğrenme tekniği kullanılmıştır. Performans karşılaştırılması, normalize edilmemiş ve penceresiz veri kümesi kullanan LightGBM'nin, normalleştirilmiş ve pencereli veri kümesi için olan en iyi performanstan (Doğruluk=%94.02) önemli farkı olmadığını gösterdi (Doğruluk=%92.53). Bu nedenle, GABP için normalleştirilmemiş sEMG verileri kullanılarak geliştirilen kontrol algoritmasının yukarı/aşağı adım sınıflandırma modülünde LightGBM kullanılabileceği sonucuna varılmıştır.","Rapidly increasing developments in the field of artificial intelligence yield implications for motion supportive devices. Powered ankle prostheses (PAP) employ actuation mechanisms that aim to support amputees during locomotion. Surface electromyography (sEMG) allows muscles contribution in developing such algorithms and their usage as the exclusive sensing source is novel. Different techniques of processing raw sEMG data exist, but their optimal usage in a PAP control algorithm has not been elaborated on. Despite their benefits, normalization of the raw sEMG data and usage of sliding window might be problematic for a real time application. The main aim of this thesis was to develop and test control algorithms for a PAP that successfully distinguishes step-up and step-down tasks of healthy population using exclusively sEMG. A specific aim was to assess the effects of normalization and windowing procedures of sEMG data on prediction success of the algorithms developed. An open database was used to acquire sEMG data of 50 participants. Four machine learning techniques namely, (i) ANN, (ii) LSTM, (iii) LightGBM and (iv) RF were used with windowed/non-windowed and normalized-non-normalized datasets. Comparison of their performances showed that LightGBM utilizing non-normalized and non-windowed dataset performed,(Accuracy=92.53%) not significantly different than the best performance obtained utilizing normalized and windowed dataset(Accuracy=94.02%). So, it is concluded that LightGBM can be used in step-up/down classification module of the control algorithm for PAP using non-normalized sEMG data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"5Gnin ortaya koyduğu birçok avantaj bulunuyor, ayni zamanda bu avantajlar çözülmesi gereken yeni problemleri beraberinde getiriyor. 5G'nin desteklediği temel kavramlardan biri Ağ Dilimlemedir. Dilimleme, aynı fiziksel altyapı üzerinde birden çok izole edilmiş sanal ağa sahip olmayı sağlar. Böylece, her ağ dilimi, çeşitli hizmet kalitesi (QoS) gereksinimlerine göre farklı hizmetler sağlayabilir. 5G'de, Yazılım Tanımlı Ağ İletişimi (SDN) ve Ağ Fonksiyonu Sanallaştırma (NFV), ağ dilimlemeyi desteklemek için kritik öneme sahiptir. Literatürde, ağ dilimlemenin çeşitli sorunları incelenmiştir ve odaklanan iki önemli alan, kabul kontrolü ve kaynak tahsisidir. Kaynak tahsisi çalışmalarının çoğu çekirdek şebekesi kaynakları üzerinedir, ancak ağ dilimleri için uçtan uca bir izolasyonu sürdürmek için radyo kaynak tahsisini de araştırmak önem arz etmektedir. Radyo Erişim Şebekesi (RAN) kaynak tahsisi alanında önemli katkılar olsa da, ağın verimini optimize etmek, kabul denetimi yoluyla tam olarak gerçekleştirilemez. Bu tezde, radyo ağ kaynaklarının kullanılabilirliğinde yüksek verimlilik sağlanması için ağırlıklı olarak geçişe (handover) odaklanıyoruz. Bir hücre içerisindeki kullanıcı sayısı baz istasyonu sınırına kadar arttığında, gelen tüm talepler karşılamanmayabilir ve kullanıcılar, talep ettikleri ağ dilimlerini kullanamayabilir. Bu tezde, radyo kaynaklarının kullanımını optimize etmek için bir optimizasyon problemi geliştirip inceliyoruz ve benzer sonuçlara çok daha düşük hesaplama sürelerinde ulaşmak için geçiş tabanlı bir buluşsal yöntem öneriyoruz ve simülasyon sonuçlarıyla, buluşsal yöntemimizin kısa bir zaman çerçevesi içinde optimale yakın çözümler sunabildiğini gösteriyoruz.","5G suggests many advantages but these advantages bring some problems to be solved. Network Slicing is one of the key concepts that $5G$ introduces. Slicing enables having multiple isolated virtual networks on top of the same physical infrastructure. Thus, each slice can provide different services with diverse Quality of Service (QoS) requirements. In 5G, Software Defined Networking (SDN) and Network Function Virtualization (NFV) are critical to support network slicing. In the literature, several problems of network slicing are studied. Two outstanding areas of focus are admission control and resource allocation. Most of the studies are on the Core Network resources although it is essential to investigate radio resource allocation in order to maintain an end-to-end isolation for slices. While there are considerable contributions around Radio Access Network (RAN) resource allocation, optimizing the throughput of the network is not fully achievable via admission control. In this thesis, we mainly focus on handover to maintain the usability and high utilization of the radio resources of the networks. When the number of users within one cell suddenly increases up to the limit of the base station, all of the incoming requests may not be handled and most of the users may suffer from not being able to use the offerings of the slices that they demand. We develop an optimization problem to optimize the radio resources and propose an heuristic to reach similar results by leveraging handover in considerably low computing times and with the simulation results we show that our heuristic can present solutions close to the optimal within a short time frame."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tezin amacı, IEEE 802.11ax kablosuz ağlarında, OBSS/PD mekanizmasını kullanarak uzamsal yeniden kullanma ve verimliği artırmaktır. Kablosuz ağ ortamı sınırlı sayıda kanal kullandığından, ortamda bulunan BSS'ler, birbirlerinin menziline girebilir ve iletim esnasında çarpışmalar yaşanabilir. Kablosuz ağlarda sıklıkla karşılaşılan iki spektral verimlilik problemi, ""Gizli Düğüm Sorunu"" ve ""Açık Düğüm Sorunu""'dur. Bu iki problem, kablosuz ağlarda ciddi performans düşüşüne sebep olabilmektedir. IEEE 802.11ax standardı, beraberinde verimlilik artırmaya yönelik bir çok yenilik getirmiştir. Bu yeniliklerden birisi de OBSS/PD mekanizmasıdır. OBSS/PD mekanizmasının temel amacı, BSS'ler arası çarpışmaları ve performans problemlerini en aza indirmektir. Bu tezde geliştirdiğimiz algoritma, OBSS/PD eşiğini, veri hızı ve çarpışma sayısını baz alarak dinamik bir biçimde ayarlamaktadır. Maksimum kullanılabilir veri hızı da baz alınarak, diğer BSS'ler duyulmayacak şekilde bir OBSS/PD eşiği seçilir. Bu sayede hız seçim algoritmaları, elverişli iletim gücü dolayısıyla daha yüksek hızları seçebilir. Bunun yanında, algoritma açık ve gizli düğüm sorunlarını da azaltmaktadır. Yapılan simulasyonlarda, geliştirdiğimiz algoritma Minstrel ve Thompson hız seçim algoritmaları ile birlikte ele alınıp, DSC ve RTOT eşik algoritmaları ile karşılaştırma yapılmıştır. Minstrel algoritması ile elde edilen sonuçlarda, geliştirmiş olduğumuz algoritma performans düşüşüne yol açmayıp referans algoritmalara göre stabil sonuçlar vermiştir. Tüm algoritmaların gözle görülür bir iyileştirme sağlamadığı da gözlemlenmiştir. Thompson algoritması ile elde edilen sonuçlarda ise referans algoritmalara nazaran belirgin iyileştirme gözlemlenmiş, toplam verimlilik ve stabilite artmıştır.","The aim of this thesis is to improve spatial reuse by using special mechanisms in IEEE 802.11ax wireless local area networks. If there are numbers of basic service sets (BSSs) in the same vicinity, overlapping BSSs may create interference. In this situation, BSSs cannot transmit simultaneously, because of the collisions. Moreover, there may be spectral efficiency problems like ""Hidden Node Problem"" or ""Exposed Node Problem"", that may cause significant performance degradation to the system. In IEEE 802.11ax amendment, to address these spectral efficiency problems, a couple of mechanisms are introduced. One of the spectral efficiency mechanisms that address these problems is the overlapping BSS preamble detection (OBSS/PD) mechanism. OBSS/PD is a color-based mechanism that is used to detect and prevent overlapping BSS interference efficiently. In this thesis, we propose a rate-adaptive dynamic OBSS/PD threshold algorithm that dynamically adjusts the OBSS/PD threshold with respect to the changes in the channel conditions and selected data rates. Additionally, hidden and exposed node problems due to overlapping BSS are reduced. The proposed mechanism is designed to work along with the rate selection algorithms. In this study, the scenarios are performed with Minstrel and Thompson rate selection algorithms. The performance of the proposed mechanism has been compared with the legacy carrier sensitivity threshold algorithms (DSC and RTOT). Our algorithm has shown more stable performance than the reference algorithms in the Minstrel scenario, and none of the threshold algorithms have shown a significant performance enhancement relative to the others. When the Thompson rate selection algorithm is used, our proposed algorithm has shown a better performance and stability than the legacy carrier sensitivity threshold algorithms."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok hızlı ilerleyen literatür içinden ilgili yayınlara ulaşmanın gittikçe zorlaşması biyomedikal alanı hedefleyen doğal dil işleme sistemlerine olan ilgiyi arttırmaktadır. Bu sistemlerin önemli bir kısmında yayınlarda geçen hastalık, gen ve molekül adları gibi özel isimlerin tespit edilmesi (varlık ismi tanıma) ve ilgili ontolojilerdeki kayıtlarla eşlenmesi (normalizasyon) ara adımlarına ihtiyaç duyulmaktadır. Bu iki görevin birbiriyle yakın bir ilişki içinde olması ve bu alandaki veri kümelerinin küçük olması nedeniyle bu çoklu görev öğrenmesi literatürde sıkça başvurulan bir yaklaşım olmuştur. Bunun yanı sıra doğal dil işleme alanında son yıllarda BERT gibi dönüştürücü mimarisine dayanan önceden eğitilmiş dil modelleri kullanımıyla farklı görevlerde büyük başarılar elde edilmesiyle biyomedikal alanında da bu tarz modellerden faydalanılmaya başlanmıştır. Biyomedikal metinlerin kendilerine has bir terminolojiye sahip olmaları ve bu metinlerde kısaltmalara sıkça rastlanması gibi nedenlerle bu alana özgü dil modellerinin eğitilmesine ihtiyaç duyulmuştur. Bu çalışmada farklı biyomedikal veri kümeleri üzerinde transformer tabanlı dil modelleri ile çoklu görev öğrenmesi yaklaşımının etkili bir biçimde birlikte kullanılmasına çalışılmıştır. İki görev arasında bilgi paylaşımının en iyi düzeyde gerçekleşebilmesi için iki görevde de ortak bir ağ ile elde edilen metin aralıklarının vektör gösterimleri kullanılmıştır. Umut vadeden sonuçlar elde edilmiş ve sistemin performansı sıkça kullanılan veri kümeleri üzerinde literatürdeki en başarılı sistemlerle kıyaslanmıştır.","The increasing difficulty of retrieving relevant information from rapidly growingliterature has raised the interest for natural language processing (NLP) systems in thebiomedical domain. In many of these systems, detection of named entities such asdiseases, genes, and molecules (named entity recognition) and matching them to thecorresponding entries in ontologies (normalization) are important intermediate steps.As these two tasks are related and datasets in this domain are relatively small, multi-task learning has been frequently used in the literature for this problem. Meanwhile,in recent years, the success of transformer-based pre-trained language models suchas BERT in various NLP tasks has led them to be also applied in the biomedicaldomain. The different characteristics of biomedical text such as abbreviations andspecific terminology motivated the development of new language models, which weretrained specifically for this domain using a biomedical corpus. In this study, we proposea multi-task learning approach for named entity recognition and normalization byutilizing transformer-based pre-trained language models. To enable the optimal sharingof information, both tasks are formulated with text span embeddings obtained witha common encoder network. Promising results are obtained and compared with theresults of state-of-the-art systems from the literature for commonly used named entityrecognition datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Beceri kazanımı zeki davranışın karakteristik özelliklerinden biridir ve robot öğrenmesi bu özelliği robotlara kazandırmayı amaçlar. Etkili yöntemlerden birisi becerinin basit halini örnekleyerek, gözetimli öğrenmenin bir çeşidi şeklinde, robota öğret-mek ve daha sonra robotun kendi kendine beceriyi geliştirmesini ve yeni görevlere pekiştirmeli öğrenme ile uygun hale getirmesini sağlamaktır. Biz bu tezde ilk olarak Uyarlanır Koşullu Nöral Hareket Primitifleri (ACNMP) adlı, güdümlü ve pekiştirmeli öğrenmeyi uyarlama esnasında eşzamanlı kullanarak örneklemeler ve keşif hareketlerini aynı temsil uzayına kodlayan yapıyı sunacağız. Simulasyon deneylerimiz bize (I) ACNMP'nin en gelişmiş yapılara göre en az on kat daha verimli olduğunu; (II) eş zamanlı öğrenme yönteminin örnekleme özelliklerini yeni hareketlerde koruduğunu; (III) vücut yapıları farklı robotlar arasında beceri aktarımına olanak sağladığını gösterdi. Gerçek robot deneyleri de ACNMP'nin daha yüksek boyutlu ve karmaşık gerçek dünya koşullarına uyum sağlayabildiğini gösterdi. Daha sonra güdümlü öğrenmeyi ödül bazlı uyarlama görevlerinde kullanma fikrini ilerleterek oluşturduğumuz Ödülle Koşullu Nö-ral Hareket Primitifleri (RC-NMP) adlı ikinci yapıyı sunacağız. Bu yapı ödülleri girdi olarak alarak, istenen ödülü veren hareket güzergahları oluşturabilmektedir. RC-NMP varyasyon çıkarımı yöntemiyle olasılıksal bir temsil uzayı oluşturup, bu uzaydan çeşitli hareket güzergahları çekerek bir populasyon oluşturmaktadır. Son olarak bu populasyonun çeşitliliği seyrek ödüllü, birden fazla çözümlü veya lokal çözümlere sahip ortamlarla başa çıkmak için evrimsel stratejilerden krosover ve mutasyon yöntemleriyle arttırılmaktadır. Simulasyon ve gerçek dünya deneylerimiz RC-NMP'nin ACNMP ve diğer iki robotik pekiştirmeli öğrenme yöntemlerine göre daha istikrarlı ve verimli olduğunu gösterdi.","Skill acquisition is a character trait of intelligent behavior, which Robot Learning aims to give to robots. An effective approach is to teach an initial version of the skill by demonstrating as a form of Supervised Learning (SL), called Learning from Demonstrations (LfD), then let the robot improve it and adapt to novel tasks via Reinforcement Learning (RL). In this thesis, we first propose a novel LfD+RL framework, Adaptive Conditional Neural Movement Primitives (ACNMP), that simultaneously utilizes LfD and RL together during adaptation and makes demonstrations and RL guided trajectories share the same latent representation space. We show through simulation experiments that (i) ACNMP successfully adapts the skill using order of magnitude fewer trajectory samples than baselines; (ii) its simultaneous training method preserves the demonstration characteristics; (iii) ACNMP enables skill transfer between robots with different morphologies. Our real-world experiments verify the suitability of ACNMP in real-world applications where non-linearity and the number of dimensions increases. Next, we extend the idea of using SL in reward-based skill learning tasks and propose our second framework called Reward Conditioned Neural Movement Primitives (RC-NMP), where learning is done using only SL. RC-NMP takes rewards as input, generates trajectories conditioned on desired rewards. The model uses variational inference to create a stochastic latent representation space from where varying trajectories are sampled to create a trajectory population. Finally, the diversity of the population is increased using crossover and mutation operations from Evolutionary Strategies to handle environments with sparse rewards, multiple solutions, or local minima. Our simulation and real-world experiments show that RC-NMP is more stable and efficient than ACNMP and two other robotic RL algorithms."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bipolar bozukluk, depresiften manik hale varan bir erimde değişimlere neden olan bir akıl sağlığı bozukluğudur. Bipolar bozukluğun teşhisi genellikle hasta görüşmeleri ve hastaların bakıcılarından alınan raporlara göre yapılır. Hastalığın tanısı, uzmanların deneyimine bağlıdır ve hastalığın diğer ruhsal bozukluklarla karıştırılması mümkündür. Bipolar bozukluğun teşhisinde otomatik süreçler kullanılması, sayısal göstergeler sağla- maya yardımcı olabilir ve hastaların daha uzun süreler için daha kolay gözlemlenmesini sağlar. Öte yandan, uzaktan tedavi ve teşhis ihtiyacı COVID-19 salgını sırasında özellikle önemli hale gelmiştir. Bu tezde, hastanın akustik, dilbilimsel ve görsel modalitelerde kayıtlarına dayanan çokkipli bir karar sistemi oluşturduk. Sistem, Bipolar Disorder veri seti üzerinde eğitilmiştir. Tekkipli ve çokkipli sistemlerin kapsamlı analizinin yanı sıra çeşitli füzyon teknikleri de incelenmiştir. Tüm hasta seanslarını tekkipli özellikleri kullanarak işlemenin yanı sıra, kliplerin görev düzeyindeki performansları da incelenmiştir. Çokkipli bir füzyon sisteminde akustik, dilbilimsel ve görsel özellikleri kullanarak, \%64.8 ağırlıksız ortalama geri çağırma puanı elde ettik, ve bu sonuç, şimdiye kadar Bipolar Disorder veri setinin test kümesinde elde edilen en yüksek skordur.","Bipolar disorder is a mental health disorder that causes mood swings that range from depression to mania. Diagnosis of bipolar disorder is usually done based on patient interviews, and reports obtained from the caregivers of the patients. Subsequently, the diagnosis depends on the experience of the expert, and it is possible to have confusions of the disorder with other mental disorders. Automated processes in the diagnosis of bipolar disorder can help providing quantitative indicators, and allow easier observations of the patients for longer periods. Furthermore, the need for remote treatment and diagnosis became especially important during the COVID-19 pandemic. In this thesis, we create a multimodal decision system based on recordings of the patient in acoustic, linguistic, and visual modalities. The system is trained on the Bipolar Disorder corpus. Comprehensive analysis of unimodal and multimodal systems, as well as various fusion techniques are performed. Besides processing entire patient sessions using unimodal features, a task-level investigation of the clips is studied. Using acoustic, linguistic, and visual features in a multimodal fusion system, we achieved a 64.8\% unweighted average recall score, which improves the state-of-the-art performance achieved on this dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin öğrenme teknikleri endoskopi vidyolarında yoğun topografi yeniden canlandırma ve lokasyon tahmini methodları için ümit vaad etmektedir. Ancak, şuan anonim veri kümeleri efektif sayısal kıyaslamayı desteklememektedir. Bu tezde, altı domuz içorganı ile eş güdümlü konumlandırma ve haritalandırma algoritmaları geliştirmede kullanılabilecek 3D nokta bulutu datası, kapsül ve standart endoskopi kayıtları oluşturuldu. Ayrıca, Unity ortamında sentetik olarak üretilmiş ve standart klinik kullanımdaki endoskop ile fantom kolondan toplanan bilgisayarlı tomografi taramasını kesin referans olarak içeren veri eklenerek kapsamlı bir endoskopi dataset oluşturulmuştur. Buna ek olarak, Endo-SfMLearner, konumsal dikkat modulü ile derin kalıntı ağlarını kombinleyen güdümsüz monokülar derinlik ve pozisyon tahmini methodu önerilmiştir. Parlaklık farkındalıklı fotometrik yitim fonksiyonu sayesinde endoskopik vidyolarda sıkça görülen kamera kareleri arası hızlı ışık değişimlerine karşı dayanıklılık artırılmıştır. EndoSLAM veri kümesi kullanımı, Endo-SfMLearner algoritmasının en yaygın kullanılan methodlarla; SC-SfMLearner, Monodepth2 ve SfMLearner ile geniş kıyaslaması ile örneklenmiştir.","Deep learning techniques hold promise to develop dense topography reconstruction and pose estimation methods for endoscopic videos. However, currently available datasets do not support effective quantitative benchmarking. In this thesis, we introduce a comprehensive endoscopic simultaneous localization and mapping (SLAM) dataset consisting of 3D point cloud data for six porcine organs, capsule and standard endoscopy recordings, synthetically generated data as well as clinically in use conventional endoscope recording of the phantom colon with computed tomography scan ground truth. To verify the applicability of this data for use with real clinical systems, we recorded a video sequence with a state-of-the-art colonoscope from a full representation silicon colon phantom. Additionally, we propound Endo-SfMLearner, an unsupervised monocular depth and pose estimation method that combines residual networks with a spatial attention module in order to dictate the network to focus on distinguishable and highly textured tissue regions. The proposed approach makes use of a brightness-aware photometric loss to improve the robustness under fast frame-to-frame illumination changes that are commonly seen in endoscopic videos. To exemplify the use-case of the EndoSLAM dataset, the performance of Endo-SfMLearner is extensively compared with the state-of-the-art: SC-SfMLearner, Monodepth2, and SfMLearner."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geleneksel iş yapma biçimleri, nesnelerin İnterneti, blok zincir, veri analizi, yapay zeka, robotik, eklemeli imalat gibi yeni dijital teknolojilerin ortaya çıkmasıyla önemli ölçüde değişmeye başladı. Firmalar dijital teknolojilerin avantajlarını kullanarak rekabetçi kalmaya devam edebilmektedir. Yeni koronavirus pandemisinin (COVID-19) tüm dünyaya yayılması, dijital inovasyonları mevcut iş modellerine entegre etme yeteneğinin, kuruluşların ayakta kalabilmeleri için hayati önem taşıdığının daha iyi anlaşılmasına neden olmuştur. Bu çalışmada, iş modelinin dijital inovasyon odaklı olacak şekilde yenilenmesine yönelik bir yöntem geliştirilmiş ve dijital inovasyon stratejilerinin kurumsal sürdürebilirlik üzerindeki etkilerini incelemek için iş modelinin yenilenmesi sürecinde de kullanılabilecek dinamik bir iş modeli önerilmiştir. Bu amaç için, mevcut iş modeli inovasyonu ve sistem dinamik literatürü incelenmiş ve bu bilgileri tamamlamak ve doğrulamak için yarı yapılandırılmış görüşmelerle 44 yöneticiden ampirik veriler toplanmıştır. Ayrıca, bu çalışmada önerilen dijital inovasyon odaklı iş modeli yenileme yöntemi gerçek bir vakaya uygulanmıştır. Bu çalışma iş modeli inovasyonu ve sistem dinamik literatürünü genişletmeyi amaçlamaktadır. Çalışma, strateji analistleri ve yöneticilere potansiyel dijital inovasyonların mevcut iş modelleri üzerindeki etkilerini analiz etme, en etkili dijital inovasyon stratejilerini keşfetme ve iş modellerini bu stratejilere göre yenileme imkanı sağlayabilir. Çalışma, kurumların rakiplerine karşı rekabet üstünlüğü elde etmesine ve teknolojik gelişmeler ışığında işlerini sürdürebilmesine yardımcı olabilir.","The traditional ways of doing business have been changed by digital innovations such as the Internet of things, blockchain, data analytics, artificial intelligence, robots, additive manufacturing, etc. Firms can stay competitive using the benefits of digital technologies. The spread of the coronavirus disease in 2019 (COVID-19) all over the world has created a better understanding of the importance of organizations' ability to keep up with digital innovations. In this study, a method for digital innovations-driven business model regeneration is developed and a dynamic business model, which can also be used in the business model regeneration process, to examine the effects of digital innovation strategies on the corporate sustainability is proposed. For this purpose, the existing literature on the business model innovation and system dynamic are examined, and the empirical data are collected from 44 managers using semi-structured interviews to complement gaps in the literature. Moreover, the digital innovations-driven business model regeneration method, which is proposed in this study, is applied to a real case. This study extends the literature on the business model innovation and the dynamic business model. The study can provide strategy analysts and managers with an opportunity to analyze the effects of potential digital innovation strategies on their current business models and to explore the most effective digital innovation strategies in order to regenerate their business model to gain a competitive advantage over their competitors or to sustain their business in light of technological developments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, derin bir sinir mimarisi olan Koşullu Nöral Süreçler (CNP'ler) üzerine inşa edilmiş bir robotik hareket öğrenme ve üretim sistemi olan Koşullu Nöral Hareket İlkelleri (CNMP) adında yeni bir öğrenim çerçevesi sunmaktadır. CNMP'ler, ön bilgileri, gözlemleri örnekleyerek doğrudan eğitim verilerinden çıkarır ve diğer hedef noktalara göre koşullu bir dağılımı tahmin etmek için kullanır. CNMP'ler spesifik olarak harici parametreler ve hedeflerle karmaşık zamansal çok modlu sensörimotor ilişkilerini öğrenir; eklem veya görev alanında hareket yörüngeleri üretir; ve bu yörüngeleri üst düzey bir geri besleme kontrol döngüsü ile hayata geçirir. Simülasyonlar ve gerçek robot deneyleri sayesinde, CNMP'lerin düşük boyutlu parametre uzayları ve karmaşık hareket yörüngeleri arasındaki doğrusal olmayan ilişkileri birkaç gösteriden öğrenebildikleri; ve ayrıca çok sayıda gösterim kullanarak yüksek boyutlu sensörimotor uzaylar ve karmaşık hareketler arasındaki ilişkileri modelleyebildikleri gözlenmiştir. Deneyler ayrıca görev parametrelerinin bile açıkça sağlanmadığı zaman, robotun öğrenilen sensorimotor temsillerini hareket yörüngeleriyle ilişkilendirerek öğrenebileceğini göstermiştir. Örneğin deneylerden birinde robot, propriyosepsiyonu ve kuvvet ölçümlerini içeren sensorimotor alanından yararlanarak nesne ağırlıklarının ve şekillerinin harekete etkisini öğrendi ve bu faktörlerden biri harici müdahale ile değiştirildiğinde hareket yörüngesini anında değiştirmeyi başarmıştır.","This thesis proposes a new framework, namely Conditional Neural Movement Primitives (CNMPs) that is learning from demonstration framework designed as a robotic movement learning and generation system built on top of a recent deep neural architecture, Conditional Neural Processes (CNPs). CNMPs extract the prior knowledge directly from the training data by sampling observations from it, and uses it to predict a conditional distribution over any other target points. CNMPs specifically learns complex temporal multi-modal sensorimotor relations with external parameters and goals; produces movement trajectories in joint or task space; and executes these trajectories through a high-level feedback control loop. Through simulations and real robot experiments, we showed that CNMPs can learn the non-linear relations between low-dimensional parameter spaces and complex movement trajectories from few demonstrations; and they can also model the associations between high-dimensional sensorimotor spaces and complex motions using large number of demonstrations. The experiments further showed that even the task parameters were not explicitly provided, the robot could learn their influence by associating the learned sensorimotor representations with the movement trajectories. The robot, for example, learned the influence of object weights and shapes through exploiting its sensorimotor space that includes proprioception and force measurements; and be able to change the movement trajectory on the fly when one of these factors were changed through external intervention."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Birden fazla tarafın merkezi bir varlık olmadan ortak bir anahtar üzerinde anlaştığı durumlarda, grup anahtar anlaşması protokolleri çok önemlidir. Bu protokollerin merkezi bir sisteme ihtiyaç duymama özelliği, katılımcıların gruptaki diğer katılımcılarla iletişim kurması ve doğrulaması gereken yerlerde performans sorunlarına neden olur. Bu sorunun üstesinden gelebilmek için, bir block zinciri platformu olan Hyperledger Fabric çözümünü kullanarak grup anahtar anlaşması protokollerine yeni bir yaklaşım öneriyoruz. Bu amaçla, çalışmamızda grup anahtar anlaşması katılımcılarının iletişim ve doğrulama yükünü blok zincir ağına taşıyoruz. Performans analizimize göre, limitli bilgi işlem kaynaklarına sahip katılımcılar protokolümüzü verimli bir şekilde kullanabilirler. Ayrıca, katılımcıların gizli parametreleri, blokzincir ağı üzerinde oluşturmuş olduğumuz birbirinden ayrık katılımcılar arasında dağıtılmaktadır. Böylece, ağ üzerindeki katılımcıların grup anahtarlarını üretmesinin önüne geçmekteyiz. Ek olarak, önerdiğimiz protokolün literatürde sunulan diğer protokoller ile aynı güvenlik özelliklerini sağladığını çalışmamızda gösterdik.","Group key agreement protocols are crucial in the case of multiple parties agreeing on a common key without a centralized entity. However, the decentralized characteristic of these protocols causes performance challenges where parties need to communicate and verify other participants in the group. To overcome this issue, we propose a new approach to the group key agreement protocols by utilizing Hyperledger Fabric framework as a blockchain platform. To this end, we migrate the communication and verification overhead of the group key agreement participants to the blockchain network in our developed scheme. This paradigm allows a flexible group key agreement protocol that considers resource-constrained entities and trade-offs regarding distributed computation. According to our performance analysis, participants with low computing resources can efficiently utilize our protocol. In addition, the secret parameters of the participants are distributed among the isolated participants that constitute the blockchain network. Thus, the only way for the network participants to compute group keys is to collude maliciously. Furthermore, we have demonstrated that our protocol has the same security features as other comparable protocols in the literature."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Büyük ölçekli sürekli-zamanlı ayrık olay akışları deprembilim, sinirbilim, finans, davranış bilimi ve birçok diğer bilim ve mühendislik disiplininde sıkça odak konusudur. Bu çalışmada, bu tür verilerden ölçeklenebilir bir şekilde-yüksek sayıda olay verisi ve olay türü altında-öğrenme sağlayacak yeni bir dizi model ve algoritma incelenmektedir. Öncelikle yüksek-boyutlu çok-değişkenli Hawkes sürecinde düşük-ranklı parametre kestirimi için iki algoritma önerilmiştir. İlk olarak, negatif olmayan matris ayrışımı ile yeni bir bağlantı üzerine kurulu bir rassal eğim iniş algoritması verilmiştir. İkinci olarak, moment-tabanlı bir yaklaşımla kestirim probleminin tek bir düşük ranklı ayrışıma indirgenebileceği gösterilmektedir. İki yaklaşımda da verinin birkaç kez taranması yeterlidir, yaygınca bilinen matris ayrışımları alt yordam olarak kullanılmaktadır, ve hızlı ve yüksek başarımlı parametre kestirimi sağlanmaktadır. Ayrıca, öz-uyarım ve türler arası uyarım davranışlarını farklı zaman ölçeklerinde tarif eden, global-yerel zamansal nokta süreçleri (ZNS) adıyla yeni bir ZNS sınıfı tanımlanmıştır. Bu sınıfın bir örneği, FastPoint, türler arası uyarım örüntülerini bir derin özyineli sinirsel ağ ile kestirerek eşdeğerlerinden yüzlerce kat daha hızlı öğrenme sağlamaktadır. Global-yerel ZNS modelleri, sıralı Monte Karlo yöntemleri ile çok daha hızlı örnek çekilmesini sağlamakta ve bilinen nokta süreci benzetimi yöntemlerinin tümünden daha verimli sonuç üretmektedir. Son olarak, ZNS modellerinin uygulama alanları, seyrek talep tahmini problemine yenileme süreçleri ve derin öğrenme yöntemlerinin uygulanmasıyla genişletilmiştir. Çalışmamız, yüksek boyutlu ZNS modellerinin yaygın kullanımının önündeki iki büyük engeli-öğrenme ve çıkarımı ölçeklemenin zorluğunu-gidermeyi amaçlamaktadır.","Large sets of continuous-time discrete event streams are often in the focus of seismology, neuroscience, finance, behavioral science among other scientific and engineering disciplines. In this work, we explore a set of novel models and algorithms to learn from such data at scale, in the presence of a large number of events and event types. First, we develop two algorithms for estimating high-dimensional multivariate Hawkes processes with a low-rank parameterization. The first approach leverages a novel connection to nonnegative matrix factorization, which we use to propose a stochastic gradient descent algorithm. We then demonstrate, via a moment-based approach, that we can reduce the parameter estimation problem to a single low-rank approximation. Notably, both approaches require only a few scans of the data, feature well-known matrix decompositions as subroutines, and yield fast parameter estimation. We also propose global-local temporal point processes (TPP), multidimensional TPP models that model self- and mutual-excitation patterns at different scales of time. One such model, FastPoint, relies on deep recurrent neural networks to approximate the mutual excitation pattern, and results in several orders of magnitude faster learning. Global-local TPPs also allow for substantially faster sequential Monte Carlo sampling, greatly accelerating the current state of the art in simulating temporal point patterns. Finally, we propose a novel application area for TPPs, applying ideas from renewal processes and deep learning to intermittent demand forecasting. Our contributions aim to remove both of the main challenges---scalable learning and inference---facing the adoption of high-dimensional TPP models."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılı basın ve sosyal medya gibi birçok farklı mecrada önyargılı ve ayrımcı bir dilin kullanıldığı ve yaygınlaştığı görülmektedir. Demokrasi ve insan hakları değerlerine karşı tehdit oluşturan ayrımcı dil ve onun daha saldırgan ve aşağılayıcı, açıkça hedef gösterici şekliyle nefret söylemi acilen çözülmesi gereken küresel bir sorun teşkil etmektedir. Biz de nefret söylemiyle mücadelede önemli olan nefret söylemi tespiti için bir model geliştirdik. Bu amaçla, Hrant Dink Vakfı'nın sistematik bir şekilde nefret söylemi bağlamında annotate ettiği yazılı basın haberlerini PRNet medya takip şirketi web sitesinden çekerek bir dataset oluşturduk. Bildiğimiz kadarıyla, bu çalışmayla, etiketlenmiş bir dataset üzerinde çalışan Türkçe için geliştirilmiş ilk model üretilir. Özellikle yazılı basın haberlerindeki nefret söyleminin büyük kısmının bağlam ve imala-ra dayanması değişen söylemsel ipuçlarını tespit edebilen ve bu söylemlerin etrafında oluşan bağlamı anlayabilen bir sistem gerektirir. Biz de metnin hiyerarşik yapısını kullanarak ifadelerin değişen anlamlarını yakalamayı hedefleyen Hiyerarşik İlgi Ağları (HİA) modelini farklı kelime temsilleriyle inceledik. Modelimizi metin işlemede önemli sonuçlar veren Konvolüsyonel Sinir Ağları ve makine öğrenmesi modelleriyle kıyaslaya-rak probleme uygunluğunu tespit ettik. Çalışmamızı geliştirmek için eleştirel söylem analizi tekniklerini temel alarak probleme yönelik dilbilimsel özellikler geliştirdik. HİA modelini bu özelliklerle birlikte zenginleştirdik. Sonuçlarımız 'diğerleri dili' kullanımına işaret eden özellik kümesiyle performansın geliştiğini gösterir. Türkçe dili için oluşturu-lan bu özellik kümelerinin nefret söyleminin nicel analizinde yeni çalışmaları teşvik edeceğine inanıyoruz.","It is well known that prejudiced and discriminatory language is being widely used and spread through several channels such as printed or social media. The discriminatory language, in particular hate speech as its more aggressive, degrading and openly targeting form, which poses a threat to the values of democracy and human rights is a global problem that needs an immediate solution. Since we find the detection of hate speech important in the fight against hate speech, we have developed a model to detect it. For this purpose, we created a dataset by retrieving printed media news that the Hrant Dink Foundation systematically annotated in the context of hate speech from the website of the PRNet media monitoring company. To the best of our knowledge, with this study, the first model developed for Turkish language that runs on a labeled dataset is produced. In particular, the fact that most of the hate speech in printed media is based on context and implications requires a system that can detect changing discursive cues and understand the context around these discourses. With different word representations, we have examined the Hierarchical Attention Network (HAN) model, which aims to capture the changing meanings of expressions by using the hierarchical structure of the text. We studied the compatibility of our model with the problem by comparing it with Convolution Neural Network (CNN), which provided important results in text processing, and with machine learning models. In order to improve our study, we developed linguistic features for the problem based on critical discourse analysis techniques. We enhanced the HAN model using these features. Our results show that performance increases with a set of features that point out the use of 'othering language'. We believe that these feature sets created for the Turkish language will encourage new studies in the quantitative analysis of hate speech."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İlaç keşfi, yeni ilaç tasarlama ve geliştirme sürecidir ancak bu alanda yapılan araştırmalar maliyetlidir ve uzun zaman almaktadır. Piyasada ilaç benzeri bir çok molekül önerilmiş olmasına rağmen, onaylanan ve piyasaya sürülen ilaçların sayısı çok düşüktür, çünkü ilaç aday moleküllerinin çoğu düşük farmakokinetik özelliklere sahiptir. Bu nedenle, ilaç benzeri moleküllerin Emilim, Dağılım, Metabolizma, Boşaltım, Zehirlilik özelliklerinin erken değerlendirilmesi, maliyetli ve başarısız çalışmalardan kaçınılabilinmesi açısından ilaç endüstrisi için oldukça önemlidir. Amacımız, ilaç aday moleküllerinin ilaç olabilme özelliklerini öngören bir yaklaşım ortaya koymak ve ADMET özellikleri ile moleküler tanımlayıcılar arasındaki ilişkileri belirtmektir.\par Bu tez çalışmasında, k en yakın komşu, destek vektör makineleri ve rastgele orman olmak üzere 3 farklı makine öğrenme algoritması kullanarak, moleküllerin ilaç olabilme özelliklerini tahmin etmek için 4 farklı molekül temsilini, 9 ADMET özelliği veri kümesi üzerinde inceleyip karşılaştırıyoruz. Tüm moleküler gösterimler arasında, morgan parmak izinin doğruluk ve F-ölçümü açısından daha iyi performans gösterdiğine, ancak parametre ayarlama ve algoritma eğitim süresinin parmak izi gösterimleri ile daha uzun olduğu sonucuna vardık. Makine öğrenme algoritmaları söz konusu olduğunda, morgan parmak izi kullanılan DVMS, daha yüksek doğruluk ve F-ölçümü göstermektedir. Moleküler tanımlayıcılardan oluşan vektör temsili ile RF sınıflandırıcısını kullanarak her ADMET özelliği için en etkili moleküler tanımlayıcıyı değerlendiriyoruz. Bazı veri kümeleri için, morgan parmak izi temsiline en çok katkıda bulunan tanımlayıcıyı ekleyerek yaptığımız deneylerde değerlendirme metriklerinde artış gözlemekteyiz.","Drug discovery is the process of designing and developing new medicine. The research and clinical experiments for new drug proposals are costly and take a long time. Although there has been proposed a lot of drug-like molecules, the number of drugs that are confirmed by regulating bodies and released to the market is very low. That is because most of the drug candidate molecules have low pharmacokinetic properties. Therefore, early assessments of ADMET properties have gained extreme importance for pharmaceutical industry, to be able to avoid costly failures. Here, our aim is to come up with an approach that reliably predicts druggability features of drug candidate molecules as well as to point out the relations between ADMET properties and molecular descriptors. \par In this thesis study, we examine and compare 4 different molecule representations to predict druggability features of molecules, using 3 different machine learning algorithms; namely k-nearest neighbor, support vector machine classifier and random forest on 9 ADMET property datasets. We conclude that among all molecular representations, morgan fingerprint performs better in terms of accuracy and F-measure, however run time for parameter tuning and train is longer with fingerprint representations. As far as the machine learning algorithms are concerned, SVM classifier with morgan fingerprint performs better with higher accuracy and F-measure. With descriptor vector representation, we examine a set of molecular descriptors and using RF classifier, we evaluate most effective molecular descriptor for each ADMET property. For some datasets, we add the most contributive descriptor to morgan fingerprint representation and report an increase on evaluation metrics."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kenar bilişim bulutçuk tabanlı hesaplama, sis hesaplama, mobil bulut bilişim ve çoklu erişim kenar bilişim gibi çeşitli hesaplamalı teknolojileri kapsayan geniş bir kavramdır. Tüm bu bilişim paradigmaları, bulut bilişim yeteneklerini ağın kenarına getirmek için ortak bir yaklaşıma sahiptir. Burada kullanılan kenar terimi, çoğunlukla hareketli olan son kullanıcılara yakın bir konumu ifade eder. Hesaplama (görev) aktarma yöntemi, kenar bilişimin önemli bir özelliğidir. Bu yöntem mobil cihazlarda pil tüketimini azaltır ve yetersiz işlem gücü, bellek ve öngörülemeyen ağ bağlantısı nedenleriyle desteklenemeyen uygulamaları çalıştırmayı mümkün kılar. Bu bağlamda, kenar bilişim, üniversite kampüsleri, havaalanları ve akıllı yollar gibi fazla sayıda mobil kullanıcının bulunduğu ortamlar için yeni uygulamalara ve senaryolara olanak verir. İletişimdeki gecikmenin yüksek ve hesaplama kaynaklarının kısıtlı olduğu dikkate alındığında, internete bağlı akıllı cihazların sayısının artması yeni zorluklar getirmektedir. Kenar bilişim bulut bilişim yeteneklerini son kullanıcıya yakınlaştırarak bu zorlukların üstesinden gelmekle birlikte, hem hesaplama hem de ağ kaynaklarının gereksi\-nimlere göre gerçek zamanlı olarak kullanıldığı çok dinamik ve esnek bir ortam sunmaktadır. Bu nedenle, farklı kaynak türlerini verimli bir şekilde yönetmek çok önemli bir konudur. Bu zorlukların üstesinden gelmek için yeni kenar orkestratörleri üzerinde çalıştık. İlk olarak, önerilen orkestrasyon algoritmalarının başarımını değerlendirebilmek için EgeCloudSim adlı bir kenar bilişim simülatörü geliştirdik. Sonrasında, çok katmanlı mobil kenar hesaplama sistemleri için bulanık mantık tabanlı bir yük orkestratörü önerdik. Bu katkılara ek olarak olarak, çok katmanlı çoklu erişimli araçsal kenar bilişim ortamları için makine öğrenme tabanlı bir yük orkestratörü sunduk.","Edge computing is a broad concept covering a variety of computing technologies such as cloudlet-based computing, Fog Computing, Mobile Cloud Computing (MCC), and Multi-Access Edge Computing (MEC). All these computing paradigms have a common approach of bringing the cloud-computing capabilities to the edge of the network. The term edge used in this area refers to a location close to the end-users. Computation (task) offloading is an essential feature of edge computing. It reduces the battery consumption and makes it possible to execute applications that are unable to be executed on mobile devices due to their insufficient processing power, memory, and unpredictable network connectivity. In this regard, edge computing can enable new applications and use cases for the environments where there are many mobile users, such as university campuses, airports, and smart roads. The increasing number of smart devices that are connected to the Internet brings new challenges in terms of high communication delay and computational resources congestion. Although edge computing overcomes these challenges by bringing cloud computing capabilities to close proximity of the end-user, it presents a very dynamic and flexible environment where both computational and networking resources are utilized in real-time in accordance with the requirements. Hence, efficiently managing and orchestrating different types of resources become crucial issues. To overcome these challenges, we introduced novel edge orchestrators. Firstly, we developed an edge computing simulator, namely EgeCloudSim, to evaluate the performance of the proposed orchestration algorithms. Secondly, we proposed a fuzzy logic-based workload orchestrator for multi-tier mobile edge computing systems. As a final contribution, we presented a machine learning (ML) based workload orchestrator for multi-tier multi-access vehicular edge computing (VEC) environments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan aksiyonlarını tanıma ve anlayabilme sosyal integrasyon için önemli bir önşarttır ve sosyal bir topluluğun üyelerinin birbirleri ile ve çevreleri ile etkileşim kurmalarına olanak sağlar. Bir insanın algısal kabiliyetlerinin gelişimi sırasında, insan aksiyonlarını tespit etme ve onları tanıma kabiliyeti uzun bir zaman içerisinde gelişir. İlk olarak; basit, belirgin ve içerisinde fazla belirsizlik içermeyen aksiyonları tanımayı öğreniriz. Bunlara örnek olarak el sallama, yemek yeme veya yürüme aksiyonları verilebilir. Bu kabiliyetimizi geliştirdikçe, gülümsemek, dinlenmek veya okumak gibi daha incelikli aksiyonları da algılamaya başlarız. Daha karmaşık durumlarda ise bu aksiyonlar birbirleri ile kesişebilir veya daha karmaşık bir aksiyonu meydana getirebilir. İnsanlara benzer bir şekilde, robotlar için de, etrafındaki insanlarla doğal ve akıcı etkileşim kurabilmek ve içinde bulunduğu duruma göre hareketlerini planlayabilmek, etrafındaki insanların hareketlerini algılayabilme ve anlayabilme kabiliyeti önem arz etmektedir. Bunun için, sosyal bir robot farklı bozucu etkilerin mevcut olduğu gerçek hayat koşullarında çalışabilen güçlü bir aksiyon tanıma modülüne ihtiyaç duymaktadır. Aksiyon tanıma, insan hareketlerinin zamana bağlı olarak gözlenmesi ve bu gözlemlerin önceden tanımlanmış bazı aksiyon sınıfları ile eşleştirilmesidir. Çoğu durumda, aksiyon tanıma ve aksiyon tespit etme görevlerine eş zamanlı olarak ihtiyaç duyulmaktadır. Aksiyon tespit etme, genellikle uzun bir görüntü içerisinden içinde tekil aksiyonlar bulunan parçaların tespit edilmesidir. Genellikle, aksiyon tanıma ve aksiyon tespit etme insanlarda doğal olarak gerçekleşir ve bilinçaltımızda insanların aksiyonlarını tanıma işlemini fazlaca efor sarf etmeden gerçekleştiririz. Bu kabiliyet sosyal etkileşimlerimizi daha akıcı hale getirir. Fakat, bilgisayarlar için bu zorlu bir görevdir, çünkü birçok aksiyon karmaşık aksiyon parçalarının bir araya gelmesi ile oluşur ve aksiyonlar oldukça benzer görünümlere ve zamansal bağlamlara sahip olabilir. Küçük farklılıklar dahi insan hareketlerini farklı bir aksiyon sınıfına yerleştirmek için yeterli olabilir.","Being able to understand and recognize actions is a crucial precondition for social integration, which enables the members of a social community to interact with each other and with their environments. During the development of a person's cognitive abilities, the ability to detect and recognize actions improve over the course of a long period. First, we learn to recognize simple and explicit actions that have little ambiguity, such as; waving, eating, or walking. As we progress this ability we learn to recognize subtler actions, such as; smiling, resting, or reading. In more complex cases, these actions may overlap or compose a more integral action, such as riding a bike. In a similar spirit to humans, for a robot to be able to make natural and seamless interactions with people and make plans that are appropriate for the state of the environment it is in, it is imperative that it can understand the actions of the people around it. For this, a robot needs a powerful action recognition module that can on real-world conditions where a variety of distortions are present. Action recognition is the task of observing the sequential progression of these movements and matching some segments of this sequence with previously defined action classes which have been labeled by the action type that defines them. In many cases, the task of action recognition comes together with the task of action detection. Action detection is the task of extracting the segments from a usually long observation that contains some action. In many cases, action recognition and detection occur naturally in humans and we subconsciously recognize a person's actions without much effort. This ability makes social interaction much smoother. However, this is a very challenging problem for computer, since many actions contain complex action segments that might have very similar appearances and temporal processions. Even subtle differences can put an action into an entirely different class."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, farklı kaynaklardan toplanan matrisler ve yüksek mertebeli tensörler şeklinde depolanan heterojen verilerin birlikte analiz edilmesi ve veri füzyon problemine yoğunlaşıyoruz. Problemin çözümünde ise bağlaşımlı matris ve tensör ayışımı modelleri kullanmaktayız. Bu yöntem, paylaşılan modlardan ortak gizli faktörleri çıkararak matrislerin ve tensörlerin aynı anda bileşenlerine ayrılmasını sağlar. Biz de burada eksik bağlantı tahmini problemi için bağlaşımlı tensör modelleri geliştirerek, çeşitli model topolojileri ve çeşitli ıraksaylar kullanarak başarılı deneysel sonuçları rapor etmekteyiz. Çoğu zaman, veri matrisleri ve tensörler değişik taraflar arasında dağıtılır. Bu taraflar arasında bilgi paylaşımı gizlilik ve mahremiyeti koruma gereksinimini getirir, bu nedenle ele aldığımız ikinci sorun dağıtılmış ve heterojen veri kümelerinin mahremiyetini korumaktır. Dağıtık bir ortamda bireylerin gizliliğini sağlayan pratik bir mekanizma geliştirecek ve bu mekanizmayi çesitli gerçek veriler kullanarak değerlendirecegiz. Bu mekanizma için Bayesçi cıkarım ve diferansiyel mahremiyet arasındaki bağlantıdan faydalanarak etkili bir bağlaşımlı tensör ayrışım yöntemi geliştireceğiz. Yöntemlerimizin mahremiyet garantisi sağlarken sentetik ve gerçek veri kümelerinde iyi tahmin doğruluğu sağlayabildiğini deneysel olarak göstereceğiz. Son olarak, tensör ayrışımı ve yapay sinir ağları arasındaki bağlantıyı göstererek, yapay sinir ağlarının kullandığı verilerinin gizliliğini korumak için bir yaklaşım önereceğiz.","In this thesis, we focus on the data fusion problem where we have heterogeneous data which is collected from different sources and stored in the form of matrices and higher-order tensors and propose coupled matrix and tensor factorization models to be able to jointly analyze these relational datasets. This method performs simultaneous factorization of matrices and tensors by extracting the common latent factors from the shared modes. We develop coupled models using various tensor models and cost functions for the missing link prediction problem and report the successful empirical results. Most of the time, the data matrices and tensors are distributed between several parties. Sharing information across those parties brings the privacy protection requirement, therefore the second problem we handle is protecting the privacy of distributed and heterogeneous datasets. We develop and evaluate a practical mechanism that ensures the privacy of individuals in a distributed setting, in which N data sites jointly estimate the parameters of a statistical model conditioned on all the data without sharing their input datasets. We exploit the connection between differential privacy and sampling from a Bayesian posterior to derive an efficient coupled tensor factorization algorithm. We empirically show that our methods are able to provide good prediction accuracy on synthetic and real datasets while providing provable privacy guarantee. Finally, we propose an approach to preserve the privacy of the neural network's training data due to the connection between tensor factorization and neural networks. We introduce a dropout technique that provides an elegant Bayesian interpretation to dropout, and show that the intrinsic noise added can be exploited to obtain a degree of differential privacy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, uzamsal olarak değişken nesne hareket bulanıklığı ve eşleştirilmemiş bulanık/keskin eğitim çiftleri varlığında el görüntülerinden bulanıklığı kaldırmayı öğrenen yeni bir yöntem öneriyoruz. Sentetik bulanıklık eklenmiş verilerden ayrık gösterimleri öğrenerek görüntüde bulanıklığı kaldırma konusunda bir miktar başarı elde edilmiş olsa da, bu yöntemler hızla hareket eden nesneler var ise iyi performans göstermez; bu sebeple düşük poz tahmin performanslarının ortaya çıkması kaçınılmaz olur. Bu durum çoğu zaman işaret dili konuşan bir kişinin ellerini ani hareket ettirmesiyle meydana gelir. Bu sorunları imge içeriğinden (el dokusu, arka plan) bulanıklık bilgilerini kaldırarak çözmeyi öneriyoruz. Birbirlerine eş gelen eğitim çiftlerinin olmayışı, ayrık gösterimlere dayanarak bulanıklaştıran /bulanıklık kaldıran paralel ağlarla ve çapraz döngü tutarlılık kayıpları ile çözümlendirilmiş ve kısmi evrişimli ağ kullanılarak bulanık bölgelerden uzamsal değişken bilgi öğrenilmiştir. Sonuçlarımızı hem niteliksel hem de niceliksel olarak, gerçek bulanık görüntülerden ve keskin imgelerden oluşan bir veri kümesi ve sentetik bulanıklık içeren bir veri kümesi üzerinden sunuyoruz.","In this thesis, we propose a novel method that learns to deblur hand images in the presence of spatially-varying object motion blur and unpaired blurry/sharp training pairs. While some success has been achieved in image deblurring by learning disentangled representations from synthetically blurred data, these methods do not perform well when objects in the frame are moving rapidly; consequently resulting in inferior pose estimation performances. This commonly occurs when the hands of a signer moves abruptly in a sign language setting. We propose to solve these problems by disentangling blur information from image content (hand texture, background). Lack of non-corresponding training pairs is dealt with cross-cycle consistency losses in blurring/deblurring branches based on disentangled representations and spatially-variant blur is extracted from blur-degraded regions using partial convolutions. We test our results both qualitatively and quantitatively on a novel hand blur dataset consisting of real blurry images and sharp frames as well as a reference synthetically blurred dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Konu modelleri, büyük ve yapısal olmayan yazılı döküman setlerinin organize edilip yorumlanmasında sıklıkla kullanılır. Doküman setlerinin anlamsal altyapısını oluşturan konuları açıklamaya ve bu konuların dokümanlar üzerindeki dağılımlarını bulmaya çalışırlar. Denetimsiz doğası nedeniyle, bir konu modeli başarısını gösterebilmesi için, çıktılarının yorumlanabilir olması gerekir. Fakat, bir konu modelinin sonuçları genellikle insan yorumuyla zayıf bir şekilde ilişkilendirilir. Bu tezde, konuların yorumlanmasını iyileştirmek ve kolaylaştırmak için etiketli belgelerden yararlanabilen, Tema Denetimli Negatif Olmayan Matris Ayrıştırması adlı yarı denetimli bir konu modeli öneriyoruz. Modelimiz, konuların temsilini etiketli belgelerle eşleşecek şekilde kısıtlar ve bu, model tarafından keşfedilen konuların kolayca anlaşılmasını sağlar. Dokümanların sağladığı etiketleri daha verimli kullanabilmek ve doküman setlerini daha derinlemesine inceleyebilmek için, modelimizde temalar, alt konular ve arka plan konularından oluşan hiyerarşik bir konu yapısı kullandık. Temaların altında, alt konular içi denetimsiz öğrenmeye izin veren katmanlar olşturuyorduk. Bu hiyerarşik yapı, kendi içinde sağladığı denetimsiz öğrenme kabiliyeti ile, denetim ile kısıtladığımız modelimizin yeni boyutlar keşfedip, daha detaylı sınıflandırmalar yapabilmesine olanak sağlar. Modelimizi, oluşturduğumuz Schwartz veri kümesinin yanı sıra Brown ve Reuters veri kümelerinde farklı denetim oranlarıyla test ettik. Modelimiz, belgelerin konularını geleneksel negatif olmayan matris ayrıştırmasından ve gizli Dirichlet tahsisi'nden her koşulda çok daha iyi tahmin ediyor; ve bunun yanında, denetimin etkisi bir logaritmik fonksiyon gibi davranır ve daha düşük oranlarda en fazla etkiye sahiptir. Ayrıca yeni terim puanlama metriğimiz, her konu için önemli ve önemsiz terimlerin ağırlıklarını başarıyla değiştirerek konuların anlaşılmasını ve yorumlanmasını kolaylaştırır.","Topic models are often used to organize and interpret large and unstructured corpora of text documents. They try to explain the topics that constitute the semantic infrastructure of the document sets and try to find the distributions of these topics for the documents. Because of its unsupervised nature, the outputs of a topic model has to be interpretable to represent its success. However, the results of a topic model are usually weakly correlated with human interpretation. In this thesis, we propose a semi-supervised topic model called Theme Supervised Nonnegative Matrix Factorization that can benefit from labeled documents to improve and facilitate the interpretation of the topics. Our model constrains the representation of the topics to align with the labeled documents and this enables the topics discovered by the model to be readily understood. To utilize the labels provided by the documents more efficiently and to explore the document sets in more depth, we used a hierarchical topic structure consisting of themes, subtopics, and background topics in our model. We created layers under the themes that permit unsupervised learning for subtopics. This hierarchical structure, with the unsupervised learning capability it provides, enables our model, which was restricted with supervision, to discover new dimensions and make more detailed classifications. We tested our model on Schwartz dataset we created, as well as Brown and Reuters datasets with different supervision ratios. Our model estimates the topics of the documents much better than the traditional nonnegative matrix factorization and latent Dirichlet allocation for any situation; and besides, the effect of supervision is noteworthy, especially at low ratios. Moreover, our new term scoring metric successfully alters the weights of significant and insignificant terms for each topic and makes the topics easier to understand and interpret."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaret dili, işitme engellilerin temel iletişim aracıdır. Ancak işaret dilinden bilgiye erişim konuşma dilindeki kadar kolaylıkla mümkün olmamaktadır. Bu tezde, işaret dili için üç farklı bilgi erişimi tekniği sunulmuştur. İlk olarak, işitme engellilerin anadillerinde arama yapabilmelerini sağlamak amacıyla Dinamik Zaman Bükmesi temelli bir Örnekle Arama tekniği geliştirilmiştir. İkinci olarak sunulan çeviri tabanlı bir diller-arası arama tekniği ile işaret dili bilmeyenlerin yazı dilinden aramalarla işaretleri bağlam içerisinde öğrenebilmeleri amaçlanmıştır. Son olarak ise, bu tezin temel çıktısı olan düşük güdümlü öğrenmeye dayanan bir anahtar kelime arama tekniği geliştirilmiştir. Hem işaret hem yazı dilinden anahtar kelimelerle arama yapılabilen bu teknik, aynı zamanda iskelet pozisyon bilgileri ve el şekli öznitelikleri gibi farklı özniteliklerle ve farklı dizi kodlama metodlarıyla birlikte kullanılabilmektedir. Bu tez kapsamında HospiSign, RWTH-Phoenix-Weather 2014T ve MeineDGS Corpus veri kümelerinde gerçekleştirilen deneyler, iskelet pozisyonu özniteliklerinin genel olarak farklı işaret dili geri getirimi tekniklerinde, ve özellikle Uzam-Zamansal Çizge Evrişimli Sinir Ağları ile kullanıldığında, iyi başarımlara ulaştığını işaret etmektedir. Bunun yanı sıra, sadece düşük güdümlü öğrenme amacıyla eğitilen dikkat tabanlı modellerin anahtar kelimelerle ilintili zamansal bölgeleri kendiliğinden tespit edebildiği görülmüştür.","Sign language is the main communication tool for the hearing impaired. However, the information retrieval from sign language is not as easy as in spoken languages. In this thesis, three methods of information retrieval are proposed for sign language. Firstly, a Dynamic Time Warping based Query-by-Example search technique is developed to enable the Deaf to search for information in their native language. Secondly, a translation-based cross-lingual keyword search method is proposed which will enable the people outside of the Deaf community to learn sign language in context with queries from the written language. Finally, as the main contribution of this thesis, a weakly-supervised keyword search technique is designed based on neural word embeddings and attention concept from neural machine translation. This technique is shown to be capable of performing both gloss search and cross-lingual written keyword search; and can be used together with different input features such as human pose estimates and various hand shape features. Our experiments conducted on three datasets, i.e. HospiSign, RWTH-Phoenix-Weather 2014T, and MeineDGS corpus, indicate that using human pose estimates extracted with OpenPose framework generally performs good under different retrieval tasks in sign language, especially when they are combined with Spatio-Temporal Graph Convolution. Furthermore, models based on attention is found to be able to temporally localize the keywords as a by-product of weakly supervised training."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Stres artık modern toplumumuzun ayrılmaz bir parçası oldu. Araştırmacılar insan sağlığı, toplum ve ekonomi ¨uzerindeki olumsuz etkilerini hafifletmek için stresle başa çıkmanın yollarını araştırdılar. Bu noktada akıllı telefonların, akıllı saatlerin ve akıllı bilekliklerin yaygın şekilde kullanılması, bu cihazlarla stresin algılanabileceği ve hafifletebilineceği araştırma konusunu gündeme getirdi. Her ne kadar geleneksel olarak laboratuvar ortamlarında araştırmalar yapılmış olsa da, son zamanlarda göze çarpmayan giyilebilir cihazlar içeren ekolojik ortamlarda bir dizi yeni çalışma başlatılmaya başlandı. Bu tezde günlük yaşam için bir stres algılama sistemi geliştirdik. Fizyolojik veri toplama için rahatsızlık vermeyen giyilebilir cihazlar kullanıldı. Bu amaçla kalp ve deri iletkenliği aktivitesi fizyolojik sinyalleri kullanıldı. Değişik kiplere özgü hatalı kayıt algılama ve düzeltme algoritmaları, öznitelik çıkarımı ve gelişmiş makine öğrenme yöntemleri önerildi. Bütün ortamlarda veri toplayarak sistemimizi laboratuvar ortamında, sınırlı, yarı sınırlı ve sınırsız gerçek yaşam ortamlarında test ettik. Her birinde seçilen ortama özgü araştırma sorularını inceledik. Gerçek hayattaki sistemlerin başarımlarını geliştirmek için yeni yöntemler önerdik. İç mekanlarda uygulanabilecek farklı stres iyileştirme yöntemleri önerdik ve inceledik. Ayrıca günlük yaşam stres yönetimi çalışmaları için umut vaat eden teknikler, hafifletme yöntemleri ve araştırma zorluklarını tartıştık.","Stress has become an integral part of our modern society. Researchers investigated ways to cope with it to alleviate its negative effects on human health, society and economy. At this point, widespread usage of smartphones, smartwatches and smart wrist-bands raised the question of whether we can detect and alleviate stress with them. Although research has traditionally been conducted in laboratory settings, a set of new studies have recently begun to be conducted in ecological environments with unobtrusive wearable devices. In this thesis, we developed a stress detection system for daily life. Unobtrusive wearable devices were used for physiological data collection. For that purpose, we used heart rate variability (HRV) and electrodermal activity (EDA) signals. Modality specific artifact detection and removal algorithms, feature extraction and advanced machine learning methods were proposed. We tested our system in a laboratory environment, restricted, semi-restricted and unrestricted real-life environments by collecting data in each environment. We proposed different techniques to improve the state of the art in real life environments. We worked on prominent environmentspecific research questions. We further examined different stress alleviation methods including those which can be applied indoors. We also discussed promising techniques, alleviation methods and research challenges for daily life stress management."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde işaret dili tanıma problemi için kullanılan Üç boyutlu Evrişimsel Sinir Ağları (3B ESA) yapılarının sınıflandırma performansını artıran Skor Seviyesinde Çoklu İpucu Kaynaşımı yöntemi önerilmiştir. İşaret Dili yazılı dil içeriğinden farklı olarak çoğunlukla el hareketleri, vücut pozu ve yüz ifadelerine odaklandığı için bu bölgelere ait ipuçları önem teşkil etmektedir. İşaret Dili Tanıma için son dönemde derin yapay sinir ağlarının gelişmesi sebebiyle bir çok yöntem önerildiği görülmektedir. Önerilmiş olan yöntemler farklı 3B ESA yapılarını kullanarak işaret dili sınıflandırması yapmaktadır ve sırasıyla Standart 3B ESA, Karma ESA ve (2+1)B ESA methodları olarak sınıflandırılmıştır. Standart 3B ESA yapısı sadece 3B filtresini kullanmakta, Karma ESA yapısı 2B ve 3B filtrelerini birlikte kullanmakta ve (2+1)B ESA yapısı ESA atlama mimarisinde darboğaz oluşturan (2+1)B bloğunu kullanmaktadır. İşaret dili tanıma problemi için bahsedilen yapıların kullanıldığı çalışmalar bulunmaktadır, ancak bu çalışmalarda işaret dilinin farklı vücut, el ve yüz gibi farklı ipucu bölgelerinin değerlendirilmediği veya gereksiz büyüklükte mimariler kullanıldığı için zayıf sonuçlar elde edildiği görülmektedir. Bu eksikliklerin çözülmesi kolayca uygulanabilen ve yalnızca Karma ESA yapısı ile tüm işaret dili ipuçlarını işleyebilen bir sistem tasarlanmıştır. Bu sistem ile el, vücut ve yüz ipucu modelleri karma ESA yapısı ile eğitilmiştir ve sonuçlar ağırlıklı skor kaynaşımı ile birleştirilmiştir. Bosphorus Sign 22k Türk İşaret Dili veri kümesi üzerinde deneyler yapılmıştır. Tasarladığımız sistem alternatiflerine göre daha hızlı çalışmakta ve 744 sınıf tahmini probleminde $\%94$ sınıflandırma başarısı ile diğerlerinden daha başarılı sonuç elde etmektedir. Gelecek çalışmalarda önerdiğimiz çoklu ipucu yapısı kullanılarak, işaret dili çevirisi gibi diğer işaret dili temelli problemlerdeki başarımın da artırılabileceği öngörülmektedir.","In this thesis, we propose a Score-Level Multi Cue Fusion approach that improves the sign language recognition performance of the three dimensional convolutional neural networks. Sign Language is the communication language of the Deaf and Hearing-impaired individuals and performed using hand movements, facial gestures, and body alignment. Sign Language Recognition is the task that aims to understand sign language and gaining increasing popularity with the task becoming feasible due to the efficiency of the neural network. Previous work uses 3D CNN network variants to inspect SL properties in different settings. The vanilla 3D variant uses 3D kernels with high processing cost, the mixed convolution variant applies both 3D and 2D kernels respectively, and R(2+1)D variants exploit bottleneck connections to exploit the bottleneck dimension. Various studies use these networks to generate an end to end framework for tasks such as sign classification and translation. To achieve better performance, 3D CNN methods use the complicated neural network architectures that have a branch for every cue system. We evaluate the 3D network performances and propose a more straightforward approach which only adopts a single neural network that can process multiple cues at test time. We exploit the hand, body, and face cues by training single individual networks and fuse results by using a weighted score fusion. We test our method on the recently published Turkish Isolated SLR dataset. Despite the simple architecture, our method achieves \%94 percent classification rate on 744 different sign glosses. We hope that the multi cue approach can help with the other SLR tasks such as translation, which is stated as future work."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın amacı, teknik göstergeler ile elde edilen farklı özellik grupları ile farklı örnekleme ve çoğaltma yöntemlerini kullanarak kripto para alım-satım hareketlerinin, özellikle Bitcoin alım-satım hareketlerinin tahmini için derin öğrenme yöntemlerini araştırmaktır. Bu amaçla, finansal zaman serisi verileri pencere kaydırma algoritması ile üç sınıfa ayrılmıştır: satın al, sat, beklet. Bu sınıflandırma algoritması, derin öğrenme ortamında bir problem olan dengesiz veri seti ile sonuçlanmıştır. Dengesiz veri seti problemini çözebilmek ve azınlık sınıflarına ait veri sayılarını arttırabilmek için doğrudan kopyalama, SMOTE, ADASYN adı verilen üç örnekleme yöntemi ve titreşim ve zaman çarpıtma adı verilen iki çoğaltma yöntemi kullanılmıştır. Ayrıca, derin öğrenme modellerine girdi olacak finansal veri özelliklerini elde etmek için bu çalışmaya teknik göstergeler dahil edilmiştir. Elde edilen finansal veri özellikleri üzerinde özellik seçme ve özellik çıkarma işlemleri gerçekleştirilmiştir. Bütün göstergeler, karşılıklı bilgi metriği kullanılarak seçilen en iyi 15 gösterge, momentum, hacim, oynaklık ve trend göstergeleri olmak üzere altı farklı özellik grubu oluşturulmuştur. Önerilen derin öğrenme mimarilerimiz, evrişimli sinir ağı ve iki farklı kodlayıcı mimarisine sahip ilgi mekanizmaları, özellik gruplarının ve örnekleme, çoğaltma yöntemlerinin farklı kombinasyonları ile eğitilmiştir. Sonuçlar umut vericidir ve SMOTE örnekleme tekniğinin uygulandığı, ilk 15 göstergeyi girdi olarak alan ilgi derin öğrenme mimarisi kullanılarak oluşturulan model ile 56.48 olan en iyi makro ortalama F1 skoru elde edilmiştir.","The purpose of this study is to investigate deep learning methods for predicting cryptocurrency, specifically Bitcoin, trading decisions considering different oversampling and augmentation methods, and using different feature groups as input, extracted using technical indicators. For this purpose, financial time series data is labelled as three classes namely, buy, sell, hold, by a window sliding approach. However, this labeling approach gives rise to imbalanced data set which is problematic in deep learning setting. In order to address imbalanced data set problem, three oversampling methods which are Direct Copying, SMOTE, ADASYN, and two augmentation methods, jittering and time warping, are used for increasing the size of data sets that belong to minority classes. Moreover, technical indicators are included in this study to extract financial data features to be fed into deep learning models. Feature selection and ablation study are performed on the extracted features. Six different feature groups are created which can be listed as; all indicators, top 15 indicators selected using mutual information metric, and momentum, volume, volatility and trend indicators. The proposed deep learning architectures, convolutional neural network and attention mechanisms with two different encoder architectures, are trained with different combinations of oversampling and augmentation methods, and feature groups. Results are promising where the best macro average F1 score of 56.48 is achieved by the model generated using attention deep learning architecture which is fed with top 15 indicators where SMOTE oversampling technique is applied."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, en yeni varyasyonel özkodlayıcı tabanlı tek örnekli ses dönüşümü yöntemlerinden biri geliştirilerek yeni bir ses dönüştürme yöntemi tanıtılmıştır. Önerilen yöntem, akustik öznitelikler olarak Mel-spektrogramları kullanmakta ve konuşulan içeriğin konuşmacı ve içerik gösterimlerini ayırarak çözülmüş gösterimler oluşturmaktadır. Üretilen Mel-spektrogramlarının kalitesini arttırmak için çekişmeli ve algısal kayıplar kullanılmıştır. Ses çevrim modelinin eğitimi sırasında algısal kaybı uyarlayabilmek için bilgisayarlı görme alanında iyi bilinen bir modelin mimarisini kullanarak bir konuşmacı sınıflandırıcısı eğitilmiştir. Voice Cloning Toolkit veri seti üzerinde deneyler yapılmış, global varyans ve insansı bir yorum simülatörü olan MOSNet açısından değerlendirilmiştir. Deneysel sonuçlar, çalışmamızın referans aldığımız ses dönüşüm yönteminin ses çevrim kalitesini önemli ölçüde artırdığını göstermektedir.","In this thesis, a new adversarial one-shot voice conversion (VC) method is introduced by enhancing one of the latest variational autoencoder based one-shot VC methods. The proposed method utilizes acoustic features as Mel-spectrograms and relies on disentangled representations by separating speaker and content representations of the spoken content. An adversarial loss and perceptual loss are combined in order to increase the quality of generated Mel-spectrograms. We train a speaker classifier by utilizing the architecture of a well-known model in the computer vision area, to be able to adapt perceptual loss during the training of the VC model. We conduct experiments on the Voice Cloning Toolkit dataset and evaluate the proposed approach in terms of Global Variance and MOSNet, a humanoid opinion score simulator. Experimental results indicate that our approach improves VC quality remarkably."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Her yıl, trafik kazaları yüzünden çok sayıda ölüm meydana gelmektedir. Trafik kazazedelerinin hayatta kalma oranlarını arttırmak için, travma müdahale ekiplerinin kaza alanına olabildiğince çabuk varmalarını sağlamak önemlidir. Otomatik olay tespiti, daha hızlı olay bildirme olanağı sağlar ve böylece kazanın gerçekleşme anı ile ilk müdahalenin olay yerine ulaşması arasındaki süreyi azaltır. Bu çalışmada, çeşitli algılama mekanizmaları ve iletişim teknolojilerinden faydalanarak, trafik olaylarının algılanması, doğrulanması ve bildirilmesine olanak sağlayan bir sistem önerilmektedir. Önerilen sistem, iki otomatik olay tespit algoritması kullanan ve olay algılanmasından sorumlu olan bir RSU (""Roadside Unit"" - Yol Kenarı Ünitesi) içermektedir. Algoritmalardan biri endüktif döngü sensörleriyle toplanmış trafik parametrelerine, diğeri VANET (""Vehicle Ad-hoc Networks"" - Tasarsız Taşıt Ağları) adı verilen bir iletişim teknolojisine dayanmaktadır. Önerilen RSU, ayrıca eCall ile WreckWatch çözümlerince gönderilen iki olay bildirme sinyalini dinler ve alır. Bu çalışmada önerilen RSU, AADL (""Architecture Analysis and Design Language"") dili ile modellenmiştir. Modelin iç yapısı, bileşenleri ile onların etkileşimlerini kapsayan bir AADL modeli tanımlanmaktadır. Çeşitli işlemci yapıları için gem5 isimli simülatör ile modelin görev yürütümü üzerine yapılan deneyler sunulmaktadır. AADL modelinin zamanlama özelliklerini belirlemek ve nihayetinde zamanlama testleri ile gecikme analiz raporları sunmak amacıyla, gem5 benzetim sonuçları kullanılmaktadır. Ayrıca, AADL Inspector ile yapılan zamanlama benzetimi gösterilmektedir. Test sonuçları, RSU mo-delimizin düşük işlemci kullanım oranı ile programlanabilir olduğunu ve üç dakikadan kısa bir sürede olay tespiti ve raporlaması sağladığını göstermektedir.","Every year, a massive number of deaths happen because of traffic accidents. In order to increase the traffic victim's survival rates, it is important to reduce the arrival time of trauma intervention teams to accidents' sites. Automatic incident detection provides faster incident reporting, in which it decreases the delay of arrival time of first responders. In this thesis, we propose a system where traffic incidents can be detected, verified and reported using multiple detection mechanisms and communication technologies to provide faster response and allow for first responders to arrive as quickly as possible. Our proposed system contains a Roadside Unit (RSU), which is responsible for incident detection using two automatic incident detection algorithms depending on traffic parameters collected by Inductive Loops sensors and communication technology called VANET. The proposed RSU, also, listens and receives two incident reporting signals sent by eCall and WreckWatch solutions. This thesis provides the internal architecture of the proposed RSU using Model-Based Engineering concept, where the RSU is modeled in Architecture Analysis and Design Language (AADL). We provide an AADL model that captures the internal structure of the RSU, its components and their interactions. We provide experiments on the model's tasks execution using gem5 simulator depending on different configurations. We used gem5 simulation results for scheduling properties of the AADL model in order to present scheduling tests and latency analysis. In addition, we present scheduling simulations using AADL Inspector. Test results show that our RSU model is schedulable with low processor utilization factors, and provides incident detection and reporting in under three minutes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Solunum seslerini akıllı bilgisayar algoritmaları ile analiz etmek ve içindeki normal olmayan solunum seslerini teşhis etmek 250 yıllık geçmişe sahip oskultasyon yönteminde yeni bir çağ başlatmıştır. Bu algoritmalar oskultasyon konusunda geleneksel steteskopların problemlerini çözebilir ve sağlık çalışanlarını destekleyebilirler. Bu tezde, hırıltı seslerini normal solunum seslerinin arasından tespit etmeyi sağlayan yeni bir akıllı algoritma geliştirildi ve sunuldu. Hırıltı seslerini akıllı algortimalar ile tesbit etmek günümüzde bir çok araştırmacı tarafından çalışılmaktadır. Hırıltılar sürekli ve normal olmayan solunum sesleri olarak tanımlanabilirler. Müzikal bir yapıya sahiptirler. Süresi, yoğunluğu ve nefes alış verişinini hangi evresinde olduğu verisi, akciğer hastalıklarının teşhisi ve durumu hakkında önemli bilgiler verir. Bu çalışmadaki hedeflerden biri daha önceki araştırmalarda hırıltı belirlemede kullanılan 9 tane ses özelliği arasıdan, en ayırıcı olanlarını belirlemektir. Ayrıca, bu özellikleri kullanarak hırıltı seslerini ayırt edebilen en başarılı makine öğrenmesi algoritmasını da bulunması hedeflendi. Son olarak, en başarılı sonuçları veren makine öğrenmesi modelini kullanarak hırıltı seslerini normal solunum seslerinden ayırt etmeyi sağlayan yeni bir algoritma geliştirildi.","Analyzing respiratory sounds and detecting anomalies in them with intelligent computer algorithms has opened a new era for auscultation that has 250 years of history. These algorithms can overcome the drawbacks of conventional stethoscopes and support medics about auscultation. In this thesis, a new intelligent algorithm to detect wheezes superimposed on vesicular sounds is developed and presented. Detection of wheezes with intelligent algorithms is one of the hot topics currently being researched by many researchers. They are continuous musical adventitious respiratory sounds. Their duration, intensity, and phase in respiratory sounds give essential information for the diagnosis and prognosis of respiratory diseases. In this study, one of the aims is to determine the best discriminative features among nine features which are mostly used in other researches. The other aim is to find the best-performed machine learning classifier to classify wheezes and normal respiratory sounds. Last, we created a novel detection algorithm is presented to detect correctly the wheeze interval in recorded respiratory sounds by employing selected machine learning model to respiratory sounds."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yapay ajanları daha özerk ve zeki yapma arayışında, onların, becerileri kendi kendilerine öğrenebilme yeteneğiyle donatılması çok önemli bir rol oynar. Bu tezde, yapay ajanların becerileri verimli bir şekilde kazanmasını sağlamak için içsel motivasyonlu keşfe odaklanmaktayız. Keşif sırasında ajan, keşfe devam edeceği bir sonraki bölgeyi içsel motivasyon sinyalini kullanarak seçer. Bu motivasyon sinyali, ajanı, ajan için ne çok kolay ne de çok zor olan bölgeyi keşfetmeye yönlendirir. İlk çalışmamızda, mevcut bir içsel motivasyon mimarisini daha iyi kullanmak amacıyla, özel öğrenme bölgelerini oluşturmak için, duyumotor uzayını öngörülebilirlik ilkesini kullanarak sürekli olarak bölen bir yöntem önerdik. Bir sonraki çalışmamız, bir dizi becerinin öğrenimi için, içsel motivasyonun yönlendirdiği keşifsel davranışların kendi kendine örgütlenmesini kolaylaştıran saklı bir uzay kullanmayı amaçlamaktadır. Bu uzayın robot ve çevre arasındaki etkileşimin dinamiklerini yansıtmasını sağlamak için, sonuç, eylem ve nesne bilgilerinin harmanlanmasını öneriyoruz. Daha sonra, bu saklı uzay farklı bölgelere ayrılmakta ve her bölge ayrı tahmin modelleri tarafından öğrenilmektedir. Önerilen yaklaşım, masa üstü bir ortamda, parametrik eylemler kullanarak farklı nesnelerle etkileşime giren, simüle edilmiş bir robotla doğrulanmaktadır. Sunduğumuz yaklaşım, robotun kendi müfredatını düzenlemesine olanak tanıyarak, robotun daha kolay olan becerilerden daha karmaşık olanlara geçmesini sağlar. Oluşan müfredatın analizi, itme becerisinden önce kavrama becerisinin ortaya çıktığı sonucuna varmaktadır, bu da bebeklerdeki beceri gelişimi ile benzerlik göstermektedir. Ayrıca, sonuçlar önerilen yöntemin çeşitli koşullar altında, benzerlerinden önemli ölçüde daha az tahmin hatası yaptığını göstermektedir.","In quest of making artificial agents more autonomous and intelligent, equipping them with the ability of self-learning of skills plays a crucial role. In this thesis, we focus on intrinsically motivated exploration to enable efficient acquisition of skills for artificial agents. During the exploration, the agent uses the intrinsic motivation signal to self-select the exploration regions to proceed. This motivation signal drives the agent to explore the region that is neither too easy nor too difficult for the agent. First, we proposed a method that continuously partitions the sensorimotor space using the predictability principle to form specialized learning regions to better employ an existing intrinsic motivation framework. Our next study aims to utilize a latent space that facilitates the self-organization of the exploratory behaviors driven by the intrinsic motivation to learn a set of skills. To make this space reflect the dynamics of the interaction between the robot and the environment, we propose blending the outcome, action, and object information. Next, the latent space is clustered into different regions; each is then learned by separate predictors. The proposed approach is validated with a simulated robot that manipulates different objects using parameterized actions in a table-top environment. Our approach allows the robot to organize its own curriculum, enabling it to proceed from easier skills to more complex ones. The analysis of the curriculum deduces that grasp emerges before pushing, which is consistent with the skill emergence in infants. Furthermore, results show that the proposed method makes significantly lesser prediction errors than its counterparts in various settings."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, Türkçe için geniş kapsamlı bir duygu analizi çatısı oluşturulmuştur. Ayrıca, İngilizce'de duygu analizine özel bazı yaklaşımlar da geliştirilmiştir. Bu kapsamda bu problemin bir sürü yönü göz önünde bulundurulmuştur. Beş tane ana katkı ve üç tane küçük katkıda bulunulmuştur. Denetimsiz, yarı denetimli ve denetimli yöntemlerle orijinal ve etkili öznitelik kümeleri oluşturulmuştur. Bundan sonra, bu öznitelikler klasik makine öğrenme metotlarına girdi olarak verilmiştir ve Türkçe ile İngilizce dillerindeki veri setleri için, yapay sinir ağlarının performansı geçilmiştir. Türkçe dili için ilk defa yarı denetimli yöntemlerle duygu sözlükleri oluşturulmuştur. Sondan eklemeli Türkçe dili için detaylı bir biçimbilimsel analiz gerçekleştirilmiş ve eklerin duygu skorları tespit edilmiştir. Bu, biçimsel olarak zengin diğer dillere de uygulanabilmektedir. Tekrarlamalı ve yinelemeli sinir ağı modellerini birleştiren özgün bir yapay sinir ağı mimarisi geliştirilmiştir. Duygusal, sözdizimsel, anlamsal ve sözlüksel öznitelikler hesaba katılarak, hem Türkçe hem İngilizce için özgün kelime vektörleri oluşturulmuştur. Ayrıca, bağlam pencereleri yancümlecik olarak belirlenerek İngilizce için kısmen orijinal bir yöntemle kelime vektörleri modellenmiştir. Bu, diğer dilbilimsel alanlara ve doğal dil işleme alanlarına uyarlanabilmektedir. Bütün bu özgün yaklaşımlar için, ölçüt olarak alınan çalışmaların başarı oranları geçilmiştir. Küçük çaplı katkılarımız, Türkçe için yön bazlı duygu analizi, yarı denetimli metot için parametrelerin değiştirilmesi ve İngilizce'de duygu analizi için yorumlarda yönlerin tespit edilmesi olarak belirtilebilir. Bu tez, Temmuz, 2020 itibariyle Türkçe için geliştirilmiş en kapsamlı çalışma olarak atfedilebilir. Bu çalışma aynı zamanda İngilizce'de duygu analizi alanı için önemli katkılarda bulunmuştur.","In this thesis, we developed a comprehensive framework for sentiment analysis that takes its many aspects into account mainly for Turkish. We have also proposed several approaches specific to sentiment analysis in English only. We have accordingly made five major and three minor contributions. We generated a novel and effective feature set by combining unsupervised, semi-supervised, and supervised metrics. We then fed them as input into classical machine learning methods, and outperformed neural network models for datasets of different genres in both Turkish and English. We created a polarity lexicon with a semi-supervised domain-specific method, which has been the first approach applied for corpora in Turkish. We performed a fine morphological analysis for the sentiment classification task in Turkish by determining the polarities of morphemes. This can be adapted to other morphologically-rich or agglutinative languages as well. We have built a novel neural network architecture, which combines recurrent and recursive neural network models for English. We built novel word embeddings that exploit sentiment, syntactic, semantic, and lexical characteristics for both Turkish and English. We also redefined context windows as subclauses in modelling word representations in English. This can also be applied to other linguistic fields and natural language processing tasks. We have achieved state-of-the-art and significant results for all these original approaches. Our minor contributions include methods related to aspect-based sentiment in Turkish, parameter redefinition in the semi-supervised approach, and aspect term extraction techniques for English. This thesis can be considered the most detailed and comprehensive study made on sentiment analysis in Turkish as of July, 2020. Our work has also contributed to the opinion classification problem in English."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezin temel amacı beyaz cevher yolaklarının büyük ölçekteki karakteristik özelliklerini bularak psikoz vakalarının teşhis ve takibinde başvurulabilecek bir teşhis ölçütü ortaya çıkarmaktır. Beyaz cevher yolakları difüzyon ağırlıklı manyetik rezonans görüntülerinin işlenmesi ile ortaya çıkan ""traktogram""da beyindeki yolakların bütününü kapsayacak şekilde oluşturulabilir. Tractogram verisini kullanarak, voksel boyutundaki sınırdan bağımsız, yani büyük ölçekte bir özellik olarak beyaz cevher yolaklarının karmaşıklık derecesinin ölçülebileceği bir yayılım ölçütü bu tez kapsamında önerilmiştir. Sentetik veriler üzerinde yaptığımız çalışmalar önerilen ölçütün bağımlı olduğu değişkenlere olan duyarlılığını göstermektedir. Önerilen büyük ölçekli yayılım ölçütünün şizofreni ve bipolar vakalarının normallerden farklı yayılım karakteristiklerine sahip olduklarını gösteren ayırt edici bir ölçüt olduğu gösterilmiştir. Önerdiğimiz büyük ölçekli yayılım ölçütü ile frontal beyin lobu ile bağlantılı olduğu bilinen singulum ve inferior oksipito-frontal fasikülleri özel olarak incelendiğinde bu farklılık ortaya çıkmaktadır. Bu yayılım ölçütü, voksel sınırları içerisinde ölçülmüş olan difüzyon ölçütleri kadar etkili bir ölçüt olduğu karşılaştırmalarla anlaşılmıştır. Önerilen ölçüt ile oluşturulmuş yayılım haritası ile teknik uygulama da yapılabilmiş ve örnek olarak singulum bölütleme çalışması yapılmıştır. Bu tezin sonuçları ışığında büyük-ölçek yayılım ölçütü ile oluşturulan beyin haritalarının psikoz vakalarının teşhisinde kullanılabilecek bir nörobelirteç olma olasılığı ortaya çıkmıştır. Önerilen yöntem farklı klinik durumlar için de sınanabilir ve teknik uygulamalarda yeni ilerlemeler sağlanabilir.","The main goal of this thesis is to find distinct macro-structural characteristics of brain white matter in the case of psychosis, where development of diagnostic imaging measures is necessary for early diagnosis and prospective studies. Given a tractogram data, which is a dense set of white matter fiber pathways of the whole brain obtained from diffusion magnetic resonance imaging, we propose to compute a global measure of dispersion for a voxel from the end point statistics of a set of fibers, which indicates complexity of the white matter voxel not locally but at macro scales. The findings on phantom data demonstrate sensitivity of the proposed measure to the tuning parameters and show its range characteristics. The findings on the real data demonstrate that proposed macro-structural dispersion information is found to be significant for discrimination of the schizophrenia and the bipolar patients from the healthy controls, especially when the frontally associative bundles such as cingulum and inferior occipito-frontal fasciculus are considered. The macroscopic dispersion measure is as informative as the local diffusion measures for the detection of changes in the white matter regions due to the psychosis. Beside, as a technical application, the dispersion map is considered and experimented for segmentation of cingulum. The findings of the thesis provide that the proposed measure is a potential diagnostic imaging marker in the case of psychosis and we contribute to the field of diagnostic research by generating a novel dispersion map of the brain that could be used for other clinical and technical applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kozmik ışınlar olarak adlandırılan yüksek enerjili parçacıklar, dünyaya ulaşarak atmosfer ile carpışırlar. İlk çarpışma yeni parçacıklar üreterek zincirleme bir etkileşimi tetikler. Çarpışmalar sonucu ortaya çıkan son parçacığın etkileşim için yeterli enerjisi kalmadığında zincirleme etkileşim son bulur. Çok yüksek enerjili bir ilk parçacık tarafından başlatılan ve üretilen ikincil parçacıkların yeryüzünde geniş bir alana yayıldığı kozmik ışın gözlemlerine parçacık sağanağı denir. Kozmik ışınların kaynaklarının ve üretim mekanizmalarının keşfi amacıyla parçacık sağanaklarını oluşturan ilk parçacığın atmosfer ile etkileşim açısı ve enerjisi bakımından eşyönsüzlükler araştırılmaktadır. Bu çalışmada kozmik ışının enerjisini ve vaka açısını, olabilirlik modeli bulunmaksızın Bayesçi yöntemle tespit ediyoruz. Bu sayede hesaplamalı olarak ̧ çözülmesi imkansız veya zor olan olabilirlik modellerine sahip parçacık fiziği problemleri için alternatif bir çözüm yöntemini ortaya koyuyoruz.",Highly energetic particles called cosmic rays arrive at earth and interact with the atmosphere to cause other particles to emerge and fuel a chain interaction of particle production until the energy is dissipated. These cascades emerging from a highly energetic initial particle and producing secondary particles that spread over a large area at the ground are called Extensive Air Showers. These showers are studied to find anisotropy in their arrival direction and energy to unveil their source and production mechanisms in the universe. In this study we utilize the likelihood free particle filtering with Approximate Bayesian Computation to estimate the incident angle and energy of the primary particle. ABC method makes use of comparison between simulated and observed summary statistics to overcome the problem of computationally intractable likelihood function of particle physics.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İlişkisel veri ayrıştırılmasında üretken modeller ilkeli bir yaklaşım sunar, ve ayrıştırma görevini Bayesçi istatistiğin olasılıksal çerçevesi içinde genişletmeye izin verir. Bu modellerin en bilinen örneği, ilişkisel veri üzerinde tanımlı bir Bernoulli karışım modeli olan raslantısal öbek modelidir. Bu çalışmada, karışık üyelikli raslantısal öbek modelinin (MMSB) üretken sürecini Bayesçi atama modelinin (BAM) genel atama çerçevesinde yeniden oluşturan BAM-MMSB modelini öneriyoruz. Geleneksel öbek modellerin aksine, BAM-MMSB gözlemleri temel bir Poisson süreci tarafından üretilen ve MMSB'nin üreteç modeline göre işaretlenmiş Poisson sayımları olarak kabul eder. İlişkisel verileri ayrıştırmak için kayda değer miktarda algoritma önerilmiştir. Ancak, bu modeller için model seçimi hala açık bir problemdir. Çalışmanın devamında, her model boyutu için marjinal olabilirliğin varyasyonel yaklaşımlarını hesaplayarak, BAM-MMSB modelinde eniyi topluluk sayısını tahmin ediyoruz. Çalışmamızda sadece model boyutu seçimi görevini yerine getirmemize rağmen, BAM'ın genel atama perspektifinin yalnızca model boyutunu değil aynı zamanda en iyi ayrıştırma modelini seçtiğimiz genelleştirilmiş bir model seçimi çözümü vaat ettiğine inanıyoruz. Çalışmada önce önerilen modeli açıklıyoruz ve çıkarım algoritmalarını türetiyoruz. Daha sonra, ilişkisel verileri atama modelinde Poisson sayıları olarak temsil ettiğimiz deneysel kurumu anlatıyoruz. Son olarak, model çıktısının yorumlanabilirliği ve model seçimi performansı açısından algoritmamızı, sentetik ve gerçek dünya veri kümeleri üzerinde yapılan deneylerle değerlendiriyoruz.","For relational data factorization, generative models provide a statistically principled approach that allows for extending the factorization task in the probabilistic framework of Bayesian statistics. The most well-known example of such models is the stochastic blockmodel which is a mixture of Bernoullis defined for relational data. In this work, we propose the model BAM-MMSB which replicates the generative process of the mixed-membership stochastic block model (MMSB) within the generic allocation framework of Bayesian allocation model (BAM). In contrast to traditional blockmodels, BAM-MMSB considers the observations as Poisson counts generated by a base Poisson process and marked according to the generative process of MMSB. A considerable amount of algorithms have been proposed to factorize relational data. However, model selection for this task is still an open problem. In the sequel, we estimate the optimal number of communities for BAM-MMSB by computing the variational approximations of the marginal likelihood for each model order. Although we only perform the model order selection task in our work, we believe that the generic allocation perspective of BAM promises a generalized model selection solution where we not only select the model order but also choose the best factorization. We describe the proposed model and derive the inference algorithms. Next, we display the experimental setup where we represent relational data as Poisson counts of the allocation model. Later, we assess our variational inference algorithm in terms of interpretability of the model output and block recovery and model selection performance by the experiments on synthetic and real-world datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşbu çalışmada, girdinin boyutundan bağımsız, sabit bir miktarda yazı-tura atma hakkı tanınan sonlu hal hesaplayıcılarının, aidiyet ispatlarını doğrulama konusunda yapabileceklerinin sınırlarını inceliyoruz. Cem Say ve Abuzer Yakaryılmaz'ın önceki bir çalışmada ispatladığı üzere, bu nitelikteki hesaplayıcıların katı tipte 1/2'den az hata yaparaktan doğrulayabildikleri dillerin kümesi, tam da NL sınıfına denk gelmektedir. Fakat bu ispatta sunulan doğrulayıcıların katı tip hatası, NL'nin büyük çoğunluğu için 1/2'ye oldukça yakın çıkmakta. Bu tezde bu zayıf türden hesaplayıcıların alabildiğine küçük katı tip hata ile doğrulayabildiği dilleri, NL sınıfının bir alt kümesi olarak belirliyoruz. Pozitif herhangi bir e değeri için, doğrusal zamanda çalışan çok kafalı bir belirsiz sonlu hal hesaplayıcısı (2nfa(k)) ile tanınabilen herhangi bir dili tanıyan, sonlu hafıza ve sonlu rastgelelik kullanan ve katı tip hatası en fazla e olan bir doğrulayıcı inşa eden bir yöntem sunuyoruz. Bu yöntemi tüm NL'ye genellemenin neden zor olduğunu tartışıyor, doğrusal zamanda çalışan 2nfa(k)'lerin dil tanıma gücünün, aynı anda zaman ve de hafıza sınırlarına tabi Turing makineleri üzerinden tanımlanmış karmaşıklık sınıfları ile olan alakasını hayli sıkı bir biçimde kuruyoruz.","We study the capabilities of probabilistic finite-state machines that act as verifiers for certificates of language membership for input strings, in the regime where the verifiers are restricted to toss some fixed nonzero number of coins regardless of the input size. Say and Yakaryılmaz showed that the class of languages that could be verified by these machines within a strong error bound strictly less than 1/2 is precisely NL, but their construction yields verifiers with strong error bounds that are very close to 1/2 for most languages in that class. We characterize a subset of NL for which verification with arbitrarily low strong error is possible by these extremely weak machines. It turns out that, for any e > 0, one can construct a constant-coin, constant-space verifier operating within strong error e for every language that is recognizable by a linear-time multi-head nondeterministic finite automaton (2nfa(k)). We discuss why it is difficult to generalize this method to all of NL, and give a reasonably tight way to relate the power of linear-time 2nfa(k)'s to simultaneous time-space complexity classes defined in terms of Turing machines."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Global ısınmanın yadsınamaz etkileri, toplumun gün geçtikçe sürdürülebilirlik konusunda farkındalığını artırmakta ve hükümetlerin yeşil enerji politikalarını desteklemesini sağlamaktadır. Öte yandan mobil ağ teknolojileri için önerilen çözümler sürdürülebilirlik açısından yetersiz kalmaktadır. Bunun yanında, gelecek nesil radyo erişim ağlarının yüksek veri ihtiyacı mobil servis sağlayıcılarının maliyetlerini arttırmakta ve bu sağlayıcıları ekonomik çözüm arayışına itmektedir. Bu tezde, tüm bu ihtiyaçlara karşılık vermek için, güneş panellerinin alternatif enerji olarak kullanıldığı radyo erişim ağlarının enerji ve maliyet optimizasyonu problemlerine odaklanıldı. Bu problemler, üçüncü nesil mobil haberleşme teknolojilerindeki solar enerji beslemeli baz istasyonlarının kurulum ve operasyon aşamalarından, beşinci nesil merkezi mobil erişim ağlarındaki fonksiyon paylaştırma ve Ethernet üzerinden radyo yaklaşımlarıyla solar enerji kaynaklarının entegrasyonuna kadar geniş bir spektrumda yer almaktadır. Çözüm için önerilen mimariler nesillerine göre yenilikçi yaklaşımlar olup, mobil servis sağlayıcılarına enerji ve maliyet giderlerini azaltmaları için en uygun boyuttaki yenilenebilir enerji ekipmanlarını seçmelerini ve bunları işletmelerini sağlamaktadır. Bunun yanında çözümlerde gerçek güneş enerjisi verisi kullanılması ve birçok değişken koşulun test edilmesi, bu çözümlerin birbirinden farklı ağ ortamlarında kullanılmasına olanak vermektedir. Böylece, bu çözümler yenilenebilir enerji kaynaklarını kullanarak mobil ağlardaki enerji tüketimi ve karbon emisyon oranlarını azaltırken, bir yandan da servis sağlayıcıların karlarını arttırarak bu sistemlerin ekonomik uygulanabilirliğini sağlamaktadır.","Due to the incontrovertible effects of global warming, society grows its sustainability awareness regularly, and governments start to change their energy policies to promote green energy sources. However, mobile network technologies have not been ready for new sustainable solutions. Besides, the high data demand in the next-generation radio access networks encourages mobile network operators to investigate cost-efficient solutions. Therefore, this thesis addresses the energy and cost optimization problems of a radio access network that uses the solar panels as an alternative energy source. We investigate several design problems from deployment and operation of solar-powered base stations in the third generation mobile communication networks to integrate the renewable energy sources into the function splitting, and Radio over Ethernet approaches in the fifth-generation centralized radio access networks. The proposed architectures are novel for their generations and offer remarkable guidance to the service providers to choose the proper size of renewable energy source equipment and how to operate this equipment to get the best energy and cost-efficiency. Besides, we provide both mixed-integer linear programming and heuristic solutions for different scales of problems. Also, we use real-world solar data and experiment with several instances to prove that our solutions can be implemented in the networks with different circumstances. Therefore, the operators can improve their profits and economic feasibility in their projected mobile communication networks while our proposed solutions reduce the energy consumptions and the carbon emission rates by promoting the use of renewable energy sources."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nesnelerin İnterneti büyümesini sağlayan en büyük etkenlerden biri ucuz ve yetenekli donanım iken belki de en büyük endişe gizlilik ve güvenliktir. Gizlilik ve güvenlik sağlamak için gereken şifreleme ve kimlik doğrulama, pille çalışan Nesnelerin İnterneti uç düğümlerinin sahip olmadığı büyük güç bütçelerine ihtiyaç duyar. Literatürdeki mevcut donanım hızlandırıcıları belirli iş yükleri için tasarlanmışlardır, bu sebeple gelecekteki güncellemeler için çok az esneklik sağlar veya hiç esneklik sağlamazlar. Özel komut tabanlı çözümler, alan maliyeti olarak daha küçüktür ve uygulanacak yeni yöntem ve algoritmalar için daha fazla esneklik sağlarlar. Özel komutların bir dezavan- tajı, sistemin işlem bitene kadar beklemesi gerekmesidir. İşlem çok uzun sürdüğünde, cihazın gerçek zamanlı olaylara yanıt süresi uzar. Bu çalışmanın amacı modüler çarpma için özel komutla genişletilmiş bir işlemci önermektir. Bu yaklaşımda modüler çarpma, tipik bir durumda, işlemciyi iki saat çevrimi boyunca engelleyebilir. RV32EC komut se- tini temel aldığımız ve Verilog ile geliştirdiğimiz tasarımımız, Eliptik Eğri Kriptografisi (ECC) alanındaki güncel şifreleme algoritmaları üzerinde denenmiştir. 128 bit modüler çarpma içeren uygulamaya özel tümdevre (ASIC) tasarımında 136 MHz saat hızına ve alanda programlanabilir kapı dizileri (FPGA) üzerinde 81 MHz saat hızına ulaştık. Yazılımsal çözüme kıyasla çeşitli kriptografik eğrilerde on üç kata kadar hız artışı elde ederken, temel mimarimiz üzerinde ortalama % 41 alan artışı ile toplam güç tüketimini % 95'e kadar azaltmayı başardık.","While one of the biggest enabling factors of Internet of Things growth is cheap and capable hardware, maybe the biggest concern is privacy and security. Encryption and authentication need big power budgets, which battery-operated IoT end-nodes do not have. Hardware accelerators designed for specific cryptographic operations provide little to no flexibility for future updates. Custom instruction solutions are smaller in area and provide more flexibility for new methods to be implemented. One drawback of custom instructions is that the processor has to wait for the operation to finish. Eventually, the response time of the device to real-time events gets longer. In this work, we propose a processor with an extended custom instruction for modular multiplication, which blocks the processor, typically, two cycles for any size of modular multiplication. We adopted embedded and compressed extensions of RISC-V for our proof-of-concept CPU. Our design is benchmarked on recent cryptographic algorithms in the field of elliptic-curve cryptography. Our CPU with 128-bit modular multiplication operates at 136MHz on ASIC and 81MHz on FPGA. It achieves up to 13x speed up over software implementations while reducing overall power consumption by up to 95% with 41% average area overhead over our base architecture."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Güneş enerjisi, en hızlı gelişen karbonsuz elektrik üretim yöntemlerindendir. Küresel iklim krizi ile mücadeledeki önemli rolüne karşın, dağıtık (1 MW kapasitenin altındaki) güneş enerjisi santrallerinin sayısındaki hızlı büyüme, elektrik piyasalarında bazı problemleri beraberinde getirmektedir. Coğrafi olarak geniş bir alanda konumlanmış yüzlerce santral, saatlik elektrik arzında önemli sapmalara yol açabilmektedir. Dolayısıyla, elektrik piyasası işlemlerinde ileri tarihli üretim tahminlemelerinin en yük\-sek isabetle gerçekleşmesi önem arz etmektedir. Bu çalışmada, Orta Anadolu bölgesinde geniş bir alana dağılmış binden fazla güneş enerjisi santralinin saatlik toplam üretim değerlerinin gün öncesinde tahminlenmesi için çözüm üreten çeşitli derin öğrenme teknikleri uygulanmıştır. Halihazırda literatürde bulunan dört farklı derin öğrenme mimarisi, bu çalışmada sunulan paralel yerel bağlantılı uzun-kısa süreli bellek ağı ile birlikte sayısal hava durumu tahminlerinin uzay-zamansal yapısına uyarlanmıştır. Bütün modeller, birden fazla grafik işlemci biriminin kullanıldığı dağıtık yapıdaki bir sezgisel hiperparametre eniyileme işleminden geçirilmiştir. Her model için en iyi çalışan deneme, doğrulama veri kümesi kullanılarak seçildikten sonra modeller kendi aralarında ve referans modellerle karşılaştırmalı olarak raporlanmıştır. Sonuçlar referanslarla kıyaslandığında derin öğrenme modellerinin uzay-zamansal güneş enerjisi tahminleme probleminde iyi çalıştığını göstermiştir.Ayrıca, iyi bir parametre seçilimi sağlandığında düşük karmaşık\-lıktaki modellerin daha karmaşık modellere yakın performans verebileceğini görülmüştür. Her hata ölçevi bakımından galip gelen tek bir model olmasa da, önerilen modelin yanlılık ve varyans ikilemi göz önünde bulundurulduğunda paylaşımlı parametreli ağ ve tam bağlantılı ağ arasında konumlanması gelecek vaat edicidir.","Solar power is one of the most rapidly growing carbon-free power generation solutions. It is considered as a key element in the fight against global climate crisis; however, rapid expansion in the distributed PV power, i.e. plants with less than 1 MW capacity, brings about some problems to the electricity markets. Spatially dispersed positioning of hundreds of plants cause significant variations in the power supply where trading operations depend on accurate forecasts of the future production. In this study, several deep learning techniques are implemented for the day-ahead solar power forecasting problem to predict the aggregated output of over a thousand solar stations distributed over a large area in the Central Anatolian Region. Four different architectures in the literature are adapted to the spatiotemporal numerical weather prediction (NWP) data, along with the proposed parallel locally-connected long short-term memory (PLC-LSTM) architecture. All models are put through a distributed heuristic hyperparameter tuning process using multiple graphical processing units (GPUs). Best-performing trials of each model are selected according to their validation results and compared with each other, together with persistence and an individual plant naive model as benchmarks. The results show that deep learning models work considerably well in spatiotemporal PV forecasting problem, compared to benchmarks. Also, it is seen that even simple architectures can perform close to models with a higher degree of complexity, when a good combination of parameters is obtained with a thorough search procedure. Although there is not a single dominating architecture prevailing in all kinds of performance metrics, PLC-LSTM shows promising results by finding a sweet spot of complexity between the shared-weight and fully-connected architectures, considering the bias and variance of the corresponding models."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kompleks robotik sistemlerde, eylem-tepki tahmini çözmesi zor problemlerdendir, özellikle değişken sayıda obje ve bu objelerin arasında çeşitli etkileşimler varsa. Bu tarz sistemleri modellemek için, veriyi birden fazla obje ve etkileşimi tarif edebilecek şekilde kodlamak gerekir. Bu tezde önce bizim çeşitli şekillerdeki objeler üzerinde yağtığımız araştırmayı sunduk. Sonrasında, bahsettiğimizde tarz sistemleri modellemek için, gra fik sinir ağı tabanlı bir yapı ve genel amaçlı bir fi zik simülatörü olan Kendi İnancını Düzenleyen Çifte Yayılım Ağları(Belief Regulated Dual PropagationNetworks)'nı öneriyoruz. Bu yapı birbirini destekleyen iki bileşenden oluşuyor, fizik tahminci ve inanç düzenleyici. Fizik tahminci robotun işlediği objelerin bir sonraki anını tahmin ederken, inanç düzenleyici robotun işlenen objelerle ilgili olan bilgisini güncelliyor. Deneylerimizde, farklı tip objeler ve eklemler bulunduran kompleks sistemlerde, robotun yaptığı eylemlerin sonuçlarını obje yörüngesi düzeyinde tahmin edebildiğini ve bu eylemlerden kazandığı tecrübelerden yararlanarak, ortam ile ilgili bildiklerini güncelleyebildiğini gösterdik. Aynı zamanda, bu sistemle nasıl alet kullanıp planlama yapılabileceiğini gösterdik.","In complex robotic systems, prediction of effects is a challenging problem when the number of objects varies, especially in the presence of rich and various interactions among these objects. To be able to model such systems, the representation of data should be able to sufficiently encode multiple objects and interactions between them. In this thesis, we fi rst show our initial research on effect prediction on objects with various shapes. Then we propose a Graph Neural Network based framework, Belief Regulated Dual Propagation Networks (BRDPN), a general-purpose learnable physics engine. Our framework consists of two complementary components, a physics predictor and a belief regulator. While the former predicts the future states of the object(s) manipulated by the robot, the latter constantly corrects the robot's knowledge regarding the objects and their relations. Through our experiments, in complex environments consisting of different shaped objects and articulation types we have shown that by using this framework, the robot can reliably predict the consequences of its actions in object trajectory level and exploit its own interaction experience to correct its belief about the state of the environment. Furthermore, we have shown that we can use this framework in tool manipulation and planning."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sıralı veri modelleme ve analizi, sinyal işleme, biyoenformatik ve hesaplamalı finans gibi birçok bilim ve mühendislik alanında kümeleme, olağandışılık tespiti ve öngörme görevlerinde önem taşır. Bu çalışmada, dinamik sistemlerin modellenmesine odaklanarak zaman serisi analiz yöntemlerinin temellerini sunuyoruz. Amacımız, sistem hakkındaki belirsizliğimizi açıklayabilen ve aynı zamanda alana özgü bilgileri bu sistem temsillerine dahil edebilen istatistiksel çıkarımlar yapabilmektir. Saklı Markov modelleri, göreceli sadelikleri ve esneklikleri nedeniyle literatürde kapsamlı bir şekilde incelenmiştir. Bu modele ilave bir saklı ölçek değişkeni sunarak, Gauss-Gamma dağılımlı saklı Markov modeli adında yeni bir model ve bu modelin durum çıkarımı ve parametre kestirme algoritmaları ileri sürüyoruz. Model, kalıcı rejimler sergilemek ve ağır kuyruklu dağılımlara sahip olmak açısından finansal piyasaların dinamiklerinden ilham alıyor. Hesaplamalı finans alanında böyle bir modele duyulan ihtiyacın arkasındaki nedenler, optimum portföy oluşturma alanında bir standart olan Ortalama-Varyans Analizinin matematiksel eksiklikleri ile ilişkilendirilerek tartışılmaktadır. Modelin performansı yapay üretilmiş ve gerçek finansal veri setleri üzerinde rejim belirleme ve portföy yönetimi deneyleri yürütülerek incelenmiştir. Sonuçlar modelin finansal piyasa dinamikleri hakkında anlamlı çıkarımlar yapabildiğini göstermektedir.","In many domains of science and engineering, such as signal processing, bioinformatics and computational finance, sequential data modelling and analysis is essential for various tasks including clustering, anomaly detection and forecasting. In this work, we present the fundamentals of time series analysis methods with a focus on modelling dynamical systems. Our goal is to make statistical inferences that are able to account for our uncertainty about the system while also being able to incorporate domain specific knowledge into these system representations. Hidden Markov models have been extensively studied in the literature because of their relative simplicity and flexibility. We propose an extension to this model called the Gaussian-Gamma hidden Markov model which introduces an additional latent scale parameter, along with its state inference and parameter estimation algorithms. The model is inspired by our prior knowledge of financial markets in terms of displaying persistent regimes and having heavy-tailed distributions. The intuition behind the need for such a model in computational finance is discussed with respect to the shortcomings of the standard mathematical framework of constructing an optimal portfolio called the Mean-Variance Analysis. We illustrate the performance of our model in both synthetically generated and real financial data sets with regime identification and portfolio management problems. Results show that our model is able to discover meaningful insights about the dynamics of financial markets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma ELMo ve DistilBERT adındaki bağlamsal ve derin doğal dil sistemlerini protesto haber metni ve kullanıcı yorumlarının ikili sınıflandırılması olmak üzere iki farklı senaryo üzerinden kıyaslamaktadır. Asıl amaç, bu modern sistemlerin birbirinden çok farklı girdileri modellemedeki başarısını ölçmek, bu sayede doğal dil işlemeyi hedef alan sistemlerin gerçek hayattaki kaynak çeşitliliğine ne kadar iyi adapte olabildiğine ışık tutmaktır. Bu amaçla, modeller eğitilirken ve başarımı ölçülürken bağlamca ayrışan veri kümeleri kullanılmıştır. Sözgelimi, ilk senaryo için Hindistan ve Çin'in yerel gazete haberlerinden, ikinci senaryo için ise sinema filmleri ve teknolojik cihazlara yapılan kullanıcı yorumlarından faydalanılmıştır. ELMo ve DistilBERT kullanılarak üretilen kelime vektörleri, biri ileriye doğru, diğeri özyineli olmak üzere iki farklı sinir ağına verilmiştir. Daha basit ve bağlamsal olmayan Çokterimli Naif Bayes Sınıflandırıcısı ve Doğrusal Destek Vektör Makinesinin sonuçları temel alınmıştır. Sonuçta, DistilBERT'in ELMo'ya kıyasla, bu iki senaryoda, farklı test ortamlarına daha dayanıklı olduğu, üstüne \%30 daha küçük ve \%83 daha hızlı olduğu görülmüştür. ELMo ise, yine, farklı bağlama geçişte, iki temel algoritmadan daha başarılı olmuştur. Buradan yola çıkarak, DistilBERT'in dilin genellenebilir anlamsal özelliklerini daha iyi öğrendiği ve gerçek-zamanlı dönüt gerektiren sistemlerde ve bellek kaynağı bakımından sınırlı bütçelerde ELMo'dan daha kullanışlı olduğu yargısına varılabilir. Öte yandan, genellenebilirliğin gözetilmediği, test verisinin eğitim verisine benzediği durumlarda Naif Bayes gibi daha basit ve ekonomik algoritmalar derin sinir ağlarına alternatifler olarak tercih edilebilir.","This study evaluates the robustness of two state-of-the-art deep contextual language representations, ELMo and DistilBERT, on supervised learning of binary protest news classification and sentiment analysis of product reviews. A ``cross-context'' setting is enabled using test sets that are distinct from the training data. Specifically, in the news classification task, the models are developed on local news from India and tested on the local news from China. In the sentiment analysis task, the models are trained on movie reviews and tested on customer reviews. This comparison is aimed at exploring the limits of the representative power of today's Natural Language Processing systems on the path to the systems that are generalizable to real-life scenarios. The models are fine-tuned and fed into a Feed-Forward Neural Network and a Bidirectional Long Short Term Memory network. Multinomial Naive Bayes and Linear Support Vector Machine are used as traditional baselines. The results show that, in binary text classification, DistilBERT is significantly better than ELMo on generalizing to the cross-context setting. ELMo is observed to be significantly more robust to the cross-context test data than both baselines. On the other hand, the baselines performed comparably well to ELMo when the training and test data are subsets of the same corpus (no cross-context). DistilBERT is also found to be 30\% smaller and 83\% faster than ELMo. The results suggest that DistilBERT can transfer generic semantic knowledge to other domains better than ELMo. DistilBERT is also favorable in incorporating into real-life systems for it requires a smaller computational training budget. When generalization is not the utmost preference and test domain is similar to the training domain, the traditional ML algorithms can still be considered as more economic alternatives to deep language representations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın amacı, Türkçe haberler için önceden eğitilmiş dil modellerini kullanarak otomatik bir çıkarıcı özetleme sistemi geliştirmektir. Önceden eğitilmiş dil modelleri, birçok Doğal Dil İşleme görevinde kullanılmış ve yüksek performans sonuçları başarmıştır. Bu çalışmada, çıkarıcı özetleme görevi için derin öğrenme metotları ile önceden eğitilmiş Türkçe dil modelleri kullanılmıştır. Önerilen mimaride önceden eğitilmiş dil modeli üzerine, haberdeki belge düzeyindeki özellikleri ve cümleler arasındaki anlamsal ilişkileri yakalamak için fazladan Transformer katmanları eklenmiştir. Son olarak, haberde yer alan cümleler 0 ile 1 arasında bir değer üreten sigmoid fonksiyonu ile skorlanmıştır. Bu modeli eğitmek için, bilinen bir Türkçe haber sitesinden 2076 haber metni ilgili özetleriyle birlikte toplanmıştır. Veriler toplandıktan sonra, makalelerdeki her cümle, sezgisel bir algoritma ile 0 veya 1 olarak etiketlenmiş ve bu etiketler kullanılarak, çıkarıcı özetleme sistemi eğitilmiştir. Modeli test ederken ise model tarafından en yüksek skoru alan 5 cümle ile haberin özeti üretilmiştir. Ayrıca hiper parametrelerin etkilerini araştırmak amacıyla farklı hiper parametre setlerine sahip 241 farklı model çalıştırılmıştır. En iyi model 38.38 Rouge-1 F skoru, 26.8 Rouge-2 F skoru ve 38.04 Rouge-L F skoruna ulaşmıştır. Bu skorlar, 37.49, 26.4 ve 37.12 Rouge F skorlarına sahip LEAD-5 bazından önemli ölçüde daha yüksek oldukları için umut vericidir. Bu çalışmada LEAD-5, okuyucuların dikkatini çekmek amacıyla en önemli cümleler haberlerin başına yerleştirildiği için çok güçlü bir baz oluşturuyor. Dolayısıyla, önerilen model, Türkçe haber veri seti için oldukça iyi bir performans göstermektedir.","The goal of this study is to develop an automated extractive summarization system for Turkish news using pre-trained language models. Pre-trained language models have been applied to wide range Natural Language Processing tasks and achieve state of the art performance results. In this thesis, pre-trained language models for Turkish are applied on extractive summarization task. The proposed model has a pre-trained language model and on top of it, Transformer layers are added to capture document level features and semantic relationships between the sentences in the news articles. Then, these sentences are scored with sigmoid function, which outputs a real value between 0 and 1. To train this model, 2076 news are collected from well-known Turkish news website. After the data collection, each sentence in the articles is labelled as 0 or 1 with a heuristic algorithm. By using these labels, an extractive model is trained. In the test time, Top-5 scoring sentences are combined to generate final summaries. Also, to investigate the effects of hyperparameters, 241 different models, which have different architecture and hyperparameter sets, are run. The best one has achieved 38.38 Rouge-1 F score, 26.8 Rouge-2 F score and 38.04 Rouge-L F score. These scores are promising since they are significantly greater than LEAD-5 baseline, which has 37.49, 26.4 and 37.12 Rouge F scores. For this study, LEAD-5 is very strong baseline since the most significant sentences are placed at the beginning of the news to capture the readers' attention. Therefore, the proposed model shows a good performance for Turkish news dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gerçek hayattaki birçok sistem ağ gösterimi kullanılarak temsil edilebilir. Ağ gösteriminde, sistemi oluşturan bileşenler düğümlerle; bu bileşenlerin arasındaki ilişkiler ise bağlantılarla gösterilir. Özel bir ağ tipi olan karmaşık ağlar ise sistemin bileşenlerinin birbiriyle etkileşimi sonucu ortaya çıkan özelliklere sahiptir. Ağlardaki küme yapısı bu özelliklerden biridir. Bir ağ içindeki kümelenme, birbiriyle daha sıkı bağlarla bağlanmış düğümlerden oluşur; bu düğümlerin ağ içindeki diğer düğümlerle ise daha az bağlantısı bulunmaktadır. Bir ağ içinde bu tip kümelenmeleri bulmak, ağ içinde benzer özellik veya fonksiyona sahip alanların tespiti, bilginin dağılımı veya hastalık yayılımı gibi birçok alanda önemli kullanım alanına sahiptir. Bu tezde, karmaşık ağlardaki kümeleri yerel yaklaşımlı algoritmalarla (ör: ortak arkadaşlar üzerinden benzerlik) ve bilgi yayılımı yöntemleriyle (ör: dedikodu yayılımı) tespit etme üzerinde çalışmalar yaptık. Mevcutta kullanılan algoritmaları inceleyerek bunların yetersiz kaldığı alanları tespit ettik. Tüm ağ üzerinde bir değeri iyileştirmeye çalışan küresel yaklaşımlı algoritmaların uzun çalışma sürelerine sahip olduklarını gördük. Yerel yaklaşım kullanarak, düğümlerin benzerlikleri ve dedikodu yayılımını baz alan algoritmalar geliştirdik. Yerel yaklaşımlı algoritmaların çalışması için, bir düğüm etrafındaki kısıtlı bilgi yeterli olmaktadır. Bu sayede, küme işlemi paralel ve dağıtık şekilde ağın farklı yerlerinde eşzamanlı yapılabilmektedir. Bununla birlikte, bilinen bir küme bulma algoritmasını baz alarak (etiket yayılım algoritması), algoritmada gereksiz yapılan adımları ortadan kaldıran bir yaklaşımla, çalışma zamanını kısaltan yeni bir algoritma geliştirdik. Tez çalışmaları sırasında tanımladığımız bu algoritmaların tanımlanması sürecinde yeni bir geliştirme altyapısı da oluşturduk.","Many real world systems can be represented using networks or graphs where elements of system are denoted by nodes and their relations by edges. Complex networks are special kinds of these networks with their emergent features created by interactions among nodes. One such emergent feature is the community structure. A community is a group of nodes where nodes within same community have more connections (i.e., edges) with each other than with the nodes in the rest of the network. Identifying such communities is the task of community detection that can be used to identify nodes with similar functions or features, densely connected regions in networks, information flow patterns and spreading of a disease or information in a network. In this thesis, we work on community detection on complex networks using local approach and information diffusion. We investigate current algorithms and try to understand the limitations of them. We especially focus on high time-complexity of algorithms because of using global approach, i.e., try to optimize a global metric or perform computations regarding the whole network repeatedly. We propose new algorithms using local approach (i.e., similarity based on common friends) and information diffusion (i.e., gossip spreading). Local approach uses locally available or computable information around a node to identify its community. With this, community detection task can be seen as a set of distributed and parallel tasks running simultaneously on different parts of the network. We also propose a variant of label propagation algorithm which decreases its overall execution time by eliminating unnecessary steps. During these studies, we develop a community detection framework which simplifies the task of defining, testing and comparing a new community detection algorithm."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet trafiğinin en büyük kısmı çoklu ortam içerikleri tarafından üretilmekte ve kablosuz mobil ağlar üzerinden bu içeriğe erişim oranı günden güne artmaktadır. İçeriğin kullanıcıya ulaştırılmasında kullanılan yöntem içeriğin türüne ve gecikmeye duyarlı olarak gerçek zamanlı iletilmesine bağlıdır. Genel olarak IP ağlarında içerik kullanıcılara ayrı kopyalar olarak gönderilir. İçerik kopyaları, canlı yayın gibi gerçek zamanlı trafikte aynı anda, isteğe bağlı videoda ise farklı zamanlarda çoğaltılmaktadır. Bu tezde baz istasyonuna düşük kaliteli bağlantısı olan kullanıcıların, kendisine yakın ve bağlantı kalitesi daha iyi olan diğer kullanıcıların yardımıyla IPTV gibi yüksek hızda gerçek zamanlı iletim gerektiren yayınları alabilmesi için kablosuz örgü topolojili ağlarda ileri düzey işbirliğine dayalı çoklu dağıtım ve yönlendirme modeli önerilmektedir. Söz konusu model, ağ kapasitesi ve iletim sistemi bilgisayarlarında ciddi bir aşırı yüke neden olan veri kopyalarının sayısını önemli oranda azaltmakta olup, bütünsel olarak kablosuz ağın verimini artırmaktadır. Kablosuz ağlarda bir diğer önemli konu da baz istasyonlarının nerelere konumlandırılacağıdır. Farklı şehirlerde mimari olarak birbirine benzerlik gösteren yerel bölgeler bulunmaktadır ve benzer yapılar sinyal yayılımı üzerinde benzer etki göstermektedir. Bu tezde ayrıca üç boyutlu şehir haritalarındaki yerel benzerliklerden ve mevcut ağ kurulumlarının sinyal ölçümlerinden yararlanılarak yeni alanlarda sinyal yayılım biçimlerini hesaplayıp baz istasyonlarının etkin şekilde yerleştirilmesini sağlayan bir çoklu yol sinyal yayılım modeli önerilmektedir.","The largest traffic on the Internet is generated by multimedia content, and the share of wireless mobile access to the multimedia content is ever increasing. The delivery process in the content depends on the type of the content, and whether it requires a strictly time sensitive live session, or it can be delivered on demand, irrespective of time of request. As a general solution in the IP networks, the delivery is taking place as multiple individual transmissions from the source to all receivers, replicating the same content at different times, or at the same time if the content is streaming live. In this thesis, we propose an advanced collaborative multicast routing model for delivering bandwidth hungry streaming content such as IPTV to multiple users having low quality wireless connection, with the help of other nearby users having a better connection quality utilizing the wireless mesh network topology. The model reduces the amount of data replication, which causes significant overhead in the network transmissions and intermediate computations, improving the overall throughput of the wireless network. An essential issue in wireless mobile networks is where to position the base stations on the network coverage area. We also propose an alternative adaptive mixed path signal propagation estimation model for planning the base station locations in new deployment areas, based on the signal characteristics of existing networks. In doing so, we utilize digital 3D maps of urban areas and signal measurements to train the adaptive model, and to exploit local similarities in cities in order to estimate the signal channel characteristics and calculate the potential base station locations for covering the new area with a specific wireless communication technology."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Beyaz veba olarak da anılan verem günümüzde en ölümcül bakteri kaynaklı hastalıklardan biridir. Bu hastalığa sebep olan tür Mycobacteriaceae ailesinden verem çubuk bakterisidir. Bakterilerin antibiyotiklere karşı direnç kazanabilmeleri yüzünden verem hastaları arasındaki ölüm oranı artmaktadır. Bu tez farklı yapay öğrenme algoritmalarının, verem tedavisinde kullanılan dört birinci sıra antibiyotiğe karşı geliştirilmiş direnç tespitinde kullanımını incelemektedir. Her bir model için 23 hedef gen üzerindeki değişiklikler girdi olarak kullanılmıştır. h37rv kimliğine sahip olan verem çubuk bakterisi genomu değişiklik tespitinde temel olarak alınmıştır. h37rv kimlikli kalıtsal materyale sahip olan bakteriler birinci sıra antibiyotiklerin hepsine duyarlıdır. Çeşitli yapay öğrenme algoritmaları incelendi ve birbiriyle kıyaslandı. Geleneksel modellerin performanslarının çok katmanlı algılayıcılardan daha yüksek olduğunu gözlemledik. Bilgi erişimi alanında kullanılan çeşitli veri gösterimlerinin antibiyotik direnç tespiti üzerindeki etkileri de incelenmiş ancak makine öğrenmesi modellerinin performanslarını arttıracak bir etkiye sahip olduğu çıkarımı yapılamamıştır. Ek olarak SHAP ismi ve\-ri\-len makine öğrenmesi anlamlandırma tekniği ile mutasyonların antibiyotik direnç tahminine katkıları incelenmiştir. Her bir hedef ilaç için en yüksek SHAP değerine sahip on mutasyonu direnç berlirleyici olarak ileri sürüyoruz.","Tuberculosis, which is sometimes referred as white plague, is one of the most dangerous diseases caused by bacteria in our era. The species causing the sickness is in the family of Mycobacteriaceae and called mycobacterium tuberculosis. Bacteria are able to acquire resistance to antibiotics, so mortality rate among tuberculosis patients is increasing. This thesis examines different machine learning algorithms to detect antibiotic resistance to four first-line drugs in tuberculosis treatment. Variants on 23 target genes are included as input for each model. The base mycobacterium tuberculosis genome, which is used to detect variants on each sample in the data set, is the genome with id h37rv. Bacteria having h37rv as genome, are susceptible to all first-line antibiotics. Different machine learning algorithms are investigated and compared to each other. We observe that traditional machine learning algorithms have higher performance than multilayer perceptrons do. The impact of different data representations used in information retrieval on antibiotic resistance detection is also examined and we can not find any clear evidence for them to improve machine learning models' performances. Additionally, the contributions of mutations are ranked via the SHAP methodology used in the interpretation of machine learning models. We propose ten mutations with the highest SHAP values for each target drug as resistance determinants."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Müzik endüstrisi her yıl hit şarkıları üretmek için büyük yatırımlar yapıyor. Dijital platformlarda artan şarkı sayısı, şarkıları tahmin etmek ve ortak özelliklerini tanımlamak için öğrenme modellerinin geliştirilmesini sağlayabilir. Bu tez, çeşitli makine öğrenmesi yöntemleri kullanılarak bir şarkının hit veya hit olmayan olarak sınıflandırılmasını inceler. Spotify tarafından sağlanan temel müzikal özniteliklerin yanı sıra, müzik teorisinden yararlanılarak müzik dosyalarından elde edilen akor ve melodilere dayanan daha karmaşık öznitelikler tasarlandı. Akora dayalı öznitelikleri ton uyumuna dayalı önemli akor yürüyüşleri kullanılarak oluşturulurken, melodiye dayalı öznitelikler sezgisel bir şekilde tasarlanmıştır. Ayrıca, dans ve rock müzik türlerinden hem hit hem hit olmayan şarkılar kullanılarak yeni veri setleri oluşturulmuştur. Temel müzik özniteliklerinin akor ve melodi bazlı özniteliklerle birlikte kullanılmasıyla ortaya çıkan sonuçlar, bu özniteliklerin hit şarkı tahmin performansında iyileşmeye yol açabileceğini göstermektedir. Rock şarkıları için, Rassal Orman sınıflandırıcısı bu öznitelikleri kullanarak sonuçlarda istatistiksel olarak anlamlı bir gelişme sağlamıştır. Destek Vektör Makinesi sınıflandırıcısı ile belirli bir öznitelik kombinasyonunun kullanılmasının, hit dans şarkıları tahmininin doğruluk puanını arttırdığı gözlemlenmiştir. Ayrıca, bu çalışmada kullanılan tüm öznitelikler bu çalışmanın son bölümünde her veri kümesi için analiz edilmiştir.","Music industry is making big investments every year to produce hit songs. The increasing number of songs available through digital platforms can enable the development of learning models for predicting hit songs and identifying their common features. This thesis investigates classifying a song as hit or non-hit by using various machine learning methods. Besides the basic musical features provided by Spotify, more complex features based on the chords and melody extracted from the music files by utilizing music theory information are designed. Chord based features are created using the important chord progressions based on tonal harmony, while the features based on melody are designed in an intuitive way. In addition, new benchmark datasets are created by using both hit and non-hit songs from dance and rock music genres. The results show that using chord and melody based features with the basic musical features may lead to an improvement in hit song prediction performance. For rock songs, the Random Forest classifier achieves a significant improvement on the results by using these features. It is also observed that using a specific feature combination with Support Vector Machine classifier increases the accuracy score of hit dance song prediction. Furthermore, all the features used in this study are analyzed in the last part of this study for each dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternetin erişilebilirliği, engelli insanların konforlu bir şekilde İnternet kullanımı için oldukça önemlidir. Buradan yola çıkarak, bu tezin amacı havayolu web sitelerinde bulunan bilet alma akışlarının engelli kişilerin erişimine ne kadar uygun olduğunu ölçmektir. Bu hedef doğrultusunda, Achecker isminde bir otomatik erişilebilirlik test aracı ile 27 havayolu web sitesinin biletleme akışı test edilmiştir. Test edilen biletleme akışlarında bulunan sayfalar; anasayfa, uçuş listeleme sayfası, uçuş listesi özet sayfası, ekstra hizmetler sayfası, profil sayfası ve ödeme sayfasıdır. Otomatik test sonuçları ve havayollarının farklı özellikleri dikkate alınarak, havayolu özelliklerinin erişilebilirlik performansları ile ilişkisi olup olmadığını tespit etmek için istatistiksel analiz yapılmıştır. Analiz sonuçlarına göre, havayolunun Amerika'ya uçuşunun bulunması ve cirosunun, havayolu web sitesi erişilebilirlik performansı ile anlamlı kolerasyonu olduğu belirlenmiştir. Havayolunun elde ettiği kâr ve otomatik testlerin koşumu sırasında kullanılan kaynak kodu tipinin de belli ölçüde anlamlı kolerasyonunun bulunduğu saptanmıştır. Bu sonuçlardan havayolu websitelerinin erişilebilirlik standartlarına uyması için uygun önleyici yasal tedbirlerin gerekli olduğu sonucu çıkarılabilir. Amerika gibi diğer ülkeler de gerekli yasalar aracılığı ile havayolu websitelerinin engelliler için daha erişilebilir hale gelmesini sağlayabilirler.","Website accessibility is very important for disabled people to use the Internet. In the light of this matter, the objective of this thesis is to measure the accessibility performances of airline website online ticketing flows for handicapped people. For this purpose, automated accessibility testing was performed for 27 airline websites with automated accessibility checker called Achecker. The tested ticketing flows of websites consisted of homepage, availability page, availability summary page, extra services page, profile page and payment page. According to the automated test results and the specifications of the airlines, statistical analyses were performed in order to see if any of the specifications has a relation with the accessibility performance of an airline. Analyses results show that having a flight to the United States and revenue have significant correlation with the accessibility performance of an airline. Two other specifications which are the profit and type of codebase used for testing also appeared to be significant to some extent despite being less significant than the former two specifications. Thus, it can be concluded that taking appropriate preventive legal measures seem to be a way for airline websites to comply more with accessibility standards. Like the United States, other countries who want to provide more accessible airline websites for disabled people may enact the relevant laws in order to force airlines to conform the accessibility standards."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Aletli yürüme bantları ve kameralı hareket yakalama sistemleri yürüme analizi için altın standart olarak kabul edilmektedir, fakat yüksek maliyetlidirler ve yalnızca hastanelerde veya yürüme kliniklerinde bulunurlar. Bu nedenle, hastane dışı kullanıma uygun mobil ve yaygın bir alternatif gereklilik haline gelmiştir. Giyilebilir hareket algılayıcılarının hareket analizi için kullanımının literatürde ümit verici örnekleri olmasına rağmen, çoğu çalışma veri toplama ve algılayıcıların yerleştirilmesi ile ilgili problemleri göz ardı etmektedir. Dahası, tipik varsayımların bazıları patolojik yürüme ile uyum göstermemekte ve hataları artırmaktadır. Bu zorlukları aşmak amacıyla, en güncel yürüme analizi yöntemlerini ileriye taşıyan giyilebilir hareket algılayıcılı bir hareket analizi sistemi öneriyoruz. Sistemimiz birçok veri toplama zorluğu ile baş edebilmekte ve patolojik yürüme koşullarında da çalışabilmektedir. Sistem zengin bir yürüme parametreleri kümesi çıkartabilmekte ve kolayca yorumlanabilen adım profili görselleştirmeleri üretebilmektedir. Sistemimizin başarımını doğrulamak ve klinik kullanıma uygunluğunu vurgulamak için 60'tan fazla nörolojik hastadan yürüme verisi topladık ve nörolojik hastalıklara özgü anahtar yürüme parametrelerini belirlemek adına bir öznitelik seçme çalışması yürüttük. Ayrıca, yürüme parametrelerinin yüksek seviyeli bir çıkarım problemi için uygunluğunu göstermek amacıyla, derin öğrenme yöntemlerinden faydalanan bir otomatik düşme riski değerlendirmesi çözümü önerdik. Elde edilen sınıflandırma başarısı var olan çözümlerden daha üstündür. Bu katkılara ek olarak, düşme riski yöntemlerinin yaygın bir sağlık hizmetine nasıl dönüştürülebileceğini gösteren, bir dizi kullanıcının aynı anda ve gerçekçi ortamlarda kullanabileceği bir hesaplama ve iletişim mimarisinin tasarımını ve değerlendirmesini sunduk.","The gold standards for gait analysis are instrumented walkways and camera-based motion capture systems which are highly accurate, but require costly infrastructure and are only available in hospitals and specialized gait clinics. Hence, a mobile and pervasive alternative suitable for non-hospital settings is a clinical necessity. Using wearable inertial sensors for gait analysis has been explored in the literature with promising results; however, the majority of the existing work do not consider realistic conditions where data collection and sensor placement imperfections are imminent. Moreover, some of the typical underlying assumptions are not compatible with pathological gait, decreasing the accuracy. To overcome these challenges, we propose a wearable inertial sensor-based gait analysis system that builds upon the state-of-the-art gait analysis methods. Our system copes with various data collection difficulties and relaxes some of the assumptions invalid for pathological gait. The system is able to extract a rich set of standard gait parameters and produce average stride profile visualizations, easily interpretable by clinicians. To validate the success of our system and highlight its clinical applicability, we collected a gait dataset from more than 60 neurological disorder patients and conducted a feature selection study to identify the key gait parameters in neurological disorders. To demonstrate how the extracted gait parameters can be used for a higher level inference problem, we also introduce an automated fall risk assessment solution, exploiting deep learning methods. The achieved classification accuracies outperform the existing solutions. As a final contribution, we present the design and evaluation of a computing and communication architecture that shows how the fall risk assessment methods can be transformed into a pervasive healthcare service that can handle numerous users concurrently under realistic conditions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde masa üstüne yerleştirilen nesneler üzerinde keşif yapan bir robotun eylem parametrelerini efektif bir şekilde düzenleyerek, farklı robot eylemlerini keşfedebileceği bir hesaplamalı model önerilmektedir. Bu amaç özelinde simüle edilmiş bir robot ortamı kullanılmış, ve robot eylem parametre uzayını, eylem sonucu gözlemlenen sonuçlara göre organize etmektedir. Aynı zamanda robot, kendi eylemlerinin sonuçlarını tahmin edebilmek adına farklı modeller de eğitmektedir. İçsel motivasyon yaklaşımıyla robot eylemlerini potansiyel olarak yüksek öğrenme gelişimi verecek bölgelerden seçmektedir. Öğrenme gelişimi tabanlı eylem seçimine ek olarak, yapılan çalışma sonucu oluşan eylem parametre bölgeleri farklı eylem sınıflarına tekabül etmektedir ve bunlara basit eylemler adı verilmektedir. Yapılan çalışma sonucu, robot zorluk seviyesi giderek artan basit eylemler öğrenmiş ve bu eylemlerin henüz tamamlanmadan sonuçlarını tahmin edebilme yeteneğini geliştirmiştir. Bunun yanında, elde edilen sonuçlar çocuk gelişimi alanındaki bulgularla paralellik göstermekte, çocuk gelişiminde kavrama eyleminin neden itme eylemine göre daha erken öğrenildiğine dair fikir verebilmektedir. Son olarak, bir eylemi yapabilecek yeteneklere sahip olmak ile aynı eylemin sonuç tahmininin yapılabilmesi arasındaki ilişkiyi de açıklayabilmektedir.","This thesis proposes an effective action parameter exploration mechanism that enables efficient discovery of robot actions through interacting with objects in a simulated table-top environment. For this, the robot organizes its action parameter space based on the generated effects in the environment and learns forward models for predicting consequences of its actions. Following the Intrinsic Motivation approach, the robot samples the action parameters from the regions that are expected to yield high learning progress (LP). In addition to the LP-based action sampling, our method uses a novel parameter space organization scheme to form regions that naturally correspond to qualitatively different action classes, which might be also called action primitives. The proposed method enabled the robot to discover a number of lateralized movement primitives and to acquire the capability of prediction the consequences of these primitives. Furthermore, our findings have some parallels with data from infant development, and might explain the reasons behind the earlier development of grasp compared to push action in infants, and the reasons behind the correspondence between development of action production and prediction."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geçtiğimiz yıllardan bu yana oyunlar makine öğrenmesi çalışmaları için önemli bir test yatağı olmaktadır. Satranç, Dama, Go ve Poker oyunlarında pekiştirmeleri öğrenme algoritmaları kapsamında derin yapay sinir ağlarıyla fonksiyon tahminlemeyle kayda değer ilerlemeler yapılmıştır. Yapay zekalar, oyunlarda dünyadaki en iyi insan oyuncuları yenerek şampiyon veya süper insan seviyelerine ulaşmıştır. Bu çalışma Türk taş oyunu Okey'e odaklanır ve derin pekiştirmeli öğrenmenin yönlendirmesiyle yapay zekanın bu oyunu öğrenebileceğini ispatlamayı amaçlar. Okey'in kısmi gözlemlenebilir ortamı, olasılıksal doğası ve birbirleriyle tam rekabet içinde olan oyuncularıyla kendine özgü bir yapısı vardır. Bu çalışma öğrenen bir yapay zekanın hiçbir doğrudan yönlendirme olmadan, sadece taş çekerken ve taş atarken her adımda ödül sinyalleri alarak, tez boyunca anlatılan olasılıksal davranış meyilleriyle, aktör-kritik algoritmasıyla, önceliklendirilmiş tecrübe tekrarlarıyla oyunu öğrenmesine odaklanmaktadır. Öğrenen yapay zeka, özel tasarlanmış 2 kişilik Okey'i Gym ortamında rastgele oynayan bilgisayar rakibine karşı oynar. Oyun çatısı içinde, öğrenen yapay zeka, yere atılan taşlardan ya da ortadaki taşlardan rastgele çeken ve her zaman elinde boşta olan taşlardan atan bilgisayar rakibine karşı oynar ve bu yapısı onu, öğrenen yapay zeka için yeterince zorlu kılar. Yapılan deneyler boyunca elde edilen sonuçlar bu çalışmada sunulmaktadır ve yapay zekanın rakibine karşı kazanma oranları bu çalışmanın elde ettiği başarı seviyesi olarak görülebilir. Literatürde yapılan kapsamlı araştırma sonucunda bu çalışma, pekiştirmeli öğrenme kullanılarak Okey oyununu oynatan ilk çalışma olarak gösterilebilir.","Games are important test beds for machine learning studies for over the last decades. Significant progress has been made in games such as Checkers, Chess, Go and Poker with the help of deep neural networks used for function approximation within reinforcement learning algorithms. Agents were able to reach champion or superhuman levels by beating the top players of the world. This study focuses on the Turkish tile game Okey and aims to prove that agents can learn to play this game with the guidance of deep reinforcement learning. Okey has a unique setting where there is partially observable environment, stochastic nature and multiple players which are fully competitive. The study focuses on teaching a learning agent to play the game without any direct supervision, solely by receiving reward signals at each step for drawing and discarding tiles, with the help of stochastic policy gradients, actor-critic algorithm, prioritized experience replays which are explained thoroughly in this thesis. The learning agent plays against a random computer opponent in the custom Gym environment created for the Okey game as a two-player game version. Within the game framework, learning agent plays against an opponent that draws a tile from discarded tiles of the agent or from the center tile randomly, and always discards from the free tiles which makes it compelling enough for the learning agent. The results of the games through the experiments are reflected and win rates of the agent against the computer opponent can be considered as the achieved success of this study. Extensive research on the existing literature shows that this is the first study that uses reinforcement learning to play the game of Okey."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"LPWAN içerisinde IoT konseptine uygun olarak geliştirilmiş olan teknolojilerden bir tanesi de LoRaWAN protokolüdür. Bu protokol LoRa modulasyonu ile birlikte çalışmaktadır. Şimdiye kadar bu protokol ile ilgili yapılan çalışmalar sadece yukarı yönlü iletişimi kapsıyordu. Ayrıca, bu protokol içerisinde kullanılan saf ALOHA tipindeki MAC protokolünün performansı tam olarak gözlemlenmiyordu. Son zamanlarda, aşağı yönlü iletişimi de kapsayan araştırmalar saf ALOHA tipindeki MAC protokolünün ve aşağı yonlü trafiğin ağın ölçeklendirmesi üzerinde negatif bir etkisi olduğu sonucunu ortaya çıkarmıştır. Bu negatif etkileri LoRaWAN protokolü içerisinde aza indirgiyebilmek için bir çözüm sunulmuştur. Bu çözüm ağ geçidi ile son cihazların senkronize bir şekilde çalışmasına yarayan bir takvimlendirme metodudur. Ayrıca, önerilen çözüm ağ geçidinden son cihazlara yollanan, aşağı yönde ki trafiği oluşturan, bilgilendirme mesajlarının toplu yollanmasını içeren iki tane de farklı yöntem sunmaktadır. Önerilen çözüm, çeşitli deney senaryolarıyla çalıştırıldığında, aşağı yöndeki trafiği azalttığı ve bir ağ geçidinin hizmet verebileceği son cihaz kapasitesini artırdığı gözlemlenmiştir. Başka bir deyişle, önerilen çözümün LoRaWAN'ın ölçeklendirilmesinde pozitif yönlü bir katkısı olmuştur.","One of the technologies developed in LPWAN according to the IoT concept is the LoRaWAN protocol. This protocol works together with LoRa modulation. So far, studies on this protocol included only uplink communication. Moreover, the performance of the pure ALOHA type MAC protocol used in this protocol was not fully observed. Recently, investigations, including downlink communication, have revealed that the pure ALOHA type MAC protocol and downlink traffic have a negative impact on network scaling. A solution is provided to minimize these negative effects in the LoRaWAN protocol. This solution is a scheduling method for synchronizing the gateway with the end devices. In addition, the proposed solution provides two different methods of sending aggregated acknowledgment messages, which are sent to the last devices from the gateway. This proposed solution has been observed to reduce downlink traffic when it is run with various test scenarios and to increase the capacity of the last device to which a gateway can serve. In other words, the proposed solution had a positive contribution to LoRaWAN scaling."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı telefonların ve mobil uygulamaların ortaya çıkışından beri özel hayatın gizliliği ile ilgili kaygılar hızla artmaktadır. Günümüzde, bir milyardan fazla insan akıllı telefon kullanmaktadır. Günlük bazda milyonlarca farklı uygulama yüklenmekte ve kullanılmaktadır. Teknik mimarilerinden dolayı, bu uygulamalar işletim sistemindeki farklı kaynakları kullanmak zorundadır. Bu işletim sistemi; Android, IOS, Windows, ya da herhangi bir mobil işletim sisteminden hangisi olursa olsun; uygulamalar telefondaki verilere erişmek için ekstra izin almaya ihtiyaç duyabilir. Hatta çoğunlukla da pazarlama amaçlı kişisel veri toplamak için gereğinden fazla erişim hakkı isteyebilirler. Bu çalışmada Google Play Store'daki Android uygulamaları incelenmiştir. Uygulamada istenen izinler, yüklenme sayısı, incelemeler ve farklı birçok detay gibi parametreleri içeren 5.000'den fazla uygulama hakkındaki detayları toplamak için Python veri kazıma kodu kullanılmıştır. Daha sonrasında veriler SPSS ve AMOS'ta analiz edilmiştir. Analizler; temel göstergelerden tek yönlü varyans analizine, çoklu regresyon ve korelasyona kadar farklılaşmaktadır. Ayrıca, verilerin dağılımını göstermek için analizlere ek olarak grafiklerden de yararlanılmıştır. Veri analizleri, hipotezleri yüksek anlamlılıkla ispatlamış ve çok yararlı olmuştur. Sonuçlar, bir uygulamanın gerektirdiği izin sayısı ile inceleme sayısı, uygulama yüklenme sayısı ve inceleme skoru gibi farklı değişkenlerle ilişkili olduğunu göstermektedir.","Privacy Concerns on Mobile Applications Vis-À-Vis the Number of Permissions Requested by Android Apps Since the introduction of smartphones and applications, privacy concerns have been rapidly rising. Today, over one billion people use smartphones with millions of apps. These apps may request different permissions from users. Whether it's Android, IOS, Windows, or any other mobile operating system, apps may mostly request permissions more than necessary. In this study, Android apps from Google Play Store are examined. Python scraping code was used to collect details for over 5,000 apps including different parameters such as permissions requested and number of installs. The data was then analyzed using SPSS, AMOS, and Power BI. The analyses made varied from simple descriptive, to one-way ANOVA, multiple regression, and correlation. Also, graphs were constructed. Data analysis was fruitful and different hypothesis were significantly. The results showed that number of permissions requested is correlated with several other variables such as number of reviews, number of installs, and review score. Also, ANOVA tests showed that different developers and categories can possess statistically different number of permissions requested. The study has several limitations such as the IP address of the computer used in Turkey. Turkish apps were suggested. Also, the number of apps collected was 5,264 which relative to total number of apps on the store might be considered as small and non-representative."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"5G tanımında sunulmuş, uyulması gereken zorlayıcı şartlara ayak uydurabilmek için tasarlanan gelecek nesil mobil şebekelere aday gösterilen mimarilerden biri de Bulut Radyo Erişim şebekeleridir (CloudRAN). Bu mimari iki temel ilke üzerine kuruludur; ilki baz istasyonu fonksiyonlarının radyo ve temel bant işlemleri olarak ayrıştırılması, ikincisi ise şebekedeki bütün temel bant ünitelerinin (BBU) temel bant ünite havuzu (BBU pool) diye adlandırılan merkezi bir birimde sanallaştırılarak gruplanmasıdır. Koordine çoklu nokta tekniği (CoMP) gelişmiş derecede bir radyo koordinasyon tekniğidir. Sinyal kalitesini arttırmak ve hücreler arası girişimi azaltmak amacıyla tek bir mobil cihaz için birden fazla baz istasyonu kullanma prensibine dayanır. şu anki mobil şebekelerde aktif bir şekilde kullanılmasına rağmen, ortaklaşa iletim ve alım modları Bulut Radyo Erişim şebekelerine uyarlandığında hem kolaylıklar hem de sorunlar ortaya çıkmaktadır. En önemli problem de işlenmemiş IQ sinyallerinin sanal temel bant üniteleri arasında karşılıklı değişiminden kaynaklanan, bant genişliği üzerindeki baskının daha da artmasıdır. Bu çalışmada, daha verimli yerleşim metodlarına ulaşmak için, sanal temel bant ünitelerinin havuzdaki fiziksel makinelere birbirleri arasındaki koordine çoklu nokta ilişkileri gözetilerek paylaştırılması konusu araştırılmaktadır. Verimli bir yerleşme planı için varsayılan yaklaşım, aynı fiziksel makinedeki sanal üniteler arasındaki iletişimin, farklı fiziksel makineler arasında olana kıyasla havuzun şebeke kaynaklarını daha az kullanacağı yönündedir. Bu önseziden yola çıkarak en iyi yerleşim planı matematiksel olarak formüle dökülmekte, ardından en iyi sonuca ulaşmanın hesaplama zorluğunun görülmesiyle en iyiye yakın sonuçları daha makul zamanlarda üreten bir metod geliştirilmektedir.","Cloud Radio Access Network (CloudRAN) is proposed as a candidate architecture for future mobile networks in order to meet the challenging requirements presented in 5G specifications. The key rationale behind CloudRAN is two fundamental principles; the first one is splitting the base station functionality into two as radio and baseband processing, and the second one is grouping those baseband units (BBU) into centralized and virtualized data centers called BBU pools. CoMP (Coordinated Multipoint) is an advanced radio coordination technique taking advantage of using multiple base stations for a single user equipment to improve signal quality and reduce interference. Despite being effectively utilized in current mobile networks, integrating CoMP to the CloudRAN, especially for joint transmission and reception modes, reveals both conveniences and challenges. The most important problem exposes itself as increased pressure over bandwidth requirements due to exchange of raw IQ signals between virtual BBUs. In this study, the placement of virtual BBUs into physical nodes of BBU pool is explored to discover efficient allocation methods with respect to given CoMP sets. The method for creating an efficient allocation follows the intuition that data exchange between two BBUs causes less stress over the network resources of the BBU pool when they are hosted on the same physical machine, as opposed to exchanging data across different machines. The optimal placement around this insight is formulated and seeing the computational complexity of finding the optimal solution, a heuristic method is developed to produce close to optimal results in polynomial time."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Güven, bankacılık sektörü için müşteri ilişkilerinde en önemli faktörlerden biridir. Neobanklar (bir diğer adıyla yeni nesil bankalar) finansal teknolojiler alanındaki en yeni oyunculardır ve hızlı adapte ettikleri yeni teknolojiler ve sundukları daha iyi müşteri tecrübesi ile geleneksel bankalara meydan okumaktadırlar. Güven faktörünün, kullanıcıların neobankları kullanıp kullanmamasındaki etkisi neobanklar için kritiktir çünkü, neobanklar bankacılık lisansı olmayan, üçüncü taraf olarak işlemleri yöneten teknoloji şirketleridir ve geleneksel bankalarla aynı yönetmeliklere tabi değildirler. Bu araştırma iki ana şeyi incelemektedir; birincisi, algılanan itibar ve algılanan uygulama kalitesinin, güven faktörünün üç boyutunu (yeterlilik, yardımseverlik ve dürüstlük) nasıl etkilediği ve ikincisi ise bu güven boyutlarının iki önemli sonucu nasıl etkilediği; kullanılan neobanka bağlı kalma isteği ve neobank hakkındaki risk algısı. Bu çalışma sonucu göstermektedir ki, algılanan itibar ve algılanan uygulama kalitesi, güveni önemli ölçüde etkilemektedir ve aynı zamanda, kullanıcıların bir neobanka bağlı kalma isteği algılanan güven ve algılanan riskten etkilenmektedir. Ayrıca, algılanan kalite, algılanan itibarı olumlu yönde etkilemektedir ve algılanan itibar ile algılanan risk arasında negatif bir ilişki vardır.","Trust is one of the most important factors for a good customer relationship in banking industry. Neobanks (also known as challenger banks) are the new players of fintech ecosystem and they challenge the traditional banks by offering state-of-the-art technologies and creating a better user experience. The importance of trust in users; decision to use fintech is a significant interest to neobanks because they are digital only companies without a physical branch network and they are not regulated as traditional banks. This empirical study primarily explores how reputation and application quality affect trust formation and secondly, how the trust dimensions impact willingness to depend on the neobank and perceived risk. The results indicate that perceived reputation and perceived app quality significantly improves trust and trust reduces perceived risk while positively influencing users' willingness to depend on a neobank. Additionally, perceived app quality positively effects perceived reputation and perceived reputation lowers perceived risk."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Protein-ligand etkileşimi canlı organizmalarda çok önemli bir rol oynar, bu nedenle çeşitli disiplinlerden birçok araştırmacının ilgisini çeker. Araştırmacılara istenilen formatta bilgi sağlayan protein-ligand etkileşim veritabanları vardır. Bu veritabanları manuel olarak biyomedikal literatüründen çıkarılmaktadır ancak biyomedikal alandaki yayınların sayısındaki artıştan dolayı bu işlem her geçen gün daha da zorlaşmaktadır, dolayısıyla otomatik olarak protein-ligand etkileşimlerini metinlerden çıkaran bir sisteme ihtiyaç duyulmuştur. Bu tezin amacı bu ihtiyacı derin öğrenme modelleri ile karşılamaktır. Tez, Evrişimli Sinir Ağı (CNN) ve Uzun/Kısa Süreli Belleğin (LSTM) protein-ligand etkileşimi için performans analizini içerir. Ayrıca, farklı verilerin modellerin performansına etkisi bakımından karşılaştırılması da tez kapsamındadır. BioCreative VI ChemProt yarışması için oluşturulan derlemi, modellerimizin eğitimi ve değerlendirilmesi için veri seti olarak seçildi. Kelime temsilleri, mesafe temsilleri, cümle öğelerinin temsilleri ve iç dış başlangıç öbek temsilleri modelde özellik olarak kullanılmaktadır. Grid arama algoritması, deneylerde her model için optimal hiperparametreleri bulmak için uygulanır. En iyi modeller ve girdi gösterimleri geliştirme seti kullanılarak seçilir ve sonra test seti ile değerlendirilir. Test setindeki sonuçlara dayanarak BiLSTM'in her durumda CNN'den daha iyi performans gösterdiği sonucuna vardık.","Protein-ligand interactions play crucial roles in living organisms, thus they attract many researchers from various disciplines. There are protein-ligand interaction databases that provide information to researchers in a suitable format. These databases extract the interactions manually from biomedical literature but the extraction process is becoming harder each day because of the increase in the number of biomedical publication, thereby the need for an automated extraction system has arisen. The aim of this thesis is to fulfill this need via deep learning models. This thesis includes performance analysis of cnn and bilstm Networks for the task of protein-ligand interaction extraction. Comparison of features in terms of their effect on the performance of the models is also included in the thesis. The gold standard corpus that is created for BioCreative VI ChemProt task is selected as our dataset for training and evaluation of our models. Word embeddings, distance embeddings, pos tags and iob chunk tags are used as features in the models. The grid search algorithm is applied to find the optimal hyperparameters for each model in the experiments. The best models and input representations are selected via using the development set then they are evaluated on the test set. Based on the results on the test set, we concluded that bilstm performs better than cnn for each evaluated feature setting."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir kelimeyi matematiksel olarak temsil etmek doğal dil işleme uygulamarında önemli bir konudur. Bengio ve arkadaşlarının 2003'te basit sinir ağları kullanarak kelime vektör temsilleri elde etmelerinin ardından, kelimeleri sürekli vektör uzayında temsil etmek daha popüler hale gelmiştir. Mikolov ve arkadaşları 2013'te, word2vec adında yeni bir yöntem öne sürerek, kelime gömevlerinin sözdizimsel ve anlamsal benzerlikleri yakalayabildiğini gösterdi. O zamandan beri İngilizce için birçok yöntem geliştirildi ve uygulamalar yapıldı. Ancak, Türkçe'de kelime temsilleri üzerine yapılan sadece birkaç çalışma vardır. Bu çalışmada kelime gömevi yöntemlerinin hem Türkçe hem de İngilizce'de nasıl çalıştığını analiz etmeyi amaçladık. Word2vec kelime gömevi modeline odaklandık ve kelime temsillerinin kalitesini artırmak için bu modeli geliştirmeye çalıştık. Ek olarak, farklı pencere ve vektör boyutlarına sahip birçok model eğittik. Farklı konfigürasyonların kelime temsillerinin kalitesi üzerindeki etkisini hem içsel hem de dışsal olarak analiz ettik. İçsel değerlendirme için kelime benzeşim görevlerini ve dışsal değerlendirme için ise kelime benzerlik görevlerini kullandık. Sonuç olarak, önerilen modellerimizin Türkçe için, çoğu benzeşim kategorisinde, orijinal word2vec modeline göre daha iyi performans sergilediği gözlemlendi. Ayrıca, pencere ve vektör boyutlarının arttırılmasının, farklı benzeşim kategorilerinde farklı sonuçlar verdiğini gözlemledik. Pencere ve vektör boyutundaki artışın her zaman olumlu sonuçlanmadığını gördük. Bazı kelime benzeşim ve kelime benzerliği görevleri için pencere ve vektör boyutu arttıkça sonuçların kötüleştiğini gözlemledik.","In natural language processing tasks, representing a word is an important issue. After Bengio et al. introduced a simple neural network language model that learns word vector representations in 2003, representing words in continuous vector space has become more popular. Mikolov et al. introduced a method named word2vec and showed that word embedding could capture meaningful syntactic and semantic similarities in 2013. Many methods and implementations have been proposed for English since then. However, there are only a few studies on word representations in Turkish. In this study, we aimed to understand and analyze how word embedding models work on both Turkish and English. We focused on the word2vec word embedding model and tried to modify it to improve the quality of word representations. Additionally, we trained many models with different window sizes and dimensions. The impact of different configurations on the quality of word representations was analyzed both intrinsically and extrinsically. We reported the accuracy on word analogy tasks for intrinsic evaluation and word similarity tasks for extrinsic evaluation. Our results show that our proposed models perform better on most of the word analogy task categories for Turkish. We also showed that increasing window sizes and dimensions does not always affect the accuracy in a positive direction. For some analogy and word similarity tasks, it affects negatively."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yürüme karakteristiklerinin takibi ortopedi, spor, rehabilitasyon ve nöroloji gibi birçok alanda kullanılan önemli bir araçtır. Mevcut yürüme analizi teknikleri klinik bir ortamı ve birçok ekipmanı gerektirmektedir. Bu çalışmada, göze batmayan ve konforlu bir yürüme analizi sistemi sunulmuştur. İvmeölçer ve jiroskop gibi gömülü sensörlere sahip olan akıllı saatler üç temel yürüme parametresinin tespiti için kullanılmıştır: adım uzunluğu, salınım süresi ve basma süresi. Farklı yaşlardan ve cinsiyetlerden, sağlıklı ve gönüllü 26 kişiden klinik ortamda veri toplanmıştır. Katılımcıların her iki bileklerine de birer akıllı saat takılmış, ivmeölçer ve jiroskop sensörlerinden veri toplanmıştır. Toplanan veri bir ön işlemden geçirildikten sonra adım özellikleri elde edilmiştir. İlgili yürüme parametreleri çeşitli regresyon modelleri kullanılarak tahmin edilmeye çalışılmış ve klinik tedavi uzmanının altın standart yürüme yolunu kullanarak elde ettiği referans değerlerle karşılaştırılmıştır. Lineer Regresyon (LR), Gaussian Proses Regresyonu (GPR), Destek Vektör Makinesi (SVM) ve Regresyon Ağacı makine öğrenimi algoritmaları ve Konvolüsyonel Sinir Ağı (CNN) ve Uzun Kısa Süreli Bellek (LSTM) sinir ağı mimarisini içeren teknikler veriye uygun bir model geliştirmek için kullanılmıştır. Modellerin performansı temel bir hata ölçüm parametresi olan Kök Ortalama Kare Hatası (RMSE) ile ölçülmüştür. Veriye en uygun model Gaussian Proses Regresyonu (GPR) olarak tespit edilmiştir. İlgili modelde adım uzunluğu 5.29 cm Kök Ortalama Kare Hata değeri ile hesaplanmıştır. Sensörlerin yerleştirildikleri konumun literatürde mevcut çalışmalara göre daha az kullanışlı bir yerde, yani bileklerde olmasına karşın, akıllı saatlerle yapılan yürüme analizinde umut verici sonuçlar ortaya çıkmış ve gelecek çalışmalar için teşvik edici nitelikte olmuştur.","Monitoring gait characteristics is an important tool used in many areas including orthopedics, sports, rehabilitation and neurology. Current methods applied to analyze the gait need clinical settings and equipments for measuring gait parameters. In this study, we propose an unobtrusive and comfortable system to perform gait analysis. Smartwatches equipped with embedded sensors including accelerometer and gyroscope are used to extract three main parameters of gait: step length, swing time and stance time. Data is collected from 26 healthy and volunteer participants with different ages and genders in clinical settings. Subjects wore smartwatches on both wrists, data is collected from two sensors: accelerometer and gyroscope. The data is preprocessed and step features are extracted. Relevant gait parameters are estimated using various regression models and compared with the ground truth data coming from the clinician using the golden standard instrumented walkway. Four machine learning algorithms including Linear Regression (LR), Gaussian Process Regression (GPR), Support Vector Machine (SVM) and Regression Tree, and two neural network architectures Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) are used to fit data. Performance of the models is measured using a basic error metric, i.e. RMSE. The best model fitting the data is found as GPR. Its RMSE value for the step length (cm) estimation is calculated as 5.29 cm. Besides the placement of sensors is less convenient than the state of the art studies, the gait analysis with smartwatches gives promising results and encourages for extended future studies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geleneksel ağlar için hizmet kalitesi farkında yönlendirme günümüzde dahi çözülemeyen bir sorun olarak karşımıza çıkmaktadır. Bunun başlıca sebebi geleneksel ağ mimarilerinin yeterince esnek olmayışıdır. Yazılım tabanlı ağlar programlanabilir merkezi kontrol birimi kullanarak esnek bir mimari sağlamaktadırlar. Bu nedenle, yazılım tabanlı ağlar hizmet kalitesi farkında yönlendirme uygulamaları için en uygun ağ mimarisidir. Fakat ağda oluşabilecek herhangi bir güvenlik açığı kullanıcıların hizmet kalitesini olumsuz yönde etkileyebilir. Bu nedenle, hizmet kalitesi farkında yönlendirme uygulamaları kimlik doğrulama mekanizmasına ihtiyaç duyar. Bu tezde, Kimlik Doğrulama Tabanlı Hizmet Kalitesi Farkında Yönlendirme sistemini öneriyoruz. Önerilen sistem, kimlik doğrulama uygulaması ve yönlendirme uygulaması adında iki uygulamadan oluşmaktadır. Kimlik doğrulama uygulaması kullanıcıların özelliklerine bağlı olarak kullanıcıların kimliklerini doğrular. Yönlendirme uygulaması ise kimliği doğrulanmış kullanıcıların yüksek kalite yönlendirme hizmeti almasını sağlar. Bu tezde, ayrıca, önerilen sistemin uygulanabilirliğini göstermek için güvenlik ve performans analizleri de sunulmuştur.","Quality of Service (QoS) aware routing is an ongoing and major problem for traditional networks since they are not able to manage network traffic for an immense variety of users due to their inflexible and static architectures. Software Defined Networking (SDN) has emerged to remove these limitations by separating the control plane and the data plane to provide centralized control with the help of programmable controllers. Such improvements also make SDN more flexible than traditional networks in terms of achieving QoS-aware routing. However, providing QoS-aware routing in SDN without using any security mechanism may become a challenging issue. For instance, malicious users in the network may escalate their privileges to monopolize resource utilization. The provision of an authentication mechanism that jointly works with QoS-aware routing is expected to solve the issue. In this thesis, we propose an Authenticated QoS-Aware Routing (AQoSAR) for Software Defined Networks to determine routing paths of a single user and a group of users in an authenticated manner. AQoSAR consists of the authentication application and the routing application. In the authentication application, we employ Ciphertext Policy Attribute Based Encryption since it easily operates with a huge variety of users by defining attributes such as QoS-aware routing metrics. In the routing application, we propose a routing approach based on a metric list rather than a single metric for determining the QoS level of users. To show the applicability of AQoSAR, the security analysis and the performance analysis are presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet ortamında görüntülerin ulaşılabilirliğinin artması ile görüntü ile ilgili cümlelerin belirlenmesi önemli bir problem haline gelmiştir. Bu araştırma alanı, haber görüntü altyazılarının otomatik oluşturulması ve özetleme konusunda haber yayıncıları için de önemlidir. Hakkında birçok çalışma yapılmış olsa da görüntü altyazılama hala zor bir problemdir. Görüntü altyazılama üzerine yapılmış önceki çalışmalar, genellikle görüntüler için yeni altyazılar üretmek üzerine odaklanmıştır. Haber metninden görüntü için en uygun cümleleri seçme problemi ilk defa bu çalışmada ele alınmıştır ve sıfırdan bir altyazı oluşturmaya çalışmak yerine görüntü ile ilgili cümleleri bulmaya çalıştığımız için yenidir. Bu teknik, haber ile resim yazısı arasındaki ilişkiyi kaybetmemeye yardımcı olur. Haberlerin sadece metin kısımlarını içeren CNN haber veri setini baz olarak kullandık ve bu veri setini haberlerin görüntülerini toplayarak genişlettik. Tf-Idf ve Word2Vec vektörleri kosinüs ve SEMILAR cümleden cümleye benzerlik yöntemlerini kullanarak haberin görüntüsü ve cümleleri için iki sınıflı referans altyapısı oluşturduk. HOG ve BOVW görüntü tanımlayıcıları ve Word2Vec metin özellik çıkarma yöntemlerini kullandık. Önerdiğimiz sistemin performansını ölçmek için Naive Bayes, k-En Yakın Komşu ve Rassal Karar Ormanı yöntemlerini uyguladık. Ayrıca, görüntü ve metin özelliklerini eşit ağırlıkla değerlendirmek için görüntü özellikleri için PCA boyut azaltma yöntemini uyguladık. Aynı zamanda, ikili sınıfların dengesiz dağılımını çözmek için de deneyler yaptık. Deney sonuçları, HOG özellik seçimi ile Naive Bayes sınıflandırıcısının daha iyi sonuçlar verdiğini göstermektedir.","With the increasing availability of images on the web, identifying image related sentences has become an important problem. This research area is also important for the news publishing community for automatic captioning of news images and summarization. Although a large body of research has been devoted to image captioning, it is still a challenging problem. Previous works on image captioning mostly focus on generating new captions for the images. The problem of identifying image related sentences in news articles is discussed in this thesis for the ﬁrst time and our approach is novel because we do not try to generate a caption from scratch, but we try to select the most appropriate set of sentences for the image from the news text itself. This technique helps not to lose the relationship between the news article and the image caption. We have used the CNN news dataset which only contains the text parts of news as basis and we have augmented the dataset by collecting the images of the news articles. We generated a two class ground truth for the image and sentences of news article by using Tf-Idf and Word2Vec vectors; and cosine and SEMILAR sentence-to-sentence similarity methods. We utilized HOG and BOVW image descriptors and Word2Vec text feature extraction methods. We implemented Naive Bayes, k-NN and Random Forest classiﬁcation methods to measure the performance of our proposed system. We have also applied PCA dimensionality reduction method for image features to evaluate the equal weights of image and text features. We have also conducted experiments to solve the unbalanced class distribution of the two classes. The experiment results show that Naive Bayes classiﬁer with HOG features gives better results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde, eğitim alanındaki bilgiye erişim arttıkça, ilkokul çocukları için yeni teknolojiler gelişmektedir. Ancak sağır ve dilsiz çocukların özellikle okul hayatlarındaki bilgiye erişimi sınırlıdır. Bunun en önemli sebeplerinden biri Türk İşaret Dili(TİD) alanındaki çalışmaların eksikliğidir. Bu çalışmada ilk kez istatistiksel makina çevirisi yaklaşımıyla Türkçe'den Türkçe İşaret Diline çeviri yapılmıştır. Tercüme için gerekli veriler ilkokul çocuklarının ders kitaplarından alınmış ve veri işleme çeşitli algoritmalar kullanılarak yapılmıştır. Sistem, Moses Decoder ile kullanılmış ve sonuçlar farklı değerlendirme ölçütleriyle test edilmiştir. Literatürde başka bir SMT tabanlı çalışma bulunmadığından, bu çalışmadan elde edilen sonuçlar karşılaştırılamamaktadır. Buna rağmen, sonuçlardan elde edilen skorların yeni çalışmalar için motive edici olduğu görülmektedir.","Nowadays, as the access to information in the field of education increases, new technologies are developing for primary school children. However, deaf and dumb children still have limited access to the information especially in their school lives. One of the most important reasons for this problem is the lack of studies in the Turkish Sign Language domain. In this study, for the first time, translation from Turkish to Turkish Sign Language has been performed with statistical machine translation approach. The data required for translation were taken from the textbooks of primary school children and data processing was performed by using various algorithms. The system has been used with Moses Decoder and the results have been tested with different evaluation metrics. Because there is no other SMT based study for Turkish Sign Language in the literature, the results obtained from this study can not be compared. Nevertheless, it is seen that the scores obtained from results are motivating for new studies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Robot biliminin gelişmesiyle birlikte robotlar sosyal hayatımızda yavaş yavaş yerlerini almaya başladılar. Sosyal hayatta yer alan robotlarla beraber, insan-robot etkileşimi (İRE) başka bir boyuta taşınmış oldu. Bu yeni ilişkinin iyi veya kötü olacağını öngörmek günümüzde imkansız. İnsanlığın robotlar hakkında en büyük korkusu bir ya da bir grup robotun dünyayı ele geçirip, insanlığın sonunu getirmesidir. Bu olası felaket senaryosunu engellemek ve insan-robot etkileşiminin sınırlarını belirlemek için robot etiği bilimi ortaya çıkmıştır. Literatürde, robot etiğinin nasıl olması ve robot etiğinden ne beklenmesi gerektiğine dair birçok yaklaşım vardır. Biz bu çalışmamızda önerilen uygulamalı etik yaklaşımlarını inceledik ve okulumuz tarafından geliştirilen yerli servis robotumuz BOSS için bir etik birimi tasarladık. Etik birimimiz bulanık mantık kullanan bir uzman sistem olarak çalışmaktadır. Bu uzman sistemin ana amacı robotun yanında çalışacağı insana herhangi bir insandan daha etik bir şekilde yaklaşmasını sağlamaktır. Uzman sistemimizde iki türlü etik kural mekanizması bulunmaktadır. Biri genel-geçer ve değişimi çok zor olan uzun dönemli etik kurallar, diğeri ise robotun çalışma ortamına ve görevine göre değişecek kısa dönemli ve değişme olasılığı yüksek etik kurallardır. Etik birim girdi olarak robotun davranış kontrolcüsünden gelen olası davranışları ve çevre algısını almaktadır. Bulanık kümelerden oluşturulan kurallar ile bu girdileri birleştirerek, robotun muhtemel davranışları içerisinden en etik yani kullanıcıya karşı en zararsız olanı seçecektir. Eğer hiçbir davranış etik değilse, robot duracak ve aksiyon almayacaktır. Bu çalışmanın ilk aşamasında etik tanımını ve etiklik parametrelerini literatüre göre belirledik. Sonrasında olası aksiyonlar üzerinden etik problemleri tasarladık. Son olarak bu etik problemlerin uzman sistem tarafından karar verme aşamasında kullanılmasını sağladık. Çalışmamızda, etik birimimizin kullanılabilirliği birim ile sohbet şeklinde incelenmiş ve etik birimi olmayan robottan davranışsal olarak ayrımı ise benzetim ortamında ve gerçek robot (NAO) deneylerinde gözlenmiştir.","With the improvements of robotics science, robots have gradually began to take their place in social environments. The human-robot interaction (HRI) studies evolved with the increasing number of robots involved in the social world. It is impossible to predict whether this changed relationship will be competent or corrupt. The most significant anxiety of humanity regarding robots is that one or a group of robots dominate the world and create an apocalypse for humankind. The science of robot ethics has emerged to prevent this possible disaster scenario and to define the limits of HRI. There are many approaches in the literature about how robot ethics should be and what to expect from robot ethics. In this thesis, we examined the applied ethics approaches and designed an ethical unit for the service robot BOSS, which was developed by our lab.Our ethics unit works as a expert system using fuzzy logic, which is called Fuzzy Expert System (FES) in machine learning. The purpose of designed FES is to enable the robot to approach the human being more ethically than any person. There are two kinds of ethics rules in our FES. One is a long-term memory of ethics that is universal consent and set in stone, and the other one is a short-term memory of ethics rules that will alternate according to the working environment and duty of the robot. The ethical module takes the possible behavior of the robot from the behavior controller and the environmental perception as inputs. By combining these inputs with rules created from fuzzy clusters, the robot will choose the most ethical, so the most harmless to the user, of the possible behaviors. If there is no ethical behavior, the robot will stop acting and show no action. In the first stage of research, we determined the outline of the ethics module and ethical parameters according to the literature. Then we designed ethical problems through possible actions. Finally, we have ensured that the FES uses these ethical problems in the inference phase. In our study, the usability of our ethics module was examined with the chat-bot interface. Behavioral comparison between the robot with the ethics module and the robot without our module was observed in the simulation environment and on NAO robot."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kapalı Zamansı Eğriler üzerine tartışmalar, bu eğrileri kullanarak Turing Makinesi ile hesaplamaları daha efektif hale getiren hesaplama modellerine yol açmıştır. Bu modeller verileri zamanda geriye gönderme gücüne sahip olmalarından ötürü zamanın nedenselliğini bozarak paradokslara yol açabilmektedirler. Modeller kendi içlerinde bu paradoksların önüne geçmek için yaptıkları varsayımlarına göre farklılık göstermektedir. Farklı hesaplama modelleri üzerine çalışmaların karmaşıklık sınıfları ve bu sınıfların birbirleri ile olan etkileşimleri üzerine açıklık getirebildiği bilinmektedir. Hesaplama modellerinin ilki Deutsch tarafından önerilmiş olup, paradoks oluşma-sını engellemek için zamanda geri gönderilen bitlerin tek bir halde bulunmak yerine bir olasılık dağılımı içinde bulunduklarını varsaymaktadır. İkinci model Lloyd vd tarafından önerilmiştir ve istenilmeyen olasılık çıktılarının sonuç kümesinden çıkarılabilme gücüne sahiptir. Bu gücü ise makinenin her zaman kararlı olması ve makine ile etkileşim sonucu çıkabilecek paradoksların olma ihtimalinin sıfır olduğu varsayımı sayesinde elde etmektedir. Üçüncü model Say ve Yakaryılmaz tarafından önerilmiştir ve Deutsch'un modelini geliştirerek modelin birkaç dezavantajını ortadan kaldıran iyileştirmeler sunmaktadır. Bu tezde, kapalı zamansı eğriler tabanlı hesaplama modelleri incelenip bu modellerin NP-complete problemlere nasıl efektif çözümler getirdiği analiz edilmektedir. İkinci olarak literatürde geçen bu sınıfa ait bir algoritmanın aynı hatayı daha az devre masrafı ile elde edebilen bir versiyonu önerilmiştir. Son olarak Deutsch'un modeli ile hesaplamalarda ortaya çıkabilen bir durum üzerine tartışma ve analiz yer almaktadır.","Discussions of Closed Timelike Curves (CTC) led to a few computation models that when used in conjunction with a Turing Machine, yield much more efficient computations. CTC assisted computation has the ability to send a piece of information back in time which breaks the time causality and has various paradoxes associated with it. Computation models deal with these paradoxes differently by making different assumptions. Regardless of the practicality of CTCs, studying different computation models has the possibility to grant valuable insight into complexity classes and their relationships among each other. The first of these models is proposed by Deutsch. The model avoids paradoxes by assuming that the states that enter and exit the machine constitute a probability distribution and that the machine outputs a stationary distribution. The second model, proposed by Lloyd et al. has the ability to discard unwanted outcomes, via the assumption of time-related paradoxes that can be caused by CTC interaction to be impossible. The third model, proposed by Say and Yakaryılmaz improves upon Deutsch's model and deals with some of its shortcomings. In this thesis, we demonstrate and analyze how these CTC based computation models help solve NP_complete, and some other problems efficiently and propose a more cost-efficient version of one such algorithm from the literature. Lastly, we explore and discuss some odd and interesting properties of calculations in DCTCs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İyimserlik, kötümserlik ve gerçekçilik, günlük yaşamda belli bir kişilik tipinin tipik davranışını tanımlamak için kullanılan insan eğilimleridir. Bu çalışmada, bu tipik eğilimlerin güven tahminlerine etkilerini bir etmen perspektifinden araştırıyoruz. Her oyuncunun tanımadığı rakiplerle oynamaya karar vermek için onlar hakkında tavsiyeler aldığı Tekrarlanan Mahkumun İkilemi oyununun genişletilmiş bir versiyonunu sunu-yoruz. Modelimizde, bir oyuncu etmenin karşılaştığı rakibi hakkında bilgisi yoksa, komşusu olan etmenlere danışır. Komşusu olan etmen bu rakibi tanıyorsa, bir tavsiyede bulunur. Aynı rakip hakkında birden fazla tavsiye alınabilir, buradaki soru bu tavsiyele-rin nasıl değerlendirileceğidir. Alınan tavsiyenin değerlendirme şekli, etmenlerin eğilim-lerine göre farklılık gösterir. Farklı unutma stratejilerinde, iyimser mi, kötümser mi, yoksa gerçekçi olmak mı en iyi performansı gösterir bunu gözlemlemek istiyoruz. Realistler diğer eğilimlerden daha iyi performans gösterdiğini gözlemliyoruz. Bunun yanında, bu oyunda tavsiye almanın etkisini de inceliyoruz. Sonuçlarımız, tavsiye almanın almamaya göre genelde avantajlı olduğunu ancak bunun etmenlerin hafızalarının kullanımına göre değişiklik gösterebileceğini gösterir. Tavsiye almayan etmenler için hafızada bencilleri tutmak her zaman için en iyi stratejidir, ancak tavsiye alan etmenler için belirli bellek kapasitelerinde bunun en kötü strateji olduğunu farkettik.","Optimism, pessimism, and realism are human dispositions that are used in everyday life to describe the typical behavior of a certain personality type. In this study, we investigate the effects of these dispositions on trust estimations from an agent's perspective. We present an extended version of the Iterated Prisoner's Dilemma game in which each player receives recommendations about other players to decide to play with unknown opponents. In our model, each agent keeps the trust values of the agents they have played before in their memory. If an agent has no information about an opponent, it consults neighbor agents of it. If neighbor agent knows that opponent, it gives a recommendation. An agent can be received more than one recommendations about the same opponent. How do agents evaluate recommendations? The evaluation process of recommendations varies according to the agent's disposition. We aim to observe which disposition shows the best performance in different forgetting mechanisms. We examine the effect of receiving the recommendation. Our results show that it is more advantageous to receive recommendations, but that varies depending on memory usage. Realist agents perform better than other dispositions. We conclude that the best forgetting mechanisms for agents receiving recommendations vary by memory capacity."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Manyetik rezonans görüntüleme (MRG) meme kanserinin teshisi ve takibiyle ilgili oldukça faydalı bilgi saglamaktadır. Günümüzde meme MRGâde genellikle dinamik kontrastlı MRG (DKG), difüzyon agırlıklı MRG (DAG) ve proton MR spektroskopik görüntüleme (1H-MRSG) teknikleri kullanılmaktadır. Bu görüntüleme tekniklerinin analizlerini ayrı ayrı yapabilen farklı yazılımlar bulunmaktadır. Bu çalısmada tüm bu tekniklerin analizini yapabilen esnek ve açık kaynak kodlu BreastIS görüntü analizi yazılımı gelistirilmistir. BreastIS görüntü analizi yazılımı MATLAB kullanılarak programlanmıstır, ve kullanıcı ara yüzü MATLAB GUI ve Java kullanılarak gelistirilmistir. Windows, Linux ve Mac isletim sistemlerini desteklemektedir. Tasarlanan yazılımın analiz ve görüntü isleme algoritmalarını ve klinik veriye uyumlulugunu test etmek için retrospektif analizler yapılmıstır. DKG analizleri için 16 meme kanseri hastaya ait MRG ve DAG analizleri için de 6 meme kanserli hastaya ait MRG BreastIS yazılımı kullanılarak analiz edilmistir. Analizler sonucunda tümörlü ve saglıklı doku arasındaki farklılıkları saptamak için hesaplanan parametrelere Mann-Whitney sıra toplam testi uygulanmıstır. DKG analizleri sonucunda hesaplanan sinyalde ortalama yüzde artıs, erken evrede artıs yüzde artıs gibi parameterler tümörlü ve saglıklı doku için istatistiksel olarak anlamlı farklılıklar göstermistir (P<0.001). DAG analizleri sonucunda hesaplanan ortalama görünen difüzyon katsayısı tümörlü ve saglıklı doku için istatistiksel olarak anlamlı farklılıklar göstermistir (P=0.002).","Magnetic resonance imaging of breast provides valuable information about breast tissue composition. A common breast MRI protocol may include dynamic contrast enhanced (DCE) MRI, diffusion weighted MRI (DWI) and proton MR spectroscopic imaging (1H-MRSI). There have been several software tools that can analyze each of these data types separately. In this study, a flexible and open-source postprocessing software called 'BreastIS 'was developed to analyze DCE-MRI, DWI, and 1H-MRSI and store them in a database for further exploration. BreastIS image processing software was implemented using MATLAB and the graphical user interface was developed using MATLAB GUI and Java. The software could be run onWindows, Mac and Linux computers. A retrospective study was conducted to test the suitability of the analysis algorithms of BreastIS tool for the use with clinical dataset. DCE-MRI data of 16 and DWI data of 6 breast cancer subjects were analyzed with BreastIS. For DCE-MRI analysis, the semi-quantitative parameters such as early and maximum percentage enhancement, signal uptake pattern and maximum pixel intensity were calculated for healthy and tumor regions of each subject. For DWI analysis, mean and maximum apparent diffusion coefficient (ADC) values were calculated for tumor and healthy regions of each subject. A Mann-Whitney rank sum test with Bonferroni multiple comparison correction was applied to find statistically significant differences between healthy and tumor regions. Maximum and early percentage enhancements and maximum pixel intensity were higher (P<0.001), and mean ADC values were lower in tumor regions (P=0.002). The DCE-MRI signal uptake pattern displayed wash-out in tumor regions. The sample analysis results indicated the suitability and usability of BreastIS tool for analysis of clinical breast MRI datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde ilaç prospektüslerinde bulunan ilaç yan etkilerini gösteren varlık isimlerinin tanınarak MedDRA sözlüğü içerisindeki kavramlara normalize etmeyi sağlayan kural ve makine öğrenmesi tabanlı bir sistem önerilmektedir. Makine öğrenmesi yaklaşımı, yakın zamanda önerilen ve cümle seviyesinde çalışan bir derin öğrenme modelini temel almaktadır. Model önceden öğrenilmiş kelime temsilleri ve kelime karakterlerinden üretilmiş evrişimli sinir ağları temsillerinin birleşiminden oluşan temsillerden faydalanır. Üretilen temsiller özniteliklerinin çıkarılması için ilk olarak uzun kısa-süreli bellek katmanından geçirilir. Son olarak, çıkarılan öznitelikleri kullanarak hedeflenen varlık isimlerini tahmin etmek üzere Şartlı Rastgele Alanlar eğitilir. Tanımlanmış ilaç yan etkilerini MedDRA sözlüğü kavramlarına normalize eden kural tabanlı yaklaşım, SciMiner isimli bir metin madenciliği sisteminin uzantısından temellenmiştir. Önerilen sistem, TAC-ADR 2017 yarışmasının veri kümesi ile değerlendirilmiştir. Bu veri kümesi ayrık ve üst üste binen varlık isimlerine sahip olduğu için, model yakın zamanda önerilen ve bu tip varlık isimlerini tanıyabilmek için tasarlanmış öbek şemasından da faydalanmaktadır. Model TAC veri kümesi üzerinde 76,97 f-skor elde etmiştir. Modelin genel gazete yazıları üzerinde eğitilmiş modeller kadar başarılı olmamasına sebepleri arasında veri kümesinin küçük olması ve sınıf örneklerinin eşit dağılmaması yer alır.","This thesis proposes a machine learning- and rule-based system for the identification of adverse drug reaction (ADR) entity mentions in the text of drug labels and their normalization through the MedDRA dictionary. The machine learning approach is based on a recently proposed deep learning model that works on the sentence level. The model makes use of the combination of the pre-trained word embeddings and Convolutional Neural Network (CNN) embeddings generated from the characters of a given token. These tokens are initially passed through bi-directional Long Short-Term Memory (Bi-LSTM) layers for feature extraction. Finally, a Conditional Random Fields (CRF) classifier is trained on those extracted features for the prediction of the target mentions. The rule-based approach, used for normalizing the identified ADR mentions to MedDRA terms, is based on an extension of the text-mining system called SciMiner. The proposed system is evaluated with the TAC-ADR 2017 challenge dataset. Since this dataset contains mentions that are disjoint and overlapping, the model also uses a recently proposed chunking scheme designed to handle those types. The model obtained 76.97 f-score performance on the TAC dataset. Some of the challenges for the worse performance compared to performance of the models trained on the generic newspaper text are the small size of the training dataset and the uneven distribution of the class instances."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Perakendecilikte, ürün satışlarının gelecekteki miktarını tahmin etmenin fayda sağlayacağı birçok senaryo vardır. Bunlar, her biri perakende sektöründe başarı için çok önemli olan nakit akışı yönetimi, kampanya yürütme ve envanter planlama gibi süreçleri içermektedir. Nicel zaman serisi analizi, ürün talebini tahmin etmek için yaygın olarak uygulanmaktadır. Nicel analizler, istatistik ve ekonometriden gelen bir dizi yerleşik yöntem içermektedir. Ancak, yeterlilikleri belirli varsayımlarla sınırlandırılmıştır ve uygulanmadan önce veriler üzerinde dikkatli şekilde bir takım istatistiksel işlemleri gerektirmektedir. Yapay Sinir Ağları, yapılandırılmamış verilerde olağanüstü başarı gösteren güçlü bir yapay öğrenme modeli sınıfıdır. Bu çalışmada, Uzun-Kısa Süreli Bellek ağına girdi olarak verilecek hiyerarşik çok değişkenli zaman serisi verilerini hazırlamak ve seçmek için beş farklı matematiksel formülasyon önerdik. Formülasyonları (veya ""şemalar) sırasıyla; (1) Uni, (2) Uni-Store, (3) Uni-Product-Pcc, (4) Uni-Product-Mi, (5) Multi-Store olarak adlandırdık. Her biri, satışların miktarını tahmin etmek için çeşitli ilişkilendirme kriterlerine göre birden çok mağazadaki ürünün satış sinyallerini gruplandırmaktadır. Deneylerde, karşılıklı bilgi (3) ve korelasyon (4) temelli şemalar muhtemelen seçilen ürünlerin miktarının az olmasından dolayı düşük performans gösterdi. Uni şeması asgari tahmin hatası veren modelleri ortaya çıkardı. Multi-Store şeması, diğer şemalardan yaklaşık üç kat daha hızlı eğitilebilen modeller ortaya çıkardı. Bu şemanın ortalama tahmin hatası Uni şemasınınkinden önemli ölçüde yüksek çıkmadı.","In retail, there are plenty of use cases that would benefit from predicting the future amount of product sales. Those use cases include cash flow management, campaign execution and inventory planning, all of which are the crucial components for the success of any retail business. Quantitative time series analysis is widely applied for predicting the product demand. It includes a set of well-established methods from statistics and econometrics. However, their capabilities are constrained by certain assumptions and they require careful statistical treatment on the data before the application. Artificial Neural Networks are powerful class of machine learning models which have shown outstanding success on the unstructured data. We proposed five different mathematical formulations to prepare and select hierarchical multivariate time series data to feed into a Long-Short Term Memory network. We referred to the formulations (or ""schemes"") as (1) Uni, (2) Uni-Store, (3) Uni-Product-Pcc, (4) Uni-Product-Mi, (5) Multi-Store. Each of them groups the product sales signals in multiple stores according to various association criteria to forecast the sales amounts. In the experiments, the mutual information (3) and correlation (4) based schemes demonstrated poor performance presumably due to the small number of selected products. Uni scheme produced the models that resulted in the minimum loss. The Multi-Store scheme produced the models that can be trained approximately three times faster than than that of the other schemes. Its average forecast error was not significantly higher than that of the Uni scheme."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsansı robotlar son yıllarındaki kullanım alanları itibariyle bir nesnenin alınması, bir yere götürülmesi veya kaldırılması gibi görevleri üstlenmektedir. Bu tezde, insan ile yapılan obje manipülasyonu çalışmalarıdan esinlenerek gezgin bir robotun insansı şekilde gündelik nesneyi manipule etmesi amaçlanmaktadır. Ancak, robotun, manipülasyon öncesi vücut ve kol hareketinin koordinasyolu ve eş zamanlı çalışma durumunun planlanması gerekmektedir. Bu çerçevede, robot kol ve vücut hareketinin zamansal ve mekansal olarak birleşmesi için özgün bir yaklaşım benimsenmiştir. Bu yaklaşımda, robot ve nesne arasında uzaklık üzerinden, robot nesneye yaklaşırken belirli bir uzaklıkta kol hareketinin, vücut hareketine eşlik etmesi modellenmiştir. Bu kontrol algoritması, robot hareketinin ve kol hareketinin ayrışmış planmasını gereksiz kılmakta ve bütünleşik bir kontrol yapısı sunmaktadır. Ayrıca, robotun yapabileceği hareketler ile ilgili olarak alt kademe görev kontrol mekanizması oluşturulmuş ve mekanizmadan çıkan aksiyonlar birleştirilerek robota al-bırak gibi görev komutları verilmektedir. Yapılan kapsamlı deneyler ile önerilen yöntem gezgin bir robotun değişik kısımları arasındaki eş zamanlı koordinasyon problemine çözüm getirmektedir.","Manipulation is an integral capability for service robots. The goal of this thesis is to design and develop an approach that enables a mobile robot to mimic human manipulation abilities. We consider a differential type of mobile robot that is endowed with an arm and gripper. The robot is assumed to have visual sensing so that it can determine the relative position of the object of interest. First, it is observed that humans exhibit various basic modes of interaction with an object of interest, including extension, flexion, gripping, release and translation. As such, the robot can be programmed to have similar capabilities through establishing the correspondence between the robot and a human with respect to the underlying manipulation mechanisms. More complex behaviors such as putting, pulling, pushing, and shaking are defined using a sequential composition of basic operations. Second, humans are observed to achieve these tasks through the coordination of their body and arm movements. For this, a control approach in which the movements of the robot body and manipulator are coupled temporally and spatially is proposed. As such, if the object of interest is within the robot's reach, then only arm movements are made. If this is not the case, the robot starts moving its body. Depending on the vicinity of the object, this may be accompanied by arm motion or not. The control algorithm results in the robot's body and arm movements to be done in a coupled manner. The proposed approach is evaluated through an extensive set of experiments involving various manipulation tasks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son 10 yılda, görüntülerden 3 boyutlu insan pozu çıkarımı yoğun araştırma konularından biri. Tek bir görüntüden 3 boyutlu poz çıkaran algoritmalar geliştirildiler. Bununla beraber, çok fazla kameranın olduğu kurulumlar da mevcut. Bu tezde, Procrustes Analiz tekniğini kullanarak tek görüntüden elde edilmiş pozları hizaladıktan sonra aykırı değerlerden kurtulup nihai 3 boyutlu pozun kritik noktalarının kordinatlarını bulabilmek için medyan filtreleme kullanacağız. CMU Panoptic, MPI_INF_3DHP ve Human3.6M verisetlerinde yaptığımız deneyler önerdiğimiz sistemin insan bedenindeki kritik noktaları birleştirmesini hassas bir şekilde başarıyor. Ayrıca, kamera seçiminin, birleştirme performansını koruyarak sistem karmaşıklığını düşürmede faydalı olduğunu gözlemledik. Dinamik kamera seçiminin statik kamera seçime kıyasla birleştirme başarımı üzerinde belirgin bir etkisi olduğununa da ulaştık.","Recovery of a 3D human pose from cameras has been the subject of intensive research in the last decade. Algorithms that can estimate the 3D pose from a single image have been developed. At the same time, many camera environments have an array of cameras. In this thesis, after aligning the poses obtained from single-view images using Procrustes Analysis, median filtering is utilized to eliminate outliers to find final reconstructed 3D body joint coordinates. Experiments performed on the CMU Panoptic, MPI_INF_3DHP, and Human3.6M datasets demonstrate that the proposed system achieves accurate 3D body joint reconstructions. Additionally, we observe that camera selection is useful to decrease the system complexity while attaining the same level of reconstruction performance. We also derive that dynamic camera selection has a more significant impact on reconstruction accuracy as against static camera selection."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaret dilleri işitme engelliler tarafından kullanılan görsel bir iletişim aracıdır. Bu diller de diğer doğal diller gibi ülkeye ve kültüre göre farklılıklar göstermekte olup, kendine özgü dilbilgisi kuralları ve lehçeleri bulunmaktadır. Bu çalışmada, işitme engellilerin hayatını kolaylaştırmak amacıyla Türkçe metinleri Türkçe İşaret Diline otomatik çeviren bir sistem tasarlanmıştır. Bu sistem, kural tabanlı ve istatistiksel çeviri yöntemlerini birleştirerek daha iyi performans sağlayan hibrit çeviri yöntemini gerçekleştirmektedir. Bu çalışmada, Aile ve Sosyal Politikalar Bakanlığı tarafından yayınlanan işaret dili sözlüğündeki örnek cümleler veri kümesi olarak kullanılmıştır.","Sign Language is the primary tool of communication for deaf and mute people. It employs hand gestures, facial expressions, and body movements to state a word or a phrase. Like spoken languages, sign languages also vary among the regions and the cultures. Each sign language has its own word order, lexicon, grammatical rules, and dialects. According to these features, a sign language also differs from the spoken language that it represents. The aim of the study is to implement a machine translation system in order to convert Turkish spoken language into Turkish Sign Language (TİD). The advantages of the rule-based and the statistical machine translation techniques are combined into the hybrid translation system. The proposed system is evaluated with Bilingual Evaluation Understudy (BLEU) scoring metric and it is proved that the hybrid translation approach performs better than rule-based and statistical approaches."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Teknolojideki sürekli gelişmeler, ödeme endüstrisindeki gelişmeleri hızlandırmakta ve bu da insanların ödeme şeklini doğrudan etkilemektedir. Yakın alan iletişimi (NFC) protokolü tabanlı ödeme yöntemi, kullanıcılar arasında en son trend ödeme yöntemidir. Kullanıcıların cep telefonlarını kullanarak hızlı ve güvenli ödeme yapmalarını sağlar. Bu çalışma, NFC mobil ödeme yöntemini benimseme faktörlerini, sosyal etkileri, kişisel özellikleri, kültürel özellikleri, davranışsal inançları ve demografik ve önceki deneyimler gibi etkileri göz önüne alarak bulmaya çalışmaktadır. Bulgularımız, Bilişim Teknolojilerinde algılanan yenilikçiliğin, algılanan riskin, göreceli avantajın ve sosyal etkinin, NFC'nin kabulü için istatistiksel olarak önemli belirleyiciler olduğunu göstermektedir. Bununla birlikte, zaman baskısı beklentilerin aksine önemsiz bir etken olarak bulunmuştur. Kanıtlanmış bir başka ilişki de, mobil ödeme servislerinin kullanımı ve NFC kullanımı arasında istatistiksel olarak anlamlı bir ilişki olduğudur. NFC'nin kabulü, mobil ödeme servisinin kullanım deneyimi ile arttığı anketlerin analizi ile kanıtlanmıştır.","Continuous developments in technology expedites the improvements in payment industry, which directly affects the way people pay. Near-field communication (NFC) protocol-based payment method is the latest trending payment method amongst users. It enables users to make fast and secure payments by simply bringing their mobile phone closer to the POS devices. However, the adoption rate of proximity based mobile payment has been low. Accordingly, the present study attempts to find the adoption factors of NFC mobile payment by considering social influences, personal traits, cultural traits, behavioral beliefs and moderating effects such as demographic and previous experience. Our findings show that perceived innovativeness in IT, perceived risk, relative advantage and social influence are statistically significant determinants for NFC adoption. However, time pressure is found as an insignificant determinant as opposed to the expectations. Another proved relationship is that there is a statistically significant relation between the use of mobile payment services and NFC. NFC adoption is higher among consumers with higher mobile payment experience."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım tanımlı ağ (YTA), veri ve kontrol katmanlarını birbirinden ayırmak üzere ortaya çıkan ağ paradigmasıdır. YTA'da bir denetleyici, veri düzleminin yönetiminden sorumlu olan merkezi ağ kontrol birimidir. Tipik olarak, tüm anahtar elemanlarından sorumlu olan tek bir denetleyiciye sahip büyük bir yazılım tanımlı ağ, mevcut veri yükü ihtiyaçlarının artması durumunda sistem yükünü taşımak için yeterli olmayacaktır. Bu amaçla, birden fazla denetleyiciye sahip olmak, sistemin esnekliğini arttırmakla kalmayıp, ağ denetim yükünün kontrolcüler arasında dağıtılmasını da sağlar. Birden fazla kontrolcünün olduğu YTA'larda, anahtar-denetleyici ataması çözmesi zor bir teknik problemdir. Kontrol düzleminde bir kesinti olduğunda, kontrol ve veri katmanları arasındaki kopukluk sistemde paket kaybına ve arızalara neden olabilir. Bu yüzden, sistemdeki bir kesinti durumunda hızlı ve performanslı bir kontrolcü-anahtar ataması önemli bir rol taşır. Bu tezde; denetleyici yük dağılımını, yeniden atama maliyetini ve arıza olasılığını göz önünde bulundurarak genetik algoritma kullanan; denetleyici arızalarında proaktif olan bir anahtar-denetleyici atama şeması PREF-CP'yi öneriyoruz. Tez çalışmamız sırasında, şemamızın başarımını geliştirilen benzer görevli diğer algoritmalar ile (rastgele ve açgözlü algoritmalar) karşılaştırdık. Deney sonuçları, önerilen PREF-CP şemasının, arıza olasılığı ve denetleyici yükü dağılımı açısından daha iyi başarıma sahip olduğunu göstermektedir.","Software-defined networking (SDN) is an emerging networking paradigm which entails separate control and data planes. In SDN, a controller is a centralized network control entity responsible for management of the data plane. Typically, a sizeable software defined network with a single controller responsible for all forwarding elements is potentially failure-prone and inadequate for dynamic network loads. To this end, having multiple controllers improves resilience and distributes network control load. However, when there is a disruption in the control plane, a rapid and performant controller-switch assignment is critical, which is a challenging technical question. Therefore, controller-to-switch assignment and robust operation are challenging research questions, since control plane hazards such as disconnection between control and forwarding planes may lead to packet loss and failures in the system. In this thesis, we propose a proactive switch assignment scheme PREF-CP in case of controller failures using genetic algorithm considering controller load distribution, reassignment cost and probability of failure. Moreover, we compare the performance of our scheme with other algorithms developed during our thesis work, namely random and greedy algorithms. Experiment results show that our proposed PREF-CP framework has better assignment performance in terms of probability of failure and controller load distribution."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Rassal değişkenler arasındaki neden sonuç ilişkilerinin çıkarımı, kontrollü deneylerin mümkün olmadığı durumlarda zorlu bir problemdir. Gizli rassal değişkenlerin varlığı problemin zorluğunu daha da arttırır, ve bundan dolayı nedensellik keşfi yazınının çoğunluğunda gizli değişkenler ihmal edilmektedir. Bu tezde nedensel yapı öğrenilmesi problemine, neden-sonuç mekanizmalarının bağımsızlığı varsayımı üzerine inşa edilmiş Bayesci bir yaklaşım getirmekteyiz. Başka herhangi bir varsayıma ihtiyaç duymadan, nedensel yapı öğrenimi problemini, uygun çizge yapılarının marjinal olabilirliklerinin karşılaştırıldığı bir Bayesçi model seçim problemine indirgemekteyiz. Gizli değişkenlerin varlığında marjinal olabilirlik hesabı, gizli değişkenli Bayes ağlarını puanlamaya eşdeğerdir ve bu problemin genel olarak çözümlenmesinin zor olduğu bilinmektedir. Bu nedenle, marjinal olabilirliğin kestirimi için asimptotik yansız bir kestirici hesaplayan bir parçacık süzgeci algoritması ile birlikte marjinel olabilirliği alttan sınırlandıran bir varyasyonel Bayes yordaması algoritması geliştirmekteyiz. Bu çalışmada, ampirik araştırmalarda sıklıkla karşılaşılan bir modelleme tercihi olan Gauss gürültülü doğrusal taban fonksiyonları karışımı modelini özellikle analiz etmekteyiz. Bu modelde, parametrelerin istatistiksel bağımsızlığı aynı Markov denkliğindeki çizgeleri ayırt edilebilir kılmakta ve yegane nedensel ağın belirlenmesine olanak sağlamaktadır. İki değişkenli durum üzerinden hem yapay hem de gerçek veri setlerinde yürütülen deneyler sonucunda, yaklaşımımızın başarısının en ileri nedensellik keşfi yöntemleriyle aynı seviyede olduğu görülmektedir. Ayrıca yaklaşımımızın genellenebilirliği, onu daha büyük ölçekli nedensel yapı öğrenimi için de umut verici bir çerçeve haline getirmektedir.","Inferring the causal structure of several random variables is a challenging task when interventions are not feasible. Presence of latent confounders further increases the difficulty of the problem, and therefore is neglected in the majority of the causal discovery literature. In this thesis, we adopt a Bayesian approach to causal structure learning by building on the assumption of the independence of cause and effect mechanisms. Without any additional assumptions, we reformulate causal structure learning as a Bayesian model selection problem where we compare appropriate graph structures using the marginal likelihood of associated graphs. In the presence of confounders, marginal likelihood computation is equivalent to scoring Bayesian networks with latent variables, which is known to be computationally intractable. In order to approximate this quantity, we develop a sequential Monte Carlo algorithm that provides an asymptotically unbiased estimator, along with a Variational Bayes algorithm that provides a variational lower bound for the marginal likelihood. We particularly analyze the mixture of linear basis functions model with Gaussian noise, which is a frequently encountered modelling choice in the empirical literature. In this model, statistical independence of parameters renders Markov equivalent graphs distinguishable, and allows the identification of a unique causal graph. We illustrate the performance of our framework in both synthetic and real data sets, focusing on the bivariate case. Our direct approach seems to perform at the level of state of the art causal discovery methods. The generalizability of our approach makes it a promising framework for large scale causal structure learning."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çalışmasında, pratik bir bina içi lokalizasyon tekniği önerilmiştir. Gelişmiş yaklaşımların aksine, bu yeni yöntem, elektromanyetik dalgaların çok yollu dağılım problemi ve gölgeleme efekti ile ilgilenmez. Elektromanyetik dalgaların dağılım modelini de uygulamadığı için bina için her alan için azalma faktörü hesaplamaya da gerek duymaz. Bunun yerine bina içi pozisyon izleme problemi, gözlem modeli olarak radyo frekans haritası ve geçiş modeli olarak difüzyon modeli kullanan Saklı Markov Modeli ile modellenmektedir. Radyo haritasının doğru tahminlenmesi kapalı ortam lokalizasyonunun hatasız yapılabilmesi için büyük önem taşımaktadır. Tahminlemenin doğru yapılabilmesi için ise elektromanyetik alandan yoğun parmak izi toplanması gerekmektedir. Radyo frekans sinyalleri ve lokasyon arasındaki lineer olmayan ilişki sebebiyle, yapay sinir ağları kullanılarak olasılıksal radyo haritası oluşturulmuştur. Elektromanyetik parmak izi toplama sürecinde kurulum ve ölçüm maliyeti yüksek olduğu için belirli noktalarda toplanan parmak izleri ile bir yapay sinir ağı eğitilmiş ve kapalı alandaki diğer noktalardaki parmak izleri tahminlenmiştir. Yapay sinir ağını eğitmek için kullanılacak parmak izlerinin radyo frekans haritası üzerinde çıkarılan belirsizlik analizi doğrultusunda seçimi için Gauss Süreci yöntemi kullanılmıştır. Derin yapay sinir ağı ile oluşturulmuş radyo haritaları ile eğitim verilerinin %30'unun çıkarılması iki farklı bina içi ortamının medyan hatalarında %1.3 ve %2.6 artışla sonuçlanmıştır. Bu durum konumlama doğruluğundan feragat etmeden toplanması gereken eğitim veri setinin azaltılabileceğini göstermektedir.","In this thesis, a practical indoor localization technique is proposed. In contrast to the state of art approaches, this practical approach does not deal with the multipath problems and shadowing e ects of electromagnetic signals as well as it does not require calculating the attenuation factors for each space because it does not apply the propagation model. Instead, indoor localization, by exploiting electromagnetic scattering properties of local area networks, is formulated as a tracking problem using a Hidden Markov model with a radio map as the observation model. Because of the non-linear relationship between radio frequency signals' strength and location, a probabilistic radio map is generated by using Neural Networks. Accurate estimation of the radio map is key in accurate indoor localization but this requires dense sampling of the electromagnetic eld, also named as ngerprinting. To decrease the time consumption of ngerprinting process, we train the neural network using an active learning strategy based on uncertainty sampling, aided by a Gaussian process. With the radio maps generated by a deep neural network, 30% of training data can be removed and this results in an increase of 1:3% and 2:6% in median error in two di erent test areas. It is concluded that without trading o localization accuracy training data size can be reduced by one third."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Finansal analiz metotları ve portföy yönetim tekniklerinin çoğu, risk sınıflandırma ve tahminlemeye dayanır. Hisse senedi getirisinin dalgalanma derecesi bir şirketin finansal riskiyle ilgili güçlü bir göstergedir. Bu sebeple, hisse senedi getirisinin dalgalanma derecesini başarılı bir şekilde öngörmek finansal analiz ve portföy yönetiminde çok değerli bir avantaj yaratır. Bu konudaki araştırmaların çoğu, bir şirketin finansal dalgalanma derecesini tahmin etmek için geçmiş veriler ve şirket bilançosuna odaklanırken bazı araştırmalar ise metinsel kaynakların içerisindeki teknik olmayan bilgileri analiz ederek yeni bilgi kaynakları sunuyor. Halka açık bir şirketin yıllık raporlarındaki metinlerden, o şirketin finansal dalgalanma derecesini öngörmek önceden metin regresyon problemi olarak tanımlanmıştı. Son yapılan araştırmalarda, yıllık raporlardan duygu ifade etmeyen kelimeleri eksiltebilmek için el ile etiketlenmiş bir deyimcelik kullanılıyor. Performansı düşürmeden deyimcelik ihtiyacını ortadan kaldırmak için metin öznitelikleri yerine kelime özniteliklerini kullandık. Yani metinleri, içerlerinde geçen kelimelerle ifade etmek yerine metinlerdeki kelimeleri öznitelik vektörleriyle ifade ettik ve bu durum parametre sayısını arttırdı. Parametre sayısındaki artış ve yıllık raporların aşırı uzunlukları göz önünde bulundurularak evrişimli sinir ağları modeli önerildi ve transfer öğrenmesi uygulandı. Deneysel sonuçlar, evrişimli sinir ağları modelinden alınan dalgalanma derecesi tahminlerinin, deyimcelik tabanlı modellerden alınan tahminlere göre daha yüksek doğrulukta olduğunu gösteriyor.","Most financial analysis methods and portfolio management techniques are based on risk classification and risk prediction. Stock return volatility is a solid indicator of the financial risk of a company. Therefore, forecasting stock return volatility successfully creates an invaluable advantage in financial analysis and portfolio management. While most of the studies are focusing on historical data and financial statements when predicting financial volatility of a company, some studies introduce new fields of information by analyzing soft information which is embedded in textual sources. Forecasting financial volatility of a publicly-traded company from its annual reports has been previously defined as a text regression problem. Recent studies use a manually labeled lexicon to filter the annual reports by keeping sentiment words only. In order to remove the lexicon dependency without decreasing the performance, we replace bag-of-words model word features by word embedding vectors. Using word vectors increases the number of parameters. Considering the increase in number of parameters and excessive lengths of annual reports, a convolutional neural network model is proposed and transfer learning is applied. Experimental results show that the convolutional neural network model provides more accurate volatility predictions than lexicon based models."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada sözlü belgeler üzerinde derin öğrenme yöntemleriyle geliştirilen soru cevaplama sistemleri açıklanmaktadır. Sözlü belgeler üzerindeki soru cevaplama sistemleri ağrılıklı olarak sözlü içeriğin otomatik konuşma tanıma (OKT) sistemi ile yazılandırılması ve ardından metin tabanlı soru-cevaplama tekniklerinin bu OKT çık- tılarına uygulanması ile gerçekleştirilir. Sorular sisteme yazılı ya da sözlü olarak sunulur ve cevapları konuşma verilerinden döndürülür. Sözlü belgelerdeki soru cevaplama, metin belgelerinden daha zordur. Birincisi, sözlü belgelerin açıkça paragraf sınırları yoktur; bu nedenle, cevapları almak için soru-bilinçli geçiş gösterimlerini kullanan uçtan uca sinir ağı tabanlı sistemler yetersiz performans gösterebilir. İkinci olarak, OKT çıktıları hatalı olabilir bu durum soru cevaplama sisteminin performansını etkiler. Bu nedenle, konuşma belgeleri üzerindeki soru cevaplama sistemlerinde bu sorunları ele almak için derin öğrenme modeline dayanan iki yeni yaklaşım öneriyoruz. İlk yaklaşım, sözde paragraflar üretip bunlar üzerinden ilgili soruları otomatik tanımlama yaparak konuşulan belgede geçiş sınırlarının bulunmaması sorununu ele almaktadır. İkinci yaklaşım OKT sistem çıktısı olan karışıklık ağını kelime güven skorları ile beraber uçtan uca sinir ağı tabanlı soru cevaplama sistemi ile bütünleştirir. Önerdiğimiz modeller uçtan-uca sinir ağı modeli ile birleştirildi ve bu modellerin performansı oluşturulan iki yeni veri seti ile incelendi. Önerilen uzantıları içeren uçtan uca sinir ağı modelinin konuşma belgeleri üzerinde soru cevaplama üzerinde etkin olduğu kanıtlanmıştır ve soru cevaplama performansını OKT çıktılarını direkt uçtan-uca sinir ağı modelinde kullanmaya göre geliştirmiştir.","This study describes a question answering (QA) system developed with deep learning methods on spoken documents. Question answering on spoken documents is mainly performed by transcribing spoken content with an automatic speech recognition (ASR) system and then applying text-based question answering methods to the ASR transcripts. The questions are presented to the system in written or spoken form and the answers are returned from spoken documents. QA task on spoken documents is more challenging than on text documents. Firstly, spoken documents do not have explicit paragraph boundaries so that end-to-end neural network based systems that utilize question-aware passage representations for retrieving answers may perform poorly. Secondly, ASR transcripts can be erroneous and this effects the performance of QA systems. Therefore we propose two novel approaches to handle these problems in deep learning based end-to-end spoken QA systems. First approach handles the absence of passage boundaries in spoken documents by generating pseudo passages and automatically determining questions related with each pseudo passage. Second approach integrates ASR system output, confusion networks with word confidence scores, into a question answering system. Our proposed approaches are integrated into an end-to-end system and we investigate the capability of these approaches with two newly curated QA datasets. The end-to-end neural network model with the proposed extensions has proven to be effective in spoken QA task and improved the QA performance on spoken documents compared to directly applying the end-to-end model to the ASR transcripts of the spoken documents."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok sözcüklü ifadelerini (ÇSİ) anlamak Doğal Dil İşleme'de ayrıştırma, makine çevirisi gibi uygulamalar için önemlidir. ÇSİ'leri saptama metinde otomatik olarak ÇSİ'leri tanımlama ve sınıflandırma işlemidir. ÇSİ'ler temel karakterlerinden dolayı zorlayıcıdır. PARSEME ağının çok sözcüklü fiil ifadeleri (ÇSFİ) üzerine yaptığı güncel çalışmaları takip ederek, ÇSFİ saptanması üzerine odaklandık. PARSEME Türkçe eğitim ve test derlemi 1.0'ı (2017), PARSEME Türkçe eğitim ve geliştirme derlemi 1.1 (2018) olarak güncelledik. PARSEME Türkçe test derlemi 1.1'i oluşturduk. Ek olarak, çift yönlü uzun kısa-vadeli bellek ve koşullu rastgele alanlar ağını ve gappy 1-level etiketleme şeması ile kullanan çok dilli ÇSFİ'leri saptayan bir sistem geliştirdik. Çalışmamızı ilerletmek için, veri gösterim formatının ÇSFİ saptama işlemi üzerindeki etkisini inceledik. Bigappy-unicrossy etiketleme formatını dizi etiketleme işlemlerinde çakışmaları tanımlamak için geliştirdik. Sonuçlarımız, veri gösterim formatının süreksiz ÇSFİ'leri tanımada önemli olduğunu gösterdi. Ayrıca, değişkenlik problemi için sinir ağları ile otomatik olarak öğrenilmiş gömmeleri kullanarak sistemimizi zenginleştirdik. Karakter seviyesinde evrişimli sinir ağlarını ve karakter seviyesinde çift yönlü uzun kısa-vadeli sinir ağlarını karşılaştırdık. İki farklı ek bilgisi gösterim şeklini çift yönlü uzun kısa-vadeli sinir ağları kullanarak inceledik. Sonuçlarımız karakter ve ek bilgisi gömmelerinin performansı genel olarak geliştirdiğini gösteriyor. Gösterim öğrenme metotu seçimi dile bağlıdır.","Understanding multiword expressions (MWEs) plays an instrumental role in Natural Language Processing applications such as parsing and machine translation. MWE identification is a task that automatically detects and classifies MWEs in running text. As with the basic characteristics of MWEs, significant challenges exist in MWE identification. Considering the recent attempts of the PARSEME network on verbal multiword expressions (VMWEs), we focus on the identification of VMWEs. We update the PARSEME Turkish train and test corpora 1.0 (2017) as the PARSEME Turkish train and development corpora 1.1 (2018). We construct the PARSEME Turkish test corpus 1.1. In addition, we develop a multilingual VMWE identification system based on bidirectional long short term memory with conditional random fields networks accompanied with the gappy 1-level tagging scheme. To extend our study, we examine the impact of data representation format on the VMWE identification task. We introduce the bigappy-unicrossy tagging scheme to recognize overlaps in sequence labelling tasks. Our results show that data representation format is important to identify discontinuous VMWEs. Moreover, we enhance our neural VMWE identification model with automatically learned embeddings by neural networks to respond to the variability challenge. We compare character-level convolutional neural networks and character-level bidirectional long short-term (BiLSTM) networks. We analyze two different schemes to represent morphological information using BiLSTM networks. Our results demonstrate that character embeddings and morphological embeddings improve performance in general. The choice of representation learning method depends on language."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde yollarda araç sayısının artması ile birlikte geleneksel taşımacılık yöntemleri özellikle kavşaklarda trafik sıkışıklığına sebep olmaktadır. Bu da hava kirliliğine ve yolda boşa zaman geçirilmesinin temel nedenleri arasındadır. Son yıllarda otonom araçlar üzerine yapılan araştırmalar sayesinde yakın gelecekte kavşaklarda daha verimli bir şekilde trafik yönetimi mümkün olacaktır. Bu tezin temel amacı, otonom araçlar için zaman temelli optimizasyon ve Model Öngörülü Kontrol (MÖK) yöntemleri ile yakıt tüketimini de ele alarak kavşak koordinasyonu sağlamaktır. Önceki araştırmalar bu yöntemlerin, otonom araçlar için geleneksel kavşak yönetim sistemlerine göre daha verimli sonuçlar elde ettiğini göstermiştir. Fakat, daha iyi yörünge planlama teknikleri kavşaklarda gecikme sürelerini azaltacaktır. Bunun yanında, optimizasyon problemi oluştururken yakıt tüketimi için de bir maliyet fonksiyonu eklemek araçların yakıt ekonomisi bakımından yararlı olacaktır. Bu tezde, verimli yörünge planlama tekniklerinin ve araçların haberleşmesi için kullanılan iletişim alanının genişliğinin zaman tabanlı optimizasyona etkileri incelenmektedir. Geniş iletişim alanının ve dinamik yörünge planlama tekniğinin daha az zaman kaybına yol açtığı gösterilmiştir. Bir diğer katkı ise, model öngörülü kontrol maliyet fonksiyonuna yakıt tüketimi maliyetini minimize edecek fonksiyonların da eklenmesi ve yakıt ekonomisine etkilerinin incelenmesidir. Ayrıca merkezcil model öngörülü kontrol sistemi merkezcil olmayan sisteme çevirilmiştir. Maliyet fonksiyonuna yakıt tüketimi denklemlerini eklemek her ne kadar yakıt tüketimini azaltsa da kavşak içinde gecikmeyi arttırdığı sonucuna varılmıştır. Ayrıca merkezcil MÖK'un merkezcil olmayana göre daha verimli sonuç elde ettiği de görülmüştür.","Traditional transportation systems cause traffic congestion especially at the intersections as the number of vehicles keeps increasing. This is also the main reason of air pollution and time wasted. Most of the people lose their time and money because of traffic congestion. Thanks to recent research on autonomous vehicles, intelligent transportation and wireless communication systems, efficient traffic management at the intersections with multi-agent scheduling methods will be possible. The main objective of this thesis is intersection coordination for multi-agent systems by using time-based optimization and Model Predictive Control (MPC) methods while considering fuel economy at the intersections. Existing results show that these methods are efficient in comparison to the traditional methods when all the vehicles are autonomous. However, better trajectory planning can improve the total delay of the system. Besides, including fuel economy in the optimization function can also decrease fuel consumption which would be good for both humanity and nature. In this thesis, the effect of trajectory planning and different communication ranges on time-based optimization method is studied. It is shown that a wider communication range and better trajectory planning provide less time delay. Another contribution of this thesis is to propose centralized and decentralized MPC algorithms by including fuel consumption related costs in the objective function. As a result, fuel consumption is decreased at the expense of an increase in the time delay. In simulations, it is also observed that centralized MPC performs better than decentralized MPC."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çekişmeli üretici ağlar (ÇÜA), karmaşık veri dağılımlarını modellemek için öne sürülmüş derin sinir ağlarıdır. Ayırıcı ağ veri dağılımının sınırlarını öğrenirken üretici ağ ayırıcı ağın hatasını yükseltmeye çalışarak örnekleme yapmayı öğrenir. Veri dağı-lımlarında genelde birden fazla tepe bulunduğu için, ÇÜA'lar veri dağılımının hepsini öğrenmekte zorlanırlar. Evrensel tek bir üretici öğrenmek yerine, her biri dağılımın yerel bir kısmından sorumlu olan birden fazla üretici öğrenen sürümler de bulunmaktadır. Bu tezde bunları inceleyerek yeni bir mimari öne sürdük: hiyerarşik üretici karışımları. Bu ağaç yapısı dağılımı hiyerarşik bir şekilde bölmeyi öğrenir; ağacın yapraklarında ise yerel üreticiler bulunmaktadır. Bu üreticiler esnek bir biçimde birleş-tirildiklerinden dolayı bütün model sürekli bir fonksiyondur ve türev bilgisine dayanan en iyileme yöntemleriyle eğitilebilir. Beş farklı veri kümesinde (MNIST, FashionMNIST, CelebA, UTZap50K ve Oxford Flowers) yaptığımız deneyler öne sürdüğümüz mimarinin yoğun katmanlı sinir ağları kadar başarılı olduğunu göstermiştir. Ayrıca öğrenilen hiyerarşik yapının veri dağılımı hakkında damıtılmış bir bilgi verdiğini de görüyoruz.","Generative adversarial networks (GANs) are deep neural networks that are designed to model complex data distributions. The idea is to create a discriminator network that learns the borders of the data distribution and a generator network trained to maximize the discriminator's loss to learn to generate samples from the data distribution. Instead of learning a global generator, one variant trains multiple generators, each responsible from one local mode of the data distribution. In this thesis, we review such approaches and propose the hierarchical mixture of generators that learns a hierarchical division in a tree structure as well as local generators in the leaves. Since these generators are combined softly, the whole model is continuous and can be trained using gradient-based optimization. Our experiments on five image data sets, namely, MNIST, FashionMNIST, CelebA, UTZap50K, and Oxford Flowers, show that our proposed model is as successful as the fully connected neural network. The learned hierarchical structure also allows for knowledge extraction."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otonom makinelerle kaza önlenmesi, verimlilik için ortamların iyileştirilmesi ve yaşlılara destek verilmesi için gerekli analizi insan tespiti ve takibi sağlayabilir. Tümyönlü kameralar geniş görüş alanları sayesinde, çözünürlükten feda ederek, daha fazla bir alanı kapsar. Tümyönlü kamera kullanımı gerekli kamera sayısını ve bant genişliğini düşürerek kurulum, işletme ve hesaplama maliyetlerini düşürebilir. Fakat, geleneksel kameralar için geliştirilmiş yapay görü yöntemleri, görüntünün oluşum geometrisi farklı olduğu için genellikle tümyönlü kameralarda başarısız olur. Bu tezde, ilkin, insan takibi için özgün bir veri kümesi, BOMNI, tanıtılmaktadır. BOMNI, insanların bir odanın içinde hareket ettiği 46 video içerir. İnsanların sınırlayıcı kutuları ve kimlikleri her karede işaretlenmiştir. İkinci olarak, insan takibi ve düşme tespitini bağlayan bir üretimsel Bayesian model sunulur. BOMNI veri kümesi üzerinde değerlendirilen bu yöntem, %93 takip isabetliliği ve çoğunlukla bir kaç kare içerisinde düşme tespiti başarımı elde etmiştir. Üçüncü olarak, benzer bir yöntem birden fazla insan takibi için geliştirilmiş ve BOMNI veri kümesi üzerinde değerlendirilmiştir. Geçmiş yönteme kıyasla bu yöntem %18 artış sağlayarak %86 takip isabetliliği elde etmiştir. Dördüncü olarak, insan tespiti için ayrımcı bir yöntem önerilmiştir. Ayrıca, öznitelik çıkarımını hızlandırmak için özgün bir yapı, Dairesel İntegral Görüntüsü, sunulmuştur. Bu yöntem IYTE veri kümesi üzerinde bilinen en yüksek insan tespiti başarımını elde etmiştir: görüntü başına bir yanlış pozitif için %4.5 ıska oranı. Son olarak, bir şekli birden fazla dikdörtgen ile ifade etme problemi, Dikdörtgen Battaniyesi Problemi, bir tamsayı programlama problemi olarak formüle edilmiş ve en iyi çözümü bulan bir dallan-ve-sınırla yaklaşımı ve yeni bir dallanma kuralı önerilmiştir. Bu problem ile tezin önceki bölümlerinde karşılaşılmıştır fakat literatürde varolan daha genel bir problemdir.","Person detection and tracking can provide the crucial analysis needed to avoid accidents with autonomous machinery, optimize environments for efficiency and assist the elderly. Omnidirectional cameras have a large field of view that allow them to cover more ground at the expense of resolution. Omnidirectional cameras can decrease setup, maintenance and computational costs by reducing the number of cameras and the bandwidth required. Computer vision methods developed for conventional cameras usually fail for omnidirectional cameras due to their different image formation geometry. In this thesis, first, a novel dataset for person tracking in omnidirectional cameras is introduced. The dataset, namely BOMNI, contains 46 videos of persons moving inside a room; where the bounding boxes and the identity of the persons are annotated at every frame. Second, a generative Bayesian framework is developed for coupling person tracking and fall detection. The method is evaluated on BOMNI dataset, producing 93% tracking accuracy and fall detection within a few frames of the event. Third, a similar method for multiple person tracking is developed and evaluated on BOMNI dataset. The method reaches 86% tracking accuracy, increasing a previous approach by 18%. Fourth, a discriminative method for person detection is presented. Also a novel structure called Radial Integral Image that speeds up feature extraction step is introduced. This method achieves state of the art detection performance on IYTE dataset: 4.5% miss rate for one false positive per image. Finally, the problem of representing a shape with multiple rectangles, Rectangle Blanket Problem, is formulated as an integer programming problem and a branch-and-bound scheme is presented along with a novel branching rule to solve it optimally. This problem is encountered in the earlier sections of this thesis, but it is a general problem that is present in the literature."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Özgün protein-ilaç etkileşimlerinin hesaplamalı metotlar ile saptanması önemli bir araştırma alanıdır. Çoğunlukla, bir ilaç yeni bir proteini hedeflemek için yeniden amaçlandırılabilir. Böylece makine öğrenmesi algoritmaları mevcut protein-ilaç etkileşimlerinden öğrenerek özgün etkileşimleri tahminleyebilir. Bu tezin temel amacı, protein ve ligandların (ilaç adaylarının) aralarındaki ilişkiyi, metinsel gösterimlerini kullanarak makine/derin öğrenme teknikleri ile modellemektir. Bu amaçla, yeni bir ligand gösterim yöntemi ve yeni bir protein gösterim yöntemi ile protein ve kimyasalların aralarındaki bağlanma kuvvetini (bağlanma ilgisini) belirlemek için iki yeni tahminleme sistemi tanıtılmıştır. Bu çalışmaların ortak teması proteinlerin (amino-asit dizileri) ve kimyasalların (SMILES dizileri) metinsel gösterimlerinin kullanılmasıdır. Metinsel gösterim, üç-boyutlu (3D) gösterime göre deneysel olarak daha kolay elde edilebilen bir bilgidir. Bu nedenle, üç-boyutlu bilgiye göre çok daha fazla molekül için metinsel gösterim bulunabilmektedir. Bu durum protein ve kimyasallar ile çalışırken önemli bir avantaj oluşturmaktadır. Ayrıca, metin bazlı gösterimlerin işlenmesi, iki-boyutlu (2D) ve 3D gösterimler ile karşılaştırıldığında hesaplamalı olarak daha ucuzdur. Biz çalışmalarımızda, tıpkı doğal diller gibi, biyo-kimyasal dizilerin kendi dillerinin olduğunu, ve bu dillerin işlenmesinin biyo-kimyasal moleküllerin karakteristikleri hakkında önemli bilgileri ortaya çıkarabileceği varsayımında bulunuyoruz. Protein aile gruplandırılması ve protein-ligand bağlanma ilgisinin tahminlenmesi gibi problemler üzerindeki çalışmalarımız literatürde en iyi performansa ulaşmıştır. Bu sonuçlar, protein ve kimyasalların metinsel gösterimlerinin farklı biyoenformatik ve kimenformatik problemlerine etkili çözümler tasarlanmasında kullanılabileceğini göstermiştir.","The identification of novel interactions between proteins and drugs with computational methodologies constitutes a significant area of research. Most often, a drug can be re-purposed to target a novel protein which enables machine learning algorithms to learn from existing interactions to predict unknown interactions. The main goal of this thesis is to model the interactions between proteins and ligands (drug candidates) using their textual representations via machine/deep learning techniques. With that aim, we introduce a novel ligand representation approach and a novel protein representation approach as well as two prediction systems for identifying the strengths of the interactions between proteins and compounds (i.e., their binding affinities). The common theme of these studies is the use of textual representations of proteins (i.e., amino-acid sequences) and compounds (i.e., SMILES). A major advantage of text-based representations is that they are experimentally easier to obtain compared to the three-dimensional (3D) representations and therefore there are more protein/ligand text-based representations available than 3D representations. Furthermore, processing text-based representations is computationally less expensive compared to processing two-dimensional (2D) and 3D representations. We hypothesize that, much like natural languages, bio-chemical sequences have their own languages and processing these languages might reveal important insights about their characteristics. The application of Natural Language Processing (NLP) based approaches in tasks such as protein family/super-family clustering and protein-ligand binding affinity prediction achieved state-of-the-art performance. These results indicate that the textual forms of proteins and ligands can be used to formulate effective solutions to address different bioinformatics and cheminformatics problems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok sözcüklü fiil ifadesi saptama birçok doğal dil işleme çalışmaları için zorlayıcı bir görevdir. Bu çalışmada, stokastik modeller ve IOB etiketleme şemasının varyantları eşliğinde dizi etiketleme yaklaşımı çok sözcüklü fiil ifadesi saptaması için kullanılmaktadır. Bu tez kapsamında, PARSEME ortak çalışmanın ilk bölümü olan birçok dilde çok sözcüklü fiil ifadesi etiketli derlemlerin oluşturulması dahilinde çok sözcüklü fiil ifadesi etiketli Türkçe derlem oluşturulmuştur. Ek olarak, Deep-BGT adında çok dilli bir sistem, PARSEME ortak çalışmanın ikinci bölümü olan dilden bağımsız çok sözcüklü fiil ifadesi saptama sistemlerinin birinci bölümde oluşturulan derlemlerin kullanılarak geliştirilmesi kapsamında geliştirilmiştir. Türkçe derlemi ortak çalışmadaki en büyük derlemlerden biridir. PARSEME ortak çalışma 1.0'da yayınlanmış eğitim ve test derlemleri yeni etiketleme kurallarına göre düzenlenerek PARSEME ortak çalışma 1.1 eğitim ve geliştirme derlemleri olarak güncellenmiştir. Sıfırdan yeni bir test derlemi oluşturulmuştur. Deep-BGT üstte koşullu rastgele alanlar katmanı ile birlikte çift yönlü uzun-kısa vadeli bellek (BiLSTM-CRF) modelini kullanmaktadır. Bildiğimiz kadarıyla, bu çalışma çok sözcüklü fiil ifadesi saptaması için BiLSTM-CRF modelini kullanan ilk çalışmadır. Deep-BGT genel sıralama ölçevine göre açık yarışta ikinci olmuştur. Buna ek olarak, zorlayıcı çakışan çok sözcüklü fiil ifadelerinin üstesinden gelmek için bigappy-unicrossy adında yeni bir etiketleme şeması tanıtılmaktadır. Son olarak, çok sözcüklü fiil ifadesi saptama sistemi, etiketleme şeması, ünite sayısı, BiLSTM katmanı sayısı ve sınıflandırıcıdan oluşan bir üst değişkenler altkümesinin değerlendirilmesiyle geliştirilmiştir. Çok sözcüklü fiil ifadelerinin çok dilli saptanması için BiLSTM tabanlı mimarilerin kapsamlı bir analizi bu doğrultuda sunulmuştur.","Verbal multiword expression (VMWE) identification is a challenging task for many natural language processing studies. In this study, sequence tagging approach accompanied with stochastic models and variants of IOB tagging scheme is used for VMWE identification. In the scope of this thesis, a VMWE annotated Turkish corpus is constructed as the first part of the PARSEME shared task 1.1 which is constructing VMWE annotated corpora in many languages. Additionally, a multilingual system called Deep-BGT is developed as the second part of the shared task which is developing language-independent VMWE identification systems using the corpora constructed in the first part. The Turkish corpus is one of the biggest corpora in the shared task. The training and test corpora that were published in the PARSEME shared task 1.0 are updated as the PARSEME shared task 1.1 training and development corpora according to the new guidelines. A new test corpus is constructed from scratch. Deep-BGT uses the bidirectional Long Short-Term Memory model with a Conditional Random Field layer on top (BiLSTM-CRF). To the best of our knowledge, this study is the first one that employs the BiLSTM-CRF model for VMWE identification. Deep-BGT was ranked the second in the open track in terms of the general ranking metric. Moreover, a novel tagging scheme called bigappy-unicrossy is introduced to rise to the challenge of overlapping VMWEs. Finally, the VMWE identification system is advanced by evaluating a subset of hyperparameters which consists of tagging scheme, number of units, number of BiLSTM layers, and classifier. A comprehensive analysis of BiLSTM based architectures for multilingual identification of VMWEs is presented accordingly."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyomedikal alandaki zorluklardan biri, elektronik kaynakların ve bu kaynaklardaki gömülü bilgilerin fazla olması ve hızla artmaya devam etmesidir. Biyomedikal varlıkların isimlerini bu elektronik kaynaklardaki metinlerde otomatik olarak belirlemek i ̧cin metin madenciliği yöntemleri geliştirmek ve bu varlıklar arasındaki ilişkileri belirlemek, birçok alandaki araştırmayı kolaylaştırmak için çok önemlidir. Bu hedefe ulaşmak için çözülmesi gereken iki ana sorun, belirli bir metindeki varlık isimlerinin belirlenmesi ile normalizasyonu ve bu varlıkların arasındaki ilişkilerin tanımlanmasıdır. Bu tezde, biyomedikal alandaki varlık isimlerinin metinlerden çıkarılması ve normalizasyonu için iki farklı bakış açısına sahip iki yeni yaklaşım önerilmiştir. Birinci yaklaşımda, metinlerdeki varlık isimlerini belirlemek ve onların bir ontoloji yoluyla normalizasyonunu sağlamak için sığ dilbilimsel bilgiden yararlanılmıştır. Öte yandan, ikinci yaklaşımda, metindeki varlık isimlerinin normalizasyonu için anlamsal bilgi içeren sözcük gömme işlemleri kullanılmıştır. Sözcük gömme temelli yaklaşım, BioNLP 2016 Bakteri Biyotop veri kümesi üzerinde mevcut yöntemlerden daha başarılı sonuçlar elde etmiştir. Önerilen yöntemlerin herikisi de denetimsizdir ve farklı alanlara uyarlanabilir. Ayrıca bu tezde, iki ayrı uygulama sunulmuştur. Birinci uygulama, bakterilerin biyotop bilgilerinin bilimsel özetlerden ̧cıkarılması için önerdiğimiz yaklaşımlara dayanan modüllerden oluşan bir sistemdir. Diğer uygulama ise, biyomedikal literatürden Brusella- konak etkileşimi ile ilgili verileri çıkarmak için geliştirilmiştir; bu uygulamanın sonuçları, biyomedikal ilişki çıkarımı için bir cümleden daha geniş bir bağlam kullanmanın önemini ortaya koymaktadır.","One of the challenges for scientists in the biomedical domain is the huge amountand the rapid growth of information buried in the text of electronic resources. Developing text mining methods to automatically extract biomedical entities from thetext of these electronic resources and identifying the relations between the extractedentities is crucial for facilitating research in many areas in the biomedical domain. Two main problems, which have to be solved to accomplish this goal, are the extraction andnormalization of entities, and the identification of the relations between them from agiven text.In this thesis, we proposed two approaches with two different perspectives for the extraction and normalization of biomedical named entities. The first approach makesuse of shallow linguistic knowledge to extract entities and normalize them through anontology. On the other hand, the second approach makes use of word embeddings, which convey semantic information, for the normalization of the entities in a giventext. The word-embedding based approach obtained the state-of-the-art results on theBioNLP Shared Task 2016 Bacteria Biotope data set. Both of the proposed methodsare unsupervised and can be adapted to different domains. We also developed twoapplications, one of which is a pipeline, which is composed of modules based on theapproaches that we proposed in this thesis, for the extraction of bacteria biotope information from scientific abstracts. The other application is developed for extracting Brucella-host interaction relevant data from the biomedical literature, whose resultsreveal the importance of using a wider context than a sentence for biomedical relation extraction."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ağlardaki arızalar, son kullanıcılar için hizmet kalitesinin kötüleşmesine sebep olabilen hizmet kesintilerine yol açmaktadır. Yazılım Tanımlı Ağlar (YTA), özellikle de veri merkezleri için, ana akım olmaya başladığından, YTA tabanlı ağlar için arıza toleransının doğru şekilde uygulanması çok önemlidir. Mevcut YTA veri düzlemi arıza toleransı yaklaşımları, sırasıyla merkezi kontrol cihazının katılımına dayanan veya dayanmayan reaktif ve proaktif olarak sınıflandırılabilir. Ancak, bu yaklaşımlar arızalar için kısmi çözümler sunmakta olup, bütünsel bir çözüm sunamamaktadır. Bu çalışmada, sadece ağdaki mevcut hataları değil, alternatif yolların kalitesini de dikkate alan dinamik (proaktif) bir koruma yaklaşımı öneriyoruz. Ayrıca, uygulama tabanlı parametrelerin olası arızalardan nasıl etkilendiğini de incelemekteyiz. Bu amaçla, video akışı için HTTP üzerinden Dinamik Uyarlamalı Akış (HDUA) kullanarak farklı durumlardaki bağlantı arızalarından kaynaklanan Deneyim Kalitesindeki (QoE) değişimi araştırıyoruz. Modern ağlarda muazzam miktarda trafik oluştuğu için tıkanıklık sorunu daha sık yaşanmaktadır. Video akışı paradigması, HDUA, ağların değişen koşullarına bir çözüm olarak önerilse de, bağlantı arıza semptomlarını gösteren yoğun yüklü bağlantılar göz önüne alındığında yeterli değildir. Bu nedenle, ağlardaki tıkanıklık gibi diğer sorunlara da uygulanabilecek esnek bir veri düzlemi arıza toleransı mekanizmasının gerçekleştirilmesi çok önemlidir. Bu nedenle, bu çalışmada, hem arıza hem de tıkanma durumlarında HDUA istemcilerinin deneyim kalitesini geliştirmek için YTA'daki veri düzlemi arıza toleransı yaklaşımını uyguluyoruz.","Failures in networks result in service disruptions which may cause deteriorated Quality of Service for the end users. Since SDN is becoming the mainstream paradigm for networks, especially for data centers, correct implementation of the fault tolerance for SDN-based networks is crucial. Current SDN data plane fault tolerance approaches can be classified as reactive and proactive which may or may not rely on the involvement of the central controller, respectively. However, none of them qualify as complete solutions, providing only partial remedies. In this work, we propose a dynamic protection approach that considers not only the existing faults within the network but also the quality of alternative paths. We also investigate how application based parameters are affected by possible failures. To this end, we explore the change in Quality of Experience (QoE) caused by link failures under different cases using Dynamic Adaptive Streaming over HTTP (DASH) for video streaming. Since tremendous amount of traffic is generated in modern networks, the congestion issue is faced more frequently. Even though the video streaming paradigm, DASH, is proposed as a solution for the changing condition of the networks, it is not sufficient considering the heavily loaded links that show the symptoms of the link failures. Therefore, the flexible implementation of the data plane fault tolerance scheme that can be applied to other problems like congestion in networks is crucial. Thus, we apply the data plane fault tolerance approach in SDN to improve the QoE of DASH clients in the case of congestion as well as the failure."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilişim sektöründe yapılan dijital dönüşüm geliştirmeleri, organizasyonlar için daha verimli çözüm bulabilmeleri açısından her geçen gün daha önemli hale gelmektedir. Kamu sektörü kuruluşları, süreçleri ek ürün ve servislerle zenginleştirip çözüme kavuşturmaya çalışmaktadır. Bunun yanında, özellikle gelişmekte olan ülkeler masraflarını azaltmak için ürün satın alımında yerli kaynaklara yönelmeye büyük önem vermektedir. Özellikle kamu sektörü ve askeri kuruluşlarda bilgi teknolojileri ürünlerinin ve teknoloji altyapısının yerli kaynaklarla geliştirilmesi veri güvenliği ve gizliliği açısından büyük önem arz etmektedir. Son zamanlarda yaşanan gelişmeler, Google'ın güvenliği sebep göstererek Android ürünlerinin Huawei telefonlarında kullanılmasını yasaklaması ve Amerika Birleşik Devletleri'nin veri gizliğinin korunmasını gerekçe göstererek F-35 jetlerinin Türkiye'ye satışını geri çekmesi, yerli üretimin önemi konusunda bir ipucu vermektedir. Bu yüzden yerli üretimin artırılabilmesi için ürünlerin yerliliğini ölçen güvenilir bir ölçek geliştirilmesi gerekmektedir. Bu çalışma özellikle bilgi teknoloji ürünleri için menşei ülkesini belirlemek adına bir metodoloji geliştirmeye odaklanmıştır. Önerilen metodoloji aynı zamanda uzman kişilerle yapılan görüşmeler sonucu tasdik edilmiştir.","Digital transformation enhancement in IT sector is getting crucial for efficient solutions in organizations. Institutions in public sector try to enrich its process solutions with additional products and services. On the other hand, in order to reduce financial expenses, especially developing countries give high emphasis on obtaining products with domestic resources. In addition to that, it becomes crucial for public and military institutions to develop IT products and technology infrastructure with domestic resources in order to preserve data security and privacy. The recent actions from Google company to ban Android products for Huawei smartphone producer for security reasons and United States withdraw for F-35 fighter jets sales to Turkey for strategic data privacy reasons give clue about the importance of domestic production. Thus, there is a need to develop a reliable scale to measure domesticity of products. This study attempts to construct a methodology for determining country of origin of IT products. Suggested methodology was verified by interviews with experts in subject area."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu araştırmada teknik göstergeleri farklı derin öğrenme yöntemleri ile kullanarak Bitcoin/Dolar paritesinin trendini tahmin etmek amaçlandı. Temel hedef, Bitcoin/Dolar paritesinin trendini tamin ederken, teknik göstergelerin kullanılması ile, yalın finansal veri olan açılış, kapanış, en yüksek, en düşük ve hacim (AKYDH) verilerinin kullanıldığı uygulamalardan daha iyi doğruluk başarım sonuçları elde etmek oldu. Bu doğrultuda, literatürde stok fiyatı tahmin etme alanında gösterdikleri başarımlardan ve teorik uyumluluklarndan ötürü, Derin Sinir Ağları (DSA), Uzun Kısa Vadeli Hafıza Ağları (UKVH) ve Kapılı Tekrarlayan Hücre (KTH) algoritmaları kullanıldı. AKYDH verilerine karşı test etmek amacı ile özellik kümesinde toplamda 156 adet teknik gösterge, matematiksel dönüşüm ve finansal kalıp kullanıldı. Bu araştırmadaki deneyler gösterdi ki, kullanılan bütün derin öğrenme modelleri için, teknik göstergeler kullanıldığında, bu göstergelerin kullanılmadığı, AKYDH verisinin kullanıldığı denemelerden daha başarılı sonuçlar elde edildi. Tek yönlü işlem komisyon oranı kullanılarak oluşturulan ve al, sat veya bekle sınıflarından oluşan, sınıf dağılımı açısından dengesiz veri kümesi için UKVH, kullanılan üç model arasında en başarılısı oldu. UKVH, bireysel sınıf tahminleme başarımlarının da kabul edilebilir ölçüde olduğu durumda %56.33'lük genel bir doğruluk tahminleme başarımı elde etti. AKYDH verisi ile bu başarım oranı en fazla %53.26 olabildi. Tek yönlü işlem komisyonu, daha dengeli dağılıma sahip bir veri kümesi elde etmek için değiştirildiğinde gözlemlenen en başarılı model %52.19 ile KTH oldu. Bu veri kümesi için AKYDH ancak %39.85'lik bir başarım elde edebildi.","This research focused on utilization of technical indicators for predicting the trend of Bitcoin/USD price with different deep learning algorithms. The goal was to achieve better trend prediction accuracy results using technical indicators compared to using only close, open, high, low and volume (OHLCV) data for Bitcoin/USD parity. Through achieving this goal, three different deep learning algorithms, Deep Neural Networks (DNN), Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU) were used because of the performance they exhibit in literature for financial stock prediction domain and their theoretical convenience. 156 technical indicators, mathematical transformations and financial patterns were used in feature set to test against OHLCV data of Bitcoin/USD. Experiments in this research showed that, utilization of technical indicators produced better accuracy results compared to OHLCV data for all three prediction models. For the imbalanced dataset distribution produced by a one-way transaction cost to decide buy, hold or sell operations, LSTM performed best among the models used in this research with achieving 56.33% accuracy score with reasonable individual class prediction rates whereas raw data could achieve 53.26%. In the scenario for which the one-way transaction cost is tuned to have a uniformly distributed dataset, GRU performed best with achieving 52.19% accuracy score whereas raw data could achieve 39.85%."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal Ağ Siteleri (SAS), kullanıcıların yaşam tarzlarını, fikirlerini, bilgi ve haberleri paylaştığı, diğer kullanıcılarla iletişim kurduğu çevrimiçi platformlardır. Herhangi bir konuda araştırma yapmak için sosyal ağ siteleri bilgi kaynağı olarak tercih edilebilir. Bu araştırmada, kripto para hakkında tweet atmış olan Twitter kullanıcılarının başka hangi konular'a ilgili olduklarını, kendi tweet'lerini konu çıkarma algoritmasını kullanarak analiz ettik. Mevcut literatürdeki kripto para birimi kullanıcılarını ilgi alanlanlarını belirlemek için çok az araştırma yapılmıştır. Twitter'ı veri kaynağı olarak seçilmesinin nedeni, Twitter'ın Twitter Uygulama Programlama Arayüzleri (API'ler) aracılığıyla kolay erişimle güncel ve geçmiş verilere erişim sağlamasıdır. Araştırmaya dahil edilecek olan Twitter kullanıcılarına erişilebilmesi için, anahtar kelimelerden oluşan bir arama sorgusu oluşturuldu. Bu anahtar kelimeler bitcoin, ethereum, ripple, btc, blockchain, fintech ve cryptocurrency olarak belirlenmiştir. Veriler, kripto para birimleri hakkında tweet atan Twitter kullanıcılarından toplanan tweet'lerden oluşmaktadır. Bu tweet'ler, konu çıkarma algoritmalarından biri olan Latent Dirichlet Allocation (LDA) kullanılarak analiz edildi. LDA analizinin sonunda, kripto para birimi ile ilgilenen Twitter kullanıcılarının politika, ekonomi, çığır açan teknolojiler, dijital bankacılık, sosyal yaşam,veri bilimi ve küreselleşme gibi konulara ilgi gösterdikleri tespit edilmiştir.","Social Networking Sites (SNSs) are online platforms in which users present their lifestyles and opinions, share information and news, and communicate with other users. SNSs have been the preferred source of information for doing academic research on any subject. In this thesis, the interest areas of Twitter users who tweeted about cryptocurrencies were scrutinized by analyzing their tweets with a topic extraction algorithm. Little research has been conducted to identify the interest areas of cryptocurrency users in the current literature. As the data source, Twitter is chosen because Twitter provides current and historical data with easy access through Twitter Application Programming Interfaces (APIs). In order to reach Twitter users, a search query consisting of the keywords to be used was created. The keywords included ""bitcoin, ethereum, ripple, btc, blockchain, fintech, and cryptocurrency"". Therefore, the data composed of tweets that were collected from Twitter users who tweeted about cryptocurrencies. These tweets were analyzed by using Latent Dirichlet Allocation (LDA), which is one of the well-known topic extraction algorithms. According to the result of LDA, Twitter users tweeted about cryptocurrency are found to be also interested in politics, economy, disruptive technologies, digital banking, social life, and data science."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaret dilinde yüz ifadeleri ve kafa hareketlerinin tanınması konusu ihmal edilmektedir. Bu ihmalin nedenlerinden biri olarak etiketlenmiş veri seti eksikliği gösterilebilir. Bu çalışmada, yüz ifadeleri ve kafa hareketlerinin yer aldığı, manuel olmayan işaretleri içeren bir Türk İşaret Dili (TİD) veriseti toplanıp, video kareleri seviyesinde işaretleme yapılmıştır. Bu tezde Türk İşaret Dili kafa hareketleri ve yüz ifadeleri veri seti sunulmakta ve manuel olmayan işaretler için bir temel tanıma sistemi önerilmektedir. Derin öğrenmeye dayalı tanıma sisteminde, önceden eğitilmiş ResNet konvolüsyonel sinir ağı kullanılarak soru, olumsuzluk, tasdik etme ve acı hareket ve ifadeleri tanınmaya çalışılmıştır. Ana dili Türk İşaret Dili olan beş öznenin işaretleri yaptığı 483 video zamansal olarak işaretlenmiştir. Deney testleri, bir özneyi dışarda bırakma tekniği kullanılarak yapılmıştır. Doğru sınıflandırılan işaretlemelere göre başarım, soru, olumsuz-sağ-sol, olumsuz-yukarı-aşağı, acı ve tasdik sınıfları için sırasıyla % 55.77, % 14.63, % 72.83, % 10 ve % 11.67 olarak ölçülmüştür. Sırasıyla farklı özneleri dışarda bırakarak eğitilen beş farklı model ve yeni bir verisetinden alınan işaret dili videoları ile çapraz veriseti deneyleri yapılmıştır. Etiketlenen 87 kısa klipten, acı sınıfı dışındaki dört sınıfa ait işaretlemeler elde edilmiştir. En iyi performans gösteren model soru işaretlemelerinin % 66.67'sini ve olumsuz-yukarı-aşağı işaretlemelerinin % 42.31'ini doğru sınıflandırmakta, geri kalan sınıflara ait tahmin yapamamaktadır.","Recognition of non-manual components in sign language has been a neglected topic, partly due to the absence of annotated non-manual sign datasets. We have collected a dataset of videos with non-manual signs, displaying facial expressions and head movements and prepared frame-level annotations. In this thesis, we present the Turkish Sign Language (TSL) non-manual signs dataset and provide a baseline system for non-manual sign recognition. A deep learning based recognition system is proposed, in which the pre-trained ResNet Convolutional Neural Network (CNN) is employed to recognize the question, negation side to side and negation up-down, affirmation and pain movements and expressions. 483 TSL videos performed by five subjects, who are native TSL signers were temporally annotated. We employ a leave-one-subject-out approach for performance evaluation on the test videos. We have obtained annotation-level accuracy values of 55.77%, 14.63%, 72.83%, 10% and 11.67% for question, negation-side, negation-up-down, pain and affirmation classes respectively in the BosphorusSign-HospiSign non-manual sign datasets. Question, negation-side, negation-up-down and affirmation movements and expressions in 87 clips from the TSL translation video of a Turkish movie are temporally annotated for cross-database experiments. The models that are fine-tuned on BosphorusSign-HospiSign set are tested with the clip frames. The best performing model classifies 66.67 \% of question annotations and 42.31% of negation-up-down annotations correctly, while the remaining class labels could not be predicted."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Metinde bir olayın geçtiğini gösteren en küçük kelime grubuna olay göstergesi denmektedir. İngilizce, İspanyolca ve Çince gibi dillerde çalışılmıs olan olay göstergelerinin tespiti bize daha çok araştırma yapılmasını ve birçok uygulamayı mümkün kılmaktadır. Türkçe'de ise ilk defa olay göstergesi tespiti ve olay göstergesi türü sınıflandırması konusu bu araştırmayla biz çalıştık. Olay göstergesi tespiti için Türkçe bir veri kaynağımız olmadığından dolayı bu problem için kendimiz bir veri kümesi geliştirdik. Bu araştırmada veri kümesini nasıl geliştirdiğimizi ve Türkçe haber metinleri için olay göstergesi tespiti ve olay göstergesi türü sınıflandırması yapan sistemimizi tanıttık. Veri kaynağı çeşitli Türkçe haber sitelerinden alınmış haberlerin içindeki kelimelerden oluşmaktadır. Veri kümesindeki her kelime elle dizi türü, gösterge türü, gösterge alt türü, realis değeri ve ana olay olup olmamasına göre işaretlenmiştir. Böylelikle bu veri kümesini olay göstergesi tespiti, olay türü sınıflandırması, realis değeri ve ana olay sınıflandırması çalışması yapmamıza olanak sağlamaktadır. Bu işaretlenmiş veri kümesi üzerinde çeşitli sınıflandırma metotları denedik. Türkçe'ye özgü morfolojik ve bağlılık ayrıştırma özelliklerinin yanısıra diğer özelliklerden de yararlandık. Bunu yaparken dile özgü özelliklerin sınıflandırmada nasıl bir etkisi olduğunu görmeyi amaçladık. Farklı makine öğrenmesi algoritmalarını kullanarak olay göstergesi tespiti, olay göstergesi türü sınıflandırması, realis değeri bulma ve ana olay tespiti için en başarılı modeli bulmaya çalıştık. Çalışmamızın sonunda Türkçe'ye özgü morfolojik ve bağlılık ayrıştırma özelliklerinin ve kelime temsillerinin sonuçlarımızı iyileştirdiğini gözlemledik.","Event nuggets are smallest textual instance that marks the existence of an event. Detecting event nuggets in a given text opens door to further research and many practical applications, therefore it has been studied extensively for some lan- guages including English, Spanish and Chinese. In this study, event nugget detection and event type classification for Turkish is studied for the first time. Due to lack of annotated data for event nugget detection in Turkish, we developed a new annotated dataset for this task. In this study we described how we manually annotated our dataset as well as our system to identify event nuggets in Turkish news texts. The dataset consists of words from Turkish news texts. Each word in the dataset is manually annotated in terms of sequence type, nugget type, realis value and whether the event nugget is the main event, thus enabling us to make analysis on this dataset for event nugget detection, event type classification, realis classification and main event detection. We made use of language specific features like morphological features and dependency parser features in Turkish as well as some other features. We aimed to see the effect of language specific features on this kind of analysis. We also experimented with different machine learning algorithms to find the best fitting model for our tasks. After having completed our experiments, we have shown that Turkish specific morphological features, dependency tree related features as well as word embeddings enabled us to achieve better results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, sosyal ağ analitiklerine dayalı bir öneri sistemi için farklı çerçeveler incelenmiştir. Bu çerçevelerde, üç farklı potansiyel müşteri tanımlama yaklaşımı incelenmiş ve bunlara karşılık gelen başarılar analiz edilmiştir. Temel ağ yapısından yararlanmak için, restoran kullanıcısı, kullanıcı kullanıcısı ve restoran restoranı olmak üzere üç ağ üretilir. İlk yaklaşımda, potansiyel kullanıcılar hem restoranların hem de kullanıcıların topluluk sayfası puanlarının ve sayfa sıralaması değerlerinin bir birleşimine göre sıralanır ve seçilir. İkinci yaklaşımda kullanıcılar, yorumlarının duygu puanlarına ve restoranların sayfa sıralamasına göre sıralanır. Üçüncü yaklaşımda, restoran-kullanıcı ağı için düğüm yerleştirmeleri hesaplanır ve kullanıcılar ile restoranlar arasındaki benzerlikleri bulmak için kullanılır. Daha sonra, bu benzerliklere dayanarak, potansiyel kullanıcılar belirli bir odak restoranında sıralanır. Bu üç çerçevenin başarısını karşılaştırmak amacıyla veri kümesi üçe bölünmüş ve üretilen modeller tarafından önerilen gerçek müşteri yüzdesine göre başarı oranları hesaplanmıştır. Bu araştırmadaki denemeler, topluluk yapısını hem kullanıcıların hem de markaların ağ sıralamasıyla birlikte kullanan Sıralamalar çerçevesinin %50'ye kadar ulaştığını ve önerilen potansiyel müşteri sayısı 100 olarak alındığında ortalama % 9.61 doğruluk elde ettiğini göstermektedir. Altta yatan ağ yapısını kullanan çerçeveler, belirli bir şirket veya marka için potansiyel müşteriler bulan öneri sistemlerinin öngörme kabiliyetini geliştirmek için kullanılabilir.","In this thesis, different frameworks for a recommendation system based on social network analytics is investigated. In these frameworks, three different potential customer identification approaches are examined and corresponding successes are analyzed. In order to exploit the underlying network structure, three networks, restaurant-user, user-user and restaurant-restaurant, are generated. In the first approach, potential users are ranked and selected according to a combination of pagerank values and community scores of both restaurants and users. In the second approach, users are ranked according to the sentiments scores of their comments in conjunction with pagerank of restaurants. In the third approach, node embeddings for the restaurant-user network are computed and used to find the similarities between users and restaurants. Then, based on these similarities, potential users are ranked for a given focal restaurant. With the aim of comparing the successes of these three frameworks, dataset is splitted into three and success rates are calculated based on the percentage of the actual customers recommended by the generated models. Experiments in this research shows that Ranks framework utilizing the community structure together with the network ranking of both users and brands reached up to 50% and on average achieved 9.61% accuracy when the number of potential customers to be recommended is taken as 100. So, frameworks utilizing the underlying network structure can be exploited to improve the prediction capability of recommendation systems that find potential customers for a given company or brand."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Difüzyon ile moleküler haberleşme difüzyon bazlı bir kanal üzerinde bilgi iletimine dayanmaktadır. Bu kanalın tasarımı kritik bir konudur. Bu tezde, haberleşme sisteminin bütün parçalarını içerisinde bulunduran ve kan damarına benzeyen silindirik bir ortam olan damarsı ortam çalışılmıştır. Haberleşme mesafesinin kan akışı sebebiyle bu tarz ortamlarda artıp uzun mesafeli uygulamalara olanak tanımasına rağmen, analitik analizler için çok uygun bir ortam değillerdir. Bu sebeple, haberleşme ortamı olarak damarsı ortamı kullanan çalışmaların bir çoğu analitik sonuçlardansa simülasyon sonuçlarına dayanmaktadır. Bu boşluğu doldurmak ve göndericinin yerini tespit etmek maksadıyla, yüzük şeklinde pasif alıcı ve Poiseuille akışını dikkate alarak, difüzyon bazlı hareketin hakim olduğu kanal modelinin analitik formülünü çıkardık. Sonrasında, bu kanal modelini kullanarak bilinen ve bilinmeyen salınım başlama zamanı olmak üzere iki farklı uygulama senaryosu için formül çıkardık. Bilinen salınım zamanı için göndericinin yerini tek bir alıcı kullanarak tespit edebilirken, bilinmeyen salınım zamanı için iki alıcı kullanarak göndericinin yerini tespit ettik. Bunlar dışında, sinyal gürültü oranı metriğine alternatif olarak, MOL-Eye diyagramı ve bu diyagramın bazı metriklerini (biriken sinyal gürültü oranı gibi) moleküler sinyalin performansının hesaplanması maksadıyla önerdik. Ayrıca, binary concentration shift keying with consecutive power adjustment (BCSK-CPA) adını verdiğimiz modülasyon tekniğini yıkıcı girişimin etkisi azaltıp, yapıcı girişimin etkisini arttırması amacıyla önerdik. Bunlar dışında, damarsı ortamda farklı alıcı ve akış gibi bileşenler kullanıldı. Son olarak, kısmı kapsayan alıcı yeni bir alıcı tipi olarak önerilmiş ve bu ortamın kanal modeli tasarlanmıştır. En sonunda, oluşturulan yapıların tamamı özel yapılmış simülatör ile doğrulanmıştır.","Molecular communication via diffusion is based on relaying information over a diffusive channel. The design of this diffusive channel is a vital issue. In this thesis, diffusion in the vessel-like environment, which is composed of a cylindrical environment resembling a blood vessel encompassing all the components of the communication system, is studied. Even though the range of communication increases in such environments due to the effect of the blood flow, vessel-like environments are not very suitable for analytical analysis. Therefore, many works, which considered vessel-like environment as the communication environment, are based on the simulation results rather than the analytical results. In order to fill this gap in the literature and to be able to localize the transmitter, we derive the analytical formulation of the channel model for diffusion-dominated movement, considering ring-shaped observing receivers and Poiseuille flow. Then, we derive formulations using this channel model for two different application scenarios, known and unknown emission time. A single receiver is used to localize the transmitter for known emission time, whereas two receivers are used for unknown emission time. Besides, as an alternative to signal-to-noise ratio (SNR), we propose MOL-Eye diagram and some metrics of this diagram (e.g., counting SNR) for the performance evaluation of a molecular signal. Also, binary concentration shift keying with consecutive power adjustment (BCSK-CPA) modulation technique is proposed to decrease destructive inter-symbol interference (ISI) effect and increase constructive ISI effect. Moreover, within the vessel-like environments, different values for the components of the environment (e.g., receiver, flow) are investigated. Lastly, partially covering receiver is proposed as a new type of receiver, and channel model of such environment is devised. Finally, all of the devised frameworks are validated with custom-made simulators."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Makine ve derin öğrenme konusundaki gelişmeler ve büyük verideki ilerleyiş ile birlikte birlikte bilgisayarlı görme, sosyal bilimler de dahil olmak üzere birçok alanı desteklemeye başlamıştır. Her ne kadar psikoloji ve alt dallarında sosyal sinyal işleme için bilgisayarlı görme kullanılsa da, oyun terapisi alanında bilgisayarlı görme kullanımında çalışma eksikliği vardır. Psikoterapik yaklaşımın bir çeşidi olan oyun terapisi bu tür öğrenme tekniklerinin uygulanması açısından uygun fakat çeşitli vücut pozlarının varlığı, farklı oyun aktiviteleri olması ve insanlar ve objelerin üstüste gelmesi gibi nedenlerden dolayı zorlu bir alandır. Bu çalışmada, iki köşegen kamera kullanarak çocuğun oyun terapisi sırasındaki duygulanım analizini izlemek için bir yaklaşım araştırılmaktadır. Ayrıca, terapi odasındaki çocuğu ve terapisti ayırt edebilmek için geliştirdiğimiz insan takip modülü sunulmaktadır. Son olarak, alan uzmanları için zamansal veriler üzerindeki etkiyi etkileşimli olarak görselleştiren, web tabanlı duygulanım analizi aracı tanıtılmaktadır. Bu çalışmada, terapi seansı sırasındaki metinlerin, yüzlerin ve vücut hareketlerininin analizi olmak üzere çeşitli yöntemler ve bu yöntemlerin birleştirilmesi üzerinde deneyler yapılmaktadır. Bu çalışmada, iki milyon yüz ifadesi içeren yaklaşık 350 saatlik terapi videosu kullandık. Sonuçlarımız önerilen sistemin umut verici ve yine de farklı aşamalarda gelişime açık olduğunu göstermektedir.","With recent developments in machine and deep learning techniques and the advent of big data, computer vision supports many disciplines, including social sciences. Although computer vision is used in social signal processing in psychology and its sub-branches, there is a lack of studies in the field of play therapy. Play therapy is a psychotherapeutic method, and it is a convenient yet challenging field to apply automatic computer analysis techniques due to the extensive range of body poses, the existence of various play activities, and occlusions with people and objects. In this thesis, we investigate an approach to track the affective state of a child during a play therapy session with two diagonal cameras. Moreover, to differentiate the therapist and the child in the therapy room, we introduce a human tracking module. Finally, we provide a web-based affect analysis tool for the field experts to interactively visualize affect over longitudinal data. We conduct experiments on various modalities and their fusions, including text analysis, face analysis and body motion analysis during the therapy session. In this study, we used about 350 hours of therapy videos, containing two million facial expressions. Our results show that the proposed system is promising and yet still open to improvement at different stages."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin pekiştirmeli öğrenme algoritmaları ile eğitilen etmenler, sürekli ortamlarda hareket dahil olmak üzere oldukça karmaşık görevleri gerçekleştirme yeteneğine sahiptir. İnsan düzeyinde bir performans elde etmek için bir görevde edinilen öğrenmeyi bilinmeyen görevlere transfer etme yeteneğini geliştirmek bu alandaki araştırmalarının bir sonraki adımı olmalıdır. Derin pekiştirmeli öğrenmede genelleme, öğrenim aktarımı araştırmalarında yeterince ele alınmamaktadır ve hatalı değerlendirme kriterlerine yol açarak yanlış algoritma karşılaştırmalarına neden olmaktadır. Bu tezde, örnekleme seçilimi ve erken durdurma yoluyla sürekli kontrol için politika gradyan algoritmalarına özgü yeni düzenleme teknikleri önerdik. Kırpma parametresi ile örnekleme seçilimi önererek aşırı öğrenmeye engel olarak, yüksek genelleme kapasitesine sahip bir robot için dayanıklı politikalar elde ettik. Derin öğrenme aktarımı problemlerinde yaygın olarak kullanılan hiperparametrelere optimizasyon iterasyonunun da dahil edilmesini önerdik. Yöntemlerimizin geçerliliğini farklı yerçekimleri ve teğetsel sürtünme ortamlarına başarılı öğrenim aktarımı gerçekleştirerek kanıtladık. Ağır kutu taşıyan bir kurye robotu deneyi tasarladık ve metotlarımızın üstün performansını grafiklerle gösterdik. Standart insansı robottan daha uzun ve daha kısa insansı robotlara başarılı bir şekilde yürüme görevini aktardık. Kaynak görev performansı, algoritmanın genelleştirme kapasitesinin bir göstergesi olmadığı için üç farklı öğrenimi aktarımı değerlendirme yöntemi önerdik. Entropi bonusu, farklı eleştirmen mimarileri ve müfredat öğrenimi kullanarak dayanıklı çekişmeli pekiştirmeli öğrenme algoritmasının genelleştirme kapasitesini arttırdık. Çekişmeli ağlar için genelleştirilmiş avantaj hesaplayıcısı tasarladık ve geliştirdiğimiz bu yöntem ile zıplayıcı robotu ağırlaştırdığımız hedef ortamda daha iyi performans gösteren politikalar elde ettik. Çekişmeli algoritmaların dayanıklılığını morfolojik olarak değiştirilmiş zıplayıcı robotlarda ve bilinmeyen yerçekimli ortamlarda tasarladığımız kriterlere göre değerlendirdik.","Agents trained with deep reinforcement learning algorithms are capable of performing highly complex tasks including locomotion in continuous environments. In order to attain a human-level performance, the next step of research should be to investigate the ability to transfer the learning acquired in one task to unknown tasks. Concerns on generalization and overfitting in deep reinforcement learning are not usually addressed in current transfer learning research. This issue results in simplistic benchmarks and inaccurate algorithm comparisons due to rudimentary assessments. In this thesis, we propose novel regularization techniques exclusive to policy gradient algorithms for continuous control through the application of sample elimination and early stopping. By discarding samples that lead to overfitting via strict clipping we will generate robust policies for a humanoid with high generalization capacity. We also suggest the inclusion of training iteration to the hyperparameters in deep transfer learning problems. We recommend resorting to earlier snapshots of parameters depending on the target task due to the occurrence of overfitting to the source task. We demonstrate that a humanoid is capable of performing forward locomotion in unseen environments with different gravities and tangential frictions using strict clipping and early stopping. Furthermore, we evaluate our propositions on a delivery task where a humanoid is required to carry a heavy box while walking and inter-robot transfer tasks where the humanoid transfers its learning to taller and shorter robots. Because source task performance is not indicative of the generalization capacity of the algorithm we propose three different transfer learning evaluation methods. We increase the generalization capacity of a state-of-art adversarial algorithm by introducing entropy bonus, proposing different critic architectures and using simpler adversaries. Finally, we evaluate the robustness of these adversarial algorithms on morphologically modified hopper environments and environments with unknown gravities according to the criteria we proposed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çekişmeli üretici ağlar (ÇÜA), eğitim kümesindeki ""gerçek"" örnekler ile üretici ağ tarafından üretilen ""sahte"" örnekleri birbirinden ayırmak için eğitilen bir ayırıcı ağ yardımıyla üretken bir model öğrenen bir derin öğrenme mimarisidir. ÇÜA'nın üretici ağı düşük boyutlu bir saklı uzay vektörünü girdi olarak alıp bu vektöre karşılık gelen bir örnek üretir. Yakın zamanda öne sürülen çift yönlü ÇÜA'da (ÇYÇÜA) ise ek bir kodlayıcı ağ yardımıyla ters yöne gidilerek girdi olarak verilen bir örnekten saklı uzay vektörü elde edilir. Bu tezdeki ilk katkımız, yine yakın zamanda önerilen Wasserstein ÇÜA'da kullanılan Wasserstein yitiminin ÇYÇÜA'ya uyarlanmasıdır. ÇYÇÜA'ya eklenen kodlayıcı ağ aynı zamanda ipucu niteliğinde yardımcı geri çatma yitimleri tanımlanmasını ve böylece daha iyi eğitilmesini sağlayabilir. Bu tezdeki ikinci katkımız da bu yardımcı geri çatma yitimlerinin tanımlanması ve uygulanmasıdır. Resim içerikli beş farklı veri kümesinde deneyler yapılarak Wasserstein ÇYÇÜA'nın ipuçları eklenmiş halinin resim üretim kalitesi ve çeşitliliği açısından daha iyi üretici ağlar öğrendiği gösterilmiştir. Bu sonuçlara hem üretilen resimlerin görsel analizi, hem de üretilen resimlerle veri kümesinde bulunan gerçek resimler arasında yapılan en-yakın-bir-komşu sınaması sonucu elde edilen nicel verilerin analizi ile varılmıştır.","The generative adversarial network (GAN) is a deep learning architecture that learns a generative model by training a later discriminator to best differentiate ""fake"" examples generated by the generator from the ""true"" examples sampled from the training set. The generator of GAN takes a low-dimensional latent space vector as input and learns to generate the corresponding input example. The aim of the generator is to generate examples that can not be separated from the true examples by the discriminator. The aim of the discriminator is to maximize the separability of the generated examples from the true examples. A recent extension is the bidirectional GAN (BiGAN) where an encoder is also trained in the inverse direction to generate the latent space vector for a given training example. Recently, Wasserstein GAN has been proposed for GAN and our first contribution is to adapt Wasserstein loss to BiGANs. The added encoder of the BiGAN also allows us to define auxiliary reconstruction losses as hints to learn a better generator, and this is our second contribution. Through experiments on five image data sets, namely, MNIST, UT-Zap50K, GTSRB, Cifar10, and CelebA, we show that Wasserstein BiGANs, augmented with hints, learn better generators in terms of image generation quality and diversity, as measured visually by analyzing the generated samples, and numerically by the 1-nearest-neighbor test."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım tanımlı ağların (YTA) kontrol düzleminde sağlamlık, tek bir kontrolör kullanıldığında zorlayıcı bir amaçtır. Bu nedenle, dağıtık kontrolörler sağlam, esnek ve güvenilir bir yazılım tanımlı ağ oluşturmak için görevlendirilir. Buna rağmen, böyle bir strateji, etkili bir kontrolör-ağ anahtarı atama şeması olmadan başarılı olamaz. Sıfırıncı gün atamasına ek olarak, çevrimiçi yeniden atama çok önemlidir, çünkü ağdaki arızalar nedeniyle kontrolörler ve anahtarlar arasındaki bağlantılar aralıklı olarak kopabilir ve ağın çalışmasını bozabilir. Bu çalışmamızda, kontrolörlerin yük dağılımına dayanan tamsayılı doğrusal programlama kullanarak ağdaki arızalara karşı reaktif bir atama modeli önerdik. Ayrıca, YTA'nın esnekliği sayesinde, izleme ajanlarını kenarda ağ fenerleri olarak kullanarak da ağı izlemek için tamamlayıcı bir stratejiden yararlandık. Ağ bağlantısı ve ağdaki gecikmeler hakkında gerçek zamanlı bilgiler, reaktif denetleyici-anahtar atamasında kullanılması için izleme ajanları tarafından sağlandı. Anahtar, link ve kontrolör arızaları için benzetilmiş tavlama ve rasgele atama yaklaşımlarıyla önerilerimizi çoğalttık. Önerilen çerçevemiz VoIP, video ve oyun gibi farklı trafik türleri kullanılarak değerlendirildi. Modelimiz ayrıca, izleme ajanlarının yardımını anlamak için iki farklı test senaryosu kullanılarak test edildi. Deneysel sonuçlar, modelimizin ağdaki arızalara karşı dayanıklılık kazandırdığını ve yük farkındalığının kontrolör-anahtar ataması için etkili bir strateji olduğunu gösterdi.","Robustness in software defined networks (SDN) control plane is a challenging goal when a single controller is employed. Thus, distributed controllers are deployed to realize a robust, resilient and reliable software defined network. However, such a strategy can not succeed without an efficacious controller-switch assignment scheme. In addition to zero-day assignment, online re-assignment is crucial since due to network failures, the connections between controllers and switches may break off intermittently and impair the network operation. In this thesis, we propose a reactive assignment model against network failures using integer linear programming based on the load distribution of controllers. We also use a complementary strategy to monitor the network by using monitoring agents as network beacons at the edge via the flexibility of SDN. Real-time information about network connectivity and latency is provided by these agents and used in the assignment decisions. We augment our proposal with simulated annealing and random assignment approaches for switch, link and controller failures. Our proposed framework is evaluated using different types of traffic such as VoIP, video, and network gaming. Our model is also investigated using two different test scenarios to assess the contribution of monitoring agents. The experimental results show that our model gives resilience against network failures while load-awareness is an effective strategy for controller assignment."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Statistical information about traffic patterns help a service provider to characterize its network resource usage and user behavior, infer future traffic demands, detect traffic and usage anomalies, and possibly provide insights to improve the performance of the network. However, the increasingly high volume and speed of data over modern networks make collecting these statistics difficult. Moreover, smarter network attacks require sophisticated detection methods that are able to fuse many network and hardware signals. Fortunately, Bayesian statistical methods are powerful tools that can infer such information under the harsh network environments. In this thesis we apply two Bayesian methods for two specific network problems. First, we use the Bayesian multiple change models to detect DDoS attacks in SIP networks by fusing the observations coming from the network traffic and the networking hardware. We show that our method is superior to classic DDoS detection methods and using hardware signals improve the detection rate. For this work, we developed a probabilistic SIP network simulator and a monitoring system, and published it as an open-source software. In our second work, we estimated network statistics from a high speed network where we can only observe a fraction of the network traffic. For this problem we develop a generic novel method called ThinNTF, based on non-negative tensor factorization. This method can work with different network sampling schemes and recovers original network statistics by detecting the periodic network traffic patterns from the sampled network data and gives better estimates compared to the state of the art.","Trafik örüntüleri hakkındaki istatistiksel veriler, ağ sağlayıcılarına ağlarındaki kaynak kullanımı ve kullanıcı davranışlarını nitelemek, gelecekteki ağ gereksinimlerini kestirmek, ağ olağandışılıklarını sezmek ve başarımı iyileştirmek konularında yardımcı olurlar. Bununla birlikte, günümüz ağlarında gittikçe artan yüksek veri hacmi ve hızı bu istatistiklerin elde edilmesini güçlendirmektedir. Dahası, akıllı ağ saldırıları ağ trafiği ve ağ donanımından gelen sinyalleri birleştirebilen, ileri tespit yöntemlerine ihtiyaç duymaktadır. Neyse ki, Bayesçi istatistiksel yöntemler zorlu ağ ortamlarında bu verileri elde edebilecek araçlardır. Bu tezde iki farklı Bayesçi yöntemi farklı problemlere uyguladık. İlkinde hem ağ trafiği hem de ağ donanım verisi kullanan bir Bayesçi çoklu değişim noktası modeli kullanarak SIP ağlarındaki DDoS saldırılarını yakaladık. Yöntemimizin diğer DDoS tespit metodlarından daha iyi olduğunu ve ağ donanım bilgisini kullanmanın başarımı arttırdığını gösterdik. Bu çalışma için olasılıksal bir SIP ağı benzetime ve gözetleme sistemi geliştirdik ve açık kaynak kodlu olarak yayınladık. İkinci çalışmamızda sadece bir kesmini gözlemleyebildiğimiz hızlı bir ağ üzerindeki ağ istatistiklerini kestirdik. Bu problem için ThinNTF adını verdiğimiz, negatif olmayan tensor ayrışımı tabanlı genel bir yöntem geliştirdik. Bu yöntem farklı ağ trafiği örnekleme şemalarıyla birlikte kullanılabilmekte ve örneklenmiş veriden dönemsel ağ istatistiklerini çıkartarak asıl istatistikler elde etmekte ve bu ilave bilgiyi kullanmatan yöntemlerden daha başarılı sonuç vermektedir."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde kullanılan mobil data ve uygulamalardan çok daha önce Konum Bazlı Sosyal Ağlar (KBSA), kısa mesaj servisleri ve toplu yayın özelliklerinin de yardımıyla kullanılmaya başlanmıştı. Teknolojinin ilerlemesi nedeniyle, bugün kullandığımız araçlar konum bilgisine sahip ve bu araçlar birçok insanın erişimine açık. KBSA'ların en çok kullanılanlarından biri olan Foursquare, oyun oynama motivasyonu ile sosyal ağ kavramlarını bir araya getirdi ve yeni bir iş modeli oluşturdu. Bu noktadan sonra KBSA'lar, satın alma kararını etkileyen, özellikle araştırma, alternatiflerin karşılaştırılması ve satın alma sonrası degerlendirme başlıklarında önemli araçlar haline geldiler. Özellikle, mekanların müşterileri tarafından yapılan değerlendirme sonuçları satın alma kararı için önemli bir karar verme parametresi olmaya devam ediyor. Ancak Foursquare'in karmaşık ve gizli değerlendirme sayısal değer hesaplama algoritması, kullanıcılar ve özellikle de mekan sahipleri için gizemini koruyor. Bu çalışmanın amacı, ""check in"", yorum, puan, fotoğraf, fiyatlama gibi parametreleri kullanarak, mekan skorunu tahminleyen bir model önermektir.","Location Based Social Networks (LSBNs) has started with broadcasting the location via text messages long before the mobile applications and mobile data. Due to the technological developments, a notable number of technologies we use today are location-aware, and they are available to more people. When one of the most popular LSBN, Foursquare, has brought together both motivation of gameplay and social networks, and it introduced a new business model to the market. They have used points and badges to motivate users for ""checking in"" to locations. After that point, LSBNs started to be a useful tool that effected purchase decision and became vital for information research, evaluation of alternatives and post-purchase evaluation. Typically, the score of the venues is a significant decision-making parameter for most of the users for a purchase decision. Due to the complex and undisclosed score calculation method of Foursquare, it has been a wonder to users and venue owners. Purpose of the research is to build a model that can predict venue scores based on variables such as check-in counts, review, tip and photo counts of venues."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dinamik grup anahtarı anlaşma protokolleri, dağıtık ve dinamik ağlarda güvenli grup iletişimi sağlayan temel kriptografik öğelerdir. Bu protokoller, sağladıkları faz-ladan operasyonlar ile gruba yeni katılımcılar eklendiğinde ya da mevcut katılımcılar gruptan ayrıldığında, protokolü en baştan çalıştırmadan grup anahtarının güncellen-mesini sağlamaktadır. Ancak, grup katılımcılarının sayısı arttıkça, ölçeklenebilirlik eksikliği dinamik grup anahtarı anlaşma protokollerinin başlıca sorunlarından biri haline gelmektedir. Örnek olarak, büyük gruplara sık bir şekilde gelen katılımcı ekleme isteği Dağıtık Servis Dışı Bırakma saldırısına benzer bir etkiye sebep olarak, sistemin kullanılırlığının ihlal edilmesine yol açabilir. Bu sebeple, dinamik grup anahtarı anlaşma protokollerinin ölçeklenebilirlik analizinin yapılması, sistemin kullanılamaz noktaya geldiği durumların tespiti açısından çok önemlidir. Bu tezde, dinamik grup anahtarı anlaşma protokollerinin ölçeklenebilirlik değerlendirmesini kuyruk modelleri aracılığıyla yapan biçimsel bir başarım modeli öneriyoruz. Ayrıca, başarım modelimizi dinamik grup anahtarı anlaşma protokolleri kullanan güvenli dosya paylaşım sistemlerinin ölçeklenebilirlik analizini de kapsayacak şekilde genişletiyoruz. Buna ek olarak, modelimizin örnek bir dinamik grup anahtarı anlaşma protokolü ve bir güvenli dosya paylaşım sistemi üzerinde uygulanabilirliğini gösteren bir kullanım senaryosu sunuyoruz. Dahası, grup iletişim sistemlerine karşı kullanılabilecek saldırı modelleri tasarlayarak, hedef alınan sistemin bir siber saldırı altında nasıl etkilendiğini gösteriyoruz.","Dynamic group key agreement protocols are cryptographic primitives to provide secure group communications in decentralized and dynamic networks. Such protocols provide additional operations to update the group key while adding new participants into the group and removing existing participants from the group without re-executing the protocol from the beginning. However, the lack of scalability emerges as one of the most significant issues of dynamic group key agreement protocols when the number of participants in the group increases. For instance, frequent participant join requests for large groups may cause an effect similar to a Distributed Denial of Service attack and violate the system availability due to the increase in group key update time. Therefore, analyzing the scalability of dynamic group key agreement protocols is crucial to detect conditions where the system becomes unavailable. In this thesis, we propose a formal performance model to evaluate the scalability of dynamic group key agreement protocols by using queueing models. We also extend our performance model for evaluating the scalability of secure file sharing systems that utilize group key agreement protocols. Moreover, we present a demonstrative use case to show the applicability of our performance model on an example group key agreement protocol and a secure file sharing system. Furthermore, we design attack models that can be used against communication systems and explain how the target system may be affected by a cyber attack."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde nesnelerin interneti (IoT) alanındaki gelişmeler ve akıllı ortamlara dair genişleyen vizyon, düşük güç tüketimi ve geniş kapsama alanı sağlayan (LPWA) teknolojilerine duyulan ihtiyacı büyük ölçüde artırmıştır. Geçtiğimiz on yılda, nesnelerin interneti ve kablosuz algılayıcı ağ uygulamalarının gelişen ihtiyaçlarını karşılamak için birçok düşük güç geniş alan teknolojisi geliştirilmiştir. Kablosuz algılayıcı ağ tasarımı, radyo ağ tasarımı ve hücresel ağlar için anten yerleştirme problemleri akademik çalışmalarda çokça kez ayrıntılı olarak incelenmesine rağmen, LPWA ağlarının optimizasyonu ile ilgili çalışmalar daha azdır. Bu tez içerisinde, temel olarak bir LPWA türü olan LoRa teknolojisi ve LoRa ağ geçitlerinin en uygun şekilde yerleştirilmesi yoluyla LoRa ağ tasarımına odaklanmaktayız. Bu amaçla, çalışmamızda benzetim tabanlı bir optimizasyon sistemi geliştirilmiş ve LoRa ağ geçidi yerleşimini eniyilemek için birden fazla algoritma önerilmiştir. Ağ geçitlerinin daha iyi yerleştirilmesini sağlamak için, genetik algoritma ve kümeleme algoritması tabanlı algoritmaların farklı sezgisel yöntemler ile birlikte kullanılması önerilmiştir. Önerilen algoritmalar gerçekleştirilen benzetimler üzerinden değerlendirilmiş ve elde edilen umut verici sonuçlar okuyucu ile paylaşılmıştır.","With emerging IoT technologies and vision for smarter environments, the need for low power wide area (LPWA) communications have substantially increased. In the last decade, many LPWA technologies have been developed in order to fulfil the needs of IoT and wireless sensor network applications. Although wireless sensor network design, radio network design and antenna placement problems for cellular networks are thoroughly studied in the literature, the works on optimization of LPWA networks are scarcer. In this thesis, we mainly focus on a specific LPWA technology, LoRa and design of LoRa networks through optimal placement of LoRa gateways. We have designed and implemented a novel simulation based optimization system and proposed multiple algorithms for optimizing LoRa gateway placement. In order to achieve better placement of gateways, use of genetic algorithm and clustering algorithm based methods with multiple heuristics are proposed. Success of the proposed algorithms are evaluated via simulation and the promising results are shared with the reader."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir objeyle nasıl etkileşime geçeceğimizi insan bedeninin sınırları belirlemektedir. Peki bedenimizi ve bununla beraber sahip olduğumuz becerileri kolayca değiştirebilseydik bu bize yeni aksiyon olasılıkları sağlar mıydı? Bu çalışmada, bedeni manipüle etmenin çevremizdeki potansiyel aksiyonları algılamamız (sağlarlık algısı) üzerindeki etkisi incelenmiştir. Birinci deneyde, hipoteze uygun şekilde katılımcıların kulp yönü ile tepki verdikleri el aynı tarafta olduğunda daha hızlı tepki verdikleri görülmüştür (Tucker & Ellis, 1986). Aynı zamanda uyarıcının katılımcıya olan mesafesi ara bir seviye eklenerek incelenmiş ve tepki süresi üzerinde anlamlı bir etkisi olduğu bulunmuştur. Bu bize sağlarlık etkisinin Sanal Gerçeklik (SG) ortamında ölçümlenebileceğini göstermektedir. İkinci deneyde avatar (SG içerisinde üç boyutlu beden gösterimi) becerilerinin sağlarlık algısını etkilediği bulunmuştur. Avatar becerileri, iki farklı el tipi kullanılarak manipüle edilmiştir (normal eller: kavrama becerisine sahip, kapsül şeklindeki eller: kavrama becerisinden yoksun). Veri toplama aşamasının, aksiyonun planlanması ve gerçekleştirilmesi olarak iki aşamaya bölünmesi değerli çıktılar sağlamıştır. Planlama aşamasında kısıtlanmış ellerde daha güçlü bir sağlarlık etkisi bulunmuştur. Bunun için olası bir açıklama daha az sayıda potansiyel aksiyonun bulunmasının avantaj sağlaması olabilir. Aksiyonun gerçekleştiği sırada ise sağlarlık etkisinin tersine döndüğü bulunmuştur. Kulp yönü etkisinin ters yönde olması literatürde çok nadir rastlanan bir durumdur. Bu durum da hareket sırasında planlamanın devam etmesi ile açıklanabilir. Tüm sonuçlar multidisipliner bir yaklaşım ile incelenmiş ve de çalışmanın sonuçları doğrultusunda SG alanındaki uygulamalarla ilgili olası çıkarımlara yer verilmiştir.","The possible actions that we can perform with an object are determined by the capabilities of the human body. Then, if we could change the body, would it create new action possibilities for us? In this study, we examined the effect of altered abilities on the perception of potential actions for a given object — affordance perception. Objects with handles are known to potentiate the afforded action. Participants tend to respond faster when the handle is on the same side as the responding hand in a bimanual speed response task (Tucker & Ellis, 1986). In the first experiment, we replicated this effect in a Virtual Reality (VR) setting by manipulating the handle orientation and distance of the object with an intermediate level. In the second experiment, we showed that this effect was influenced by the avatar (a 3D representation of the body and its movements in VR) which was manipulated by two different hand types (able hand, i.e., able to grasp vs. restricted hand, i.e., not able to grasp). The division of the data collection into action planning and action execution created a valuable insight. Specifically, during action planning, the affordance effect was significantly stronger for the restricted hand. One explanation for this is that fewer action possibilities provided the restricted hand an advantage in processing time. During action execution, on the other hand, the affordance effect was reversed. This reversed effect is rarely found in the literature. In this case, it may be due to the ongoing action planning during action execution. The results were examined from a multidisciplinary perspective, together with a discussion on the implications for VR applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geçtiğimiz on yılda, trafik sıkışıklığını, sürücü eforunu ve kaza oranını azaltmak amacıyla geliştirilen otonom sürüş ve sürücü destek sistemleri popüler araştırma konuları haline gelmiştir. Bugünün ulaşım ihtiyaçlarının farklılaşması sonucunda otonom sürüş algoritmalarında ortaya çıkan değişimler, çift yönlü iletişim topolojileri ve veri aktarımındaki gecikmelerle birlikte değerlendirildiğinde, konvoy sistemi uygulamalarının zor bir kontrol problemine dönüşmesine neden olmuştur. Ek olarak, konvoydaki araç sayısı arttıkça kontrol problemine yönelik çözümler için gereken hesaplama gücü de artmakta ve tepki süresinin önemli olduğu bu tip uygulamalarda dağıtılmış denetleyicilerin kullanılması, daha güvenilir sonuçlar elde edilmesine olanak tanımaktadır. Bu tezin amacı, tek yönlü ve çift yönlü de dahil olmak üzere çeşitli iletişim bağlantıları altında Dağıtılmış Model Öngörülü Kontrol (DMPC) kullanarak araç konvoyları için bir İşbirlikçi Uyarlamalı Seyir Kontrol Algoritmaları önermek ve iletişim gecikmesinin neden olduğu sürekli hal hatası için bir çözüm üretmektir. Mevcut araştırmalar, DMPC'nin farklı tek yönlü iletişim topolojileri altında hızlı yanıt süresiyle sıfır sabit durum hatası sağlayabildiğini göstermektedir. Ancak çift yönlü bağlantıların ve iletişim gecikme etkisinin yeterince ele alınmadığı tespit edilmiştir. Bu tezde, takip araçlarından gelen bilgileri optimizasyon sorununa dahil etmek ve lider araçtan alınan gecikmeli bilgilerin sonuçlarını yönetmek için uygulanabilecek DMPC algoritmaları araştırılmıştır. DMPC'nin, iki yönlü iletişimi modellemek ve yönetmek için kullanılacak doğru yöntem olduğu gösterilmiştir. Simülasyon sonuçları, iletişim gecikmesinin sürekli hal hatası üzerindeki olumsuz etkilerinin başarıyla önüne geçilebildiğini göstermiştir.","Over the past decade, autonomous driving and driver assistance systems have become popular research topics with the aim of reducing traffic congestion, driver labor and rate of accidents. This has changed the requirements and priorities of today's transportation perception and reveals a need for an increased level of complexity. Changes in autonomous driving algorithms as a result of this differentiation have led the platoon system applications turn into a difficult control problem when evaluated together with bidirectional communication topologies and delays. Furthermore, the increased number of vehicles added to the platoon requires higher computational power. Using distributed controllers in such applications where response time is important helps us get more reliable results. The main objective of this thesis is to investigate Cooperative Adaptive Cruise Control Algorithms for Vehicular Platoons using Distributed Model Predictive Control (DMPC) under various communication links including unidirectional and bidirectional and also to propose a solution for a pre-known communication delay. Existing studies show that DMPC provides zero steady-state error with a fast response time under unidirectional communication topologies, however bidirectional links and communication delay effect are not adequately addressed. This thesis presents DMPC algorithms based on the information coming from the follower vehicles and delayed information received from the leader vehicle. It is shown that DMPC is the right tool to be utilized to both model and manage bidirectional communication. Simulation results demonstrate that the steady state error caused by the communication delay is successfully handled."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Literatürde ortaya sürülmüş olan pek çok makine, bir sonlu durumlu makinenin ek bir hafıza ünitesi ile güçlendirilmiş hali olarak düşünülebilir. Bu tezde, bu makine-\newline lerden ikisine, gruplar üzerinde tanımlı sonlu durumlu makinelere ve eve dönen vektör makinelerine odaklanılmıştır. $ G $ grubu üzerinde tanımlı bir makine, sahip olduğu ek hafıza ünitesinde $ G $ grubundan bir elemanı tutma hakkına sahip, belirlenimci olmayan bir sonlu durumlu makinedir. Başlangıçta hafıza ünitesinin değeri $ G $ grubunun birim elemanıdır. Bir hesaplamanın başarılı sayılabilmesi için hafıza ünitesinin değerinin, her adımda grubun bir elemanıyla çarpıldıktan sonra bitimde grubun birim elemanına eşit olması beklenir. Bu çalışmada tam sayılı ve rasyonel sayılı matris grupları üzerinde tanımlanan sonlu durumlu makine-\newline ler incelenmiş, bu makinelerin tanıdığı dil sınıflarının birbirleri ile olan ilişkileri ortaya çıkarılmıştır. Grubun büyüme hızı, makinelerin çalışma süresi gibi çeşitli parametrelere bakılarak, bu parametrelerin makinelerin tanıma gücünü nasıl etkilediği araştırılmıştır. Matris yarıgruplarının karar verme problemleri ile ilintili makinelerin karar verme problemleri arasında bir bağ kurulmuştur. Grup üzerinde tanımlı makinelerle yakından ilişkili olan bazı modeller incelenmiş ve bir takım yeni sonuçlar elde edilmiştir. Yeni tanımladığımız eve dönen vektör makinesi, bir sonlu durumlu makinenin bir vektörle güçlendirilmesi ve makineye bu vektörü her adımda bir matrisle çarpma hakkı verilmesiyle ortaya çıkmıştır. Makinenin vektörün başlangıç vektörüne eşit olup olmadığını kontrol etme hakkı vardır ve makinenin kabul şartı, hesaplama bittiğinde vektörün başlangıç vektörüne eşit olması ve kabul durumlarından birinde bulunulmasıdır. Kullanılan matris kümesi sınırlanarak ve vektörün eşitlik kontrolünün sadece en sonda gerçekleşmesine izin verilerek, farklı kısıtlamaların makineye olan etkisi incelenmiştir. Makinenin çeşitli sürümleri tanımlanarak, bu modellerin dil tanıma gücüyle klasik modellerin dil tanıma gücü karşılaştırılmıştır. Matris grupları üzerinde tanımlı sonlu durumlu makinelerle, bir yönlü belirlenimci olmayan kör eve dönen vektör maki-\newline neleri arasında ilişki kurularak eve dönen vektör makineleri ile ilgili yeni sonuçlar elde edilmiştir. Gerçek zamanlı eve dönen vektör makineleri üzerinde özellikle durulmuş, bazı kapalılık özellikleri gösterilmiş ve bu makinelerin tek durumlu versiyonları analiz edilmiştir. Stern-Brocot ağacından faydalanarak dizgeleri vektörlere kodlamaya yarayan bir metod geliştirilmiştir.","Many of the numerous automaton models proposed in the literature can be regarded as a finite automaton equipped with an additional storage mechanism. In this thesis, we focus on two such models, namely the finite automata over groups and the homing vector automata. A finite automaton over a group $ G $ is a nondeterministic finite automaton equipped with a register that can hold an element of the group $ G $. Initially the register is initialized to the identity element of the group and a computation is successful if the register is equal to the identity element at the end of the computation after being multiplied with a group element at every step. We investigate the language recognition power of finite automata over integer and rational matrix groups and reveal new relationships between the language classes corresponding to these models. We look at various parameters such as the growth rate of the groups and the run-time of the machines, to discover the effects of these parameters on the language recognition power. We establish a link between the decision problems of matrix semigroups and the decision problems of corresponding automata. We look at some computational models which are closely related to finite automata over groups, namely the valence pushdown automata and the context-free valence grammars and present some new results. We also propose the new homing vector automaton model, which is a finite automaton equipped with a vector, and which can multiply this vector with an appropriate matrix at each step. The vector can be checked for equivalence to the initial vector and the acceptance criterion is ending up in an accept state with the value of the vector being equal to the initial vector. We examine the effect of various restrictions on the model by confining the matrices to a particular set and allowing the equivalence test only at the end of the computation. We define the different variants of the model and compare their language recognition power with that of the classical models. We establish a link between finite automata over matrix groups and one-way nondeterministic blind homing vector automata which extends our knowledge on the latter. We pay special attention to real-time homing vector automata and analyze their stateless versions and closure properties. We develop a method for encoding strings into vectors, based on the Stern-Brocot Tree, which may be of independent interest."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ConceptNet, yakla¸sık 15 bin yazarın katkıda bulundu˘gu 700 binden fazla genel bilgi ¨orne˘gi kullanılarak olu¸sturulmu¸s geni¸s bir kavram ve ili¸ski a˘gıdır. Ba¸slangı¸cta ˙Ingilizce i¸cin geli¸stirilmi¸s olsa da, daha sonra bir¸cok farklı kaynaktan yola ¸cıkılarak di˘ger dillerin eklenmesiyle ¸cok dilli bir ara¸c haline getirilmi¸stir. Farklı kavramların birbiriyle olan ili¸skilerini barındırması a¸cısından, ¨ozellikle metin analizleri, anlam veya ba˘glam ¸cıkarma i¸slemleri yapan sistemler i¸cin de˘gerli bir kaynak oldu˘gu s¨oylenebilir. T¨urk¸ce, metin i¸sleme ve anlam ¸cıkarma sistemleri s¨oz konusu oldu˘gunda di˘ger dillere kıyasla benzer kaynaklardan yoksun olan bir dildir. ConceptNet, i¸cinde T¨urk¸ce veri olmasına ra˘gmen, her iki kavramın da T¨urk¸ce oldu˘gu ¨orneklerin sayısı a¸cısından kaynak olarak yeterli de˘gildir. Bu ¸calı¸smada, ˙Ingilizce ConceptNet baz alınıp ¸ceviri kaynakları kullanılarak, T¨urk¸ce ConceptNet olu¸sturulması amacıyla uygulanmı¸s ¸ce¸sitli y¨ontemler tartı¸sılmı¸s ve elde edilen sonu¸clar a¸cıklanmı¸stır. WordNet, Wikipedia ve Google Translate gibi farklı kaynaklar kullanılarak birden fazla model test edilmi¸stir. Her modelden elde edilen sonu¸clar ve bu sonu¸cları iyile¸stirmeye y¨onelik yakla¸sımlar tartı¸sılmı¸s, ili¸skilerin kendileriyle ilgili detaylar, varsayımlar ve zorluklar a¸cıklanmı¸stır.","ConceptNet is a large-scale network of concepts and relationships, based on various common sense knowledge bases and built upon more than 700 thousand sentences contributed by approximately 15 thousand authors. It was originally developed for the English language and later became a multilingual tool with the addition of other languages using many different sources. It can be seen as a database of how different concepts relate to each other, especially as a valuable resource for systems that perform text analyses, meaning or context extraction. Turkish is a language that lacks similar sources for processing texts and extracting meaning. Although ConceptNet includes examples for Turkish, not many are available where both concepts are in Turkish. This study discusses various methods to create a Turkish ConceptNet using translational techniques based on English ConceptNet and explains the results herewith obtained. Multiple models are tested, using different sources including WordNet, Wikipedia and Google Translate. Results obtained from each model and approaches to improve these results are discussed, while also explaining details, assumptions and drawbacks relevant to each relation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Üretim, tüketim ve kullanım sonrasında doğaya zarar vermeyen ürünler genel literatürde çevreci ürünler ya da yeşil ürünler olarak adlandırılıyorAyrıca sürdürülebilir yöntemlerle üretilen ya da geri dönüşüme uygun olan cep telefonu, hard disk, bilgisayar, tablet, televizyon, ekran gibi elektronik ürünlere de çevreci teknolojik ürünler adı verilir. Bu ürünlerin üretim ve kullanım ömrü sonrasındaki geri dönüştürülebilme özellikleri ele alındığında, çevreci teknolojik ürünlerdeki amaç doğaya sıfır ya da asgari zarar vermektir. Bu akademik çalışmada tüketicilerin günlük hayatta en çok kullandığı ürünler olan kişisel hijyenik kâğıt ürünleri ve teknolojik ürünlerin çevreci olup olmamalarına gösterdikleri özen ve seçim kriterleri incelendi. Tüketici iç görüsü ve yenilikçiliğin artması ile görünen o ki tüketicilerin çevreci ürün alımına olan eğilimleri de değişmektedir. Bu çalışmanın ana amacı ise çevreci teknolojik ürün ve çevreci kişisel bakım ürün üretiminin tüketicilerin satın alma alışkanlıklarını nasıl etkilediğini ölçmektir. Yaptığımız çeşitli araştırmalar sonucunda satın alma kriterini etkileyen farklı değişkenlerin olduğu saptanmıştır. Bu satın alma kriterlerinin belirlenmesiyle günümüz çağında teknolojik ürün üretimi yapan şirketlere ve kişisel bakım ürünü üreten şirketlere fikir verilmesi hedeflenmiştir.","Green products are defined as products that do not produce any harm on the environment throughout their production, use or disposal. Green technological product production is aimed to use of recyclable and sustainable goods for saving the natural resources. Technologic and strategic details of achieving sustainability, innovation and high satisfaction of consumer in personal care products and technological products have been researched in this work with the analysis conducted by the data comprised from experienced end-users. In this work, the attitude – behavior inconsistencies in terms of hygienic green/sustainable paper product purchasing and technological green products was evaluated. It was concluded that innovation and insight of end-user has gained more significance due to changes in perception and tendency towards sustainable and environmental approaches particularly in production process. The main goal of this work to analyze how these ecological, green and sustainability innovations can be reflected in purchase behavior of customers towards green products. To do so, several parameters, e.g. predominant motives, facilitators and obstacles having an influence on purchase decision towards green products, were identified. Furthermore, the probable reasons for the reported inconsistencies in green purchase behavior were identified. This work also discusses the main predictions in consumer's green purchase behavior. This will help policy makers and managers to encourage people for purchasing green products."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Olağandışılık Sezimi (AD), mevcut veri kümesinin diğer gözlemleriyle örtüşmeyen gözlemlerin sezimlenmesidir. Olağandışılık türleri ile bunların veri kümesi içindeki oluşumları belirlenmeye çalışılır. Öte yandan, zaman serisi yapıları zaman içinde gelişen devingen yapılara sahiptir ve bu tür yapılarda gözlemler önceki gözlemlere bağlıdır. Bu tez, zaman serisi yapıları altındaki olağandışılık sezimi sürecine odaklanmaktadır. Bu problem her zaman kolay değildir, çünkü olağandışılığın tanımı, sürecin devingen yapısı bağlamında değişebilir ve sistem içerisindeki olağandışılık sezimi işlemi gözlemlerdeki yüksek gürültülerle karışabilir. Bu tezde, akış verilerinin alt kümelerinde meydana gelene olağandışılıkları belirlemeye çalışıyoruz. Bunu yaparken, sistemdeki olağandışılıkları hatalı gözlemlerden ayırt etmek istiyoruz. Bu nedenle verilerdeki toplu olağandışılıkları araştırmaktayız. Bu özelliklere sahip olan zaman serisinde olağandışılık sezimi (ADTS) için hem istatistiksel çıkarım yöntemleri hem de derin öğrenme yaklaşımları öneriyoruz. Derin öğrenme yaklaşımları olarak Tekrarlayan Sinir Ağları (RNN) ve Uzun Kısa Süreli Bellek'i (LSTM) kullanırken, Gaussian karışım modelini (GMM) ve özelleştirilmiş bir gizli Markov modelini (HMM) istatistiksel yaklaşımlar olarak kullanıyoruz. GMM'ler hariç, yukarıda önerilen modellerde veri kümelerinin sıralı yapılarını dikkate alıyoruz. Yöntemlerimizi, Borusan rüzgar türbinleri verilerine uyguluyoruz ve model sonuçlarını bu veri kümesi üzerinde yaptığımız deneylerle karşılaştırıyoruz.","Anomaly detection (AD) is the discovery of the observations which does not conform with the rest of the observations. The types of anomalies and their occurrences that exist in the data set are tried to be determined. On the other hand, time series structures have dynamic structures, which are evolving over time, and in such structures, observations will be affected by previous observations. This thesis focuses on the anomaly detection process under time series structures. This problem is not always straightforward because the definition of anomaly could change with the context of the dynamic structure and anomaly detection process in the system could interfere with the intense noises at the observations. In this thesis, we try to identify anomalies in the sub-sequences of the streaming data. When doing so, we also want to discriminate the anomalies in the system with the faulty observations. Therefore we investigate collective anomalies in the data. We propose both statistical inference methods and deep learning approaches for such type of anomaly detection in time series (ADTS) problem. We use a Gaussian mixture model (GMM) and a customized hidden Markov model (HMM) as statistical approaches, while we use Recurrent Neural Networks (RNN) and Long Short-Term Memories (LSTM) as deep learning approaches. Except for GMMs, we take into account the sequential structures of data sets in the models proposed above. We apply our methodologies to the Borusan wind turbines data and we compare the model results with the experiments we performed on this dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez zaman duyarlı öneriler, örtük kullanıcı geri bildirimi ve sıralama öğrenme kesişimindeki problemlere odaklanmaktadır. Zaman duyarlılığı sağlamak için başlıca zorluklara dikkat çekilmekte, örtük geri bildirimi işleyebilmenin önemi belirtilmekte ve zaman duyarlı öneriler için örtük geri bildirimden öğrenebilen modeller vurgulanarak sıralama öğrenme yöntemlerine genel bir bakış sunulmaktadır. Daha sonra ise büyük ölçekli örtük geri bildirim veri kümeleri ve akışlarını işleyebilen ve zaman duyarlı öneri oluşturmadaki zorlukları aşabilen yeni ve geliştirilmiş kişiselleştirilmiş sıralama öğrenme yöntemleri önerilmektedir. Bu öneriler şunları kapsamaktadır: (i) İşbirlikçi filtreleme için kullanıcı geri bildirim verisi akışı madenciliği ve SASCF algoritması, (ii) Paralel kişiselleştirilmiş çift ögeli sıralama öğrenme ve PLtR algoritma ailesi, (iii) Matris ayrıştırma modellerinden en üst N öge tahmin etmenin verimliliğini artırma ve MMFNN meta-algoritması, (iv) Kullanıcı oturumlarında yönelim öğrenme ve BRF algoritma ailesi, (v) Soğuk başlangıç ortamında doğru zamanlı talep dışı öneriler ve hibrit bir sıralama öğrenme yaklaşımı. Önerilen yöntemlerin hem teorik hem de gerçek hayat verileri üzerinde yapılan deneysel analizlerinin sonuçları, sıralama doğruluğu, uyum sağlayabilme, öge çeşitliliği, verimlilik ve ölçeklenebilirlik kriterleri için önemli performans ve dengeleme iyileşmeleri göstermektedir.","This thesis focuses on the problems at the intersection of time-sensitive recommendations, implicit user feedback, and learning to rank. Major challenges for achieving time sensitivity are distinguished, the importance of handling implicit feedback is emphasized, and an overview of learning to rank methods is presented with an emphasis on the models that can learn from implicit feedback for time-sensitive recommendations. Subsequently, novel and improved personalized learning to rank methods are proposed to handle large-scale implicit feedback datasets and streams as well as to defeat the different challenges for achieving time-sensitive recommendations. These proposals comprise: (i) Mining the user feedback stream for collaborative filtering and the SASCF algorithm, (ii) Parallel personalized pairwise learning to rank and the PLtR family of algorithms, (iii) Improving the efficiency of top-N predictions from matrix factorization models and the MMFNN meta-algorithm, (iv) Learning intention in user sessions and the BRF family of algorithms, and finally (v) Timely push recommendations in a cold start setting and a hybrid learning to rank approach. Theoretical as well as extensive empirical analyses of the proposed methods on real-life data show significant performance and trade-off improvements with respect to ranking accuracy, adaptivity, diversity, efficiency, and scalability."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son on yılda, modern toplumdaki hastalıkların ¸coğu stresden kaynaklanmaktadır. Bu yüuzden araştırmacılar günlük yaşamdaki stresi mümkün olduğunca erken tespit etmek ve azaltmak istemektedir. Teknolojinin gelişmesiyle birlikte akıllı telefonlar, akıllı bileklikler, akıllı saatler günlük hayatımızın ayrılmaz bir parçası haline geldi. Bu yaygın olarak kullanılan giyilebilir cihazlar ile stresin tespit edilip edilemeyeceğinin araştırma konusu olmuştur. Araştırmalar, laboratuvar ortamında başlamış ve son zamanlarda laboratuvar dışında gerçek hayat uygulamaları olarak devam etmektedir. Bu tez çalışmasında iki farklı durum çalışması yaptık. İlk önce, Samsung Gear S2 akıllı saati ile gerçek yaşam ortamlarında 17 katılımcıdan 339 saat fizyolojik veri ve 7119 iş yükü anketi sorusu topladık. Katılımcılar genellikle bu deneyi bir ay i¸cerisinde tamamladılar. Kalp atı¸s hızı değişkenliği ve ivmeölçer özellikleri stres seviyelerini değerlendirmek için kullanıldı. İkinci olarak, içerik odaklı stress ölçümü deneyi yaptık. Algoritma kampında 21 katılımcıdan 672 saat (9 gün içinde) fizyolojik veri topladık. Bu etkinlikte serbest, ders ve yarışma oturumları vardır. Kalp atış hızı, cilt iletkenliği ve ivmeölçer sinyalleri ile makine ögrenmesi yöntemlerini kullanarak yarışma, ders ve serbest zaman aktivitelerinden yaklaşık %98 başarım elde ettik. İkinci olarak,","In the last decades, most of the diseases in modern society are caused by stress. This is the reason researchers want to detect and alleviate stress in daily life as early as possible. With the advance of technology, smartphones, smartbands, watches have become integral items of our daily lives. The research question that whether detecting stress with these widely used wearable devices is possible has arisen. The research has started in laboratory environments and recently a number of works have taken a step outside the laboratory to real life. In this thesis, we employed two different case studies. First, we collected 339 hours of physiological data and 7119 workload survey questions from 17 participants in their real-life environments with Samsung Gear S2 smartwatch. The duration of this experiment for the participants was a month on average. Heart rate variability and accelerometer features are used to evaluate the level of stress. Second, we conducted a context-driven stress measurement experiment, we collected 672 hours (in 9 days) of physiological data from 21 participants of an algorithmic competition event. This event has free, lecture and contest sessions. By using heart rate, skin conductance, and accelerometer signals, we achieved approximately 98% accuracy of discriminating contest stress, the cognitive load (lecture) and relaxed activities by using machine learning methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Videolarda duygu tahmini, son yıllarda aktif bir araştırma alanıdır. Bu çalışma alanı filmlerde kişiselleştirilmiş duygusal analizi, video önerisi ve uygunsuz sahne sansürü için önemlidir. Bu tezde, filmlerde duygu tahminini inceliyoruz. Problem öznitelik çıkarımı, öznitelik özetleme, öznitelik seçimi, regresyon ve veri sentezi açısından incelenmiştir. Videolardan çıkarılan ses ve görüntü özellikleri Mel-frekans kepstrum katsayıları, ton doygunluğu histogramı, yoğun ölçek değişmezlikli öznitelik dönüşümü, yüz hareket birimleri ve VGG ağının altıncı tam bağlantılı katmanından çıkarılmıştır. Öznitelikler, tanımlayıcı istatistikler fonksiyoneller ve Fisher vektör kodlaması ile özetlenmiştir. Kanonik korelasyon analizine dayalı öznitelik seçimi deneylenmiştir. Aşırı öğrenme ve destek vektör makineleri regresyon teknikleri olarak kullanılmıştır. Film sahnesi ve film ruh hali dağılımı incelenerek eğitim ve doğrulama seti kurulmuştur. Sınıf dengesizliği sorunu, veri setindeki azınlık sınıfları için sentetik veriler üretilerek çözülmüştür. Birleştirme teknikleri en iyi sonuç aldığımız özniteliklere skor ve öznitelik seviyesinde uygulanmıştır. Ardışık etiketlerin ani değişiklikleri için yumuşatma filtresi kullanıldı. Bizim yaklaşımımız, Mediaeval 2017 organizasyonu tarafından sağlanan Filmlerin Duygusal Etkisi çalışmasında test edildi. Bu veri seti, zorlu bir veriseti olan Liris-Accede veri setinden seçilerek oluşturulmuştur. Duygu olumluluğu modelinin en iyi sonucu, yüz hareket birimleriyle, renk doygunluğu histogramının skor füzyonuyla elde edildi. Duygu şiddetinin en iyi sonucu, VGG'nin altıncı tam bağlı katman özelliğiyle renk doygunluğu histogramının öznitelik füzyonuyla elde edildi. Duygu olumluğunda iyi bir sonuca ulaştık. Elde ettiğimiz en iyi duygu şiddeti modelinde, tahminlerin bazı eğimleri ile gerçek etiketleri arasında pozitif korelasyonlar görüldü.","Video emotion estimation has been an active area of research in recent decades. This study area is crucial for personalized content delivery, video recommendation, video summarization, and inappropriate scene censorship. In this thesis, we study movie emotion estimation. The problem is explored with regards to feature extraction, feature summarization, feature selection, regression, and data synthesis. The audio and image features extracted from videos are Mel-frequency cepstral coefficients, hue saturation histogram, dense scale-invariant feature transform, facial action units, and the sixth fully connected layer's feature of VGG network. The features are summarized via descriptive statistics functionals and Fisher vector encoding. Feature selection technique based on canonical correlation analysis is applied to the features. Extreme learning and support vector machines are used as regression techniques. We construct train and validation set examining movie scene and movie mood distributions in the dataset. We synthesis data for the minority classes in the unbalanced dataset. Feature and score level fusion techniques are applied to the best features. We use smoothing techniques for sudden changes of consecutive labels. Our approach is evaluated on the Emotional Impact of Movies Task's dataset provided by Mediaeval 2017 organization; the movies of the dataset are selected from a challenging Liris-Accede dataset. Fusion of facial action units and hue saturation histogram features provide the best arousal results. Score fusion of sixth fully connected layer feature of VGG and hue saturation histogram achieve best valence results. We obtain good Pearson Correlation Coefficient results for the best valence result. In the best arousal model, some slopes in predictions are in line with slopes of actual label graph."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, yüksek ve çok boyutlu yapılar arasındaki mesafe yakınsama yordamlarına ve onların uygulamalarına odaklanıyoruz. İki yeni mesafe yakınsama kullanan yöntem önerilmekte ve onlar siber güvenlikte sıradışılık tespitine (Dağıtılmış Hizmet Reddi (DHR) saldırı ve saldırgan tespiti) ve nesne geri çağırmada gerey (tensör) ayrıştırmaya (kıt veride imge ve görüntü sınıflandırma) uygulanmaktadır. İlk olarak, iki bileşenden oluşan bir özerk (otonom) siber güvenlik sistemi düşünüyoruz: DHR saldırısı tespiti için bir izleyici ve sistemdeki kötü niyetli kullanıcıların tespiti için bir ayırt edici. Örneklenmiş öznitelik vektörleri arasındaki Mahalanobis uzaklığının değişimini takip eden bir özgün uyarlanabilir değişim noktası tespit modeli izlenilen dizgedeki olası DHR saldırılarının hesabını yapmaktadır. Kullanıcıların davranışsal örüntüleri arasındaki benzerlik skorları üstünde koşan bir öbekleme modeli kötü niyetlileri masumlardan ayırmakta kullanılır. İkinci olarak, izdüşülmüş örnekler üzerinde en yakın komşu sınıflandırma doğruluğunu iyileştiren izdüşüm yönlerini bulan uzaklık tabanlı bir geniş kenar paylı ayrımcı gerey ayrıştırması (GKAGA) öneriyoruz. Siber güvenlik dizgesini benzetilmiş SIP haberleşme ortamında deniyoruz. Hem saldırı hem saldırgan tespiti bileşenleri yazındaki bazı rakipler ile karşılaştırılmaktadır. Gerey ayrıştırma, kıt veri durumunda, imge ve görüntü geri çağırma sorununa uygulanmakta ve başarımı diğer ayrıştırma yöntemleri ile karşılaştırılmaktadır. Her iki uygulama için deneysel sonuçlar rapor edilir. Önerilen metotların rakiplerinden daha yüksek doğruluk oranı sergiledikleri gösterilmektedir.","In this thesis, we focus on distance approximation methods between high and multi-dimensional structures and their applications. Two novel methods using distance approximations are proposed and they are applied to anomaly detection in cyber security (Distributed Denial of Service -DDoS- attack and attacker detection) and tensor decomposition in object retrieval (image and video classification on scarce data). At first, we consider an autonomous cyber security system that consists of two components: A monitor for detection of DDoS attacks and a discriminator for detection of users in the system with malicious intents. A novel adaptive real time change-point detection model that tracks the changes in the Mahalanobis distances between sampled feature vectors in the monitored system accounts for possible DDoS attacks. A clustering model that runs over the similarity scores of behavioral patterns between the users is used for segregating the malicious from the innocent. Secondly, we propose a discriminative tensor decomposition with large margin (LMTD), which is a distance based model that finds the projection directions where the nearest neighbor classification accuracy is improved over the projected instances. We experiment the cyber security system in a simulated SIP communication environment. Both the attack and attacker detection components are compared with some competitors in the literature. The tensor decomposition is applied to the image and video retrieval problem, where the data is scarce, and its performance also is compared with other decomposition methods. The experimental results are reported for both applications. It is shown that the proposed methods perform higher accuracy rates than their competitors."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, Türkçe metinlerde kullanılan sözcük gösterim yöntemlerinin (word-2vec, fastText ve ELMo) analizine yönelik bir çalışma yapılmıştır. Sözcük gösterimleri, sözcükleri yüksek boyutlu vektör uzayında göstermek için kullanılır. Benzer anlamdaki sözcüklerin bu uzay içinde yakın yerlerde konumlanması amaçlanır. Sözcük vektörleri metin sınıflandırma ve çeviri gibi alanlarda kullanılabilir. Farklı boyutlardaki Türkçe derlemler üzerinde word2vec, fastText ve ELMo yöntemleri üzerinde deneyler yapılıp sözcük çantası yöntemiyle karşılaştırılmıştır. Word2vec yöntemi sözcük seviyesinde çalışırken, fastText harf seviyesindeki gösterimleri kullanarak sözcükleri temsil edebilmektedir. ELMo, cümledeki bağlam bilgisini kullanarak sözcük vektörleri oluşturur. Word2vec ve fastText yöntemleri ise bağlam bilgisini kullanamaz. Öğrenilen sözcük vektörleri sözdizimsel ve anlamsal sınama kümelerinde ve konu sınıflandırmada karşılaş-tırılmıştır. Deneylerimiz, fastText modelinin konu sınıflandırma konusunda, word2vec modelinin ise anlam benzeşmelerinde daha başarılı olduğunu göstermektedir.","In this study, we analyze the effect of different word embedding methods in representing Turkish texts, namely word2vec, fastText, and ELMo. Word embeddings are used for representing words in a high dimensional vector space such that similar words are placed nearby. This will help in different tasks, such as document classification, machine translation, and so on. We conduct experiments on Turkish corpora of different sizes using word2vec, fastText, and ELMo, and compare them with bag-of-words (BOW). Word2vec works at the word level; fastText works at the character (subword) level and the representation of a word is calculated by combining the representations of subwords. ELMo is context-dependent, that is, the representation of a vector depends on other words in the sentence, whereas word2vec and fastText are context-independent. Learned word embeddings are evaluated on noun and verb inflections, semantic analogy tests, as well as on topic classification of news documents. Our experiments indicate that fastText vectors are better on classification tasks. Word2vec vectors are more useful on semantic analogies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Markov Zinciri Monte Karlo ve Ardışık Monte Karlo yöntemleri, istatistiksel modelleme ve kestirim problemlerinde yaygın olarak kullanılmaktadır. Standart olasılık dağılımlarından örnek üretmek için kullanılan analitik yöntemler, karmaşık dağılımlar söz konusu olduğunda işlevlerini yitirirler. Görece basit modeller için bile, model parametreleri üzerindeki sonsal dağılım, standart dağılımlar cinsinden ifade edilemeyebilir. Bu sebeple Monte Karlo yöntemlerine sıklıkla başvurulmaktadır. Bu tez çalışmasında, ilk olarak, bir öneri sistemi ve kullanıcıları arasındaki etkileşim için bir istatistiksel model sunup, kullanıcıların tercihleri üzerinde bir sonsal dağılıma ulaşıyoruz. Önerilen model oldukça basit ve sezgisel olmakla birlikte, literatürde yaygın olarak bilinen Dirichlet-Multinomial modelinin bir varyantı gibi düşünülebilir. Bu tez çalışmasının birincil amacı olmasa da, bu durum, analizi kolaylıkla yapılan modeller için bile, varsayımlardaki küçük değişikliklerin, model analizinde kullanılan yöntemleri ne kadar değiştirebileceğine bir örnek oluşturmaktadır. Daha sonra, kullanıcı tercihleri üzerindeki sonsal dağılımdan örnek üretmek amacıyla, resample-move algoritmasını temel alan ve Gibbs-içinde-Metropolis stilinde bir hareket çekirdeği kullanan bir Ardışık Monte Karlo algoritması öneriyoruz. Önerilen algoritmanın geçerliliğini, aynı sonsal dağılımı hedef alan Stan uygulamasıyla test ediyoruz. Son olarak da Thompson Örneklemesi presibini temel alan bir öneri sistemi-kullanıcı etkileşimi senaryosunu simülasyonlarla inceliyoruz.","Monte Carlo methods, such as Markov Chain Monte Carlo (MCMC) and Sequential Monte Carlo (SMC), have extensive use cases in probabilistic modeling and inference. They usually appear as a way of drawing samples from a distribution of interest, because even for a relatively small model, the target distribution may easily go out of the domain of standard probability distributions, rendering the analytical tools to be almost useless. Sampling methods have been used effectively in such cases. In this thesis, we will be dealing with a probabilistic model that captures the interaction between a recommender system and its users and define a posterior distribution over the user's preferences. The model itself is actually very similar to a Dirichlet-Multinomial model, but it has completely different analytical properties. Although it is not the main purpose of this thesis, this fact also serves as a demonstration of how a slight change in a model may result in a problem which requires drastic changes in the methods of approach. We propose a Sequential Monte Carlo scheme, based on the resample-move algorithm with a Metropolis-within-Gibbs style move kernel, that targets the posterior distribution over the user's preferences. We also provide Stan implementations that target the same posterior distribution and use it for validation purposes. Then we investigate a recommender-user interaction mechanism based on the idea of Thompson sampling by simulating interactions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biz, normal fotoğrafın yanısıra derinlik bilgisi de veren (RGB-D) kameraya sahip evde çalışacak robotlar için bir görsel anlama sistemi oluşturduk. Bu sistem üç temel kısımdan oluşuyor; (i) RGB-D bilgisiyle nesne tanıma ağı (ii) basit bir takip algoritması, ve (iii) 3 boyutlu anlamsal haritalama modülü. Bizim en büyük kısıtımız ise sistemimizin gerçek zamanlı çalışabilmesi. Çoğu RGB-D nesne tanıma ağı derinlik bilgisine uzun süren ön işleme yöntemleri uyguladıkları için gerçek zamanlı çalışamıyor. Biz de derinlik bilgisini ham olarak kullanmayla kendi geliştirdiğimiz bir ön işleme yöntemini kullanmayı iki alanında en ileri yönteme uyarlayarak karşılaştırdık. Derinlik bilgisine normal fotoğraftaki doku bilgisini de gömerek oluşturduğumuz gerçek zamanlı çalışabilir ön işleme yöntemiyle SUN RGB-D veri kümesinde sadece ham derinlik bilgisiyle elde ettiğimizden %0.9 daha iyi bir ortalama duyarlıkların ortalaması skoru elde ettik. Bu iki girdi türüyle eğittiğimiz ağları normal fotoğraf girdisi alan orijinal ağlara karar seviyesinde entegre ettiğimizde ise sadece normal fotoğraf girdisi işleyen ağa göre %2 civarında daha iyi sonuçlar aldık. Küçük bir evde nesne tanıma veri kümesi topladık ve basit bir takip algoritması ekleyerek bu veri kümesinde aldığımız skorları %5 oranında arttırdık. 3 boyutlu anlamsal haritalama yaptığımız son modülümüzde haritalama kısmını açık kaynak kodlu RTAB-Map kütüphanesi ile oluşturduk. Anlamsal içeriği ise nesne tanıma ağlarıyla ve bir takip algoritmasıyla bu haritaya ekledik. Nesne tanıma ağları 2 boyutlu nesne kutuları önermesine rağmen biz üç boyutlu harita oluştururken robotun farklı açılardan nesneleri görmesinden faydalanarak bu bilgiyi 3 boyuta döktük.","We created a visual understanding pipeline for house robots with Red-Green-Blue-Depth (RGB-D) sensors. Our pipeline consists of three components; (i) an RGB-D object detection network, (ii) a simple tracking algorithm, and (iii) a 3D semantic mapping module. Our constraint is running the whole system in real-time. Most RGB-D object detection networks do not have such constraint and cannot run in real-time because they require costly preprocessing methods. Instead of the costly methods, we seek ways to make raw depth data more useful by a cheap preprocessing technique of RGB overlaying on the depth data. After adding depth branches into two state-of-the-art RGB object detection networks we compared performances of feeding raw depth input and RGB overlaid depth input on the SUN RGB-D dataset. The results of using only one type of input show that our overlaying method gets 0.9\% better mean average precision (mAP) than feeding the network with raw depth data. SSD with decision level fused depth network increased the mAP around 2% compared to RGB only SSD. We collected a small household object detection dataset to test the tracking method combined with the object detector. We used median flow tracking on the object boxes detected by the object detector, which increased the mAP of the object detection network by around 5% on our dataset. Our final module consists of 3D semantic mapping which we used Robot Operating System node of the Real-time Appearance-Based Mapping library for the 3D mapping part. The semantic information of the objects are created by the object detector network combined with the tracker. Although the object detector network proposes 2D bounding boxes around the objects, labeling these pixels and seeing the object from different angles allow us to create 3D maps with object labels."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mobil bilişimin giderek daha da yaygınlaştığı, daha karmaşık ve dağıtık uygulamaların ortaya çıktığı günümüzde, bu uygulamaları kullanıcılara yüksek hızlarda ve daha etkin sunmanın önemi de artmıştır. Hareketli kullanıcılara daha iyi hizmet vermenin yollarından biri bulut bilişimdir. Ancak veri merkezlerinde işlenecek verileri gönderip işlenmiş verileri almak coğrafik mesafelerden ötürü zaman almaktadır. Hareketli kullanıcılar, uygulamaları kullanırken beklemeye çok daha az meyilli olduklarından, kenar bilişim, öngörülen beşinci nesil (5G) mobil ağlarda hareketli kullanıcılar için servis kalitesi gereksinimlerini karşılamanın daha iyi bir yolunu sunuyor. Kullanıcılara kenar bilişim kullanılarak daha hızlı, daha etkin hizmet vermek amaçlanırken, ağ bakımı ve ağ gözetimi de önemli bir yer tutmaktadır. Bu yüzden, 5G bağlamında OpenFlow tabanlı Yazılım Tanımlı Ağlar kullanılarak kurulmuş bir mimari daha fazla avantaj sağlamaktadır. Gerçek hayattaki senaryoları test etmek amacı ile Yazılım Tanımlı Ağlar için test ortamları kurulmaktadır. Bu test ortamları ya tamamen Mininet kullanılarak ya da tamamen gerçek donanımlar kullanılarak oluşturuluyor. İki yöntemin de birçok avantajları olsa da, Mininet ile tam doğru ölçumler alamayabiliyoruz ve gerçek test yataklarında da ölçeklenebilirlik sorunu ile karşılaşıyoruz. Bu çalışmada her iki yaklaşımı bir araya getirerek melez bir test ortamı sunup, deneyi tasarlayacakların ihtiyaçlarına göre her iki tarafın özelliklerinden faydalanacak düzenekler yaratmasına olanak sağladık. Yaptığımız deneylerle de hedeflenen kenar bilişim senaryolarını Mininette ve melez ortamda karşılaştırmalı olarak ortaya koyduk. Aynı deney değişkenleri altında farklı sonuçlar oluştuğunu gözlemledik ve bu farkları sebepleriyle inceledik.","As mobile computing becomes more and more widespread along with more complex and distributed applications, the importance of providing these applications to users at high speed and with high efficiency is increasing. One of the ways to better serve mobile users is cloud computing. However, sending data to be processed to data centers and receiving processed data take time because of the geographical separation of resources. Since users are less inclined to wait while they use their mobile applications, edge computing offers a better way to handle the QoS requirements for mobile users in the envisaged fifth generation (5G) mobile networks. Network maintenance and network monitoring have also a significant place if we aim to provide faster and more efficient services to users with edge computing. Therefore, an architecture which is built using OpenFlow based Software Defined Networks offers even more benefits in the context of 5G. To this end, the testbeds for Software Defined Networks are established in order to test the real-life scenarios. These testbeds are usually created either using Mininet or on real hardware. Even though they have great advantages, Mininet testbeds do not produce precise results and real testbeds are not easy to expand. In this study, we aim to bring these two approaches together and provide a hybrid testbed that utilizes the features of both approaches for those who wish to perform experimentation in this field. In the experiments we have done, we presented the comparative evaluation results obtained using Mininet and our hybrid testbed for the desired edge computing scenarios. We observed different results under the same experimental variables and examined these differences with their reasons."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Varlık İsimlerinin Tanınmasıö verilen bir döküman içindeki özel isimlerin belirlenip, doğru kategorilere ayrılmasını amaçlayan bir Doğal Dil İşleme görevidir. Bu alandaki erken çalışmaların büyük bir bölümü alandaki uzmanlar tarafından seçilmiş özelliklerin istatistik bazlı sistemler tarafından analizine dayanmaktadır. Yakın zamanda bu alandaki en başarılı sonuçlar ise kelimelerin vektörel olarak temsil edilmesinden faydalanan yapay sinir ağı bazlı sistemler tarafından elde edilmiştir. Birden fazla görevi birlikte öğrenen, birlikte öğrenme sistemleri, genelde verisetlerinin iki görev için de etiketlenmiş olmasını gerektirir. Bu çalışmada öncelikle Türçe için yapılmış daha önceki özellik bazlı çalışmaları detayli bir şekilde inceleyip, farklı özellikler kullanarak sonuçları iyileştiriyoruz. Bu aşamada bağlılık ayrıştırma ile ilgili özelliklerin varlık isimlerinin tanınmasında performansı iyileştirdiğini gösteriyoruz. Sonraki bölümde daha önce denenmemiş bir model kullanarak bağlılık ayrıştırma ve varlık isimlerinin tanınması görevlerinin beraber öğrenilmesini gösteriyoruz. Modelimiz benzer birlikte öğrenme sistemlerinden farklı olarak iki görev için de ayrı verisetlerinden faydalanıyor. Elde ettiğimiz sonuçlar, birlikte öğrenmenin ayrı verisetleri kullanarak yapılmasının, aynı verisetinin otomatik olarak etiketlenmesine kıyasla daha iyi performans verdiğini gösteriyor.","Named Entity Recognition (NER) is the task of detecting and categorizing the entities in a given text. It is an important task in Natural Language Processing (NLP) and forms the basis of many NLP systems. Previous work on NER that make use of statistical models can be categorized into two main categories: feature-based and embedding-based. Earlier work on NER made frequent use of manually crafted features. In order to use manually crafted features we either automatically annotate the dataset for the given features using third party software or manually annotate the dataset, both of which require additional work. Recent work make use of BiLSTM based neural networks and represent words with embeddings. This relieves systems from relying on manually created feature sets. In this work, we started with analyzing the performance of the feature based systems. In this phase, we reimplemented a previous work and improved the performance by making use of the dependency parsing features. Following these results, we implemented a novel method that makes use of both dependency parsing features and embeddings. We propose a novel BiLSTM CRF based neural model that makes use of the dependency parsing feature to learn both tasks jointly in a unique way. Our model jointly learns both dependency parsing and named entity recognition using separate datasets for each task. The model does not require the named entity recognition dataset to be annotated for the dependency parsing task. Our results show that performance increases when we use a joint learning model instead of annotating the named entity recognition dataset automatically."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde öneri sistemleri birçok alanda kullanılmaktadır. Bu çalışma Türkçe dilinde yazılan sohbet ortamı mesajlarına yönelik özel olarak tasarlanmış bir öneri sistemi tanıtmaktadır. Önerilen sistem, sohbet ortamlarındaki grup yazışmalarını analiz ederek kullanıcılarına en iyi eşleşen önerileri sunmayı amaçlamaktadır. Bu hedefi gerçekleştirmek adına normalizasyon, analiz ve öneri aşamalarından oluşan kural tabanlı bir yaklaşım tasarlanmış ve uygulanmıştır. Ayrıca, sistemin neden seçilen yerleri önerdiğini açıklayan bir açıklama modülü eklenmiştir. Sistem, nitelik veri kaynağı ve restoran veri kaynağı adında iki veri kaynağı dışında bir de kural tabanından faydalanmaktadır. Nitelik veri kaynağı, restoranlarla ilgili özellikleri barındıran bir veri kümesi iken; restoran veri kaynağı, sistem tarafından önerilecek restoranları barındırmaktadır. Kural tabanı ise, sohbet ortamı mesajlarından daha doğru bir şekilde bilgi çıkarmak amacıyla elle tanımlanmış kurallar dizisidir. Test verisi konusunda yaşanan sıkıntı nedeniyle, sistemi değerlendirme süreci oldukça zorlu oldu. Sistemi değerlendirmek amacıyla, hem restoran veri kaynağı, hem de sohbet ortamı mesajları simule edildi.","Recommendation systems have recently been used in many fields. This study describes a restaurant recommendation system which is developed specifically for data that is collected from chat messages typed in Turkish. The proposed system aims to recommend best matching places to a group of users in a chat environment analyzing their conversations. In order to achieve this goal, a rule-based approach which composes of normalization, analysis and recommendation steps has been designed and implemented. Furthermore, an explanation module used for explaining why the system recommends selected places has been added. The system benefits from two data sources that are property data source and restaurant data source and a rule base. While the property source is a dataset contains features related to restaurant domain, the restaurant source has all places that can be recommended by the system. On the other hand, the rule base is a sequence of rules defined manually to extract information from chat messages in a more accurate way. The evaluation process of the system has been very difficult since no test data are available. To evaluate the system, both restaurant data source and chat messages are simulated manually."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Öğüt, bir hesaplama aygıtına bu aygıtın gücünü kendi sınırlarının ötesinde genişle- terek hesaplamasına yardım etmek için sağlanan dış kaynaklı güvenilir bir bilgi parçası- dır. Hesaplanabilir olma kısıtlaması olmayan bu yardımın içeriği tipik olarak yalnızca aygıtın gerçek girdisinin boyutuna bağlıdır ve girdinin esas içeriğinden bağımsızdır. Öğüt alan hesaplamanın özellikleri çeşitli hesaplama modelleri baz alınarak ve karmaşık- lık, çok biçimli hesaplama, formel diller ve sözde rastgelelik gibi farklı kavramlar ile bağlantılı biçimde çalışılagelmiştir. Sonlu durumlu makinalara bu türden harici yardım sağlamak için geliştirilen birkaç model de çeşitli gruplar tarafından çalışılmıştır. Bu araştırma kapsamında iki yeni öğüt alan sonlu durumlu makine modeli tanım- landı: öğüt şeritli sonlu durumlu makineler ve işaretle öğüt alan sonlu durumlu makine- ler. İlk modelde öğüt, bir dizi şeklinde ve girdi şeridinden bağımsız olarak erişilebilen ayrı bir şerit üzerinde sağlanır. İkinci modelde ise öğüt, girdi şeridi üzerine konulan ve iz adı verilen tek biçimli işaretler aracılığı ile sağlanmaktadır. Bu modellerin her birinin hesaplama gücü ve sınırları, temel hesaplama modelinin belirlenimci, olasılıksal ya da kuantum olmasına ve öğütün belirlenimci ya da rastgele biçimde seçilmesine bağlı olarak değişen çeşitli durumlarda incelendi. Artan öğüt miktarının bir hesaplama kaynağı olarak etkileri çeşitli biçimlerde değerlendirmeye dahil edildi. Her bir modelin versiyonları dil tanıma güçleri açısından, kendi aralarında ve daha önceden çalışılmış benzer makine modelleri ile karşılaştırıldı. Bu incelemenin temel sonuçları olarak söz konusu modeller tarafından değişik durumlarda tanınabilen dil sınıfları arasındaki çeşitli ayrışma, örtüşme ve sonsuz sıradüzen ilişkilerinin varlığı gösterildi.","Advice is a piece of trusted supplemental information that is provided to a computing device, in advance of its execution in order to extend its power beyond its limits and hence to assist it in its task. The content of this assistance, which is not restricted to be computable, typically depends only on the length, and not the full content of the actual input to the device. Advised computation has been studied on various computational models and in relation with concepts as diverse as complexity, nonuniform computation, formal languages and pseudorandomness. Several models for providing such external assistance to finite automata have also been studied by various groups. In this research, we introduce two novel models of advised finite automata: finite automata with advice tapes and finite automata with advice inkdots. In the former model advice is provided in the form of a string which is placed on a separate tape accessible independently from the input. In the latter one, we model advice as a set of uniform marks placed on the input tape which are called inkdots. We examine the power and limits of each of these models in a variety of settings where the underlying model of computation is deterministic, probabilistic or quantum and the advice is deterministically or randomly chosen. The roles of increasing amounts of advice as a computational resource are taken into consideration in various forms. The variants of each model are compared with each other and with the previously studied models of advised finite automata in terms of language recognition power. The main results of this analysis are demonstrated by establishing various separations, collapses and infinite hierarchies of the language classes that can be recognized with different models in varying settings."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı telefonlar en hızlı gelişen teknolojilerin başında geliyor. Sayısız özellikleriyle, akıllı telefonlar insanların pek çok konuda en büyük yardımcısıdır. Öte yandan, insanlara daha etkin ve verimli bir şekilde destek sunabilmeleri için yapılandırılmaları gerekiyor. Bu çalışmayı yapmamız için bizi teşvik eden, bulundukları konumlara göre akıllı telefonların otomatik olarak yapılandığı sistemdir. Bu özellik, Küresel Konumlandırma Sistemi'nin (KKS) katkılarıyla dış mekanlarda mümkündür. Fakat KKS verilerinin iç mekanlarda yeterli doğruluk sağlayamamasından dolayı, bu tezde, cihazın kendi sensörleri ve Wi-Fi kullanılarak akıllı telefonun bir oda içerisindeki yerinin tam olarak belirlenmesi amaçlanmıştır. Çalışmamızın kilit noktası, tamamen akıllı telefon üzerinden çalışılıyor olmasıdır. Motivasyonumuza uygun olarak iç mekanda belirli yerlerden, sensör verileri ile Wi-Fi sinyal verileri, bir Android akıllı telefonda geliştirdiğimiz Veri Toplama Uygulaması kullanılarak toplandı. Bu uygulama ile bir tümleşik veri tabanı yaratıldı. Beş farklı denetimli makine öğrenme algoritması oluşturulan veri tabanına uygulanarak doğruluk ve işlem süresi kriterlerine göre değerlendirildi. Öğrenme setinin %20'sinde %98 doğruluk sağlayan Karar Ağacı Sınıflandırıcısı en başarılı sınıflandırıcı olduğu belirlendi. Kullanılan sensör verilerinin hangisinin konumları birbirinden ayırmakta daha anlamlı olduğunu bulmak için, özelliklerin tahminleme gücü araştırıldı. Model değerlendirme sonuçları baz alınarak, her odaya özgü karar ağacı oluşturmak amacıyla yine aynı Android akıllı telefon üzerinde Veri Sınıflandırma uygulaması geliştirildi. Üç farklı odada gerçekleştirlen testlerde, her bir odadaki doğru noktayı saptama başarısının yüzde 80'den fazla olduğu görüldü.","Smartphones are leading among the fastest-growing technologies. With their numerous features, smartphones are the best assistants to users in their lives on several counts. However, a smartphone still requires an extensive con guration to assist every user eciently and e ectively. In this thesis, we are motivated to develop a system that makes a smartphone self-con gure automatically depending on its place. This has been well established for outdoor environments with contributions of GPS (Global Positioning System). However, GPS does not provide accurate data in indoor environments. Hence, in this thesis, we aim to determine the exact place of a smartphone in a room by exploiting on-device sensors and Wi-Fi services. The key point of our study is that it entirely works on the smartphone. In accordance with our motivation, sensors data and Wi-Fi RSSI values were collected from xed places via Data Collection Application which we developed on an Android smartphone. A fusion ngerprint database was created. Five supervised machine learning algorithms were evaluated on the ngerprint database in terms of classi cation accuracy and process time. The best performance was obtained from Decision Tree Classi er with 98% accuracy rate on 20% of training samples. Predictive power of used features were studied to specify which sensors are more meaningful for distinguishing indoor places from each other. Depending on model evaluation results, a Data Classi cation Application was developed on the same Android smartphone to generate a dedicated decision tree for each di erent room. Tests were carried out in three di erent rooms to show that more than 80% accuracy was achieved in nding the correct place in each room."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kişiyi yeniden tanıma, kişilerin pozlarının çeşitlilik gösterdiği ve vücutlarının bir kısmının görüntü içinde olmadığı durumlarda oldukça zorlu bir problemdir. Bu tezde, bu tip zorlu durumlarda da çalışabilecek, kısma dayalı bir kişiyi yeniden tanıma yöntemi önerilmektedir. Önerilen yöntem, girdi imajlarının hizalı olmasını gerektirmemekte ve kişi vücudunun yalnızca bir kısmının görülebildiği durumlarda da çalışabilmektedir. Önerilen yöntemde, bir poz tahmin edici yardımıyla, girdi imajlardaki vücut kısımları saptanır ve çıkarılır. Çıkarılan vücut kısımları, ilgili derin öğrenme modelleri ile ayrı ayrı işlenir. Her model, verilen iki vücut kısmı imaj girdisi için, iki farklı ham imajdan çıkarılan bu vücut kısımlarının aynı kişiye ait olma olasılıklarını çıktı verir. Füzyon aşamasında, vücut kısmı modellerinin çıktıları birleştirilir ve son olasılık değeri olarak çıktı verilir. Üç füzyon yöntemi incelenmiş ve üçü arasında en iyi yöntemin, mevcut vücut kısmı modeli çıktılarının ortalamasının alınması olduğu deneysel olarak gösterilmiştir. Yöntemin geliştirilmesi ve değerlendirilmesi amacıyla, Robot Kafe veri kümesi toplanmıştır. Robot Kafe veri kümesi, içinde yukarıda değinilen zorlukları barındırmaktadır. Veri kümesinin hazırlanması için bir işaretleme aracı geliştirilmiştir. Bu işaretleme aracı, videolardan kişi imajlarının kolay ve hızlı bir şekilde çıkarılmasını sağlamaktadır. Robot Kafe veri kümesi, 93 kişiye ait 10,969 imaj içermektedir. Deneyler, Robot Kafe ve CUHK03 veri kümeleri ile gerçekleştirilmiştir. Deney sonuçları, önerilen yöntemin eksik vücut kısımları ve poz çeşitliliği gibi zorluklara karşı varolan bazı yöntemlerden daha güçlü olduğunu göstermiştir.","Person re-identification (re-id) is a challenging task particularly when people have various poses and some parts of the person's body are occluded or missing in the view. In this thesis, we propose a part-based person re-id method to cope with these challenges. The proposed method does not require any alignment in input images and is able to work even if only a part of the body is seen. In the proposed method, with the help of a pose estimator, body parts are detected and extracted from the input images. The extracted body parts are processed separately through associated deep learning models. Given two input body part images, each model outputs the probability that the given body parts extracted from two different raw images belong to the same person. In the fusion step, outputs of each body part model are combined and the result is output as the final probability value. We investigated three fusion methods and empirically showed that averaging the available body part model outputs is the best fusion method among the three. In order to develop and evaluate our proposed method, we collected the Robot Cafe dataset which abounds with the challenges mentioned above. For this purpose, we developed an annotation tool to easily and fastly select and extract person images from videos. Robot Cafe dataset has 10,969 images from 93 persons. The experiments are conducted on Robot Cafe and CUHK03 datasets. The experiment results showed that our method is more robust to missing body parts and huge pose changes compared to some of the previous studies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Endüstride ve akademik çevrelerde ev otomasyon sistemleri alanında önemli miktarda mimari ve uygulama bulunmaktadır. Bunların birçoğu, bulut teknolojilerini kullanarak herhangi bir yerde bulunan ev sakinlerini bilgilendirmeyi hedeflemektedir. Ayrıca, bazıları yalnızca olayları, çevre koşullarını izleyen ve ev sakinlerini bilgilendiren pasif sistemler olarak adlandırılabilir. Bu geleneksel yaklaşım akıllı nesnelerin gelişmesi ve onların veri işleme yeteneklerinin artmasıyla değişiyor. Onlar artık çevredeki diğer cihazların mevcut durumunu analiz ederek karar verebilen aktif cihazlar haline geliyorlar. Bu çalışmada, görevleri katmanlara ve modüllere ayırarak ev ortamının uzaktan veya yerel olarak yönetilmesini sağlayan, iyi yapılandırılmış bir ev otomasyon sistemi olan FOGHA tasarlanmış ve uygulaması yapılmıştır. Güvenilirlik, güvenlik ve yönetebilme kaygıları nedeniyle ev aletleri ve bulut sunucuları arasındaki doğrudan iletişim arzu edilen bir durum olmadığı için, hesaplama düğümleri bulut ve sis olmak üzere iki ana alt sisteme ayrılmıştır. Sis katmanı fiziksel olarak akıllı nesnelere yakındır ve ev ortamının yerelde yönetilmesi onlar tarafından sağlanmaktadır. Sistemimizde, Raspberry Pi (RPI) cihazları bu amaçla dağıtık ve hatalara toleranslı şekilde kullanılmaktadır. Bu nedenle, bu cihazlar genel sistemin yerel beyinleri olarak görülebilirler. Ağ geçidi sis katmanı yöneticisi, diğerlerine ek olarak sis katmanını yönetirken ve bulut sunucularla iletişim kurarken, diger sis katmanı yöneticileri çevredeki akıllı nesnelerden veri toplar ve onları yönetir. Sistem tasarımına ilaveten, bir FOGHA mimarisi prototipi hazırladık ve üzerinde işlevsel testler yaptık.","There are considerable amount of architectures and implementations for home automation systems in both industry and academia. Many of them target to inform home residents who can be anywhere in the world using Cloud technologies. In addition, some of them could be named as passive systems which only monitor events, environmental conditions and inform the owner to take actions. This traditional approach is changing in the way of smart things with their increased processing capabilities. They are becoming active appliances which can make decisions by analysing the current state of the other appliances in the environment. In this study, we designed and implemented a well-structured home automation system, namely FOGHA, which enables both remote and local management of the home environment by separating tasks into layers and modules. Since direct communication between home appliances and Cloud servers is not desirable because of reliability, security and orchestration concerns, we divided the computation nodes into two main subsystems as Cloud and Fog. The latter subsystem is physically near to smart things and local orchestration of home environment is provided via Fog managers. In our system, Raspberry Pi (RPI) single board computers are used for this purpose in a distributed and fault-tolerant manner. Thus, they can be seen as the local brains of the overall system. While the gateway Fog manager additionally orchestrates other Fog managers and communicates with the Cloud, others collect data from smart things and manage them. Additional to the system design, we implemented a prototype of the FOGHA architecture and performed functional tests on it."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal medya, sosyal ağlar ve blokzincir türevi dağıtık platformlar tarafından üretilen veri miktarı son yıllarda hissedilir seviyede artmıştır. Veri miktarının bu derecede artması ile, toplanan verinin analiz edilmesi ve işlenmesi ile ilgili uygulamalar ortaya çıkmıştır. Bu uygulamalardan bir tanesi coğrafi olarak etiketlenmiş olan verinin hangi coğrafi bölgeye ait olduğunun efektif ve hızlı bir biçimde bulunmasıdır. Bu çalışmada, coğrafi noktaları coğrafi alanlar üzerine paralel sınıflandıran bir metod önerilip, bir yazılım aracı olarak kodlanmıştır. Kodlanan yazılımı test etmek amacıyla Twitter üzerinden, nüfus yoğunluğunu hesaba katarak Türkiye'nin en yoğun bölgelerinin beşinden veri toplanmıştır. Coğrafi sınıflandırma performansını etkileyen en önemli faktörler kullanılan coğrafi endeks ve parallelleştirme stratejisidir. Uygulamamız, Hierarchical Triangular Mesh (HTM) ve R-Tree coğrafi endekslerden ve açık kaynak kodlu, dinamik veri miktarina göre uygulama ihtiyaçlarına cevap veren Apache Spark ve Kafka platformlarından faydalanılarak ölçeklenebilir ve dağıtık yapıda geliştirilmiştir. Microsoft SQL Server'in sunduğu coğrafi endeks ve Kondor et al. tarafından HTM ile SQL Server'da geliştirilen metod, önerdiğimiz metod ile performans yönünden karşılaştırılmıştır. Uygulamamız, veri akımlarını hafıza üzerinde işleyen Spark üzerine inşa edildiği için, akımları efektif olarak işleyemeyen İlişkisel Veri Yönetim Sistemi bağımlı yaklaşımlara göre yüksek performans göstermektedir. Geliştirdiğimiz metod ile sorgu kümesinin büyüklüğüne bağlı olarak sınıflandırma süresi 1.6 ila 4.5 kat arasında hızlanma göstermiştir. Ayrıca tasarladığımız sistem, ölçeklenebilir mimarisi sayesinde milyarlar mertebesinde veriyi işleme olanağı sunmaktadır. Metodumuz performans artırmanın yanında maliyeti azaltmaktadır. Zira üç saat gibi kısa bir sürede bulut üzerinde bir aylık Twitter verisini çok düşük maliyet ile sınıflandırır.","The amount of data generated by social media, social networks and distributed platforms such as blockchain, have reached quite high levels. There are various use-cases to process this huge amount of data. One is to classify the geo-tagged data which is produced by social networks into geographical regions. We propose an efficient parallel classification approach and implement a classifier tool which is capable of processing huge geographical point data in parallel. Twitter data from five major cities of Turkey is used as classification test set considering the density of the regions. There are important factors effecting the classification performance such as spatial indexing and parallelization strategy. Hierarchical Triangular Mesh (HTM) and R-Tree spatial indexes are used for indexing regions and open-source Apache Spark and Kafka platforms are used to implement our classification application in a distributed and scalable environment. The mentioned platforms are designed to handle huge data streams and quickly respond varying volume of data traffic. Benchmarks are provided in thesis to show effectiveness of our approach against built-in spatial index of Microsoft SQL Server and approach of Kondor et al. in which HTM is applied on SQL Server. Our method has significant advantage since it is built upon Apache Spark platform which is crafted for processing chunks of data stream in real-time, however other approaches are based on SQL Server which cannot efficiently process massive streaming data. 1.6-4.5 fold speed-ups have been obtained in classification performance. The speed-up factor may change according to the query set size. Since our system has a scalable architecture it is possible to expand query set to billions of records. Apart from improved performance, our method is cost-effective since Twitter data collected over a month can be processed on cloud in around 3 hours with a small cost."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Öneri sistemleri (RS), kullanıcıların, çok sayıda veri koleksiyonu içerisinden bilgiye erişmelerine yardımcı olan programlardır. Bu tezde, etiketler, yer imleri veya izlenimler gibi örtük derecelendirmeleri ve kullanıcının profili veya öğe özellikleri gibi içerik bilgilerini kullanan hibrit modelleri araştırıyoruz. Literatürde, bu tür bilgileri kullanan öneri yaklaşımları, sırasıyla işbirlikçi filtreleme (CF) ve içerik tabanlı yöntemler olarak bilinmektedir. Hesaplama metodolojisi olarak biri matris ayrıştırmasına, diğeri ise derin öğrenmeye dayanan iki tekniği karşılatırıyoruz. Matris ayrıştırma temelli yaklaşım olarak, örtük derecelendirme matrisinin yanı sıra, bilimsel makalelerin başlıklarını ve özetlerini yan bilgi olarak kullanan Bayesci negatif olmayan matris faktörizasyonu (BNMF) yöntemini araştırıyoruz. Derin öğrenme metodu kapsamında CF yöntemi olarak olasılıksal matris faktörizasyonunu ve içerik tabanlı özellik çıkarımı olarak istiflenmiş gürültü giderici otokodlayıcılarına (SDAE) Bayesci yaklaşımı kullanan işbirlikçi derin öğrenme (CDL) yöntemini araştırıyoruz. Deneylerimizde bu teknikleri \% 0.22'lik derecelendirme yoğunluğuna sahip bir CiteULike veri kümesine uyguluyoruz. Deneysel sonuçlarımız, CDL'nin bu veri setinde bağlaşık BNMF'den daha etkili olduğunu göstermektedir. Bizim görüşümüzce, CDL, doğrusal olmayan ve derin bir yapıya sahip olan Bayesci SDAE bileşeni nedeniyle daha iyi performans göstermektedir.","Recommendation systems (RS) are programs that assist users in accessing information in vast amount of data collections. In this thesis, we investigate hybrid models that use both implicit ratings such as tags, bookmarks or impressions, and content information such as user's profile or item properties. In the literature, recommendation approaches that use such information are known as collaborative filtering (CF) and content-based methods, respectively. As computation methodology we investigate and compare two techniques, one is based on matrix decomposition and the other one is based on deep learning. As a matrix decomposition based approach, we investigate Bayesian nonnegative matrix factorization (BNMF), that we enhance using side information, the titles and abstracts of scientific articles, besides the implicit rating matrix. As a deep learning method, we explore collaborative deep learning (CDL), which uses probabilistic matrix factorization as CF method and Bayesian stacked denoising autoencoder (SDAE) as content feature extraction. We apply these techniques in our experiments to a CiteULike dataset with a rating density of 0.22\%. Our experimental results show that CDL is more effective than coupled BNMF on this dataset. In our opinion, CDL performs better due to its Bayesian SDAE component which has nonlinear and deep structure."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Metinden-konuşma (TTS) sistemleri, 1970'lerden beri yardımcı bir teknoloji olmuştur. Ticari kullanım on yıllar önce başlamış olmasına rağmen, sentetik konuşma kalitesi hala kayıtlı konuşma kadar iyi değildir. Bu çalışmanın odaklandığı konular- dan biri, TTS sistemlerinde konuşmacı uyarlamasıdır. Konuşmacı uyarlaması, belirli bir TTS modelini, sesi arzu edilen bir konuşmacının ses karakteristiği ile sentezleye- cek şekilde değiştirmektir. Bu çalışmada, transfer öğrenme yöntemlerini içeren derin sinir ağı (DNN) tabanlı yeni konuşmacı uyarlama teknikleri sunulmuştur. Kümelenme yöntemlerini kullanarak çok boyutlu konuşmacı temsil vektörlerini birkaç boyutlu vek- törlerle değiştirdik. Nesnel sonuçlar, parametrelerin sayısında önemli bir düşüşe ek olarak, başlangıç performansına göre uyarlamada belirgin iyileşme olduğunu göstermek- tedir. Bu çalışmanın ikinci yönü, DNN tabanlı post filtreleme yöntemleri üzerinde gerçekleştirilen konuşmacı uyarlamasıdır. Öznel sonuçlar, postfiltre uyarlanmasının, sentetik konuşmanın istenen konuşmacının sesine benzerliğini arttırdığını, ancak kalite- de önemli bir iyileşmenin gözlenmediğini göstermektedir. Bu çalışmada önerilen teknik- ler, DNN mimarisinin ve konuşmacı temsil vektörlerinin seçiminden bağımsızdır, bu nedenle, ileride konuşma tanıma gibi ilgili alanların deneyleri için genişletilebilir ve kullanılabilir.","Text-to-speech (TTS) systems have been an assisting technology since the 1970s. Although commercial use has begun decades ago, synthetic speech quality is still not as good as recorded speech. One particular subject of this field focused by this study is the speaker adaptation in TTS systems. Speaker adaptation is the task of modifying a given TTS model such that the modified model synthesizes speech samples with the voice characteristic of a desired speaker. In this study, deep neural network (DNN) based novel speaker adaptation techniques incorporating transfer learning methods are presented. We replaced the high dimensional speaker embeddings with few dimensional vectors using clustering methods. Objective results indicate significant improvement to the adaptation performance compared to baseline techniques in addition to a significant drop in the number of parameters. The second aspect of this study is the speaker adaptation performed on DNN-based postfiltering methods. The subjective results show that the adaptation of postfiltering increases the similarity of synthetic speech to the desired speaker's voice although no significant improvement in quality is observed. The techniques proposed in this study are independent of the choice of the DNN architecture and speaker embedding, thus, can be extended and used for experiments of relevant fields such as speech recognition in the future."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Üçlüler(varlık-ilişki-varlık) biçiminde ifade edilen gerçekleri kullanarak yeni ve bilinmeyen gerçekler çıkarsamak popüler bir istatistiksel ilişkisel öğrenme görevidir ve bilgi grafiği bağlantı tahmini problemi ismi ile tanımlanır. Problem tanımının doğası gereği mevcut veri setlerini temsil etmek için tensörler yaygın olarak tercih edilmektedir. Varlıklar ve ilişkiler için saklı özelliklerin varlığında, orijinal veri kümesi tensörüne yaklaşmak için tensör ayrıştırma modelleri kullanılır. Varlıkların ve ilişkilerin bu saklı özellikleri, yaklaşım sırasında kestirilir/çıkarsanır ve aralarındaki etkileşim, üçlülerin varoluş olasılıklarını ortaya çıkarır. Bu tez çalışmasında, bilgi grafik problemlerinde kullanılmak üzere, yakın zaman önce tanıtılan Toplam Koşullu Poisson Ayrıştırması'nın tensör uzantısını önermekteyiz. Genelleştirilmiş Doğrusal Modeller'e alternatif olarak Toplam Koşullu Poisson Ayrıştırması değer aralığı sınırlı olan veriyi, toplamları üzerinden koşullandırılmış L bileşen Poisson Ayrıştırması ile modellemek için kullanılabilir. Standart parametreleri ayrıştıran Genelleştirilmiş Doğrusal Modeller'den farklı olarak, Toplam Koşullu Poisson Ayrıştırması doğrudan moment parametrelerini ayrıştırır. Bilgi grafiği problemi için toplamları birler tensörüne koşullanmış iki Poisson tensör ayrıştırması tanımlamaktayız. Beklenti Enbüyütme ile en büyük olabilirlik kestirimi, varyasyonel çıkarsama ve Gibbs örneklemesi ile ise Bayesci çıkarsama sunuyoruz. Toplam Koşullu Poisson Ayrıştırması modellerinin öngörü performanslarını, standart veri kümeleri (Nation, UMLS, ve Kinship) üzerinde, en ileri Genelleştirilmiş Doğrusal Model olan Lojistik Tensör Ayrıştırması'nın performansıyla karşılaştırmaktayız.","Extracting new unknown facts from given facts in the format of triples(entity-relation-entity) is a popular statistical relational learning task and defined with the name of knowledge graph link prediction problem. Due to nature of the problem definition, tensors are widely preferred to represent existing datasets. In the presence of latent features for entities and relations, tensor factorization models are used to approximate to the original dataset tensor. These latent features of entities and relations are estimated/inferred during approximation and interaction between them reveals the probabilities of triple existences. In this thesis, we propose the tensor extension of recently introduced Sum Conditioned Poisson Factorization, in order to use it in knowledge graph problems. Sum Conditioned Poisson Factorization is an alternative to Generalized Linear Models and can be used to model bounded data with L component Poisson Factorizations which are conditioned on their summation. Unlike GLMs which factorize canonical parameters, SCPF decomposes directly the moment parameters. For knowledge graph problems, we define two Poisson tensor factorizations by conditioning their summation to a tensor of ones. We introduce maximum likelihood parameter estimation with Expectation Maximization and Bayesian inference with variational inference and Gibbs sampling. We compare the predictive performance of SCPF models with the performance of state of the art Generalized Linear Model, Logistic Tensor Factorization on standard datasets (Nation, UMLS, and Kinship)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Derin pekiştirmeli öğrenme (DRL), derin sinir ağlarını pekiştirmeli öğrenme ile birleştirir. Bu yöntemler, seleflerinden farklı olarak, eylemleri doğrudan tahmin etmek için ham sensör verilerinden yüksek boyutlu gösterimler çıkararak uçtan uca öğrenirler. Aynı algoritmayı, ağ mimarisini ve üstel parametreleri kullanan DRL yöntemlerinin ATARI oyunlarının çoğunda ustalaştığı gösterilmiştir. Ancak, DRL'nin neden bazı oyunlarda ötekilerinden daha iyi çalışmasının sebebi araştırılmamıştır. Bu tezde, her oyunun karmaşıklığının bir dizi etkenle (arama alanının büyüklüğü, düşmanların varlığı/yokluğu, ara ödülün varlığı/yokluğu vb.) tanımlandığı ve oyunların öğrenme hızlarının ve başarılarının bu etkenlere bağlı olduğu öne sürülmüştür. Bu amaca yönelik olarak basitleştirilmiş Labirent ve Pacman ortamları kullanılarak bu etkenlerin DRL'nin yakınsaması üzerindeki etkisini görmek için deneyler yapılmıştır. Bu çalışmanın sonuçları DRL'nin nasıl çalıştığını daha iyi anlamak için bir ilk adımdır ve gelecekte DRL'nin etkili bir şekilde uygulanabileceği senaryoları belirlemekte bilgilendirici olacaktır.","Deep Reinforcement Learning (DRL) combines deep neural networks with reinforcement learning. These methods, unlike their predecessors, learn end-to-end by extracting high-dimensional representations from raw sensory data to directly predict the actions. DRL methods were shown to master most of the ATARI games, beating humans in a good number of them, using the same algorithm, network architecture and hyper-parameters. However, why DRL works on some games better than others has not been fully investigated. In this thesis, we propose that the complexity of each game is defined by a number of factors (the size of the search space, existence/absence of enemies, existence/absence of intermediate reward, and so on) and we posit that how fast and well a game is learned by DRL depends on these factors. Towards this aim, we use simplified Maze and Pacman environments and we conduct experiments to see the effect of such factors on the convergence of DRL. Our results provide a first step in a better understanding of how DRL works and as such will be informative in the future in determining scenarios where DRL can be applied effectively e.g., outside of games."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım tabanlı ağlarda programlanabilir varlıkların yani denetleyici ve anahtarlayıcıların varlığı, yüksek bant genişlikli iletişimi kolayca kullanımı için dinamik ve yönetilebilir ağlar için hiyerarşik bir yapı sağlar. Bununla birlikte, yazılım tabanlı ağlardaki mevcut protokollerin yetersizlikleri nedeniyle bu tür yapılar doğrulanmamış paket düşmeleri ve yanlış paket yönlendirmeleri gibi ataklara neden olabilir. Örneğin, veri düzleminin çalışmasını manipüle etmek için bir anahtarlayıcının ele geçirildiğinin tespiti OpenFlow ile mümkün değildir. Bu tür güvenlik açıklarının üstesinden gelmek için kullanılabilecek potansiyel adaylardan birisi ele geçirilmiş olan anahtarlayıcıları tespit etmek için varlıkların öznel davranışlarını yansıtacak bir yaklaşım kullanmaktır. Kişisel davranışları değerlendirmek için hesaplamalı güven temelli çözümün sağlanması, tehlikeye giren anahtarlayıcıların belirlenmesine yardımcı olacaktır. Bu nedenle, bu tezde, güvenli yönlendirmede kullanılacak anahtarlayıcılar için bir Güven ile İyileştirilmiş Güvenli Yönlendirme'yi öneriyoruz. Önerilen model, bir ağın farklı durumları için en uygun güven düzeyini bulmak için üç farklı güven hesaplaması sunar. Önerilen yaklaşımın uygulanabilirliğini göstermek için, ele geçirilen anahtarlayıcıların tespiti için bir dizi simülasyon gösteriyoruz. Simülasyon sonuçları Güven ile İyileştirilmiş Güvenli Yönlendirme'nin güvenli yolları seçerken risk altındaki düğümleri tespit etmek ve ortadan kaldırmak için etkin bir şekilde çalıştığını göstermektedir.","The presence of programmable entities, namely controllers and switches, in Software Defined Networks (SDNs) provides a hierarchical architecture to achieve dynamic and manageable networks for easily utilizing high bandwidth communications. However, such architecture may cause unsubstantiated packet dropping and incorrect packet forwarding due to the inability of current networking protocols in SDN. For instance, the detection of a compromised switch, which can be used for manipulating the data plane operation, is not possible with OpenFlow. One of the potential candidates to overcome such vulnerabilities is to use an approach to reflect subjective behaviors of entities for detecting the compromised ones. The provision of computational trust based solution for evaluating subjective behaviors is expected to help determine compromised switches. Therefore, in this thesis, we propose a Trust Enhanced Secure Routing (TESR) for switches to be used in secure routing. The proposed model provides three different trust computations in order to find the most suitable trust level for different states of a network. To show the applicability of the proposed approach, we demonstrate a set of simulations for the detection of compromised switches. Simulation results show that TESR operates effectively to detect and eliminate compromised nodes while selecting secure paths."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, kadın ve erkek olarak algılanan bireylerin son yüzyıllardaki renk seçimlerini otomatik olarak inceleyen bir sistem önerilmiştir. Bu çalışma, batı sanatındaki cinsiyet tanımını ve algısı, bu tanımın 17. ile 20. yüzyıllar arasında kültür, edebiyat ve sanat dallarında görselleştirilmesi projesinin bir parçası olarak yapılmıştır. Bu çalışmada Rijksmuseum Amsterdam tarafından paylaşılan sayısal imgeler kullanılmış, bu portrelerdeki modellerin kıyafetlerindeki baskın rengin çıkarılması için bir metod önerilmiştir. Bu çalışmanın sonucunda, sayısal sanat bilimiyle ilgili bilim insanlarının kullanabileceği bir uygulama çıkartılmıştır. Çalışmada kullanılan veri kümesi, portrelerin yanısıra, pek çok tarihi eser ve nesneyi de içinde bulunmaktadır. Portre resimlerinin bu kümeden ayrıştırılması için, Rijksmuseum veri kümesine yüz bulma algoritması uygulanmıştır. Arkasından, bu portreler, modelin algılanan cinsiyetine göre ayrıştırılmak üzere, insan fotoğrafları ile eğitilmiş bir sınıflandırıcıdan geçirilmiştir. Bu amaçla, üç farklı yüz veri kümesi kullanılmış ve çeşitli eğitim kümesinin resimlerde cinsiyet algısı üzerindeki etkileri incelenmiştir. Modele ait renk bilgisine yoğunlaşabilmek için, kıyafet bölütlenmesine gerek duyulmuştur. Bu sebepten, yüzdeki simgesel noktaları kullanarak kıyafet için ilgi bölgesi çıkartan basit ama kuvvetli bir algoritma sunulmuştur. Bu bölge, renk dağılımlarını ve hakim rengi çıkarmak için kullanılmıştır. Bu amaçla, dört farklı renk çıkarım yöntemi kıyaslanmıştır. Son olarak, etkileşimli bir arayüz yardımı ile, sonuçların görülebildiği ve incelenebidiği bir platform hazırlanmıştır. Bu platform, kullanıcıları renk eğilimlerini zaman ekseninde görselleyebilmesi ve bu sayede farklı dönemleri renk dağılımlarını ve bu renklerin çağrışımlarını inceleyebilmesini sağlamaktadır.","In this thesis, we propose an automated methodology to study the trend of color preferences for male and female subjects of paintings over several hundred years. This study is part of a larger project on understanding how sex is defined and described in the Western culture, by tracing the transformation of gender representations in culture, literature, and arts from 17th to 20th century. The data are collected using digital images of paintings from Rijksmuseum Amsterdam. We proposed an approach to extract the dominant color in clothes of the sitters of portrait paintings. The resulting application of this study could provide a useful tool for the digital humanities scholars. Artworks used in this study consists of different artifacts and objects. We ran a face detection algorithm on the Rijksmuseum dataset for the portrait painting collection. Following that, the portraits were classified into their perceived sex by an algorithm, trained on photographic images. Three different face image databases were employed and compared to measure the impact of varied training set conditions on perceived sex classification from paintings. To concentrate on the color information of the sitter, clothing segmentation of the sitter is a necessity. Hence, a simple, yet robust algorithm that uses the location of the face as a landmark to identify a region of interest to represent the clothing in portrait paintings is proposed. This region is used to extract the color distribution, and one dominant color. We contrasted four color extraction methods for this purpose. An interactive interface, where the results of the approach can be viewed and analyzed by an individual is designed. It provides a full overview of the color trends on a temporal axis, thus making it possible to study color preferences in different eras, as well as the changes in color connotation. The interface is designed as a visualization tool for curators or researchers and makes it possible to receive feedback."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nanoağlar alanında yaygın olarak kabul görmüş olan Difüzyon yoluyla Moleküler Haberleşme (DyMH), avantajlarının yanı sıra zorlukları da beraberinde getirmektedir. DyMH'nin yeteneklerini ve kısıtlarını değerlendirebilmek için, alımlama sürecinin ve erişilebilir hızının ayrıntılı olarak kavranması son derece önemlidir. Yansıtıcı küresel bir verici ve tamamen emici küresel bir alıcı ile ağ kurulumu daha gerçekçi olur, fakat analitik türetimler de artarak zorlaşır. Bu tezde, Mesajcı Moleküllerin (MM) ilk geçiş zamanı dağılımını istatistiksel olarak modellemek için iki yeni ağır kuyruklu dağılım öneriyoruz, model doğrulaması için Kolmogorov-Smirnov uyuşum testi yapıyoruz ve modelleme başarımını çok çeşitli sistem parametreleri altında inceliyoruz. Ayrıca, MM emilim olasılığı, sinyal-girişim oranı ve yansıtıcı verici kullanmanın avantajlarına değiniyoruz. Sinyalin ağır kuyruğunun Semboller Arası Girişim (SAG) yaratmasından dolayı, DyMH bellekli bir kanaldır ve Shannon'ın belleksiz kanallar için kapasite formülü uygulanamaz. Bu nedenle, DyMH'nin girişime duyarlı demodülasyon olasılıkları ve ikili hatası olasılıklarının isabetli bir modelini öneriyoruz, uyuşum testleri gerçekleştiriyoruz ve yazındaki tek sembol sürelik bellek varsayımının fazla iyimser olduğunu ispatlıyoruz. Bunlara ek olarak, ergodik sonlu durumlu SAG kanalları için erişilebilir hızın genel formülasyonunu DyMH'ye uyarlıyoruz ve sistem parametreleri, demodülasyon eşiği ve girdi dağılımının erişilebilir hız üzerindeki etkilerini inceliyoruz. Ayrıca, erişilebilir hızın yapay sinir ağı ile kestirimi üzerine ilk gözlemlerimizi sunuyoruz. Son olarak, biyolojideki hücre uzantısı kavramını DyMH'ye uygulayarak girişimin fiziksel olarak azaltılmasını ve uzantı konuşlanma değişkenlerinin erişilebilir hıza olan etkisini inceliyoruz.","As a widely acknowledged information transfer method in the nanonetworking domain, Molecular Communication via Diffusion (MCvD) presents many advantages as well as challenges. In order to assess the capabilities and restrictions of MCvD, a thorough understanding of the reception process and the achievable rate holds utmost importance. With a reflective spherical transmitter and a fully absorbing spherical receiver, the network setup becomes more realistic, but analytical derivations become increasingly difficult. In this thesis, we propose two novel heavy-tail distributions to statistically model the distribution of the first passage time of messenger molecules (MM), conduct Kolmogorov-Smirnov goodness of fit tests for model validation, and examine the modeling performance under diverse deployment parameters. We also investigate MM absorption probability, Signal-to-Interference Ratio, and the advantages of using a reflective transmitter. Since the heavy-tailed signal causes Inter-Symbol Interference (ISI), the MCvD channel has memory, and Shannon's capacity formula for memoryless channels is inapplicable. To this end, we propose an accurate ISI-aware model of demodulation and bit error probabilities for Binary Concentration Shift Keying modulated MCvD, carry out goodness of fit tests, and prove that the literature's assumption of a single symbol duration memory is overly optimistic. Furthermore, we adapt the general formulation of the achievable rate for ergodic finite state ISI channels to MCvD and investigate the effect of deployment parameters, demodulation threshold, and input distribution on the achievable rate. We also present preliminary findings on estimating the achievable rate with a neural network. Finally, we apply the biological concept of protrusions to MCvD, in order to physically reduce ISI and study the effect of protrusion deployment parameters on the achievable rate."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde altruistik davranış için bir bilişimsel model önerilmiş, önerilen modelin fiziksel robot üzerinde uygulaması gösterilmiş, ve uygulama kullanılarak elde edilen insan-robot işbirliği deneylerinin sonuçları sunulmuştur. Önerilen modelimiz, primat beynindeki duyudevinimsel mekanizmalardan ilham alarak, obje sağlarlıklarından hem niyet tahmini hem de aksiyon uygulamada, bilhassa altruistik davranış üretmek amacıyla yararlanmaktadır. Modelin temelinde yer alan kanı, hareket üretmek için geliştirilen duyudevinimsel sistemlerin, başkalarının aksiyonları sonucu oluşan görsel uyaranları işlemede kullanılabileceği, dolayısıyla da altruistik davranışın ortaya çıkmasına yol açabileceğidir. Bu nedenle biz, altruistik davranışların bilinçli bilişsel işlemlerin sonucu olmak zorunda olmadığını ve hata minimizasyonu gibi basit duyudevinimsel işlemlerin sonucu olarak ortaya çıkabileceğini tartışıyoruz. Modelde sağlarlıklar, gözlenen aktörün meşgul olabileceği muhtemel aksiyonlar kümesini sınırlayarak, daha hızlı ve doğru bir niyet çıkarımına olanak sağlayarak kilit bir rol oynamaktadır. İstenen işlevselliği sağlamak amacıyla model bileşenleri çift kollu insansı sistem üzerinde fonksiyonel üniteler şeklinde uygulanmıştır. Model bileşenlerinin çalıştığını tasdik etmek amacıyla, sağlarlık çıkarımı, görev uygulaması benzeri bir takım deneyler yapılmıştır. Mühim olarak, insanların bizim altruistik modelimizin uygulandığı robot ile olan etkileşimlerini değerlendirebilmek amacıyla, sistem adına naif ve gönüllü insanlar üzerinde geniş çaplı deneyler yaptık. Sonuçlarımız gösteriyor ki önerilen bilişimsel model, altruistik davranışın ortaya çıkmasını biyolojik olarak da makul bir şekilde açıklayabilir, buna ek olarak da insansı robot üzerinde uygulandığı zaman insan ortakları bu davranıştan yararlanmaya yönlendirebilir.","This thesis proposes a computational model for altruistic behavior, shows its implementation on a physical robot, and presents the results of human-robot interaction experiments conducted with the implemented system. Inspired from the sensorimotor mechanisms of the primate brain, our model utilizes object affordances for both intention estimation and action execution, in particular to generate altruistic behavior. At the core of the model is the notion that sensorimotor systems developed for movement generation can be used to process the visual stimuli generated by actions of the others, and thus can lead to the emergence of altruistic behavior. Therefore, we argue that altruistic behavior is not necessarily a consequence of deliberate cognitive processing but may emerge through basic sensorimotor processes such as error minimization. In the model, affordances also play a key role by constraining the possible set of actions that an observed actor might be engaged in, enabling a faster and accurate intention inference. The model components are implemented on an anthropomorphic dual-arm manipulator system as functional units to provide the desired functionality. A set of experiments are conducted validating the workings of the components of the model, such as affordance extraction and task execution. Significantly, to asses how human partners interact with our altruistic model deployed robot, extensive experiments with \naive\insentence subjects are conducted. Our results indicate that the proposed computational model can explain emergent altruistic behavior in a biologically plausible way, and moreover engage human partners to exploit this behavior when implemented on an anthropomorphic robot."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hızlı ve ucuz veri işaretleme, makine öğrenmesinin son on yılda birçok alanda aşırı rağbet görmesiyle birlikte daha da önemli bir hale geldi. Kitle kaynak servislerinin çıkışı, araştırma yönünü `kitlelerin bilgeliğini' kullanmaya itti. Kitle kaynak temelli etiket toplama işlemini kitle etiketleme olarak adlandırıyoruz. Bu tezde, sürekli değerli etiketler için kitle oydaşım kestirimi üzerine odaklanıyoruz. Maalesef, kötü niyetli veya dikkatsiz işaretçiler, oydaşım etiketinin kalitesine ve güvenilirliğine kötü etki etmektedir. Bundan ötürü, değişik işaretçi davranışlarını dikkate alan Bayesçi modeller geliştiriyoruz ve modellerimizi değerlendirmek için iki yeni kitle işaretli veri kümesi tanıtıyoruz. Kaliteli oydaşım etiketi kestirimi, işaretçi ve işaretlenecek örnek seçiminin akıllı bir şekilde yapılmasını gerektirir. Zaman ve bütçe kısıtlarından dolayı, bu seçimleri işaret toplama sırasında yapmak önemlidir. Bu nedenle, sürekli değerli kitle işaretlerinden aktif bir şekilde etiket kestirimi yapan bir aktif kitle etiketleme yaklaşımı öneriyoruz. Yöntemimiz, bilinmeyen parametreleri olan işaretçi modellerine dayalıdır ve sıralı, ikili veya sürekli değerli etiketlere ulaşabilmek için Bayesçi çıkarım kullanır. İşaret istemek için işaretçi ve işaretlenecek örnek ikilisini seçmede kullanılan sıralama fonksiyonları tanıtıyoruz. Ek olarak, işaretçi baskınlığını engellemek için cezalandırma yöntemi öneriyoruz, sisteme yeni işaretçiler eklemek için keşfetme ve kullanma dengesini araştırıyoruz ve oydaşım etiketi kalitesine göre aktif işaretlemeyi durdurma kriteri koymanın etkilerini inceliyoruz. Kıstas veri kümelerindeki deneysel sonuçlar, yöntemimizin kitle etiketleme problemine bütçeye ve zamana duyarlı bir çözüm sağladığını göstermektedir. Son olarak, çok değişkenli işaretlemelerdeki nitelikler arası bağıntıları dikkate alan çok değişkenli bir model tanıtıyoruz ve hakkındaki ilk gözlemlerimizi sunuyoruz.","As machine learning gained immense popularity across a wide variety of domains in the last decade, it has become more important than ever to have fast and inexpensive ways to annotate vast amounts of data. With the emergence of crowdsourcing services, the research direction has gravitated toward putting `the wisdom of crowds' to use. We call the process of crowdsourcing based label collection crowd-labeling. In this thesis, we focus on crowd consensus estimation of continuous-valued labels. Unfortunately, spammers and inattentive annotators pose a threat to the quality and trustworthiness of the consensus. Thus, we develop Bayesian models taking different annotator behaviors into account and introduce two crowd-labeled datasets for evaluating our models. High quality consensus estimation requires a meticulous choice of the candidate annotator and the sample in need of a new annotation. Due to time and budget limitations, it is beneficial to make this choice while collecting the annotations. To this end, we propose an active crowd-labeling approach for actively estimating consensus from continuous-valued crowd annotations. Our method is based on annotator models with unknown parameters, and Bayesian inference is employed to reach a consensus in the form of ordinal, binary, or continuous values. We introduce ranking functions for choosing the candidate annotator and sample pair for requesting an annotation. In addition, we propose a penalizing method for preventing annotator domination, investigate the explore-exploit trade-off for incorporating new annotators into the system, and study the effects of inducing a stopping criterion based on consensus quality. Experimental results on the benchmark datasets suggest that our method provides a budget and time-sensitive solution to the crowd-labeling problem. Finally, we introduce a multivariate model incorporating cross attribute correlations in multivariate annotations and present preliminary observations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, büyük ölçekli insan eylemi tanıma problemi için önerilmiş olan bir yöntem olan Geliştirilmiş Yoğun Gezingeler yöntemini uyarlayıp basitleştirdiğimiz bir işaret dili tanıma sistemi önerilmektedir. İşaret dili tanıma problemi çoğunlukla el hareketleri, vücut duruşu ve yüz ifadesine odaklandığı için, Geliştirilmiş Yoğun Gezingeler özniteliklerini çıkartıldıktan sonra elde edilen gezinge koordinatları poz çıkartma ile elde edilmiş olan el koordinatları ile eşleştirerek el çevresindeki gezingeler ayrılmıştır. Gezinge filtrelemesine ek olarak, bu çalışmada bir uzam-zamansal öznitelik çıkartma yöntemi olan El Betimleyicileri işaret dili tanıma için önerilmiştir. Önerdiğimiz bu yöntemde, sol ve sağ ellerin etrafından uzam-zamansal betimleyiciler elde edilmektedir. Betimleyiciler elde edildikten sonra, her bir işaret videosu, eğitim betimleyicilerinden elde edilen Gauss Karışım Modelinden türetilen Fisher Vektörler olarak tanımlanmıştır. Sonrasında, bu Fisher Vektörler işaret dili sınıflandırması yapmak için eğitilecek bir Destek Vektör Makinesine girdi olarak verilmektedir. Sistemi öznitelik çıkartma hızı, hesaplama karmaşıklığı ve bellek gereksinimi açısından değerlendirmek için BosphorusSign veri setinin alt kümeleri üzerinde deneyler yapılmıştır. Yapılan bu deneylerde, bütün öznitelik türlerinde, bütün betimleyicilerin beraber kullanıldığı durumda sistem en iyi tanıma performasını elde etmiştir. Yörünge filtreleme yöntemi temel yönteme yakın bir tanıma performansı verdiği gibi aynı zamanda yörüngelerin sayısını büyük bir ölçüde azaltmıştır. Ayrıca, farklı parametreler ve video çözünürlükleri kullanmanın El Betimleyicilerinin performansı üzerindeki etkisini analiz ettik. Bu çalışmada yaptığımız deneyler, el bölgesinden elde edilen betimleyicilerin işaret dili sınıflandıran sistemimiz için en önemli öznitelikleri barındırdığını göstermiştir.","In this thesis, we propose a sign language recognition system in which we have adapted and simplified the Improved Dense Trajectory (IDT) approach which was originally proposed for large-scale human action recognition problem. Since the sign language recognition problem mostly focuses on hand gestures, body posture and facial expressions, we have extracted IDT features and filtered the trajectories around the hand region by matching the trajectory coordinates with hand coordinates obtained by pose extraction. In addition to trajectory filtering, we also propose Hand Descriptors, a spatio-temporal feature extraction method, for sign language recognition. In our proposed method, we extract spatio-temporal descriptors around left and right hands. After descriptor extraction, we encoded each sign video as Fisher Vectors which were derived from a Gaussian Mixture Model which was estimated from the training descriptors. Then, we have trained Support Vector Machines to perform sign language classification using the Fisher Vectors as its inputs. We have conducted experiments on two subsets of the BosphorusSign dataset and evaluated the performance of the system in terms of feature extraction speed, computational complexity and memory requirement. In our experiments, the combination of all descriptors yields the best recognition performance on both subsets for both features. We have found that trajectory filtering approach yields a similar recognition performance to the baseline approach while the number of trajectories are drastically reduced. Moreover, we have analysed the effects of using different parameters and video resolutions on the performance of the Hand Descriptors. Our experiments have shown that hand region produces the most important features in our sign language classification system."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,Bu tezde veri ırmağı analizi için çevrimiçi makine öğrenmesi algoritmalarını araştırdık. Standart çevrimdışı algoritmaları gözden geçirdikten sonra çevrimdışından çevrimiçine dönüştürmeleri açıkladık ve sonra veri ırmağı madenciliği tekniklerinin geniş kapsamlı tanımlamasını ve analizini yaptık. Çevrimiçi gruplama ve sınıflandırma algoritmalarından örnek olarak özellikle çevrimiçi k-ortalama ve çok katmanlı algılayıcı modellerine odaklandık. Sayısal deneylerimizi yaptıktan sonra teorik ve deneysel analizlerimizi farklı bakış açıları kullanarak bu tezde algoritmaların çevrimiçi biçimleri için bu deneyler üzerinden anlattık.,"In this thesis we give a survey of online machine learning algorithms for data stream analysis. After giving an overview of standard batch algorithms, we explain batch-to-online conversion, and we give a in-depth description and analysis of data stream mining techniques. We particularly focus on online k-means algorithms and multilayer perceptron models as representative examples of online clustering and classification algorithms. We also present theoretical and empirical analyses of different approaches for online versions of these algorithms through numerical experiments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Görüntü paylaşımı, birçok çevrimiçi sosyal ağ tarafından sunulan bir hizmettir. Görüntülerin mahremiyetini korumak için kullanıcıların, yükledikleri her görüntünün mahremiyet ayarlarını düşünmesi ve ona göre düzenlemesi gerekir. Ancak bu, iki ana nedenden ötürü zordur: Birincisi, araştırmalar, kullanıcıların çoğu zaman kendi mahremiyet tercihlerini bilmediklerini, ancak zaman içinde bunların farkına vardıklarını göstermektedir. İkincisi, kullanıcılar mahremiyet tercihlerini bildiklerinde bile, bu politikaları belirlemek zahmetlidir ve bir sosyal ağda beklenen hızlı paylaşım davranışına müdahale etmek çok fazla çaba gerektirir. Bu tezde görüntülerin içerik etiketlerini kullanarak görüntüler için mahremiyet ayarı öngören etmen tabanlı bir yaklaşım olan PELTE'yi öneriyoruz. Her kullanıcı etmeni, kullanıcısı tarafından yeni yüklenen görüntünün mahremiyet ayarını otomatik olarak tahmin etmek için önceki görüntülerin mahremiyet ayarlarını kullanır. Etmenler şüpheye düştükleri zaman, mahrem olanla ilgili kullanıcıya bir öneride bulunmak için diğer güvenilir etmenlerin paylaşım davranışlarını analiz ederler. Çevrimiçi sosyal ağdaki mevcut tüm görüntülere erişerek mahremiyet ayarı önerisinde bulunan mevcut merkezi yaklaşımların aksine, PELTE etmen temellidir ve böylece her bir kullanıcı etmeni yalnızca kullanıcısının paylaştığı veya kullanıcısıyla paylaşılan görüntülerin ayarlarına erişebilir. Gerçek veri kümeleri kullanarak yaptığımız benzetimler, PELTE'nin bir kullanıcı sosyal ağda yeni olduğu, diğer kullanıcılarla sadece birkaç görüntü paylaştığı, kullanıcının sosyal ağda tanıdıklarının değiştiği ya da görüntülerin sadece birkaç etiketinin olduğu zamanlarda bile mahremiyet ayarlarını doğru bir şekilde tahmin edebildiğini göstermektedir.","Image sharing is a service offered by many online social networks. In order to preserve privacy of images, users need to think through and set the privacy settings for each image that they upload. This is difficult for two main reasons: First, research shows that many times users do not know their own privacy preferences, but only become aware of them over time. Second, even when users know their privacy preferences, specifying these policies is cumbersome and requires too much effort, interfering with the quick sharing behavior expected on an social network. Accordingly, this thesis proposes an agent-based approach, PELTE, that predicts the privacy setting of images using their content tags. Each user agent makes use of the privacy settings that its user have set for previous images to predict the privacy setting for a new uploaded one automatically. When in doubt, the agent analyzes the sharing behavior of other trusted agents to make a recommendation to its user about what is private. Contrary to existing approaches that assume a centralized online social network where privacy is set by accessing all the available images, \textsc{PELTE} is distributed and thus each agent can only view the privacy settings of the images that it has shared or those that have been shared with it. Our simulations on a real-life dataset show that PELTE can accurately predict privacy settings even when a user is new in a online social network, she has shared a few images with others, the images have only a few tags or the user's friends have varying privacy preferences."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ardışık Monte Carlo (SMC) yöntemleri, doğrusal ve Gaussian olmayan dinamik sistemlerde iyi bilinen ve çokça kullanılan yöntemlerdir. Ancak, ağır hesaplama \linebreak gereklilikleri nedeniyle, çok sayıda örnek gerektiren birçok uygulamada gerçek zamanlı kısıtlara uymayabilirler. Paralelleştirme sayesinde, çevrimiçi süzgeçleme gibi gerçek zamanlı görevler gerçekleştirilebilir. Fakat, SMC yöntemlerinde yeniden örnekleme aşaması örnek etkileşimini gerektirir ve dolayısıyla paralelleştirilmesi kolay değildir. Bu tezde, ilk olarak, yeniden örnekleme algoritmalarını paralel hale getirmenin standart yöntemini sunuyoruz ve bu yöntemin gerçekleşiminde açığa çıkan sorunları tartışıyoruz. Daha sonra, literatürde daha önce tarif edilen kelebek yeniden örneklendirmesinden esinlenerek, kelebek iletişimi (RBC) ile yeniden örnekleme yapan paralel bir yeniden örnekleme algoritması öneriyoruz. Amacımız, iletişim örüntüsüne kısıtlar koyarak, iletişim yükü ve yük dengesizliği gibi standart yaklaşımın önemli darboğazlarını ortadan kaldırmaktır. Deneylerimizi bilgisayar grupları ve GPU'lar dahil olmak üzere farklı paralel hesaplama mimarileri üzerinde yaptık. RBC algoritmasını standart yaklaşımla, yürütüm süresi ve doğruluk açısından karşılaştırdık. RBC algoritmasının, bilgisayar kümeleri ile GPU'lar üzerinde standart yaklaşımı geride bıraktığını ve etkin örneklem büyüklüğünün ihmal edilebilir kaybına karşılık, yüksek hızı ve doğruluğu başarılı bir şekilde elde ettiğini gördük.","Sequential Monte Carlo (SMC) methods are well known and widely used for state estimation in nonlinear/non-Gaussian dynamical systems. However due to the heavy computational requirements, they may not satisfy the real-time constraints in many applications requiring a large number of samples. By means of parallel implementation, real-time tasks such as online filtering can be achieved. However, the resampling stage in SMC methods requires sample interaction, hence it is not trivial to parallelize. In this thesis, we first provide a standard way to parallelize resampling algorithms, and discuss the issues arising from its implementation. We then propose a parallel resampling algorithm, resampling with butterfly communications (RBC), inspired by butterfly resampling previously described in the literature. Our aim is to eliminate the important bottlenecks of the standard approach such as communication overhead and load imbalance by imposing constraints on the communication pattern. We conducted experiments on different parallel computing architectures including computer clusters, and GPUs. We compared the RBC algorithm with the standard approach in terms of execution time and accuracy. We found that the RBC algorithm outperforms the standard approach on computer clusters and GPUs, and successfully achieves high speed and accuracy in exchange for negligible loss of effective sample size."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yutulabilir kablosuz kapsül endoskopi, mide-bağırsak kanalı incelemeleri ve pek çok hastalık ve patolojinin tanısı için kullanılan, gelişmeye açık, tahriş miktarı düşük bir tanılama teknolojisidir. Tıbbi cihaz şirketleri ve pek çok araştırma grubu pasif kapsül endoskopinin daha doğru, hassas ve hastalıklı bölgelerin genişliğini ve yerini sezgisel olarak tespit edebilecek şekilde geliştirmek için önemli ilerlemeler kaydetti. Aktif olarak kontrol edilen, yeni-nesil kapsül endoskopi robotlarının konumlandırılması için güvenilir, gerçek-zamanlı çoklu duyarga ilişkilendirme özelliği hayati önem taşımaktadır. Bu çalışmada, kapsül endoskopi robotunun gerçek-zamanlı konumlandırılması için yinelenen yapay sinir ağları ile modellenen doğrusal olmayan robot kinematiği kullanılarak, değişen gözlem modeli temelli yeni bir, çoklu duyarga ilişkilendirme yaklaşımı önerildi. Sunulan yöntem çoklu duyargalardan, manyetik konumlandırma sistemi ile elde edilen 5 serbestlik-dereceli mutlak poz ölçümü ve görsel odometri yöntemi ile elde edilen 6 serbestlik-dereceli göreceli poz ölçümü, gelen gürültülü verilerden gizli durum vektörü için ardışık olarak kestirim yapılmasıyla ilgilenmektedir. Model üzerinde kestirim yapabilmek için, çevrimiçi kestirim için etkili olan, parçacık filtresi olarak da bilinen ardışıl Monte Carlo yöntemleri kullanılmıştır. Ex-vivo deneyler kullanılarak domuz midesi modelinde yapılan detaylı analizler ve hesaplamalar, sistemin farklı türde kapsül endoskopi robotunun gezingeleri için yüksek ilerleme ve dönme doğruluklarına sahip olduğunu ispatlıyor.","Ingestible wireless capsule endoscopy is an emerging minimally invasive diagnostic technology for inspection of the gastrointestinal (GI) tract and diagnosis of a wide range of diseases and pathologies. Medical device companies and many research groups have recently made substantial progresses in converting passive capsule endoscopes to active capsule robots, enabling more accurate, precise, and intuitive detection of the location and size of the diseased areas. A reliable, real time multi-sensor fusion functionality is crucial for localization of actively controlled next-generation endoscopic capsule robots. In this study, we propose a novel multi-sensor fusion approach based on switching observations model using non-linear kinematics learned by recurrent neural networks for real-time endoscopic capsule robot localization. Our method concerns the sequential estimation of a hidden state vector from noisy pose observations delivered by multiple sensors, a 5 degree-of-freedom (5-DoF) absolute pose measurement by a magnetic localization system and a 6-DoF relative pose measurement by visual odometry. For the inference of the model, Sequential Monte Carlo (SMC) methods known as particle filters are employed, which are effective for on-line inference. In addition, the proposed method is capable of detecting and handling sensor failures by ignoring corrupted data, providing the robustness of a medical device. Detailed analyses and evaluations made using ex-vivo experiments on a porcine stomach model prove that our system achieves high translational and rotational accuracies for different types of endoscopic capsule robot trajectories."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Makine öğrenmesini içeren veri madenciliği yöntemleri iş hayatında yıllardır uygulanmaktadır ve bugün bu yöntemler yükseköğretimdeki eğitimciler ve veri bilimcileri tarafından büyük ilgi görmektedir. Bir öğrencinin üstün başarı ile mezun olma yolunda olup olmadığına dair doğru ve erken tahmin, risk altındaki öğrencilerin uygun şekilde desteklenmesini ve en başarılı öğrencilerin bu yolda kalabilmesini garanti altına almak adına yöneticiler, eğitimciler ve danışmanlar için çok önemlidir. Bu çalışma, 2 yıl veya altındaki akademik veri ile öğrencilerin üstün başarı ile mezun olup olmayacağını doğru bir şekilde tahmin etmek için bazı tahmin modellerinin değerlendirilmesi ve geliştirilmesine yönelik veritabanlarında bir bilgi keşfi yöntemi sunmaktadır. Tahmin modellerinin geliştirilmesinde, öğrencilerin başarısının bazı önemli unsurları ile birlikte öğrenci deneyimi ile ilgili ek anlayışlar tanımlanmaktadır","Data mining methods, including machine learning, have been applied for many years in business contexts and are now receiving a great deal of attention from educators and data scientists in higher education. Accurate, early prediction of whether a student is on track to graduate with distinction is a critical tool for administrators, educators, and advisers to ensure that at risk students are properly supported and students on the path to the highest success are able to stay on track. This study proposes a knowledge discovery in databases approach toward the development and evaluation of several prediction models to accurately predict with two years of academic data or less whether students will graduate with distinction. In developing the prediction models, several important factors of students' success are identified as well as additional insights about student experience."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, dinamik el hareketleri gibi zaman dizilerinin modellenmesi konusunu inceliyoruz. Modelleme problemine otomata ve simgesel dil teorileri kullanarak yaklaşıyor ve el hareketlerinin modellenmesi açısından önemli özelliklerin tanımlanmasını sağlıyoruz. Bu sayede önerilen modellerin başarımları ve yeteneklerini ayrıntılı şekilde inceleyecek bir yaklaşım geliştirmiş oluyoruz. Bu yöntemle varolan modellerin eksikliklerini tanımlıyor ve hangi özelliklere ihtiyaçları olduğunu keşfediyoruz. Özellikle saklı Markov modelleri, girdi-çıktı Markov modelleri, belirli süre modelleri, saklı koşullu rassal alanlar ve saklı yarı Markov modelleri inceliyor ve karşılaştırıyoruz. Bunların sonucunda araştırmamızda ortaya çıkan tüm önşartlara uyan bir saklı yarı Markov model örneği öneriyoruz. Ayrıca sol-sağ yapıdaki bir modelin izole el hareketleri için en uygun model olduğunu gösteriyoruz. Son olarak bütün modelleri karşılaştırıyor ve sonuçlarını belgeliyoruz. Tezin ikinci kısmında rassal karar ormanları kullanarak el şekli ve pozu tanıma problemine yoğunlaşıyoruz. Bilinen bir beden pozu kestirim yöntemini ele uyarlıyoruz, ve aynı yöntemi geliştirerek el şeklini bir defada tanıyan bir yöntem öneriyoruz. Ayrıca çok katmanlı bir uzman karar ormanı ağı kullanarak başarım oranını artıran veya hafıza kullanımını düşüren bir model öneriyor ve karşılaştırıyoruz.","In this thesis, we focus on the problem of modelling sequential data, and particularly hand gestures. We approach the modelling problem using automata theory and theory of formal languages, which allows us to determine the crucial aspects of hand gestures. Furthermore, we show how this approach can help us assess the capabilities of candidate models. The resulting framework can identify problems of models, and set requirements for models to properly represent the gestures. We use this approach to examine common graphical models such as hidden Markov models (HMM), input-output HMMs, explicit duration models, hidden conditional random fields, and hidden semi Markov models (HSMM). We also devise an efficient variant of HSMMs that conforms to all of the requirements set by our previous analysis. We further show that mixtures of left-right models is the most suitable setting for gestures. Finally, we compare all the mentioned models and report the results. In the second part of the thesis, we focus on modelling hand shape with randomized decision forests (RDF). In particular, we extend a known body pose estimation method to hand pose, and then introduce a novel RDF that directly estimates the hand shape. Furthermore, we propose a multi-layered expert network consisting of RDFs that either considerably increases the accuracy, or reduces memory requirements without sacrificing accuracy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde mikroblog platformları bilgi, düşünce, duygu paylaşımı dahil bir çok konuda kullanılmaktadır. Bu platformların içerisinde, 320 milyon kullanıcısı (Nisan 2017) ile Twitter başı çekmektedir. Twitter'ın mikroblog platformları arasındaki bu durumu, onu organize aktivitelerin kullanılması ve bu yollarla kullanıcılara doğru olmayan bilgilerin iletilmesi konusunda cazip kılmakta. Twitter'ın günümüzdeki kullanımına bakıldığında, organize davranışların seçim kampanyaları (Amerika Birleşik Devletleri 2016 Başkanlık Seçimi), doğal afetler (2010 Haiti Depremi), direniş hareketleri (2011 Arap Baharı) gibi bir çok konularda karşımıza çıktığını görmekteyiz. Bunlara ek olarak, son zamanlarda Twitter'da Sahte Haberler yayması için kullanıcıların istihdam edildiklerini, ve otomatik botların kullandıklarını görmekteyiz. Bu durum, sosyal medya kullanıcıları arasındaki güven ilişkisini zedeleyebilmekte, ve toplumun doğru olmayan haberler doğrultusunda manipülatif yönlendirimine olanak vermektedir. Bu bilgiler ışığında, Twitter'daki tweet atma davranışlarını ``organize'' ve ``organik'' olarak iki ayrı kategoride değerlendirilebilmekte. Bu tez, bir tweet kümesindeki davranışların ``organize'' veya ``organik'' olduğunu anlayabilen, otomatik olarak kullanılabilecek bir sınıflandırma modeli sunmaktadır. Yapılan çalışmalarda 200 milyon tweet analiz edilmiştir. İlgili tweet set'lerin hepsi ingilizcedir ve çoğunluğu Amerika Birleşik Devletleri kullanıcıları tarafından atılmıştır. Model'i üretmek için kullanılan eğitim seti her biri 299 parametreden oluşan toplam da 800 kaydın olduğu bir eğitim setinden üretilmiştir. Kullanılan algoritmalar arasında, en iyi sonucu ``Random Forest'' algoritması \%98 f-skoru ve doğrulukla vermiştir.","Microblogging platforms are widely used to share information, feelings, and ideas about anything. With nearly 320 million users (as of April 2017) Twitter is one of the most popular microblogging platforms making it a lucrative platform for propagating (mis)information through organized activities. Such cases have been observed during election campaigns (2016 United States), disasters (2010 Haiti earthquake), and resistance movements (2011 Occupy Wall Street, 2011 Arab Spring). As a result of this, there exists an increased use of social media to recruit people to illegal organizations and to spread fake news. Recruited users utilize various Twitter entities like hashtags, mentions, URLs to organize and coordinate their efforts towards a specific goal. Besides from recruited users, fake accounts and bots are also frequently used in Twitter. In such cases, users can be manipulated, since users assume that tweets are posted with the free will of individuals without intent of collusion. This thesis proposes a supervised classification model for distinguishing tweet sets that are ``organized'' and ``organic''. A prototype implementation of this model is implemented and experiments with a large tweet sets are conducted. During study, numerous features associated with tweets and posting behavior were examined to identify those that are appropriate for training the model. Analyzed tweets were collected by querying hashtags, since hashtags serve to group tweets. The training data set, which has a size of 1000 records with 299 features, is used as a result of analyzing more than 200 million tweets. Among the applied supervised learning algorithms, Random Forest gave the best results in all data sets with f-measure and accuracy of 0.98."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kredi kartı sahtekarlıkları her yıl milyarlarca dolar zarara neden olmaktadır. Bunun doğal bir sonucu olarak finansal kurumlar kredi kartı sahtekarlık tespitine büyük önem vermektedirler. Finansal kurumlar kredi kartı sahtekarlık tespiti için genelde kural bazlı sistemler kullanmaktadırlar. Bu tip sistemlerde tanımlanan kurallar sahtekarlık uzmanlarının geçmiş tecrübelerinden ve sahtekarlık soruşturma sonuçlarından yararlanarak oluşturulur. Kural tanımlama manuel bir süreçtir ve bu durum önemli bir dezavantaj oluşturur. Yapay zeka modellerinde ise manuel bir süreç ihtiyacı bulunmamaktadır. Kredi kartı sahtekarlık tespiti alanında çalışan çok sayıda araştırmacı yapay zeka modellerinin sunduğu bu avantajın farkına varmıştır. Bu tezde, kredi kartı sahtekarlıklarının tespiti için yapay zeka bazlı yeni modeller öneriyoruz. İlk olarak, Kart Kullanıcısı Davranış Modeli'ni (KDM) öneriyoruz. KDM kart kullanıcısının davranış alışkanlıklarını modellemek için kredi kartı işlem tutarlarını kümeleme metodunu kullanır. KDM eğitilirken sadece gerçek işlemler kullanılır. KDM performansını artırmaya yönelik olarak dört odak noktası öneriyoruz. Bu odak noktalarını tek-kart ve çok-kart odak noktası, tatil dönemi harcamaları odak noktası, günün saatleri odak noktası ve enflasyon odak noktası olarak sıralayabiliriz. Önerdiğimiz ikinci model ise Model Topluluğunda İyimser, Kötümser ve Ağırlıklı Oylama Modeli'dir (TİKA). TİKA iyi bilinen altı yapay zeka tekniğinin bir topluluk olarak bir araya getirilmesiyle oluşturulmuştur. TİKA'yı oluşturan yapay zeka modelleri eğitilirken geçmişteki gerçek ve sahte işlemler birlikte kullanılır. TİKA'da iyimser, kötümser ve ağırlıklı oylama stratejilerini sahtekarlık tespit performansını artırmaya yönelik olarak öneriyoruz. Önerdiğimiz üçüncü model ise Harcama Alışkanlıkları Benzerlik Modeli'dir (HAB). HAB'da harcama alışkanlık benzerlik ölçütlerini sahtekarlık tespit performansını artırmak için kullanıyoruz. Türkiye'nin öncü bankalarından birinden aldığımız gerçek kredi kartı işlemlerini içeren veri kümesini kullanarak önerdiğimiz üç modelin performansını değerlendiriyor ve bu modellerin karşılaştırmalı analizini sunuyoruz.","Financial institutions attach great importance to credit card fraud detection, as a natural consequence of the multi-billion dollar annual losses incurred due to credit card fraud. Rule based systems have been commonly used by financial institutions to detect credit card fraud. The rules applied in such systems are formulated based on the experience of fraud experts and the results of fraud investigations. Rule discovery is a manual process, and this fact is an important disadvantage of rule-based systems. Unlike rule-based systems, artificial intelligence models are expected to learn from past transaction data and consequently no manual process is necessary. Many researchers in the domain of credit card fraud detection have recognized this advantage offered by artificial intelligence models. In this thesis, we propose novel artificial intelligence based models for detecting credit card fraud. First, we propose Cardholder Behavior Model (CBM). CBM is an unsupervised model and uses clustering transaction amounts to represent the spending behavior of cardholders. We propose four focal points to fine-tune CBM, which are single-card versus multi-card focus, holiday season spending focus, time of day focus and inflation focus. The second model we propose is called Optimistic, Pessimistic and Weighted Voting in an Ensemble of Models (OPWEM). OPWEM is an ensemble of six well known artificial intelligence techniques, namely Decision Tree, Random Forest, Bayesian Network, Naïve Bayes, Support Vector Machine, and K*. We propose optimistic, pessimistic and weighted voting strategies in OPWEM for better detection of credit card fraud. The third model we propose is called Spending Behavior Similarity Model (SBSM). SBSM uses spending behavior similarity measures in order to improve the performance of supervised models. A dataset of real-life credit card transactions from a leading bank in Turkey has been used to evaluate the performance of three proposed models. Finally, we provide a comparative evaluation of three proposed models."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Karmaşık ağlar son yıllarda biyolojik ve sosyal ağlar gibi çizgelerle modellenen gerçek sistemlerdeki çalışmaların artmasıyla oldukça dikkat çekti. Bu alandaki bir problem de derece dizileri veya kümelenme katsayısı gibi belirli özellikleri sağlayan çizge topluluğundan tipik örneklerin üretilmesidir. Bu tezde, basit ve iki parçalı çizgeler için örnekleme problemi ele alınmıştır. Kenar geçiş adımlarına dayanan doğal bir Markov zinciri yöntemi basit çizgeler için sunulmuştur. Belirli bir derece dizisinin olası gerçekleşimleri üzerine doğrudan tekdüze dağılımdan örneklerin elde edilmesinin zorluklarından dolayı, basit ve iki parçalı çizgeler için önem örnekleme ve sıralı öonem örnekleme tekniklerini kullanan algoritmalar araştırılmıştır. Burada, Blitzstein ve Diaconis ve Chen ve ark. tarafından sunulan algoritmalar üzerinde duruyoruz. İki parçalı çizgeler için Miller ve Harrison tarafından önerilen bir yöntemi basit çizgeler için adapte ederek ve dönüştürerek yeni bir tekdüze örnekleme ve tam sayma algoritması önerilmiştir. Son olarak algoritmaların uygulamaları hipotez testi, ağ analizi ve grafik sayımı gibi çeşitli örneklerde gösterilmiştir.","Complex networks have attracted considerable attention in recent years with the increase in the studies of real systems modeled by graphs such as biological and social networks. One problem in this domain is the generation of typical instances from a collection of graphs admitting certain properties, such as the degree sequence or the clustering coefficient. In this thesis, the sampling problem is addressed for simple and bipartite graphs with a given fixed degree sequence. A natural Markov chain method relying on the edge switching steps is introduced for simple graphs. Due to the difficulties of directly obtaining samples from the uniform distribution over the set of possible realizations of a given degree sequence, algorithms using importance sampling and sequential importance sampling techniques are investigated for simple and bipartite graphs. Here, we focus on algorithms proposed by Blitzstein and Diaconis and Chen et al. A new uniform sampling and exact counting algorithm is proposed for simple graphs by adapting, and transforming the method suggested by Miller and Harrison for bipartite graphs. Lastly, applications of the algorithms are illustrated in several examples such as hypothesis testing, network analysis and graph enumeration."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüksek hacimli dizileme (YHD) teknolojileri büyük ölçüde veriyi düşük maliyete üretiyor, bu durum büyük miktardaki DNA dizisi verisini analiz etmek için algoritma geliştirme araştırmasını hızlandırdı. Bu tezde, genomiks alanında üç bağlantılı probleme yeni çözümler getiriyoruz. İlk olarak, her ne kadar YHD'ye dayalı analizlerin doğruluğu ve tekrarlanabilirliği üzerinde önemli gelişmeler kaydedilse de YHD platformlarının dayanıklılık açısından kullanılabilirliği hala açık soru. Yaygın bir YHD platformunun klinik uygulamalarda kullanılabilirliğini dayanıklılık açısından incelemek için iki bireyin genomlarının tüm genom dizileme verisini iki ayrı merkezde diziledik. YHD platformları ilk-aşama klinik tesler için veri sağlamada çok güçlüler ancak varyant tahminlerinin klinik uygulamalarda kullanılmadan önce ortogonal yöntemlerle doğrulanması gerektiği sonucunu gözlemledik. İkinci olarak genom birleştirme problemi için hala yaratıcı çözümlere ihtiyacımız var. Çok kısa DNA dizilerini -idealde- tüm kromozom dizilerine birleştirmek şu sebeplerden karmaşık bir iş (i) genomların tekrarlı ve kopyalı yapısı (ii) YHD'nin ürettiği verinin kısa ve hatalı olması. Birleştirme doğruluğunu artırmak için üç farklı teknolojiden (Illumina, Ion-Torrent, Roche-454) veri dahil eden yeni bir metod sunuyoruz. Son olarak, ortalama dizi parçacığından uzun yeni dizi insersiyonlarının tanımlanması hala zorlu bir iş. Özellikle yeni dizi insersiyon bulma için geliştirilmiş ve yeniden tüm genom birleştirmesini es geçebilecek az sayıda algoritma var. Tek veya çok genom dizisi verisetlerinde verimli ve doğru bir şekilde yeni dizi insersiyonlarını bulan ve genotipleme yapan yeni bir algoritma Pamir'i sunuyoruz.","High throughput sequencing (HTS) technologies generate huge amount of data with very low cost, which prompted research on algorithm development to analyze large DNA sequence datasets. In this thesis, we propose new solutions to three related problems in genomics field. Firstly, although the accuracy and reproducibility of HTS based analyses is highly improved, the usability of these platforms in terms of robustness is still an open question. We produced whole genome shotgun (WGS) sequence data from the genomes of two individuals in two different centers to assess the usability of a widely used HTS platform in terms of robustness in clinical applications. We observe that HTS platforms are powerful enough for providing data for first-pass clinical tests, but before using in clinical applications, the variant predictions need to be confirmed by orthogonal methods. Secondly, we still need innovative methods for the de novo genome assembly problem. The task of assembling very short DNA sequence reads into -ideally- complete chromosome sequences is further complicated due to (i) the repetitive and duplicated structure of genomes, and (ii) the fact that the data produced by the HTS technologies tend to be short and error prone. We present a new method to increase the assembly accuracy by integrating data from Illumina, Ion-Torrent and Roche-454 platforms. Lastly, characterization of novel sequence insertions longer than the average read length remains a challenging task. There are only a few algorithms that are specifically developed for novel sequence insertion discovery that can bypass the need for the whole genome de novo assembly. We present a new algorithm, Pamir, to efficiently and accurately discover and genotype novel sequence insertions using either single or multiple genome sequencing datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Negatif olmayan matrisler, veri örneklerinin negatif olmayan sınırlı değerler aldığı kalem önerme ve ses sinyali işleme gibi birçok alanda karşımıza ̧çıkmaktadır. Olasılıksal yaklaşımlar bu alanlardaki birçok görev için kullanılmakta ve matris ayrıştırma modelleri bu alandaki en ileri metodlar arasında yer almaktadır. Bunlardan biri Poisson Ayrıştırma adında gözlemleri Poission dağlımıyla modelleyen bir saklı değişken modelidir. Ancak bu şekilde, değer aralığı sınırlı olan gözlemlere, Poisson dağılımıyla sınırlı olmayan değer aralığı verilmektedir. Bu çalışmada, Poisson Ayrıştırma genişletilmiş ve gözlemler Bernoulli, İkiterimli, Kategorik ve Çok terimli gibi sınırlı değer aralığına sahip dağılımlarla modellenmiştir. Ortaya çıkan model, birçok Poisson Ayrıştırmanın, kendilerinin toplamlarına koşullandırılmasıyla oluşturulduğundan Toplama Koşullu Poisson Ayrıştırması olarak adlandırılmıştır. Toplama Koşullu Poisson Ayrıştırması modelinde çıkarım için iki algoritma sunuyoruz: Gibbs örnekleyicisi ve Beklenti-Enbüyütme. Algoritmalar ve model, benzeştirilmiş ve gerçek veri kümeleriyle test edilmiştir. İlk olarak, üretici modellen elde edilen sentetik veriyle, iki algoritmayı kıyaslıyoruz. Daha sonra, Swimmer adında bir veri kümesinde modelin yorumlanabilirliğini gösteriyoruz. Modelin sıralama ölçekli puanlama verisindeki performansı ölçmek içinse MovieLens 500-K adında kullanıcı film puan veri setini kullanıyoruz. Sonuçclar önerilen modelin, mevcut diğer modellerden test puanlarını tahmin etmede ve üst-K önermede daha üstün olduğunu gösteriyor. Son olarak, modelin zaman serisindeki kullanımını araştırmak için Bach Korallerinden çıkarılan piyano rulo verisiyle deney yapıyoruz. Burada, modelin zaman serisi analizinde önsel dağılımlar için kullanılabilecek parametreler sağladığını göstermekteyiz.","Non-negative matrices appear in many domains from item recommendation, audio signal processing to computer vision in which data instances have a bounded non-negative range. For various tasks in these areas, probabilistic approaches have been widely applied where matrix factorizations are among the state-of-the-art meth- ods. A particular one is a latent variable model called Poisson Factorization which models bounded data with Poisson distribution assigning them unbounded ranges. In this work, we extend Poisson Factorization to model bounded data with bounded distributions such as Bernoulli, Binomial, Categorical and Multinomial. The resulting model is named as Sum Conditioned Poisson Factorization as the model is constructed by conditioning multiple Poisson Factorizations on their sum. We present two algorithms for inference in Sum Conditioned Poisson Factorization: Gibbs sampler and Expectation-Maximization. The algorithms and the model are tested with simulated and real data sets. First, we compare the algorithms with data generated from the model synthetically. Then, we demonstrate the interpretability of the model on a binary valued data set named Swimmer. In order to measure the performance of the model on ordinal rating data, we use MovieLens 500-K. The results indicate that the proposed model outperforms Poisson Factorization and other models in terms of predictive performance for test ratings and top-K recommendation. Finally, we conduct experiments on piano roll data extracted from Bach Chorales for investigating the use of the model in time series. The experiments reveal that the model provides parameters that can be used for prior distribution in time series analysis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal ağlarda kullanıcılar kişisel bilgilerini paylaşmaktan çekinmezler. Bunun karşılığında ise, mahremiyetlerinin korunmasını beklerler. Sosyal ağlarda mahremiyet ihlalleri, sosyal ağın yanlış çalışmasından ziyade kullanıcı hareketlerinden kaynaklı oluşur. Kullanıcılar kendileri ve başka kullanıcılar hakkında içerik paylaşabilirler. Birçok kullanıcı içerikleri dağıtmaya başlayınca, içerikler istenmeyen kişiler tarafından görülebilir. Hatta çıkarım yolu ile var olan bilginin ötesinde yeni bilgiler de açığa çıkabilir. Bu tezde öncelikle sosyal ağlarda karşımıza çıkabilecek mahremiyet ihlallerini tanımlıyoruz, ve bunun için bilginin anlamsal olarak ifade edilmesi gerektiğini gösteriyoruz. Önerdiğimiz yöntemde, sosyal ağ sistemi etmen tabanlı bir sistem olarak ele alınıyor. Etmenler kullanıcıların mahremiyet gereksinimlerini bilerek sistem ile taahhütler yapıyor. Taahhütlerin yerine getirilmemesi ise mahremiyetin ihlal edildiği anlamına geliyor. Önerdiğimiz bir algoritma sayesinde, farklı sosyal ağ derinliklerinde mahremiyet ihlallerini tespit ediyoruz. Başka bir doğrultuda, önerdiğimiz mahremiyet modelleri sayesinde, etmenler müzakere yöntemlerini kullanarak mahremiyet ihlalleri yaşanmayacak şekilde içerik paylaşabiliyor. Diğer bir deyişle, etmenler içeriği paylaşmadan önce iletişime geçerek, mahremiyeti koruyan ortak bir içerik üzerinde anlaşıyorlar. Önerdiğimiz bir yöntemde, etmenler kullanıcıların mahremiyetini karşılıklı olarak korumaya çalışıyorlar. Bunu yaparken, mahremiyet kurallarını ve fayda fonksiyonlarını gözetiyorlar. Önerdiğimiz diğer yöntemde ise, etmenler ontolojilerini kullanarak mahremiyetlerini korumak üzere argümanlar üretiyor, ve tartışma sonucunda içeriğin paylaşılıp paylaşılmayacağına karar veriyorlar. Önerilen yöntemde, etmenler Varsayım-tabanlı Muhakeme sistemini kullanıyorlar. Tüm bu modelleri uygulama olarak sunuyor, ve gerçek hayat senaryoları kullanarak değerlendiriyoruz.","People are willing to share their personal information in social networks. The users are allowed to create and share content about themselves and others. When multiple entities start distributing content without a control, information can reach unintended individuals and inference can reveal more information about the user. This thesis first categorizes the privacy violations that take place in online social networks. Our proposed approach is based on agent-based representation of a social network, where the agents manage users' privacy requirements by creating commitments with the system. The privacy context, including the relations among users or content types are captured using description logic. We propose a sound and complete algorithm to detect privacy violations on varying depths of social networks. We implement the proposed model and evaluate our approach using real-life social networks. A content that is shared by one user can very well violate the privacy of other users. To remedy this, ideally, all the users that are related to a content should get a say in how the content should be shared. To enable this, we model users of the social networks as agents that represent their users' privacy constraints as semantic rules. In one line, we propose a reciprocity-based negotiation for reaching privacy agreements among users and introduce a negotiation architecture that combines semantic privacy rules with utility functions. In a second line, we propose a privacy framework where agents use Assumption-based Argumentation to discuss with each other on propositions that enable their privacy rules by generating facts and assumptions from their ontology."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez araç konumlandırmayı harita ve araçlar arası haberleşme kullanarak geliştirmeyi hedeflemektedir. Global uydu navigasyon sistemi(GNSS) alıcısı, odometre ve sayısal haritaların parçacık filtresi temelli bir algoritma ile birleştirilmesi önerilmiş ve uygulanmıştır. Algoritmanın değişik uydu görünebilirlik durumlarındaki davranışını test etmek için İstanbul'un değişik noktalarında saha testleri gerçekleştirilmiştir. Sonuçlar algoritmanın %96 başarı ile harita üzerinde doğru yol parçasını seçebildiğini göstermektedir. Önerilen algoritma araçlar arası haberleşme ağları(VANET) üzerinde karşılıklı konumlama eklentisi ile daha da geliştirilmiştir. Göreceli mesafenin varış zamanının ölçümü temelli istatiksel bir fonksiyonu deneysel olarak elde edilmiştir. Karşılıklı konumlandırma prosedürü konumlama hassasiyeti ve ağ performansı açısından değişik sayıda işbirlikçi araç içeren gerçekçi simülasyon çalışmaları ile incelenmiş ve IEEE 802.11p radyo modemle donatılmış beş araçlık bir filo ile deneysel olarak değerlendirilmiştir. VANET'lerde iş birliğinin konum ölçümünün yararlanırlığını geliştirdiği gibi tekil bir GNSS alıcısına göre %40 oranında hassasiyetini de artırdığı ispat edilmiştir. Yerel bütünlük sıcaklık haritası kavramı yeni bir yerel bütünlük metodu olarak önerilmiştir. Algoritma şehir kanyonlarının tespit edilmesinde ve GNSS'e bir destek olarak başarılıdır. Sayısal haritalar ve araçlar arası haberleşme kullanan füzyon yapımızın ileri sürücü destek sistemleri uygulamalarında verimli olarak kullanılabileceği ve yerel bütünlük metodumuz ile füzyonun ve konumlandırmanın daha da geliştirilebileceği sonucuna varılmıştır.","This thesis aims to enhance vehicle localization through the fusion of digital maps and vehicular communication. A particle filter based algorithm for fusing global navigation satellite system (GNSS) receiver, odometer, and digital maps is proposed and implemented. Implementation deployed on an embedded system and tested in the field. Field tests were carried out different in parts of \.Istanbul to measure the performance of the algorithm in different satellite visibility conditions. Results show that algorithm selects the correct road segment on the digital map with 96% success rate. The proposed algorithm was further enhanced with the addition of mutual positioning on vehicular ad-hoc networks (VANETs). The measurement-based statistical model of relative distance as a function of Time-of-Arrival(TOA) is experimentally obtained. The mutual positioning procedure is investigated in terms of positioning accuracy and network performance through realistic simulation studies with a different number of collaborative vehicles, and the proposed mutual positioning procedure is experimentally evaluated by a fleet of five IEEE 802.11p radio modem equipped vehicles. It is shown that collaboration in a VANET improves the availability of position measurement and its accuracy up to 40% in comparison with the stand-alone GNSS receiver. Local integrity heat map concept is introduced as a new local integrity methodology. Local integrity heat map is implemented and tested with extensive field tests. Algorithm is successful in detecting urban canyons and can be used as an augmentation for GNSS. It is concluded that our fusion framework with the use of digital maps and inter-vehicle communications can be efficiently used for ADAS applications and our local integrity method can further enhance fusion and localization"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Robotların ev içlerine girmesiyle, robot – insan ilişkileri eskisine göre daha önemli bir araştırma alanı oldu. Bu yüzden insanlara evlerinde eşlik edecek bir robot yapma kararı aldık. Bunu gerçekleştirmek için 4 farklı sorun ile uğraşıldı: çeşitli robot kafaları-nın oluşturulması, robotların ses üretilmesinin sağlanması, robotun konuşurken dudak pozisyonlarını konuşma ile uyumlu olarak hareket ettirebilmesi ve robotlara söylenen cümlelerdeki kelimeler arasında ilişki kurabilmesi. Bu sorunların ilki 3 farklı robot kafasının yapılması ile çözüldü. İkinci sorunu çözmek için Biçimleyici Konuşma Sentezleme yöntemi kullanıldı. Üçüncü problemin çözünde ise her bir harf grubu için özel dudak pozisyonları tanımlandı ve konuşma sırasında bu dudak hareketleri sırasıyla robotlar tarafından yapıldı. Sonuncu problem de ise Türkçe için kök bulma, ek belirleme, ilişki bulma araçları geliştirildi. Söylenen cümleler kalıplara sokuldu ve kalıplardan robotun bilgi çıkarabilmesi yapıldı. En sonunda insanlar ile robotun birlikte oyun oynaması sağlanıp, sistemin ne kadar iyi çalıştığı değerlendirildi.","With the introduction of robots to the domestic environments, robot - human relations have become a more important research area. That is why we decided to make a robot to accompany people in their homes. We were dealing with four different problems to accomplish this: creation of various robot heads, providing the robot the ability to produce speech sound, the ability to move lip positions in accordance with speech when the robot is talking and establishing a relationship between the words in the sentences which are spoken to the robots. The first of these problems was solved by the construction of three different robot heads. To solve the second problem, the Formant Speech Synthesis method was used. In the solution of the third problem, special lip positions were defined for each group of letters and during the speech these lip movements were made by robots respectively. In the last problem, root finding, annotation and relation finding tools were developed for Turkish. By the extraction of information from what was said by the robot by finding the suitability of the phrases. The mentioned statements were inserted into the patterns and the robot was able to extract information from these patterns. In the end, people and the robot were able to play together and the system was evaluated for how well it worked."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dağıtık sistemlerde dinamik grup anahtarı anlaşma protokollerinin nedeni dinamik katılımcı kümesinin grup anahtarını güvenli bir şekilde hesaplamasını sağlamaktır. Dinamik grup anahtarı anlaşma protokollerinin konferans iletişimi, dosya paylaşım sistemleri ve mobil tasarsız ağlarda kullanılması beklenir. Dinamik grup anahtarı anlaşma protokollerinde katılımcıların sayısı, katılımcıların gruba katılmaları ve ayrılmaları yüzünden zamanla değişe-bilir. Gruba katılma ve ayrılma işlemlerinin güvenliği sırasıyla geriye doğru gizlilik ve ileriye doğru gizlilik özellikleri ile sağlanabilir. Halihazırda var olan grup anahtarı oluşturma protokollerinin kullanımında problemlerin listesi şu şekildedir: (i) konferans iletişimde yetersiz hata tespiti, (ii) dosya paylaşım sistemlerinde mahremiyetin sağlanamaması, kullanılabilirliğin ihlali, katılımcıların erişim haklarının yetersiz bir yöntem ile iptal edilmesi, güvenilir üçüncü şahıslara bağımlılık ve (iii) mobil tasarsız ağlarda güvenli olmayan küme başı seçimi. Bu tezde, ilk olarak hata tespiti ve düzeltilmesinde daha iyi performans sağlayan dinamik grup yetenekleri ile iyileştirilmiş Dinamik Konferans Anahtarı Anlaşma Protokolünü öneriyoruz. Daha sonra ise önerilen protokolün etkili erişim haklarının iptal olmasını sağlayan Üç-Aşamalı Güvenli Dosya Paylaşım sistemini öneriyoruz. İkinci olarak, Kısmi Geriye Doğru Gizlilik yöntemini sağlayan Anahtar Anlaşma Protokolünü öneriyoruz. Kısmi Geriye Doğru Gizlilik özelliği, yeni katılımcıya gruba dahil olmadan bir önceki grup anahtarının hesaplanmasını sağlayan yeni bir güvenlik özelliğidir. Önerilen özellik ile bağlantılı olarak, özel Dosya Paylaşım Sistemini öneriyoruz. Üçüncü olarak, Mobil Tasarsız Ağlar için Grup Anahtarı Anlaşma Protokolünü öneriyoruz. Bu protokolde, Mobil tasarsız ağlarda yeni ve güvenli küme başı seçimini konseptini öneriyoruz.","The essence of dynamic group key agreement protocols is to help compute a secure key for a group communication with a dynamic set of participants in distributed systems. Dynamic group key agreement protocols are expected to be used in applications such as conference communications, file sharing systems and mobile ad hoc networks. In dynamic group key agreement protocols, the number of participants may vary in time because of participants are joining or leaving a group. The security of such operations is affected by the existence of backward confidentiality and forward confidentiality, respectively. There are a number of problems related to the use of existing dynamic group key agreement protocols: (i) inefficient fault detection in conference communications, (ii) lack of privacy, violation of availability, inefficient participant revocation, dependency for key escrow in file sharing systems and (iii) insecure cluster head selection in mobile ad hoc networks. In this thesis, we first introduce an improved Dynamic Conference Key Agreement Protocol with dynamic group capabilities to provide better performance in fault detection and correction. Then, we show the application of the proposed protocol on Three-Tier Secure File Sharing System with efficient participant revocation. Second, we propose another Key Agreement Protocol with Partial Backward Confidentiality. The partial backward confidentiality property is a novel security property that allows a new participant to compute the last valid group key just before joining the group. In relation to this protocol, we propose a Private File Sharing System. Third, we propose a Group Key Agreement Protocol for Mobile Ad hoc Networks. In this protocol, we introduce the new concept of secure cluster head selection."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Konuşma geri getirimi, yalnızca ilgilenilen konuşma parçalarının bulunması için değil aynı zamanda daha iyi otomatik konuşma tanıma (OKT) sistemlerinin kurulabilmesine yönelik, otomatikleştirilmiş ve kolaylaştırılmış bir konuşma madenciliği için, önemli bir problemdir. Bilhassa, anahtar sözcük arama (ASA) sistemleri, bir kullanıcının sağladığı anahtar sözcüğün telaffuz edildiği belirli kısımları bulmak suretiyle bu hedefleri gerçekleştirmeyi amaçlamaktadır. Anahtar sözcük arama için en akla yatan ve en çok kullanılan yöntem, OKT sistemleri kullanarak konuşmadan metin yazıları elde etmek ve bu OKT çıktısında metin tabanlı arama yapmaktır. Öte yandan, mevcut etiketli konuşma eğitim verilerinin yetersiz olduğu kısıtlı kaynaklı diller için güvenilir OKT sistemleri oluşturulamayacak ve kendilerine bağımlı ASA sistemleri başarısız olacaktır. Ayrıca, ilgilenilen anahtar sözcük OKT sisteminin dağarcığında yer almıyorsa, kelime düzeyi OKT çıktılarında bulunması imkansız olacaktır. Bu tezde, kısıtlı kaynaklı diller için ASA'nın yukarıda bahsedilen problemlerini ele alacağız. Tamamen farklı bir yaklaşımla, örnek ile sorgu problemlerinin benzerlik arama tekniklerinden esinlenen fikirlerle bir ASA sistemi kurmayı hedefledik. Bunun için, metin sorguları için yapay olarak ``sahte örnekler'' oluşturduktan sonra, bir alt-dizi dinamik zaman bükme araması kullanıyoruz. Ayrıca, dinamik zaman bükmede kullanılmak üzere, bu sorgu gösterimleri ile uygun bir mesafe metriğini bütünleşik ularak öğrenilmesini inceliyoruz. Önerdiğimiz bu yeni ASA sisteminin, dağarcık dışı terimlerin bulunmasında, mevcut en iyi ASA tekniklerinden daha iyi performans gösterdiğini, ve farklı yapısı nedeniyle geleneksel OKT tabanlı ASA sistemleri ile birlstirildiğinde ciddi iyileştirmeler sağladığını gördük.","Retrieval of spoken content is one key endeavor, not only for nding the speech parts of interest, but also for an automated and facilitated speech mining towards better automatic speech recognition (ASR) systems. In particular, keyword search (KWS) systems aims to address these goals, by locating the speci c parts of speech where a user provided keyword uttered. The most intuitive and convenient method for keyword search is to obtain text transcriptions from speech using ASR systems, and then conduct text based search on this ASR output. However, for low resource languages, for which available labeled speech training data is not sucient, reliable ASR systems cannot be built and, KWS systems that depend on them will fail. Furthermore, if the keyword of interest is not within the vocabulary of the ASR system, it can never be found in the word level transcriptions. In this thesis, we address the above mentioned issues of KWS for the low resource languages. We aim to build a KWS system, using a completely di erent approach, with ideas inspired by the similarity search techniques of the query by example retrieval tasks. For this, we utilize a subsequence dynamic time warping-based search, after arti cially modeling \pseudo examples"" for text queries. Furthermore, we investigate a joint learning of these query representations and a proper distance metric for use in dynamic time warping. We show that, this new KWS system, we propose, outperforms the state of the art KWS techniques for retrieval of out-of-vocabulary terms, and provides signi cant improvements when combined with the conventional ASR-based KWS system due to its heterogeneity."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Modern mimariler gelişen teknoloji ile geçici hatalara karşı daha savunmasız hale gelmiştir. Bir sistemdeki tüm önbellek yapılarını seçici olmaksızın korumak, performans ve enerji tüketimi açısından önemli bir ek yük getirir. Bu tez kapsamında performans ve güç tüketimi kısıtları altında asimetrik olarak güvenilir önbelleklere sahip çok çekirdekli bir sistem kullanılarak, yalnızca güvenilirlik açısından kritik olan kod parçalarını koruyan bir mekanizma önerilmiştir. Önerilen sistemimiz L1 önbellek yapılarında ECC korumasına sahip en az bir yüksek güvenilirlikli çekirdek ve önbellek yapılarında koruma bulunmayan birden fazla düşük güvenilirlikli çekirdeklerden oluşmaktadır. Bu tez kapsamında, güvenilirlik temelli kritik kod bölümleri, kritik veri kullanımı, kullanıcı ek açıklamaları ve statik analiz temel alınarak farklı yöntemlerle belirlenmiştir. İlk yaklaşımımızda, kritik kod bölümlerini çalıştıran uygulama iş parçacıkları First Come First Served (FCFS) tabanlı bir çizelgeleme algoritması ile dinamik olarak korunan çekirdeğe eşlenmiştir. Yapılan deneysel çalışma sonucunda, önerilen yaklaşımımız bir dizi uygulama için tamamen güvenilir sisteme yakın güvenilirlik ve performans sonuçları ile daha düşük güç tüketimi ve maliyet değerleri sunmuştur. Bununla birlikte FCFS tabanlı çizelgeleme algoritması bazı iş yükleri için düşük sistem performansı ve eşitlik sonuçlarına sahiptir. Bu tez kapsamında, sistem performansı ve eşitlik perspektiflerini iyileştirmek için, uygulamalar hakkında ön bilgi gerektiren önceliğe dayalı çizelgeleme teknikleri ve korunan çekirdek(ler) üzerindeki harcanan toplam süreyi eşitlemeyi {hedef-leyen} dinamik çizelgeleme teknikleri sunulmuştur. Yapılan deneysel değerlendirme sonucunda, önerilen çizelgeleme tekniklerinin FCFS algoritmasına kıyasla sistem performansını ve eşitlik sonuçlarını önemli ölçüde iyileştirdiği gözlemlenmiştir.","Modern architectures are vulnerable to soft errors due to shrinking transistor sizes and high frequencies. Protecting all system elements unselectively has notable overhead on performance and energy consumption. In this thesis, we propose an enhanced protection mechanism to supply reliability need of the system using sufficient additional hardware under the performance, power and cost constraints. In our reliability optimization framework, we utilize a heterogeneous chip multiprocessor with multiple cores which have identical micro-architecture but different protection levels on their individual cache structures. Instead of protecting all code regions, Reliability-based Critical Sections are determined which indicates the code portions that need to be protected for each application. These code portions are determined based on critical data usage, user annotations, or static analysis, each of which identifies critical code fragments differently throughout this thesis. Software threads which execute reliability-based critical sections are mapped onto the protected core(s), whereas the threads which execute non-critical regions are mapped to the unprotected ones, dynamically during the execution. Therefore, the dynamic allocation of application threads and an efficient scheduling method are required in our framework. We started with a primitive scheduler based on First Come First Served (FCFS) policy. Additionally, we propose and evaluate various scheduling algorithms with different characteristics for mapping the application threads on the protected cores. Our experimental evaluation shows that our proposed approach takes advantage of protecting only critical code regions and presents comparable performance and reliability results with fully protected systems with lower power consumption and cost values for a set of applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, zaman serilerindeki ani değişimlerin tespiti için kullanılabilecek bir Bayesçi değişim noktası modelini sunuyoruz. Bu model, değişim noktalarını ve veri dinamiğini saklı değişkenler olarak temsil eden bir çok katmanlı saklı Markov modelidir. Çalışmamızda genel bir üreteç modeli, çıkarım yapmak için kullanılan ileri-geri yönlü algoritmayı ve parametre kestirimi için beklenti enyükseltme algoritmasını anlatıyoruz. Modelin incelediğimiz dört özel hali, gözlemlenen sistemin durumunda ve özniteliklerin yoğunluk ve/veya oranında meydana gelen değişiklikleri tespit edebilmektedir. Modelin genel halinin incelemesinin yanı sıra, özel hallerinden birinin -Dirichlet-Multinomial modeli- çözümlemesini yapıp nasıl gerçekleştirilmesi gerektiğini açıklıyoruz. Modelin özgün bir uygulaması olarak Oturum Başlatma Protokolü~(SIP) ağlarında Dağıtık Hizmet Engelleme~(DDoS) saldırısı tespiti problemini inceledik. DDoS saldırı verisi üretmek için bir ağ izleme ünitesi ve belirli sayıda kullanıcı arasında gerçek zamanlı SIP aramaları üreten bir olasılıksal SIP ağı benzetim sistemi geliştirdik. Saldırılan bilgisayarın ağ bağlantısından ve kaynak kullanım istatistiklerinden çıkardığımız bir veri kümesi üzerinde yaptığımız deneylerde farklı niteliklere sahip birçok DDoS saldısını gerçek zamanlı olarak, yüksek doğruluk ve düşük yanlış kabul hatası oranlarıyla tespit edebildiğimizi gözlemledik.","In this work, we present a Bayesian change point model that identifies the time points at which a time series undergoes abrupt changes. Our model is a hierarchical hidden Markov model that treats the change points and the dynamics of the data stream as latent variables. We describe a generic generative model, forward-backward recursions for exact inference and an expectation-maximization algorithm for hyperparameter learning. The model specifications discussed here can sense the changes in the state of the observed system as well as in the intensity and/or the ratio of the features. In addition to investigating the change point algorithm in generic notation, we also give an in-depth analysis and appropriate implementation of a particular model specification, namely, Dirichlet-Multinomial model. We present a novel application of the model: Distributed Denial of Service~(DDoS) attack detection in Session Initiation Protocol~(SIP) networks. In order to generate DDoS attack data, we build a network monitoring unit and a probabilistic SIP network simulation tool that initiates real-time SIP calls between a number of agents. Using a set of features extracted from target computer's network connection and resource usage statistics, we show that our model is able to detect a variety of DDoS attacks in real time with high accuracy and low false-positive rates."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İçinde bulunduğumuz yeni çağda, bilgi miktarı çok hızlı artmakta ve bilgiye ulaşım gittikçe kolaylaşmaktadır. Bugün artık, bilgi kaynakları kısıtlı olmaktan çıkmış ve en kısıtlı kaynak bilgiye harcanacak olan zaman ve dikkat haline gelmiştir. Biz de bu kapsamda, kısıtlı dikkate sahip etmenlerin yoğun bilgiye maruz kaldığı bir takım karmaşık sosyal simülasyonlar tasarladık. Yapay market, ekonomi ve oyunlardaki sosyal ve evrimsel rekabeti incelemek için  ana yöntem olarak, etmen-temelli benzetim kullandık. Amacımız sınırlı mantıksal çıkarım yeteneklerine sahip yapay etmenler arasındaki işbirliği ve rekabet dinamiklerini incelemektir. (i) İlk olarak basit bir kültürel market modeliyle, bireylerin hafızasından yer kapmak için birbiriyle yarış halinde olan kültürel ürünlerin dinamiklerini inceledik. Reklam ve tavsiye dinamiklerini karşılaştırdık. Reklam edilen ürünün bilinirliliğinin (şöhretinin) markete daha fazla sayıda standart ürün koyularak da arttırılabileceğini gözlemledik. (ii) İkinci çalışmamızda, tutsak ikilemi oyunu özelinde dikkat kıtlığının, oyunların çıktısını nasıl etkileyebileceğini inceledik. Dikkatin kısıtlı olduğu durumlarda, en iyi stratejinin, dikkatin işbirliğinden kaçan ve tehlike arz eden, bencil bireylere yöneltilmesi gerektiği ortaya çıktı. (iii) Üçüncü çalışmamızda, bencil bireyler arasında işbirliğinin nasıl ortaya çıkabileceğini, evrimsel açıdan inceledik.  Bencil bireylerle etkileşim negatif skor getirmediği sürece,  bir sonraki nesillerin hafızalarından sıyrıldığını,  ve koruyucu bir hafıza kalmadığında toplumun bencil bireylerce işgal edildiğini gözlemledik. Tutsak İkilemi oyunundaki skor matrisini, bencil bireylerle etkileşimin negatif skor getireceği şekilde yeniden düzenledik.  Belli bir dozdaki tehdidin işbirliğini arttırdığını gözlemledik. Evrimsel açıdan bakıldığında,  hafızanın bencilliğe karşı bir bağışıklık kalkanı gibi çalıştığını gördük.  Bu durum, evrim neticesinde, zuhur eden bir özellik olarak ortaya çıkmıştır.","the scarcest resource of today is not information but rather attention. We design several complex adaptive social systems in which agents with limited attention capacity confront a wealth of information. We take rather an exploratory approach and use primarily agent-based models to study the dynamics of competitive endeavours, such as artificial markets and games. Our purpose is to study the dynamics of cooperation and competition among boundedly rational artificial agents. (i) First we built a simple model in which cultural items compete for the limited attention of agents and we investigate the impact of advertisement pressure. We observe that the market share of the advertised item improves as a result of an increase in the standard items. (ii) Secondly, we work on attention games in a specific context of Iterated Prisoners Dilemma. We find out it is best for agents to pay attention to defectors in order to achieve a higher social welfare. Hence, cooperators becomes more prudent to the defective moves. (iii) Thirdly, we investigate the evolution of cooperation. This time agents are ""hard-wired"" to pay attention to defectors. Agents have limited memory size and refuse to play with defectors. As opposed to what we expect, we observe that subsequent generations loose their memory and are ultimately invaded by defectors, when playing with a defector brings non-negative payoffs. We reformulate the payoff matrix structure to incorporate negative payoffs and show how threat (of receiving negative payoffs) fosters greater memory size and cooperation. We also observe how memory acts like an immune response of the subsequent generations against aggressive defection. This functionality of self-immunization has emerged as a result of the co-evolutionary process."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Link tahmini, sosyal ağ analizinde temel bir problemdir. Halihazırda aralarında bağlantı olmayan nodların gelecekte aralarında bağlantı kurma tahminini yapmak bir sınıflandırma problemidir. Bu problemin çözümü için bu çalışmada eğiticili öğrenme algoritmaları ve eğiticisiz bir metot kullanılmıştır. Bulanık mantığın link tahminindeki sonuçlarını da görebilmek için eğiticili öğrenme algoritmalarından biri olarak bulanık mantık temelli bir algoritma kullanılmıştır. Iki farklı ağ kullanılmıştır: bunlar, bilgisayar bilimleri yazarlarından oluşan ve göz hastalıkları yazarlarından oluşan ağlardır. Bu ağlar ayrıca kendi içlerinde ağırlıklı ve ağırlıksız olarak kullanılmıştır. Bir ağda ağırlık, iki nod arasındaki ilişkinin gücünü gösterir. Deney sonuçları göstermiştir ki ağırlıklı ağlarla elde edilen sonuçlar, ağırlıksız olarak kullanılan ağlarla elde edilen sonuçlardan daha iyi çıkmıştır. Link tahmini, şuan aralarında bağlantı olmayan iki nod için, gelecekteki yeni bağlantıyı tahmin etme görevidir. Eğiticili öğrenme algoritmaları ile yapılan link tahmini deneylerinde, nodların metrik değerleri input olarak kullanılmış, bu nodların gelecekte aralarındaki link varlığı ise sınıf etiketi olarak kullanılmıştır. Eğer aralarında link varsa sınıf etiketi 1 olarak, eğer link yoksa sınıf etiketi 0 olarak atanmıştır. Eğiticisiz metotta ise her bir nod çifti için metric değerleri en yüksekten en düşüğe kadar sıralandırılmıştır. Deney sonuçları göstermiştirki eğiticili öğrenme algoritmaları ile elde edilen performans, eğiticisiz metot ile elde edilen performansdan daha iyi çıkmıştır. Eğiticili öğrenme algoritmaları ile yapılan deneylerin sonuçlarında ise olasılık teoremini ve karar ağacını kullanan algoritmalar, bulanık mantık kullanan algoritmadan daha iyi sonuç vermiştir.","Link Prediction is a fundamental problem in the social networks analysis. In order to solve this problem supervised learning algorithms, which include one fuzzy rule based algorithm were applied in this study. Besides supervised learning algorithms, an unsupervised strategy is also applied to compare the supervised and unsupervised results. Two different networks are chosen for the experiments: a computer science co-authorship network and an eye disease co-authorship network. Those networks were used in both weighted and unweighted versions in the experiments. In a network, a weight refers the strength of a relationship between nodes. Our Experiments' results proved that weighted networks had better results in comparison to unweighted networks. In the link prediction, the task is to predict the new connections in future for unconnected pair of nodes in present. In the link prediction process with supervised algorithms, metric values were employed as predictor attributes and existence of links was used as class labels. On the other hand, in link prediction process with the unsupervised strategy, a ranking method was employed. In the light of the experiments, it was seen that supervised algorithms had better performance than the unsupervised strategy. Furthermore, among the supervised algorithms, a decision tree and a probabilistic algorithm provided the best performances in comparison with fuzzy rule based algorithm."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan ve toplumun sağlık ve huzurunda elzem bir rol oynayan uyku, gözlemlenmesi gereken önemli bir aktivitedir. Uyku süresince yaşanan problemler kişilerin günlük yaşamını olumsuz etkilemekte olup düşük kalitedeki uyku pek çok hastalığa sebep olmaktadır. Uykudaki problemleri teşhis edebilmek için literatürde bir çok gözlemleme sistemi geliştirilmiştir. Kişiyi rahatsız etmeyen, düşük maliyetli ve herkes tarafından ulaşılabilir bir sistem tasarlanmasına dikkat edilmelidir ve bu tezde, bu özellikler akıllı giyilebilir saat ve akıllı telefon yardımıyla sağlanmıştır. Önerilen sistem bir önizleme sistemidir ve kişilerin uykudayken yaşadıkları solunum problemlerinin ciddiyetini ölçmektedir. Bu amaçla, akıllı saatteki ivme ve kalp atış ölçer alıcılarıyla akıllı telefondaki ses ölçüm alıcısı aktifleştirilmiştir. Tasarlanan sistemin deneyleri bir uyku kliniğinde uzman uyku doktoru tarafından muayene edilen 17 denek üzerinde yapılmıştır. Dokuz denekte az sayıda anormal solunum olayı görülürken geriye kalanlarda pek çok anormal solunum olayı saptanmıştır. Deneklerden toplanan veriler birleştirildikten sonra, bu verilerin çeşitli kombinasyonları; farklı öznitelik çıkarım, seçim ve örnekleme yaklaşımlarıyla oluşturulmuştur. Sınıflandırma sonuçları verilerin çeşitli kombinasyonları, farklı eğitim ve puanlama yaklaşımları yardımıyla beş makine öğrenimi algoritması tarafından çıkarılmıştır. Sistem performansı iki yolla ölçülmektedir; anormal solunum olaylarının ayrımsanma başarısı ve deneklerin solunum problemlerine göre sınıflandırılma başarısı. Anormal solunum olaylarının ayrımsanma başarısı için elde edilen en iyi doğruluk oranı %85,95 iken, deneklerin sınıflandırılma başarısı; 17 kişide bir yanlış sınıflandırmadır.","Sleeping is an important activity to monitor since it has a crucial role in the overall health and well-being of the people and the society. The problems in sleep affect the daily lives of people negatively and a great deal of diseases has a strong correlation with low sleep quality. In order to diagnose the problems in the sleep, different monitoring systems are developed in the literature. The unobtrusiveness, reduced cost and reachability are the main design considerations and in this thesis, those are accomplished with the smart wearables; smart watch and smart phone. The proposed system can be utilized as a prescreening tool which recognizes the severity of problems in respiration during sleep. For this purpose, the accelerometer and heart rate monitor sensors on smart watch and the sound level sensor on smart phone are activated. The experiments of this system are performed with 17 subjects in a sleep clinic. The subjects are examined by the specialist doctor and among those subjects; nine of them perform a few abnormal respiratory events whereas lots of abnormal respiratory events are observed for remaining eight subjects. The data collected from these subjects is merged and used to generate various combinations by employing varied feature extraction, feature selection and sampling approaches. Five different machine learning algorithms are implemented and the classification results are generated with the various combinations of data, training and scoring strategies. The system performance is measured in two ways; discrimination success of abnormal respiratory events and classification success of subjects according to the problems in their respiration. The best achieved accuracy rate of distinguishing abnormal respiratory events is 85.95% whereas the classification success of subjects is one misclassification through 17 subjects."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Düşmeler, yaşlılar ve aileleri için ciddi sonuçlar içeren önemli sağlık sorunlarına neden olur. Düşmeleri önlemek için etkili önlemler erken bir aşamada alınmalıdır. Bu nedenle, düşme riskinin değerlendirilmesi, düşme riski seviyesinin saptanması ve bu seviyeye uygun bir önlem alınması için önemlidir. Kullanılan düşme riski değerlendirme ölçekleri, kişiden kişiye değişen gözlem ve yargıya bağlı olduğundan dolayı objektif ve güvenilir değildir. Yürüme parametrelerini kullanarak düşme riskini daha objektif ve doğru bir şekilde değerlendirmeyi amaçlayan sistemler vardır. Ancak bu sistemler ya çok sayıda sensörden oluşur ve kullanımı rahatsızlık vericidir ya da makine öğrenme metodolojisinden faydalanmamaktadır. Bu çalışmada, makine öğrenme tekniklerinden faydalanarak, yürüyüş parametrelerine bağlı, doğruluk oranı yüksek, rahatsızlık verici olmayan, objektif ve sürekli ölçümleme yapmayı hedefleyen bir sistemin geliştirilmesi amaçlandı. Bu amaçla, iki yürüme analizi tekniği incelendi: Kinect tabanlı bir sistem ve araştırma grubumuz tarafından geliştirilen ayağa monte edilen hareket sensörü tabanlı bir sistem. İkinci sistemi kullanarak, deneyler yaptık ve deneylerimize 21 tanesi nörolojik sorunlara sahip olmak üzere toplam 37 denek katıldı. Bu deneylerin amacı yürüme parametreleri üzerinden, yürüme özniteliklerini hesaplamaktı. En önemli yürüme öznitelikleri, öznitelik seçme yöntemleri kullanılarak belirlendi. Bu öznitelikleri kullanarak, çeşitli makine öğrenme yöntemleri ile denekler iki farklı gruba sınıflandırıldı: yüksek ve düşük düşme riskli grup. Bu sistem, düşme riski yüksek olan kişileri tespit etmemizi sağladı ve sistem sayesinde kişinin yakınları önlem almaları için uyarıldı. Sınıflandırma sonuçları doğruluk, duyarlılık, özgüllük ve F-ölçüsü temel alınarak değerlendirildi.","Falls lead to severe public health problems resulting in devastating psychological and physical consequences for older people and their families. Therefore, fall risk assessment has been a popular field of research in the last decades to understand the underlying reasons of the fall and eventually to identify people at high fall risk so that effective preventive strategies for falls can be taken at an early stage. Clinical and functional fall risk assessment tools are not objective and reliable for the assessment of fall risk as they require human observation and judgement. Related studies aim to assess the fall risk based on gait parameters in a more objective way, however, they either propose obtrusive systems composed of numerous sensors or do not utilize machine learning methodology. In this study, we employ machine learning techniques and aim to develop an accurate, unobtrusive, objective and continuous fall risk assessment system based on gait parameters. For this purpose, we studied two gait analysis techniques: a Kinect-based gait analysis system, and a foot-mounted inertial sensor-based gait analysis system developed by our research group. Using the latter, experiments are conducted to extract gait parameters of 37 subjects of whom 21 have neurological conditions with gait implications. Gait features are computed from these gait parameters. Feature selection techniques are used to determine the most significant gait features. Based on these features, different machine learning algorithms are employed to classify people into high and low fall risk groups. This system enables us to identify people who are likely to experience a fall in the near future and inform their caregivers to take preventive interventions. The predictions are evaluated based on the accuracy, sensitivity, specificity and F-measure."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevrimiçi sosyal ağların kullanımı hızla artmaktadır. Bu artışla birlikte, kullanıcıların mahremiyetinin korunması her geçen gün zorlaşmaktadır. Sosyal ağlar bu mahremiyet sorununu kullanıcılara mahremiyet sınırlamalarını başlangıçta sorarak çözmeye çalışmaktadır. Ancak bir gönderinin kime gösterileceğine karar vermek çoğu zaman gönderinin kendisine ve bağlama bağlıdır. Dolayısıyla kullanıcılar her bir gönderinin gösterileceği kişileri ayarlamak zorunda kalmaktadır. Bu süreç zahmetli ve hata yapmaya açıktır. Buna uygun şekilde, bu çalışma ilk olarak her bir gönderi için mahremiyet ayarı öneren bir yaklaşım ileri sürmektedir. Bu öneriler kullanıcıların eski gönderileri ve mahremiyet ayarlarından yapılacak yapay öğrenmeye dayanmaktadır. Fakat, kullanıcının yeterince eski gönderisi olmadığında öneriler yapılırken başka bilgiler de hesaba katılmalıdır. Kullanıcı etmenlerinin hesaba katabilecekleri olası mahremiyet kurallarına dair diğer kullanıcılarınkilere danışabilecekleri çok etmenli bir sistem mimarisi önermekteyiz. Kullanıcılar gönderileri paylaşmaya karar verirken onları paylaşmanın faydalarını da değerlendirdikleri için, mahremiyet temelli karar almaya ek olarak, kullanıcıların her bir gönderiyi paylaşmasının faydasını dikkate alan bir sistem önermekteyiz. Bu sistem bir gönderiyi paylaşmanın fayda bileşenlerinden onun alacağı beğeni sayısı, ona yapılacak yorum sayısı ve yeniden paylaşılma sayısını tahmin etmeyi hedeflemektedir. Bu tahminler kullanıcıların eski gönderileri ve onların faydaları üzerinden yapılacak öğrenmeye dayanmaktadır. Kullanıcılara paylaşım kararlarında yardım etmek üzere bu mahremiyet ve fayda temelli yaklaşımlar birleştirilmektedir. Mahremiyet yaklaşımlarını kendi yarattığımız değerlendirme veri kümeleri üzerinde, sonuncuyu ise Facebook'tan topladığımız veri kümesi üzerinden değerlendirmekteyiz.","The use of online social networks is growing rapidly. With this rapid increase, preserving privacy of users is becoming harder and harder. Typically, social networks address the privacy problem by asking users to define their privacy constraints up front. However, many times deciding on whom to show a post is dependent on the post itself and its context. Hence, users are forced to configure each post specifically, which is both cumbersome and prone to error. Accordingly, this study first proposes an approach that suggests privacy configurations for each post. The suggestions are based on learning from users' previous posts and configurations. However, when the user does not have many previous posts, recommendations need to take other information into account. We propose a multiagent system architecture where agents of the users consult other users' agents about possible privacy rules they can take into account. In addition to privacy-based decision making, we also propose another approach that considers users' utility of sharing each post since users also regard its benefits when they decide to share. The system aims to estimate benefits such as the number of likes that a post gets, the number of comments that it receives and how many times it is shared again. These estimations are built on learning from users' previous posts and their benefits. These privacy-based and utility-based approaches are combined in order to assist users in their sharing decisions. We evaluate single-agent and multi-agent privacy-based approaches on a benchmark dataset that we created based on content from Flickr and Reuters while we evaluate the latter one on a dataset that is collected with our Facebook application."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan davranışının otomatik analizi gürültü, çevresel farklılıklar ve etiketlenmiş veri yetersizliği gibi sebeplerden dolayı zor bir problemdir. Laboratuvar ortamında toplanmış veri bu analizi kolaylaştırırken, kontrolsüz ortamda toplanmış verideki büyük varyansı modelleyebilmek için karmaşık bir model gerekmektedir, bu da aşırı öğrenme problemiyle başa çıkmayı gerektirir. Bu tezde çokkipli bir sistemle insan sesi, yüz imgeleri ve videolarından hızlı ve gürbüz bir analiz sistemi önerilmektedir. İnsan yüzlerinden görünüm ve derin öğrenme öznitelikleri çıkararak çekirdek uçta öğrenme makinesi sınıflandırıcılarını birleştirmekteyiz. Önerilen yöntem bir dizi insan analizi yarışmasında değerlendirilmiştir. Deneylerimiz sonucunda uçta öğrenme makinelerinin geleneksel alternatiflere göre hızlı ve isabetli bir yöntem olduğunu göstermekteyiz. Ayrıca, derin öğrenme parametrelerinin ilgili görev için güncellenmesi ve çokkipli birleştirmenin tahmin isabetini neredeyse bütün görevler için yükselttiğini gözlemlemekteyiz. Önerdiğimiz sistem Emotion Recognition in the Wild (EmotiW) yarışmasında 2. sırada, ChaLearn Apparent Personality Analysis from First Impressions (FI) ve ChaLearn Job Candidate Screening (JCS) yarışmalarında 1. sırada yer almıştır. Sonuçlar göstermektedir ki uçta öğrenme makineleri zaman ve hesaplamasal karmaşıklık anlamında maliyetsiz ama aynı zamanda isabetli öğrenme yapılmasına elverişlidir.","Automatic analysis of human behavior has been a difficult problem due to noise, environmental differences and lack of annotation. While lab-controlled data provides an easier learning experiment, ""in the wild"" datasets require systems complex enough to fit to unseen data, at the same time, deal with the problem of overlearning. In this thesis, we propose a fast and robust multimodal system that analyzes humans from facial images, videos and voice. We extract dense appearance descriptors as well as Deep Convolutional Neural Network (DCNN) features from the faces and we train kernel Extreme Learning Machine (ELM) classifiers, which are then combined by various fusion schemes. We apply our pipeline to a number of affective and biometric challenges and we show that ELM provides fast and accurate learning compared to traditional learning methods. We also show that multimodal fusion and DCNN fine-tuning improves the accuracy in almost all tasks. Our method has ranked second in the Emotion Recognition in the Wild (EmotiW) challenge and first in the second round of ChaLearn Apparent Personality Analysis from First Impressions (FI) challenge as well as the ChaLearn Job Candidate Screening (JCS) challenge. Our results show that using extreme learning machine, efficient learning can be performed in terms of both time and computational complexity while preserving high performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çokdeğişkenli zaman dizisi sınıflandırma problemi zaman dizilerinde veri madenciliğinde sık görülen problemlerden biridir ve finans, tıp, insan-bilgisayar etkileşimi gibi bir çok alanda karşılaşılır. Geleneksel olarak bu problem tek değişkenli zaman dizisi sınıflandırma metotlarının çokdeğişkenliye uyarlamalarıyla çözülür. Bu çalışmada, çokdeğişkenli dizilerin sınıflandırılması için özel olarak geliştirilmiş öznitelik temelli bir metot sunulmaktadır. Bu metot sadece tek değişkenli müstakil dizilerin kendi özniteliklerinen değil, aynı zamanda değişkenler arası ikili etklişimin bilgisinden de yararlanır. Metot iki temel özniteliğin kaynaşımından oluşur: aralık ortalamaları ve kutupsal histogram yoğunlukları. Etiketli öznitelik vektörleri, yüksek boyutlu değişkenler üzerinde iyi çalışan rassal ormanlar aracılığıyla sınıflandırılır. Metodun literatürde sıklıkla kurllanılan ölçüt veri setleri üzerindeki performansı raporlanmıştır. Buna göre metot tatmin edici ölçülerde hatasız sonuçlar vermektedir ve uygulanabilirlik açısından bakıldığında gerektiği şekilde ölçeklendirilebilmektedir. Ayrıca değişkenler arası ikili etkileşim özniteliklerinin doğruluk oranlarını vakaların çoğunda arttırdığı görülmüştür. Buna ek olarak toplam hesaplama sürelerinin en büyük kısmı yine bu özniteliklerin hesaplanmasına harcanmaktadır. Bütün bunlar ışığında metot, geliştirilmesi gereken pek çok yanı olmasına karşın en modern metotlarla mukayese edilebilir seviyededir.","Multivariate time series (MTS) classification is an instance of common time series data mining tasks and is ubiquitously found in many domains such as medicine, finance or human-computer interaction. Traditionally, the research community has approached the problem by extending the well-established methods available in the univariate time series (UTS) classification literature. In this work, a new feature based method is developed specifically for MTS classification and aims to capture not only features of individual univariate series---as the extension methods do--- but also the interaction between them. The method utilizes simple interval statistics as the base feature and polar histogram densities to represent 2-way interactions. The feature vectors are processed with a random forest classifier for its ability to handle high-dimensionality. The results are reported for benchmark datasets of various types and from a range of domains. The method provides a satisfyingly accurate and scalable solution to the problem. The 2-way interaction information significantly increases the accuracy in most of the cases while the extraction phase of this information dominates the computation time. The method is comparable to the state-of-the-art methods in the literature even though there is a significant room for improvement."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sonlu özdevinir ya da sonlu durum makinesi, bilgisayımda kullanılan matematiksel bir modeldir ve özdevinir teorisinde en çok çalışılan modellerden biridir. Yıllar boyunca deterministik, nondeterministik, olasılıksal ve kuantum özdevinir gibi sonlu durum makinelerinin birçok farklı çeşidi önerilmiştir. Ayrıca, bu özdevinir modellerinin birbirleri arasındaki ilişkileri ve biçimsel dillerle olan bağları üzerine ayrıntılı çalışmalar yapılmıştır. Bu tezde, özdevinir modellerinde özlülük özelliği üzerine çözümlemeler yapılmıştır. Konu kapsamı, üç ana başlık altında ayrıntılandırılmıştır. İlk olarak, çeşitli sonlu makine modellerinin deterministik özdevinirler tarafından simüle edilmesi konusunda yapılan çalışmalar yer almıştır. İkinci olarak, üç düzenli dil ailesi tanımlanmış ve bu dil ailelerinin farklı özdevinir modelleri tarafından en az kaç durum ile tanınacağı gösterilmiştir. Üçüncü olarak, tek harfli alfabeler kullanılarak yaratılabilecek düzenli dilleri ve bu dilleri tanıyan sonlu makineleri birlikte tanımlayan bir biçim geliştirilmiştir. Adı, ""Tekli Sonlu Periyodik Biçim"" olan bu form kullanılarak düzenli dillerin kapalılık özellikleri üzerine detaylıca çalışılmıştır.","Finite state automaton, or finite automaton, is a mathematical model of computation and has been one of the most studied models in automata theory. Throughout the years, many different types of finite state automata are proposed, such as deterministic, nondeterministic, probabilistic, and quantum automata. Furthermore, the important questions that how they are related to each other, and how they are related to formal languages, have been a subject of intensive research. In this thesis, we study the succinctness properties of various finite automata. First, we thoroughly study the topic of simulating various finite automata by deterministic finite automata. Second, we work with three different families of regular languages and we provide the various minimal automata (i.e. minimal in the sense of the number of states used) deciding them. Third, we provide a descriptive form called ""Unary Finite Periodic Form"", or shortly UFPF, to efficiently describe regular languages over unary alphabets and we introduce algorithms to show the efficient realization of closure properties of UFPF."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevrimiçi sosyal ağlar kullanıcıların, diğer kullanıcılar ile bağlanmasını, içerik paylaşmasını ve diğer kullanıcıların paylaşımlarını incelemesini sağlamaktadır. Bu sosyal ağların yaygınlaşması, daha önceden üstünde düşünülmemiş mahremiyet sorunlarını yanında getirmektedir. Mahremiyet belirli kişilerden belirli bilgileri saklama hakkı olarak tanımlanmaktadır. Bu ağların kullanıcıları kendilerinin ve arkadaşlarının kişisel bilgilerini, fotoğraflarını ve videolarını paylaşabilmektedir. Çevrimiçi sosyal ağlara yüklenen bir içeriğin yönetim hakları, bunları yükleyen kullanıcıya verilmektedir. Bu, içerik ile alakası bulunan kullanıcılar için mahremiyet ihlaline imkan vermektedir. İçerikte bulunan herkesin onun hakkında söz sahibi olması hedeflenmelidir. Bu çalışma, mahremiyet ihlallerini çözmekte kullanıcılara yardımcı olan melez bir müzakere mimarisi önermektedir. Her kullanıcı, kullanıcının sosyal bağlantılarını ve mahremiyet ölçülerini bilen bir etmen tarafından temsil edilmektedir. Bu etmenler anlambilimsel olarak temsil edilmekte ve fayda fonksiyonları ile de kararlar almaları sağlanmaktadır. Çeşitli müzakere yöntemleri ile birlikte mütekabiliyet ilkesini kullanarak, geçmişteki etkileşimleri göz önünde bulundurup müzakere yapmayı sağlayan bir değiş-tokuş sistemi de geliştirilmektedir. Yapılan müzakerelerin sonuçlarını ölçmek için yeni bir değerlendirme metodu sunulmaktadır. Müzakere yöntemlerimizi karşılaştırmak için simülasyonlar yapılmaktadır. Sonuç olarak geliştirdiğimiz yöntemler çevrimiçi sosyal ağlar tarafından kullanılmakta olan yöntemlerden daha iyi sonuçlar vermektedir.","Online Social Networks (OSNs) are web-services that enable users to connect with other users, share content and view other users' content. Spread of online social networks brings privacy problems that are not addressed before. Privacy is defined as the right to conceal certain information from designated people. Users share personal information, photos and videos about themselves as well as their friends. OSNs give management rights of a content to the user who uploads them. This can lead to privacy violations for other users that are related to the content. These users may not want some people to see the content and the uploader may not be aware of this preference. Ideally everyone related to a content should have a say on how it is shared. We propose a hybrid negotiation architecture that helps users to solve privacy violations. Every user is represented by an agent that knows the relations and the privacy concerns of the user. We represent these agents and their relations semantically, also enable usage of utility functions for them to reach decisions. We develop various negotiation strategies as well as a trade-off mechanism that uses reciprocity principal to have negotiations that consider past interactions. We introduce a new evaluation metric for measuring the outcome of the negotiations. We run simulations to compare our negotiation strategies. As a result, our proposed strategies perform better than the existing methods of OSNs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın amacı, Türkçe metin tabanlı sınıflandırma işlemine kelime temsillerini dâhil eden bir yaklaşım getirmek ve söz konusu yaklaşımın uygulanabilirliğini ve performansını, Türkçe şarkıların müzik duygu analizinde değerlendirmektir. Bu çalışmada izlenen metot, iki temel aşamadan oluşmaktadır. Birinci aşamada kelime temsilleri, Word2Vec ve GloVe algoritmaları kullanılarak internet ortamından toplanan 2,5 milyondan fazla Türkçe dokümandan oluşan metin tabanlı büyük bir veri kümesi ile eğitilmiştir. Ardından oluşturulan kelime vektörleri vasıtasıyla, duygu tespiti yapılmak üzere seçilen ve ön işlemden geçirilen şarkı sözleri için şarkı sözü vektörleri oluşturulmuştur. Çalışmanın ikinci aşmasında ise, oluşturulan şarkı sözü vektörleri, çeşitli makine öğrenmesi teknikleri vasıtasıyla müzik duygu analizi işleminde kullanılmıştır. Karşılaştırma amacıyla, yaygın olarak kullanılan TF-IDF skorlarına dayanan kelime çantası (bag-of-words) yaklaşımı ve Doc2Vec algoritması da Türkçe müzik duygu analizi için düşünülmüştür. Aynı zamanda kelimeleri köklerine ayrıştırma ve önceden derlenmiş olan etkisiz kelimeleri filtreleme işlemlerinin sonuçlar üzerindeki etkisi de araştırılmıştır. Araştırmadan elde edilen sonuçlar, metin tabanlı büyük veri kümesi aracılığıyla oluşturulan kelime temsillerinin, Türkçe metin sınıflandırma sürecine dâhil edilmesinin etkinliğini ve performansı iyileştirdiğini ortaya koymaktadır.","The objective of this study is to bring an approach that incorporates word embeddings into Turkish text classification process, and to evaluate the applicability and performance of this approach by applying it for Turkish music mood detection. The methodology followed in this study consists of two main parts. In the first part, word embeddings are trained through a large collection of textual data, which includes more than 2.5 million Turkish documents gathered from the Internet, by using Word2Vec and GloVe algorithms. Subsequently, lyrics vectors are generated for the pre-processed lyrics selected for mood detection through the use of word embeddings that were trained initially. In the second part of the study, lyrics vectors are employed as features in music mood detection performed via various machinelearning techniques. Besides, Turkish music mood detection is also done by using traditional bag-of-words approach, in which TF-IDF term weighting scheme is used, and Doc2Vec algorithm for comparison purposes. The effects of stemming of the words into their roots and filtering out the precompiled list of stop-words on the results are investigated as well. The results obtained from the study show the effectiveness of incorporating word embeddings generated using big textual data collection into the Turkish text classification process, which is clearly illustrated by the improved classification performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde yazılım sistemleri geçmişe göre çok daha karmaşık bir hale gelmiştir. Birbirine bağımlı uygulamaların, birbirinden farklı teknolojilerin aynı anda kullanıldığı yazılım sistemlerinin test edilmesi bir çok farklı nedenden dolayı zordur. Bu nedenler, bağımlı bileşenlerin ulaşılamaz olması, üçüncü parti servisleri kullanmanın yüksek maliyeti ve farklı takımların takvimlerinin çakışması gibi sıralanabilir. Bu sebeplerden dolayı, bu tür yazılım sistemlerinde gerçek bileşen yerine sanal bir kopyayı kullanmak kolaylık sağlayabilmektedir. Servis sanallaştırma verilen bir bileşenin davranışlarını taklit etmeye yarayan bir tekniktir. Servisler durumsal ve durumsal olmayan olmak üzere iki sınıfa ayrılır. Bu tezde, hem durumsal hem de durumsal olmayan servislerin sanallaştırılması için yeni teknikler önerilmiştir. Bizim bilgimize göre bu çalışma durumsal servislerin sanallaştırılmasını konu alan ilk çalışmadır. Bu çalışmada bioinformatik ve makine öğrenmesi algoritmaları kullanılmıştır ve çalışmamızın geçerliliği gerçek servislerden toplanan verilerle test edilmiştir.","Today's enterprise software systems are much more complicated than the past. Increasing number of dependent applications and heterogeneous technologies makes testing of such systems challenging due to multiple reasons including unavailability of components, high cost of using services and con icting schedules of different development teams. Therefore in such software systems, it may be more convenient to use virtual components instead of the real ones. Service virtualization is a technique to mimic the behavior of a real component. Services are classi ed into two groups namely; stateful and stateless services. In this thesis, we introduce techniques for creating virtual copies of both stateful and stateless services. To the best of our knowledge, this is the rst work to create virtual services for stateful services. We employ bioinformatics and machine learning algorithms in developing our solutions. We demonstrate the validity of our approaches on data sets collected from real life services and obtain promising results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Evrimsel Bağlaşım (EB), bir sistemin gelişimi sırasında birlikte sıkça değişen yazılım sisteminin parçaları (artifact) arasındaki örtülü ilişkidir. Yazılım sistemlerinde EB'yi anlamak önemlidir çünkü mimari problemler, çapraz kesim, yazılım hataları ve etki analizi hakkında bilgi verir. Günümüzde, yazılım içindeki ve yazılımlar arasındaki artan boyut ve bağlaşım, EB üzerinde çalışmanın önemini arttırmaktadır. Bu tezin ilk bölümünde, evrimsel bağlaşım ile yazilim hataları arasındaki ilişkiyi anlamak için ampirik olarak nadiren incelenmiş olan büyük endüstriyel yazılım sistemlerini analiz ettik. EB ile hatalar arasındaki ilişki hakkında literatürdeki çelişkili sonuçların nedenlerini araştırdık. Sonuçlarımız, EB ölçülerinin açıklayıcı gücünün, yazılım boyutu ve yazılım geliştirici faaliyetleri gibi hata tiplerine ve modül özelliklerine bağlı olarak değiştiğini göstermektedir. Tezin ikinci bölümünde ölçüm teorisi ve metroloji ilkelerini kullanarak EB ölçme değerlendirme kriterleri geliştirdik. Mevcut EB ölçütlerinin zayıf yönlerini ve güçlü yanlarını, ölçüm teorisi ilkelerine dayanarak gösterdik. Uygulayıcılara ve araştırmacılara, hangi EB ölçütlerini ne zaman kullanmaları gerektiği konusunda tavsiyeler sunduk. Ayrıca, EB ölçütlerinin nasıl türetildiğini ve nasıl yorumlanacağını anlamak için gerekli olan EB kavramları için bir meta model geliştirdik. Bu tez ölçüm teorisi ve metroloji ilkelerini EB ölçümlemesine uygulayan ilk çalışmadır.","Evolutionary Coupling (EC) is the implicit relationship between the artifacts or parts of the software system that are frequently changed together during evolution of a system. Understanding the EC in software systems is important, as it has been shown to provide insight into architectural problems, cross-cutting concerns, software defects and the impact of change. Today, the increasing size and coupling within and between software increases the importance of work on EC. In the first part of this thesis we analyse large commercial systems which have rarely been empirically studied to understand the relation between EC and defects. We explore the reasons for the contradicting results in the literature about the relationship between EC and defects. No studies exist to explain these contradictory findings. Our results show that the explanatory power of EC measures varies depending on defect types and module features such as size and developer activity. In the second part of the thesis we develop EC measurement evaluation criteria by using measurement theory and metrology principles. We show the weaknesses and strengths of current EC measures based on measurement theory principles. We provide recommendations for practitioners and researchers about what EC measure to use and not to use as well as when to use these measures. Furthermore, we develop a meta-model for EC concepts, which are essential in understanding how the measure is derived and how to interpret it. To the best of our knowledge, this is the first work that applies measurement theory and metrology principles to EC measurement."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, konuların bir dizi ilgili unsura karşılık geldiği kısa ileti mesaj kümelerindeki konuları çıkarmayı amaçlamaktadır. İlk yaklaşım olan BounTI, dağınık, yapılandırılmamış ve parçalanmış kısa iletilerin içindeki konuları yakalamak için, herhangi bir alana özel olmayan daha düzgün yazılmış olan Wikipedia'nın kullanımını inceler. Konu unsurlarını bulmak için kullanılan tf hesaplamasında kısa ileti mesaj kümelerini tek bir belge olarak kabul eder. Başka bir genel kısa ileti kümesi, idf hasaplamada kullanılır ve bu hesaplamada her bir kısa iletiyi bir belge olarak kabul eder. İngilizce Wikipedia makalelerinin tf-idf vektörlerini hesaplar. tf-idf vektörlerinin kosinüs benzerliği konuları belirler. Bu yaklaşım 2012 ABD Seçimi sırasında toplanan 1 milyonun üzerinde mesaj ile değerlendirildi ve sonuç olarak 0,96 hassaslık skoru elde edildi (F1=1). İkinci yaklaşım olan S-BounTI, anlamsal olarak yapılandırılmış konuların üretilmesini inceler ve bu sayede, daha fazla bilgi elde etmek için işlenebilmelerini sağlar. S-BounTI, bir mesajın elemanlarını bağlantılı parçalar olarak kabul eder. Aynı mesajda iki parçanın birlikte olmasını bir ilişki olarak kabul eder. İlgili elemanlar ve aralarındaki ilişkilerin çizgesinden, en büyük klikleri kullanarak konuları belirler. Konuları ifade etmek için bu tezde tanımlanan Topico ontolojisini kullanır. Konu elemanıları Bağlı Açık Verilerdeki (LOD) kaynaklara bağlı olduğu için, LOD ile birlikte kullanılabilirler. Bu yaklaşımı incelemek için 2016'daki ABD seçimleriyle ilgili tartışmalar süresince, Carrie Fisher'ın ölümü ve Kuzey Dakota'daki boru hattı gösterileri gibi diğer olaylarda atılan 1 milyondan fazla kısa ileti değerlendirmeye alınmıştır. Nicel ve nitel gözlemler ve konuların kullanımını göstermek örnek için SPARQL sorguları ve sonuçları sunulur. Her iki yaklaşım umut verici sonuçlar vermiştir ve gelecekteki araştırma ve geliştirme için uygundur. S-BounTI'nin ilgili elemanları BounTI'den daha iyi temsil ettiği görülmüştür.","This thesis aims to identify topics in collections of microblog posts, where topics correspond to a set of related topic elements. The first approach, BounTI, examines the use of Wikipedia -- well written cross-domain articles -- to capture topics within microblog posts that are messy, unstructured, and fragmented. The topic elements are identified based on their tf-idf scores, where the microblog post set is considered as a single document for tf computation. For idf computation, a public stream post set is used where each post is considered as a document. The tf-idf vectors of Wikipedia articles are computed, and the cosine similarity of the tf-idf vectors determine the topics. This approach was evaluated with more than 1 million tweets gathered during the 2012 US presidential election, resulting in a precision of 0.96 and F1=1. The second approach, S-BounTI, examines the generation of semantically structured topics, so that they can be further processed to yield more information. S-BounTI considers distinguishing elements of a post set as linked entities. Co-occurrence of two elements in the same post is considered as a relation. The related element sets which form topics are maximal cliques of the graph of elements and relations. To express topics, an ontology for microblog topics is introduced. The topics can be utilized in conjunction with LOD. Over 1M posts during the 2016 U.S. presidential election debates, and other events such as the death of Carrie Fisher and the Dakota Access Pipeline demonstrations were considered for evaluation. Quantitative and qualitative observations are provided and example SPARQL queries and their results are presented to show the utilization of the topics. Both approaches gave promising results and are suitable for future research and development. S-BounTI has been found to represent related elements better then BounTI."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Her dönemin başında üniversite öğrencilerinin ders programlarına karar vermeleri gerekir. Çok sayıda ders alternatifi içinden programların hazırlanması daha kolay olacağı için öğrenciler daha çok ders sunulmasını ister. Ancak sunulan ders sayısının artması öğrencilerin ders seçimi konusunda kararsızlık yaşamasına sebep olur. Bu problem her ne kadar az ders adedinde de geçerli olsa da ders sayısı arttıkça problemin çözümü güçleşir. Bir başka problem ise öğrenciler almak isteyebilecekleri ve programlarına uyan derslerin varlığından haberdar olmayabilirler. Kendilerine ders tavsiyesinde bulunabilecek bir sistem, bu açıdan faydalarına olabilir. Ayrıca, öğrenciler mezuniyet planlarını yapmak isteyebilirler. Mezuniyet için gereken dersleri ve onların dönemlere nasıl paylaştırılacağını görmek isteyebilirler. Bu problemlerin çözümü adına Boğaziçi Üniversitesi öğrencileri için tasarlanan, ders programını optimize eden, ders tavsiyesinde bulunan ve mezuniyet planlaması yapan bir online platform olan Mecanin geliştirilmiştir. Bu tezde, Mecanin'e girilen ders programlarını optimize etmekte kullanılan ve mezuniyet planı çıkaran iki ayrı tamsayı programlama modeli ve ders tavsiyesi algoritması sunulmuştur. Geliştirilen algoritmalar test edilmiş, rastgele, popülerlik tabanlı ve popülerlik tabanlı olasılıksal üç algoritmayla karşılaştırılmış ve karşılaştırma sonuçları gösterilmiştir.","University students need to prepare their course programs at the beginning of each semester. A large number of offered courses is desired by students since it is easier to create a schedule using a great diversity of courses. However, increase in the number of offered courses makes students to be indecisive about selecting courses. Although this problem exists for smaller number of courses, it becomes harder as the number of courses increases. Another problem for students is that they may not be aware of some courses which are good fit for their preference and course program. They can make use of a course recommendation tool which helps them find their prospective courses. Furthermore, students are also interested in making their graduation plan. They might have completed some courses and could be interested in arrangement of remaining ones into semesters. In order to address these problems, Mecanin, an online platform for Boğaziçi University students that provides a course schedule optimizer, a course recommendation tool, and a graduation planner, is developed. In this thesis, integer programming models for course program optimization and graduation planning are proposed along with recommendation algorithms to suggest courses to students. Proposed algorithms are tested and compared with three baselines which are random, popular, and popularity-based probabilistic recommendation algorithms, and the results are presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyometri bir kişinin tutum ve özelliklerine bağlı olarak kimliğini tespit etme işlemidir ve fizyolojik ve davranış temelli olmak üzere ikiye ayrılmaktadır. Bu tezde, davranış temelli bir biyometrinin örneği olarak, kişilerin kimliğini sosyal platformlardaki yazım alışkanlıklarından tespit etmeye çalışmaktayız. Çevrimiçi sosyal platformlar, istenmeyen içeriği filtrelemek için denetleme mekanizmalarını uygular ve sözlü saldırı, istismar, cinsel taciz gibi durumlara karşı harekete geçmeye çalışır. Burada biyometri olarak adlandırdığımız şey, bir sosyal platformda engellenen kullanıcıların farklı kimlikle geri dönmesi durumunda kimliğinin tespit edilmesi ya da sahte hesapların ardındaki kişilerin ortaya çıkarılmasıdır. Bu amaçla bir kimlik tanıma sistemi ortaya koyarak literatürde yaygınlıkla işlenenen diğer biyometri yöntemleri ile karşılaştırmaktayız. Ortaya koyduğumuz biyometrik kimlik tanıma yaklaşımı, COPA olarak adlandırılan ve çevrimiçi bir oyun platformundan toplanmış olan ikiden fazla kişinin çevrimiçi grup sohbetlerini içeren bir Türkçe veritabanında ölçümlemektedir. Önerdiğimiz kimlik tanıma yönteminin farklı sosyal mecralarda da dayanıklılığını ölçümlemek için Ekşisözlük adlı Türkiye'de yaygın bilinirliği olan sosyal bir platformdan da veri toplamış bulunuyoruz. Ayrıca, önerilen yöntemin farklı dillerdeki kimlik tanıma başarımını ölçümlemek amacıyla İngilizce ve Portekizce haber kayıtlarını da kullanmaktayız. Bu içerikler üzerinde, hem genel profil bilsini hem de yazı örneklerini ayrı ayrı ele alarak modellediğimiz kimlik tanıma sisteminde bir kişiyi güvenilir şekilde tespit etmek için en az ne kadar yazı içeriğine ihtiyacımız olduğunu da araştırmaktayız.","Biometrics is the identification of a person by personal properties and traits, and can be divided into physiological based and behavioural based methods. In this thesis we investigate the identification of users of a social platform from their verbal behaviour, which is an example of behaviour based biometrics. Online social platforms implement moderation mechanisms to filter out unwanted content and to take action against possible cases of verbal aggression and abuse, sexual harassment, and such. Since they can have large numbers of users, it is desirable to automatize parts of this process. What we call chat biometrics aims to re-identify a user from chat messages. The typical application scenario is the re-identification of banned users, returning under different identities, and aggressors operating through multiple fake accounts. We propose a processing pipeline, and contrast the problem with the authorship identification problem, which is well-studied in the literature. We evaluate our proposed approach on a large corpus of multiparty chat records in Turkish (namely, the COPA database), which was collected from a multiplayer game environment. We also introduce a new corpus in this study, collected from a well-known Turkish social platform called Ekşisözlük, in order to test the robustness of the system across domain changes, as well as on Portuguese and English news datasets, to show performance across languages. We evaluate both profile-based and instance-based approaches, and provide detailed analyses with regards to the required amount of text to identify a person reliably."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dağılımlarında düzensizlik gösteren biçimbirimsel sistemler, sözcüklerin zihinde nasıl işlendiği ve temsil edildiğine ilişkin önemli ipuçları sunar. Bu çalışma, eylem köküne eklenen eklerde düzensiz bir dağılım gösteren Türkçe Geniş Zaman ekinin ana dili Türkçe olan yetişkinler tarafından nasıl işlendiğini ve temsil edildiğini araştırmaktadır. Ünlüyle biten kökler için -r (uyu-r), ünsüzle biten tek heceli köklerin çoğu için -Ar (çal-ar), çok heceli kökler (çalış-ır) ve tınılı sesle biten 13 tek heceli kök için -Ir (al-ır) alan Geniş Zaman yapısının ediniminde yaşanan zorluklar bilinmektedir. Bu çalışmada anadili Türkçe olan 90 yetişkin katılımcının, Türkçe'de var olmayan, tınılı sesle biten 168 tek heceli kök ile (vel-, rur-, vb.) Geniş Zaman yapısı üretimi test edilmiş, katılımcılara, uydurulmuş bir eylem içeren tümceler dinletilmiş ve izleyen taşıyıcı tümcede bu eylem kökünü sesli olarak tamamlamaları istenmiştir (Ali biraz önce veldi. Ali yazın her gece vel____ gibi). Bulgularımız, yetişkinlerin söz konusu eylemlerle -Ar ekini %86 oranında kullandığını göstermiştir (dolayısıyla, büyük çoğunluk vel-ir yerine vel-er'i tercih etmiştir). -Ir kullanımında, var olan eylemlerle benzerliklerin rol oynayıp oynamadığını ortaya çıkarmak için çeşitli benzerlik ölçütleri geliştirilmiş, dilde mevcut olan aynı ilk ünsüz C_ _, aynı ünlü _V_ ve aynı ünsüz örüntüsü C_C'yi paylaşan düzensizlik gösteren eylemlerin kullanım sıklığıyla –Ir kullanımının ilişkili olduğu, uyak ölçütünün, ise dil kullanıcıları açısından güvenilir bir ipucu oluşturmadığı gözlenmiştir.","Morphological systems that possess irregular suffixation provide us important cues with respect to how words are processed and represented in the mind. This study attempts to find out how adult speakers of Turkish process and represent the aorist, an irregular pattern proven to be extremely challenging in acquisition, as it takes the form of -r for vowel-ending verbs (uyu-r 'sleeps'), -Ar for most monosyllabic verbs (çal-ar 'plays'), and -Ir for multisyllabic verbs (çalış-ır 'works') and 13 monosyllabic sonorant-ending verbs (al-ır 'takes'). In this study we have tested 90 native speakers with respect to their production of the aorist with 168 monosyllabic, sonorant-ending nonce roots (vel-, rur-, etc.). Participants were auditorily presented with sentences that contained nonce roots and instructed to orally conjugate the nonce root in a subsequent carrier sentence such as in Ali biraz önce veldi. Ali yazın her gece vel____. 'Ali velled a short while ago. Every summer night, Ali vel___.' Our results have shown that adult speakers of Turkish have opted for the use of -Ar with a rate of 86% (i.e., vel-er preferred over vel-ir by the overwhelming majority). To uncover the role of similarity in the use of –Ir, we have explored various similarity measures and have found that -Ir use appears to be correlated with the type frequency of existing irregulars sharing the same first consonant C_ _, the same first vowel _V_ and the consonantal template C_C. Rhyme, however did not appear to be a salient cue that language users rely on."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez her yerde birden bulunan hesaplama ortamını geliştiren, radyo frekanslı tanımlamanın (RFID) güvenlik ve gizlilik konuları üzerinde durmaktadır. RFID teknolojisini günlük kullanıma uygun hale getirmedeki en önemli mesele gizliliktir. Düşük maliyetli RFID etiketlerinin devre boyutu, güç tüketimi ve hafıza boyutu açısından kaynak sınırlamaları olduğu için, varolan kriptografik fonksiyonlara dayanarak gizli kimlik denetim protokolleri tasarlamak çok güçtür. Bu nedenle, hafif kriptografiye dayanan yeni gizli kimlik denetim protokolleri gerekmektedir. Biz bu tezde, düşük maliyetli etiketler üzerinde odaklandık. Bu tez başlıca üç başlık altında katkı sağlar. İlk olarak, RFID protokollerininin karşılıklı kimlik doğrulama ve kullanılabilirlik açısından güvenliğini analiz ediyoruz ve bu protokollere karşı kimliğe bürünme ve uyumsuzluk saldırıları öneriyoruz. İkinci olarak, kaotik-harita tabanlı RFID protokollerinin güvenliğini analiz ediyoruz. Bu protokollere karşı gizli ahahtar açıklama, izleme, kimliğe bürünme ve senkronizasyon saldırıları öneriyoruz. Önerdiğimiz saldırılara dayanıklı revize edilmiş protokoller öneriyoruz. Son olarak, RFID gizlilik ve ölçeklenebilirlik sorunlarını inceliyoruz. İstenilen düzeyde gizlilik sağlayan önceki tüm RFID protokolleri arka-uç sunucuda lineer çalışma gerektirir. RFID sistemleri için PUF tabanlı ölçeklenebilir kimlik doğrulama protokolleri oneriyoruz. Onerdiğimiz protokoller Vaudenay'ın gizlilik ve güvenlik modeline göre yıkıcı gizlilik sağlar. Onerdiğimiz protokoller anahtarları PUF kullanarak saklar ve bozma saldırılarına karşı güvenlik sağlar. Bildiğimiz kadarıyla, önerdiğimiz protokoller sabit tanımlama zamanı ile bu seviyede gizlilik sağlayan ilk protokollerdir.","This thesis studies security and privacy issues of Radio Frequency Identification (RFID) technology that enhances ubiquitous computing environment. Privacy is one of main issues to adopt RFID technology in daily use. Due to resource constraints of low cost RFID tags in terms circuit size, power consumption and memory size, it is very restricted to design a private authentication protocol based on existing cryptographic functions. Therefore new private authentication protocols should be designed with lightweight cryptography primitives. In this thesis, we focus on low cost RFID tags. Our contributions are as follows. First, we analyze the security of recent RFID authentication protocols with respect to two security requirements: mutual authentication and availability. We propose impersonation and de-synchronization attacks against recent RFID authentication protocols. Secondly, we analyze the security of chaotic-map based RFID protocols. We propose secret disclosure, tracking, impersonation and de-synchronization attacks against these protocols. We propose revised protocols resistant to our proposed attacks. Finally, we study privacy and scalability issues in RFID. All previous RFID protocols giving the desired level of privacy required linear work in the back-end server. There are several PUF-based protocols which requires work logarithmic in the number of RFID tags in a system. We propose PUF-based scalable authentication protocols for RFID systems. They provide destructive privacy according to the Vaudenay's privacy and security model. They defend against compromising attack by using PUFs as a secure storage to keep secrets of the tag. To the best of our knowledge, they are the first to provide this level of privacy with constant identification time."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hafif kognitif bozukluk, Parkinson hastalığının (PH) yaygın bir belirtisidir. Parkinson hastalığında hafif kognitif bozukluk (PH-HKB) tanısında kullanılacak nesnel görüntüleme biyoişaretleyicileri gerekmektedir. Atardamar fırıl etiketleme MRG (ASL-MRG) kontrast madde ya da iyonlaştırıcı radyasyon kullanmadan serebral kan akışını (SKA) ölçmeyi sağlamaktadır. Bu çalışmada, 19 PH-HKB ve 19 işlevsel normal Parkinson hastasında (PH-KN) ASL-MR görüntüleri, 3T manyetik alanda alındı. SKA haritaları perfüzyonün tek çıkarım ile kantitatif görüntülenmesi (QUIPSS II) formülü kullanılarak atardamar kan hacmi (aKH) düzeltmesi ile hesaplandı. SKA ve aKH haritaları FSL'de T2 ağırlıklı MR görüntülerinin içine yerleştirilerek birleştirildi ve MNI152 beyin atlasıyla çakıştırıldı. PH-HKB ve PH-KN hastaları arasında çeşitli beyin bölgelerinin SKA ve aKH değerleri karşılaştırıldı. aKH düzeltmesi yapılarak ve yapılmayarak hesaplanan SKA haritalarının histogram parametrelerindeki farklılıklar değerlendirildi. Nöropsikolojik test skorları ve SKA değerleri arasındaki korelasyonlar değerlendirildi. Her grubun farklı beyin bölgelerindeki SKA değerleri birbirleriyle karşılaştırıldı. Bir grafiksel kullanıcı arayüzü ASL-MRG'den SKA değerlerini hesaplamak için MATLAB'de tasarlandı. PH-HKB ve PH-KN hastaların SKA değerleri arasında istatiksel olarak anlamlı fark yoktu. PH-HKB ve PH-KN gruplarının beyin bölgelerindeki SKA değerleri arasında bazı varyasyonlar vardı. PH-HKB hastalarının bazı beyin bölgelerinde SKA değerleri ile nöropsikolojik test skorları arasında negatif bir korelasyon eğilimi vardı. Bu çalışmanın sonuçlarının diğer MR parametreleri ile birleştirilmesiyle PH-HKB tanısı için MR temelli bir biyoişaretleyicinin tanımlanması mümkün olabilir.","Mild cognitive impairment is a common symptom of Parkinson's disease (PD). Objective imaging biomarkers are required for the diagnosis of PD with mild cognitive impairment (PD-MCI). Arterial spin labeling MRI (ASL-MRI) enables the measurement of cerebral blood flow (CBF) without using contrast agent or ionizing radiation. In this study, ASL-MR images of 19 PD-MCI and 19 cognitively normal PD (PD-CN) patients were acquired at 3T. CBF maps were calculated with arterial blood volume (aBV) correction using the quantitative imaging of perfusion using a single subtraction (QUIPSS II) formula. CBF and aBV maps were fused into T2 weighted (T2w) MR images, and registered to MNI152 brain atlas in FSL. The CBF and aBV values of several brain regions were compared between PD-MCI and PD-CN patients. The differences in histogram parameters of CBF maps, which were estimated with and without aBV correction, were assessed. The correlations between the neuropsychological test scores and CBF values were assessed. The CBF values in different brain regions of each group were compared with each other. A graphical user interface (GUI) was designed in order to calculate CBF maps out of ASL-MRI in MATLAB. There were not any statistically significant differences between the CBF values of PD-MCI and PD-CN patients. There were some variations between the CBF values of the brain regions in PD-MCI and PD-CN groups. There was a trend of a negative correlation between the neuropsychological test scores and the CBF values in some brain regions of PD-MCI patients. The results of this study combined with other MR parameters might enable the definition of an MR based biomarker for PD-MCI diagnosis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, GPGPU veya ekişlemci gibi hızlandırıcıların kullanıldığı heterojen süperbilgisayarlardaki iş çizelgeleme problemini ele almaktadır. Homojen süperbilgisayarlarda, mevcut kaynaklara kullanıcı işlerinin çizelgelenmesi problemi NP-zor sınıfındadır. Heterojen sistemler iş çizelgeleme problemini birleşimsel olarak daha zor yapmaktadırlar. Bu tezde amaçlarımız (i) son teknoloji heterojen süperbilgisayarlar için yeni tür iş çizelgeleme algoritmaları tasarlamak, (ii) bu algoritmaları kullanılmaya hazır açık kaynak kodlu yazılım ekleri olarak gerçekleştirmek ve (iii) bu algoritmaların etkinliğini gerçcek hayat kullanımını öykünerek göstermektir. Heterojen süperbilgisayarlardaki iş çizelgeleme problemini çözmek için dört farklı model önerilmiştir. İlk modelde, topolojiyi dikkate almayan basit bir beraber tahsis etme problemi formülleştirilmiştir. İkinci modelde, problemi bir müzayede problemi olarak ele alıp ve bir boyutlu bir sistem topolojisi varsayarak her iş için otomatik olarak birden fazla teklif yaratılmıştır. Üçüncü modelde, sayı aralıkları kullanarak kaynak istekleri yapabilen şekillendirilebilir işler desteklenmiştir. Dördüncü ve son modelimizde, hiyerarşik şekilde bağlanmış şişman-ağaç topolojisi de dikkate alınmıştır. Tüm bu modeller tam sayı programlama problemi olarak formüle edilip, her çizelgeleme adımında periyodik olarak çözülmektedir. Çizelgeleme algoritmalarının başarımlarını test etmek için daha önceden tanımlanmış olan iş yüklerine ek olarak, heterojen sistemler için daha gerçekçi iş yükleri yaratacak olan kendi iş yükü üreticimiz de geliştirilmiştir. Yapılan testler algoritmalarımızın geleneksel geri dolgulama algoritmalarından sistem kullanımı, ortalama iş bekleme süresi ve/veya iş parçalanması açılarından bakınca daha iyi performans ortaya koyduğunu göstermektedir.","This thesis addresses the job scheduling problem for heterogeneous supercomputers where accelerators such as GPGPUs or co-processors are employed. On homogeneous supercomputers, the problem of scheduling user jobs to the available resources is NP-hard. Heterogeneous systems make the scheduling problem combinatorially more difficult. In this thesis, we aim to (i) design a new class of scheduling algorithms for state-of-the-art heterogeneous supercomputers, (ii) implement these scheduling algorithms as ready to use open source plugin software (iii) demonstrate the effectiveness of these algorithms by emulating real life usages. We propose four different models to solve the scheduling problem on heterogeneous supercomputers. In the first model, we formulate a simple co-allocation problem that does not take topology into consideration. In the second model, we implement the problem as an auction problem and automatically generate multiple bids for each job by assuming a one dimensional system topology. In the third model, we support moldable jobs that may request a range of resources. In our fourth model, we also consider topologically aware scheduling for hierarchical fat tree interconnection architectures. All of these models are formulated as integer programming problems and are solved periodically at each scheduling step. We use existing workloads to test the performance of our scheduling algorithms and also develop our own workload generator that generates realistic workloads for heterogeneous systems. The tests carried out show that our algorithms perform better than the traditional backfiilling algorithm in terms of system utilization, average job waiting time and/or job fragmentation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Niceliksel Edebiyat Analizi (NEA), günümüzde hızla gelişen ve edebi metinlerin sayısal analizlerini yapan bir alandır. Bu tezdeki temel motivasyonumuz kelime seçimlerine bakarak yazarların edebi eserlerini tasnif etmektir. Bir grup edebi eseri yazarlarına göre tasnif edip edemeyeceğimizi ve türlerine göre eserleri ayırt edip edemeyeceğimizi ve her bir karakterin konuşmalarını bir metin olarak ele alırsak karakterler hakkında bilgi edinip edinemeyeceğizi inceliyoruz. Bu sorular NEA alanında özgün sorulardır.","Quantitative Analysis of Literature (QAL) is a rapidly growing field and it deals with numerical analyses of literary texts. Our motivation in this thesis is to classify literary pieces of authors based on their choice of words. We examine, whether given a set of literary documents we can classify them by author, whether we can classify them depending on their genre or not and whether by treating speech by individual protagonists as texts we can infer something about the protagonists themselves. These are novel questions in the field of QAL."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Artan enerji maliyetleri nedeniyle, telekomünikasyon servis sağlayıcılarının enerji etkin yöntemlere olan ilgisi her geçen gün artmaktadır. Telsiz veri iletişimi ve akıllı telefon kullanım oranlarının hızla artması, cep telefonu operatörlerinin işletme maliyetlerini de bir hayli arttırmıştır. Bunların yanı sıra, çevrebilimciler tarafından küresel ısınmanın başlıca nedeninin atmosfere fazla miktarda salınan sera gazı olduğu ve salınan sera gazının %72'sinin karbondioksit (CO2) olduğu belirtilmektedir. Yüksek enerji maliyetleri ve artan çevresel farkındalık, cep telefonu operatörlerini enerji etkin yeşil yöntemler kullanarak CO2 ayak izlerini ve enerji harcamalarını azaltmaya itmiştir. Bu tezde, (i) klasik hücresel ağlar (ii) paket anahtarlamalı çoktürel hücresel ağlar ve (iii) yeni nesil çok katmanlı hücresel ağlar olmak üzere üç farklı telsiz ağ tipi için enerji tasarruf yöntemleri önerilmektedir. Sıralanan her bir ağ tipi için toplam enerji tüketimini en aza indirmeyi amaçlayan, bunu yaparken de belirli bir servis kalitesini sağlayan matematiksel eniyileme modelleri geliştirilmiştir. Eniyileme modellerindeki karar değişkenleri ise, mevcut veri trafiği yoğunluğuna göre yeni baz istasyonları yerleştirmek, baz istasyonlarını açıp kapatmak ve yayım güçlerini değiştirmektir. Mevcut eniyileme araçları küçük ölçekli problemler için kesin sonuçlar üretse de, daha karmaşık büyük ölçekli problemlerin çözümü için yeni sezgisel algoritmalar tasarlanmıştır. Gerçek hayat koşullarına mümkün olduğu kadar yakın örneklerle yapılan başarım değerlendirmesi sonuçlarına göre, önerilen yeşil yöntemlerin ağ topolojisini mevcut veri trafiği koşullarına göre uyarlayarak enerji farkındalıklı ağlar yarattığı ve önemli miktarda güç tasarrufu sağladığı gösterilmiştir.","Increasing energy costs drive the telecommunication service providers to become highly interested in energy efficient operations. The exponential growth in mobile data exchange which is further augmented by the rapid proliferation of smart phones increases the operational expenses of the cellular network operators significantly. Also, ecologists state that the primary triggering factor of the global warming is adding excessive amounts of greenhouse gases to the atmosphere and 72% of the totally emitted greenhouse gases is carbon dioxide (CO2). Increasing environmental awareness combined with the high energy prices has driven the network operators to reduce their CO2 footprint by adopting energy efficient green methods. In this thesis, our main focus is to save energy in three types of wireless cellular networks (i) Conventional Cellular Networks (ii) Packet-switched Cellular Networks and (iii) Next Generation Multi-tier Cellular Networks. We formulate novel mathematical optimization problems for each of the listed cellular networks to find the best possible topology which minimizes the overall power consumption of the network while satisfying a certain quality of service level. Our decision variables in the optimization models are switching base stations on/off and adaptively adjusting their transmission power levels as well as deploying additional pico base stations as a remedy according to the present traffic conditions. Although the optimization tools provide the optimum solutions for smaller instances of the problem, we propose novel heuristics to solve large-scale realistic instances due to their prohibitive complexity. Results of extensive simulations, which are designed as close to real life conditions as possible, show that the proposed green methods help to maintain an energy-aware network and save significant amount of energy by adjusting the network topology to the current traffic conditions adaptively."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bulaşıkları bulaşık makinesine yerleştirmek zaman alır ve birkaç günde bir tekrar edilmesi gerekir. Bu yüzden, bardakları makineye yerleştiren robotik bir sistem yapmaya karar verdik. Bunu gerçekleştirebilmek için üç farklı sorunun çözülmesi gerekti: tezgahın üstündeki bardakları tanıma; 2 boyutlu yerleşim planlama; robot kolla yerleştirmek için hareket planlaması. Bu sorunların hepsinin çözümleri simülasyon ortamında ve gerçek dünyada 5 serbestlik derecesine sahip bir robot kol ve derinlik kamerasıyla yapıldı. Bizim bu projeyle katkımız farklı buluşsal yöntemleri ve optimizasyon metodlarını maliyet fonksiyonları ve metodlarıyla kullanarak yerleştirme planlaması yapmamızdır. Üst-Sol-Doldurma ve Sol-Üst-Doldurma yöntemlerini nesneleri paketlemek için ve Benzetilmiş Tavlama, Genetik Algoritma ve iki farklı Parçacık Sürü Optimizasyonu metodlarını optimuma yakın bir sonuç bulmak için kullanıyoruz. Metodlarımızdaki ilk yerleşim düzeni, en yakın nesneyi önce yerleştirme, boyutlarına göre veya rastgele yerleştirme yöntemlerinden biri ile bulunuyor. Ağırlıklı-toplam ve uyumları sıralama yöntemleri, yerleştirme problemi maliyeti, kullanıcı tercihine bağlı maliyet ve mühendislik maliyeti fonksiyonlarıyla beraber optimizasyon algoritmalarımızda kullanılıyor. Fonksiyonlardaki parametreleri ve ağırlıklarını bulmak için ön araştırma ve kullanıcı araştırmaları yapıldı. Bunun üzerine, insanların yerleştirme biçimlerini gözlemlemek için gözlemsel araştırma yapıldı. İnsanların yerleştirmelerini düzenlilik kriterine göre Likert ölçeğiyle puanlayabilmek için açımlama sistemi yapıldı. Buradan elde edilen değerler obsesif kompulsif bozukluğun düzenlilik kriteriyle ilişkisini bulabilmek için gözlemsel araştırmadaki değerlerle karşılaştırıldı. Simülasyon sonuçlarımız, genelde, ağırlıklı-toplam metodu için Sol-Üst-Doldurma yöntemiyle kullanılan Genetik Algoritmanın en az maliyeti doğurduğunu gösterdi. Uyumları sıralama yöntemiyle ise Sol-Üst-Doldurmayla kullanılan Benzetilmiş Tavlama yönteminin en az maliyeti olduğu gözlemlendi.","Placing the dishes into a dishwasher can take a considerable amount of time, which is a process a person would have to repeat every few days. Therefore, we decided to build a robotic system which would place the mugs on the counter-top to the dishwasher tray. Three types of problems are solved in order to realize this task: object recognition for detecting the mugs; 2D packing problem for placement planning of mugs on the dishwasher tray; placing the mugs into the dishwasher through manipulation. These tasks are solved within a simulation environment and in the physical world by a 5 degree-of-freedom robot arm and a depth camera. Our contribution with this project is placement planning, in which we use different heuristics and optimization methods with different cost methods and functions. Top-Left-Fill (TLF) and Left-Top-Fill (LTF) heuristics are used for packing and Simulated Annealing (SA), Genetic Algorithm (GA), and two different Particle Swarm Optimization (PSO) methods are used for finding the near-optimal solution for the placement of the mugs. The initial configurations of our methods are made with closest-item-first, sorted-size heuristics and random order. In our optimization algorithms, we use weighted-sum (WS) and ranking fitness (RF) methods with bin-packing cost (BPC), user preference-based cost (UPC) and engineering cost (EC) functions. In order to find the parameters and their weights for the cost functions, we conducted preliminary and user studies. Furthermore, we made an observational study to examine the placement methods of the participants. An annotation system was made to rate the sortedness of these placements with a Likert scale. The sortedness of the placements were compared with the Obsessive-Compulsive Scale test results from the observational study to observe the relation. The results of our simulation experiments show that, in general, the GA with the LTF heuristic produces the lowest costs with the WS method, whereas for the RF method, the best optimization method is the SA."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Spektrum nadir ve değerli bir kaynak olmasına rağmen, belli bölgelerdeki çeşitli frekans bantlarında spektrumdan faydalanmanın oldukça düşük olduğu gösterilmiştir. Bu olgu ışığında spektrum kullanımındaki verimsizliği aşmak amacıyla lisanslı bantların ikincil bir ağ tarafından kullanılmasına izin veren bilişsel radyo kavramı geliştirilmiştir. Ayrıca, bu zorlu durum çok büyük artış gösteren kablosuz ağlar üzerinden içerik tüketimiyle eş zamanlı gerçekleşmektedir. Bu kapasite problemini çözmek için 5G kablosuz ağ standartı geliştirilmektedir. 5G teknolojilerinde Cihazdan-Cihaza İletişim bu darboğazı aşmak için seçilen önemli bir yaklaşımdır. Ayrıca bu sistemlerde farklı ağ katmanlarından oluşan heterojen kablosuz ağların her yerde gerekli servis vermeleri beklenmektedir. Bu tezde, uydularla tümleşik bilişsel radyo ağlarında içerik dağıtımı için analitik bir Markov modeli geliştirilmiştir. Ek olarak, bu tür altyapı-tabanlı mobil ağları incelemek için bir simülasyon yaklaşımı da oluşturulmuştur. Simülasyon modelimiz enerji verimliliğine odaklanmasına rağmen başka başarım değerlendirmeleri amacıyla genişletilebilir. Ayrıca söz konusu ortamda ağ yoğunluğu, farklı içerik sağlayı-cılardan içerik edinimi tercih oranları ve ortalama içerik boyutu gibi çeşitli sistem parametrelerinin sistem başarımı üzerine etkileri araştırılmıştır.","Although the spectrum is a scarce and valuable resource, the utilization of spectrum in various frequency bands in certain areas are shown to be very low. Because of this under-utilization and inefficiency, cognitive radio (CR) concept where licensed bands are allowed to be used by a secondary network is being developed. Moreover, this new phenomenon has been coexisting with the exploding content consumption over wireless networks. Upcoming fifth generation (5G) wireless standards have been developed to address this capacity crunch. In 5G ""toolkit"", Device-to-device (D2D) communications is an important approach adopted to alleviate this issue. Moreover, heterogeneous wireless networks composed of different network tiers are expected to provide services in an omnipresent setting. In this thesis, we develop an analytical Markovian model for content delivery over satellite integrated cognitive radio networks. Additionally, we devise a simulation for studying this infrastructure-based mobile network. The simulation model is focused on energy efficiency. However, it can be extended for other performance evaluation purposes. We also investigate the effect of various system parameters on the performance of these systems such as network density, preference ratios for content retrieval from different content holders and average content size in this setting."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde ¸cekirdek a˘glarda Da˘gılmı¸s Hizmet Engelleme Saldırısı (DDoS)'na karşı filtreleme bazlı savunma mekanizmaları geliştirilmiştir. İlk olarak, çeşitli filtreleme teknikleri analiz edilmiş ve avantajları ve dezavantajları sunulmuştur. Güvenlik analistleri için bu metotların karşılaştırılmalı sınıflandırılması yapılmıştır. Sınıflandırma sonuçları, hem proaktif hem de işbirlikçi modellerin çok az sayıda olduğunu ortaya koymuştur. Bir metodun proaktif olması saldırı yayılmadan engellemesini sağlarken, işbirlikçi olması ağın farklı noktaları hakkında bilgi edinip filtrelere birlikte karar vermelerini sağlamaktadır. Biz de bu sebeple proaktif ve işbirlikçi bir model olan ScoreForCore'u öne sürdük. Bu metot, anlık saldırı trafiği için en uygun öznitelikleri seçen, istatistiksel, paket bazlı bir savunma mekanizmasıdır. Sonuçlarımıza göre bu mekanizmanın legal ve saldırı paketleri üzerindeki başarısı oldukça yüksek çıkmıştır. Öne sürdüğümüz strateji, çekirdek ağlar için yeni gelişmekte olan Yazılım Tabanlı Ağ (YTA) teknolojisi için de uygulanabilir. Bu sebeple, bu çalışmada ilk olarak YTA ortamında literatürdeki en yeni gelişmeleri sunmak için ¸ceşitli savunma mekanizmaları analiz edilmiş ve karşılaştırmalı sınıflandırılması yapılmıştır. Daha sonra da, bizim savunma stratejimiz, YTA ortamında kabiliyetli anahtarlayıcılarla uygulanmıştır. Bu mekanizma (SDNScore), bilinen saldırılar için ¸cok iyi sonuçlar vermiştir. Hatta bilinmeyen saldırılar i¸cin bile 84% başarı göstermiştir. SDNScore modelinde kabiliyetli anahtarlayıcılar ve YTA paradigması arasında bir seçim yapma durumu olduğu için, biz bu modeli geliştirip, tüm yükü yönetici makinaya taşıyan ve kabiliyetli anahtarlayıcılara ihtiyaç duymayan Joint Entropy Based Scoring on SDN (YTA için Ortaklaşa Entropi Tabanlı Skorlama) isimli başka bir mekanizma daha öne sürdük. Sonuçlara göre bu mekanizma YTA ortamı için güçlü bir savunma ortamı sağlamıştır.","In this thesis, we present filtering based defense mechanisms against Distributed Denial of Service (DDoS) attacks for core networks. Initially, several filtering techniques are analyzed and their advantages and disadvantages are presented. A comparative classification of these methods is provided for security analysts. Classification results suggest that there are a few filtering methods that are both proactive and collaborative. Proactivity provides prevention of attacks before it spreads whereas collaboration enables getting knowledge about different points of the network and deciding filters together. Thus, we proposed a proactive and collaborative model called ScoreForCore. It is a statistical packet based defense mechanism that selects the most appropriate attributes for current attack traffic. Our results suggest that the success of the system's behavior on legal and attack packets increased considerably. This strategy is also convenient for current emerging technology for core networks, called Software Defined Networking (SDN). It has several problems related to security that are largely induced by the centralized control paradigm. In that regard, DDoS attacks are specifically valid for SDN environment. Several defense mechanisms in SDN environment are analyzed and comparative classification is provided for rendering the current state of the art in the literature. Then, our defense strategy is applied on SDN environment with capable switches. This mechanism's(SDNScore) results suggest that it gives perfect results for several known attacks and 84% success for an unknown attack. Since there is a trade-off between SDN paradigm and capable switches in SDNScore, we improved it and proposed another model called Joint Entropy based Scoring for SDN (JESS) that carries all burden to the controller and does not need capable switches. The results suggest that it is an elegant defense method for SDN environment."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, doğal dilden anlamsal ilişkilere dönüşüm için bir yaklaşım ortaya koyuyoruz. Bu çalışmada, büyük oranda yapısal olmayan döküman içeriğine odaklandık. Yöntem, Vikipedi'den seçilen cümlelerin dilbilgisel model analizi üzerine temellenmiştir. Düzenli ifadeler, dilbilgisel modelin yaratılması için kullanılmıştır. Cümlelerin dilbilgisel yapısına ek olarak, anlamsal ilişkilerin yaratımı için adlı varlıklar kullanılmıştır. Farklı türlerdeki ilişkiler üzerinde yapılan deney sonuçlarına göre, 0.5 doğruluk payı üzerinden belirlenen sınıra göre %71 ve %82 oranında başarı görülmüştür.","In this thesis, we propose a method for conversion from natural language into semantic relations. In this research, we focus on text written in highly unstructured form. The method is based on analysis of grammatical patterns of the sentences chosen from Wikipedia. Regular expressions are used for the generation of grammatical patterns. In addition to the grammatical structure of sentences, we also made use of the named entities to create semantic relations. Experiments on different types of relations showed that 71% and 82% success rates can be obtained for a threshold of 0.50 correctness rate."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Internet ortamnda bulunan bilgilerin birçoğu, dil, fiziksel engeller, okuryazarlık düzeyi, uzmanlık ve buna benzer birçok engel sebebiyle küresel nüfusun büyük bir kısmı için erişilememekte. İçeriği daha erişilebilir hale getirmek için girişimlere, tercüme edilmesi ya da değiştirilerek daha geniş kitlelerce ulaşılabilmesini sağlamaya çalışmak örnek olarak gösterilebilir. Ancak, bu yöntemler çoğu kez özel derlemeler (Wikipedia) ya da kişilerin bloglar ya da web siteleri üzerinden oluşturduğu alternatif içeriklerle sınırlıdır. Alternatif içeriklerin(renarration) oluşturulabildiği ve bu içeriklerin bulunabilmesinin yanısıra, kullanılabildiği bir altyapıya ihtiyaç bulunmaktadır. Bu tezde, Web üzerindeki veriler için alternatif oluşturulmasına olanak veren bir altyapı tasarlanmıştır. Bu altyapı alternatif verilerin oluşturulmasına ek olarak, veriler arasındaki ilişkilerin de tutulmasına olanak vermektedir. Önerilen altyapı, tez kapsamında geliştirilen bir ontolojiyi kullanmaktadır. Bunlara ek olarak, alternatif veriler oluşturulurken harici kaynakların kullanılmasının yanısıra, bu kaynaklar arasındaki ilişkiler de altyapı kapsamında saklanmaktadır. Bu ilişkilerin saklanması, içeriklerin daha erişilebilir hale gelmesi adına büyük bir potansiyele sahiptir. Önerilen ontoloji ve altyapının ispatı adına bir prototip geliştirilmi³tir.","Much of the content on the Web is not accessible to a large portion of the global population due to barriers such as language, literacy levels, physical impairments, expertise, etc. Attempts to make content more accessible are made by those who translate or otherwise transform material for wider consumption. However, such efforts are often limited to a particular collections (i.e.Wikipedia) or by people who make it a point to create alternatives via blogs and web sites. There is need for a framework that supports the specification of providing alternative narrations (rennarations) in a form that is processable so that they can be located and otherwise utilized. In this thesis we propose a framework for a crowdsourced approach to ren- narating Web documents. This framework aims to support the creation of relations between Web resource elements. A rennaration ontology is created for supporting this framework. Furthermore, it utilizes rennarations with external resources establishing relations among existing resources. Establishing relations has the potential of increasing the utility for further accessibility. A prototype for proof of concept has been built."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, ayrık olasılık dağılımının entropisinin toplanır hata payıyla kestirimi iki farklı kurguda irdelenmektedir. Buna göre bilinmeyen bir olasılık dağılımı p'ye erişim iki farklı sorgu türüyle sağlanmaktadır. Herhangi bir girdisi olmayan SAMP sorgusu p[x] olasılığıyla x döndürmektedir. Girdi olarak x alan PMF sorgusunun ise çıktısı p[x]'dir. SAMP modeli ismini verdiğimiz ilk kurguda p ile sadece SAMP sorgusu vasıtasıyla iletişim sağlanmaktadır. SAMP+PMF modeli olarak adlandırdığımız ikinci kurgudaysa hem SAMP hem de PMF sorguları kullanılabilmektedir. Daha kesin bir ifadeyle, çalışmanın odak noktası olasılık dağılımı p'nin entropisinin yüksek ihtimalle toplanır hata payıyla kestirimi problemidir. Shannon entropisinin kestirimini incelediğimiz bölümde Valiant ve Valiant'ın SAMP modelinde göstermiş olduğu eşleşen alt ve üst sınırları ve Canonne ve Rubinfeld'in SAMP+PMF modelinde inşa etmiş olduğu algoritmayı tasvir ediyoruz. Renyi entropisini incelediğimiz bölümdeyse Acharya ve diğerleri tarafından sunulan üç farklı eşleşen alt ve üst sınır çiftini analiz ediyoruz. Kendi katkımız olarak, önce SAMP+PMF modelinde Shannon entropisinin kestirimi probleminin en az poli-logaritmik sayıda sorgu gerektirdiğini kanıtlayarak Canonne ve Rubinfeld'in sunduğu üst sınırın optimal olduğunu gösteriyoruz. İkinci olarak, yine SAMP+PMF modelinde Renyi entropisinin kestirimi probleminin eşleşen üst ve alt sınırlarını inşa ediyoruz.","We investigate the query complexity of additively estimating entropy of a discrete probability distribution in two settings. Let p be an unknown probability distribution on [n]:= {1, 2, ..., n}, and define two kinds of queries: A SAMP query takes no input and returns x with probability p[x]; a PMF query takes as input x and returns the value p[x]. In the SAMP model of query complexity, the only allowed interaction with p is via SAMP queries. In the SAMP+PMF model, both SAMP and PMF queries are utilized to interact with p. In particular, we consider the task of estimating the entropy of a probability distribution. For the usual Shannon entropy, we review the matching upper and lower bounds established by Valiant and Valiant in the SAMP model, and describe the algorithm constructed by Canonne and Rubinfeld in the SAMP+PMF model. For the Renyi entropy, we analyze three different matching upper and lower bound pairs introduced by Acharya et al. in the SAMP model. We show that at least poly-logarithmic number of queries are necessary to estimate the Shannon entropy in the SAMP+PMF model, matching a recent upper bound of Canonne and Rubinfeld. In addition, we prove matching upper and lower bounds to estimate the Renyi entropy in the SAMP+PMF model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Modern radarlarda kullanılan hedef takip algoritmaları, hedef doğum ve ölümlerini dikkate alarak birden çok hedefi aynı anda takip edebilecek şekilde dizayn edilmektedir. Bu algoritmalar, tek hedef takibi için kullanılan filtrelere veri ilişkilendirme tekniklerinin entegre edilmesiyle geliştirilmiştir. Son dönemde ise veri ilişkilendirme temelli metodlara alternatif olarak rassal sonlu kümeleri kullanan hedef takip algoritmaları ortaya çıkmıştır. Veri ilişkilendirme tekniklerinden farklı olarak, rassal sonlu küme temelli teknikleri hedeflere dayalı bir takip gerçekleştirmezler, onun yerine bütün durum uzayını örten bir hedef yoğunluk fonksiyonunu zaman içerisinde yayarlar ve bu şekilde durum uzayının boyutunu azaltırlar. Bu tezde, öncelikle lineer bir senaryo üzerinde alıcı özellikleri ve hedef yoğunluğundaki değişimin bir rassal sonlu küme temelli teknik olan OHY Filtresinin performansı üzerindeki etkisini araştırıyoruz. Alıcı özelliği parametreleri olarak tespit olasılığı ve parazit oranını; hedef yoğunluğundaki değişim için ise hedef doğum ve ölüm olasılıklarını kullanıyoruz. Bu parametrelerin etkilerini açıklayan bir lineer regresyon modeli de sunuyoruz. Performans ölçütü olarak ise OSPA mesafesini kullanıyoruz. Her bir adımda sonuçlarımızı bir veri ilişkilendirme tekniği ile, en yakın global komşu tekniği ile, her iki tekniğin avantaj ve dezavantajlarını belirlemek için kıyaslıyoruz. İkinci olarak ise lineer olmayan modellerin her iki teknik üzerindeki etkisini araştırıyoruz. Lineer durumdaki ortalama OSPA mesafesini her iki teknik için eşit yapan değerlere sabitleyerek, hangi tekniğin lineer olmayan modellerden daha çok etkilendiğini belirlemek maksadıyla modele nonlineerliği ilave ediyoruz.","Target tracking algorithms adopted in modern radars are designed such that they can track multitarget by considering target births and target deaths. These algorithms are derived by integrating the data association techniques into the single target filters. Recently, target tracking methods exploiting random finite sets have been emerged as an alternative to the data association techniques. Unlike data association methods, random finite set based techniques do not perform tracking based on the targets but instead propagate a target intensity function covering the entire state space in time and thereby decrease the dimension of the state space. In this thesis, firstly on a linear scenario we investigate the effects of receiver characteristics and variation of target intensity on the performance of PHD filter that is a random finite set based filter. The parameters we consider for receiver characteristics are detection probability and false alarm intensity; for variation of target intensity we investigate the effect of target birth and death probabilities. We also provide a linear regression model representing effects of these parameters. As a tracking performance metric we use OSPA distance. At each step, we compare our results with a data association method, global nearest neighbor technique, in order to identify the advantages and disadvantages of the both of the methods. Secondly we investigate the effect of the nonlinear models on both of the methods. By fixing the parameters to the values that results in equal average OSPA distances of both techniques in the linear case, we include nonlinear models in order to identify which technique is effected by nonlinearity more."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Parkinson hastalığı (PH), PH işlevsel normal (PH-KN), PH hafif kognitif bozukluk (PH-HKB) ve PH demans (PHD) olarak sınıflandırılabilmektedir. PH-HKB erken tanısı için noninvazif biyoisaretleyiciler bulmaya ihtiyaç vardır. Proton manyetik rezonans spektroskopik görüntüleme (1H-MRSG), beyindeki metabolik aktivite hakkında spektroskopik bilgi sağlayan bir noninvazif MR tekniğidir. 19 PH-HKB ve 21 PH-KN hastaları bu çalışmaya dahil edildi ve nöropsikolojik testler uygulandı. Tüm hastalarda çoklu voksel 1H-MRSG verileri alındı. İşlenmemiş MRSG verilerinden çıkarılan 1H MR spektroskopik pik parametre haritaları yaratmak ve onları referans T2-ağırlıklı MR görüntüler üzerine yerleştirmek için bir MRSG veri analiz aracı geliştirildi. T2-ağırlıklı görüntüler üzerine yerleştirilen metabolik haritaları bir MNI152 beyin haritasına çakıştırmak için FMRIB yazılım aracı (FSL) kullanıldı. Mann-Whitney sıra toplam testi uygulanarak, PH-HKB ve PH-KN hastalarının metabolik parametreleri ve nöropsikolojik test skorları arasındaki farklar karşılaştırıldı. Friedman testi ile PH-HKB ve PH-KN hastalarında, farklı beyin bölgelerindeki MR spektroskopik metabolit oranların değişimleri incelendi. Nöropsikolojik test skorlarının MR spektroskopik metabolit oranları ile korelasyonlarına Spearman sıra korelasyon katsayısı kullanılarak bakıldı.Çoklu karsılaştırmaları hesaba katınca, PH-HKB ve PH-KN'nın farklı beyin bölgelerinde MRS metabolitlerinde anlamlı farklılıklar yoktu. Buna rağmen, frontal lob ve serebral beyaz maddede metabolit farklılıklara dair bir eğilim görüldü. Nöropsikolojik test skorları ve pek çok spektroskopik parametreler arasında bir korelasyon vardı. Bu çalışmanın sonuçları, ileride başka olası MR temelli biyoişaretleyiciler ile birleştirilerek, PH-HKB tanısı için bir biyoişaretleyici tanımlanmasında kullanılabilir.","Parkinson's disease (PD) patients could be categorized as PD with cognitively normal (PD-CN), PD with mild cognitive impairment (PD-MCI), and PD with dementia (PDD). There is a need for finding noninvasive biomarkers for the early diagnosis of PD-MCI. Proton magnetic resonance spectroscopic imaging (1H-MRSI) is a non-invasive MR technique that provides spectroscopic information about metabolic activity of the brain. 19 patients with PD-MCI and 21 patients with PD-CN were included in this study and neuropsychological tests were performed. Multi-voxel 1H-MRSI data were acquired in all patients. An MRSI data analysis tool was developed to create 1H MR spectroscopic peak parameter maps out of raw MRSI data and overlay them onto reference T2-weighted MR images. FMRIB Software Library (FSL) tool was used to register metabolite maps overlaid onto T2-weighted MR images to an MNI152 brain atlas. A Mann-Whitney rank-sum test was applied to compare the differences of metabolic parameters and neuropsychological test scores between PD-MCI and PD-CN. A Friedman test was used to analyze the MR spectroscopic metabolite ratio variations in different brain regions of PD-MCI and PD-CN. Spearman rank correlation coefficient was used to find correlations of neuropsychological test scores and MRS metabolite ratios. There were no significant differences in MRS metabolite ratios in different brain regions of PD-MCI and PD-CN after accounting for multiple comparisons. However, frontal lobe and cerebral white matter showed trends for metabolic differences. Neuropsychological test scores were correlated with several spectroscopic parameters. The results of this study might enable a definition of a biomarker for PD-MCI diagnosis in the future, when combined with possible other MR based biomarkers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dijital teknolojilerin çevrimiçi iletişim yelpazemizi genişletmesiyle birlikte, metin- sel duygulanım (afekt) analizi bir çok disiplinde önemli bir ilgi odağı haline gelmiştir. Bu alanda İngilizce dili üzerine birçok çalışma yapılmış olsa da, Türkçe diline yönelik oldukça kısıtlı sayıda çalışma bulunmaktadır. Bunun bir nedeni duygulanım analizi için gereken sözlüksel (lexical) kaynakların ve sistem değerlendirmesi için gerekli olan referans derlemlerin (corpora) yetersiz olmasıdır. Bu çalışmada, birçok aracı birleştirerek Türkçe iletişim metinlerinin sürekli ve boyutsal duygulanım analizini gerçekleştirecek bir yaklaşım sunuyoruz. Twitter verisi, film eleştirileri ve lise öğrencilerine yönelik öğretmen yorumları, çevrimiçi sohbet ve psikoterapi kayıtları gibi birçok Türkçe derlemler üzerinde bu modeli test ettik. Çevrimiçi sohbet kayıtlarını analiz etmek, dilbilgisel düzensizlikler, kısaltmalar, yazım yanlışları ve yapısal olmayan bir dil kullanımı gibi sorunları da beraberinde getirmektedir. Bu problemlerin üstesinden gelebilmek amacıyla birçok ön veri işleme tekniği gerçekleştirdik. Sonrasında, İngilizce için hazırlanmış bir duygulanımsal kelime sözlüğünü Türkçe'ye adapte ederek ve eş anlamlı kelime gruplarıyla genişleterek, memnuniyet (valence), uyarılma düzeyi (arousal) ve baskınlık (dominance) boyutları için ölçeklendirilmiş 15,200 kelimelik bir kaynak elde ettik. Aynı zamanda, bir cümlenin genel duygulanım durumunu yakalayabilmek için sık kullanılan kısaltmaların, emotikonların, özel isimlerin, pekiştirici kelimelerin birer listesini bazı dilsel sinyallerle birlikte kullandık. Sohbet kayıtları üzerine duygulanımsal bir değerlendirme refaransı oluşturabilmek için bir cümle işaretleme anketi düzenledik. Son olarak elde ettiğimiz sonuçlar kural ve kelime bazlı modelimizin faydalı olduğunu göstermekle birlikte birçok farklı aşama hala geliştirilmeye açıktır.","As digital technologies expanded our range of online communication, textual affect analysis become the focus of considerable interest in several disciplines. While many studies have been conducted in English language, there are only a few tools specific for the Turkish language. One reason for that is the lack of lexical resources for affect analysis and annotated corpora for an accurate evaluation. In this thesis, we develop an approach for continuous and dimensional affect analysis of Turkish communications by combining several tools. We conduct experiments on various text corpora in Turkish including online multi-party chat records, psychotherapy records, Twitter data, movie reviews, and teachers' comments on high school students. Analyzing such texts brings challenges like non-standard word usage, grammatical irregularities, abbreviation usage, and spelling mistakes. We propose several pre-processing steps to deal with these. Then, we adapt an affective word dictionary from English to Turkish, and by expanding it with synsets, obtain 15,200 words with annotations for valence, arousal, and dominance. We also employ a list of frequently used abbreviations, emoticons, interjections, modifiers (intensifiers and diminishers), and other linguistic indicators to capture the overall affective state at the sentence level. We recruit and train annotators to obtain affective ground truth specifically for multi-party chat records. Our results show that the proposed system is useful, yet there is much room for improvement at different stages."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar Destekli teşhis sistemleri son yıllarda sıklıkla çalışılan bir konu olmuştur. Bu sistemler doktorlara teşhis koyma esnasında yardımcı olmayı amaçlar. Özellikle erken teşhisin önemli olduğu hastalıklarda bu sistemlerin kullanımı erken teşhis olasılığını artırır. Bu çalışmanın amacı karşılıklı bilgi miktarı üzerine kurulu bir yöntemi tanıtmak ve örnek olarak Alzheimer hasatları verileri üzerinde ilk deneyleri yapmaktır. Önerilen bu sistemde her bir girdi için üç boyutlu PET görüntülerinin oluştuğu bir data set kullanılmaktadır. Karşılıklı bilgi miktarı kullanılarak bu girdilerin birbirlerine benzerlik miktarı ölçülür. Her bir girdi data setteki diğer bütün girdilerle karşılaştırılır ve bir karar indeksi hesaplanır. Bu indekse göre bur girdinin hastalığa sahip olup olmadığına karar verilir. Sistemin performansı hesaplandığı zaman kurulan sistemin görüntülerin hasta veya normal olduklarını ayırt edebildiği gözlemlenmiştir. Kurulan sistem ve kullanılan metot gayet basit, kolaylıkla uygulanabilir ve klinik alanda kullanılabilecek kadar hızlıdır.","Computer aided diagnosis (CAD) is one of the most important topic in recent years since the systems are able to provide a second reliable opinion to physicians and early diagnosis with these systems are possible. In this study we aim to construct a system for the detection of Alzheimer's disease (AD) using PET images from a database. The CAD system includes a database consisting of a 3D PET image for every query. Via using a similarity metric namely mutual information(MI), every query compares to all other query in database. According to their similarity results, a decision index is calculated. The decision index demonstrate presence or absence of AD. The system was developed and evaluated using two different databases extracted from Alzheimer's disease Neuroimaging Initiative (ADNI) database. All normal and Alzheimer's images are stored and ordered in database. First database consists of 259 normal and 138 AD patient whereas second database consists of 102 normal and 95 AD patient. Main difference of two database is registration. Images in second database are warped with talairach atlas. CAD performance was evaluated using Receiver Operating Characteristic analysis. For every query, a decision index was calculated. According to our results we observed that accuracy and speed of the CAD system is affected by certain parameters. The method proposed in the article is adequate to distinguish the disease. The mutual information method is very simple, applicable and fast enough to use in clinic area."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Doğal dil işleme alanında çok sayıda anahtar kelime çıkarma ve metin özetleme algoritmaları vardır, bunlardan bazılarını bu tezde tartıştık. Methodları anlamak için otomatik metin özetleme üzerinde bir araştırma ile başladık. Ayrıca Word2Vec ve PageRank algoritmalarını kullanarak anahtar kelime çıkartmak için yeni ve etkili bir yöntem önerdik. Bu tezde farklı metin tipleri üzerinde, hem tek metin hem de çoklu metin özetlemede kullanılan iki farklı grafik tabanlı metin özetleme algoritmasını araştırdık, çoklu metin özetlemede LexRank ve tekli metin özetlemede TextRank kullandık. Neredeyse tüm anahtar kelime çıkartma algoritmaları vektör uzayında kelimeleri tanımlamak için yüksek boyutlu vektörler kullanır. Biz metinden otomatik anahtar kelime çıkartma problemine öngörmesiz öğrenme işi olarak yaklaştık ve metindeki her kelimeyi düşük boyutlu vektör olarak ele aldık. Word2Vec ve PageRank algoritmalarını kullanarak yeni bir anahtar kelime çıkartma yöntemi geliştirdik. Bizim sonuçlarımız gösteriyor ki özetleme algoritmalarımız haber metinleri üzerinde en iyi sonuç verirken kısa öyküler için daha az optimal sonuçlar vermektedir. Bunun yanında hukuki metinler üzerindede kullanılabilir sonuçlar elde ettik. Öte yandan, one- hot temsili ve Word2Vec temsili kullanarak bu algoritmaların verdikleri sonuçların farklarını karşılaştırdık ama biz bu yöntemler arasında anlamlı bir farklılık gözlemleyemedik.","There is a large number of algorithms for keyword extraction and text summarization in natural language processing, as we discuss some of these in this thesis. We started with a survey on automatic text summarization in order to understand the state of the art methods. Also we proposed a new and efficient method for keyword extraction task using Word2Vec and PageRank algorithms. In this thesis, we investigated two different graph based text summarization algorithms for both single and multi-document settings on different types of texts where we used LexRank for multi-document summarization and TextRank for single document summarization. We also investigated a number of keyword extraction methods. Almost every keyword extraction method use high dimensional vectors to define words in a vector space. We approached the problem of automatic extraction of keywords from text as a unsupervised learning task and we treat each word in the document as a low dimensional vector. We developed a new keyword extraction method using Word2Vec and PageRank algorithms. Our results show that summarization algorithms give best result on news texts, usable results on legal texts while they give less than optimal results for short stories. On the other hand, we also compared differences in using one-hot-representation and Word2Vec representation but we observed no significant differences between these methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda, anlamsal benzerlik yöntemlerinden, metin getirimi, otomatik özetleme, belge sınıflandırma gibi doğal dil işlemesi problemlerinin bir çok alanının önemli bir parçası olarak yararlanılmaktadır. Anlamsal bilginin katılması, metnin anlaşılması ve yapılandırılması için güçlü bir araçtır. Metin madenciliğinden yararlanan çalışma alanları arasında, biyomedikal literatürü kendine özgü dilinden dolayı en zorlu alanlardan birisidir. Biyomedikal literatürün karmaşık doğasının sonucu olarak, alana özgü uyarlamalara olan gereksinim kaçınılmazdır. Biyomedikal alan kapsamında, bu alana özgü bir çok kelimeler arası anlamsal metin benzerliği yöntemi bulunmaktadır. Ancak, bilgimiz çerçevesinde, literatürde biyomedikal alana özgü geliştirilmiş cümleler arası anlamsal benzerlik hesaplama yöntemi bulunmamaktadır. Bunun yanı sıra, yapmış oldugumuz deneyler, alandan bağımsız olarak geliştirilmiş en son çalışmaların başarısız sonuçlar ürettiğini göstermektedir. Çalışmamızda, biyomedikal alana özgü cümleler arası anlamsal benzerlik ölçümü için dağılımsal cümle vektörlerine dayanan bir yaklaşım, genel ve alana özgü ontolojileri kullanan bir yöntem ve üst düzey öznitelikler ile eğitilmis güdümlü makine öğrenmesi tabanlı bir yaklaşım önerilmektedir. Önerilen yöntemler biyomedikal alandan 100 tane cümle ikilisinden olusan elle etiketlenmiş veri kümesi üzerinde değerlendirilmiştir. Deney sonuçları, önermiş olduğumuz güdümlü anlamsal benzerlik hesaplayıcı yöntemimizin, alandan bağımsız sistemlere kıyasla en yüksek başarıyı elde ettiğini ve Pearson Korelasyon metriğine göre %42.6 başarıyı arttırdığını göstermektedir.","During the last decades, the use of semantic text similarity has been adopted as a major component in many Natural Language Processing tasks, including text retrieval, summarization, and document categorization. Integration of semantic information acts as a powerful tool for a better understanding and structuring of text. Among the many domains that benefit from text mining studies, biomedical literature is one of the most challenging areas because of its domain-specific language. As an inevitable result of the complex nature of the biomedical literature, domain-specific adaptations are crucial requirements. There are several semantic text similarity approaches that have been applied on the word-level. However, and to the best of our knowledge, there has not been any research on sentence-level semantic similarity in the biomedical domain. Furthermore, our experimental results revealed that domain-independent state-of-theart approaches in sentence-level semantic similarity do not effectively cover biomedical knowledge and produce poor results. In this study, we propose several different approaches for domain-specific semantic sentence-level similarity computation, including measures utilizing distributional vector representations of sentences, methods combining general and domain specific ontologies, as well as a supervised approach exploiting high-level features. Our proposed methods are evaluated using a manually annotated data set which consists of 100 sentence pairs from biomedical literature. The experiments showed that the supervised semantic similarity computation approach obtained the best performance and improved over the previous domain-independent systems up to 42.6% in terms of the Pearson correlation metric."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevrim içi sosyal ağlarda mahremiyetin korunması, bu ağlarda kişisel bilgilerini paylaşan insanların çoğalmasıyla daha da önemli hale gelmektedir. Herhangi bir sosyal ağ kullanıcısı kolaylıkla başka bir kullanıcıyı ilgilendiren bir paylaşımda blunabilir. Fakat, paylaşım ile bağlantılı olan kullanıcıların mahremiyet kısıtları birbirinden farklılık gösterebilir ve bu durum mahremiyet ihlallerine neden olabilir. Bu nedenle tüm bağlantılı kullanıcılar, mahremiyetlerini korumak için kendi aralarında bir müzakere gerçekleştirmeli ve kendilerini ifade etmelidir. Bu çalışma, Varsayım-Tabanlı Münakaşa kullanarak kullanıcıların bir paylaşım üzerine müzakere etmelerini sağlayan PriArg'ı sunmaktadır. Bir çevrimiçi sosyal ağdaki her kullanıcı bir etmen tarafından temsil edilmektedir. Her bir etmen kullanıcıların sahip olduğu bilgileri ve mahremiyet kısıtlarını içeren bir ontoloji ile donatılmıştır. Bu sayede, her etmen kendi kullanıcısının mahremiyet kısıtlarından haberdardır ve onun yerine hareket edebilir. Bir etmen bir paylaşım yapmak istediğinde, bu etmen ile diğer tüm bağlantılı etmenler arasında bir münakaşa gerçekleşir. Etmenler, kendilerini ifade edebilmek ve karşılarındaki etmeni ikna edebilmek için birbirlerine argümanlar sağlarlar. Münakaşa sonunda paylaşımın yapılıp yapılmamasına karar vermek için, münakaşa sırasında sağlanan tüm bilgiler alınır ve bir Varsayım-Tabanlı Münakaşa motoruna verilir. Etmenler gerek duydukları her bilgiyi kendi ontolojilerinde bulamayabilirler. Bu durumda, sosyal ağ içerisindeki diğer etmenlere danışabilirler. Çalışmamız, PriArg'ın gerçek dünya senaryolarına uygulanabilirliği gösterilerek değerlendirilmiştir. Bunun yanısıra bir kişisel mülakat ve bir çevrim içi anket yürütülerek PriArg sonuçları kullanıcı beklentileri ile karşılaştırılmıştır. Son olarak, literatürde bulunan benzer çalışmalar ve PriArg karşılaştırılmıştır.","Preserving privacy in online social networks (OSNs) is becoming increasingly important as more people expose their personal information in those networks. A social network user can easily share a post concerning other users. However, privacy constraints of these relevant users may be different from each other so that privacy violations occur. Therefore, all relevant users must be able to engage in a discussion and express themselves, so that they can protect their privacy. We propose PriArg to enable relevant users discuss on a post using Assumption-Based Argumentation (ABA). We present each user in an OSN with an agent, which is equipped with an ontology. Ontologies involve the social network knowledge of users as well as their privacy constraints. Hence, agents are fully aware of the privacy constraints of their user and can act on behalf of them. When an agent wants to share a post, an argumentation session starts between the agent and other relevant agents. They provide each other arguments to express themselves and to convince other agents that their claim is true. At the end of the argumentation, we use an ABA engine to find whether sharing the post is justified according to the provided arguments. Agents may not have necessary information in their ontology to support their arguments. In this case, they can ask other agents in the social network for information. We evaluate our approach by showing its applicability with the real world scenarios. Moreover, we conduct a survey and an interview to compare the PriArg results with user expectations. At last, we compare the related work in the literature with PriArg."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Proteinler arası etkileşimlerin birçok biyolojik süreçte aktif rol oynaması, aralarındaki fiziksel etkileşimlere dair bilgileri de fazlasıyla önemli kılıyor. Proteinler arası etkileşimleri doğrulamak için kullanılan deneysel teknikler, etkileşimlerin güvenilirliğini değerlendirebilmek için oldukça önemli. Proteinler arası etkileşimlere ve bu etkileşimleri tespit etmek için kullanılan deneysel yöntemlere dair verilerin önemli bir kısmı sadece bilimsel yayınlarda gömülü durumda bulunuyor. Bu çalışmada, tam metin makalelerde, proteinler arası fiziksel etkileşimleri tespit etmek için kullanılan deneysel yöntemlerin anlatıldığı pasajları belirleme problemine bilgiye erişim alanının arama problemi olarak yaklaşılıyor. Temel sistem, Proteomics Standard Initiative - Molecular Interactions (PSI-MI) ontolojisinde yer alan deneysel yöntem isimleri derlenerek yaratılan sorguların metin içerisinde eşleştirilmesine dayanıyor. Bu temel sistem sorgularının, alakalı terimler ile genişletilmesine dayalı iki yeni yöntem daha geliştirildi. İlk yöntem gözetimli bir yaklaşım olup, terim sıklığı-ilgililik sıklığı (tf.rf) metriğinin, el ile etiketleyip bu çalışmanın ilave çıktısı olarak yayınladığımız 30 makalelik veri kümesinin 13 makalelik eğitim alt kümesi üzerinde uygulanması ile en belirgin terimlerin sorgulara eklenmesine dayanıyor. Bu yöntemin 17 makalelik test kümesi üzerinde değerlendirilmesi sonucu temel sisteme kıyasla bulma skorunda daha başarılı oldugu gözlenmiştir. İkinci yöntem ise gözetimsiz bir yaklaşım olup deneysel yöntem isimleri için öğrenilmiş kelime temsilleri kullanılarak sorgular genişletilmiştir. Bu yöntemin 17 makalelik test kümesi üzerinde değerlendirilmesi sonucu temel sisteme kıyasla bulma ve F-ölçütü skorlarında daha başarılı olduğu gözlenmiştir.","Information regarding the physical interactions among proteins is crucial, since protein-protein interactions (PPIs) are central for many biological processes. The experimental techniques used to verify PPIs are also vital for characterizing and assessing the reliability of the identified PPIs. A lot of information about PPIs and the experimental methods are only available in the text of the scientific publications that report them. In this thesis, we approach the problem of identifying passages with experimental methods for physical interactions between proteins as an information retrieval search task. The baseline system is based on query matching, where the queries are generated by utilizing the names (including synonyms) of the experimental methods in the Proteomics Standard Initiative - Molecular Interactions (PSI-MI) ontology. We propose two methods, where the baseline queries are expanded by including additional relevant terms. The first method is a supervised approach, where the most salient terms for each experimental method are obtained by using the term frequency-relevance frequency (tf.rf) metric over $13$ articles from our manually annotated data set of $30$ full text articles, which is made publicly available as an additional contribution of this study. The first method is evaluated on the test set consisting of the remaining $17$ articles and achieves better recall score compared to the baseline. On the other hand, the second method is an unsupervised approach, where the queries for each experimental method are expanded by using the word embeddings of the names of the experimental methods in the PSI-MI ontology. The second method achieves better recall and F-measure scores over the test set compared to the baseline."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Grafik İşleme Üniteleri (GİÜ'ler) son zamanlarda genel amaçlı uygulamaların paralelleştirilmesi konusunda popüler olmuştur. GİÜ'ler çok sayıda güçlü işlemciden oluşup hazır paket olarak sunulmaktadır. Gerçeklenebilirlik Problemi (GP) bilinen en eski NP-karmaşıklık problemlerinden biridir. GP çözümünün otomatik teorem ispatı, devre tasarımı, yapay zeka ve yazılım doğrulama gibi çeşitli uygulama alanları vardır. GP'yi deneysel olarak çözen birçok algoritma olmasına karşın, bunların tüm GP örnekleri üzerinde etkili olduğuna inanılmamaktadır. Bu tezde, GP'yi çözmek için algoritma seçim mekanizması olarak yapay sinir ağlarını kullanan yeni bir GİÜ tabanlı paralel bir yaklaşım öneriyoruz. Bizim sistemimizde, nihai sonuca ulaşmak için yapılan deneyler üzerinde oluşturulan alt problemlerin, doğru algoritmalar (çözücüler) seçilerek çözülmesi ile 3 kata kadar hızlanmalar olduğunu gösteriyoruz.","Graphics Processing Units (GPUs) have become popular for parallelization of general purpose applications recently. GPUs are composed of huge number of powerful processors in a readily available package. The Satisability Problem (SAT) is one of the earliest NP-complete problems. The solution to SAT has various application areas, including automated theorem proving, circuit design, artificial intelligence, and software verification. Although many algorithms exist to experimentally solve SAT, they are not believed to be efficient on all SAT instances. In this thesis, we propose a novel GPU based parallel approach using neural networks as the algorithm selection mechanism to solve the SAT. We demonstrate speedups of up to 3 times on benchmarks by choosing the correct algorithms (solvers) to solve sub problems to reach the final result in our system."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Beynin çalışma şeklini daha iyi anlayabilmek için beynin bölümleri arasındaki ilişkileri anlamak çok önemlidir. Beynin her bir bölümü birbiri ile kimyasal veya fonksiyonel etkileşim halindedir ve bu etkileşimleri inceleyen çok fazla sayıda çalışma bulunmaktadır. Bu çalışmalarda yer alan beyin bölümleri arasındaki ilişkiler, çevrimiçi erişilebilir yayınlanmış makalelerde yer almaktadır. Metin madenciliği teknikleri kullanılarak özellikli ilişkilerin çıkartılması bize ilişkiler hakkındaki büyük resmi görmemiz konusunda yardımcı olmaktadır. Biz de bu çalışmamızda, doğal dil işleme (NLP) teknikleri kullanarak beynin bölümleri arasındaki ilişkileri yayınlanmış makalelerden çıkartmayı hedeflemekteyiz. Çalışmamızda ""Paraventricular Thalamic Nucleus (PVT)"" adı verilen beyin bölümünün ilişkileri üzerinde yoğunlaşıyoruz. Dilbilimsel bir yaklaşımla, örüntülere bağlı olarak ilişkilerin yer aldığı cümleler seçilerek, daha sonrasında bu cümleler üzerinde bağlılık ayrıştırıcı ve öğe ayrıştırıcı kullanılarak ilgili beyin bölümleri ve birbirleriyle ilişkileri çıkartılmıştır. Çalışmamızda, ilişkilerin yanısıra bu ilişkilerin yönü de tayin edilerek beyin bölümlerinin birbiriyle bağlantılarını gösteren bir bağlantı grafiği sunulmaktadır. Geliştirdiğimiz sistem, Whitetext projesinin derlemi üzerinde değerlendirildikten sonra aynı metodlar PVT beyin bölümünün bağlantı grafiğini çıkartma ve analiz etme konularında kullanılmaktadır. PVT, uyarılma, isteklendirme, ilaç arama davranışı ve dikkat gibi çok sayıda işlev üzerinde etkisi olduğu inanılan önemli bir beyin bölümüdür. Çalışmamızın sonuçlarının göstereceği üzere PVT beyin bölümü davranış değerlendirmesi konusunda yeni bir araştırma odağı olabilir.","Identifying the relations among different regions of the brain is vital for a better understanding of how the brain functions. While a large number of studies have investigated the neuroanatomical and neurochemical connections among brain structures, their specific findings are found in publications scattered over a large number of years and different types of publications. Text mining techniques have provided the means to extract specific types of information from a large number of publications with the aim of presenting a larger, if not necessarily an exhaustive picture. By using natural language processing techniques, the present study aims to identify relations among brain regions in general and relations relevant to the paraventricular nucleus of the thalamus (PVT) in particular. We introduce a linguistically motivated approach based on patterns defined over the constituency and dependency parse trees of sentences. Besides the presence of a relation between a pair of brain regions, the proposed method also identifies the directionality of the relation, which enables the creation and analysis of a directional brain region connectivity graph. The approach is evaluated over the manually annotated data sets of the WhiteText Project. In addition, as a case study, the method is applied to extract and analyze the connectivity graph of PVT, which is an important brain region that is considered to influence many functions ranging from arousal, motivation, and drug-seeking behavior to attention. The results of the PVT connectivity graph show that PVT may be a new target of research in mood assessment."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmamızda dilin oluşumundaki farklılıkları araştırdık. Dilin ortaya çıkışı ile ilgili temel, oyun teorisi modelleri bir çok çalışmada ortaya koyulmuş ve kullanılmıştır. Bu çalışmalarda en sık karşılaşılan varsayım toplumdaki herkes ile anlaşabilmenin evrimsel üstünlük sağlayacağı yönündedir. Fakat, toplumdaki herkesle iletişim içinde olmak gerçekte çok mümkün görünmemektedir, çünkü hafıza ve yerleşim gibi sınırlamalar bireyleri kısıtlamaktadır. Dolayısıyla toplum, her bireyin toplumun sadece belli bir kısmı ile iletişim halinde olacağı şekilde organize edilmelidir. Bizim modelimizde, bireyler dilin aktarımından sorumlu olan öğretmenleri ebeveynlerinin komşularından seçmektedir ve bu komşuluk ilişkileri toplumda bir sosyal ağ oluşmasına neden olmaktadır. Bulgularımızdan bazıları, komşu çevresinin büyüklüğü ile toplam oluşan farklı dil sayısının, tüm toplumun büyüklüğünden bağımsız olarak, ilişkili olduğu yönündedir. Üstelik, komşu seçiminde dil yakınlığı gözetmenin, fiziksel yakınlık gözetmeye göre herhangi bir evrimsel avantaj sağlamadığını gözlemledik. Sonuç olarak, biz bu çalışmayı dildeki farklılıkların oluşumunu anlamak adına önemli bir katkı olarak görüyoruz.","In this work, we investigated the emergence of diversity in language. Fundamental game theoretical model for emergence of language has been established and used in several studies. In these studies most basic assumption is that understanding everyone in the population gives evolutionary advantage to an agent. However, being in interaction with everyone is not achievable in reality where various limited resources such as memory and physical availability bind agents. Thus population should be organized in a way that each agent can interact only some percentage of population. In our model, agents select their teachers, who are responsible for the transmission of language, from neighbors of their parents, which forms a social network in population. Our findings include that emerged number of different languages in population is related to the percentage size of neighborhood and is independent of population size. Furthermore, we observe that seeking language-wise similarity in teacher selection makes no evolutionary difference in emergence of language, instead of seeking physical closeness. As a result, we see this study as an important contribution towards understanding the emergence of diversity in languages."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otomatik video görüntüsü işleme yöntemleri özellikle insan bilgisayar etkileşimini iyileştirme amacı ile öncem kazanmıştır. Video görüntülerinin analizinde özellikle zor bir problem görüntüdeki kişilerin duygu durumunu kestirebilmektir. Yüz ifadesi sınıflandırmanın uzaktan eğitim sistemlerinden Asperger sendromlu kişilerin kullanacağı uygulamalara ve güvenlik uygulamalarına uzanan geniş uygulama alanı mevcuttur. Bu tez çalışması kapsamında kontrollü ve gerçekçi koşullar altında toplanmış video görüntülerinden yüz ifadesi tanıma problemini ele alıyoruz. Yakın zamanda yapılan yüz bulma, hizalama, video öznitelik çıkartma ve sınıflandırma yaklaşımlarını inceledikten sonra yeni bir yöntem öneriyoruz. Bu yöntemde iyileştirilmiş yoğun izlekler yaklaşımını yüz hizalama sonrası uyguluyor, geometrik öznitelikler ve LGBT-TOP özniteliklerini Fisher vektörleri ile kodlayarak ekstrem öğrenme makineleri sınıflandırıcılarına veriyoruz. İyileştirilmiş yoğun izlekler yaklaşımı bu çalışma ile ilk defa yüz ifadesi tanıma problemine uygulanmıştır. Yaklaşımın her aşamasını karşılaştırmalı deneylerle, CK+ ve EmotiW 2015 veritabanları üzerinde sınıyoruz. Bu veritabanlarından birincisi kontrollü kayıt koşullarında toplanmış, nötr yüzden ifadeli yüzlere geçişleri içermektedir. İkinci veritabanı ise gerçekçi koşullarda, doğal ifadeler, zor ışıklandırma ve karmaşık arkaplan görüntüleri içeren film klipleridir. CK+ veritabanında 94.80\% (aşağılama ifadesi olmadan 95.79\%) ile en iyi sonuçlardan birini elde ediyoruz. EmotiW 2015 veritabanında elde ettiğimiz 43.39\% sınıflandırma başarısı ise yarışma temel sonucundan oldukça yüksektir. İki veritabanında da elde ettiğimiz iyi sonuçlar kullandığımız hizalama ve öznitelik çıkartma yöntemlerinin başarılı bir sistem ortaya koyduğunu göstermiştir.","Automatic video data analysis has been a growing interest in order to improve human computer interaction. One of the most challenging parts in video analysis is the ability of evaluating human emotion robustly. Vast applications of human facial expression recognition can be seen everywhere from educational systems to treatment of Asperger's and surveillance. In this thesis, we explore facial expression recognition on both laboratory and realistic videos. After studying recent works about face detection, facial alignment, video description and classification, we present our novel approach in, which our proposed pipeline including facial alignment in combination with improved dense trajectory, geometric, encoded with Fisher vector encoding and LGBP-TOP features are fed to extreme learning machine. It is the first time that improved dense trajectory features are used in facial expression recognition. Furthermore, we extensively study each step of our pipeline in a comparative manner. We evaluate our approach on CK+ and EmotiW 2015 challenge datasets. Videos in first dataset are captured in laboratory settings and start from neutral state and end with peak expression while the second one is selected from movies with realistic conditions, spontaneous emotions, complicated background and challenging illumination variations. On Ck+ dataset, we obtained 94.80\% and 95.79\% (without contempt) accuracy, which is among the best results obtained on the CK+. On EmotiW 2015 challenge dataset, we got 43.39\% accuracy, which is higher than the baseline of the challenge considerably. In both datasets we were able to obtain the state-of-the-art results. Our results show that using appropriate pipeline of face alignment combined with efficient visual descriptors can result in a robust system with high ability of recognition."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nakit ile ilgili maliyetler Otomatik Vezne Makinesi yönetim maliyetinin önemli bir kısmını oluşturmaktadır. Müşteri memnuniyetini sağlamak ve ihtiyaç fazlası nakitten günlük faiz ile bankaya ek gelir sağlayabilmek için belirli aralıklarla nakit yüklemesi veya alınması gerekmektedir. Standart makinelerin tersine geri dönüşümlü adı verilen yeni tip Otomatik Vezne Makinelerinde para yatırma ve çekme işlemi aynı para kasedi üzerinden yapılmakta ve bu özellik nakit yönetimine yeni kısıtlamalar getirmektedir. Bununla birlikte geri dönüşümlü makineler yüksek maliyetli olduğu için planlaması dikkatli yapılmalıdır. Bu çalışmada, amacımız otomatik vezne makinesi ağlarını nakdi maliyetler açısından optimize etmektir. Makineye ne zaman, ne miktarda para yükleneceği ve nakit dağıtımında hangi rotanın izleneceğine bütünleşik olarak karar veren optimizasyon problemi tamsayı lineer programlama olarak formüle edilmiştir. Aynı zamanda nakit maliyetini azaltmak amacıyla hangi makinelerin geri dönüşümlü makineler ile değiştirilmesi gerektiği kararı da çalışmamızın çıktıları arasındadır. Otomatik Vezne Makinesi nakit yönetimi problemi için polinom zamanlı buluşsal algoritma tasarlanmış ve optimizasyon formülasyonu ile nakit maliyeti ve geri dönüşümlü makine ile değiştirme kararı açısından karşılaştırma yapılmıştır. Performans sonuçlarına göre tasarlanan buluşsal algoritmanın pratikte kullanılabilir olduğu görülmüştür.","Cash related costs constitute a large portion of management cost of an Automated Teller Machine (ATM) network. Cash should be loaded to or taken from ATM devices in certain intervals in order to both meet customer satisfaction and to be able to generate additional revenue from excess cash through daily interest rates. Unlike classical ATMs, new generation ATMs have a single tape for cash withdrawal and deposit; this property imposes new restrictions on ATM cash management. Moreover, recycle ATMs are costly and hence their deployment should be planned carefully. In this thesis, our aim is to optimize the ATM networks in terms of cash related costs. We formulate an optimization problem as an integer linear program, which jointly decides on when to visit an ATM, how much amount of money to load to which ATM and which road should be followed for the distribution of cash to the ATMs. We also decide on which ATMs in the network should be replaced by a recycle ATM. We then propose a polynomial-time heuristic algorithm and compare it with the optimization formulation in terms of cash cost and the recycle ATM decision. We demonstrate through performance evaluation that our heuristic algorithm is suitable for practical implementation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezin ana katkısı çeşitli fiziksel egzersiz hareketlerini gerçekleştirirken çocukları, gerçek zamanlı geri bildirim, rehberlik ve teşvik sağlayarak motive eden bir sosyal destekli insan robot etkileşimi sisteminin tasarımı ve kodlanmasıdır. Ön testler rehabilitasyon tedavisi kapsamında yapılmış olmasına rağmen, bu tarz egzersiz faaliyetlerini teşvik etme sisteminin potansiyelinin fizik tedavi alanının ötesinde olmasından ötürü, gerçek zamanlı ̧çalışan sistem, çocukları sağlıklarını iyileştirme için ve fiziksel olarak aktif olmaları için motive eden bir egzersiz koçu gibi davranacak şekilde tasarlanmıştır. Gerçek zamanlı sistem tasarım aşamasında egzersiz koçu ve çocuklar eşliğinde yapılan bir çok ön çalışma ile test edilmiştir. Ayrıca, gerçek zamanlı sosyal destekli robotik egzersiz sisteminin etkinliğini ve fizibilitesini çeşitli performans ve değerlendirme ölçüleri aracılığıyla test etmek için 4 ve 12 yaş arası 19 sağlıklı çocuk ile deneysel bir çalışma yürütülmüştür. Çalışmanın sonuçları sistemin, çocukları fiziksel egzersizleri tamamlamaları için motive etme ve çocukların fiziksel egzersizleri tamamlamalarına yardım etme konularındaki etkinliğini doğrulamıştır. Çocuklar robot antrenör eşliğindeki etkileşim oturumları boyunca fiziksel egzersiz yapmış olup, etkileşim sonrası sorulan anket aracılığıyla, etkileşimi; eğlencelilik açısından, egzersiz robotunu; sosyal sempati, arkadaşlık ve toplumsal varlık açılarından olumlu ve/veya yüksek notlarla puanlamışlardır.","The main contribution of this thesis is the design and implementation of an autonomous socially assistive human robot interaction system to engage children in performing several physical exercise motions by providing real-time feedback, guidance, and encouragement. Preliminary offline tests were done within a rehabilitation therapy context but since the potential of the system to encourage such exercise activities is beyond the physical therapy fields, we designed an online system to behave as an exercise coach that can motivate children to start and continue improving their health and become physically active. The online system was tested in several preliminary experiments with an exercise coach and children during the design process. Furthermore, an experimental study was conducted with 19 healthy children aged between 4 and 12 to test the feasibility and the effectiveness of our online Socially Assistive Robotic (SAR) exercise system across a variety of performance and evaluation measures. The results of the study validate the effectiveness of the system in motivating and helping children to complete physical exercises. The children engaged in physical ex- ercise throughout the interaction sessions with a robot coach and rated the interaction highly in terms of enjoyableness, and rated the robot exercise coach highly in terms of social attraction, social presence, and companionship via a questionnaire answered after each session."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Amaçlı topluluklar, belirli hedeflere ulaşmak için müşterek çalışan insan gruplarıdır. Bu topluluklar iletişim, koordinasyon ve durum takibi için genellikle sosyal ağ uygulamaları kullanırlar. Twitter ve Facebook bu tarz amaçlarla yoğun olarak kullanılmaktadır. Bu uygulamalar genel iletişim ihtiyaçlarını karşılar, fakat her topluluğun farklı bilgi ve bilgi işleme ihtiyaçları vardır. Örneğin, bir doğal afet müdahale topluluğu, felaketzedelere ulaştırılması gereken hizmet ve eşyalara ilgilenirken, hayvan haklarıyla ilgilenen başka bir topluluk, hayvanların kayıt altına alınması ve sağlık hizmetlerinin sağlanmasıyla ilgilenecektir. Bu toplulukların bilgi ihtiyaçları açık bir şekilde çok farklıdır. Belirli alanlara özel bilgi ve bilgi işleme ihtiyaçlarını gidermek için genellikle ihtiyaçlara göre şekillendirilmiş özel uygulamalara ihtiyaç duyulur. Bu tarz uygulamalar geliştirilmek yazılım becerileri isteyen bir iştir. Oysa, bu tarz ihtiyaçları belirtmek için kolay yollar sağlansaydı, birçok bilgi tipi son kullanıcılar tarafından tarif edilebilirdi. Bu çalışmada, son kullanıcıların amaçlı topluluklara yönelik Web uygulamaları üretmelerini sağlayan, ontoloji tabanlı bir yapı sunuyoruz. Bu yapı, sanal toplulukları özgün bilgi ve eylem çeşitleri ile modelleyen Purposeful Online Communities (POC) ontolojisini temel alır. Bu ontolojinin kullanımı örnek topluluklarla gösterilmiştir.","A purposeful community is a group of individuals whose actions help the community reach a set of goals. Such communities often use social network applications to communicate, coordinate, and track their activities. Twitter and Facebook are widely used for such purposes. These applications provide generic support for communication, whereas every community has different information and processing needs. For example, a community who is responding to a natural disaster will be concerned about the services and goods that need to reach victims or a community who is interested in animal rights will be interested in documenting various animals and making health services available. Clearly, the type of information for these communities is very different. Providing support for domain specific information and its processing usually involves custom applications by those who have the application building skills. Yet, many kinds of information could easily be defined by end users. If only, the means for specifying such needs were available. We propose an ontology-driven model for end users to create community-specific web applications that consume and generate Linked Data. Our model is based on the Purposeful Online Communities (POC) Core ontology, which models online communities in terms of community-specific information and activity structures. We demonstrate the use of this ontology with example communities."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, işitme engellilerin hastane ve bankalarda kullanmaları amacıyla tasarlanmış bir insan-bilgisayar etkileşim platformu önerilmektedir. Söz konusu sistemin geliştirilmesi için öncelikle sağlık ve finans alanlarında işaretler içerin BosphorusSign Türk İşaret Dili veritabanı toplanmıştır. Veritabanı için dil bilimcilere, Türk İşaret Dili kullanıcılarına ve ilgili alanların uzmanlarına danışılmıştır. Toplanan veritabanının bir alt kümesi kullanılarak hastanelerde işitme engellilerin iletişimine yardımcı olacak HospiSign sistemi tasarlanmıştır. HospiSign platformu kullanıcılarına önceden belirlenmiş soruları ve bu sorulara verebileceği cevapları sunarak, ağaç tabanlı bir etkinlik diyagramı ile kullanıcıları yönlendirmektedir. HospiSign'a cevap olarak verilen işaretleri tanıyabilmek için ellerin şeklini, pozisyonunu, hareketini, ve üst vücudun duruşunu niteleyen öznitelikler kullanılmıştır. İşaretlerin zamansal özellikleri Dinamik Zaman Bükmesi ve Zamansal Şablonlar kullanılarak modellenmiştir. İşaretler k-En Yakın Komşu algoritması ve Rassal Karar Ormanları kullanılarak sınıflandırılmaktadır. Sistemin öznitelik, zamansal modelleme ve sınıflandırma yönlerinden değerlendirilmesi için BosphorusSign veritabanının bir alt kümesinde deneyler yapılmıştır. Deneyler sonucunda ellerin pozisyonu ve hareketini niteleyen özniteliklerin birlikte kulanımının en yüksek başarımı verdiği görülmüştür. Farklı zamansal modelleme ve sınıflandırma yaklaşımlarından ise birbirlerine yakın başarımlar elde edilmiştir. Yapılan deneyler sonucunda ağaç tabanlı etkinlik diyagramı kullanımının sistem başarımını arttırmanın yanı sıra kullanıcı adaptasyonunu da hızlandırdığı görülmüştür. Bu çalışmalara ek olarak, alan uyarlama ve yüzel nirengi noktası bulma yöntemleri incelenmiş, ve işaret dili ve işmar tanıma problemleri için kullanılabilirlikleri sınanmıştır.","In this thesis, we propose a human-computer interaction platform for the hearing impaired, that would be used in hospitals and banks. In order to develop such a system, we collected BosphorusSign, a Turkish Sign Language corpus in health and finance domains, by consulting sign language linguists, native users and domain specialists. Using a subset of the collected corpus, we have designed a prototype system, which we called HospiSign, that is aimed to help the Deaf in their hospital visits. The HospiSign platform guides its users through a tree-based activity diagram by asking specific questions and requiring the users to answer from the given options. In order to recognize signs that are given as answers to the interaction platform, we proposed using hand position, hand shape, hand movement and upper body pose features to represent signs. To model the temporal aspect of the signs we used Dynamic Time Warping and Temporal Templates. The classification of the signs are done using k-Nearest Neighbors and Random Decision Forest classifiers. We conducted experiments on a subset of BosphorusSign and evaluated the effectiveness of the system in terms of features, temporal modeling techniques and classification methods. In our experiments, the combination of hand position and hand movement features yielded the highest recognition performance while both of the temporal modeling and classification methods gave competitive results. Moreover, we investigated the effects of using a tree-based activity diagram and found the approach to not only increase the recognition performance, but also ease the adaptation of the users to the system. Furthermore, we investigated domain adaptation and facial landmark localization techniques and examined their applicability to the gesture and sign language recognition tasks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım testi, yazılım geliştirme sürecinin ayrılmaz bir parçasıdır. Konkolik test üzerinde sistematik testin daha büyük yazılımlara uygulanabilmesi amacıyla on yıllarca süren çalışmaların sonucu geliştirilmiş bir birim test yaratma tekniğidir. Ancak kısıt çözümü gibi darboğazlar konkolik testçilerin büyük projelerde kullanılmasına engel teşkil etmektedir. Kısıt çözümündeki darboğaz Test Altındaki Birim'in icra yollarındaki yüksek sayıda dallanmadan ileri gelmektedir. Bu tezde, Artımlı Kısmi Yol Kısıtları adını verdiğimiz ve standard konkolik testçi üzerine geliştirdiğimiz özgün bir kısıt çözüm stratejisi önermekteyiz. Önerdiğimiz değişiklik bazı yol koşullarını gözardı ederek kısıt çözücüye çok sayıda ama küçük sorgular göndermektedir. IPPC algoritmasını iyi bilinen bir konkolik test sistemi olan CREST üzerinde geliştirdik. IPPC üzerine olan çalışmamızda kısıt çözücü üzerindeki yükü azaltırken aynı dallanma kapsamasına ulaşılabileceğini göstermekteyiz. İddialarımızı farklı stratejileri çeşitli C programları üzerinde test ederek desteklemekteyiz. Deneysel sonuçlar yaptığımız değişikliğin standard konkolik testçinin işleyiş süre performansını deneylerin yarısında artırdığımızı ve eğer test altındaki birim fazla imkansız yol içeriyorsa 5 kattan daha fazla hızlanma sağladığını göstermektedir. Yaptığımız çalışma otomatik birim test yaratımı için büyük kısıtların çözülmesine olan ihtiyacı ortadan kaldırdığımızı göstermektedir.","Software testing is an essential part of the software development process. Concolic testing is an automated unit test generation technique which is a result of decades of study on making the automated testing scalable. However, bottlenecks such as constraint solving still prevents concolic testers to be used in large projects. The constraint solving bottleneck occurs due to the large number of branches on the execution paths of a Unit Under Test (UUT). In this thesis, we design a novel constraint solving strategy called Incremental Partial Path Constraints (IPPC) on top of a standard concolic tester. Our strategy makes more but smaller queries to the constraint solver, i.e. ignores some path conditions. We implement IPPC on top of a known concolic testing framework, CREST. We show that it is possible to reach the same branch coverage as the standard concolic tester while decreasing the burden on the constraint solver. We support our claims by testing several C programs using different strategies. Experimental results show that our modification improves runtime performance of the standard concolic tester in half of the experiments and results in more than 5x speedup when the UUT has many infeasible paths. Ultimately, IPPC eliminates the need for solving large constraints while automatically generating unit tests."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde gen ifadesi zaman serisi verisinden bilgi çıkarılması için yöntemler araştırılmıştır. Bu zaman serileri altta yatan biyolojik mekanizmalara dair dolaylı ölçümler sağlar, bu yüzden analizlerde istatistiksel modelleme tekniklerine yoğunca başvurulur. Özellikle popüler bir analiz yaklaşımı, ifade profili benzerliklerine göre genleri öbeklemektir. Fakat bilimsel veri analizi açısından öbekleme güçlü bir metodoloji gerektirir ve Bayesci nonparametri bu konuda gelecek vaat eden bir çerçeve sağlar. Bu bağlamda, iki yeni model geliştirildi: Standart sonsuz karışım modelini genişleten Sonsuz Çokyönlü Karışım (IMM); ve karışım bileşenlerinde gen ifadesi zaman serilerine uyarlanmış özgül bir yapıyı varsayım alan Parçalı Doğrusal Dizilerin Sonsuz Karışımı (IMPLS). Bayesci paradigmada gen analizi için anahtar nesne, model ve gözlemler verildiğinde, bölüntüler üzerindeki sonsal dağılımdır. Fakat, bölüntüler üzerinde bir sonsal dağılım oldukça karmaşık bir nesnedir. Burada Markov zinciri Monte Carlo çıkarımı uygulayarak gen bölüntülerinin sonsal dağılımından bir örneklem elde ediyoruz, ve sezgisel bir yöntemle genleri öbekliyoruz. Bölüntüler üzerindeki dağılımların analizi için entropi toplaşması (EA) adını verdiğimiz alternatif, yeni bir yaklaşım da geliştirildi. EA'nın kullanımı, edebi bir metne (Ulysses, James Joyce) uygulanan öbekleme deneyiyle gösterildi. Biyoenformatik uygulamamız olan CLUSTERnGO'da (CnG) sonuçta çıkan öbeklerin amaca uygunluğunu değerlendirmek için standart çoklu hipotez testi uygulanır, bir gen ontolojisine ait terimlerle kodlanmış önceki biyolojik bilgilerle karşılaştırılır. CnG'nin süreç akışı dört fazdan oluşur (Yapılandırma, Çıkarım, Öbekleme, Değerlendirme).","This thesis investigates methods for extraction of information from gene expression time series data. These time series provide indirect measurements about the underlying biological mechanisms, hence their analysis heavily depends on statistical modelling techniques. One particularly popular analysis approach is clustering genes by their similarity of expression profiles. However, for scientific data analysis, clustering requires a rigorous methodology and Bayesian nonparametrics provides a promising framework. In this context, two novel models were developed: Infinite Multiway Mixture (IMM) that extends the standard infinite mixture model; and Infinite Mixture of Piecewise Linear Sequences (IMPLS) that assumes a specific structure for its mixture components, tailored towards gene expression time series. In the Bayesian paradigm, the key object for gene analysis is the posterior distribution over partitionings, given the model and observed data. However, a posterior distribution over partitionings is a highly complicated object. Here, we apply Markov Chain Monte Carlo (MCMC) inference to obtain a sample from the posterior distribution of gene partitionings, and cluster genes by a heuristic algorithm. An alternative, novel approach for the analysis of distributions over partitions is also developed, that we named as entropy agglomeration (EA). We demonstrate the use of EA by a clustering experiment on a literary text, Ulysses by James Joyce. In our bioinformatics application CLUSTERnGO (CnG), the relevance of resulting clusters are evaluated by applying standard multiple hypothesis testing to compare them against previous biological knowledge encoded in terms of a Gene Ontology. The complete workflow of CnG consists of a four-phase pipeline (Configuration, Inference, Clustering, Evaluation)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım testi daha yerleşik bir disiplin haline geldikçe, yazılım testleri için kalite kontrol yapılması ihtiyacı da doğmaktadır. Mutasyon testinin bu amaçla literatüre giriş yapmasının üzerinden onyıllar geçti. Bu tezde, eş zamanlı Java programlarının mutasyon testini inceliyoruz. Bu amaçla, ""Mutanticide"" isminde, açık ve özgür bir mutasyon testi aracı geliştirdik. Ek olarak, yeni bir mutasyon operatörü öneriyor, daha önceden var olan 14 mutasyon operatörüyle beraber kullanıyoruz. Bu mutasyon operatörlerinin her birini ve sisteme kattıkları potansiyel hataları tanıtıyoruz. Bir baytkod enstrümantasyon aracı kullanarak, mutasyon adaylarının nasıl bulunabileceğini ve programın mutantlarının nasıl üretilebileceğini açıklıyoruz. Değişen boyuttaki yazılımlar üzerinde yapılan deneyler, eş zamanlı programlamaya odaklanan test kümesine sahip programların daha fazla eş zamanlı hata yakaladığını gösteriyor. Ayrıca, yeni operatörümüz RNNA'nın, etkili ve verimli olduğu, ürettiği düşük mutant sayısı ve yüksek ölü mutant yüzdesinden dolayı, seçmeli mutasyon yöntemiyle ispatlanıyor. Ek olarak, RNNA çok iş parçacıklı mutasyon operatörlerinin yeterli alt kümesi içine de giriyor. Bu çalışmada önerdiğimiz diğer bir mutasyon operatörü olan RSR ise java.util.concurrent Java kütüphanesini kullanan programları hedefliyor. Bu operatör, bahsi geçen kütüphaneye dair geliştirmeyi planladığımız mutasyon operatörlerinin ilk adımını teşkil ediyor.","As software testing becomes a more established discipline, the need for quality assurance of software test suites arises. It has been decades since mutation testing was first introduced into the literature for this purpose. In this thesis, we investigate mutation testing of concurrent Java programs. We have developed a publicly available mutation testing tool, ""Mutanticide"", for this purpose. Additionally, we propose a new mutation operator, and use it in combination with previously introduced 14 mutation operators. We describe each of these mutation operators and potential bugs they introduce into the system. Using a bytecode instrumentation tool, we explain how to discover mutation candidates and create mutants of a program. Experiments on varying size of software show that programs which have test suites focusing on concurrency catch more multi-threaded bugs. Also, our new operator, RNNA, is proven by selective mutation to be efficient and effective as it produces low number of mutants with a high percentage of dead mutants. In addition, RNNA ends up in the sufficient subset of concurrent mutation operators, too. Another mutation operator that we propose in this study, RSR, targets programs making use of the Java library java.util.concurrent. This operator is the first step of our work to develop more mutation operators regarding the aforesaid library."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Noktadan noktaya (NN) ya da paylaşımlı veri yolu gibi haberleşme mimarileri, çekirdek sayısı ve bu çekirdekler arasındaki iletişim hacmi arttıkça ölçeklenememektedir. Güç tüketimini azaltmak için, Yonga-üstü-Ağ (YüA) mimarileri öne sürülmüş olup, bu mimariler Yonga-üstü-Sistem topluluğu tarafından yaygın olarak kabul görmüştür. Ancak ağ boyutu arttıkça, YüA mimarileri daha fazla alan kaplamakta ve daha çok güç tüketmektedirler. Bu yüzden, bu tezde, geleneksel YüA mimarilerine alternatif olarak, Dinamik Yeniden betimlenebilir Noktadan Noktaya (DYNN) mimariler sunulmaktadır. DYNN'de sisteme yeni haberleşme istekleri geldiğinde, bağlantılar dinamik olarak yeniden betimlenir. Çok çekirdekli sistemler üzerinde koşan Gömülü Sistem (GS) uygulamalarında, trafik akışı genellikle önceden bilinmektedir. DYNN mimarisi hem NN hem de YüA mimarilerinden esinlenerek tasarlanmıştır. Eğer trafik akışı önceden bilinirse, yeniden betimleme (YB) işlemi hesaplama zamanında yapıldığından, DYNN, NN kadar hızlı çalışır. Böylece, bir sonraki haberleşme senaryosu, haberleşme başlamadan kurulabilir. DYNN'de YB alanı ağ boyutu ile doğru orantılı olduğundan dolayı, DYNN, geleneksel YüA gibi ölçeklenebilmektedir. Etkin bir YB için, tez kapsamında üç adet YB motoru tasarlanmıştır. Bu motorların en son sürümü DYNN'de kullanılmış olup, hedef sistem tarafından desteklenen en yüksek hızda çalışabilmektedir. Eğer GS üzerinde çekirdeklerin yerleşmesi etkin eşleme ve yönlendirme algoritmaları kullanılarak yapılırsa, DYNN, geleneksel YüA'lardan daha iyi sonuçlar vermektedir. Bu yüzden, tez kapsamında sezgisel eşleme ve yönlendirme algoritmaları tasarlanmıştır. Deneysel sonuçlara göre, DYNN'nin yonga üstü haberleşmede verinin arttığı en kötü durumda bile, geleneksel YüA'dan daha iyi çalıştığı gözlemlenmiştir.","Communication architectures such as Point-to-Point (P2P) and shared bus are poorly scalable as the number of cores or the communication volume increase. Network-on-Chip (NoC) has been proposed to reduce power consumption and has been widely adopted by the System-on-Chip (SoC) community. Yet, NoCs occupy more area and consume more power as the size of network increases. In this thesis, we propose a novel dynamic reconfigurable P2P (DRP2P) communication architecture for reconfigurable embedded systems, which is an alternative to the conventional NoC architectures. In DRP2P, interconnects are reconfigured on-the-fly as new communication requests arrive at the system. In embedded applications running on the multi-core systems, the traffic flow is usually known. Hence, DRP2P is very suitable for embedded systems. DRP2P is inspired from both P2P interconnects and NoC architecture. If the traffic flow is known in advance, it works as fast as P2P while reconfiguration process is done at the time of computation. Thus, next communication scenario can be established before communication starts. Since the reconfigurable wiring area in DRP2P is proportional to the network size, it is as scalable as NoC. In order to achieve reconfiguration efficiently, we developed three different dedicated self reconfiguration engines. The latest version of these engines is exploited in DRP2P architecture. DRP2P gives better results than conventional NoCs if the physical placement of cores on the embedded system is done properly by utilizing mapping and routing algorithms. Hence, fast and heuristic mapping and routing algorithms are also designed in the scope of this thesis. Experimental evaluations have shown that DRP2P outperforms conventional NoCs even in the worst case scenario as the amount of data in on-chip communication increases."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezdeki yaklaşım ve yöntemler başka problemlere genelleştirilebilir olmakla birlikte, özelde iyi belirlenmiş bir bilgisayar destekli tanı problemi üzerinde uygulanmıştır. Amacımız, fetal kafatası imgeleri uzmanlarca incelendiğinde görülebilen spina bifida (açık omurga) sinir tüpü hasarının saptanmasıdır. Otomatik hastalık tespiti yapan uygulamaların amacı özgün çerçevelerde belirlenebilir. Bu tip sistemler, yanlış teşhisleri önlemek amaçlı alternatif gözlemciler olarak kullanlabilir. Spina bifidanın varlığı fetal kafatası biçiminin taşıdığı işaretlerden anlaşılmakta ve bu yüzden, okuyacağınız tezde, ultrason (US) ile edinilen fetal kafatası imgelerinden çıkarılan biçim öznitelikleri kullanılmaktadır. Literatürdeki biçim gösterimi ve öznitelik edinim teknikleri çeşitlilik gösterirken, bunlardan ikisi gerçeklenmiştir. Eğrilik ölçek uzayı ve momentlere (Zernike momentleri) dayalı gösterimler, özniteliklerin ötelenme, dönme ve ölçeklenme dönüşümleri altında değişimsiz olması veya yapılandırılabilmeleri itibariyle, gürbüz gösterimler olarak değerlendirilmektedir. Biçimlerle sınıflandırma, genellikle, bölütleme sorunu ile beraber ortaya çıkmaktadır. US imgelerinin tam-otomatik olarak bölütlenmesi uygulamada zor olduğundan, tezimizde, az sayıda nokta işaretlenerek yarı-otomatik bölütleme hedeflenmiştir. Kullanılan yöntemler basit sezgisellere ve aktif görünüm modellerine dayanmaktadır. Deneylerde en yakın komşu ve destek vektör makineleri sınıflandırıcıları kullanılmakta ve tıbbi verilerin doğasındaki azlık sorunu yüzünden veri kümeleri alt-örnekleme ve üst-örneklemeyle işlenmektedir. Temelde doğru bölütlemelerle bildirilen sonuçlar, belirli amaçları gözeten en iyi işletim noktalarının belirlenebileceğini göstermektedir.","The work of this dissertation focuses on a specific computer aided diagnosis (CAD) problem, although the main concept can be generalized to similar problems. Our aim is to detect the presence of the spina bifida (open spine) neural tube defect that is evident for a physician when the fetal skull image of a subject is examined. The objective of applications performing automatic anomaly detection can be set in their original contexts. Such systems, as a second observer, may help avoid false diagnoses. Fetal skull shapes possess markers that signal the presence of spina bifida. That is why this thesis concentrates on exploiting features extracted from skull shapes obtained via ultrasound (US). Among the variety of shape representation and feature extraction schemes, we have implemented and experimented with two. Both the curvature scale space (CSS) and moment-based (i.e. Zernike moments) representations have proved to be robust in that the extracted features provide classification invariant under the similarity transformations of translation, rotation and scaling. Classification of shapes is commonly coupled with the problem of segmentation. Since the fully-automatic segmentation of US images is practically difficult, we have attempted to achieve segmentation semi-automatically after the manual marking of a small number of points on images, based on simple heuristics and the Active Shape Models (ASM). Our experiments use k-nearest neighbor (kNN) and Support Vector Machines (SVM) classifiers. The inherent problem of rarity of medical data sets is tackled with methods of undersampling and oversampling. The results, reported for ground truth segmentations, reveal the availability of optimal operating points serving particular objectives."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde veri merkezleri, kaynak verimliliği ve performans arasında optimal bir dengeye ulaşmaya çalışır. Bu tezde, sistem kaynaklarının verimli kullanımı ile ilgilenilmiş ve iş bitirme süresinin iyileştirilmesi amaçlanmıştır. Çok değişken iş yüklerinin, heterojen büyük veri merkezlerinde çizelgelenmesinde yaşanan zorluklar ele alınmıştır. İlk olarak iletişim gereksinimleri olan işler için iletişim ve hesaplama gereksinimlerini birlikte kontrol ederek kaynak verimliğini ve iş bitirme sürelerini iyileştiren bir çizelgeleme algoritması önerilmiştir. İkinci olarak, öncelikli çizelgelemenin çeşitli yönlerini keşfetmek ve iş tahliyeleri ile iş bitirme süresi arasındaki ödünleşimi analiz etmek için yeni bir çizelgeleme çatısı önerilmiştir. İş tahliyelerinin sistem performansı üzerindeki etkilerini daha iyi anlayabilmek için, temel tahliye yöntemleri önerilmiş ve gerçek iz kullanılarak performans değerlendirmesi yapılmıştır. Bunun yanında, bu tezde iş yükleri heterojenliği kullanılarak, öncelikli çizelgeleme ve iş yükü farkındalığı olan bir çizelgeleme algoritması önerilmiştir. Önerdiğimiz yöntem ile iş çizelgelemesine iş yükü farkındalığı entegre edilerek, iş bitirme süresi ve kaynak verimliliğinde önemli iyileştirmeler elde edilmiş ve başarım çalışmaları ile gösterilmiştir. Son olarak, düşük öncelikli işler için çalıştırılma garantisi sağlanırken aynı zamanda yüksek öncelikli işlerin performansını da gözeten yeni bir çizelgeleme planı önerilmiştir. Önerilen yöntem hem önceliklendirme hem düşük öncelikli işlerin performans sorunlarını hibrit bir çizelgeleme yaklaşımıyla başarıyla ele almaktadır.","Nowadays, large computing clusters constantly strive for an optimal tradeoff between resource efficiency and performance. In this thesis, we are concerned with the efficient use of system resources and we also aim to improve response time of the tasks. We tackle with the challenges of task scheduling on large heterogeneous clusters executing highly heterogeneous bursty workloads with different priorities, resource demands, and performance objectives. Firstly, we propose a scheduling algorithm for tasks with communication needs which improves the response time and resource utilization by controlling communication and computation resources at the same time. Secondly, we propose a novel scheduling framework for exploring various aspects of priority scheduling with heterogeneous workloads while investigating the tradeoff between evictions and response time. To better understand the impact of evictions, we first analyze simple eviction policies and wasted resources associated with evictions by using trace-driven simulations. Furthermore, by exploiting the heterogeneity of the workload, we propose a workload-aware slot configuration and task assignment methodology incorporated with slot-based priority scheduling to improve class-based response time and resource efficiency. Finally, we introduce a task scheduling policy which aims to provide scheduling and execution guarantees for low priorities while preserving the performance benefits of high priority tasks. The proposed scheduling effectively handles both prioritization and performance issues of low priorities by utilizing a combination of preemptive and non-preemptive scheduling."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hayvan çiftlikleri, toplumun artan ihtiyaçlarını etkin bir şekilde karşılayabilmek için giderek büyümektedir. Bu durum, hayvanlar hakkında faydalı bilgilerin toplanabilmesi ve anlık durumları ve sağlıklarının takibi için yeni izleme ve takip sistemlerini gerekli kılmaktadır. Ancak hayvanların kimliklendirmeleri ve takibi, benzerlikleri ve davranışlarının tahmininin kolay olmayışı sebebiyle zor bir problemdir. Bu tezde yeni bir inek tanımlama sistemi önerilmektedir. Önerilen çözümü li-teratürdeki diğer sistemlerden ayıran belirgin özellikler bulunmaktadır. Örneğin bu sistem, hayvanların üzerine koyulan işaretlere veya harici cihazlara ihtiyaç duymamaktadır, karanlık ortamlarda bile çalışabilmekte, ayırt edici görünüşleri olmayan siyah inekleri bile tanımlayabilmekte, göreceli olarak ucuz ve hassas yer tespiti sağlamaktadır. Önerilen çözüm, belirli yüksek-liğe konan RGBD kameralarla çekilen hayvanların üst arka gövdesinin 3B şekil analizine dayanmaktadır. Yerel yüzey özelliklerine göre iki boyutlu imgeler oluşturulmakta ve bu imgeler yüz tanımlama algoritmaları kullanılarak kimliklendirilmektedir. Önerilen sistemin uygulanabilirliğini değerlendirmek amacıyla gerçek zamanda çalışan bir prototip yazılım geliştirilmiş ve bildiğimiz kadarıyla literatürde bulunmayan bir 3B sığır veri öbeği oluşturulmuştur. Bu veri öbeği, hareketli ve belirgin görünüşleri olmayan hayvanlardan farklı ışık koşullarında alınmıştır. Yapılan testlerde önerilen çözümün uygulanabilirliği alınan veri öbeği ile doğrulanmış olup, 50 ineğin %88'i doğru bir şekilde tanımlanabilmiştir.","Animal farms have been steadily growing to meet the consumption requirements of the society in an efficient manner. This fact necessitates new monitoring and tracking systems to collect useful information about the herds in order to observe their general health and instantaneous state. However, recognizing and tracking an animal in a farm is a difficult task due to the target's similarity and hard to predict dynamics. In this thesis, a novel cow identification system is proposed. There are prominent features of this solution which differentiates it from the others in the literature, i.e., it does not need any markers or external devices placed on the animal; works in even unlighted environments; identifies even black cows without distinctive coat patterns; is relatively cheaper, and enables accurate positioning. Proposed solution is based on 3D shape analysis of the top back part of the animals captured with RGBD cameras placed at an adequate height, where two dimensional images are constructed with respect to the local surface features and are subsequently identified by using face recognition methods. To evaluate the applicability of the proposed system, a real-time prototype software has been developed and a 3D cattle dataset is acquired which, to our knowledge, is unique in the literature. This dataset is gathered from moving animals which do not have distinctive coat patterns and captured in different lighting conditions. Applicability of the proposed solution has been verified by testing with the acquired dataset. Convincing results are obtained where %88 of 50 cows are identified successfully."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan-makina iletişimini insan-insan iletişimine yaklaştırmak için, insan-makina etkileşim alanında duygu durum (örn. duygu, ruh hali), özellik (örn. kişilik) ve sosyal işaretler (örn. düş kırıklığı, fikir ayrılığı) analizine artan ilgi söz konusudur. Bunun akıllı eğitim sistemlerinden duyguları anlayabilen robotlara, akıllı çağrı merkezlerinden uzaktan hastaları takip eden sistemlere kadar çeşitli uygulamaları vardır. Konuşmacı durum ve özelliklerini kapsayan hesaplamasal paralinguistik çalışma alanı, konuşmacı ve veritabanı değişkenliği gibi gerçek hayat problemleriyle yüzleşmektedir. Bu tezde, bu problemleri çözmek için çeşitli yapay öğrenme yöntemleri geliştirilmesi hedeflenmiştir. Yüksek boyutlu paralinguistik verilerin modellenmesi için otomatik model seçim yöntemleri geliştirilmiştir. Bu yaklaşımlar farklı değişkenlik kaynaklarını parametrik bir şekilde ele alabilmektedir. İstatistiksel modeller ve sınıflayıcılara özlü, potansiyeli yüksek öznitelikler sağlamak için ayrımsayıcı izdüşüm tabanlı yeni değişken seçim yöntemleri tanıtılmıştır. Ek olarak, zorlu koşullarda gürbüz duyuşsal hesaplama için çok-kipli tümleştirme teknikleri irdelenmiştir. Önerilen yöntem ve yaklaşımlar INTERSPEECH Computational Paralinguistics Challenge (2013-2015), Audio-Visual Emotion Challenge (2013/2014), ve Emotion Recognition in the Wild Challenge 2014 gibi bir dizi yakın tarihli yarışma veri kümelerinde geçerlenmiştir. Bu tezde önerilen yöntemler sadelik ve hesaplamasal verimlilik özelliklerini taşımakla beraber, bu veri kümelerinin çoğunda problem üzerinde raporlanmış en iyi çözümlere çok yakın veya daha yüksek başarı elde etmiştir.","The analysis of affect (e.g. emotions or mood), traits (e.g. personality), and social signals (e.g. frustration, disagreement) are of increasing interest in human computer interaction, in order to drive human-machine communication to become closer to human-human communication. It has manifold applications ranging from intelligent tutoring systems to affect sensitive robots, from smart call centers to patient telemonitoring. The study of computational paralinguistics, which covers the analysis of speaker states and traits, faces with real life challenges of inter-speaker and inter-corpus variability. In this thesis, machine learning methods addressing these challenges are targeted. Automatic model selection methods are explored for modeling high dimensional paralinguistics data. These approaches can deal with different sources of variability in a parametric manner. To provide statistical models and classifiers with a compact set of potent features, novel feature selection methods based on discriminative projections are introduced. In addition, multimodal fusion techniques are sought for robust affective computing in the wild. The proposed methods and approaches are validated over a set of recent challenge corpora, including INTERSPEECH Computational Paralinguistics Challenge (2013-2015), Audio-Visual Emotion Challenge (2013/2014), and Emotion Recognition in the Wild Challenge 2014. The methods proposed in this thesis advance the state-of-the-art in most of these corpora and yield competitive results in others, while enjoying the properties of parsimony and computational efficiency."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Zamana bağımlı çizgeler için en kısa yol problemi son yıllarda oldukça popülerleşti. Akıllı telefonlar hayatımızın ayrılamaz bir parçası olduğundan beri, bu telefonlardaki uygulamalar insan hayatını kolaylaştıran birçok olanak sağlıyor. Navigasyon uygulamaları da bunlardan biridir. Son teknoloji ürünü olan yer bulma uygulamaları harita verisinin yanında gerçek zamanlı trafik verilerinden de yararlanmaktadırlar. Dolayısıyla, en kısa yol problemini gerçek zamanlı verilerde, yani zamanla değişen çizgelerde çözmek artık bir gereklilik olmuştur. Zamana bağımlı çizgelerde en kısa yol problemi için literatürde çeşitli ardışıl algoritmalar bulunmaktadır. Ancak, bu algoritmalar genellikle iki problemin sıkıntısını çekmektedirler: yürütüm sürelerinin uzun olması veya çok fazla bellek gereksinimi. Önceden sunulan algoritmalardaki bu problemler, onların, gerçek zamanlı verilerle çalışan ve hızlı yanıt sürelerine ihtiyaç duyan dolaşım uygulamalarında kullanılmasını mümkün kılmamaktadır. Zamana bağımlı akış hızı modeli içeren en kısa yol seri algoritmasının, çok daha fazla bellek gerektirmeden, yürütüm süresinin hızlandırılması için ""Değiştirilmiş Dijkstra"" algoritmasını temel alarak paralel algoritmalar öneriyoruz. Cuda ve OpenMP kullanarak 3 farklı paralel gerçekleştirme geliştirdik: Bunlar (i) Cuda tabanlı uyarlama, (ii) OpenMP tabanlı uyarlama ve (iii) Cuda ve OpenMP tabanlı karma uyarlama. OpenMP uyarlamasında 10 kat, diğer uyarlamalarda da 17 kat hızlanma elde edilmiştir.","Shortest path problem in time dependent graphs has become a popular problem in recent years. Ever since the smart phones became an inseparable part of our lives, the applications on those devices started to provide many functionalities which make human life much easier. Navigation applications are one of them. State of the art navigation applications benefit from real time traffic data besides the map data. Therefore, it becomes a necessity to solve the problem of shortest path with real time data, i.e., on time dependent graphs. Various sequential algorithms for the shortest path problem in time dependent graphs are appearing in the literature. However, these algorithms mostly suffer from the following two problems: long running times or huge memory requirements. These problems of the previously proposed algorithms are making them unsuitable for navigation applications which run on real time data and which need fast response times. In order to speed-up the running time of the sequential algorithm, without requiring much more memory, for shortest path problem with time dependent flow speed model, we propose parallel algorithms based on Modified Dijkstra algorithm. We develop three different parallel implementations by using Cuda and OpenMP: These are (i) a Cuda based version, (ii) an OpenMP based version and (iii) a hybrid Cuda and OpenMP based version. We get up to 10-fold speedup in the OpenMP version, and 17-fold speed up in the other two versions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, rejim değiştiren volatilite modellerinde değişim noktası tespit yöntemini kullanarak bütünleşik durumların tespiti ve parça parça zamana bağlı değişim gösteren parametreler için bir kestirim tekniği sunmaktadır. Bu yaklaşım değişim nokta sayısı bilinmeyen GARCH ve EGARCH bazlı volatilite modellerinin tahmini için bir Sıralı Monte Carlo yöntemidir. Arka yoğunlukları ve çevrimiçi tahminleri hesaplamak için modern harici parçacık filtreleme teknikleri kullanılmıştır. Bu yaklaşım, aynı zamanda bu tip volatilite modellerinde karşılaşılan ortak atalara yol bağımlılığı sorununa da otomatik olarak çözüm sağlamaktadır. Bu model daha önce İstanbul Menkul Kıymetler Borsası (İMKB) olarak bilinen Borsa İstanbul günlük getiri verisi üzerinde test edilmiştir. Volatilite modelleri için koşullu varyansın tüm parametrelerinin dinamik olarak değişim gösterdiği bir tam yapısal değişim noktası spesifikasyonu tanımlanmıştır. Sonuç olarak, önerilen yaklaşım ve modelin zaman serisini farklı rejimlere bölerek her rejime ait volatilite modeli parametrelerini çoklu değişim noktası tespit süreci ile birlikte öğrendiği ve geçmiş yöntemlere göre daha iyi bir tahmin gücü ortaya koyduğu deneylerle gösterilmiştir.","This dissertation proposes a combined state and piecewise time-varying parameter learning technique in regime switching volatility models using multiple changepoint detection. This approach is a Sequential Monte Carlo method for estimating GARCH & EGARCH based volatility models with an unknown number of changepoints. Modern auxiliary particle filtering techniques are used to calculate the posterior densities and online forecasts. This approach also automatically deals with the common ancestral path dependence problem faced in these type volatility models. The model is tested on Borsa Istanbul (BIST) formerly known as Istanbul Stock Exchange (ISE) market data using daily log returns. A full structural changepoint specification is defined in which all parameters of the conditional variance of the volatility models are dynamic. Finally, it is shown with simulation experiments that the proposed approach partitions the series into several regimes and learns the parameters of each regime's volatility model in parallel with the multiple changepoint detection process and shows better forecasting power compared to previous techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otomatik insan davranışı tanıma, akıllı evler, sağlık izleme uygulamaları ve acil durum servisleri gibi birçok çevresel zeka uygulaması için önemlidir. Sağlık izleme sistemlerini sürdürülebilir yapmak için insan aktivitelerinin otomatik olarak algılandığı akıllı ortamlara ihtiyaç vardır. İnsan davranışlarını anlamak için, akıllı ortamlardan toplanan veriler üzerinde makine öğrenmesi yöntemlerini kullanabiliriz ancak bu yöntemler işaretlenmiş eğitim kümelerine ihtiyaç duyarlar. Bu kümeleri oluşturmak insan çabası gerektirdiğinden pahalıdır. Ayrıca, insan faaliyetlerinin karmaşık yapısı, onları doğru bir şekilde modellemeyi zorlaştırır. Hiyerarşik modeller daha doğru temsil için bir çare olabilir, ancak uygun karmaşıklık düzeylerini bulmak kolay değildir. Son olarak, otomatik insan davranışı izleme sistemlerini dünya ölçeğinde uygulanabilir kılmak için model davranışını her farklı evin sakinlerinin davranışlarını yansıtacak şekilde ayarlamak gereklidir. Her ev için haftalarca eğitim kümesi toplamaktansa, zaman içinde sadece en çok bilgi içeren noktalar için etiket toplayarak, etiketleme eforunu azaltırken öğrenme yönteminin yararlılığını artıracak bir mekanizma geliştirilebilir. Bu tezde, (i) tüm araştırmacılara açık, karşılaştırma amacıyla kullanılabilir veri kümeleri oluşturarak, (ii) makine öğrenmesi modelinde, her aktiviteye özel olarak hiyerarşi seviyesi belirlemek için bir yöntem önererek, (iii) farklı yaklaşımların ve modellerin değerlendirilmesini, alanın özel ihtiyaçlarını gözetecek şekilde geliştirerek, (iv) evde birden fazla kişinin yaşadığı durumları kullanıcılara ek yük getirmeyecek şekilde ele alan yöntemler önererek, (v) geniş ölçekli kurulumlarda etiketleme eforunu azaltmak için aktif ve yarı-denetimli öğrenme teknikleri kullanarak, yukarıda bahsedilen konuları hedef alan çalışmalar yapılmıştır.","Recognizing human behavior in an automated manner is essential in many ambient intelligence applications such as smart homes, health monitoring applications and emergency services. In order to make such long term health monitoring systems sustainable, we need smart environments in which the human activities are recognized automatically. In order to infer the human behavior, we can use machine learning methods on the data collected from the smart environments but those methods require annotated datasets to be trained on. Recording and annotating such datasets are costly since they require time and human effort. Moreover, the complex nature of human activities makes it difficult to accurately model them. While hierarchical models can be a remedy for more accurate representation, finding suitable complexity levels is not a trivial task. Finally, when we deploy automatic human behavior monitoring systems on a world-wide scale, we need to fine tune the model behavior for each new house to accurately reflect the residents' behavior for that specific house. Rather than annotating a dataset consisting of several weeks of data, an algorithm can be used to decide for which point in time it would be most informative to obtain annotation in order to minimize the need for annotation and maximize the usefulness of annotation. This thesis addresses the above mentioned issues by (i) collecting publicly available benchmark datasets, (ii) proposing a methodology for incorporating a hierarchy into the model that is tailored for various activities individually, (iii) improving the ways of evaluating different approaches and models considering the domain specific needs, (iv) handling multi-resident environments in an unobtrusive manner and, (v) using active and semi-supervised learning techniques in order to reduce the annotation effort in large scale deployments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Parçacık süzgeçleri olarak da bilinen ardışık Monte Carlo (AMC) yöntemleri, lineer ve Gaussian olmayan durum uzaylarında Bayesçi kestirim için çokça kullanılan bir araçlar bütünüdür. Bu yöntemler geleneksel olarak seri hesaplama mimarileri düşünülerek geliştirilmiş olsa da, paralel hesaplama konusundaki son gelişmeler AMC camiasının da dikkatini çekmiş ve parçacık süzgeçlerinin paralelleştirilmesine yönelik çalışmalar olmuştur. Parçacık süzgeçlerinin paralelleştirilmesi yönündeki çabalar yeniden örnekleme algoritmalarının paralelleştirilmesi üzerine yoğunlaşmıştır. Bu tezde, yeniden örnekleme algoritmalarının, büyük çapta paralel mimariler üzerinde gerçeklenmesini inceliyoruz. Klasik yeniden örnekleme algoritmalarının grafik işleme üniteleri (GPU) üzerinde ger\-çek\-len\-me\-le\-ri\-nin yanı sıra hesaplama zamanı maliyetlerini analiz ediyoruz. Klasik yeniden örnekleme algoritmalarına ilaveten son zamanlarda öne sürülmüş olan ve eldeki paralel mimariye özgün yeniden hesaplama algoritmaları tasarlanmasına olanak sağlayan genişletilmiş yeniden örnekleme çerçevesini sunuyoruz. Bu çerçeve içinde geliştirilmiş olan ve kısıtlı iletişim koşulları altında çalışabilen kelebek yeniden örnekleme algoritmasını gerçekleyip hesaplama zamanı analizini sunuyoruz. Kelebek yeniden algoritmasının yakınsaklığına ilişkin teorik sonuçları sunup bu sonuçları doğrulamak, GPU üzerinde gerçeklenmesine dair rehber ilkeler belirlemek ve klasik yeniden örnekleme algoritmalarıyla karşılaştırmak için deneyler düzenliyoruz. Bu deneyler sonucunda görüyoruz ki, kelebek yeniden örnekleme algoritmaları klasik algoritmalardan altı kat kadar hızlı olabilirken Monte Carlo hatasını rekabetçi bir seviyede tutabilir.","Sequential Monte Carlo (SMC) methods, also known as particle filters, are a popular set of tools in Bayesian inference on non-linear non-Gaussian state space models. While these algorithms are traditionally developed with serial computation in mind, recent developments in the field of parallel computation has caught the attention of SMC community as well and there have been efforts to parallelize particle filters. Efforts on parallelization of particle filters are focused on the parallelization of resampling algorithms. In this thesis, we investigate the parallelization of resampling algorithms on massively parallel architectures. We present implementations of classical resampling algorithms on graphical processing units (GPU) and give an asymptotic analysis of their computation time. We present a recent framework called augmented resampling that can be used to produce resampling algorithms specifically designed to work on some parallel computing architecture. Within this framework, we implement the butterfly resampling algorithms, that works under limited degree of communication between computational units, on GPUs and present asymptotic analysis of their computation time. We present theoretical results on convergence properties of butterfly resampling algorithms and conduct simulations to verify these theoretical results, to obtain practical guidelines for their implementation on GPUs and to compare their performance to classical resampling algorithms. We see that butterfly multinomial resampling algorithm can provide upto six times speed-up over classical multinomial resampling algorithm, while keeping the Monte Carlo error at a competitive level."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı telefon, tablet ve küçük ekranların multimedya içerik için kullanımının artmasıyla birlikte video uyarlama, kullanıcı deneyimini zenginleştirmek için önemli bir araç haline geldi. Bu tezde, videolardaki önemli içeriği tespit etmek ve video uyarlama yapabilmek için konumsal ve zamansal olarak seyircinin dikkatini çeken noktalara dayanan, yeni bir içerik bazlı yaklaşım sunuyoruz. Önerdiğimiz metot görüntülerde dikkati çeken bölgelerin uyarlama sırasında korunmasını sağladığı gibi, videonun kareleri arasında da zamansal uyumu kaybetmemektedir. Ayrıca tezde bu uygulama için özel olarak tasarlanmış bir dinamik bercestelik metodu öneriyoruz. Bu metot görüntülerde dikkati çeken noktaları zaman içinde izleyerek tutarlılığı sağlıyor. Sunduğumuz yaklaşımın kalitesini beş farklı video hedeflendirme metoduyla niteliksel ve niceliksel olarak kıyaslayarak gösteriyoruz. Niceliksel değerlendirme diğer tüm video hedeflendirme çözümlerine uygulanabilmesi için genel görüntü/video kalite ölçütleriyle yapılmıştır. Nicel ve nitel değerlendirme arasında bulduğumuz korelasyonu kullanarak hâlihazırda bulunan niceliksel ölçütlerin birleşiminden oluşan yeni bir ölçüt sunuyoruz. Sunduğumuz bu ölçüt ile nicel sonuçlara olabildiğince yakın sonuçlar verilmiştir. Bu ölçütün video uyarlama metotlarını kıyaslamak için kıyaslamak için kullanılabileceğini düşünüyoruz.","With increased usage of smartphones, tablets and small displays to play multimedia content, video retargeting becomes an important tool for better user experience. In this thesis, we propose a novel content-based approach for video retargeting that relies on spatio-temporal saliency to estimate relevant information in videos. Our method preserves spatial saliency as well as temporal coherence. We also propose a spatio-temporal saliency algorithm designed for this application domain that combines spatial saliency with motion trajectories. We demonstrate the quality of the proposed approach through quantitative and qualitative evaluation, contrasting it with five different video retargeting methods. Quantitative evaluation is done using generic image/video quality metrics, so that they can be applied on any video retargeting solution. We have extracted the correlation between the quantitative and qualitative evaluation, to propose a new metric that is a combination of the existing quantitative metrics. The proposed metric is proven to be the best approximation to the qualitative results, thus can be used as a benchmark to evaluate video retargeting methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım Tanımlı Ağlar (YTA) kontrol ve veri düzlemlerini ayıran yeni bir ağ yaklaşımı olarak önerilmiştir. Bu sistemlerde merkezi kontrol birimleri olan kontrolörler başarım ve verimlilik hedeflerine ulaşmak açısından cok önemlidirler. Kontrolörlerin yerleşimi, anahtarlara atanması ve yük dengelemesini sağlayarak çalışması çetin bir araştırma sorusudur. Literatürde çeşitli yük dengeleme yöntemleri önerilse de bu konu hala araştırılmaya muhtaçtır. Bu tezde YTA'da yük dengeleme ile ilgili konuları tartışıyor ve Hiyerarşik YTA Kontrolörlerinde Işbirlikçi Yük Dengeleme adında bir yük dengeleme yöntemi öneriyoruz. Ayrıca bu yöntemin başarımını değerlendiriyor ve önemli ödünleşimleri inceliyoruz.","Software-defined networking (SDN) has been proposed as a new networking paradigm which separates the control and data forwarding planes. The controllers which are centralized network control entities are crucial for meeting the performance and efficiency requirements of these systems. The placement of these network entities, switch assignment and their load-aware operation is a challenging research question. Although various load-balancing schemes are proposed in the literature, this research topic is yet to be explored adequately. In this thesis, we discuss load-balancing issues in SDN and propose a load-balancing scheme, namely Cooperative Load Balancing Scheme For Hierarchical SDN Controllers (COLBAS). Moreover, we evaluate the performance of this scheme and investigate important trade-offs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nano ağlar olarak tanımlanan, nano ölçekteki cihazlar arasındaki bağlantı, son yılların önemli çalışma alanlarından biri olarak değerlendirilmektedir. Bu tezde, nano ağlardaki haberleşmeyi sağlayabilme amacıyla konu ile ilgilenen araştırmacılar tarafından faydalanılan birçok yaklaşım arasından difüzyon ile haberleşme (DiH) seçilmiştir. Bu tezde, DiH sistemlerinin beraberinde getirdiği haberleşme problemlerinin üstesinden gelmek adına, moleküler haberleşme çalışmalarında çoğunlukla göz önünde bulundurulmayan molekül bozunması olgusu hesaba katılmaktadır. Önerilen modelin performansı benzetimler ve çözümsel ifadeler yardımıyla değerlendirilmektedir. Benzetimlerde, molekül bozunmasının bazı temel nano boyuttaki haberleşme ölçevleri üzerindeki faydaları gösterilmektedir. Bunun yanı sıra, semboller arası girişimin azalması ve gönderilen sinyalin doğru deşifre edilmesi amacıyla diğer haberleşme değiştirgeleri için belirlenen özgül değerlere bakılarak, molekül bozunmasını dikkate alan sistemlerin değişkenleri için uygun değer seçimi yapılmaktadır. Bir önceki sembolden kalan artık molekül miktarının önceden belirlenmiş bir eşik değerinin altında kalması ve alıcı hücreye varan taşıyıcı molekül sayısının bu değerin üzerinde olması, bu belirlemelerde kısıt olarak verilmiştir. Daha sonraki çözümlemede, molekül bozunmasının sistemin veri hızı ve enerji tüketimi üzerindeki etkileri incelenmektedir. Sonuçlar, uygun taşıyıcı molekül yarı-ömür değerleri kullanıldığında, veri hızının arttığını ve enerji harcamasının azaldığını göstermektedir.","The interconnection between the nanoscale circuit components, which is referred to as nanonetworking, is a hot topic for nearly a decade. Among the various approaches studied in the literature, we apply communication via diffusion (CvD) method. Despite its practicality and ease of implementation, CvD brings along its own drawbacks especially to the reliability of the system. In order to overcome these drawbacks, we consider molecule degradation, which the literature on molecular communication mostly overlooks, in this thesis. We evaluate the performance of this proposed model by simulations and by using analytical expressions. In the simulations, we demonstrate the positive effects of molecule degradation on basic communication metrics in this scale. In addition, we use the analytical formulas in selecting the proper values of degradation utilized system parameters for mitigating intersymbol interference and correctly demodulating the signal. In this sense, the number of stray molecules remaining in the inter-cellular environment from the previous symbol is limited not to exceed the predefined threshold value while the number of received molecules is bounded to be greater than it. In the subsequent analysis, we examine the effects on the data rate and the energy consumption of the overall system. Results demonstrate that the increase in the data rate and the decrease in the energy expenditure can be achieved using appropriate half-life values."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otomatik belge özetleme, verilen bir ya da birden çok belgenin içeriğinin kısa ve kapsayıcı bir şekilde özetlenmesi işlemidir. Otomatik belge özetleme alanında İngilizce dili üzerine yapılmış çok sayıda çalışma olmasına rağmen, diğer diller için, özellikle Türkçe için, yapılmış çok az çalışma bulunmaktadır. Metin sadeleştirme, cümlelerin dil bilgisi ve sözlük dağarcığı açısından içerdikleri karmaşıklıkların azaltılmasını hedefler. Bu yüzden otomatik metin sadeleştirme sistemleri Doğal Dil İşleme alanındaki problemlerde sistem başarımını iyileştirecek önemli bir aşama olarak değerlendirilmektedir. Bu tezde, farklı seviyelerde uygulanan kelime kökü bulma yöntemlerinin ve cümle sadeleştirme tekniklerinin Türkçe dili için otomatik çoklu belge özetleme başarımı üzerine etkileri incelenmiştir. Otomatik özetleme sisteminin değerlendirilmesi için insanlar tarafından özetlenmiş bir veri kümesi derlenmiş, bildiğimiz kadarıyla Türkçe için ilk çoklu belge özetleme sistemi çalışması gerçekleştirilmiştir. Ayrıca cümlelerin sözdizimsel özelliklerini kullanan kural tabanlı bir cümle sadeleştirme yöntemi geliştirilmiştir. Elde edilen sonuçlarda, kelime sonundan harf atma tekniği en iyi başarımı elde ederken, detaylı morfolojik analiz yöntemleri başarımı ROUGE ölçütüne göre artırmamıştır. Ayrıca, verilen bir cümleyi birden fazla daha sade cümleye ayıran cümle sadeleştirme tekniklerinin özetleme sistemi öncesinde uygulanması başarımı az miktarda yükseltirken, cümle kısaltmaya dayalı cümle sadeleştirme teknikleri ROUGE ölçütü değerlerini düşürmüştür.","Automatic text summarization is the task of generating a compact and coherent version of a given text document or a set of text documents. Although there is a vast number of studies for automatic document summarization on English, there is only a limited number of studies for other languages, especially for Turkish. Text simplification aims to reduce the grammatical or lexical complexities of the sentences. Automatic text simplification systems can be an important part of any NLP task to improve system performance. In this thesis, we analyzed the effects of applying different levels of stemming approaches such as fixed-length word truncation and morphological analysis and the effects of applying text simplification techniques for multi-document summarization (MDS) on Turkish, which is an agglutinative and morphologically rich language. We constructed a manually annotated MDS data set, and to the best of our knowledge, reported the first results on Turkish MDS. Additionally, we developed a rule-based text simplification system for Turkish that utilizes the syntactic features of the sentences to identify simplification patterns. Our results show that a simple fixed- length word truncation approach performs slightly better than no stemming, whereas applying complex morphological analysis does not improve Turkish MDS in terms of ROUGE scores. Applying simplification rules that split complex sentences to individual simpler sentences as a preprocessing step slightly improves summarization performance, whereas applying a compression-based simplification approach relying solely on rule matching decreases the obtained ROUGE scores."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, büyük çaplı ve/ya farklı kaynaklardan toplanan ayrık veriler için iyi bir modelleme doğruluğu ve uygulanabilirlik ödünleşimi sağlayan bağlaşımlı matris ve tensör ayrışımı modelleri üzerinde yoğunlaşıyoruz. Bu tezdeki asıl amacımız bağlaşımlı tensör ayrışım modelleri için çıkarım yöntemi geliştirmek olacaktır. İlk olarak, olabilecek bütün model topolojilerini kapsamayı hedefleyen titiz bir tensör ayrışım simgelemi geliştireceğiz. Simgelemimiz, tensör ayrışım modellerinde paralel ve dağıtık çıkarım yapmaya olanak sağlayan kısmen ayrışabilir yapıyı vurgulamaktadır. İkinci olarak, bağlaşımlı ayrışım modellerinde çıkarım yöntemleri geliştireceğiz. Önerdiğimiz yöntemler üç ana grupta toplanabilir. İlk gruptaki yöntemlerde, enbüyük olabilirlik ve enbüyük sonsal kestirim için eniyileme tabanlı yöntemler üzerinde duracağız. İkinci grup yöntemler bağlaşımlı ayrışım modellerinde önemli bir rol oynayan ilgili ağırlık ve ıraksayları da beraber olarak kestirmektedir. Son olarak üçüncü grupta tam Bayesçi çıkarım yöntemleri üzerinde yoğunlaşacağız ve saklı değişkenlerin sonsal dağılımlarından örnek çekme amacıyla birçok Markov Zinciri Monte Carlo yöntemi geliştireceğiz. Önerdiğimiz yöntemleri birçok zorlu uygulamada sınayacağız. Bilhassa, ses işleme alanında görülen birçok zorlu uygulama için yeni ayrışım modelleri geliştireceğiz. Ayrıca, dağıtık çıkarım yöntemlerimizi büyük çaplı bağlantı kestirimi problemlerinde sınayacağız ve bu uygulamaların hepsi için başarılı sonuçlar göstereceğiz.","In this thesis, we focus on coupled matrix and tensor factorization models; that provide a good modeling accuracy -- practicality trade off for modeling large-scale and/or heterogeneous data that are collected from diverse sources. Our main concern in this thesis will be to develop inference methods for coupled tensor factorization models. We will first develop a rigorous tensor factorization notation, that aims to cover all possible model topologies and coupled factorization models. Our notation highlights the partially separable structure of tensor factorization models, which paves the way for developing parallel and distributed inference algorithms. Secondly, we will develop novel methods for making inference in coupled tensor factorization models. The proposed methods can be separated into three groups. In the first set of methods, we will focus on optimization-based approaches for making maximum likelihood and a-posteriori estimation of the latent variables. The second group of methods builds up on the first group and jointly estimates the relative weights and divergence functions, which play important role in coupled factorization models. Finally, in the third group, we will focus on full Bayesian inference, where we will develop several Markov Chain Monte Carlo methods for sampling from the posterior distributions of the latent variables. We will evaluate our methods on several challenging applications. We will develop novel factorization models for addressing challenging audio processing applications. We will also evaluate our distributed inference methods on large-scale link prediction applications, where we will report successful results in all of these applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayarla görme alanında, hareket ve etkinlik tanıma üzerine birçok araştırma yapılmıştır. Video indeksleme, gözetim ve video özetleme gibi uygulama alanları için videolarda hareket tanıma oldukça önem taşır. Bu tezde, KYM videolarda hareket ve etkinlik tanıma, hem öznitelik çıkarma hem de sınıflandırma açısından araştırılmaktadır. Gerçekçi ortamda büyük ölçekli hareket tanıma problemi için yeni bir yaklaşım önerilmektedir. Video betimleme yöntemlerinin üzerinden geçildikten sonra, önerilen yaklaşım tanıtılmaktadır. Bu yaklaşımda, Fisher vektörleri ile tanımlanmış yerel yörünge öznitelikleri, aşırı öğrenme makinesi (extreme learning machine) sınıflandırıcısına verilmektedir. Aşırı öğrenme makinesinin, destek vektör makinesi gibi diğer sınıflandırıcılara göre daha hızlı ve başarılı bir alternatif olduğu gösterilmiştir. Ek olarak bu çalışmada, insan vücudu bölümleri hakkında bilgi içeren bazı orta seviye özniteliklerin bu problem için kullanılabilirliği araştırılmaktadır. Önerilen yaklaşımın her basamağı yoğun ve karşılaştırmalı bir şekilde incelenmektedir. Değerlendirmeler yakın zamanda ilk olarak yarışmalar için yayınlanmış gösterge veri kümeleri üzerinde yapılmaktadır. Bunlar UCF101, THUMOS 2014 ve ChaLearn Looking at People 2014 Track 2 olarak sıralanabilir. İlk veri kümesindeki videolar sadece hareket içerecek şekilde kırpılmışken, diğer iki veri kümesindekiler zamansal olarak kırpılmamıştır ve dolayısıyla daha zor koşullar içerir. THUMOS 2014 veri kümesindeki 102 hareket sınıfı üzerinde %63.37 ortalama başarı elde edilmiştir. Bu sistem THUMOS yarışmasında üçüncülük almıştır. Sonuçlarımız aşırı öğrenme makinesinin hem hesaplama açısından etkin, hem de yüksek başarılı bir sınıflandırıcı olduğunu göstermiştir.","A great deal of research in computer vision community has gone into action and event recognition studies. Automatic video understanding for actions are crucial for application areas such as video indexing, surveillance and video summarization. In this thesis, we explore action and event recognition on RGB videos both in terms of feature extraction and classification. We propose a novel approach for large-scale action recognition in a realistic setting. After reviewing the technical background about recent popular video description methods, we present our approach in which improved dense trajectory features in combination with Fisher vector encoding are fed to extreme learning machine classifier. It is shown that extreme learning machine provides a fast and accurate alternative to other traditional classifiers such as support vector machines. Additionally, we investigate the usability of some mid-level features that we introduce to encode information about human part regions. We extensively study each step of our pipeline in a comparative manner. We evaluate our approach on recently published benchmarks which were introduced as challenge datasets: UCF101, THUMOS 2014 and ChaLearn Looking at People 2014 Track 2. Videos in the first dataset contain cropped actions while the ones in the last two datasets are temporally untrimmed, introducing more challenge. On 102 action classes of THUMOS 2014 dataset, we achieve 63.37% mean average precision using the challenge protocol, which has ranked 3rd among other participants. Our results show that, using extreme learning machine, efficient learning can be performed in terms of both time and computational complexity while preserving high performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nörogörüntüleme araştırmalarında büyük miktarlarda veri toplanması bilişsel süreçlerle ilgili bilginin ayrıştırılması için yeni yöntemlerin geliştirilmesini gerektirmektedir. Bu tez çalışmasının amacı çok boyutlu ve birden fazla nörogörüntüleme modalitesinden elde edilen beyin verisinin işlenmesine elverişli yöntemler sunmaktadır. Nörogörüntüleme modalitelerinin tümleştirilmesindeki (fusion) en büyük zorluk elde verilerin uzaysal ve zamansal olarak farklı bilgiler taşımasıdır. Bu problem, tensörlerle ifade edilen EEG ve fMRG verisinin hem ortak hem de ayrık altuzaylarda ayrıştırılması ve ortak uzaysal profilin kortikal yüzeyde doğrudan veriden hesaplanması ile aşılmıştır. Aynı şekilde beyin bağlantılılığının Granger nedensellik analizi de tensör tabanlı bir modelle ifade edilmiş ve böylelikle tensör yöntemleri bu problemde kullanılabilmiştir. Bağlantılılık analizi için sunulan ilk yaklaşımda tensör yöntemleri kullanılarak bağlantılılık örüntüsü seyrekleştirilmiştir. İkinci yaklaşımda ise bağlantı örüntüleri atomsal yapılara bölünmüştür. Genel teori ve hesapsal olarak etkin algoritmalar sunulmuştur. Önerilen teknikler tümleştirme modeli için eşzamanlı EEG ve fMRG kayıtlarının üzerinde; bağlantılılık modelleri için hızlı çekim fMRG veri seti üzerinde uygulanmıştır. Önerilen yaklaşımların nörolojik hastalıkların erken teşhisinden beyin-bilgisayar arayüzü gibi uygulamalara kadar geniş bir alanda kullanım imkanı olabilir.",Acquisition of large amounts of data in neuroimaging research requires development of new methods that can disentangle the underlying information and reveal the features related to cognitive processes. This thesis attempts to propose new methods that favor the multimodality and multidimensionality of the brain data. The main difficulty for the fusion of imaging modalities is the discrepancies in their spatial and temporal resolutions as well as the different physiological processes they reflect. This problem is addressed by decomposing the EEG and fMRI data cast as tensors on both common and discriminant subspaces and computing the common spatial profile from the data on the cortical surface. The Granger causality analysis of brain connectivity is reformulated on tensor space enabling incorporation of tools developed in that area of research. The first approach on this analysis facilitated tensor methods for sparse representation of the connectivity patterns whereas the second method resolved them as atomic structures. General theory and computationally efficient algorithms are presented. The techniques are illustrated on the simultaneous EEG/fMRI recordings for the fusion model and on the fast fMRI data for the connectivity analysis. The proposed approaches may have a wide application area ranging from the early diagnosis of neurological diseases to the brain-computer interface studies.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Zengin bir algılayıcı kümesi ile donatılmış akıllı telefonlar, insan eylemlerinin tanınmasında alternatif platformlar olarak yaygın hesaplama alanında araştırılmaktadır. Ancak bu tip sistemlerin kitleler tarafından başarılı bir şekilde kabul edilebilmesi için bir takım zorluklar mevcuttur. Bu tezde, bilhassa insan davranışlarından ve donanımdan kaynaklanan zorluklara yoğunlaşılmıştır. Bu faktörlerin eylem tanıma başarımı üzerindeki etkisini analiz edebilmek için, 20 katılımcıdan ivmeölçer algılayıcısı kullanılarak, beş temel hareket eylemi içeren bir veri kümesi toplanmıştır. Bu veri kümesi kullanılarak, eylem tanımanın cihaz, cihaz modeli, kullanıcı, cihaz yönelimi ve cihaz pozisyonu gibi telefon üzerinde eylem tanımayı etkileyecek faktörlerden bağımsız olarak yapılıp yapılamayacağı analiz edilmiştir. Öncelikle cihaz ve cihaz modelinden bağımsız bir şekilde eylem tanıma deneylerinde %96 başarım elde edilirken, cihaz pozisyonu ve kullanıcı bağımlılığı testlerinde %87 ve %90 başarım elde edilebildi. Bu konularla baş etmek için, öncelikle doğrusal ivmelenme değerleri hesaplandı ve ardından algılayıcıların birleşimi ile ivmenin telefon koordinatlarından dünya koordinatlarına çevrilmesi sağlandı. Bu metotlar ile, cihazın yöneliminin etkisi ortadan kaldırılarak, kişiden ve yönelimden bağımsız eylem tanımanın başarımı sırayla %98 ve %95'e yükselmiştir. Son olarak telefonun pozisyonun etkisi üç farklı metot, genel sınıflandırma, pozisyona-özel sınıflandırma ve ortak sınıflandırma kullanılarak analiz edilmiş ve pozisyona özel sınıflandırma yapmanın gerekli olmadığı genel sınıflandırma kullanmanın da benzer sonuçlar elde ettiği gösterilmiştir. Ancak, karışıklık matrislerine yakından bakıldığında sabit aktivitelerin (ayakta durma ve oturma) başarımı düşürdüğü ve bu aktiviteleri tek bir sınıfta birleştirilmesi ile eylemler %98 üzerinde bir başarım ile tanınabilmektedir.","Smart phones equipped with a rich set of sensors are explored as alternative platforms for human activity recognition in the ubiquitous computing domain. However, there exist challenges that should be tackled before the successful acceptance of such systems by the masses. In this thesis, we particularly focus on the challenges arising from the differences in user behavior and in the hardware. To investigate the impact of these factors on the recognition accuracy, we collected data from 20 users focusing on five basic locomotion activities using the accelerometer, gyroscope and magnetometer. Using this dataset, we analyze whether activity recognition can be performed independently in terms of device, device model, user, device orientation and device position. We first show that, using raw acceleration, above 96% recognition accuracy can be obtained for device and model dependency tests, while success rate for orientation and user dependency tests remained at 87% and 90%. In order to tackle these issues, we first calculated linear acceleration, then using sensor fusion these acceleration readings are converted from phone coordinates to the earth coordinates. These methods helped in removing the orientation effects and increased both the user-independent and orientation-independent activity recognition accuracy to 98% and 95%. Finally, we analyze the impact of phone position on activity recognition using three different methods, namely using a generalized classifier, position-specific classifier and a joint classifier and show that using position-specific classification is not necessary, a generalized classifier performs very similarly. However, analyzing the confusion matrices, we observe that, stationary activities (sitting and standing) reduce the performance and combining these activities into a stationary class boosted recognition rates up to 98%."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevirimiçi çoklu oyunculu bilgisayar oyunları, kendine özgü davranış kuralları ve sosyal normları ile yeni sosyal platformlar oluşturmaktadır. Bulunulan platforma göre saldırgan ve tacizkar davranışlar değişkenlik gösterebilmesine rağmen, hemen hemen tüm oyun üreticileri bu tür davranış ve istenmeyen durumlar ile aktif olarak mücadele etmektedir. Yapay zeka ve otomatik öğrenme yöntemleri, geliştiriciler tarafından oyun öğelerinin etkileşiminde kullanılmasının yanında daha sağlıklı bir oyun ortamı oluşturabilmek için oyuncuların davranışlarının analizinde de kullanışlı olabilmektedir. Bu tez çalışmasında, çevirimiçi sosyal bir oyun platformundaki oyuncuların sözel ve sözsüz iletişim verisi kullanılarak tacizkar oyuncular ve ilgili oyuncu şikayetlerinin otomatik olarak sınıflandırılması üzerine yenilikçi yaklaşımlar öneriyoruz. Çalışmamızda oyuncu şikayetlerinde taraf olan oyuncuların oyun profillerinden oluşan öznitelikler ile birbirleri arasında geçen iletişime dair bilgiler üzerinden çıkarımı yapılan öznitelikleri kullanmaktayız. Bu yenilikçi yaklaşımın benzer özelliklere sahip başka oyun platformlarına adapte edilerek oyun geliştiricilere yardımcı olacağını öngörüyoruz. Çalışmamızda kullandığımız 100.000 tekil kullanıcı ve 800.000 oyun verisi barındıran COPA oyun veritabanını sunuyoruz. Bu veritabanı, Türkçe çoklu sohbet verisinin yanında oyuncu profili, sosyal etkileşimleri ve elle incelenmiş ve işaretlenmiş oyuncu şikayetlerini içermektedir. Önerdiğimiz yöntemler bu veritabanı üzerinde deneylerden geçirilmiştir. Son olarak, öznitelik kümemizi iyileştirme amacıyla otomatik duygu analizi ve aynı oyuncuya ait birden fazla oyuncu hesabı olup olmadığını kestirebilmek için geliştirdiğimiz yöntemleri anlatmaktayız.","Online multiplayer games create new social platforms, with their own etiquette, social rules of conduct and ways of expression. What counts as aggressive and abusing behavior may change depending on the platform, but most online gaming companies need to deal with aggressive and abusive players explicitly. Artificial intelligence and machine learning techniques are not only useful for creating plausible behaviors for interactive game elements, but also for the analysis of the players to provide a better gaming environment. In this thesis, we investigate the verbal and non-verbal data generated in an online social gaming platform and propose novel algorithms for automatic classification of abusive players and player complaints. We use features that describe both parties of the complaint (namely, the accuser and the suspect), as well as interaction features of the game itself. This methodology is sufficiently generic, and it can be applied to similar gaming platforms, thus describing a useful tool for game companies. We also introduce the COPA Database of 100.000 unique users and 800.000 individual games, which includes multiparty chat records in Turkish, in addition to player profiles, social interactions, and annotated complaint data. The proposed supervised methodologies for complaint classification are tested on this database, and we advance the state-of-the-art in this challenging problem. In addition, we developed a methodology for affect analysis to enrich the interpretation of the data. Finally, we developed a system for authorship recognition based on chat records to identify duplicate user accounts and returning abusive users by analyzing the chat data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Uygulama ve sistemlerdeki güvenlik problemleri bilgi kaybına, finansal kayıplara ve hatta insan yaşamının kaybına varabilecek kadar ciddi sonuçlar doğurmaktadır. Bu nedenle bilgi sistemleri güvenliği her geçen gün daha fazla dikkat çekmektedir. Bu güvenlik problemlerinin büyük bir kısmı, güvenlik fonksiyonlarının tasarım aşamasında düşünülmemesinden ve geliştirme aşamasında doğrudan yazılıma eklenmesinden kaynaklanmaktadır. Halbuki, güvenlik fonksiyonlarının analizi, tasarımı ve doğrulanması çok yüksek önem derecesine sahiptir. Hatta bazı durumlarda, yazılım tasarımlarının ve kodlarının formel veya yarı-formel olarak doğrulanması ve yetkili otoritelerce sertifikalandırılması beklenmektedir. Bilgi sistemlerinin güvenlik fonksiyonlarının değerlendirilmesi için sıklıkla kullanılan standartlardan birisi Ortak Kriterler'dir. Bu tez çalışmasında, bilgi sistemlerinin güvenlik özelliklerinin analizi, tasarımı ve değerlendirmesi için yeni bir çerçeve olarak Model Güdümlü Güvenlik Çerçevesi'ni (MDSF) önermekteyiz. Amacımız, bilgi sistemleri geliştiren kişileri ve üst seviye Ortak Kriterler sertifikasyonu (EAL 6 ve EAL 7) için değerlendirme yapan yetkilileri, hazırlık ve inceleme süreçlerinde Unified Modelling Language (UML), Object Constraint Language (OCL), Promela ve Spin dil ve araçlarını kullanarak desteklemektir. MDSF ile, IT ürününün UML modeli üzerinden, güvenlik analizi ve tasarımı yapılabilmesini desteklemek amacıyla, UML diline yeni bir profil önermekteyiz. UML'e ek olarak, güvenlik tehditlerinin belirlenmesi, farklı model seviyeleri üzerinde uyumluluk kontrolü ve IT ürününün UML tasarım modeli üzerinde güvenlik poliçelerinin doğrulanması amacıyla OCL'in kullanılabileceğini göstermekteyiz. Ayrıca, tasarım modelinin, güvenlik ihtiyaçlarını karşılayıp karşılamadığını formel olarak göstermek amacı ile model dönüştürme ve model doğrulama tekniklerini UML, OCL ve PROMELA üzerinde kullanmaktayız.","Information system security is receiving increasing attention every day because a security problem can cause serious financial loss or even loss of lives. Some of these security problems occur as a result of poor design practices, where important security functionality is not designed properly and is directly implemented later in the development cycle in an unmethodical way. Researchers have put a great deal of effort into defining processes and tools to design and develop more secure information systems. However, verification of the designed and developed security functionality is of utmost importance. In some cases, designs and codes also need to be formally or semi-formally verified and certified by authorities. The Common Criteria is one of the widely used universal frameworks for evaluating the security functionality of information systems. In this thesis, we propose a new framework, Model Driven Security Framework (MDSF), for the analysis, design and evaluation of security properties of the information systems. Our aim is to support information system developers and evaluation authorities who implement the higher-level Common Criteria (Levels 6 and 7) security assurance process using formal methods based on Unified Modelling Language (UML), Object Constraint Language (OCL), Promela and Spin. With MDSF, we extend UML to support security analysis and design on the UML models of the information system. In addition to UML, we use OCL in MDSF for threat identification, consistency checking among diagrams and security policy enforcement in the design model. We also propose a model transformation and model checking approach to formally verify whether the design model satisfies the security requirements listed in the analysis model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otonom robotların insanlara ait yaşam alanlarında görevlendirilmesi hedefi, uzun soluklu bir tutku olmakla birlikte, günümüzde gerçekleşmeye - evvele kıyasla - çok daha yakındır. Robot navigasyonunda karşılaşılan temel sorunların birçoğu, bu alanda yapılan yoğun çalışmalar sonucu çözülmüştür. Literatürde, hareketli robotların hiçbir yere çarpmadan hedeflerine ulaşmalarını sağlayacak birçok navigasyon yöntemi bulunmaktadır. Bununla birlikte, İnsan-Robot Etkileşimi (İRE) çalışmaları, hareketli robotların çarpışmasızlık açısından güvenli olmalarının yanında, hareketlerinin insanlar tarafından anlaşılabilir olmasının da gerekli olduğunu ortaya koymaktadır. Hareketli robotların hareketlerindeki anlaşılırlık, onların insan nezdinde kabul görme oranını artıracaktır. Bu sayede, biz insanlar, gündelik hayattaki robot varlığını içselleştirmeye başlayacağız. İnsan-farkında navigasyon, eski navigasyon yöntemlerinin bu doğrultudaki eksikliklerine atfen ortaya çıkmıştır. Sosyal Kuvvet Modeli, ilk olarak, yayaların hareketlerini matematiksel olarak ifade etmek amacıyla ortaya atılmıştır. Bu yaklaşım, tur rehberi olarak görev alacak robotumuzun üzerinde çalışmasını planladığımız, insan-farkında navigasyon modülünü geliştirmek için kullanılmıştır. Bu model, yapay potansiyel alanlar ailesinin bir üyesidir; doğası itibariyle, robot navigasyonunda yerel patika planlayıcı olarak kullanılmaya uygundur. Çalışmada, söz konusu model sunulmakta ve onun temel patika planlama algoritmalarından farkları anlatılmıştır. Yaklaşımın, yerel patika planlayıcı olarak programlanış detayları aktarılmakta ve benzetim ortamında, sosyal olarak kabul edilebilirliği daha yüksek navigasyon üreten algoritmamızın işleyişi gösterilmektedir.","Today, the long-lived dream of employing autonomous mobile robots in human environments is more close to coming into reality than ever. Most of the fundamental navigation problems are solved due to an extensive research on the field of mobile robotics. Today, there are many navigation strategies that enable robots to navigate through their surrounding environments in a collision-free manner. However, Human-Robot Interaction (HRI), suggests that, in addition to being safe, navigation of a robot must be understandable to humans, as well. Comprehensibility of the movements of a robot increases its acceptance among humans. This way, it is believed by many that, we will begin to internalize the presence of mobile robots in our daily lives. The concept of human-aware navigation refers to these shortcomings of the previous methods in this direction. Social Force Model was proposed to describe the motion of the pedestrians. We use this approach to develop a human-aware navigation module for our tour-guide robot. This model is a variant of a large-family, so-called artificial potential fields. The nature of the model makes it a good candidate for local path planning. In this work, we present the model and the differences of it from fundamental path planning algorithms. We explain the implementation of the model as a local path planner and show on simulated environment that a more socially-acceptable motion may be achieved using this model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde sosyal medya kullanımının artan popülerliği ve sosyal meydada paylaşılan verilerin içerdiği bilginin değeri göz önüne alındığında, bu tür yapılandırılmamış metinlerden bilgi çıkarımı yapabilemek büyük ilgi görmeye başlamıştır. Bu durum doğal dil işleme araştırmaları açısından pek çok zorluğu da beraberinde getirmiştir. Bu çalışmamızda morfolojik açıdan zengin bir dil olan Türkçe için varlık ismi tanıma probleminin, özellikle mikroblog metinleri gibi yapılandırılmamış metinlerde çözümüne odaklandık. Bu amaçla, güdümlü ve güdümsüz öğrenme aşamalarından oluşan ve yapay sinir ağlarını baz alan yarı güdümlü bir öğrenme tekniği kullandık. İlk olarak hızlı ve güdümsüz bir öğrenme metodu kullanarak çok boyutlu sürekli vektör uzayında Türkçe kelime temsillerini elde ettik. Daha sonra gerek bu kelime temsillerini, gerekse yapılandırılmamış mentinler için daha iyi sonuç verecek şekilde uyarlanmış, dilden bağımsız öznitelikleri kullanarak bu tür metinler için bir Türkçe varlık ismi tanıma sistemi geliştirdik. Yapılandırılmamış ve kısa Türkçe metinleri incelemek amacıyla, en popüler mikroblog platformu olan Twitter üzerine yoğunlaştık ve geliştirdiğimiz sistemi tweet adı verilen kısa Twitter mesajları üzerinde denedik. Sistemimizin Türkçe Twitter mesajları üzerindeki performansının daha önce bu amaçla yayınlanmış sistemlerin performansından daha iyi olduğunu gördük. Türkçe Twitter metinlerinde varlık ismi tanıma için yayınlanmış en gelişkin sistemi %11 iyileştirme ile aşmış olduk. Sistemimizin dile özgü tek aşaması, varlık isimleri tanınmadan önce Türkçe Twitter metinleri üzerinde uyguladığımız Türkçe metin normalizasyonu aşamasıdır ve bu aşama yapılandırılmamış metinlerde performansı artırmaktadır. Normalizasyon aşaması dışında dile özgü öznitelikleri doğrudan kullanmadığımız için yöntemimizin morfolojik açıdan zengin diğer dillerdeki yapılandırılmamış metinlere de kolayca uyarlanabileceğine inanıyoruz.","Recently, due to the increasing popularity of social media and the value of information contained within real data, the necessity for extracting information from informal text types such as microblog texts gains significant attention, together with the challenges it brings to the Natural Language Processing (NLP) research community. In this study, we focused on the Named Entity Recognition (NER) problem for Turkish, which is known as a morphologically rich language, on informal text types such as microblog texts. For that purpose, we utilized a semi-supervised learning approach composed of an unsupervised stage followed by a supervised stage based on neural networks. We applied a fast unsupervised method for learning continuous representations of Turkish words in vector space. We make use of these obtained word embeddings, together with language independent features that are engineered to work better on informal text types, for generating a Turkish NER system on microblog texts. For examining informal and short texts in Turkish, we focused on the most popular microblogging environment called Twitter and we evaluated our Turkish NER system on short and unstructured Twitter messages called tweets. With our NER system, we achieved better F-score performances than the published results of previously proposed NER systems on Turkish tweets. To be more precise, we outperformed the state-of-the-art F-score by up to 11% on the same Turkish Twitter data. The only language dependent stage of our system is the normalization scheme we applied for Turkish microblog texts as a preprocessing step before the NER application, which improves the performance of our NER system on informal text types. Since we did not employ any language dependent features, other than this Turkish text normalization, we believe that our method can be easily adapted to microblog texts in other morphologically rich languages."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mahremiyet Web tabanlı sistemler için önemli bir konudur. Web sistemleri mahremiyet politikalarını yayımlayarak kullanıcı bilgilerine karşı olan tutumlarını açıklarlar. Kullanıcıların mahremiyet gereksinimlerinin birbirinden çok farklı olabilmesine rağmen, Web sitelerindeki mahremiyet politikaları büyük ölçüde sabittir ve kullanıcı bazında değişmez. Çevrimiçi sosyal ağlar kullanıcılarına kısmi olarak kişisel mahremiyet ayarları yapma imkanı tanısa da sosyal ağlarda mahremiyet ihlali sıklıkla karşılaşılan bir durumdur. Bunun nedeni bağlam, izleyici ve içerik temelli mahremiyet endişelerinin kullanıcı tarafından yeteri kadar detaylı girilmesine olanak sağlanmamasıdır. Bu sorunu çözmek için, her paylaşım öncesi paylaşımın ilgilendirebileceği tarafların otomatik olarak müzakere etmesine olanak sağlayan bir yapı öneriyoruz. Buna yönelik olarak, sosyal ağlardaki her bir kullanıcının kendisine ait bir etmen yazılımı olmasını öngörüyoruz. Bir sosyal ağ kullanıcısı başka bir kullanıcının mahremiyetini ihlal edebilecek bir aktivitede bulunacağı zaman (ör. fotoğraf paylaşımı), ilgili kullanıcıların etmen yazılımları sahiplerinin mahremiyetini koruyacak şekilde müzakere ederek bu aktivitenin oluşturacağı mahremiyet ihlalini daha en başından önlemiş olacaklardır. Bu çalışma ile bahsedilen etmen yazılımların iletişim kurallarını belirleyen bir müzakere protokolü geliştirilmiştir. Ayrıca bu protokole uyan örnek bir etmen yazılım ontoloji teknolojisi kullanılarak geliştirilmiş olup, bu etmen yazılımda kullanıcı tercihlerinin nasıl modellendiği ve mahremiyet sınırlarının nasıl etkin bir biçimde müzakere edilebileceği gösterilmiştir. Yazdığımız etmen yazılım üzerinde yaptığımız değerlendirmeler, sunduğumuz yöntemin sosyal ağlarda yaşanan bazı mahremiyet ihlallerini daha gerçekleşmeden önleyebileceğini göstermektedir.","Privacy is a major concern of Web systems. Traditional Web systems employ static privacy policies to notify its users of how their information will be used. Recent social networks allow users to specify some privacy concerns, thus providing a partially personalized privacy setting. However, still privacy violations are taking place because of different privacy concerns, based on context, audience, or content that cannot be enumerated by a user up front. Accordingly, we propose that privacy should be handled per post and on demand among all that might be affected. To realize this, we envision a multiagent system where each user in a social network is represented by an agent. When a user engages in an activity that could jeopardize a user's privacy (e.g., publishing a picture), agents of the users negotiate on the privacy concerns that will govern the content. We employ a negotiation protocol and use it to settle differences in privacy expectations. We develop a novel agent that represents its user's preferences semantically and reason on privacy concerns effectively. Execution of our agent on privacy scenarios from the literature show that our approach can handle and resolve realistic privacy violations before they occur."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Modern çok çekirdekli CPU ve GPU mimari simülasyonunu hızlandırmak için sentetik karşılaştırma uygulamalarını otomatik şekilde yaratan, karakterizasyon ve sentezleme bileşenleri olan yeni sentezleme araçları geliştirdik. İlk olarak, CPU ve GPU sistemleri için önemli olan karakteristiklerin kümesi belirledik. Daha sonra geliştirdiğimiz araçlar ile bu karakteristikleri mevcut uygulamalardan toplayarak bu uygulamaların yüksek hızda simülasyonuna olanak sağlayan minyatür halleri olan sentetik karşılaştırma uygulamaları oluştururduk. CPU uygulamalarının önemli karakteristiklerini toplamak için yazılım mimari kalıplarını kullandık ve çeşitli makine öğrenme tekniklerini uygulayarak bu yazılım mimari kalıpları otomatik olarak tanımladık. Bununla beraber bu makine öğrenme tekniklerini doğruluk ve hız açısından karşılaştırdık ve yazılım mimari kalıplarının tanımlanmasının performans ve mimari eniyileme açısından önemli olduğunu gösterdik. Sentezlenen karşılaştırma uygulamalarımız küçük, hızlı, taşınabilir ve okunabilir olduğu gibi sentezlendikleri gerçek uygulamanın karakteristiklerini de doğru şekilde taklit etmektedir. Sentetik CPU karşılaştırma uygulamalarımız Pthreads veya Multicore Association (mesaj iletim veya kaynak yönetim) kütüphanelerini ve sentetik GPU karşılaştırma uygulamalarımız OpenCL kütüphanesini kullanabilmektedir. Bu çalışma ile varolan GPU uygulamarından ilk kez sentetik OpenCL karşılaştırma uygulaması geliştirildi. CPU tekniklerimiz için MIMIME aracını geliştirdik ve sentetik karşılaştırma uygulamaları yarattık. Benzer şekilde, GPU tekniklerimiz için MINIME-GPU aracını geliştirerek deneylerle tekniklerimizi doğruladık.","We present a novel automated multicore benchmark synthesis framework for multicore systems including CPUs and GPUs with characterization and generation components to speed up architectural simulation of modern architectures. We first identify a set of important application characteristics for CPUs and GPUs. Then, our framework captures these characteristics of original multicore applications and generates synthetic multicore benchmarks from those applications where synthetic benchmarks are a miniaturized form of applications that allow high simulation speeds and act as proxies of proprietary applications. We use parallel software architectural patterns in capturing important characteristics of CPU applications where we apply different machine learning techniques in a novel approach to automatically detect parallel patterns used in applications. In addition, we compare these techniques in terms of accuracy and speed and demonstrate that detecting parallel patterns is crucial for performance improvements and enables many architectural optimizations. The resulting synthetic benchmarks are small, fast, portable, human-readable, and they accurately reflect the key characteristics of the original multicore applications. Our synthetic CPU benchmarks use either Pthreads or Multicore Association (message passing and resource management) libraries and synthetic GPU benchmarks use OpenCL library. To the best of our knowledge, this is the first time synthetic OpenCL benchmarks for GPUs are generated from existing applications. We implement our techniques for CPUs in the MINIME tool and generate synthetic benchmarks. Similarly, we implement our techniques for GPUs in the MINIME-GPU tool and experimentally validate them."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz ağ algılayıcıları (KAA) ve akıllı telefonlar kullanılarak geliştirilen Yaşsam Takip sistemleri yaşam kalitesinin çıkarılmasında sıkça kullanılmaktadır. İnsanların 24 saatlik yaşamı ev içi, ev dışı ve uyku olmak üzere üç ana kısma ayrılabilir. Kişinin ev içi veya ev dışı yaşamını takip eden ve yaşam kalitesini değerlendiren birçok çalışma mevcuttur. Fakat, asıl zor olan kişinin 24 saati boyunca gerçekleştirdiği eylemlerin takibini yapan bir sistemin geliştirilmesidir. İnsanların hayatlarının üçte birini uyuyarak geçirdiği düşünüldüğünde, uyku da ihmal edilmemesi gereken önemli bir eylemdir. Uyku çalışmalarında genellikle kişinin uyku kalitesine odaklanılırken, uyku kalitesini etkileyen etkenler göz ardı edilebilmektedir. Ayrıca, kişinin yaşam tarzının uyku kalitesine önemli etkisi olduğu düşünülmektedir. Bu amaçla, kişinin uyku da dahil 24 saatlik yaşamını kapsayan kesintisiz bir eylem takip sistemi geliştirdik. Önerilen sistem bir KAA ve bir akıllı telefon kullanarak, insanlardan yaşam günlüğü ve uyku verilerini toplamaktadır. KAA çeşitli algılayıcıları kullanarak gececil çevresel değerleri ve uyku verilerini toplamaktadır. Diğer taraftan, akıllı telefon üzerinde çalışan uygulamalar kişinin gerçekleştirdiği eylemleri ve bulunduğu yerleri süreleriyle beraber kayıt altına almaktadır. Deneysel veri toplama aşamasında dokuz kişi on beş gün boyunca sistemimizi kullanmıştır. Sistem geliştirilirken kullanıcılara rahatsızlık vermemesi ve onların özeline saygılı olması hedeflenmiştir. Kişinin uyku kalitesini etkileyen öğelerin bulunması amacıyla, toplanan verilere üç ayrı öznitelik seçim yöntemleri uygulanmıştır. Deneylerin sonucunda, Uyku Gecikmesi ve Serbest Etkinlik Süresi öznitelikleri bütün yöntemler tarafından uyku kalitesini etkileyen önemli etkenler olarak raporlanmıştır.","Human life monitoring systems utilizing wireless sensors networks (WSNs) and/or smart phones became a hot topic for the evaluation of the life quality. A daily life of a human can be divided into three main parts as outside, home and sleep. There are various systems that monitor the lifestyle of a human either inside or outside the home. Yet, the challenge is to develop a system that covers all the activities of a person for 24 hours. Considering the fact that people spend one-third of their lives sleeping, sleep is another important activity to monitor. While sleep studies mainly focus on the sleep quality of a person, the effects of life style and ambient factors on the sleep quality are usually neglected. In this thesis, we propose a seamless human life monitoring system that covers 24 hours of a person's life including the sleep activity. The proposed system utilizes a WSN and a smart phone and collects life-log and sleep data from multiple users. The WSN collects nocturnal ambient and sleep data via various sensors. On the other hand, the applications running on the smart phone collect daily performed activities with their durations and locations. In the data collection phase, we employed nine people for fifteen days. The system is designed to provide the unobtrusiveness and respect the privacy of the users. By using the collected data, we extracted the sleep behavior and the life style choices of the users. In order to figure out the factors affecting the sleep quality of a person, we applied three feature selection algorithms namely the decision tree, the correlation coeficient, and the sequential feature selection to the collected data. The results indicate that two features namely the Sleep Onset Latency and the Leisure Activity Duration are reported as important features in all of three algorithms for their effects on the sleep quality."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nanoteknoloji, mevcut teknolojilerin nano seviyede yetersiz kaldığı durumların üstesinden gelmek için birçok alanda kullanılmaktadır. Ancak, nano-makinelerin kısıtlı işlemci güçleri ve hafızaları düşünüldüğünde, karmaşık işlemlerin yapılabilmesi için yeni iletişim yöntemlerine ihtiyaç duyulacagı anlaşılmaktadır. Nano seviyede iletişim, ele alınması gereken önemli bir problem olarak ortaya çıkmaktadır. Doğadan esinlenen difüzyon ile moleküler haberleşme yöntemi bu problemin çözümünde kullanılabilecek yöntemlerden birisidir. Taşıyıcı moleküllerin alım sürecinin, difüzyon ile moleküler haberleşme başarımına önemli bir etkisi olmasına rağmen, soğuran alıcının aldığı sinyali etkileyen faktörler literatürde yeterli ölçüde araştırılmamıştır. Bu tezde, öncelikle analizlerimizde kullanılmak üzere difüzyon ile moleküler haberleşme benzetiminin daha etkin biçimde yapılabilmesi için iki yeni model önerilmektedir. Önerilen modellerden ilki, benzetim hassasiyetini koruyarak daha hızlı çalısmasını sağlayan iki-alanlı benzetim modeli, diğeri ise difüzyon ile moleküler haberleşme benzetimlerinin dağıtık yapılmasına olanak veren HLA tabanlı mimaridir. Sonrasında, analitik formüllerin elde edilebilmesi için soğuran alıcı alım süreci değişik yönleriyle analiz edilmektedir. Sonuçlar, alıcı ve reseptör üretim maliyetlerinin eniyilemesini mümkün kılmaktadır. Son olarak da, soğuran alıcılarda bilginin demodülasyonu için yeni bir yaklaşım önerilmekte ve önerilen modelin enerji ihtiyacı ve veri hızı incelenmektedir.","Nanotechnology is currently being applied to vast number of fields to overcome the challenges faced with existing technologies that cannot efficiently scale down to nano level. However, considering the limited processing and memory resources of nano-machines, performing complex tasks requires new communication mechanisms. Communication is one of the important issues to be addressed in nano-scale environment. Inspired by the nature, molecular communication via diffusion is a candidate to address this issue. Although the reception process of the messenger molecules has a significant impact on the performance of molecular communication via diffusion, the factors that effect the received signal for an absorbing receiver have not been investigated in the literature. In this thesis, we first introduce methods for efficient simulation of molecular communication via diffusion to enable further analysis. We propose two novel simulation architectures; a dual-zone simulation model to decrease execution time while preserving simulation accuracy and an HLA based architecture for distributed simulation of molecular communication via diffusion. Then, we analyse different dimensions of reception process for an absorbing receiver to derive closed form formulations. The results presented enable optimizations that will have a direct effect on production costs of receptors and the receivers. Finally, we propose a new approach for demodulation of information for an absorbing receiver and analyse energy consumption and data rate for the proposed model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Saldırı çizgeleri, güvenlik açıkları ve bunların etkileşimlerinin olası olduğu tüm dizileri göstererek aşamalı ağ saldırılarını önlemek için analitik destek sağlamaktadır. Saldırı çizgeleri genellikle çok fazla sayıda düğümden oluşmaktadır. Bu düğümleri analiz etmek ve aşamalı ağ saldırılarına karşı korunma çözümleri bulmak zordur. Bu tezde, kompakt saldırı çizgeleri kullanarak, ağları korumak için düşük maliyetli bir çözüm bulan açgözlü, sezgisel bir yöntem öneriyoruz. İlk olarak, ağda önceden belirlenmiş kritik kaynaklara ulaşan olası tüm saldırı yolları çıkartılır. Minimum maliyetle saldırı yollarına en fazla katkı sağlayan güvenlik açığı yada başlama koşulu devre dışı bırakılmak için seçilir. Bu işlem tekrarlanarak devam eder ve toplam maliyet ayrılan bütçeyi aştığında bir güvenlik analisti onu durdurabilir. Simülasyon sonuçları, önerilen yöntemin çizge büyüklüğü ile hemen hemen doğrusal karmaşıklığa sahip ve çok geniş ölçekli çizgelere uygulanabilir olduğunu göstermektedir. Simülasyon sonuçları ayrıca, yöntemin optimum çözüme yaklaşık düşük maliyetli bir çözüm bulduğunu göstermektedir. Buna ek olarak, önerilen yöntem ağın tehditlere karşı ne kadar savunmasız olduğunu göstermek için her adımda ağın güvenlik seviyesini ölçer. Bu özellik, ağ güvenlik değerlendirmesi ve mevcut durum farkındalığı için faydalıdır.","Attack graphs provide analytical support to prevent multistep network attacks by showing all possible sequences of vulnerabilities and their interactions. Since attack graphs generally consist of a very large number of nodes, it is computationally challenging to analyze them for hardening a network against attacks. In this thesis, we propose a greedy heuristic method to find a cost-effective solution to protect a network using compact attack graphs. First, we extract all possible attack paths which reach predetermined critical resources embedded in the network. The exploit or initial condition which contributes the most to attack paths with least cost is selected to be removed. This process continues iteratively and a security analyst can stop it when the total cost exceeds the allocated budget. The experimental results show that our algorithm scales almost linearly with the size of the networks and it can be applied to large-scale graphs with a very large number of nodes. They also show that the algorithm finds nearly minimum cost solution compared to optimal solution. In addition to providing a network-hardening solution, our proposal measures the security level of the network in every step to demonstrate how vulnerable the network is against threats. This accompanying feature is beneficial for network security assessment and situation awareness."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmamızda morfolojik açıdan zengin dillerde varlık ismi tanıma probleminin çözümüyle ilgilendik. Bu bağlamda, yapay sinir ağlarına dayalı yarı güdümlü öğrenme metodunu kullandık. İlk evrede, hızlı ve güdümsüz bir algoritma kullanarak kelimelerin çok boyutlu sürekli uzaydaki vektör gösterimlerini elde ettik. İkinci evrede ise, kelimelerin bu gösterimleri ile birlikte diğer bazı dil bağımsız öznitelikler de kullanarak varlık ismi tanıma sistemi geliştirdik. Oluşturduğumuz bu sistemi çok çekimli dillerden olan Türkçe ve Çekçe üzerinde denedik ve bu diller üzerinde yayınlanmış en gelişkin sistemlerden daha iyi performanslar elde ettik. Türkçe'de en gelişkin sistemi %2.26 ile, Çekçe'de ise en gelişkin sistemi %1.53 ile geliştirdik. Dile özgü öznitelikler de kullanan bu en gelişkin sistemlerden farklı olarak, çalışmamızda tamamen dilden bağımsız öznitelikler kullandık. Dolayısıyla yaptığımız bu çalışmanın morfolojik açıdan zengin olan diğer dillere de kolaylıkla ve başarıyla uygulanabileceğini düşünüyoruz.","In this study, we addressed the Named Entity Recognition (NER) problem for morphologically rich languages by employing a semi-supervised learning approach based on neural networks. We adopted a fast unsupervised method for learning continuous vector representations of words, and used these representations along with language independent features to develop a NER system. We evaluated our system for the highly inflectional Turkish and Czech languages and obtained better F-score performances than the previously published results for these languages. We improved the state-of-the-art F-score by 2.26% for Turkish and 1.53% for Czech. Unlike the previous state-of-the-art systems developed for these languages, our system does not make use of any language dependent features. Therefore, we believe it can easily be applied to other morphologically rich languages."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüz teknolojisindeki gelişmeler ölçeklenebilirlik alanındaki beklenen verim artışını karşılayamadığından dolayı geleceğin hesaplama sistemleri için heterojen ve eş zamanlı mimarilerin yaygın kullanımı kaçınılmazdır. Yeniden betimlenebilir yapısı sayesinde alanda programlanabilir kapı dizileri (APKD=FPGA) bu tür mimariler için gelecek vaat eden bir altyapıdır. APKD'nin her bir birimi kendisine uygun olan farklı bir görevi yapmak üzere betimlenebilir. Bu tür veri bağımlı hesaplama mimarileri için çoklu giriş-çıkışlı ve hızlı yazmaç dosyası olmadığı takdirde mevcut hesaplama gücü israf edilmiş olur. Her bir işlem biriminin nitelikleri farklı olduğunda ise, bu mimari çalışma hızı, veri üretim/tüketim oranı, ihtiyaç duyulan port sayısı, veri yolu genişliği, adres aralığı, bitlerin dizilimi gibi farklı nitelikler açısından APKD'nin her bir ünitesine hizmet verebilecek bir heterojen yazmaç dosyasına ihtiyaç duyulmaktadır. Bu tezde, çoklu giriş-çıkışlı yazmaç dosyası tasarımı önerilmiştir. Bu yazmaç dosyası, APKD içinde bulunan rastlantısal erişim hafızasının kümeleme ve kopyalama yöntemlerinin verimli kaydırma yazmacı tabanlı çoklu pompalanma yöntemiyle tasarlanmıştır. Sayısal tasarıma ek, bu yazmaç dosyası yüksek seviyeli sentez araçları için modellenmiştir. Bu çalışma daha da ilerletilerek, APKD tabanlı heterojen sistemler için heterojen yazmaç dosyası tasarlanmıştır. Bu yazmaç dosyasında, işlem ünitelerinin veri genişiliği ve adres aralıkları ayarlanabilmektedir. Harcanan güç ve alan miktarlarının azaltılması için, çoklu pompalama yönteminden faydalanılmıştır. Bu yöntem işlemci ile yazmaç dosyası arasndaki hız farklarını kullanmaktadır. Bu çalışma APKD tabanlı heterojen yazmaç dosyaları alanındaki ilk çalışmadır. Deney sonuçlarına göre her iki yazmaç dosyası mimarisi de geleneksel mimarilere göre daha yüksek başarımlıdır.","For the future of computing, wide usage of heterogeneous and parallel architectures is indispensable since advances in technology scaling cannot satisfy the expected increase in performance of computational platforms anymore. FPGA is a promising platform for such computing systems due to its configurable structure. Each part of an FPGA can be configured to perform a different task that it is best suited for. Multi-port and fast register files are very essential for this type of data intensive computational systems. Otherwise, available computational power cannot be utilized properly. When the characteristics of processing elements are different, such a system needs a heterogeneous register file (RF) that can serve different parts of the FPGA with different characteristics in terms of running frequency, data consumption/production rate, required number of ports, data widths, address spaces and endianness. In this dissertation, we firstly propose a new multi-port RF design which exploits the banking and replication of BRAMs with efficient shift register based multi-pumping (SR-MPu) approach. We also model this register file for the use of HLS tools. Finally, we propose a heterogeneous register file (HRF) architecture for FPGA-based heterogeneous systems. In this RF, world length and address spaces of the processing elements are adjustable. For the power and area reduction, the design takes advantage of frequency differences between processing elements by an efficient multi-pumping system. According to the literature, this is the first study on FPGA-based heterogeneous RFs. Experimental results show that both RF architectures outperform conventional RFs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gen ifadesi deneylerinin bir aşamasında veriler manuel yöntemlerle elde edildiği için verilerin güvenilirliği düşüktür. Bu verilerin bir veri madenciliği algoritmasına ya da modele direkt girdi olması durumunda varılmak istenen sonuçların güvenilirliğinin olumsuz yönde etkilemesi kaçınılmazdır. Çalışmamızda, elde edilen verilerin belirsizliğini azaltmak için her verinin, örnek veri üretme teknikleriyle elde edilen veri kümeleriyle temsil edilmesini sağladık. Örnek veri yaklaşımı verilerin belirsizlik yüzdesini azaltırken işlem yapılan veri setinin örnek veri kümesi eleman sayısı oranında artmasına, dolayısıyla da ilgili veri işleme algoritmalarının sonuç üretme zamanının artmasına neden olmaktadır. Çalışmamızın ilk kısmında belirsiz verilerin hızlı bir biçimde kümelenebilmesi için çok çekirdekli sistemler üzerinde eş zamanlı çalışabilen M-FDBSCAN adını verdiğimiz bir ""belirsiz veri kümeleme"" algoritması geliştirdik. Algoritmada önerilen yöntemle yalnızca çok çekirdekli sistemlerde değil tek çekirdekli sistemlerde de veri işleme hızında büyük artışlar sağlandığı gösterdik. Çalışmamızın ikinci kısmında M-FDBSCAN algoritmasını, zaman serisi verilerinin hızlı ve etkin bir biçimde işlenebildiği, E-MFDBSCAN adı verilen bir ""evrimsel kümeleme"" algoritmasına dönüştürdük. Bu yeni algoritma global kümelerin oluşturulmasını sağlamaktadır. Çalışmamızın son aşamasında oluşturulan global kümelerin zaman bazlı evrimsel desenlerini kullanarak bir öngörü modeli geliştirdik. Bu öngörü modeliyle bir sonraki zaman noktasına ait bir global kümenin benzerlik ve desen bilgilerinin kestiriminin yapılabilmesini sağladık.","Because of using manual methods in some parts of gene expression experiments, reliability of the data is low. If this data is directly utilized as input to a data mining algorithm or a model for evaluating gene expression data, then the adverse affects to the desired results will be inevitable. In order to eliminate aforementioned adverse affects and reduce the fuzziness, we represent the data with sample data sets that are generated by using uncertain data management techniques. Sample data approach not only reduces the percentage of fuzziness, but also it causes the output generation time to be increased due to an increase in the amount of processed data, which is directly proportional to the cardinality of the sample data set. In the first part of the study, we introduce an uncertain data clustering algorithm, named M-FDBSCAN, for enabling one to cluster uncertain data rapidly, which runs on multi-core systems in a concurrent fashion. We show that by using the proposed method, the algorithm yields considerable performance improvement on single core systems, as well. In the second part of the study, M-FDBSCAN algorithm is converted into an evolutionary clustering algorithm, named E-MFDBSCAN, by which time series data can be processed rapidly and efficiently. This new algorithm enables to generate global clusters. In the last part of the study, using time-based evolutionary patterns of global clusters a prediction model is constructed. The proposed prediction model enables us to predict the patterns and the similarities of a global cluster that will be generated at the next time point."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Eğitim verisi büyüklüğü istatistiksel makine çevirisi (İMÇ) için büyük öneme sahiptir çünkü veri büyüklüğü; eğitim süresi, model büyüklüğü, çözümleme hızı ve sistemin başarım skoru gibi birçok şeyi etkiler. Az kaynaklı diller için İMÇ sistemleri hazırlanırken karşılaşılan en büyük zorluklardan birisi de kullanılabilir eğitim verisi miktarının sınırlı olmasıdır. Bu tezde, alan dışı bir paralel derlem kullanılarak eğitim verisinin genişletildiği bir yaklaşım önerilmiştir. Alan dışı derlemden en iyi cümleleri seçip eğitim verisine eklemek sistemin genel performansı için önemlidir. Önerdiğimiz yöntem ile önce alan dışı derlemdeki cümleler dil modeli kullanılarak sıralanır, daha sonra kelime doyurma süzgeci tekniğiyle içlerinden bazıları seçilerek eğitim verisine eklenir. Önerilen yöntem İngilizce-Türkçe dil çifti için denenmiş ve başarılı sonuçlar elde edilmiştir. İngilizce-Türkçe makine çevirisinde 0.8 BLEU puanına varan skor artışı sağlanmıştır. Sonuçlar öbek tablosu kombinasyonu yöntemleri ve en iyi İngilizce-Türkçe makine çevirisi sistemleri ile de karşılaştırılıp elde edilen gelişmeler raporlanmıştır. Ayrıca cümleler sıralarken n-gram tabanlı dil modellerinin yanı sıra bağımlılık tabanlı dil modellerine göre sıralama da denenmiş ve sonuçlar paylaşılmıştır.","The training data size is of utmost importance for statistical machine translation (SMT), since it affects the training time, model size, decoding speed, as well as the system's overall success. One of the challenges for developing SMT systems for languages with less resources is the limited sizes of the available training data. In this thesis, we propose an approach for expanding the training data by including parallel texts from an out-of-domain corpus. Selecting the best out-of-domain sentences for inclusion in the training set is important for the overall performance of the system. Our method is based on first ranking the out-of-domain sentences using a language modeling approach, and then, including the sentences to the training set by using the vocabulary saturation filter technique. We evaluated our approach for the English-Turkish language pair and obtained promising results. Performance improvements of up to +0.8 BLEU points for the English-Turkish translation is achieved. We compared our results with the translation model combination approaches and the best English-Turkish translation systems as well, then reported the improvements. Moreover, we implemented our system with dependency based language modeling in addition to n-gram based language modeling and reported comparable results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Taraflılık ve olumluluk analizi, son yıllarda oldukça ilgi çeken bir araştırma alanı haline geldi. Bu alanda, temel olarak, metin, konuşma veya resim gibi içeriklerde taraflılık veya olumluluk gibi özellikler olup olmadığını bulmayı sağlayan yöntemler geliştirilir ve araştırılır. Taraflılık ve olumluluk analizi alanları, adlarının da çağrıştırdığı gibi, birbirleriyle oldukça ilgilidir fakat taraflılık analizi görece daha az ilgi görmüş bir alandır ve insanlar içinbile zor bir konu olmasından dolayı daha fazla çalışılmaya muhtaçtır. Taraflılık tespitini ilk alt probleme ayırabiliriz; birincisi, taraflılık özelliklerini çıkarmak ve ikinci olarak, verilen yeni bir metnin taraflılığını tahmin etmek. Birinci problem için, dilbilimsel özellikler başlıca başvuru kaynaklarındandır. Taraflılığın tahmininde ise çoğunlukla yapay öğrenme yöntemleri kullanılır. Bu açıdan, taraflılık tespiti problemi, bir çeşit metin sınıflandırma problemine indirgenebilir. Biz bu çalışma-da, yapay öğrenme yöntemlerini kullanarak, haber metinlerinde taraflılık tespiti problemi konusunda çalıştık ve doküman seviyesinde çalışan bir uygulama geliştirdik. Metinlerdeki betimleyici öğelerin taraflı tonu yakalamada iyi bir özellik olabileceği önkabulü altında, taraflılık sınıflandırması için yeni bir öznitelik kümesi tanımladık. Denetimli öğrenme algoritmaları kullanarak, yöntemimizi kendi topladığımız ve etiketlediğimiz bir veri seti üzerinde test edip değerlendirdik. Yöntemimizin ve deney bulgularımızın, taraflılık tespiti alanına katkı sunacak nitelikte kullanışlı olduğunu gördük; deneylerdeki başarım değerlerinin de düşük olmadığını gözlemledik. Sonuç olarak, bu çalışma ile Türkçede yapılmış ilk taraflılık sınıflandırması sistemini, etiketlenmiş yeni bir veri seti ile beraber sunuyoruz.","Subjectivity and sentiment analysis research has gained increasing attention in the recent years like many language technologies. Its aim is to investigate and to develop techniques to recognize subjectivity or sentiment in human-generated content such as text, speech or image. While subjectivity and sentiment detection tasks are necessarily related to each other, subjectivity detection is relatively understudied and needs more attention, being a challenging problem even for humans. For capturing subjectivity clues in the text, various linguistic properties are made use of and for predicting the subjectivity of an unknown piece of text, machine learning methods are applied. In this respect, the subjectivity detection problem can be reduced to a text classi cation problem. A set of texts evaluated for some prede ned clues of subjectivity, are input to a learning module, which will predict if a given unknown piece of text is subjective or objective. In this work, we study subjectivity detection in news items using machine learning methods and develop a framework that runs at the document-level. We assume that the descriptive features of expressions is a good candidate to capture the subjective tone in texts and based on this premise, propose a novel feature set for subjectivity classi cation. We implement a supervised scheme and extensively evaluate it on a dataset which we have collected and annotated. Our ndings present new directions and useful contributions to the subjectivity detection literature. We introduce the rst subjectivity detection system in Turkish language, present our new database with annotations and report high accuracy in subjectivity detection."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"This thesis focuses on the practical implementation of transmitter location estimation algorithms using software de ned radio devices for the purpose of radio environment map construction, which is used to determine primary user location and available channels for Cognitive Radio. To this end, a testbed is also set up and technical and physical details of this testbed are explained. Using the received signal strength (RSS) data collected from receivers with xed known locations, the path loss character of an open eld line of sight channel is estimated. Then, the location of an immobile transmitter is estimated using the collected RSS data from multiple receivers by applying one proposed and one known technique, and the results of these estimations are explained and compared. The e ect of receiver count and the environmental factors on the precision of the results are also explained. To share the gained experimental knowledge, the practical diculties, tradeo s, and experiences encountered during the implementation and measurement phases are explained."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Protein ve ilaçlar arasındaki ilişkinin analizi, yalnızca yeni ilaçların keşfi konusunda değil, proteinlerin ilaçlar üzerinde oluşturabileceği olası evrimsel baskının daha iyi anlaşılması açısından da büyük önem taşımaktadır. Benzer proteinlerin benzer ligandlara bağlanması esasına dayalı olarak tasarladığımız bu çalışmada, ligand benzerliği iki farklı yaklaşımla ele alınmıştır. İlk olarak, protein aileleri üyeleri arasındaki ilişkiyi bağlandıkları ligandlar yolu ile inceleyen ligand-merkezli ağ modelleri tanıtılmıştır. Proteinlerin ağın düğümleri olarak temsil edildiği üç farklı ağ modelinde, iki protein düğümü, ağırlığı proteinlerin ortak olarak bağlandıkları ligandların sayısına veya bağlandıkları ligandların benzerliğine bağlı olarak değişen bir kenar ile bağlanır. Bu kısımda Beta-laktamaz ve Penisilin-Bağlayan Protein aileleri üzerine yoğunlaşılmıştır. Ligand paylaşım bilgisinin kullanımıyla oluşturulan grupların hem amino-asit dizilimi hem de fonksiyonel benzerlikleri olan proteinleri biraraya topladığı gözlenmiştir. Ligand benzerlik bilgisinin kullanımı proteinlerin gruplanması işlemini iyileştirmekle kalmayıp aynı zamanda ortak ligand ağlarının bulamadığı bazı etkileşimleri vurgulamıştır. İkinci kısımda, protein-ligand ilişkisi tahminlemede makine öğrenmesi yaklaşımını izleyerek Destek Vektör Makinelerinin kullanıldığı farklı ligand benzerlik çekirdek fonksiyonlarının karşılaştırılmasına odaklanılmıştır. Bu modelde daha büyük bir veri kümesi olarak GPCR ve iyon kanalları aileleri incelenmiştir. Test ettiğimiz 15 farklı ligand çekirdek fonksiyonu arasında GPCR veri kümesinde, SMILES karakter dizisini kullanan LINGO bazlı TF-IDF kosinüs benzerliği, 2D parmakizi Tanimoto modelinden daha iyi bir performans üretmiştir.","Analysis of the interactions between target proteins and drugs is crucial not only for drug discovery, but also for a better understanding of the possible evolutionary pressure that the drugs exert on the proteins. Based on the hypothesis that similar proteins bind to similar ligands, ligand similarity is utilized with two different approaches. We first introduce ligand-centric network models to analyse the relationships of protein family members via the drugs that they bind to. We build three different types of networks in which the proteins are represented as nodes, and two proteins are connected by an edge with a weight that depends on the number of shared identical or similar ligands. As a test case, we focus on Beta-lactamases and Penicillin-Binding Proteins. The use of ligand sharing information to cluster proteins results in modules comprising proteins both with sequence and functional similarity. Consideration of ligand similarity not only enhances the clustering of the target proteins, but also highlights some interactions that were not detected in the identical ligand network. In the second part, we follow a machine learning approach for predicting protein-ligand interactions using Support Vector Machines (SVM) where we focus on comparing different ligand similarity kernels. For this task, a larger data set of GPCR and ion channels is examined. Among the 15 different ligand kernels we experiment with, LINGO based TF-IDF cosine similarity achieves a 0.009 better AUC score than the widely used 2D Fingerprint Tanimoto model on the GPCR data set."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Vikipedi (Wikipedia), şüphesiz ki insanlık tarihinin en önemli müşterek bilgi ürünlerinden biridir. Vikipedi'yi üreten ortak çaba temel bir önemi haizdir çünkü, topluluk anonim, ücret almayan editörleri içermekte ve gözlenebilir bir yukarıdan aşağıya hiyerarşi bulunmamaktadır. Bu çalışmada biz, Vikipedi kullanıcılarının ortaklaşa metin/madde düzenleme faaliyetinin bir ajan-bazlı modelini öneriyoruz. Bu şebeke (graph) teorisi yaklaşımında, her kullanıcı ve madde çokşekilli (multimodal) ilişki ağında birer düğüm (vertex) ile temsil edilmektedir. Eğer bir kullanıcı bir maddeyi düzenlemeyi seçerse, o kullanıcının düğümü ile ilgili maddenin düğümü arasında bir bağ (edge) yaratılır. Kullanıcı tercihleri, statüleri, maddelerin nispi içerik kaliteleri, yardımlaşmanın dağılımı ve sonuçta oluşan ilişkiler, ağ üzerinde incelenir. Girdi parametrelerinin, topaklanma katsayısı (clustering coefficient), yol uzunluğu (path length), küçük dünya karakteristiği (small world characteristic), derece orantısı (degree correlation) ve derece dağılımı (degree distribution) gibi başlıca şebeke niteliklerine etkisi analiz edilmiştir. Benzetim (simülasyon) bulguları, kullanıcıların ilgi alanlarının boyutlarının ve aktif kullanıcı yüzdesinin, şebekedeki toplam bağ sayısı ile, dolayısıyla ansiklopedi kalitesiyle, doğru orantılı olduğuna işaret etmektedir. İyi madde eşik parametreleri ise, aksine, yüksek kaliteli içerik (iyi madde ve seçkin madde) eşiğini yükseltmekte ve ansiklopedideki toplam düzenleme sayısı ile ters orantılı olduğu görülmektedir. Vikipedi'de iyi ve seçkin madde seçimi için kolaylaştırılmış ve otomatik bir süreç tavsiye ediyoruz. Deneyler seçkin madde eşiğinin düşürülmesinin Vikipedi'nin tamamında kalite artışı sağladığını göstermektedir. Ayrıca başarılı editörlerin emeğinin yayılması için seçkin içerikte içsel bağlantı yoğunluğunun arttırılmasını tavsiye etmekteyiz.","Wikipedia is no doubt one of the most important collaborative informational products of human history. The collaborative effort that produces Wikipedia is of fundamental importance because the community includes anonymous, uncompensated editors and a lack of observable top-down hierarchy. In this study, we propose an agent-based model for Wikipedia users' activity of collaborative article editing. In this graph-theoretical approach every user and article are represented as vertices in a multimodal affiliation network. When a user chooses to edit an article, an edge between the node of the user in question and that of the edited article, is created. User preferences, statuses, relative content quality of articles, distribution of collaboration and resulting relationships are examined in the network. We analyse input parameters' effects on resulting principal graph characteristics, namely the clustering coefficient, the path length, the small world characteristic Q, degree correlation, and degree distribution. Simulation findings point out that, users' area of interest dimensions and active user percentage are positively correlated with the total edge count in the graph; therefore, the encyclopaedia quality. Conversely, good article threshold parameters raise high-quality article specifications and are negatively correlated with the total edit count in the encyclopaedia. We recommend an easier, automated process for the selection of good and featured articles of Wikipedia. Experiments have demonstrated that lowering the barrier of high quality status for articles, results in more effort and quality for the encyclopaedia as a whole. Additionally, we recommend more internal link concentration in good and featured articles, in order to spread the effort of their successful editors."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu makalede, dokümanlardan anlamlı kavramlar çıkarmak için sözlük-tabanlı bir metot geliştirilmiştir. Şu ana kadar İngilizce'de kavram çıkarma üzerine birçok çalışma yapılmıştır; ama sondan eklemeli bir dil olan Türkçe için bu alanda henüz geniş kapsamlı bir çalışma olmamıştır. Bu çalışmada biz resmi Türkçe sözlüğünden faydalandık. Normal sözlükler kavram madenciliğinde az kullanılmaktadır; ama kelimelerin sözlükteki anlam cümlelerindeki diğer kelimelerle başta hipernim, hiponim, eşanlam olmak üzere bazı ilişkilere sahip olduğu göz önünde bulundurularak yürütülen çalışma sonunda başarı oranları yüksek çıkmıştır.","In this study, a dictionary-based method is used to extract expressive concepts from documents. So far, there have been many studies concerning concept mining in English, but this area of study for Turkish, an agglutinative language, is still immature. We used dictionary for concept extraction. The dictionaries are rarely used in the domain of concept mining, but taking into account that dictionary entries have synonyms, hypernyms, hyponyms and other relationships in their meaning texts, the success rate has been high for determining concepts."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telif hakkı uygulamalarının artmasından dolayı son on yılda damgalama sistemleri önem kazandı. İnsan duyma sistemi görme sistemine göre daha hassas olduğundan sese bilgi gömmek resimlere kıyasla daha zordur. Bundan dolayı dijital ses için damgala- ma algoritmaları resimler için olanlardan daha azdır.Bu tezde geniş spektrum dijital ses damgalama sistemi kullanılarak biyometrik kimlik doğrulama sistemi sunuldu. Açık kaynak IP üzerinden ses gönderme programı olan Sipdroid programı Android işletim sistemi üzerinde kullanıldı. Biyometrik kimlik doğrulama sistemi Sipdroid programına eklendi. Öncelikle, konuşmada gönderen kısım sisteme eşsiz biyometrik özellikleri ile kayıt olmalıdır.T. C. kimlik numarası, tuş basma dinamikleri ve ses biyometrik özellik olarak seçildi. Kayıttan sonra, kaydedilen biyometrik özellikler sese damgalanan materyal olarak kullanıldı.Gömme işleminden önce imge Doğrudan Serili Geniş Spektrum (DSSS) sistemi kullanılarak genişletildi. Konuşma sırasında imge konuşmaya Frekans Sekmeli Geniş Spektrum (FHSS) sistemi kullanılarak gömüldü ve alıcıya gönderildi. Damgalanan ibiyometrik veriler konuşma sonrası alıcının telefonunda yeniden oluşturuldu. Uygulanan metod orijinal ses sinyaline ihtiyaç duymaz. Deneysel sonuçlar gömme sisteminin hem daha az duyulabilir hem de gauss gürültüsü ekleme, düşük geçiş filtresi, kesme, sıkıştırma gibi yaygın işaret işleme ataklarına karşı daha sağlam olduğunu gösterdi. Alıcı kısmında sisteme giriş yapılabilmesi için, kullanıcının biyometrik özelliklerinin damgalanan biyometrik veri ile eşleşmesi gerekir.","Watermarking has become important in the last decade because of the copyright protection applications. Embedding information into an audio file is more difficult as compared to images, because human auditory system is more sensitive than human visual system. Therefore, the proposed watermarking algorithms for digital audio have been less than those for digital image and video. This thesis presents a biometric authentication scheme based on spread spectrum watermarking technique. We add a biometric authentication system to the Sipdroid open source VoIP program. Firstly, senders must register to the system with their unique biometric features. T.C Identity number, keystroke dynamics and voice are used as biometric features. After registration, these biometric features are used as watermarked material. Before embedding, the watermark is spread with the Direct Sequence Spread Spectrum (DSSS) technique. While talking, this watermark material is embedded to speech and sent to receiver using Frequency Hopping Spread Spectrum(FHSS) technique. The watermarked biometric data is constructed in the receiver's phone after conversation is finished. This method does not need the original audio carrier signal when extracting watermark because it is using the blind extraction. The experimental results demonstrate that the embedding technique is not only less audible but also more robust against the common signal processing attacks like low-pass filter, adding white Gaussian noise, shearing, and compression. In order for receiver to be able to login to the system, biometric features of the user should match with the watermarked biometric data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Veri ve iletişim teknolojilerinde enerji tüketimi son yıllarda önemli bir konu haline gelmiştir. Enerji tüketim maliyetleri ve çevresel faktörler kablolu ağlarda yeşil ağ çözümlerini gerektirmektedir. Üstten destekli rotalama, normalde kullanılan rotalama mekanizmalarının standartlarını değiştirmeye gerek kalmadan performansını ve güvenilirliğini arttıran bir metottur. Bu çalışmada, kablolu ağlardaki üstten destekli rotalama, enerji etkinliği açısından ele alınmıştır. Üstten destekli rotaları ve röle düğümlerini belirleyen JORRA (Bütünleşik Üstten Destekli Yönlendirme ve Röle Ataması) isimli bir optimizasyon problemi tanımladık. Ağdaki kaynak-hedef ikilileri için enerji etkinliği ve güvenilirlik arasındaki dengenin yanısıra röle maliyetleri, ağ elemanlarının uyutma modunun olup olmayacağı gibi konuları da göz önüne aldık. JORRA problemini ILP olarak tanımladık. Bunun yanısıra polinom zamanlı iki buluşsal algoritma tasarlayarak performans değerlendirmesi ile bu algoritmaların pratik uygulamalara elverişli olduğunu gösterdik.","Power consumption of information and communication technologies (ICT) has increasingly become an important issue in the last years. Both energy costs and environmental concerns call for energy aware ""green"" networking solutions in wired networks. Overlay routing is an attractive method to enhance the performance and reliability of routing mechanisms without the need to change the standards of the current underlying routing. In this work, we focus on overlay routing in wired networks from an energy efficiency perspective. We formulate an optimization problem called JORRA (Joint Overlay Routing and Relay Assignment), which jointly determines the overlay routing paths and relay nodes. We consider issues such as the relay costs, whether the network elements can be put into sleep mode or not as well as the energy efficiency and reliability trade off for source and destination pairs in the network. We formulate JORRA as an integer linear program. Moreover, we propose two polynomial time heuristic algorithms and demonstrate through performance evaluation that our heuristics are suitable for practical implementation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet ortamındaki elektronik belgelerin sayısındaki hızlı artış, bilgi yükü problemini de beraberinde getirmistir. Otomatik çoklu doküman özetleme bu problemi çözmede gelecek vaadeden yöntemlerden biridir. Otomatik çoklu doküman özetleme için temelde iki yaklaşım vardır. Bunlar özetlenecek metinlerden önemli cümlelerin çeşitli yöntemlerle seçilmesi ile özet oluşturan cümle seçerek özetleme ve özetleme işini doğal dil işleme metotları kullanarak metinlerden yeni cümlelerin oluşturulmasıyla yapan yorumlayarak özetleme yaklaşımlarıdır. Cümle seçerek özetleme yöntemlerinin büyük bir kısmında cümleler arası benzerlik bulma işi önemli bir yer tutar. Bu çalışmada, bağımsal dilbilgisini cümleler arası benzerlik bulma probleminde kullandık ve oluşturduğumuz benzerlik yöntemini cümle seçerek çoklu doküman özetleme işine uyguladık. Bu iş için iki farklı bağımsal ağaç bazlı cümleler arası benzerlik bulma yöntemi kullandık. İlk olarak ilişki çıkarımı için önerilmiş bu yöntemler hesaplamalarında bağımsal dilbilgisindeki bağıntıların türlerinden yararlanmıyorlardı. Bu metotlarla çalıştıktan sonra bağıntıların türlerini de hesaba katan bir dizi yeni bağımsal dilbilgisi bazlı cümleler arası benzerlik bulma yöntemi geliştirdik. Tasarlanan bu yöntemler diğer iki yöntemden daha iyi sonuç verdiler. Bu çalışma sonucunda cümleler arası benzerlik bulmada bağımsal dilbilgisi kullanımının başarılı sonuçlar verdiğini gördük. Cümleleri bağımsal ağaç yapısını kullanarak göstermenin cümleler arasındaki benzer kısımları bulmakta iyi sonuç verdiğini gözlemledik. Ayrıca bağımsal ağaçlardaki bağıntıların türlerinin cümlelerdeki önemli kısımların bulunmasında önemli rol oynadığı sonucuna vardık.","Information overload is one of the greatest challenges in recent years, especially due to the rapid increase of data produced on the Internet. Automatic summarization of documents about similar topics is a salient solution to overcome this problem. There are mainly two approaches for this task, extractive multi-document summarization where the summary is created by selecting salient sentences from documents, and abstractive multi-document summarization where new sentences are generated using natural language generation methods. Sentence similarity calculation is significant in most of the extractive multi-document summarization approaches. In this study we introduce usage of dependency grammars to compute sentence similarity for extractive multi-document summarization problem. We adapt and investigate the effects of two untyped dependency tree based sentence similarity kernels, which have originally been proposed for relation extraction, to multi-document summarization problem. In addition, we propose a series of new dependency grammar based kernels to better represent the syntactic and semantic similarities among the sentences. The proposed methods incorporate type information of dependency relations for sentence similarity calculation. Our best method achieves significantly better scores than the untyped dependency tree based kernels. We observe that using dependency grammar representation of sentences leads better results in finding the similarities between sentences and the type of dependency relations is crucial in identifying the important parts in sentences."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada acil durum ve afet müdahalelerinde kaynak yönetimi sorununu ele alan algoritmaların geliştirilmesi ve kullanılması üzerinde durulmuştur. Sunulan sistem, Afet Yönetim Platformu (AYP), servis sağlayıcıların veri kaynaklarından veri almakta ve buna bağlı olarak gelen istekleri mümkün olabildiğince yük dengesini korumaya ve hizmet süresini minimize etmeye çalışarak tahsis etmektedir. Çalışma için, yük dengesine ve hizmet süresine farklı derecede önem veren, üç değişik kaynak yönetimi algoritması önerilmiştir. İlki, gelen isteği en yakın kaynağa tahsis eden Minimum Uzaklık algoritması. İkincisi, gelen isteği yükü en az olan kaynağa tahsis eden Minimum Yük algoritması. Sonuncusu, önceki iki algoritmayı birleştiren Karma algoritma. Önerilen algoritmaların performansı bekleme süresi, başarı oranı ve maksimum yük oranına göre değerlendirilmiştir. Farklı yüklere karşı ideal düzeni bulmak için ölçümler simulasyonlardan izlenmiştir. Çalışmada biri zaman tabanlı diğeri ortalama istek geliş süresi tabanlı iki farklı simulasyon gerçekleştirilmiştir. Sonuçlara göre Minimum Yük algoritması genellikle tüm ölçümlerde en iyi olduğu halde, Minimum Uzaklık algoritması her durumda ve tüm ölçümlerde en kötü olarak belirlenmiştir. Performansta lider konum, ortalama istek geliş süresi değerleri değiştikçe, Minimum Uzaklık ile Karma algoritmalar arasında değişmektedir.","This thesis focuses on the development and use of algorithms that address the issue of resource management in response to emergency and disaster situations. The presented system, named Disaster Management Platform (DMP), takes the data from the data sources of service providers and distributes the incoming requests accordingly both to manage load balancing and minimize service time, which results in improved user satisfaction. Three different resource management algorithms, which give different levels of importance to load balancing and service time, are proposed for the study. The first one is the Minimum Distance algorithm, which assigns the request to the closest resource. The second one is the Minimum Load algorithm, which assigns the request to the resource with the minimum load. Finally, the last one is the Hybrid algorithm, which combines the previous two approaches. The performance of the proposed algorithms is evaluated with respect to waiting time, success ratio, and maximum load ratio. The metrics are monitored from simulations, to find the optimal scheme for different loads. Two different simulations are performed in the study, one is time-based and the other is request interarrival time-based. The results indicate that, the Minimum Load algorithm is generally the best in all metrics whereas the Minimum Distance algorithm is the worst in all cases and in all metrics. The leading position in performance is switched between the Minimum Distance and the Hybrid algorithms, as request interarrival time values change."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nanoağlar nanometre ölçüsündeki makineler arası iletişimin gerçekleştirilmesi adına umut vaat eden yeni bir kavramdır. Nanoağlar literatüründe önerilen çözümler arasından; bu tezde, birçok moleküler haberleşme türüne temel oluşturan Moleküler Difüzyon ile Haberleşme sistemine odaklanılmaktadır. Tez içerisinde, ilk olarak, haber-leşme molekülü yıkımı olan kanallarda soğurma özelliği olan alıcıların 3-B küre şeklinde analitik olarak modellenmesi ele alınmakta, formülasyon ve simülasyon arasındaki uyuşmalar gösterilmektedir. İkinci olarak, sinyal zirve noktası zamanı ve sinyal zirve noktası enliği gibi metrikler kullanılarak molekül yıkımının sinyal karakteristiklerine olan etkileri analitik olarak gösterilmektedir. Burada, haberleşme molekülü yıkımına tabi olan sistem, yıkıma tabi olmayan sistem ve elektromanyetik iletişim kanalı belirtilen karakteristikler açısından karşılaştırılmaktadır. Son olarak, farklı molekül yıkımı hızlarına göre sistem performansı değerlendirilmektedir. Burada, sistem performansı semboller arası girişim, algılama performansı, bit hata oranı ve veri hızı gibi geleneksel ağ metrikleri ile değerlendirilmektetir. Sonuçlar, molekül yıkımı kullanılan sisemlerin doğru koşullar altında kayda değer performans artışı sağladığını göstermektedir. Belirli bir iletişim uzaklığı için, molekül yıkım hızını artırmak sistem performansını bahsi geçen tüm metriklerde bir tepe noktasına kadar artırmaktadır. Ancak, bu noktadan sonra, hızlı molekül yıkımının çoğu molekülün alıcıya ulaşamadan yıkılmasına ve sonuç olarak sistem başarımının düşmesine sepep olduğu gözlenmektedir.","Nanonetworking is a promising new paradigm that focuses on communication between nanoscale machines. In the nanonetworking literature, many solutions have been suggested to enable the information transfer between nano-machines. Among these solutions, we focus on molecular communication via diffusion which constitutes a basis for many types of molecular communication. Specifically, we start with the analytical model of 3-D absorbing receiver under messenger molecule degradation and show that our formulations are in agreement with the simulation results. Next, we identify the effects of degradation in signal characteristics such as pulse peak time and pulse amplitude, and we analytically show how degradation is used for signal shaping in molecular communication via diffusion. Here, we also compare communication under degradation with the case of no degradation and electromagnetic communication in terms of channel characteristics. Lastly, we evaluate the performance of the degradation system for different choices of degradation rates. Here, we assess the system performance according to traditional network metrics such as the level of inter-symbol interference, detection performance, bit error rate, and data rate. Our results indicate that introducing degradation significantly improves the system performance. For a given distance, increasing degradation rate also increases the system performance in terms of all metrics mentioned above up to a peak performance point. However, after the peak point, degradation becomes too fast and causes most of the molecules to degrade before reaching the receiver, which in turn deteriorates the system performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ortamı manipüle edebilme, insanların günlük yaşamlarının önemli ölçüde bu yetiye dayandığı düşünülürse, özerk hareketli servis robotlarının sahip olması beklenen özelliklerin başında gelmektedir. Tam formu görevin gereksinimleri ile ortamın, nesnenin, ve robotun fiziksel özellikleri nedeniyle ortaya çıkan kısıtlarca belirlenmekle birlikte, hareketli bir robot pek çok şekilde manipülasyon yapabilir. Çeşitli incelemeler insanların günlük manipülasyon görevlerinde çoğunlukla etkileşim ve gözlem sonucu elde ettikleri manipülasyon tecrübelerinden faydalandıklarını göstermektedir. Bu motivasyonla, bu tez çalışması, pratik ve etkili hareketli manipülasyonun nesneye özgü, ayrık, ve potansiyel olarak olasılıksal durumlar şeklinde saklanan geçmiş tecrübelerin yeniden kullanılması ile başarıldığı durum temelli bir yaklaşım sunmaktadır. İlgilenilen nesnenin kavranabildiği senaryolarda, insanların hedefe (nesne ya da varış yeri) kabaca ve olabildiğince doğrudan uzandıktan sonra, görevin başarıyla tamamlanabilmesini garantilemek için, hedefin yakınında hedefe özgü ufak bir grup hassas hareketi kullanma eğiliminde olduklarını gözlemlemekteyiz. Bu nesneye özgü göreli hareketlerin kritik olmakla birlikte tekrar eden mahiyetlerinden esinlenerek, robotun bu durumların ufak bir kümesini ezberleyip durum tabanında saklamasını ve manipülasyon planlama ve icra etmede kılavuz olmaları için mümkün olduğunca yeniden kullanmasını sağlamaktayız. Örnekleme tabanlı üretici planlama algoritmalarıyla birleştirildiğinde, bu kılavuzluk, kabaca ve doğrudan uzanma etkisini oluşturmak üzere planlama sürecini kasıtlı olarak uygulanabilir durumlara doğru yönlendirerek planlama zamanını azaltmaya yardımcı olmaktadır. Buna ek olarak, erişilen durumları tekrar ederken icrayı gözlemleyip denetlemek görevin başarılma oranını arttırmaktadır. Deney sonuçlarımız, elde bulunan kısmi plan ve icralarla yoktan üretilenlerin birbirini tamamlayan kombinasyonunun hızlı, güvenilir, ve tekrarlanabilir çözümler sağladığını göstermektedir. İlgilenilen nesneler çok ağır ya da irilerse, ya da robot bir kavrama mekanizmasından yoksunsa, manipülasyon itme aracılığıyla hala mümkün olabilir. Bununla birlikte, gerçekçi iterek-manipülasyon senaryolarında robot, nesne, ve ortam arasındaki potansiyel fiziksel etkileşimlerin karmaşıklığı çok fazladır. Bu da genellenebilir analitik hareket ve etkileşim modelleri kurmayı ya da her robot, nesne, ve ortam kombinasyonu için fizik motorlarının parametrelerinin ayarlanmasını zorlaştırmaktadır. Bu problemi esnek bir şekilde çözebilmek amacıyla, robotun etkileşim ve gözlem aracılığıyla itilebilir gerçek dünya nesneleri için ayrık, deneysel, olasılıksal hareket modelleri (yani olasılıksal durumlar) edinmesini sağlayan bir durum tabanlı iterek-manipülasyon sistemi sunmaktayız. Daha sonra bu olasılıksal durumlar, ilgilenilen nesneyi istenen hedef konuma taşıyabilmek ve sıkışık görev ortamlarında potansiyel olarak karşılaşılabilecek engelleri yoldan çekebilmek için gereken güvenli ve başarılabilir itme planlarını oluşturmak için yapıtaşları olarak kullanılmaktadırlar. Buna ek olarak, olasılıksal durumların artımsal olarak edinilip iyileştiriliyor olmaları, robotun ilgilenilen nesnelerin nakliye amacıyla yüklenmeleri ya da boşaltılmaları sonucu kütlelerinin değişmesi gibi durumlara uyum sağlayabilmesine imkan tanımaktadır. Çok geniş kapsamlı deneylerle gösterdiğimiz üzere, tamamen etkileşim ve gözleme dayalı doğası, sunduğumuz yöntemi robottan, nesneden, ve ortamdan (gerçek ya da benzetim) bağımsız hale getirmektedir. Ayrıca geliştirdiğimiz iterek-manipülasyon yönteminin geçerliliğini bir takım öncü gerçek dünya deneyleriyle de doğrulamaktayız.","The ability to manipulate the environment is one of the primary skills that autonomous mobile service robots are expected to have, considering that the daily lives of humans heavily rely on this skill. There are various ways for a mobile robot to perform manipulation, the exact form of which is determined by the requirements of the task and the constraints imposed by the physical properties of the environment, the object, and the robot itself. Anecdotal evidence suggests that humans mostly reuse their manipulation experiences, acquired through interaction and observation, especially in recurring everyday manipulation tasks, both in prehensile and non-prehensile manipulation contexts. With this motivation, this thesis contributes a case-based approach to achieving practical and efficient mobile manipulation through the utilization of past experience, stored as object-specific, distinct, and potentially probabilistic cases. In scenarios where the objects of interest can be grasped, we observe that humans tend to reach for the targets (i.e. the object of interest or the destination) roughly and as directly as possible while exploiting a small set of target-specific critical moves within their close proximity to guarantee successful completion of the task. Inspired by the critical yet recurring nature of these target-specific relative moves, we let the robot memorize and store a small number of them as cases in its case base, and reuse them whenever possible to guide manipulation planning and execution. When combined with sampling-based generative planners, this guidance helps reduce planning time by deliberately biasing the planning process towards the feasible cases to achieve the rough and direct approach effect. Additionally, monitoring the execution while reiterating the reached cases improves task success rate. Our experiments show that this complementary combination of the already available partial plans and executions with the ones generated from scratch yields to fast, reliable, and repeatable solutions. When the objects of interest are too heavy or bulky, or a grasping mechanism is not available, it may still be possible to perform manipulation through pushing. However, in realistic mobile push-manipulation scenarios, the complexity of the potential physical interactions between the robot, the objects, and the environment is vast. This makes it non-trivial to write generic analytical motion and interaction models or tune the parameters of physics engines for every robot, object, and environment combination. In order to handle this problem flexibly, we introduce a case-based push-manipulation framework that enables the robot to acquire, through interaction and observation, a set of discrete, experimental, probabilistic motion models (i.e. probabilistic cases) for pushable passively-mobile real world objects. These probabilistic cases are then used as building blocks for constructing safe and achievable push plans to navigate the object of interest to the desired goal pose as well as to potentially push the movable obstacles out of the way in cluttered task environments. Additionally, incremental acquisition and tuning of the probabilistic cases allows the robot to adapt to the changes in the environment, such as increased mass due to loading of the object of interest for transportation purposes. The purely interaction and observation driven nature of our method makes it robot, object, and environment (real or simulated) independent, as we demonstrate through extensive testing and experimentation. We also verify the validity of our push-manipulation method in preliminary real world tests."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sistem seviyesindeki denektaşları çok çekirdekli mimarilerde tasarım sürecinin erken safhalarında verimlilik değerlendirmesine olanak sağlamaktadır. Fakat denektaşlarının geliştirilmesinin maliyeti yüksektir. Bireşimsel denektaşları elde edildikleri asıllarıyla benzer verimlilik davranışlarına sahiptir. Buna ek olarak, daha hızlı çalışırlar ve kaynak formu mevcut olmayan tescilli müşteri kodlarının vekili olarak gorev yapabilirler. Biz bu tezde SystemC/TLM ya da Pthreads uygulamalarından sistem seviyesindeki bireşimsel denektaşları elde eden bir çatı sistemi geliştirdik. Bu denektaşları farklı kullanım senaryoları için düşünülmüş olup ilki eşbenzetim ortamlarındaki sanal platformları ve ikincisi de kütüphane desteği veya gerekli hesaplama yeteneği bulunmayan simulasyon platformlarını hedeflemektedir. Bizim çatı sistemimiz Etem ve ark. tarafından geliştirilen bireşimsel denektaşı elde etme çatı sisteminin SystemC ön ve arka uçlarıyla genişletilmesiyle uygulanmıştır. Deneylerde bizim sistem seviyesindeki denektaşlarımızın elde edildikleri asıl denektaşlarına kıyasla daha küçük olmalarıyla beraber daha hızlı olduklarını gözlemledik. Mesela iyi bilinen çok çekirdekli bir denektaşı takımı olan PARSEC ile bireşimsel denektaşları elde ettiğimizde denektaşlarımız PARSEC denektaşlarına kıyasla ortalama 141 kat hızlanmaya sahip oldu. SystemC/TLM uygulamalarından elde edilen denektaşlarıyla yapılan deneyler aynı şekilde kısa çalışma süresine sahip tasarımlara rağmen ortalama 4 kat hız artışına sahip oldu. Biz bireşimsel denektaşlarımızın elde edildikleri asıllarıyla benzer verimlilik davranışları gösterdiğini ve üç farklı çok çekirdekli mimaride taşınabilir olduğunu gözlemledik. Özel olarak, üç mimaride de PARSEC ile elde edilen denektaşları %81'den fazla benzerliğe ve SystemC ile elde edilen denektaşları %88'den fazla benzerliğe sahiptir.","System-level benchmarks enable performance evaluation early in the design cycle of multi-core architectures. However, benchmark development is costly. Synthetic benchmarks have similar performance behavior as the originals that they are generated from. Additionally, they can run faster, and they can act as proxies for proprietary customer codes that are not available in source form. In this thesis we develop a framework to generate system-level synthetic benchmarks from SystemC/TLM or Pthreads applications. These benchmarks are intended for different use cases, the former targeting virtual platforms in co-simulation environments and the latter targeting simulation platforms lacking either library support or necessary computing capabilities. Our framework was implemented by extending the synthetic benchmark generation framework developed by Deniz et al. with a SystemC front-end and back-end. In experiments we observe that not only are our system-level benchmarks much smaller than the real benchmarks that they are generated from but they are much faster also. For example, when we generate synthetic benchmarks from the well-known multi-core benchmark suite, PARSEC, our benchmarks have an average speedup of 141x over PARSEC benchmarks. Experiments with benchmarks generated from SystemC/TLM applications also have an average speedup of 4x even for designs with the shortest execution times. We observe that our synthetics maintain similar performance characteristics as the original benchmarks and they are portable across three different multi-core architectures. Specifically, benchmarks generated from PARSEC have more than 81% similarity and benchmarks generated from SystemC have more than 88% similarly on all three architectures."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada lise öğrencilerinin eğitimlerine yardımcı olması için geliştirilen kapalı-alan Türkçe tek cevaplı Soru Cevaplama (SC) sisteminin inşasında tasarlanan soru analizi ve bilgi çıkarımı (BÇ) modülleri için geliştirilmiş teknikler anlatılmakta ve değerlendirilmektedir. Verilen bir soruda tam olarak neyin sorulduğu ve cevaplamanın ne şekilde yapılması gerektiğini belirlemek için sorudan gerekli bilgileri çıkartan soru analizi, bir soru cevaplama sisteminin en önemli parçalarından biridir. Bu nedenle bu çalışmada soru analizindeki en önemli iki problem olan odak çıkarımı ve soru sınıflandırılması problemlerine, kural tabanlı ve Saklı Markov Modeli (SMM) tabanlı modellerin sentezinden oluşan ve sorudaki kelimeler arasındaki bağlılık ilişkilerini kullanan çözümler sunulmuştur. Ek olarak bir SC sisteminin bir başka önemli modülü olak BÇ modülü de incelenmiş, ve içerisinde verilen sorunun cevabının aranacağı ilgili bilgileri kümesinin verimli bir şekilde çıkartılması için de teknikler önerilmiştir. BÇ modülü, soru ile ilgili döküman ve pasajları Indri ve Apache Lucene arama motorlarını kullanarak bulmaya çalışmaktadır. Sunulan çözümler, üzerine sadece cevap modülünün eklenmesiyle tam bir SC sisteminin oluşturulabileceği bir altyapı oluşturmaktadır. Önerilen tüm çözümlerin karşılaştırmalı deneyleri, baz modelleri ile birlikte sunulmuştur. Bu çalışmada aynı zamanda, elle toplanıp işaretlenmiş Türkçe standard veri kümesi, bu alanda daha sonraki araştırmalarda kullanılmak üzere genel kullanıma açılmıştır.","This study describes and evaluates the techniques we developed for the question analysis and information retrieval (IR) module of a closed-domain Turkish factoid Question Answering (QA) system that is intended for high-school students to support their education. Question analysis, which involves analyzing the questions to extract the necessary information for determining what is being asked and how to approach answering it, is one of the most crucial components of a QA system. Therefore, we propose novel methods for two major problems in question analysis, namely focus extraction and question classification, based on integrating a rule-based and a Hidden Markov Model (HMM) based sequence classification approach, both of which make use of the dependency relations among the words in the question. We also investigate the IR module, which is another critical aspect of a QA system, and introduce the IR module to efficiently gather the relevant information to a given question, with which the answer will be determined. IR module searches for the relevant documents and passages through the combined use of search engines Indri and Apache Lucene. Solution to these problems constitute the framework, on top of which a whole QA system can easily be built with only an addition of an answering module. Comparisons of all solutions with baseline models are provided. This study also offers a manually collected and annotated gold standard data set for further research in this area."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal medya metinlerinde kullanılan dilin bozukluğu bu metinleri doğal dil işleme araçları ile otomatik olarak işlemeyi çok zorlaştırmakta. Bu bozuk metinleri düzeltip kitap biçimlerine dönüştürme bir diğer deyişle metin normalizasyonu, bu soruna bir çözüm ortaya koymaktadır. Bu çalışmada, sosyal metinlerin sözcüksel ve içeriksel özelliklerinin yanısıra dibilgisi özelliklerinden de faydalanılan gözetimsiz bir metin normalizasyonu yaklaşımı sunuyoruz. İçeriksel ve dilbilgisel özellikler, büyük ve etiketlenmemiş bir sosyal medya derlemi kullanarak oluşturduğumuz kelime ilişkilendirme çizgesi yardımı ile hesaplanıyor. Bu çizge, kelimelerin metin içerisinde birbirleriyle olan konum ilişkilerini ve cümle öğe bilgilerini (part-of-speech) içermektedir. Sözcüksel özellikleri bulmada kelimelerin en uzun ortak altdizileri ve birbirine dönüşme uzaklıkları gibi yazım benzerlikleri yanısıra çift metafon~(double metaphone) gibi ses bilimsel benzerlikleri göz önünde bulunduran yöntemlerden faydalanıldı. Yakın zamanda sıkça kullanılan sözlük bazlı çalışmaların aksine, önerdiğimiz yaklaşım metin normalizasyonunu düzeltilecek metnin içeriğini göz önünde bulundurarak uygulamaktadır. Standart veri kümesi üzerinde literatürdeki sonuçlardan daha yüksek sonuçlara ulaşan sistemimiz farklı parametreler kullanılarak kapsama~(recall) degerinden ödün vermeden çok daha yüksek kesinlik~(precision) değerlerine ulaşabilmektedir.","The informal nature of social media text, renders it very difficult to be automatically processed by natural language processing tools. Text normalization, which corresponds to restoring the noisy words to their canonical forms, provides a solution to this challenge. We introduce an unsupervised text normalization approach that utilizes not only lexical, but also contextual and grammatical features of social text. The contextual and grammatical features are extracted from a word association graph built by using a large unlabeled social media text corpus. The graph encodes the relative positions of the words with respect to each other, as well as their part-of-speech tags. The lexical features are obtained by using the longest common subsequence ratio and edit distance measures to encode the surface similarity among words, and the double metaphone algorithm to represent the phonetic similarity. Unlike most of the recent approaches that are based on generating normalization dictionaries, the proposed approach performs normalization by considering the context of the noisy words in the input text. Our results show that it achieves state-of-the-art F-score performance on a standard data set. In addition, the system can be tuned to achieve very high precision without sacrificing much from recall."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yakın zamanda donanım alanında yaşanan gelişmeler, yazılımı her zamankinden daha koşutzamanlı olmaya yöneltti. Yazılımda koşutzamanlılığa çoklu iş parçacığı ile erişilir, bu doğrulamada zorluklar yaratır. Bu zorluklar koşutzamanlılığın gerekirci olmayan doğası nedeniyle saptanması zor problemler olan kaynak bekleme, veri yarışları ve bölünmezlik ihlallerini içerir. Veri yarışları paylaşılmış verilerin çoklu iş parçacıkları tarafından koşutzamanlı erişilmesi sonucuda ortaya çıkar ve beklenmedik program davranışlarına neden olabilir. Bu tezde çoklu iş parçacıklı uygulamalarda veri yarışlarını saptama tekniklerini tanımlayacağız. Önce-gerçekleşen ve kilit kümesi algoritmalarının kombinasyonu olan melez veri yarışı algoritmasını geliştirdik. Kilit kümesi algoritmasından yaralanarak yanlış eksileri ve önce-gerçekleşen algoritmasindan yararlanarak ise yanlış artıları attık. Algoritmamız uygulamanın ikili kodu üzerinde çalışır (kaynak koda ihtiyaç duymadan), bundan dolayı endüstride konuşlanmış yazılımlara uygulanabir. Dinamik veri yarışı saptama teknikleri uzun yürütüm süresi ve yüksek hafıza gereksiniminden muzdariptir. Bahsi geçen ek yükleri azaltmak için kesit konseptinden yararlandık, bir kesit bir iş parçacığı tarafından arka arkaya yapılan hafıza erişimlerinden oluşur. Melez veri yarışı detektörümüzün etkinliğinin geçerliliğini denetlemek için bir önce-gerçekleşen ve bir kilit kümesi detektörü ile karşılaştırarak deneyler yaptık. Çeşitli sabit noktalarla gerçeklestirdiğimiz deneyler gösterdi ki melez detektörümüz önce-gerçekleşen detektöre kıyasla \%20 daha hızlıdır ve kilit kümesi detektöre kıyasla \%50 daha az veri yarışı üretir. Kullanılırlığı ve performansı artıracak 4 farklı optimizasyon uyguladık.","Recent advances in hardware drive software to be more concurrent than ever. Concurrency in software is achieved by multithreading, which creates verification challenges. These challenges include problems such as deadlocks, race conditions and atomicity violations, all of which are notoriously difficult to detect due to the non-deterministic nature of concurrent software. Data races result from the concurrent access of shared data by multiple threads and can result in unexpected program behaviors. In this thesis, we describe techniques to detect data races in multithreaded applications. We developed a hybrid algorithm that is a combination of the state-of-the-art happens-before and lockset data race detection algorithms. We take advantage of lockset algorithm and happens-before algorithm for discarding false negatives and false positives, respectively. Our algorithm works on the binary of the program (without the need for the source code), hence makes it applicable to industrially-deployed software. Since it is a dynamic technique, it has execution time and memory overhead. We utilized the concept of segments to decrease these overheads, where a segment is formed by consecutive memory accesses of a single thread. We performed experiments to validate the effectiveness of our hybrid race detector by comparing it with a happens-before and lockset-based race detector. Our experiments on several benchmarks showed that our hybrid detector is 20\% faster than happens-before detector and produces 50\% less potential data races than the lockset detector. We proposed four different optimizations to further decrease the execution time and enhance the usability."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tezin konusu yazılım kalitesi üzerinedir. Araştırma kapsamında, yeni gelen hata raporlarını kişilere atayan ve hataları düzeltecek yazılım geliştiriciler için hataya yatkın yazılım kodu modüllerini tahmin eden bir öneri modeli geliştirilmiştir. Bu modelde, yazılım modülleri üzerindeki çalışma ağı verisi ve hata raporu verisi kullanılmaktadır. Her hata raporu kategorisinde, yazılım geliştirici merkeziliği üzerinden hata raporları, yazılım geliştiricilere önerilmektedir. Tezde önerilen modelin performansı küresel olarak geliştirilen büyük ölçekli bir kurumsal yazılım üzerinde tahmin doğruluğu ve iş yükü dağılımı dengesizliği başarım kriterlerine göre sınanmıştır. Model, (i) Yazılım geliştirici iş yükü dengesizliği, (ii) Yazılım ekiplerine yeni katılan geliştirici gruplarına hata raporu atanması sorunlarına çözüm üretmesi için genişletilmiştir. Öğrenme tabanlı bir hata tahmin modelinin tahminleri yakın geçmişi göz önüne alarak gerçek zamanlı olarak güncellenmiştir. Yapılan deneysel analize göre, (i) Önerilen modelin başarımı hata raporu atamalarının tarihsel dağılımına yakınsamaktadır, (ii) Modele eklenen buluşsal yöntemler ile geliştirici iş yükü dağılımı daha dengeli hale getirilebilmektedir, (iii) Kronecker ağları yardımıyla ortak ̧calışmanın ileride nasıl bir yapıda olacağı tahmin edilerek yazılım ekiplerine yeni katılan geliştirici gruplarına hata raporu atanabilmektedir, (iv) Gerçek zamanlı hata tahmin modeliyle zaman içerisinde yanlış alarm oranları arttırılmadan hata yakalama performansı kayda değer miktarda artmaktadır.","Assignment of new issues to developers is an important part of software maintenance activities. In this research, we build an issue recommendation model that recommends new issues to developers and highlights the defect prone software modules to the developer who owns an issue. Existing solutions address the automated issue assignment problem through text mining. We propose a recommender model that uses the collaboration network of developers on software modules and the structured issue data as its input. We perform an exploratory analysis using the issue data of two large software systems and observe the trends in the issue ownership, issue defect relations and issue timelines. Our base model estimates the developer centrality for each issue category and recommends issues to developers based on their centrality ranking. We test the performance of our recommender using the maintenance data of a globally developed large enterprise software using recommendation accuracy and workload imbalance as the performance metrics. We extend the recommender to address, (i) The problem of developer workload imbalances, (ii) The problem of assigning issues to a new group of developers by using stochastic Kronecker networks to model the future structure of the collaboration network. We change a learning based defect predictor's output based on recent history to update the predicted defect-prone software modules on a real-time basis. Our empirical analysis shows that: (i) The performance of our recommender model approximates historical trends of issue allocation, (ii) Heuristics applied to the model output reduces the issue ownership inequalities and model approximation performance, (iii) Kronecker networks can be used to estimate the future collaboration on the issues and the model can be extended by them to propose issues to new developer groups, (iv) Real time defect prediction model can significantly improve probability of detection over time while not changing false alarm rates."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde cep telefonları gelişmiş ve gelişmekte olan ülkelerde yaygın olarak kullanılmaktadır. Gelir seviyesi yüksek olan ülkelerde telefon; bilgisayar işlevselliği, gelişmekte olan ülkelerde ise, daha çok alt yapıdan eksikleri yada daha hayati ihtiyaçları karşılamak amacıyla kullanılmaktadır. Bu çalışmada Fildişi Sahilleri'nin ülke genelinde toplanmış olan, cep telefonu konuşma kayıtları analiz edilip kullanılmıştır. Olağan dışı önemli olayların ülke boyutunda tespit edilebilmesi ve olay gerçekleşmeden tespit edilebilirliği nin, cep telefonu verisi kullanılarak mümkün olup olmadığı hedeflenmiştir. Bunun yanı sıra, bu çalışmanın cep telefonu verisi kullanarak analiz yapacak diğer çalışmalara, veri seti temininden görselleştirmeye kadar, bir yol haritası olması hedeflenmiştir. Bu çalışmada kullanılan veri seti, Orange Telekomunikasyon tarafından, Fildişi Sahillerinde, Aralık 2011-Nisan 2012 tarihleri arasında toplanılmış ve anonimize edilmiştir, aynı zamanda bu veri Data for Development (D4D) akademik yarışmasının bir parçası olarak paylaşıldı. Çalışmamızda Markov tabanlı Poisson süreci (MMPP) methodu kullanıldı. Verinin toplanıldığı sırada ülke, yüzlerce ölü ve yaralı ile sonuçlanan bir iç savaş içerisindeydi. Bu kargaşadan kaynaklanan olayları Birleşmiş Milletlerin Güvenlik Konseyi raporlarından elde ederek, çalışmamızda tespit edilen olayların başarısı değerlendirildi.","Mobile phones are extensively used both in developed and developing countries. Richer countries tend to use it as a computer, whereas in developing countries it is a kind of replacement of inadequacy of infrastructure, or it is used to cover more crucial needs. This work is an explorative analysis of the nationwide Call Detail Record (CDR) in Cote d'Ivoire. Our aim is to detect anomalous incidents and to explore the possibility of early detection of severe incidents from mobile phone data. Beside this, this work is a kind of roadmap who would like to work on CDR data, from obtaining open data set to visualization tool selection. Data is collected and anonimized in Cote d'Ivoire by Orange Telecom, from real call data. It has been published as a part of a scientific challenge, Data for Development (D4D). We explored irregularity of phone usage by probabilistic Markov modulated Poisson process (MMPP) method. During the data collection period (from December 2011 to April 2012) Cote d'Ivoire was suffering from civil war, which caused hundreds of deaths and many injuries. Validation of the experiments has been done through United Nations Security Council's report covering these dates."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dağıtık ve çok etmenli sistemler alanında, hatalı düğümler içeren bir ağın onaylaşımı saglaması önemli bir problemdir. Belirli bir görevi yerine getirmesi istenen dağıtık bir sistem, bazı hatalı düğümlerinin olumsuz davranışlaırna karşı gürbüzlük göstermelidir. Bu hatalı düğümler aynı zamanda Bizans düğümleri olarak da bilinmektedir. Bu tezde, Yaklaşık Bizans onaylaşımını sağlamak için Ortalama-Seçimli-İndirgenmiş (OSI) hata toleranslı özgun bir algoritma önerilmistir. Algoritmanın başarımı için gerekli olan ilinge koşulunun, önceki sonuclarla kıyaslandığında, gevşetildiği gosterilmiştir. Literatürde yer alan sonuçların aksine, ağların senkronizasyonunun ve iletişim kanallarındaki gecikmenin varlığının bu koşulu değiştirmediği ispatlanmıştır. Daha sonra, önerilen hata toleranslı algoritma icin yakınsama hızı ve zamanı analizi gerceklestirilmiş ve sonuclar zamanla değişen ağlara genişletilmiştir. Bizans ağları için sunulan hata toleranslı algoritmaların birçogunda, ağdaki her bir düğümün, hatalı düğümlerin maksimum sayı, ft, bilgisine sahip olduğu kabulü yapılmaktadr. Ayrıca bu tezde, bu ön bilgiyi gerektirmeyen yeni bir algoritma ailesi önerilmis ve Bizans hatalarının varlığında performansları değerlendirilmiştir.","Reaching consensus in a network which contains faulty nodes is a critical problem in the eld of distributed and multi-agent systems. A distributed system which intends to do a certain task needs to display robustness against adverse behavior of some of its faulty nodes, known also as Byzantine nodes. In this thesis, a novel Mean- Select-Reduced (MSR) fault tolerant algorithm is proposed for achieving Approximate Byzantine Consensus. It is shown that the topological condition required for the success of the algorithm is more relaxed compared to the previous results. In contrary to results that appeared in the literature, it is proved that synchronicity of networks and presence of delay on communication paths do not change this condition. Subsequently, the convergence rate and time analysis for the proposed fault-tolerant algorithm is carried out and the results are extended to time-varying networks. In most of the fault-tolerant algorithms that have been introduced for Byzantine networks, it is assumed that each node has knowledge of the maximum number of faulty nodes, ft, in the network. In this thesis, we also propose a new family of algorithms which do not require this a priori information and evaluate their performance facing Byzantine failures."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz duygaç ağları (KDA) tasarımı en iyi duygaç yerleştirme ve duygaç etkinlik çizelgelemesinin yanısıra en iyi ana alıcı yerleştirme ya da rotalama ve en iyi veri rotalama problemlerini de içerir. Bu tezde ilk olarak hareketli ana alıcının sınırlı yapısını yansıtmak için ana alıcının yolculuk süresini ve bu sürede biriken bilgiyi göze almaya çalışıyoruz. Toplam ana alıcı yolculuk süresini ağ ömrünün bir parçası olarak ele alıyoruz. Bu amaçla çoklu sayıda ana alıcı devrini ve bilginin duygaçlardan ana alıcıya sınırlı sekme sayısıyla en kısa yol üzerinden aktarıldığı veri rotalama iletişim protokolü uygulamasını olanaklı kılacak esneklikte iki karma tamsayılı doğrusal programlama (KTDP) gösterimi sunuyoruz. KTDP gösterimlerinin çözümü için sezgisel yöntemler öneriyor ve sıfırdan farklı ana alıcı yolculuk süresinin önemini bilgisayısal deneylerle gösteriyoruz. Ayrıca KTDP gösterimlerini çoklu sayıda hareketli ana alıcılı yeni bir KTDP gösterimi ile genişletiyor ve çoklu ana alıcı varlığında ana alıcı yolculuk sürelerinin gözardı edilebilir olduğunu gösteriyoruz. Daha sonra, duygaç yerleştirme, etkinlik çizelgeleme ve bilgi rotalamayı ana alıcı yerleştirme ya da rotalama problemleriyle derin bir biçimde bütünleyen KTDP gösterimleri geliştiriyoruz. Bütünlemenin kapsamı ana alıcı rotalama ve veri rotalama problemlerinin bütünlenmesinden başlamak- ta, duygaç yerleştirme, etkinlik çizelgeleme, ana alıcı ve veri rotalama problemlerinin bütünlenmesine uzanmaktadır. Bütünlemenin olumlu etkisini gösterimlerin en iyi amaç işlev değerlerini çok sayıda rassal problem örnekleri üzerinden kıyaslayarak gösteriyoruz. Aynı zamanda KTDP gösterimlerinin çözümü için sezgiseller ve bir dal-eder yöntemi geliştiriyor, bunların doğruluk ve etkinliklerini geniş bir deney problemi kümesini kullanarak sınıyoruz.","The design of a Wireless sensor network (WSN) involves the optimal deployment and activity scheduling of the sensors as well as optimal deployment or routing of sinks and optimal routing of data flows. In this thesis, we first attempt to reflect the limited nature of the mobile sink by considering nonzero sink travel times and taking the data accumulated during the sink travel time into account. The total sink travel time is considered as a part of the network lifetime. We provide two mixed integer linear programming (MILP) models that are flexible enough to handle multiple sink tours as well as a hop limited data routing protocol in which data is routed from sensors towards the sink through the shortest paths including at most a predefined number of hops. We propose heuristic procedures for the solution of the MILP models and show the importance of considering nonzero sink travel times by numerical experiments. An extension to these MILP models that possess a framework with multiple mobile sinks is also developed and it is demonstrated that sink travel times can be neglected for multiple sinks. Later on, we develop several MILP models which integrate sensor placement, activity scheduling and data routing issues with the static sink placement or mobile sink routing design issues. The breadth of the integration changes from the integration of the sink routing problem with the data routing problem to the integration of the sensor placement, activity scheduling, sink routing problems with data routing problems. We study the effect of the integration of WSN design issues by comparing the objective value of the models on a large set of randomly generated problem instances. We also devise heuristics and a branch-and-price algorithm for the solution of the proposed MILP models and empirically test their accuracy and efficiency on a large set of test instances."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan hafızası yanılabilir. Bu probleme bir çözüm olarak, yakın gelecekte giyilebilir cihazlar bir kişi ve kişinin çevresi ile ilgili her türlü bilgiyi otomatik ve aralıksız bir şekilde kaydetme potansiyeline sahip olacaklar. Bu sayede bir kişinin hayatı kayıt altına alınabilir. Bu tezde, bir akıllı telefon kullanıcısının günlük deneyimlerini kaydeden ve daha sonra elde edilmesini sağlayan bir mobil hayat-kayıt uygulaması sunulmaktadır. Bu bağlamda ilk olarak Smartphone Tracker adında, akıllı telefonlar kullanarak geniş çaplı veri toplama çalışmaları yürütmemizi sağlayan bir sistem sunuyoruz. Bu sistemi kullanarak, 22 katılımcılı bir veri toplama çalışması üzerinden akıllı telefonların çevresini algılama yeteneklerini inceliyoruz. İkinci olarak, mobil cihazlara anlamsal mekan farkındalığı sağlayan yeni bir algoritma sunuyoruz. Bu algoritmayı kullanarak, bir kullanıcının ziyaret ettiği ev, iş yeri ve ebeveynlerin evi gibi anlamsal olarak değerli mekanlara giriş ve çıkış zamanlarını belirleyebiliyoruz. Son olarak, telefon görüşmelerini, kısa mesajları, hava koşullarını, ortamın sesini ve ziyaret edilen mekanları otomatik olarak kayıt altına alan Auto Diary adında bir mobil hayat-kayıt uygulaması sunuyoruz. Ek olarak uygulama içerisinde, geçmiş deneyimlerin ilişkisel işaretler ile elde edilmesini sağlayan bir özellik de sunulmaktadır. Örneğin, ``Yağmurlu bir pazartesi sabahıydı. Ofisimdeydim ve kardeşimden saat 10 ile 12 arası bir telefon aldım."" cümlelerindeki işaretler, tanımlanan gün içerisinde kaydedilen ses ve benzeri deneyimlerin elde edilmesi amacı ile uygulama içerisinde sorgu terimleri olarak kullanılabilir. Auto Diary'nin epizodik bellek bozukluğu yaşayan insanlar için faydalı olabiliceğini öngörüyoruz. Uygulama, geçmiş deneyimlerini çok daha detaylı şekilde hatırlamak isteyen insanlar için de faydalı olabilir.","Human memory is fallible. As a remedy to this problem, in the near future wearable devices will have the potential to automatically record every bit of information concerning a person and his/her environment continuously. This way, lifelog of a person can be generated. In this thesis, we present a mobile lifelogging application that captures daily experiences of a smartphone user and allows to retrieve them later. In this direction, we first introduce a system named Smartphone Tracker which allows us to conduct large-scale data collection studies using smartphones. Using this system, we investigate the sensing capabilities of smartphones through a real life data collection study with 22 participants. Second, we present a novel algorithm which provides semantic location awareness to mobile devices. Using this algorithm, we are able to detect the entry/departure times to/from semantically meaningful places a user visits, such as home, office, parents' home, etc. Finally, we present a mobile lifelogging application named Auto Diary which automatically records SMS messages, phone calls, weather conditions, ambient audio and visited locations. In addition, a retrieval functionality is offered which allows to retrieve past experiences via associative cues. For example, the cues from the statements ``It was a rainy Monday morning. I was in my office and received a phone call from my brother between 10 am and 12 am."" can be used as query terms in the application to retrieve the experiences (e.g., audio recordings) captured in the described day. We envision that Auto Diary can be useful for people experiencing episodic memory impairment. It can also be useful for people who want to remember their past experiences with greater precision."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kanonik Korelasyon Analizi (KKA) iki değişken kümesi arasındaki doğrusal bağıntıları belirlemeyi amaçlayan bir yöntemdir. KKA son zamanlarda makine öğrenme alanında aynı verinin farklı temsillerinden olusan çok-bakşlı veri kümelerinin artmasıyla birlikte çokça kullanılmaya başlamıştır. Bu tez, KKA yönteminin gürbüzlüğü ve sınıflandırma başarısının arttırılmasına yönelik çalsmaları içermektedir. KKA, maksimum korelasyona sahip izdüşüm vektörlerinin (eşdegişkenler) bulunması için bakışları karmaşık sınıf etiketleri gibi kullanmaktadır. Bu nedenle, KKA eğitim kümesi üzerinde aşırı ögrenmeye sebep olabilir. Topluluk öğrenme yöntemleri sınıflandırma ve kümeleme yöntemlerinin bu tür aşırı ögrenme sorunlarını engellemek için kullanılmış, ancak KKA icin bir topluluk yaklaşımı henüz önerilmemiştir. Bu tezde, birden fazla alt-örneklemden elde edilen eşdegişken kümelerinin birleştirilmesiyle nihai bir eşdegişken kümesinin elde edilmesi için bir topluluk yöntemi önerdik. Çeşitli veri kümeleri üzerinde elde edilen deneysel sonuçlar topluluk KKA yönteminin başarısını göstermektedir. KKA yönteminin gerçeklemesinde sınıf etiketlerinden yararlanılmadığı için, bu yöntemle elde edilen öznitelikler sınıf-ayırıcı özelliğe sahip olamayabilmektedir. Bu tez iki bakış arasındaki ortak bilgiyi iceren ve aynı zamanda farklı sınıflara ait örnekleri ayırt edebilen öznitelikler arayan bir yöntem önermektedir. Önerdiğimiz yöntem her biri doğrusal gizli katmanlı ve hem sınıf örneklerini hem de birbirlerinin çıktılarını tahmin etmeyi amaçlayan iki çok katmanlı algılayıcıdan oluşmaktadır. Deneysel sonuçlar, önerilen yöntemle çıkartılan özniteliklerin daha yüksek sınıflandırma başarısı verdiğini göstermiştir. Bu tez çalışmasının diğer bir katkısı, KKA yönteminin bir öznitelik seçme yönteminin geliştirilmesinde kullanılmasıdır. Bunun yanında çok-bakışlı veri kümeleri için topluluk sınıflandırma ve kümeleme üzerine çalışmalarımızı da içermektedir.","Canonical Correlation Analysis (CCA) aims at identifying linear dependencies between two sets of variables. CCA has recently become popular in the field of machine learning with the increase in the number of multi-view datasets, which consist of di fferent representations coming from diff erent sources or modalities. This thesis presents our e fforts to improve the robustness and discriminative ability of CCA. CCA uses the views as complex labels to guide the search of maximally correlated projection vectors (covariates). Therefore, CCA can over fit the training data. Although, ensemble approaches have been e ffectively used to avoid such overfi ttings of classifi cation and clustering techniques, an ensemble approach has not yet been formulated for CCA. In this thesis, we propose an ensemble method for obtaining a fi nal set of covariates by combining multiple sets of covariates extracted from subsamples. Experimental results on various datasets demonstrate the usefulness of ensemble CCA approach. The correlated features extracted by CCA may not be class-discriminative since it does not utilize the class labels in its implementation. This thesis introduces a method to explore correlated and also discriminative features. Our proposed method utilizes two (alternating) multi-layer perceptrons, each with a linear hidden layer, learning to predict both the class-labels and the outputs of each other. The experimental results show that the features found by the proposed method accomplish signi cantly higher classifi cation accuracies. Another contribution of this thesis is the use of CCA to improve a filter feature selection algorithm. We also present our works on ensemble classifi cation and clustering for multi-view datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sağlık sektörü, kağıt belgelerden elektronik kayıtlara geçişle birlikte, bilgi teknolojileri ve internete oldukça bağımlı hale gelmiştir. Elektronik kayıtların maruz kalabileceği güvenlik risklerine karşı tedbirler alınmadığı sürece kaliteli bir sistem elde etmek mümkün olmayacaktır. Bu çalışmada, Türkiye'de özel bir hastane ile ortak çalışılmış ve hastane bilgi sistemlerindeki güvenlik zaafiyetleri ortaya koyularak hastane sistemleri için güvenli bir ağ altyapısının önerilmesi hedeflenmiştir. Türkiye'deki düzenlemelere ait kriterler ABD ve AB'deki kriterler ile karşılaştırılmış; farklı sektörlerin uyguladığı ve sağlık sektöründe de uygulanabilecek iyi uygulamaları içeren güvenlik kontrolleri sunulmuştur. Çalışma, hastanenin HIPAA ve ISO 80001 gibi bilinen sağlık standartlarına uyumlu olmadığını göstermektedir. Hastane yönetiminin kişisel mahremiyet ve güvenlik konularına yaklaşımının destekleyici olmadığı ve sorumluluğun IT ve Biyomedikal Mühendisliği Departmanları'na bırakıldığı görülmektedir. Tehditler ve mevcut sistemdeki zaafiyetler sıralanırken hastanenin ileride siber tehditlere karşı mağdur olmaması açısından, hastanenin adı açıklanmamıştır. Hastanelerin elektronik ortama geçişiyle birlikte, vatandaşların elektronik sağlık kayıtlarının korunması, kişisel mahremiyeti sağlamak açısından zorunlu hale getirilmelidir. Bu çalışma sağlık sektöründe politikaları belirleyenlere ve düzenleyici otoritelere vatandaşlar için güvenli bir ortam oluşturma konusunda yol gösterici olabilir.","Healthcare industry has become widely dependent on information technology and internet; as it moves from paper to electronic records. Despite the benefits of electronic system, good quality may not be totally achieved unless its risks to security are mitigated. Working in collaboration with a 150 bed private hospital in Turkey; this study aims to present a secure healthcare network infrastructure while presenting the security vulnerabilities in the current hospital information systems. The regulation criteria in Turkey and counterparts in USA and EU are compared according to their privacy approach and a list of items for common security controls from different industries is proposed as a best practice. The study shows that the hospital is not compliant with known healthcare standards like HIPAA or ISO 80001. Management's attitude against privacy and security shows that the responsibility is totally to IT and Biomedical Engineering Departments. Since explaining the threats and corresponding vulnerabilities in the system may cause the hospital be prone to cyber-attacks, the name of the hospital is secluded. As hospitals are adopting electronic transactions, consideration must be given to protect public electronic health records in terms of personal privacy aspects. Healthcare industry in Turkey should benefit from best practices in other industries and applications in other countries. This study can lead the pathway for policy makers in healthcare organizations and regulation authorities to implement a more secure environment for every citizen."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"Computational paralinguistics deals with the underlying meaning of the verbal messages. Understanding the meaning of verbal messages provides interpreting spoken content and behaving accordingly like humans. It allows us to develop human like machines. Hence, paralinguistic area is attracting increasing attention for research. Paralinguistic analysis involves extracting features from raw speech data, chunking, selecting relevant features and training the model. In this thesis, the focus is on the feature selection step. Feature selection aims at finding a relevant and necessary set of features to train generalizable models. The main challenge for feature selection methods is the greedy-search nature of them. One major motivation for this study to develop an efficient feature selection technique is the success of a recently developed discriminative projection based feature selection method. Here, the method is enhanced by applying the power of stochasticity to overcome traps in local minimum while reducing the computational complexity. The proposed approach assigns weights both to groups and to features individually in many randomly selected contexts and then combines them for a final ranking. The efficacy of the proposed method is shown in two recent challenge corpora to detect level of depression severity and conflict."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyolojik verilerin ikili sınıflandırması hem Biyoenformatik hem de Makine Öğrenmesi alanları için önemli bir araştırma problemidir. Özellikle etiketlenmiş verilerin sayısı çok azsa, bu problem daha da zorlaşmaktadır. İkili sınıflandırma için kullanılan üç ana makine öğrenmesi yontemi bulunmaktadır: sadece etiketlenmiş verileri kullanan gözetimli öğrenme, sadece etiketlenmemiş verileri kullanan gözetimsiz öğrenme ve hem etiketlenmiş hem de etiketlenmemiş verileri kullanan yarı-gözetimli öğrenme. Bu çalışmada, k-NN (En Yakın k Komşu), Liner ve RBF (Radyal Temelli Fonksiyon) çekirdek fonksiyonları ile SVM (Destek Vektör Makinesi) algoritmalarını temel alan gözetimli öğrenme ve bizim geliştirdiğimiz çeşitli yarı-gözetimli öğrenme algoritmaları, iki farkli biyoenformatik verisi olan insan HIV-1 virüsü protein-protein etkileşimlerini öngörmek ve kolon kanseri tekrarlamasını öngörmek için karşılaştırılmıştır. Geleneksel yarı-gözetimli öğrenme yaklaşımlarından farklı olarak, belirli bir sınıfa ait olduğuna dair bulgular bulunan etiketlenmemiş verileri anlatan `kesin olarak etiketlenmemiş' veri kavramı ortaya atılmıştır. Geliştirdiğimiz algoritmaların davranışsal özelliklerini gözlemlemek adına bilindik bir optik sayı verisi üzerinde `5' ve `6' sayıları sınıflandırılmıştır. Bu veri kümesinde `kesin etiketlenmemiş veri' oluşturmak için etiketlenmiş verilere yapay gürültü eklenmiştir. Tüm veri kümelerinde kesin etiketlenmemiş veri kullanımının performans göstergelerini arttırdığı görülmüştür. Bu çalışmada geliştirilen yarı-gözetimli yöntemlerden SS-kNN (Yarı-gözetimli k-NN)'nin ve SS-SVM (Yarı-göze-timli SVM)'in diğer algoritmalara göre kolon kanseri verisi ve optik sayılar verisi için doğruluk ve insan HIV-1 protein-protein etkileşimi verisi için kesinlik-geri getirme eğrisinin altında kalan alan açısından daha iyi sonuç verdiği gözlemlenmiştir.","Binary classification of biological data is an important research problem both in the Bioinformatics and Machine Learning fields. This problem is particularly challenging when the number of labeled instances is very few. There are three main machine learning approaches for classification: supervised methods, which only use labeled data, unsupervised methods, which only use unlabeled data, and semi-supervised methods, which use both labeled and unlabeled data. In this study, we compare the supervised and various developed semi-supervised methods which are based on k-NN (k Nearest Neighbor), SVM (Support Vector Machine) with linear kernel, and SVM with RBF (Radial Basis Function) kernel for two different Bioinformatics problems: predicting reccurrence in colorectal cancer from microarray data and predicting HIV-1-Human protein-protein interactions. As distinct from traditional semi-supervised learning approaches, we introduce the definition of `softly labeled' data that defines unlabeled data with additional information about their highly expected labels. We also evaluate our algorithms on a well-known optical digit dataset to classify the numbers `5' and `6' by generating synthetic noise and use as softly labeled data to better understand the behaviors of our algorithms. For all datasets, we concluded that softly labeled data are informative and enhances the evaluation results. Our semi-supervised methods SS-kNN (Semi-supervised kNN) and SS-SVM (Semi-supervised SVM) perform better than other algorithms in terms of accuracy for colorectal cancer and optical digit data, and area under the precision-recall curve for HIV-1-human protein-protein interaction data. Furthermore, in general, our semi-supervised methods achieve better performances than the supervised ones."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biyolojik veri üretimi, mikrodiziler ve yeni nesil sekanslama teknolojilerinin oluşumu ile baş döndürücü bir hızla artmaktadır. Yüksek Çıktılı Biyolojik Veri (YÇBV) olarak adlandırılan bu sonuçlar kapsamlı analiz metotlarına ihtiyaç duymaktadır. Yaşam bilimleri penceresinden bakılınca veri analizi sonuçları en fazla biyolojik patikalar düzleminde yorumlanınca fayda sağlamaktadır. Bayes Ağları (BA) hem doğrusal hem de doğrusal olmayan ilişkileri modelleyebilmekte ve stokastik olayları olasılıksal bir çerçevede gürültüye tolere ederek inceleyebilmektedir. Bu özellikler BA'ları YÇBV analizine uygun bir yöntem kılmaktadır. Isci v.d. tarafından yapılan yakın tarihli bir çalışma, Bayes Patika Analizi (BPA), YÇBV'yi BA kullanarak analiz eden bir yaklaşım önermektedir. Biyolojik patikalar BA olarak modellenip YÇBV'yi en iyi açıklayan patikalar bulunmaktadır. Bu tezin iki temel amacı vardır. Birinci amaç, BPA sistemini geliştirmektir. Veri işleme aşamasında, her gen için iki grup (kanser ve normal) arasındaki ifade değişim oranı hesaplanmakta ve ağ skorlama modülünde kullanılmak üzere sert eşik seviyeleri ile ayrıklaştırılmaktaydı. Buna ek olarak, çeşitli seviyelerde altı farklı ayrıklaştırma metodu denedik. Skorlama aşamasında, üç farklı skorlama yöntemi uygulayıp Bayes-Dirichlet eş yöntemiyle mukayese ettik. İstatistiksel belirginliği ölçme aşaması, rastsallaştırılmış veri kümelerini gen sinyal değerleri seviyesinde elde ederek bu konuda mevcut BPA yaklaşımının başarısız olduğu durumların üstesinden gelmek için geliştirdik. Optimize edilmiş yazılımın indirilip insan dahil çeşitli organizmalara uygulanabilmesi için web erişimi sağladık. İkinci amacımız, geliştirilmiş patika analizi yaklaşımını çeşitli gerçek kanser mikrodizi verilerine uygulayıp aktif patikaları belirlemektir. Sonuçlarımızı kıyaslanabilir bir yaklaşım olan SPIA ile karşılaştırdık.","Biological data production has been increasing at an unprecedented pace with the advancements of microarrays and next-generation sequencing technologies. Such High Throughput Biological Data (HTBD), requires detailed analysis methods. From a life science perspective, data analysis results make most sense when interpreted within the context of biological pathways. Bayesian Networks (BNs) capture both linear and nonlinear interactions, and handle stochastic events in a probabilistic framework accounting for noise. These properties make BNs excellent candidates for HTBD analysis. A recent study by Isci et al. proposes an approach, called Bayesian Pathway Analysis (BPA), for analyzing HTBD using BNs in which known biological pathways are modeled as BNs and pathways that best explain the given HTBD are found. In this thesis, we have the following two fundamental aims. Our first aim is to improve the BPA system. In the data processing phase, fold changes between two groups (i.e., cancer and normal) were calculated for genes and discretized using hard cut-off levels to be used in the network scoring module. We evaluated six different discretization methods with various numbers of levels. In the scoring phase, we applied three scoring methods and compared the results with the Bayesian-Dirichlet Equivalent scheme currently applied in the system. The statistical significance assessment phase was improved by obtaining randomized data sets at the gene signal level to overcome the cases where the current BPA fails to provide random data sets. We provide a web portal where the optimized software can be downloaded and used for various organisms including human. Our second aim is to apply the improved pathway analysis approach on various real cancer microarray data sets in order to investigate the pathways that are commonly and differently active. We compared our findings with a comparable approach, SPIA."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, ortam destekli yaşam çevrelerinde mevcut eğilimler ve zorluklar analiz edilmiş ve günlük yaşam algılama sistemlerini uzaktan izleme konusundaki kavramlarla uyumlu çalışacak, çabuk entegre edilebilir, bakımı ve geliştirilmesi kolay bir izleme sistemine ihtiyaç duyulduğu sonucuna varılmıştır. Bu gereksinimi karşılayabilmek adına geliştirdiğimiz, ortam sakinlerinin günlük yaşamlarını izleyip olağandışı gelişmeleri gerçek zamanlı olarak algılayabilen CAREACT sistemi bu güne kadar bir arada görülmemiş özellikleri bünyesinde barındırmaktadır. Bu özellikler arasında birlikte çalışabilirlik, kural tabanlı olay örgüsü algılama, analiz edilebilirlik ve uyarlanabilirlik bulunmaktadır. CAREACT üzerine inşa edildiği karmaşık olay işleme teknolojisinin kural tabanlı olay örgüsü algılama, gerçek zamanlı çalışma ve analiz edilebilirlik yeteneklerine tamamıyla sahip olup yoğun yük altında başarılı bir biçimde çalışabilmektedir. Bu tez çalışmasında ayrıca son derece yenilikçi bir yaklaşım olan ?Gelecek Olaylar? kavramı üzerinde de durulmaktadır. ?Gelecek Olaylar? yaklaşımı zaman kısıtı işleme modelini değiştirmektedir ve bu sayede ilgili kısıtları işleme süresi sabit zamanlı olarak gerçekleşmektedir. CAREACT sistemini geliştirip test merkezimizdeki mevcut izleme sistemlerinden birine entegre ederek, önerilen mimarinin uygulanabilir olduğunu ve olağandışı etkinlikleri algılama yetisini kayda değer bir şekilde artırdığını göstermiş bulunmaktayız.","In this thesis, we analyzed current trends and challenges in ambient assisted living environments and deduced that there is a need for a monitoring system that incorporates existing telemonitoring concepts to activities of daily living recognition systems in a way that is easy to integrate, requires little or no maintenance after deployment and is easy to modify whenever needed. To address this need, we present CAREACT, an ambient assisted living system which monitors daily lives of inhabitants for anomaly detection in real-time with a set of features supported by state of the art literature, that have not been combined in a single system up to date: interoperability, rule based pattern detection, adaptivity and analyzability. CAREACT is built on complex event processing technology which has builtin support for rule based pattern detection and interoperability that works in real-time under heavy load. In this work, we also present a new methodology, called future events, that changes the paradigm of processing the time windows within patterns in a way that it takes constant time to process time windows regardless of their size. We implemented CAREACT and integrated it with one of the existing activities of daily living systems in our testbed environment to show that the proposed architecture is applicable and indeed it increases the efficiency of the anomaly detection process."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde ispatçı ve çürütücü adlı iki oyuncunun girdinin dil içinde olup olmadığı üzerine oluşturduğu diyoloğun sınırlı kaynaklı olasılıksal bir hakem tarafından okunduğu yeni bir münazara modeli tanımlanmaktadır. Modelimiz tek yönlü etkileşimli ispat sistemleri, noksan bilgili oyunlar ve olasılıksal kontrollü münazara modellerini birleştirir ve genelleştirir. Tam-, kısmi- ve sıfır-bilgili münazara çeşitleri ele alınmaktadır. Kısmi- ve sıfır-bilgili münazaralarda ispatçı çürütücünün mesajlarından sırayla bazılarını ve hiçbirini göremezken, tam-bilgili münazaralarda her iki oyuncu da birbirlerinin mesajlarını tamamen görürler. Zamansal, belleksel ve olasılıksal olarak sınırlı bir hakemin bu çeşitlerde münzaraları kontrol ederek hangi dil ailelerini tanıyabileceği araştırılmaktadır. O(1) bellek ve O(1) rastgelelik kullanan hakemlerin bu üç münazara çeşidi için tanıyabildiği dil sınıflarının tam tanımı yapılmaktadır. İlaveten, sonlu bellekli hakemler tarafından herhangi bir hata payı ile kontrol edilebilen sırasıyla sıfır- ve kısmi-bilgili münazaralara sahip diller kümesi için alt limitler verilmektedir. Tam- ve kısmi-bilgili münazaraların zaman-sınırlı hakemler tarafından kontrol edildiği durumun gücü de araştırıldı ve bu hakemlerin ne kadar rastgelelik kullanırlarsa kullansınlar aynı sınırlara sahip belirlenimci hakemlere bir üstünlük kuramadıkları anlaşıldı. Fakat, rastgelelik kullanılmasının bu zaman-sınırlı hakemlerin beleklerinin zaman-sınırının logaritmasına kadar indirilebilmesine izin verdiği ortaya çıktı. Ayrıca, polinom zaman ve logaritmik bellekle sınırlı hakemlerin PSPACE'teki diller için tam- ve kısmi-bilgili münazara kontrol etmesinin logaritmik rastgelelik kullanılarak da mümkün olduğu gösterilmektedir. Son olarak, polinom zaman ve logaritmik bellek kullanıp tam-bilgili münazara kontrol eden hakemlerin yapısından faydalanıp böyle münazaralara sahip dillerin nicellendirilmiş matrisler üzerinde maksimum çarpım problemine indirgenebileceği gösterilerek bu problemin yakınsanamazlığı ile ilgili bir sonuç sunulmaktadır.","We introduce a model of probabilistic debate checking, where a silent resource-bounded verifier reads a dialogue about the membership of a given string in the language under consideration between a prover and a refuter. Our model combines and generalizes the concepts of one-way interactive proof systems, games of incomplete information, and probabilistically checkable complete-information debate systems. We consider debates of partial- and zero-information, where the prover is prevented from seeing some or all of the messages of the refuter, as well as those of complete-information. The classes of languages with debates checkable by verifiers operating under severe bounds on the time, memory, and randomness are studied. We give full characterizations of versions of these classes corresponding to simultaneous bounds of O(1) space and O(1) random bits, and logarithmic space and O(1) random bits. We further examine the power of constant-space model by giving lower bounds for the classes of languages checkable by such verifiers for any desired error bound when we loosen the randomness bound. We also examine the power of debate checking by time-bounded verifiers and show that no amount of randomness can help a time-bounded verifier to outperform its deterministic counterpart. However, we show that randomness does seem to help when we further constrain these time-bounded verifiers to use only logarithmic space in the order of their time bound. Additionally, in case of logspace and polynomial-time verifiers, we show that logarithmic randomness is sufficient to check complete- and partial-information debates for the languages in PSPACE. Finally, we show that any language having debates checkable by logspace polynomial-time verifiers can be reduced to the quantified max word problem for matrices, which allows us to present a result on the hardness of approximating this problem."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Türkiye Elektrik Piyasası Simülasyonu Oyunu, insanlara ciddi oyun yapısını kullanarak, Türkiye elektrik piyasasının temelini öğretmek ve onlara gerçek market ortamında alıştırma yapma şansını vermek amacı ile tasarlanmıştır. Türkiye Elektrik Piyasası Simülasyonu Oyunu neredeyse gerçek Türkiye elektrik piyasasındaki gerçekleştirilebilen tüm işlemleri kapsamaktadır. Türkiye elektrik piyasası ile ilgili bilgi kaynağı sıkıntısı yaşanan bir dönemde, oyun katılımcıları bu oyun sayesinde Türkiye elektrik piyasasının karmaşık yapısı ve bu piyasadaki güncel değişiklikler hakkında bilgi sahibi olabilmektedir. Bu oyun ile katılımcılar Türkiye elektrik piyasasını değişik perspektiflerden gözlemleme şansı bulmaktadır. Katılımcılar gerekli yatırım adımlarını atarak elektrik üretim santrallerine sahip olabilmekte ve gerçek marketteki ile tamamen aynı olan elektrik ticareti işlemlerini yapabilmektedir ve bu sayede herhangi bir risk almadan Türkiye elektrik piyasası ile ilgili ciddi bir deneyime sahip olabilmektedir. Türkiye elektrik piyasası oyunu çeşitli aşamalardan oluşmaktadır ve oyunun tüm aşamaları kısa olarak nitelendirilebilecek bir zaman diliminde tamamlanabilmektedir. Bu çalışma Türkiye elektrik piyasasında işlem yapmakta olan şirketlerin, üniversitelerde elektrik ile ilgili bölümlerin ve Türkiye elektrik piyasası hakkında bilgi sahibi olmak isteyen insanların ihtiyaçlarını karşılamak noktasında önemli bir adımdır. Anahtar kelimeler: Elektrik, Elektrik Piyasası, Ciddi oyun","Turkish Electricity Market Simulation Game is designed to inform people about the basics of the Turkish electricity market and give them chance to train themselves in the real market conditions by using serious game methodology. Turkish Electricity Market Simulation Game covers almost all of the operations which can be done in the real Turkish electricity market. In the environment where people cannot find up-to-date information sources about the Turkish electricity market, participants learn the basics of the Turkish electricity market, which is complicated, and up-to-date changes in the Turkish electricity market, which is hard to follow, by playing the game. In the game, participants have a chance to see the Turkish electricity market from different perspectives. They can own power plants by making investments and they can do trading operations which are done exactly in the same manner in the real market. Participants gain experience about the Turkish electricity market without taking any risks. The Turkish Electricity Market Simulation Game consists of many stages and total completion time for all these stages is not too long, which makes the game very efficient in terms of time. This study corresponds with the needs of the companies that are active in Turkish electricity market, electricity related departments in the universities and people interested in the Turkish electricity market. Key words: Electricity, Electricity market, Serious game"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Twitter, Facebook, Linkedin gibi büyük ölçekli sosyal ağların ortaya çıkmasıyla büyük verinin artan büyüme eğilimi daha da belirgin hale geldi. Bu durum, yoğun şekilde bağlı bu büyük verinin saklanmasına ek olarak etkili bir mekanizmayla işlen- mesi gereksinimini doğurdu. İlişkisel veri tabanı yönetimi sistemleri gibi geleneksel çözümlerin yetersiz kalması insanların graf veritabanlarına yönelmesine sebep oldu. Graf veritabanları, veri yapısı modellerinin grafları temel alması nedeniyle bağlı ver- iler için doğal bir çözüm olmaktadır. Milyarlarca düğüm ve ilişkiyi tek bir makinede işleyebilmelerine rağmen sosyal verinin artan büyüme hızı limitlerini zorlamaktadır. Bu çalışmada bir graf veri tabanı sisteminin işlem hacmini arttırabilmek için graf veri tabanlarının bölümlenmesini değerlendirmeyi amaçladık. Bu doğrultuda hem graf veri tabanını bölümlendiren hem de dağıtık bir graf veri tabanı sistemi sunan bir yapıyı tasarladık ve gerçekledik. Önceki çalışmalardan farklı olarak erişim örün- tülerine dayanan bir bölümlendirme üzerinde yoğunlaştık. Denemelerimiz esnasında erişim örüntülü bölümlendirme, sadece grafın yapısına dayanarak bölümlendirme ya- pan yöntemi geride bıraktı. Değerlendirmelerimiz için Erdös Projesi ve Pokec sosyal ağ verilerini kullandık.","With the emergence of large scale social networks such as Twitter, Facebook, Linkedin and Google+ the growing trend of big data become much clear. In addition to storing this highly connected big data, an efficient mechanism for processing this data is also needed. The inadequacy of traditional solutions such as relational database management systems for processing highly connected data caused the people head toward graph databases. Graph databases are the natural fit for connected data with their underlying data structure model depending on graphs. They are able to handle up to billions of nodes and relationships on a single machine but the high growing rate of social data pushes their limits. In this study, we evaluate partitioning graph databases in order to increase throughput of a graph database system. For this purpose we designed and implemented a framework that both partitions a graph database and provides a fully functional dis- tributed graph database system. Comparing to previous studies we have concentrated on access pattern based partitioning. Within our experiments access pattern based partitioning outperformed unbiased partitioning that only depends on static structure of the graph. We have evaluated our results on real world datasets of Erdös Webgraph Project and Pokec social network."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, olasılıksal zaman serisi sınıflandırma ve topaklandırma yöntemleri üzerine çalışılmıştır. Bu amaçla, Markov modelleri, saklı Markov modelleri, Markov modeli karışımları ve saklı Markov modeli karışımları kullanılmıştır. Ayırıcı Markov modelleri ve ayırıcı saklı Markov modelleri de incelenmiştir. Bu tezde, Markov modeli karışımları ve saklı Markov modeli karışımları öğrenmek için iki yeni algoritma öneriyoruz. Literatürde, karışım modellerinin öğrenilmesi çoğunlukla global optimum bulma garantisi olmayan Beklenti Enbüyütme algoritması ile yapılmaktadır. Biz, yapay öğrenme literatüründe son dönemde popüler olmaya başlayan spektral öğrenme yöntemlerinin kullanılmasını öneriyoruz. Spektral öğrenme algoritmaları saklı değişken modelleri için sadece gözlemlenebilir moment matris veya tensörlerinin özdeğer-özvektör ayrışımını alarak parametre kestirimi yapma olanağı sunmaktadır. Spektral öğrenme algoritmalarının popülerliği, hesap yükü bakımından ucuz olmaları ve lokal optimumlara takılma sorunu olmadan parametre kestirimi yapabilmelerinden kaynaklanmaktadır. Önerdiğimiz algoritmalarının geçerliliğini göstermek için, insan edim videoları üstünde sınıflandırma, insan hareket yakalama (motion capture) ve internet ağı verileri üstünde topaklandırma deneyleri yapıyoruz. Neticede, önerdiğimiz spektral öğrenme tabanlı algoritmaların yüksek topaklandırma başarısı gösteren ve hızlı algoritmalar olduğunu gösteriyoruz.","In this thesis, we investigate probabilistic methods for time series classification and clustering problems. For various classification and clustering tasks, we survey different time series models such as Markov models, hidden Markov models (HMM), mixture of Markov models and mixture of HMMs. We also investigate discriminative versions of Markov model and HMM. The novel contribution of this thesis is the derivation of algorithms for learning mixtures of Markov models and mixtures of hidden Markov models. Mixture models are special latent variable models that require the usage of local search heuristics such as Expectation Maximization algorithm, that can only provide locally optimal solutions. In contrast, we make use of the spectral learning algorithms, recently popularized in the machine learning community. Spectral learning algorithms are able to estimate the parameters in latent variable models by solving systems of equations via eigendecompositions of matrices or tensors of observable moments. As such, spectral methods can be viewed as an instance of the method of moments for parameter estimation, an alternative to maximum likelihood. The popularity stems from the fact that these methods provide a computationally cheap and local optima free alternative to EM. We conduct classification experiments on human action sequences extracted from videos, clustering experiments on motion capture data and network traffic data to illustrate the viability of our approach. We conclude that the spectral methods are a practical and useful alternative in terms of computational effort and solution quality to standard iterative techniques such as EM in many application areas."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu araştırma farklı tıbbi tanılar için insan bilgisinin yanında, veri madenciliği üzerinde farklı alternatifler aramak içindir. Yapılan birçok başarılı uygulama örnekleri içerisinde insan teşhis yeteneklerinin sonuçlarının nöral teşhis sistemi sonuçlarına göre daha kötü sonuçlar verdiği göstermektedir. Çalışma sağlık alanındaki Onbir adet verinin veri madenciliği analizi ile ilgilidir.Çalışma içerisinde farklı Tıbbi alanlar hedeflenerek Veri Madenciliği analizlerinin çeşitli Sağlık verilerine yaptığı yorumlar incelenmiştir. Yapay sinir ağlarının sağlık alanındaki çalışmaları kısaca tanıtıldı, tıbbi veri tabanı ve eğitim, ve tıbbi verilerin bir sinir ağı test edilmesine yönelik temel yaklaşımların üzerinde duruldu. Birkaç test yapılandırmaları, algoritmalar için en iyi ayarı belirlemek için test edilmektedir. Bu çalışmada kullanılan Sekiz adet veri madenciliği algoritmaları bulunmaktadır. Detayları ise şu şekildedir: DT, SVM, RBF, MLP, k-NN, Naive Bayes, Bayes Net ve Lojistik Regresyon. Belirtilen Sekiz adet algorithma ?10-fold cross validation? ve ?train/test split? değerlendirmeleri göz önüne alınarak Onbir adet veri üzerinde değerlendirilmiştir. Bununla beraber PCA için de ayrı bir değerlendirme gerçekleştirilerek araştırma içerisindeki farklılıkları gösterilmiştir. Tez içerisinde odaklanılan performans metrikleri ise şu şekildedir: Percent Correct, True Positive Rate, False Positive Rate, Precision, Recall, F-Measure, AUC ve Error Rates. Bu tez farklı algoritmalar ve veriler üzerien bir kıyaslama çalışması olduğundan dolayı, tez çalışmasının değerlendirilmesi için özel bir kıyaslama ölçütü oluşturulmuştur.","This research is to search for alternatives to the resolution of complex medical diagnosis where human knowledge should be apprehended in a general fashion. Successful application examples show that human diagnostic capabilities are significantly worse than the neural diagnostic system. The study presents the particular case of analysis of eleven datasets containing data associated to several Healthcare datasets. The datasets are analyzed in various Healthcare domains to target different Medical areas. Paradigm of artificial neural networks is shortly introduced and the main problems of medical data base and the basic approaches for training and testing a network by medical data are described. There are eight algorithms used in this study, which are DT, SVM, RBF, MLP, k-NN, Naïve Bayes, Bayes Net and Logistic Regression. These eight algorithms have been performed with using 10-fold cross validation and train/test split over the eleven datasets. It?s also examined what is the effect of Principal Component Analysis inside the research. The performance metrics that are focused in this thesis are Percent Correct, True Positive Rate, False Positive Rate, Precision, Recall, F-Measure, AUC and Error Rates. As this is a benchmarking study for different classifiers and datasets, a special benchmarking criterion has been created for the evaluation of the thesis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ev ortamlarında insan hareketlerinin tanınması çevresel destekli yaşama uygulamalarında büyük yarar sağlar. Sürekli ve uzun vadeli izleme ile evden yaşayan insanların günlük rutinleri hakkında çıkarımlar yapılabilir ve bir hastalığın habercisi olabilecek anormal durumlar önceden anlaşılabilir. Ek olarak, sağlık çalışanları bu tarz durumlarda önceden bilgilendirilebilir. Algılayıcı ağlarındaki son gelişmeler araştırmacıların kablosuz algılayıcı ağları insan hareketi izleme uygulamalarında kullanmasına olanak sağlamıştır. Biz, evde yaşayan insanların günlük yaşamlarını izleyen bir çevresel destekli yaşam sistemi öneriyoruz. Bu amaçla, çeşitli çevresel algılayıcılardan oluşan bir kablosuz algılayıcı ağı iki kişinin yaşadığı bir eve kurduk. 30 tam gün boyunca, gerçek yaşam koşulları altında, evde yaşayanların özel hayatlarına saygı göstererek günlük yaşam hareketleri hakkında veri topladık. Çeşitli makine öğrenimi yöntemleriyle, toplanan veriyi evde yaşayan insanların davranışlarını modellemek ve onların alışkanlıkları hakkında çıkarımlar yapabilmek için sınıflandırdık. Bu tezde, tasarladığımız kablosuz algılayıcı ağın mimarisi hakkında detaylı bilgiler verip, veri toplama boyunca edindiğimiz tecrübeleri ve sınıflandırma sonuçlarını paylaşıyoruz.","Human activity recognition in home settings provides great facilities in ambient assisted living applications. With continuous and long term monitoring, daily routines of the residents can be inferred and any abnormal situation which can be an indicator of a disease can be detected. Furthermore, health professionals can be informed in advance in such situations. Recent advances in sensor network technologies enable researchers to utilize wireless sensor networks in human activity monitoring applications. We present an ambient assisted living system which monitors the daily living of residents. For this purpose, we deployed a wireless sensor network which consists of many ambient sensors in a real house in which two residents live. Data about daily living activities of residents were collected for 30 full days accounting the privacy issues under real world conditions. Using several machine learning methods, we classified the collected data in order to model behaviours of residents and make inferences about their habits. In this thesis, we elaborate the system architecture of the wireless sensor network, share the experiences obtained during the data collection process, and the results of the classification."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İmge işlemede tekrar kullanım, var olan bir imgenin görsel bileşenlerinin yeni bir imge oluşturmak için kullanılmasını ifade etmektedir. Bu tezde literatürde daha önce kapsamlı olarak ele alınmamış bir konu olan dijital sanat eserlerinde tekrar kullanımın otomatik olarak tespit edilmesi üzerinde çalıştık. Bu çalışmada iki yeni veri seti sunuyoruz: farklı tekrar kullanım biçimlerini sistematik olarak benzeten sentetik bir veri seti ve internetten derlenmiş, alt bilgi içeren görüntülerden oluşan doğal bir veri seti. Doğal veri setindeki görüntülerden yola çıkarak temel tekrar kullanım ve düzenleme tiplerini tanımlayan bir taksonomi önerdik. Daha sonra, imgelerde kopya tespiti, içerik tabanlı imge erişimi ve sanat eserlerinin bilgisayar analizi gibi problemlerde yaygın olarak kullanılan yöntemleri --renk histogramları, HOG, BoW modelinde kullanılan SIFT tanımlayıcısı ve renk-tabanlı varyantları-- görüntü tekrar kullanım tespiti için kullanımını değerlendirdik. Var olan yöntemlere ek olarak, AISP adını verdiğimiz, görsel olarak belirgin olan alanlara uydurulan eş merkezli elipslerden çıkarılan özelliklerden faydalanan, ön plan hassasiyeti olan bir görüntü tanımlama algoritması önerdik. Sonuçlarımız, görüntülerin kompakt bir şekilde karakterize edilmesine olanak sağlayan AISP yönteminin kabul edilebilir doğruluk oranları ile tekrar kullanım tespiti problemi için özellikle nesnelerin belirgin olarak ön planda olduğu durumlarda kullanışlı olabileceğini, bununla birlikte görüntülerin sanatçılar tarafından oluşturulduğu daha doğal durumlarda SIFT tanımlayıcılarının BoW modeli ile kullanımının tavsiye edilebilir olduğunu göstermektedir.","Image reuse refers to the use of visual elements of existing images in order to create new ones. In this thesis, we study the automatic image reuse detection problem in digital artworks, which is a relatively under-studied problem of image retrieval. We introduce two novel image reuse datasets: an artificial dataset that simulates different types of reuse systematically, and an annotated natural dataset that includes a set of digital artworks that are crawled from the web. Based on the natural dataset, we propose a taxonomy which identifies the primary types of reuse and manipulations. Then, for image reuse detection, we evaluate different feature extraction and classification methods that are commonly used for image copy detection, content-based image retrieval, and computer analysis of artworks. The features we use include, color histograms, Histogram of Oriented Gradient (HOG) descriptors, and the Scale Invariant Feature Transform (SIFT) descriptor and its color-based variants. We use the bag-of-visual-words (BoW) approach with the SIFT descriptors. We also present a novel image description algorithm, called the Affine Invariant Salient Patch (AISP) descriptor, which provides a foreground sensitive description of images by fitting concentric ellipses to the most salient region in an image and extracting features from each track. Our results show that the AISP method can be suitable for reuse detection with its compactness and good retrieval accuracy, especially in images with prominent foreground objects. On the other hand, the use of the SIFT descriptors in a BoW model can be more advisable in a more natural setting and for cluttered scenes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Teknolojinin gelişimi ile birlikte Down sendromu gibi genetik düzensizliklerin gebelik sırasında tanımlama yöntemleri oldukça gelişmiştir. Down sendromu teşhisi için fetal doku örneklerini analiz eden amniyosentez veya koryon villus örneklemesi gibi kesin tanı koyan yollar vardır, fakat her hamilelikte bu invaziv yöntemleri kullanmak uygun değildir. Bu yöntemler büyük ölçüde tıbbi bakım maliyetini artırmanın yanı sıra, fetus için risk teşkil etmektedir. Bu sebeple öznitelik ve görüntüleme analizleri gibi invaziv olmayan yöntemler ile bu gebeler ""yüksek risk"" grubunda sınıflandırılabilmektedir. Bu sınıftaki gebeler daha fazla tanısal test ile değerlendirilmektedir. Bu tezde, invaziv testleri azaltmak amacıyla Down sendromu yüksek riskli sınıfını oluşturmak için karar verme problemleri yapay öğrenme bakış açısı ile ele alınmıştır. İlk olarak, Down Sendromu tahmini için sınıflandırma tekniklerinin kapsamlı bir analizi sunulmuştur. Aynı zamanda, özniteliklerin belirleyici etkileri değerlendirilmiş ve gereksiz değişkenler elenerek ideal öznitelik alt kümesi belirlenmiştir. Çalışmanın devamında, metodolojik iyileştirmeler ve kullanılan veri kümesinin bilgi içeriğinin genişletilmesi ile tahmin performansı arttırılmıştır. İlk olarak, dengesiz sınıf dağılımı problemi ele alınmış, karar eşiği optimizasyonu ve öğrenme kümesinin yeniden örneklenmesi ile çözüm yöntemleri analiz edilmiştir. İkinci olarak, kategorik özniteliklerin sayısal değerlere dönüştürülmesinin tahmin gücüne olan etkisi incelenmiştir. Bu çalışmanın kapsamında iki farklı veri seti kullanılmıştır. Son olarak, Trizomi 21 tahminlemesi için Bayes Teoremini kullanan olasılıksal sınıflandırıcılardan Naive Bayes ve Bayes Ağlar yöntemleri uygulanmıştır. Ayrıca yaygın olarak kullanılan sınıflandırıcılardan Karar ağacı, Destek Vektör Makinesi, Çok Katmanlı İdrak, ve k-NN kullanılmıştır. Ana motivasyonlarımızdan biri olan olasılıksal sınıflandırıcılar ile diğer sınıflandırıcıların performansı duyarlılık, özgüllük, doğruluk ve ROC değerleri esas alınarak karşılaştırılmıştır. Deneylerde (i) olasılıksal sınıflandırıcıların Trizomi 21 tahmininde kabul edilebilir başarı oranı elde ettiği ve (ii) bu çalışmada önerilen teknikler kullanılarak tahmin performansının arttırılabileceği görülmüştür.","Over the last 20 years, new technology has improved the methods of detection of fetal abnormalities, including Down syndrome. While there are ways to diagnose Down syndrome by obtaining fetal tissue samples by amniocentesis or chorionic villus sampling, it would not be appropriate to examine every pregnancy this way. Besides greatly increasing the cost of medical care, these methods do carry a slight amount of risk to the fetus. So non-invasive methods such as characteristics and screening analysis have been developed to try to identify those pregnancies at ""high risk"". These pregnancies are then candidates for further diagnostic testing. In this thesis, we address the decision-making problems in diagnosing Down syndrome cases from the machine learning perspective aiming to decrease invasive tests. Initially, we present a comprehensive and comparative analysis of the classification techniques in Down syndrome prediction. In parallel, we evaluate the predictor effects of input features in order to eliminate the redundant features and decide the optimum feature subset leading to the highest prediction performance. Later, we focus on improving the classification performance either by parameter optimization or by improving the information content of the data. First we handle the problem of imbalanced class distribution. As a solution to imbalance class problem we analyse decision threshold optimization and re-sampling the training data techniques. Secondly, we use probabilistic classifiers based on applying Bayes Theorem, Naive Bayes and Bayesian Networks, to predict the Trisomy 21 case. In contrast to probabilistic classifiers we also apply some of widely used and well known classifiers such as Decision Tree, Support Vector Machine, Multi Layer Perceptron, and k-NN. In this thesis, we aim to evaluate the probabilistic classifiers performance with respect to these methods. This comparison is based on performance metrics such as sensitivity, specificity, accuracy and Receiver Operating Characteristics. The results of the experiments show that (i) probabilistic classifiers enable acceptable prediction of Trisomy 21 case and (ii) the classification performance can be improved by using the proposed techniques in this study."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevre destekli yaşam, yaşlı kişilerin sürekli bir sağlık personeli gözetimi altında olmaksızın, akıllı teknolojiler yardımı ile yaşlılığın getirdiği fiziksel ve sosyal etkilerin yarattığı problemlere çözüm sunmak ve kişilerin yaşam kalitelerini artırmak için oluşturulmuş bir kavramdır. 'Sağlıklı yaşlanma' olarak da özetlenebilen bu konsept çerçevesinde öncelikli amaç, yaşlı kişilerin sağlık hizmetleri için koruyucu bir yaklaşım izleyerek kişinin fiziksel ve zihinsel sağlığını devam ettirebilmesidir. Fiziksel ve zihinsel sağlığın korunması düzenli egzersiz hareketlerinin yapılmasıyla mümkündür. Bu çalışmada, bahsedilen teknolojinin bir parçası olarak, yaşlı kişilere günlük egzersiz hareketlerinde yardımcı olabilecek bir egzersiz eğitmeni robotu geliştirilmesi amaçlanmıştır. İnsan ve robot arasındaki etkileşim senaryosu temel olarak iki farklı kısımdan oluşmaktadır. İlk kısımda, robot bir dizi egzersiz hareketleri sergileyen egzersiz eğitmeninin hareketlerini analiz ederek bu hareketleri nasıl yapması gerektiğini öğrenecektir. İkinci kısımda ise, robot eğitmenden öğrendiği bu hareketleri yaşlı kişinin karşısında yaparak ona gösterecek ve ondan kendisini tekrar etmesini isteyecektir. Kişinin hareketleri doğru yapıp yapmaması üzerine geri bildirimlerde bulunarak istenilen performansın elde edilebilmesi için yaşlı kişiye yardımcı olacaktır. Robotun yapması planlanan egzersiz hareketleri gerçek dünya ile benzerlik taşıması açısından bir huzur evinde gerçekleştirilen toplu egzersiz seansları sırasında sergilenen hareketlerden seçilmiştir. Çalışmamızda Aldebaran şirketi tarafından üretilen insansı robot Nao ve insan hareketlerini analiz edebilmek için Microsoft Kinect algılayıcısı kullanılmıştır.","Ambient assisted living is a concept that summarizes the effort to create intelligent technologies to help elderly people to live without constant supervision by costly health personnel, as well as to improve their quality of life by offering solutions to typical problems related with age and its physical and social implications. The primary goal in this endeavor is to develop a preventive approach of health care for elderly, sometimes summarized by the concept of 'successful aging', where the subject retains and sustains his physical and mental well-being. Both physical and mental health require regular activity (possibly in the form of regular exercises) for this purpose. In this study, we aim to develop a fitness coach robot which can help elderly people in their daily physical activities. The overall scenario includes two different parts. First, a human supervisor performs fitness motions and the robot will learn them by analyzing the behavior of the demonstrator. In the second part the robot performs the learned gestures to the best of its abilities, and while monitoring the elderly subject with an RGB-D camera, provides verbal guidance to complement the visual display, correcting gestures on the fly. The gestures were selected from an actual training programme at an elderly care home in order to create a real world scenario. A humanoid robot, Nao, is used for this study and a 3D depth sensor, Microsoft Kinect sensor is utilized to analyze human gestures."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın amacı, yapay öğrenme tekniklerini kullanarak soy metal katalizörleri üzerinde su-gazı geçiş reaksiyonu için literatürde yayınlanmış deneysel verilerden bilgi çıkarmak ve böylece literatürdeki eğilimleri anlayarak katalizör tasarımını iyileştirmektir. Bunun için ilk olarak, literatürde 2002 ve 2012 yılları arasında yayınlanan 85 makaleden deneysel veriler çıkarılmış ve 4372 veri noktası ve 87 değişken içeren bir veri tabanı oluşturulmuştur. Sonra, bilgi çıkarımı yapmak için kullanılacak yöntem seçilmiş, bunun için yapay öğrenmede en etkili yöntemler arasında yer alan destek yöney makinaları ve yapay sinir ağları yöntemleri daha önce laboratuvarımızda analiz edilmiş olan bir veri tabanı üzerinde test edilmiş, yapay sinir ağları daha başarılı bulunmuştur. Bu nedenle oluşturulan su gazı geçiş reaksiyonuna ait veritabanı sinir ağları yöntemiyle modellenmiştir. Optimum yapay sinir ağı yapısı, değişik ağ yapıları oluşturularak kıyaslanmış, bunun için bir modelin genelleme (modelin hiç görmediği veriyi tahmin edebilme) yeteneğinin ölçüsü olarak kabul edilen ortalama karekök hataların toplamı kullanılmıştır. Çalışma sonunda veri tabanına en uygun ağın her biri 21 nöron içeren iki saklı katmanlı ağ yapısının uygun olduğu görülmüştür. Daha sonra, her makaledeki veriler, diğer makalelerdeki veriler kullanılarak tekrar eğitilen modelle teker teker tahmin edilmeye çalışılmıştır. 85 makale içerisinden 29 makale, 0.5'in üzerinde bir R2 değeri ile, başarılı sayılabilecek biçimde tahmin edilmiştir. Ayrıca, katalizör tasarım ve operasyonel değişkenlerin katalizör performansına etkileri ve göreceli önemleri sinir ağları yöntemiyle analiz edilmiş ve sonuçlar genel olarak literatüre uygun çıkmıştır.","The aim of this thesis is to apply the machine learning methodologies for knowledge extraction from experimental data for water gas shift reaction over noble metal catalysts from the papers published in the literature to understand the general trends and improve the catalyst design. First, the experimental data were extracted from 85 articles in the literature between 2002 and 2012 and a database containing 4372 data points with 87 variables was constructed. Then the methodology for knowledge extraction was selected; the neural networks and support vector machines, which are the two most effective machine learning tools, were compared using a dataset that was analyzed in our group before, and the neural network method showed better performance on prediction the unseen data. Hence the water gas shift reaction database was analyzed by using neural networks. An optimal network structure was determined by constructing various neural network topologies and comparing the testing RMSE, which is a measure of generalization ability of the model (prediction ability for the unseen data); two hidden layer network containing 21 nodes in each layer was found to be optimum to represent the database. Then, the experimental CO conversions in each article were predicted by the neural networks trained using the data from the remaining articles. The results in 29 articles out of 85 were predicted with a R2 value of higher than 0.5, which can be considered as successful. The effects and relative significances of the catalyst design and operation variables were also analyzed and found to be generally in agreement with the literature."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sonlu durum makinesi otomata teorisinin en çok incelenen modellerinden biri olmuştur. Standart modelin gücünün sınırlı olması araştırmacıları bu standart modelin üzerine farklı eklemeler yapmaya itmiştir. Sayaçlı makineler, çarpımlı sonlu durum makineleri, grup üzerinde tanımlı sonlu durum makineleri bu eklemelere örnektir. Bu tezde $ k $ boyutlu bir vektörle güçlendirilmiş ve her adımda bu vektörü uygun kxk matrislerle çarpmaya programlanmış gerçek zamanlı sonlu durum makineleri incelenmiştir. Bir adımda vektörün sadece tek bir girdisi 1'e eşit mi diye kontrol edilebilir. Makinelerin belirlenimci, belirlenimci olmayan, ``kör'' versiyonları tarafından tanınan diller incelenmiş ve birbirleriyle karşılaştırılmışlardır. Bu makineler ile, sayaçlı makinelerin ve genellenmiş sonlu durum makinelerin birbirleriyle yakından ilişkili olduğu ortaya çıkmıştır.","Finite automaton has been one of the most studied models in automata theory. The limited power of the standard model has led researchers to make various extensions to the standard model. Counter automaton, automaton with multiplication, finite automaton over groups are some of the examples of such extensions. In this thesis, we study the computational power of real-time finite automaton that has been augmented with a vector of dimension $k$, and programmed to multiply this vector at each step by an appropriately selected kxk matrix. Only one entry of the vector can be tested for equality to 1 at any time. We study the classes of languages recognized by deterministic, nondeterministic, and ``blind'' versions of these machines and compare them with each other. It turns out that these machines are closely related to some of the classical models like counter automata and generalized finite automata."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın amacı ciddi oyunların takım oluşturma üzerine etkilerini çok kullanıcılı çevrimiçi ortamlarda ölçmektir. Bu amaçla hâlihazırda gerçek hayatta takım oluşturma için kullanılan Zoom oyunu çok kullanıcılı çevrimiçi ortama uyarlanmıştır. Farklı sayılarda katılımcılardan oluşan gruplar halinde toplam 43 kişi bu oyunu oynamıştır. Derinlemesine yapılan bir literatür taramasının ardından, ciddi oyunların takım oluşturma üzerindeki etkilerini çok kullanıcılı çevrimiçi ortamlarda ölçmek için, açık ve kapalı uçlu sorulardan oluşan bir anket hazırlanmıştır. Katılımcılar oyunla ilgili düşüncelerini bu anketi doldurarak belirtmişlerdir. Kapalı uçlu soruların cevapları The Statistical Package for Social Sciences (SPSS) yazılımı kullanılarak, güvenilirlik İç Tutarlılık Katsayısı Analizi uygulanarak, hipotezler de Regresyon ve Çoklu Regresyon Analizleri kullanılarak test edilmiştir. Buna ek olarak açık uçlu soruların cevapları da incelenmiştir. Kapalı uçlu soruların cevaplarından elde edilen veriler göstermiştir ki; ciddi oyunların oluşturulduğu ortamların fiziksel özellikleri ve katılımcıların ciddi oyunlara karşı tutumu takım oluşturma başarısını etkiler ve katılımcıların kişilik özelliklerinin bu iki ilişkinin gücü ve yönü üzerinde etkisi vardır. Açık uçlu soruların cevaplarının incelenmesi sonucu göstermiştir ki; katılımcılar, çok kullanıcılı çevrimiçi ortamdaki ciddi oyunu yararlı, ilgili, amaca hizmet eden ve eğlenceli bir oyun olarak nitelemişlerdir. Aynı zamanda bu ve bu gibi oyunların yüz yüze oynanan takım oluşturma oyunlarının bir alternatifi olarak kullanılabileceklerini ifade etmişlerdir.","The aim of this study is measuring the effects of serious game on team building in a multi-user virtual environment. For this purpose serious game Zoom which has been used in real life for team building was adapted into online multi-user virtual environment. 43 people played the game as a group which consists of different number of participants. After comprehensive literature review, a questionnaire which consists of both closed-ended and open-ended questions was prepared in order to measure the effects of serious game on team building in a multi-user virtual environment. Participants declared their ideas about the serious game by filling this questionnaire. The responses to the close-ended questions were analyzed by using The Statistical Package for Social Sciences (SPSS) software, reliabilities were tested by Cronbach?s Alpha analysis and hypotheses were tested by applying Regression and Multiple Regression analysis. In addition to this the responses to the open-ended questions were examined. Analysis of data gathered from close-ended questions shows that physical characteristics of the serious game environment and attitudes of participants toward serious game affect the team building success and these two relations are moderated by personality of the participants. As a result of examination of open-ended questions that participants described the serious game in a multi-user virtual environment as helpful, relevant, on purpose and entertaining. Also they stated that this game and the games similar to this can be used as an alternative to the face-to-face team building games."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Birçok uygulamada, alınan ölçüm kaynaklarının mümkün olduğunca doğru tespit edilmesinin gerekliliğinden ötürü kablosuz algılayıcı ağlarında konum tespiti son yıllarda gittikçe önem kazanmıştır. Kanal ve yol kaybı modelleme, başarılı bir konum tespit sistemi tasarımında anahtar rol oynamaktadır. Bu çalışmada, şimdiye kadar geliştirilen kapalı alan kanal modelleri ile en çok kullanılan mesafe tahmini ve konum tahmini algoritmaları incelenmiştir. Değişken alıcı verici arası mesafelerinde yol kaybı verileri toplamak üzere ZigBee tabanlı bir AİŞG (Alınan İşaretin Şiddet Göstergesi) ölçüm sistemi tasarlanmıştır. ZigBee algılayıcı ağları için empirik bir kapalı alan kanal modeli tasarlanmış ve incelenen konum tahmini algoritmalarında kullanılarak konum tespiti gerçeklemeleri yapılmıştır. Tasarlanan kanal modelinin yanısıra incelenen konum tahmini algoritmaları da nümerik olarak benzetim çalışmalarıyla test edilmiştir.","Localization in wireless sensor networks is getting more and more important in the recent years, since many applications need to locate the source of incoming measurements as precise as possible. Channel propagation and path loss modelling is the key point in successful position estimation. In this thesis, most popular distance estimation and position estimation methodologies are discussed, as well as the indoor channel models developed so far are presented. A ZigBee based RSSI (Received Signal Strength Indicator) measurement system is designed to collect path loss data with varying distances between the transmitter and the receiver. An empirical indoor channel model for ZigBee sensor networks is developed based on the path loss measurements, and implemented with the discussed position estimation methodologies. Not only the developed path loss model, but also the presented position estimation methodologies are evaluated numerically via simulations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kavramsal Radyo Ağlarındaki çalışmalar, kanal sezimlemede müşterek operasyonun sezimleme güvenilirliğini ve dolayısıyla ağ verimliliğini artırdığını göstermiştir. Fakat müşterek kanal sezimleme bu çalışmalarda varsayılan operasyon modu olarak kabul edilmektedir, ki bu varsayım bir çok sebepten ötürü gerçekleşmeyebilir. Cünkü kavramsal radyolar batarya ile çalışan cihazlardır ve zaten nadir olan boş kanal fırsatlarını yakalamak için sezimleme yaparken değerli bir kaynak olan enerjilerini ve zamanlarını sadece müşterek sezimlemede yardım isteyen diğer kavramsal radyolara harcamak istemeyebilirler. Bu çalışmamızda biz bu varsayımı ortadan kaldırıp kavramsal radyolar arası sosyal ilişkilere dayandırılan bir müşterek sezimleme sistemi oluşturduk. Dolayısıyla kavramsal radyoları arkadaşlık bağı, sosyal grup ve bencillik gibi özellikleri olan kullanıcıları ile bağdaştırdık. Kavramsal radyolar arasındaki bu ilişkilere dayanarak, bu ilişkilerin farkında olan bir müşterek sezimleme planı geliştirdik ve bu planın sezimleme performansı üzerindeki etkilerini inceledik. Biz, sosyal metriklerin kullanıldığı bir sezimleme planının müşterek sezimlemeyi desteklediğine ve sosyal ilişkilerle iç içe bir modellemenin yeni çağın ağlarına daha uygun olacağına inanıyoruz. Çalışmamızda sosyal ilişkilerin farkında olan müşterek sezimleme planımızın, müşterek sezimleme için rastgele kavramsal radyo seçiminde bulunan bir modele göre, kanal fırsatları yakalama, haberleşme yükü ve saldırgan kullanıcılar ile müşterek sezimleme yapmama açılarından çeşitli benzetim senaryoları altında daha iyi bir performans sergilediğini gösterdik.","Previous works in cognitive radio networks (CRNs) have shown that cooperation in sensing improves sensing reliability and in turn enhances the network throughput. Although this altruistic cooperative behavior is accepted as the default mode of oper- ation, it may often be invalid under practical circumstances. In this thesis, we loosen this assumption and introduce a cooperative mode of operation conditioned on social relations between Cognitive Radios (CRs). Rather than taking CRs as wireless devices with no context, we associate each CR with its user that has some social relations, e.g. friendship, community, selfishness. Using these relations among CRs, we propose a social-aware cooperative sensing scheme (SAC) and analyze its effects on sensing performance. We examine that exploiting social metrics is highly beneficial for cooper- ative sensing in CRNs and a model with social relations embedded will fit better to the next decade?s networking paradigm. Furthermore, we show in this thesis that a social aware sensing scheme outperforms a randomly cooperating candidate selecting scheme in terms of opportunity discovery, cooperation message overhead, and avoidance of cooperation with malicious users under various simulation scenarios."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde Analog ve Karışık İşaret (AKİ) sistemler için gözcü tabanlı doğrulama yöntembilimi incelenmiş ve gözcülerin analog özellikleri daha ifade edebeilmesi sağlanmıştır. Gözcü tabanlı doğrulama yöntemleri, ilk olarak sayısal tasarım ve yazılım alanları için geliştirildiği için analog özellikleri ifade etmekte yetersiz kalmaktadır. Bu yüzden, öncelikle analog işaretler için hale kavramını öne sürülmüştür. Haleler, analog işaretlerin çevresinde kabul edilebilir alanlar tanımlayarak analog karşılaştırmayı kolaylaştırmaktadır. İkinci olarak analog doğrulamada yaygın olarak kullanılan ölçümler ve devre çözümlemeleri AKİ gözcüleri ile bütünleştirilmiştir. Bu bütünleşme ile AKİ sistemler için tam ve birleşik bir doğrulama ortamı elde edilmiştir. Son olarak AMS-Verify aracı geliştirilmiş ve önerilen doğrulama çözümleri bu araç ile gerçeklenmiştir. Sunulan üç örnek tasarımda ise AKİ özellikler için gözcü formülleri yazılmış ve bu özellikler AMS-Verify aracı kullanılarak benzetimler üzerinden doğrulanmıştır.","This thesis studies assertion based verification methodology for analog and mixed-signal (AMS) designs and improves analog expressiveness of assertions. Assertion based verification methodology is originally derived for digital domain, hence AMS assertion languages are inadequate to express all aspects of AMS designs. Therefore, we first introduce the halo concept for analog signals to formally express them with their tolerance and variation values in assertions. Haloes of analog signals define an effective region around these signals which help analog comparison. Second, we integrate measurements and circuit analyses into AMS assertions. These analyses are widely used verification techniques in conventional AMS verification. Their integration into assertions provide a complete and unified AMS verification methodology. Finally, we develop AMS-Verify, a flexible framework to verify AMS properties on simulations. AMS-Verify is able to express analog tolerances, measurements and circuit analyses. We validate our solutions in three case studies using AMS-Verify framework."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son on yıl içerisinde Eğitim Yönetim Bilişim Sistemleri Türkiye?de direk bir değişinim içerisindedir. Bu bağlamda, bu sistemlerden elde edilen veriler ile yapılacak eğitsel veri madenciliğinin çok gerekli olduğu düşünülmektedir. Bu çalışmada, meslek lisesi öğrencilerinin bölüm seçim süreci için, öğrencilerin 9. sınıf dersleri ve 10. sınıf bölüme bağlı ve genel dersleri arasındaki bireysel ilgileşim yardımıyla çalışan basit lineer regresyon algoritması ile bir web-tabanlı karar destek sistemi (WTKDS) tasarlanmıştır. WTKDS?nin metodolojisine temel bilgi keşif dizisi aşamaları uygulanmış ve yürütülme aşaması Bahçelievler Ticaret Meslek Lisesi?nden edinilen veriler ile gerçekleştirilmiştir. Bu çalışma neticesinde, en iyi yürütme ve değerlendirme için E-Okul ve WTKDS?nin kombinasyonunun gerekli olduğu sonucuna varılmıştır.","Education Management Information Systems have been going under direct mutation in Turkey during last decade. In this manner, educational data mining becomes very essential to be discussed with the data gathered by those systems. In this study, a web-based decision support system (WBDSS) is designed with multiple linear regression algorithm for the department selection process of vocational high schools by the help of the individual correlation between 9th level courses and 10th level departmental and common courses of students. The main knowledge discovery sequences of data mining have been applied to the methodology of WBDSS and the system is implemented by the data gathered from Bahçelievler Vocational Trade High School. As a result of the research a combination between E-Okul and WBDSS is found to be remarkable for best implementation and evaluation purposes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan beyninin yarıküreleri anatomik ve işlevsel asimetriler göstermektedir. Bu asimetrilerden ortaya çıkan işleyiş ilkeleri arasındaki farkı açıklamak için birçok teori öne sürülmüştür. Bunlardan biri, sol yarıkürenin seri, sağ yarıkürenin ise paralel bilgi işlemlemesi yaptığını öne sürmektedir. Bu bağlamda ?paralel? ve ?seri? terimlerinin neye işaret ettiği muğlaktır. Mevcut çalışma, seri ve paralel işlemlemeyi farklı disiplinlerde tartışıldığı şekilleriyle tanımlamak ve bu teorik arkaplan ışığında bahsedilen teoriyi değerlendirmeyi amaçlamaktadır. Bulgular, kesin olmamakla birlikte, sol yarıkürenin seri işlemlemeye, sağ yarıkürenin ise paralel işlemlemeye yatkın olduğu yönündedir.","Human cerebral hemispheres exhibit anatomical and functional asymmetries. Various theoretical models are offered for explaining the difference between the working principles of the two hemispheres that stem from these asymmetries. One such model proposes that the left hemisphere operates in a serial manner, while the right hemisphere operates in a parallel manner, in terms of processing information. In this context, what the terms ?serial? and ?parallel? refer to is ambiguous. The present study aimed to define serial and parallel processing as it is discussed in various disciplines and assess the theory in the light of this theoretical background. The findings support the hypothesis that there is a tendency for the left hemisphere to operate in serial manner and the right hemisphere in parallel manner, yet they are not conclusive."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan eli bilgisayar sistemlerinde önemli bir iletişim aracı olmuştur. Eklemli iskelet modelleri ile giriş aygıtlarının ve hızlı bilgisayarların gelişimine kadar uğraşılamamıştır. Bu tezde derinlik algılayıcıları ile insan el pozu kestirimi için gerçek zaman ötesinde çalışan model tabanlı eklem metodları geliştirdik. Derinlik imgesinden öznitelik özütleme ve çıkarımı için Rasgele Karar Ağaçları (RDF) kullandık. RDF'leri şekil tanıma için uygulayarak başladık. Şekil tanımayı aynı derinlik resminde eklemler etrafında merkezlenmiş birden fazla şekli destekler biçimde geliştirdik. Mean shift algoritması kullanarak bu bölgelerin merkezlerindeki eklemleri kestirdik (RDF-C). Şekil tanıma ve eklem kestirimini birleştirip melez ağaçlarla kaliteyi arttırdık. RDF'ler piksel tanıma ile kullanıldığında kapatma durumlarına dayanıklı değiller. Bu problemi tanıma adımını atlayarak ve eklemleri kestirirken bağlanım kullanarak aştık. Bu metodlar gerçekçi olmayan biçimde eklemleri bağımsız olarak kabul ediyorlar. Bu yüzden tek resim tabanlı yöntemimizi modelin geometrik özelliklerini kullanarak geliştirdik (RDF-R+). 10 mm kabul eşiğinde doğruluk değerlerini sentetik ve gerçek veriler üzerinde hesapladık. RDF-C ve RDF-R+ metodlarını kıyasladığımızda doğruluk değerlerinin büyük artış gösterdiğini gözlemledik. Son olarak, tek resim temelli matodlarımızı dinamik hareketler izlemek için geliştirdik. Sentetik veriden kavrama hareketinin manifoldunu öğrendik. RDF kestirimlerimizi manifold üzerine izdüşümleyerek düzelttik ve Kalman süzgeci ile izledik.","The human hand has become an important interaction tool in computer systems. Using the articulated hand skeleton for interaction was a challenge until the development of input devices and fast computers. In this thesis, we develop model-based super real-time methods for articulated human hand pose estimation using depth sensors. We use Randomized Decision Forest (RDF) based methods for feature extraction and inference from single depth image. We start by implementing shape recognition using RDFs. We extend the shape recognition by considering a multitude of shapes in a single image representing different hand regions centered around different joints of the hand. The regions are utilized for joint position estimation by running mean shift mode finding algorithm (RDF-C). We combine shape recognition and joint estimation methods in a hybrid structure for boosting the quality. RDFs, when used for pixel classification are not resistant to self-occlusion. We overcome this by skipping the classification, and directly inferring the joint positions using regression forests. These methods assume joints are independent, which is not realistic. Therefore, we conclude our single image based framework by considering the geometry constraints of the model (RDF-R+). The accuracies at 10 mm acceptance threshold are acquired for synthetic and real datasets. Comparing RDF-C and RDF-R+ methods respectively, we report significant accuracy increase. We finally extend single image methods to tracking dynamic gestures. We learn the grasping motion from synthetic data by extracting a manifold, and fix RDF estimations by projecting them onto the manifold. We then track the projections by using a Kalman Filter."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir sayı kümesinin maksimum (ya da minimum) elemanının değerini ve/veya adresini (pozisyonunu) bulmak en temel aritmetik işlemlerden biridir. Çeşitli uygulama alanlarındaki birçok sistem, bu işlemi yerine getiren hızlı devrelere ihtiyaç duyar. Bu tezde, n tane k-bit uzunluğunda sayının en büyüğünün (benzer biçimde en küçüğünün) hem değerini hem de adresini bulan devreler için detaylı bir literatür taraması ve üç tane yeni devre topolojosi sunuyoruz. Önerdiğimiz topolojileri şu şekilde adlandırıyoruz: Array-based Topology (AbT), Hybrid Binary tree Topology (HBT) ve Quad tree Topology (QT). Önerilen topolojilerden en hızlısı (AbT) işini O(logn + logk) sürede tamamlarken, literatürdeki en hızlı topolojinin işini tamamlaması için O(logn logk) süre gerekir. Hem literatürdeki topolojiler hem de önerilen topolojiler için HDL kod üreteçleri yazdık. Bu otomatik kod üreteçleri herhangi bir n ve k değeri için ilgili topolojinin HDL kodunu üretebilecek yetenektedirler. Daha sonra ise, en iyi zaman kısıtını ikilik arama algoritmasına benzer bir yaklaşım ile bulan, yinelemeli ve standard-devre tabanlı bir sentez süreci uyguladık. Böylece, hem önerilen topolojiler hem de literatürdeki topolojiler için alan, güç tüketimi ve zaman sonuçlarını elde ettik. Ayrıca, bu sonuçları kullanarak şu birleşik başarım kıstaslarını da hesapladık: alan-zaman çarpımı (AZÇ), alan-zaman-kare çarpımı (AZ2Ç), güç-zaman çarpımı (GZÇ) ve enerji-zaman çarpımı (EZÇ). Sentez sonuçları, literatürdeki en hızlı devrenin, ortalamada AbT'den 1.61 kat, QT'den 1.28 kat ve HBT'den 1.01 kat daha yavaş olduğunu gösterdi.","Finding the value and/or address (position) of the maximum (or similarly minimum) element of a set of binary numbers is a fundamental arithmetic operation. Numerous systems, which are used in various application areas, require fast (low-latency) circuits to carry out this operation. In this thesis, we present a detailed literature survey of previous works and propose three circuit topologies that determine both value and address of the maximum (or similarly minimum) element within an n-element set of k-bit binary numbers. Our proposed topologies are Array-based Topology (AbT), Hybrid Binary tree Topology (HBT), and Quad tree Topology (QT). The timing complexity of the fastest proposed architecture (AbT) is O(logn + logk), whereas the timing complexity of the fastest topology in previous work is O(logn logk). We wrote RTL code generators for the proposed topologies as well as their competitors. These automated generators are scalable to any value of n and k. Then, we applied a standard-cell based iterative synthesis flow, which finds the optimum timing through binary search. We obtained area, power consumption, and timing results for the proposed topologies as well as their competitors. Using these results, we also compute some combined performance metrics such that area-timing product (ATP), area-timing-square product (AT2P), power-timing product (PTP), and energy-timing product (ETP). The synthesis results showed that on the average, AbT is 1.61 times, QT is 1.28 times, and HBT is 1.01 times faster than the fastest in the literature."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda dünya, insanların vakitlerinin büyük bir bölümünü duygularını, düşüncelerini, ve fikirlerini ifade ederek geçirdikleri sanal ve sosyal bir çevre haline geldi. Bu sanal sosyalleşme, bizleri değerli sanal bilgilerin toplandığı bir çağa taşıyor gibi gözüküyor. Sosyal ağ uygulamaları, özellikle mikroblog siteleri, bu bilgi birikiminde başrol oynuyorlar. Bu sitelerin özgür formatta bilgi paylaşımına olanak sağlayan karakteristik özellikleri, çok çeşitli fikirlerin hızlıca ortaya çıkmasını, etkileşmesini, ve yayılmasını sağlıyor. Bu bağlamda, fikirleri takip edilen, kabul edilen ve dikkate alınan fikir öncülerinin tespit edilmesi, pazarlama, reklam, politika gibi çok çeşitli alanlarda kritik bir öneme sahip olmaya başladı. Bu çalışmamızda, Twitter sosyal ağındaki konu tabanlı fikir öncülerinin belirlenmesine odaklandık. Daha önceden belirlenmiş konular üzerinde ilgisi olan Twitter kullanıcıları arasındaki dört farklı ilişki tipini çıkararak, düğümleri bu Twitter kullanıcıları olan sosyal ağlar oluşturduk. Bu sosyal ağlardaki her bir kenarın ağırlığını, bu ilişki tiplerini belirli kurallar ile birleştirerek hesapladık. Sonrasında ise, oluşturduğumuz bu sosyal ağlara, PageRank gibi çeşitli merkezilik metriklerini içeren sosyal ağ analizi yöntemlerini uygulayarak fikir öncülerini tespit etmeye çalıştık. Son olarak, tespit ettiğimiz fikir öncüsü adaylarını değerlendirebilmek için ise duygu analizi yöntemlerini kullandık. Topluluğun konu tabanlı genel duygu durumu ve o konulardaki fikir değişimi, bulunan fikir öncüsü adaylarının belirlenmiş konuda gerçekten öncü olup olmadığını tespit etmemizde bize yol gösterdi.","Recently, the world has become a huge virtual and social environment where people spend a great deal of time expressing their thoughts, feelings and opinions. This virtual socialization seems to bring us to a new era where valuable virtual information is being accumulated. Social networking applications, especially microblogging sites, are the leading actors of this data accumulation. Their free format characteristics lead different kinds of opinions to emerge, interact and broadcast rapidly. In this perspective, detecting opinion leaders, that is people whose opinions are followed, accepted, or taken into consideration, has become crucial in various domains such as marketing, advertisement, and politics. In this research, we focused on identifying topic-specific opinion leaders in Twitter. We extracted four different relationship types, namely retweet, mention, reply, and follow, between Twitter users who were interested in specific topics. Then we formed weighted and directed topic-based social graphs by combining these relationships to compute the edge weights. In order to detect opinion leaders, we applied social network analysis methods including PageRank, betweenness and closeness centrality metrics. We used sentiment analysis methods to evaluate the detected opinion leader candidates. The overall topic-based sentiment and opinion change of the community guided us whether the candidates are the real influencers in a predefined topic or not."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Modern işlemci teknolojisinde transistör boyutlarının gittikçe küçülmesi ve transistörlerin çok daha hızlı frekanslarda çalışması nedenleri ile, yonga bileşenlerinin geçici hata oranları artmaktadır. Geçici hatalar için sunulan çözümlerin değerlendirilmesi için bir güvenilirlik metriğine ihtiyaç duyulmaktadır. Bu tez, çok çekirdekli mimarilerde çalışan paralel uygulamaların geçici hata hassasiyetlerini incelemektedir. İlk olarak, iş parçacıklarının hata hassasiyetlerini ölçen ve paralel uygulamaların göreceli hata hassasiyetlerini belirleyen, İş Parçacığı Hasar Görebilirlik Faktörü olarak isimlendirdiğimiz bir metrik önerilmektedir. Çalışmamız kapsamında, metriğin analitik tanımı verilerek uygulama verisinden metrik değerini hesaplayacak bir yapı oluşturulmuştur. Metriğin doğrulanmasına yönelik olarak, paralel uygulamalar için hata enjeksiyon deneyleri uygulanmıştır. Bu tezde ayrıca, farklı problemlerin paralel uygulamaları için performans-hata hassasiyeti analizi yapılarak farklı tasarım seçeneklerinin sistem performansı ve güvenilirliği üzerindeki etkileri incelenmiştir. Bu iki özelliği hesaba katarak yaptığımız analizler sonucunda, birbirine yakın performans değerlerine sahip ancak farklı hata hassasiyeti gösteren iki seçenek için tercih belirgin bir şekilde ortaya çıkmaktadır. Bu tez ayrıca, çok çekirdekli sistemler için güvenilirlik tabanlı çekirdek paylaştırma stratejileri önermektedir. Çekirdek paylaştırma stratejilerimizi değerlendirmek için, çok iş parçacıklı birden fazla uygulamadan oluşan iş yükleriyle deneysel çalışmalar yapılmıştır. Bu tezde ayrıca, iş parçacığı seviyesinde hassasiyet analizi yapılarak uygulamadaki kritik iş parçacığı ve iş parçacığı bölgesi tespiti için bir kritik iş parçacığı belirleme algoritması önerilmiştir. Bu algoritma, güvenilirliği arttırmak için kullanılan kısmi çoklama yönteminde en önemli kod parçacıklarının tespitinde kullanılmış, farklı çoklama seviyeleriyle ölçülen hassasiyet değerleriyle tekniğin etkinliği gösterilmiştir.","Continuously reducing transistor sizes and aggressive low power operating modes employed by modern architectures tend to increase transient error rates. A metric of reliability is required in order to evaluate approaches that address soft errors. This thesis explores a soft error vulnerability analysis of parallel applications running on multicore architectures. We propose and evaluate a novel metric, Thread Vulnerability Factor, in order to quantify thread vulnerability and to qualify the relative vulnerability of parallel applications to soft errors. We present the analytical definition of our metric, and develop a framework to calculate the metric value by gathering application data. To demonstrate the validity of the metric, fault injection based experiments are conducted for multithreaded applications. This thesis also presents the performance-vulnerability analysis of parallel applications for a variety of applications and discusses the effects of design choices on system performance and reliability. By considering tradeoff between these two concerns, we observe that design choice becomes clear for some of the applications which provide different vulnerability values with almost equal performance. Additionally, we propose and evaluate reliability-aware core partitioning schemes for multicore architectures. A simulation study with various workloads consisting of multiple multithreaded applications is performed in order to evaluate the proposed partitioning schemes. We also present a thread-level vulnerability assessment tool by considering user preferences; and we propose a novel critical thread identification algorithm to determine critical thread and critical thread region in a multithreaded application. We utilize our algorithm to determine the thread for redundant execution in a partial fault tolerance system and demonstrate the efficiency of the method by providing vulnerability values for executions with different redundancy levels."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son ilerlemeler ışığa çıkardı ki, birbirleriyle bağlantılı karmaşık hücresel olayları içeren biyolojik patikalar düşünüldüğünden çok daha karmaşık yapılıdırlar. Bu zor durum biyolojik fenomenin ardındaki çok dallı mekanizmayı anlamayı zorlaştırmaktadır. Buna çözüm olarak biyoenformatik dünyası modülerlik kavramını biyolojik gerçekliklerin anlaşılmasını kolaylaştırmak için öne sürmektedir. Yüksek işlem hacimli veri teknolojilerinden biri olan mikrodiziler güçlü bir araç olup sistematik tarzda tek bir deneydeki genomun genel bir tasvirinin sağlanmasının yanı sıra, gen türleri ve gen kavramlarının paralel analizi için tasarlanmıştır. Öncelikli bilgi birleşiminin yanı sıra yetersiz örnek sayısı ve deneysel hatalar ile başa çıkma yeteneklerinden dolayı, olasılıklı grafik modeli olan Bayes ağları, mikrodizi verilerinden gen düzenleyici ağ oluşturmada kendisini iyi kanıtlamış bir tekniktir. Bu çalışmada BNP adı ile sunduğumuz algoritma, seçilen biyolojik patikaların ilişkilerine derinlemesine bir anlam kazandırır. Modelimizden alınan sonucu güçlendirmek ve genler arasındaki yeni etkileşimleri keşfetmek için, harici biyolojik bilgiyi dahil ederek Bayes ağları üzerinden bir gen etkileşimi atlası inşa ettik. Ayrıca FLAT adındaki, harici bilgi kullanmaksızın yapılan hesaplamalarla, kendi metodolojimizi karşılaştırdık. Tüm simulasyonların sonuçlarına göre BNP'nin FLAT'tan daha iyi performans gösterdiğini gördük.","Recent advances have enlightened that biological pathways are far more complicated than once thought, due to the inclusion of interconnected complex cellular actions, which made hard understanding the multifaceted mechanisms behind the biological phenomena. As a panacea, the bioinformatics community has brought up the modularity concept to ease the understanding of biological ground truth. A microarray is a high-throughput technology, which provides a global view of the genome in a single experiment with a systematic manner by enabling the analysis of the expression levels of a large number of genes simultaneously. Bayesian networks are probabilistic graphical models, which are well proven technique to infer gene regulatory networks from microarray data because of their ability to incorporate prior knowledge. In this study, we present an algorithm, called BNP, to infer biological pathways. Fortifying the results obtained by our model and exploring the novel interactions between genes, we construct a gene interaction atlas via Bayesian networks by incorporating external biological knowledge. Furthermore, a comparison of our methodology with the FLAT method, which does not use any external knowledge, shows that BNP outperforms it in all simulations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde ileri sürücü destek sistemleri (ADAS) ve otonom araç algoritmalarının yeni gelişen çok çekirdekli işlemci (CPU) ve grafik işleme ünitesi (GPU) mimarileri üzerine verimli olarak uyarlanması ve gerçek zamanlı performans gereksinimlerinin karşılanması hedeflenmektedir. GPS, odometre ve sayısal haritaların tümleştirildiği bir paralel parçacık filtresi tabanlı konumlandırma ve harita eşleme algoritması ile Kinect kamera ve sayısal harita tümleştirmesinin kullanıldığı bir paralel şablon eşleme tabanlı trafik işareti tanıma algoritması önerilmektedir. Algoritmalar, OpenMP programlama modeli kullanılarak çok çekirdekli işlemciler üzerinde ve CUDA programlama modeli kullanılarak grafik işleme üniteleri üzerinde gerçeklenmiştir. Sensörler ile donatılmış bir test aracı ile değişik yol ve hava şartlarında gerçek veri toplanmış ve algoritmaların performans testleri her biri altı çekirdekli iki işlemcisi ve her biri 512 çekirdekli iki grafik işleme ünitesi bulunan bir sistem üzerinde gerçekleştirilmiştir. Çalışma zamanları ve paralel işleme hızlanmaları incelenmiştir. Parçacık sayıları\-nın konumlandırma algoritmasının başarım oranı üzerindeki etkisi gözlemlenmiştir. Test sonuçları, grafik işleme üniteleri üzerinde sıralı sistemlerdeki gerçeklenmelerine oranla, parçacık filtresi tabanlı konumlandırma ve harita eşleme algoritması için 75 kata varan, trafik işareti tanıma algoritması için ise 35 kata varan hızlanmalar elde edilebildiğini ve algoritmaların araç ortamında gerçek zamanlı olarak kullanılabileceğini göstermektedir. Genel amaçlı çok çekirdekli işlemci ve grafik işleme ünitesi mimarilerinin, her bir uygulama için kullanılan özel donanım ve yazılım platformlarının yerine, ileri sürücü destek sistemi algoritmalarının paralel olarak gerçeklenebileceği ve gerçek zamanlı olarak çalıştırı\-labileceği birleşik bir araç işlemci platformu oluşturabileceği sonucuna varılmaktadır.","This thesis aims to address the real-time performance requirements of ADAS(Advanced Driver Assistance System) and autonomous vehicle applications on emerging multicore CPU and manycore GPU architectures. A parallel particle filter basedvehicle localization and map matching algorithm which fuses GPS, odometer and digital maps, and a parallel template-matching based traffic sign recognition algorithm which employes a Kinect sensor and digital map fusion are proposed. Implementations were performed on multicore CPUs using OpenMP programming model and on manycore GPUs using CUDA programming model. Real data were collected via a vehicle equipped with sensors for various road and weather conditions and performance tests were conducted on a parallel system having two six-core CPUs and two 512-cores GPUs. The execution times and speedup of parallel processing is examined. The effect of number of particles on the success rate of the localization algorithm is also observed. Test results show that up to 75 times speedups for particle filter based localization and mapmatching algorithm and up to 35 times speedups for the traffic sign recognition algorithm can be achieved on GPUs compared to implementations on sequential systems, and evidently the algorithms can be used with real-time performance in the vehicle environment. It is concluded that the emerging general purpose multicore/manycore processors can constitute a unified vehicle computing platform where ADAS applications can be implemented in parallel and run with real-time performances by replacing specialized hardware and/or software platforms used for each application."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde stereoskopik 3B (üc boyutlu) videolar izlenirken ortaya çıkabilen derinlik kaynaklı rahatsızlıkların öngörülmesi üzerine yapılan bir çalışma belgelenmektedir. Ticari amaçlı 3B videolarda ortaya çıkabilen aşırı derinlik seviyeleri izleyicileri rahatsız edebilir ve bundan dolayı da kullanıcının video izleme deneyiminin kalitesi düşer. Bu nedenle görsel kalitesi yüksek 3B videolar elde edilebilmesi açısından, videolardaki aşırı derinlik seviyelerinin tesbiti önemlidir. Bu çalışmada aşırı derinlik seviyelerinden kaynaklanan derinlik rahatsızlıklarının tesbiti için bir plan ortaya konulmaktadır. Aşırı derinlik, stereo imge çiftleri arasında yüksek ayrıklık seviyelerine işaret etmektedir. Bu nedenle, derinlik rahatsızlıklarının tesbiti için en yüksek ayrıklık seviyelerini tesbit ve takip eden algoritmalar denenmiştir. En yüksek ayrıklıklar, sadece ayrıtlar üzerindeki ayrıklıkları içeren, seyrek ayrıklık haritalarından elde edilirler. Seyrek ayrıklık haritalarını elde etmek için beş farklı blok eşleme yöntemi denenmiştir: Mutlak Farkların Toplamı (SAD), Herman Weyl?in Uyuşmazlık Ölçütü (HWDM), Uyarlanabilir Destek Pencereleri (ASW), Ölçekten Bağımsız Öznitelik Dönüşümlerinin Mutlak Farklarının Toplamı (SADSIFT) ve Gradyant Yönelimlerinin Korrelasyonu (CGO). Bu beş yöntem en yüksek ayrıklıkların kestirimindeki başarımlarına göre karşılıklı olarak incelenmişlerdir. Ayrıca izleyici rahatsızlığı ile ilgili verilerin toplanması ve en yüksek ayrıklık istatistiklerinin kullanıcı deneyimini ön görmede kullanılması ile öznel testler de yapılmıştır. Sonuçlarımızı incelediğimizde CGO yönteminin en yüksek ayrıklıkların kestiriminde daha başarılı olduğu gözlenmiştir. Ayrıca CGO ile elde edilen en yüksek ayrıklık istatistiklerinin derinlik rahatsızlığından şikayatçi olabilecek izleyici sayısının ön görülmesinde kullanılabilecekleri gösterilmiştir.","This thesis documents a work in which prediction of depth related discomfort levels, while watching stereoscopic 3D videos is studied. In commercial 3D videos, excessive depth levels can cause discomfort to the viewer and hence decreases the users quality experience of the video. Therefore detecting excessive levels of depth is important to maintain a better visual quality in 3D videos. In this work a scheme is presented for detection of depth discomforts, resulting from excessive depth levels. An exaggerated depth corresponds to high disparity levels between stereo image pairs. In order to detect depth discomforts, we developed and tested algorithms to detect and track maximum disparities. The maximum disparities are extracted from sparse disparity maps, where the disparities are obtained for only certain edge locations. The sparse disparity maps are obtained using five varieties of block matching, which are: Sum of Absolute Differences (SAD), Herman Weyl?s Discrepancy Measure (HWDM), Adaptive Support Windows (ASW), Sum of Absolute Differences of Scale Invariant Feature Transforms (SADSIFT) and Correlation of Gradient Orientations (CGO). A comparative study of these five methods is performed in terms of their performances in estimation of maximum disparities. Also subjective tests are run by collecting viewer discomfort data and using maximum disparity statistics as a predictor of user experience. By examining our results, we observed CGO performs better in maximum disparity estimation. Also it is shown, that the maximum disparity statistics obtained through CGO can be used to predict the number of viewers, which experience depth discomforts."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Artan enerji fiyatları ile enerji üretim ve tüketiminin çevresel sonuçları, kablosuz ağların enerji verimliliğini daha önce görülmemiş şekilde önemli hale getirmiştir. Buna ek olarak, yeni servislerin ve gelişmiş kablosuz cihazların yaygınlık kazanmasıyla kablosuz ağlarn gereksinimleri ve kapasite beklentileri durmaksızın artış göstermektedir. Bu tezde bilişsel ve heterojen kablosuz ağ paradigmaları, yukarıda bahsedilen olgulardan dolayı önemli bir hale gelen enerji verimliliği perspektifinden incelenmektedir. ""Yeşil ağlar"" hedefini hayata geçirebilmek için özellikle enerji verimliliği analizi ve bu ağların modellenmesi konusuna odaklanılmaktadr. İlk olarak kablosuz ağlarda enerji verimliliği konusunu kapsamlı bir şekilde ele alıyoruz. Kesitsel düzeyde, kablosuz veri iletişimini tüm yönleriyle etkileyen bilişsel radyo (CR) paradigmasını inceliyoruz. Bilişsel radyo kavramını ""enerji-verimli operasyon"" ve ""enerji verimliliğini sağlayıcı"" perspektiflerinden değerlendiriyoruz. Mikroskopik düzeyde ise küçük hücrelere yani femto-hücrelere odaklanıyor ve bilişsel femto-hücre ağları (CFN) adı verilen yeni bir ağ paradigması öneriyoruz. Bu ağı analitik modelimiz aracılığıyla enerji verimliliği perspektifinden değerlendirerek başarımını geleneksel femto-hücre ağları ve sadece makrohücrelerden oluşan bir ağ ile karşılaştırıyoruz.","The surging energy costs and the environmental consequences of energy generation and exploitation have put energy efficiency aspect of wireless systems into focus in an unprecedented manner. Moreover, the capacity expectations and requirements for wireless networks have been relentlessly increasing with the adoption of new services and sophisticated wireless terminals. In this thesis, we evaluate cognitive and heterogeneous wireless network paradigms from energy efficiency perspective that has become vital due to the above mentioned phenomena. We specifically focus on energy efficiency analysis and modeling of these systems for realizing the ""green networks"" objective. We first provide a comprehensive account of energy efficiency of wireless networks. At a cross-sectional level, we consider cognitive radios (CR) paradigm which is affecting all facets of wireless data communications. The CR concept is evaluated from the ""energy-efficient operation"" and ""energy efficiency enabler"" perspectives. At the microscopic level, we focus on small cells, namely femtocells, and propose a new networking paradigm called cognitive femtocell networks (CFN). We analyze them in terms of energy efficiency via our analytical model and compare their performance with that of macrocell-only networks as well as traditional femtocell networks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Uygulamaya özgü kriterleri karşılayan karmaşık tasarımların gerekliliği ve pazara giriş baskısı, Yüksek Seviyeden Üretim (YSÜ) araçlarına olan ihtiyacı arttırmaktadır. YSÜ araçları istenilen işlevin yüksek seviyede davranış tanımını girdi olarak alıp, donanımın Yazmaç Almacı Seviyesinde (YAS) Donanım Tanımlama Dili(DTD) tanımları- nı çıktı olarak verir. YSÜ araçları, Alanda Programlamalı Kapı Dizilerini (APKD) veya Uygulamaya Özgü Tümdevreleri (UÖT) hedeflemektedir. APKD'ler, mimari esnekliği, alanda güncellenmeye uygunluğu ve hesaplama güçlerinden dolayı UÖT ve mikroişlemcilerden daha çok ilgi görmektedir. Bu tez çalışmasında, APKD'ler için YSÜ aracı önerilmektedir. Bu aracın yetenekleri şu şekildedir: (i) Veriyolu ve kontrol birimini içinde barındıran eniyilenmiş YAS üretimi. Bunu yapabilmek için, araç eniyileme sonuçlarını ve aritmetik işleçlerin gecikme modellerini kullanarak saat periyodu süresi çıkarılmaktadır. (ii) Veriyolu üzerinde kaynak paylaşımı ve eniyileme yapılmamış Altın YAS üretimi (iii) Üretilen YAS tanımlamalarının, kestirim modelleri kullanılarak, gecikme ve alan kestirimi. Geliştirilen araç RH(+) Tasarım Otomasyonu çerçevesine eklenmiştir. Üretilen YAS'lar Xilinx Spartan-3 APKD'leri kullanılarak test edilmiştir. Araç tarafından üretilen YAS'ların gecikme ve alan kestirimleri, farklı girdiler için Xilinx ISE aracının kestirim sonuçlarıyla karşılaştırılmıştır.","The need for complex designs that meet the desired application specific criteria and time-to-market pressure increase the importance of High Level Synthesis (HLS) tools, which take high level behavioral representation of the desired functionality as the input and generate HDL description of hardware at RTL level for FPGA or ASIC targets. FPGAs are getting more popular than ASICs and microprocessors due to their architectural flexibility, on-site upgradability and computing power. In this thesis, an HLS tool for FPGAs is proposed. This tool has the following capabilities: (i) generation of optimized RTL which consists of datapath and its controller. To achieve this, the tool extracts the clock period of the optimized RTL by using the optimization results and the delay models of the arithmetic operators. (ii) generation of Golden RTL where there is no optimization and resource sharing on the datapath. (iii) estimation of delay and area of the generated RTL specifications by using the estimation models. This tool is integrated in RH(+) Design Automation Framework. The generated RTLs are tested in Xilinx Spartan-3 FPGA. The estimated delay and area of both the Golden RTL and Optimized RTL generated by the tool are compared with the results of Xilinx ISE tool set for different input applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mikroblog sistemlerinin kullanıcı sayıları gün geçtikce artmaktadır. Bu sistemlerde kullanıcılar düşüncelerini anlık olarak paylaşabilir. Tezde sosyal medya tabanlı acil durum tespit ve mobil bildirim üzerine çalışılmıştır. Amacımız herhangi bir olay yaşandıktan hemen sonra yada olay yaşanmadan önce o bölgede bulunan insanlara olayın varlığı konusunda bir bildirim yapabilmektir. Çalışmamızda gözetimli öğrenme metodları yardımıyla, mikroblog sisteminden acil durumu tasfir eden bilgi çıkartıyoruz. Topladığımız mesajlardan olayın konumunu tahmin ediyoruz. Tespit ettiğimiz olayın çevresinde bulunan kişilere, geliştirdiğimiz mobil uygulama ile bildirim gönderiyoruz. İnsanlar acil durumlarda yaşadıkları olayları mikroblog sistemlerde paylaşıyorlarmı, farklı türdeki olaylar (örn: yangın, deprem) mikroblog sistemlerde kullanıcılar tarafından nasıl paylaşılır bu sorulara cevap bulmaya çalışıyoruz. Olay her ne olursa olsun konum bilgisinin tespit edilmesi kritik öneme sahipir. Çalışmada görüyoruz ki acil durumlarda insanlar paylaştıkları mesajın içinde olayın yaşandığı konumuda paylaşmaktadırlar. Kişinin profilinde belirttiği konum bilgisi farklı bir bölgeyi işaret etsede, eğer kişi paylaşım yaptığı mesajın içinde konum belirtmişse aslında olayın tam olarak yaşandığı yada olaya yakın bir bölgeyi paylaştığını görüyoruz. Mikroblog sistemlerden olay ile alakalı mesajları toplayan, olayın nerede yaşandıgını tahmin eden ve olayın çevresinde bulunan kişilere bildirim yapacak bir model öneriyoruz. Önerdiğimiz modelin formal yapısını ve prototip uygulaması ortaya koyuyoruz. Çalışmamızı mikroblog sistemlerden deprem ve yangın olaylarını; zaman, konum bazında tespit etme başarısı ile değerlendiriyoruz. Sistemimizin çalıştığı zamanları güvenilir kaynaklarla karşılaştırdığımızda 246 depremden 25 tanesini, 85 yangından ise 42 tanesi hakkında bildirim yaptığını görüyoruz. Bu testin sonucuyla modelimizin gelişim alanlarını değerlendiriyoruz.","There is rapid increase in the number of microbloggers everyday. Users can share their thoughts instantaneously. In this thesis, we have studied on identification of emergency related contributions in social media and mobile emergency notification. Our goal is to notify interested people immediately or beforehand about possible existence of an emergency situation. We are extracting emergency related information from microblogging systems with the help of supervised learning methods. Afterwards, we estimate the location of the incident from the messages we have collected from microblogging systems. Once we identify an incident occurrence, we send a notification to people nearby the incident via mobile application. We try to answer if contributors share emergency related information on microblogging systems and if so, how contributors express different types of incidents (ex: fire, earthquake) in microblogging systems. Whatever the incident type, location information is critical to determine. Our study exposes that, in case of emergency situations contributors share location information in post. In case contributor specifies an incorrect location in profile, we have found that in post location indicator points to the location incident occurred. We propose a model that fetches incident related posts from microblogging system, estimates incident location and notifies people nearby incident occurrence. We describe formal structure of our model and prototype developed. We evaluate our system by the accuracy of location, time estimation for incident detection about fire and earthquake incidents. Once we compare detections of our system with trustworthy sources, out of 246 earthquake incidents 25, out of 85 fire incidents 42 of them generated notifications. As a result of evaluation, we assess future improvements of our system."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İdrar tahlili, böbrek ve idrar yolu hastalıklarında sıklıklı kullanılan kayda değer bir teşhis tekniği ve fiziksel muayenenin temel bir ögesidir. İdrar tahlilinde büyük ölçüde kullanılan idrar stripleri, birbirlerinden dar şeritlerle ayrılmış birçok renkli reaktif bloklardan ya da pedlerden oluşmktadır. Her bloktaki reaktif madde idrarda belli içeriklerle reaksiyona girer ve eğer o içerik idrarda var ise blok renk değiştirir, oluşan renk değişimi, test edilen maddenin idrardaki konsantrasyonuyla doğru orantılıdır. Test stripleri günümüzde ilgili test stripine ait refraktometrik cihazla analiz edilir. Bu tezde, Parallax'ın TCS3200-DB renk sensörü kullanılarak hem MATLAB'in hem de Android işletim sisteminin GUI'si vasıtasıyla kontrol edilebilen BUSA isimli mobil bir idrar strip okuyucusu tasarlanmıştır. Bu dizaynın arkasında temel fikir, CombiScan 500'ün kontrol solüsyonlarının, Yeditepe Üniversitesi Hastanesi'nde CombiSCan 500 tarafından analiz edilen 40 hastanın ve pH ve glikoz miktarları bilinen hazırlanmış solüsyonları renk verileri içeren bir veritabanı oluşturmaktır. CombiScan 500 tarafından analiz edilen 15 hasta BUSA ile karşılaştırılmıştır. Karşılaştırmanın kesinliği bilirubin, ürobilinojen, glikoz, protein, kan, nitrit ve lökosit için 1 ve keton için 0.933'tür. Karşılaştırmanın duyarlılığı glikoz, protein ve kan için sırasıyla 1, 0.2 ve 1'dir. pH ve dansite (özgül ağırlık) fark ortalama ve standard sapma sonuçları sırasıyla 0.133, 0.5156 ve 0.0017, 0.0059 olan Bland Altman metotu ile analiz edilmiştir. Sonuç olarak, BUSA idrarın pH'ını ve dansitesini ve bilirubin, ürobilinojen, keton, glikoz, protein, kan, nitrit ve lökositin negatifliğini ölçmede başarılıdır. Ayrıca, BUSA protein dışında glikoz ve kanın pozitifliğini ölçmede de başarılıdır.","Urinalysis is a remarkable diagnostic technique and an essential part of physical examination used frequently in kidney and urinary tract diseases. Urine reagent strips which are widely used in urinalysis are impregnated with a number of colored reagent blocks or pads separated from each other by narrow bands. The reagents in each block react with specific components of urine in such a way that the block changes color if the component is present, and the color change produced is proportional to the concentration of the component being tested for. Recent analysis of test strips is perfomed via refractometric devices of the corresponding test strips. In this thesis, a mobile urine strip analyzer called BUSA which can be controlled via both GUIs of MATLAB and Android operation system was designed by using Parallax's color sensor, TCS3200-DB. The fundemental idea behind this design was to form a database which included color data of control solutions of CombiScan 500, 40 patients analyzed by CombiScan 500 in Yeditepe University Hospital and prepared solutions of known pH and glucose amount. 15 patients analyzed by CombiScan 500 were compared to BUSA. Specificity of the results of the comparison for bilirubin, urobilinogen, glucose, protein, blood, nitrite and leukocyte was 1 and for ketone was 0.933. Sensitivty of the results of the comparison for glucose, protein and blood was 1, 0.2 and 1 respectively. pH and specific gravity were analyzed via Blant Altman method which means and standard deviations were 0.133, 0.5156 and 0.0017, 0.0059 respectively. In conclusion, BUSA is succesful at measuring pH and specific gravity of urine and negativeness of bilirubin, urobilinogen, ketone, glucose, protein, blood, nitrite and leukocytes. In addition, BUSA is successful at detecting positiveness of glucose and blood, except protein."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Eylem Tanıma konusu yaşam kalitesi ve insan sağlığı ile ilgili doğrudan uygulamaları olan ve günümüzde aktif olarak çalışılan bir araştırma alanıdır. Bu konudaki çalışmalar insanların gün boyunca gerçekleştirdikleri eylemleri farklı türlerde algılayıcılar kullanarak yüksek doğruluk oranıyla sınıflandırabilmeyi amaçlamaktadır. Günlük yaşantımızın vazgeçilmez parçalarından biri haline gelen akıllı telefonlar, insanların eylem tanıma teknolojilerinden ilave bir alet kullanma ya da taşıma zorunluluğu olmaksızın faydalanmalarını sağlayabilecek cihazlardır. Fakat bu cihazların güç ve hesaplama açılarından kısıtlı kaynaklara sahip olması, bu cihazlar üzerinde güç-yoğun ve işlemci-yoğun sınıflandırma yöntemleri ile yüksek doğruluk oranları elde etmeyi zorlaş- tırmaktadır. Bu çalışma hafif bir sınıflandırma algoritması (KNN) ile beş farklı günlük eylemin yüksek doğruluk oranı ile tanınabilmesini sağlayacak bir etkin öznitelik seçimi sunmayı amaçlamaktadır. Bu doğrultuda, bazı özgün öznitelik tipleri ile yaygın olarak kullanılan diğer bazı öznitelik tipleri bir arada kullanılmıştır. Ayrıca, sistemi ener- ji verimli kılmak adına tüm bu öznitelikler yalnızca pantolon cebinde taşınan bir akıllı telefondaki yerleşik ivmeölçerden alınan verilerden çıkarılmıştır. Bu çalışmada ayrıca öznitelik çıkarımından önce algılayıcıdan edinilen veriyi pencerelemek için kullanılan farklı pencere uzunlukları ve pencere işlevlerinin etkisi de değerlendirilmiştir. Elde edilen sonuçlar gösteriyor ki etkin öznitelik seçimi, KNN gibi gerçek-zamanlı ve çevrimiçi sınıflandırmaya uygun, basit bir sınıflandırma algoritması ile umut veren doğruluk oranlarına ulaşmayı mümkün kılmaktadır.","Activity Recognition (AR) is an active area of research that has direct applications on life quality and health of human beings. Related studies aim to classify different daily activities of people with high accuracy rates using various types of sensors. Becoming an essential part in our daily lives, smartphones are now suitable tools that enable people to make use of AR technologies without being obliged to use or wear some extra device. However, due to power and computational constraints of these devices, it becomes a challenging task to attain accurate results by using power and CPU-intensive classifiers. In this study, we present an efficient selection of features to attain high accuracies in recognizing five daily activities with a lightweight classifier, K Nearest Neighbors (KNN). Since previous studies in this area show that it is possible to obtain high recognition performance with the KNN classification algorithm, we focused on the problem of feature selection to see how far this performance can be enhanced by employing the most appropriate feature sets for the KNN algorithm. We use some well-known features together with some more specific features and in order to keep the system energy-efficient, all features are extracted from the readings of a single accelerometer on a smartphone that is carried in the trousers' pocket with different orientations. In this study, we also evaluated the effect of different window lengths and window functions that are used for segmenting the data prior to feature extraction. The results show that by having an efficient selection of features it is possible to obtain promising accuracy rates with a simple classification algorithm like KNN which facilitates online and real-time activity recognition on smartphones."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çoketmenli sistemler insan müdahalesi olmadan yorumlama, muhakeme etme ve karar almayı içeren hesaplama problemlerinin çözümü için yeni teknikler sunmaktadır. Etmen iletişimi her çoketmenli sistemin temel bir bileşenidir. Etmen iletişiminde eşgüdümün sağlanabilmesi için bir düzenleme mekanizmasına ihtiyaç duyulur. Taahhüt protokolleri bu amaç için etkin bir mekanizma sağlar. Tipik olarak bu tür protokoller tasarım aşamasında tanımlanarak etmenlerin uygulamaları içine gömülürler. Ancak önceden tanımlı taahhüt protokolleri etmenlerin çeşitliliği, etmen tercihlerindeki değişiklikler ve ortam değişiklikleri nedeniyle büyük ölçekli ve açık çoketmenli sistemler için uygun değildirler. Buna bağlı olarak, bu tezde etmenlerin önceden tanımlı taahhüt protokollerine bel bağlamamaları gerektiğini ve ihtiyaç duyduklarında çoketmenli sistemin mevcut durumunu göz önüne alarak kendi taahhüt protokollerini oluşturabilir olmaları gerektiğini öne sürüyoruz. Buna ulaşmak için üç aşamalı bir etmen süreci öneriyoruz. İlk aşamada, etmen, hedeflerini, yeteneklerini ve diğer etmenlerin hizmetlerini temel alarak taahhüt protokolleri üretir. Bu amaçla, taahhüt protokollerini verimli olarak üreten iki algoritma önerilmiştir. İkinci aşamada, üretilen protokoller etmeninin bakış açısından sıralanır. Bu amaçla, taahhüt protokollerinin maliyetlerini, sağladıkları menfaati ve güvenilirliklerini kullanan ölçütler tanımlanmıştır. Son olarak, üçüncü aşamada etmen diğer etmenlerle pazarlık ederek yapılabilir protokollerden biri üzerinde anlaşmaya varmaya çalışır. Bunun için protokollerin yapılabilirliğini biçimsel olarak tanımlanmış ve protokollerin gerçekleştirilebilir olduğunun denetimi için kısıt sağlama tekniği tabanlı bir algoritma sunulmuştur. Bu üç aşamalı süreç taahhüt protokollerinin ihtiyaç duyulduğunda oluşturulması ve yürürlüğe konması için bir yöntem sunmaktadır.","Multiagent systems offer novel techniques to solve computational challenges that involve data interpretation, reasoning and decision making, without human intervention. An important aspect of every multiagent system is interaction among agents, which requires agents to employ regulation mechanisms to coordinate their actions. Commitment protocols provide an effective mechanism for this purpose. Typically, these protocols are defined at design time and embedded into agents' implementation. However, predefined commitment protocols are not adequate for large-scale, open multiagent systems, because of the variety of agents, changes in the agent preferences and changes in the environment. Accordingly, in this thesis we argue that agents should not rely on preexisting commitment protocols and they should be able to generate their own commitment protocols when needed, taking the current context of the multiagent system into account. In order to achieve that, we propose a three-phase agent process. In the first phase an agent generates a set of commitment protocols based on its goals, capabilities and other agents' services. For this purpose we propose two sound and complete algorithms that can efficiently generate commitment protocols. In the second phase, the generated commitment protocols are ranked from the generating agent's perspective. To achieve this we formulate a set of metrics that use cost, benefit and trustworthiness of commitment protocols to rank them. Finally, in the third-phase the agent negotiates with other agents over selected feasible commitment protocols to reach an agreement on a protocol for enactment. In this context we formalize commitment feasibility and provide an algorithm based on constraint satisfaction techniques to check if a set of commitments can be carried out. This three-phase process provides a complete method for agents to generate and enact commitment protocols on demand."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Paralel tetrahedral grid üreticisi mevcut sıralı NETGEN grid üreticisi kullanılarak geliştirilmiştir. Geliştirdiğimiz grid oluşturma algoritmaları bir ana düğüm üzerinde geometriyi veya hacimsel gridi alt geometrilere ve alt-gridlere ayrıştırıyor ve sonrasında birden çok işlemci üzerinde paralel olarak her alt-geometri veya alt-grid üzerinde daha ayrıntılı hacimsel grid üretimi gerçekleştiriyor. Temel olarak üç yöntem uygulanmaktadır. Birinci yöntemde geometri parçalanır ve yüzeysel alt-gridler üretilir. Daha sonra bu alt-gridlerden ayrıntılı hacimsel grid paralel olarak üretilir. Grid inceltme bazlı yöntemlerimizde (Metod 2. ve 3. yöntemlerinde) ayrıca CAD geometri bilgileri kullanır. ""sahip günceller"" kuralı kullanan grid göç algoritması da uygulanmıştır. Sonuçlar, inceltme tabanlı yöntemler kullanarak, bir dakika altında bir milyardan fazla elemandan oluşan bir gridin elde edilebileceğini göstermektedir. Geliştirilen yazılım ücretsiz açık kaynaklı kod olarak http://code.google.com/p/parallel-netgen/ adresinden temin edilebilir.","A parallel tetrahedral mesh generator is developed using the existing sequential NETGEN mesh generator. Mesh generation algorithms developed decompose the geometry or volume mesh into multiple sub-geometries or sub-meshes sequentially on a master node and then create fine volume meshes from those sub-geometries and submeshes in parallel on multiple processors. Three methods are implemented. The first decomposes the geometry and produces conforming surface sub-meshes from which volume meshes can be generated in parallel. The second and third methods which are refinement based also make use of the CAD geometry information. A scalable mesh migration algorithm that utilizes ""owner updates"" rule is implemented. Results show that using refinement based methods; a mesh with over a billion volume elements can be generated in under a minute. Our developed software is also distributed freely as open source code at the address http://code.google.com/p/parallel-netgen/."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Belirli bir konuda makaleleri önem sırasına göre sıralamak zordur. Tam metni tarama üzerine kurulu olan bilgi çıkarım teknikleri makalelerin ana konularını tespit etmekte çok başarılı değillerdir. Ayrıca bu bilgi çıkarım teknikleri makalenin önemi konusunda bir çıkarımda bulunamazlar. Bir atıf ağı oluşturmak, en çok önemli olan makaleleri bulmak için iyi bir yöntem olabilir, ancak bu yöntem de makalelerin konusu ile bir ilişki kuramamaktadır. Bir atıf işaretçiğinin çevresindeki metin genellikle atıfta bulunulan makalenin iyi bir özetidir. Bu nedenle, atıf metni analizi konu bazında makaleleri önem sırasına göre sıralamak için araştırmacıların konu üzerindeki genel kanısını kullanmak için bir fırsat sunar. Bu çalışmada verilen bir konu içindeki makaleleri önem sırasına göre sıralamak için atıf metinlerini analiz ediyoruz. Burada sunduğumuz model, hedef konu üzerine kurulu olan yönlü ve ağırlıklı bir atıf ağı kurmak amacıyla atıf metinlerini kullanıyor. Eğer atıf metni hedef konu için oluşturduğumuz terimler grubundan herhangi bir terimi kapsarsa, bu iki makale arasında atıf verenden atıf alana doğru yönlü ve ağırlıklı bir çizgi oluşturuyoruz. Bundan sonra bu ağın çizgeleri sıralamak için genel olarak kullanılan ağ üzerindeki çizge sıralama algoritmalarını kullanıyoruz. Deneylerimizin sonucunda, bu metodun verilen bir konuda en önemli makaleleri üst sıralarda sıraladığını gösterdik. Önerdiğimiz yaklaşımın en büyük katkısı ise verilen bir terim için ilgili makaleler bu terimi içermese dahi sistemimizin bu makaleleri de sırayabilmesidir.","It is hard to detect important articles in a specific context. Information retrieval techniques based on full text search can be inaccurate to identify main topics and they are not able to provide an indication about the importance of the article. Generating a citation network is a good way to find most popular articles but this approach is not context aware. The text around a citation mark is generally a good summary of referred article. So citation context analysis presents an opportunity to use the wisdom of crowd for detecting important articles in a context sensitive way. In this work, we analyze citation contexts to rank articles properly for a given topic. The model proposed here uses citation contexts in order to create a directed and weighted citation network based on the target topic. We create a directed and weighted edge between two articles if citation context contains terms from the term set we created for the target topic. Then we apply common ranking algorithms for the vertices of network. We showed that this method successfully detects the most prominent articles in a given topic. The biggest contribution of this approach is that we are able to identify important articles in the target topic even though they don't contain the term represents the interested context."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım sürekli evrim içindedir ve birçok yaklaşım yazılım bakım verimliliğini incelemek için öne sürülmüştür. Bu yüksek lisans tezinde küçük fonksiyonel geliştirmeler için bir verimlilik ölçüm modeli tasarlamak ve uygulamak için gerekli sürecin tanımlanması amaçlanmıştır. İki motivasyon bu araştırmayı etkilemektedir: 1.) Bakım maliyetini yönetmeye yardımcı olmak için yazılım bakım sürecinin verimliliğini anlamak, 2.) yazılım bakım verimliliğini etkileyen maliyet sürücüleri anlamak. Bu araştırmanın bir başka amacı, geliştirme modeli olarak küçük geliştimeler için verimlilik modeli oluşturmanın mümkün olup olmadığının sorusuna yanıt bulmaktır. İlk olay çalışması, bir banka organizasyonunda çalışan büyük bir teknoloji grubundan geliyor. Bu çalışma metodolojinin uygulamaya uygulanabilirliğini gösteriyor. Bu yaklaşımda, düşük seviyedeki tanecikliği yakalayabilen COSMIC ölçüm yöntemi kullanılarak , küçük geliştirmelerin ölçümlenebildiği gösterilmiştir. Ayrıca, her küçük geliştirme için dökümantasyon kalitesi incelenmiştir. Küçük geliştirmeleri ölçümleyebilmek için yeterli bilgi yer aldığı için dökümantasyon kalitesi yüksektir. Tam olarak 88 küçük geliştirme incelendi ve ayrı ayrı ölçüldü. Herbir küçük geliştirmenin ölçüm boyutu COSMIC ISO 19761 uluslararası standardına dayanmaktadır. Tüm bağımsız değişkenler kullanılarak bu veri kümesi ile bir verimlilik modeli üretmek mümkün olmuştur (R-square değeri 0,75). Kullanılan metodoloji deneyselliğin iyi kontrol edildiğini gösteriyor: Büyük bir uygulama bir gelişim içinde belli bir zaman diliminde aynı kişi tarafından tasarlanmış, programlanmış ve geliştirilmiş, bakım yapan kişi tarafından dökümante edilmş, bir denetim ortamında ölçülmüş ve bir uzman tarafında doğrulanmıştır.","Software is in constant evolution and many approaches have been suggested to study software maintenance productivity. This master thesis aims to describe the process to design and implement a productivity measurement model for small functional enhancements to legacy software. Two motivations influence this research: 1) understanding the productivity of the software maintenance process to help manage the cost of maintenance, 2) understanding the cost drivers that affect the software maintenance productivity. Another purpose of this research is to determine whether it is possible to construct productivity model(s) for small enhancements that is as good as development model. The case study, to show the feasibility of the application of the methodology, is coming from a large technology group that works for a bank organization. In this approach, it is showed that small enhancements can be measured by using the COSMIC measurement method that has the possibility to capture a lower level of granularity. Also, the quality of documentation for each small enhancement was studied. Because the person who has done the maintenance was at hand for this exercise, it was possible to complete the documentation. Therefore the quality of the documentation is high. Totally, 88 small enhancements are investigated and measured separately. The measurement of the functional size of each individual enhancement was based on the COSMIC ISO 19761 international standard. It was possible to produce a sound productivity model with this sample using all independent variables (R square of 0,75). The methodology used is showing that the experimentation was well controlled: within an enterprise for one major application for a period of time, design, program and implement by the same person, documented from the maintainer, measure within a control environment and verify by an expert."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sensor teknolojisindeki gelişmeler sayesinde, üç¸ boyutlu (3B) yüz tanıma sıklıkla kullanılan bir biyometrik kip haline gelmiştir ve özellikle güvenlik uygulamalarında tercih edilmektedir. Ama yüz yüzeyini kapatan örtme durumları, çözülmesi gereken zor bir sorun olmaktadır. Bu tezde, üç farklı problemi ele alarak tamamen otomatik bir 3B yüz tanıma sistemi önermekteyiz: (i) Örtmeli yüzeylerin kayıtlanması, (ii) örtmeli bölgelerin belirlenmesi, ve (iii) örtmelerin çıkarıldığı boşluklu yüzeylerden öznitelik çıkarılması ve tanıma işleminin gerçekleştirilmesi. Kayıtlama için, adaptif olarak model seçimine dayalı bir yöntem önermekteyiz. Bu yöntemde, örtmesiz yüzeye uygun şekilde model seçilerek, nokta eşleştirmede yalnızca örtmesiz yüz parçalarının kullanılması sağlanmaktadır. Kayıtlama sonrası, örtmeli yüzeyleri bulmak için iki farklı örtme kestirim yöntemi önermekteyiz: İlk yöntemde, piksel bazlı istatistiksel yöntemler kullanılmakta ve herbir pikselin karşılık gelen modele uyumu test edilmektedir. İkinci yöntemde ise, komşuluk ilişkileri de kestirim aşamasına dahil edilmektedir. Örtme durumlarının üstesinden gelmek için iki farklı yaklaşım değerlendirilmektedir: (i) Örtmelerin yüzeydençıkarılması, (ii) Eksik bölgelerin geri çatma ile doldurulması. Öznitelik çıkarımı ve sınıflandırma aşamasında ise, bir maskeleme stratejisi önermekteyiz. Maskeli projeksiyon adını verdiğimiz bu yöntem sayesinde, alt-uzay yöntemleri boşluklu veri ile kullanılabilir hale gelmektedir. Gerçekçi örtmeli kayıtlar içeren iki farklı 3B yüz veri kütüphanesi (Bosphorus ve UMB-DB) ile elde edilen deneysel sonuçlar sayesinde şu çıkarımlar yapılabilir: (i) Önerilen kayıtlama tekniği örtmeli durumlar için iyi bir alternatif olmaktadır; (ii) Örtme kestiriminde, istatistiksel yüz modelleme piksel bazlı karar vermeyi sağlarken, yüzey devamlılığını ifade eden komşuluk bilgisini dahil etmek sonuçları iyileştirmektedir; (iii) Geri çatma sadece yüzey yaklaştırımı sağladığı için tanımada yarar sağlamamaktadır; (iv) Maskeli projeksiyon alt-uzay tekniklerini boşluklu veriye uygulamaya olanak sağlamaktadır.","With advances in sensor technology, three dimensional (3D) face has become an emerging biometric modality, preferred especially in high security applications. However, dealing with occlusions covering the facial surface is a great challenge. In this thesis, we propose a fully automatic 3D face recognition system, attacking three sequential problems: (i)Registration of occluded surfaces, (ii) detection of occluded regions, and (iii) classification of occlusion-removed faces. For the alignment problem, we propose an adaptively selected model based registration scheme, where a model is selected for an occluded face such that only the valid non-occluded patches are utilized in correspondence establishment. After registration, occlusions are detected, where we propose two different occlusion detection approaches. In the first detector, fitness to a pixelwise statistical model of the facial surface is used. In the second approach, in addition to the facial model, neighborhood information is incorporated. For occlusion handling, two different strategies are evaluated: (i) Removal of occlusions, and (ii) restoration of missing parts. In the classification stage, a masking strategy, which we call masked projection, is proposed to enable the use of subspace analysis techniques with incomplete data. Experimental results on two databases with realistic facial occlusions, namely, the Bosphorus and the UMB-DB, confirm that: (i) The proposed registration technique based on the adaptively selected model is a good alternative to obtain occlusion robustness; (ii) in occlusion detection, use of a statistical facial model is beneficial to make a pixelwise decision, which can further be improved by incorporating neighborhood relations to model coherency of surfaces; (iii) restoration provides only an approximation of the surface and is not suitable for classification purposes, (iv) masked projection serves as a viable approach to apply subspace techniques on incomplete data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nanoaglar nanomakineler arasındaki haberlesme uzerine yogunla san yeni birhaberlesme kavramıdır. Bu tezde, bu konu dahilinde onerilen bir cok haberlesme sistemininicinden Dif¨uzyon Ile Haberlesme sistemi uzerine yogunlastık. Bu sistem, biyolojikhucreler arasında molekul salınımı tabanlı haberlesmeden esinlenilerek gelistirilmistir.Dif¨uzyon ile haberlesme, biyonanomakineler arası kullanım icin dusunulen sistemlerarasında en ¨onde gelenler arasındadır. Literat¨urde bu sistem uzerine yapılmıs bazıcalısmalar bulunmakta, ancak bunların bir cogu sistemin sadece tek bir ozelligineyogunlasmaktadır. Bu calısmaların aksine, bu tezde, once temel bir kanal modeli ilebaslayıp sonra bu model uzerinden belli baslı fiziksel katman meselelerini ele alacagız.Bu sisteme ait ozel olasılıksal haberlesme ortamı, bir cok fiziksel katman konusununtekrar gozden gecirilmesi ve incelenmesini gerekli kılmaktadır (¨or: kanal modeli, girisimanalizi). ¨ Oncelikli olarak ortak bir kanal ve enerji modeli gelistirip sistemin kapasitesinihesaplayacagız. Ardından bu sistem icin iki modulasyon teknigi onerip bir kısım giri simkaynaklarının (Semboller arası ve Kanallar arası) kanal kapasitesi uzerindeki etkileriniinceleyecegiz. Ayrıca bu sistemde molekuller icin salınım noktası seciminin oneminigosterecegiz. Sonuclarımıza gore bu haberlesme sisteminin birbirinden 1 ila 10 muzaklıkta olan biyonanomakineler icin iyi bir cozum olması beklenmektedir. 10 m'ninotesinde sistemin basarımını hızlıca dusmektedir. Son olarak daha kontrollu dif¨uzyontemelli bir sistem olan Kalsiyum Sinyallesmesine genel bir bakıs atıp bu sistem uzerinegelecekte neler yapılabileceginden bahsedecegiz. Kalsiyum sinyalle smenin aralarında 10m'den daha uzun mesafeler olan cok sayıda biyo-nanomakineden olusan uygulamalaricin kullanılması ongorulmektedir.","Nanonetworking is a new communication paradigm that focuses on communicationbetween nanomachines. Among the various methods that are being proposed inthe context of this paradigm, we focus on the Communication via Diffusion system inthis thesis. Modeled after molecular release based communication between neighboringcells in living organisms, this system is currently one of the most prominent systemsenvisioned to be used between bio-nanomachines. While there are some studies onthis system in the literature, most of them focus on a single aspect of the system.In contrast, in this thesis we start with a basic channel model and consider severalphysical layer issues built upon this channel model. The unique probabilistic mediumused in this system requires revisions in physical layer issues (e.g., channel modeling,interference analysis) specific to this medium. We firstly develop a joint channel andenergy model to evaluate the capacity of this system. Then, we propose two differentmodulation techniques and elaborate on the effects of the interference sources (namelythe Intersymbol and Co-channel Interferences) over the channel capacity. We also showthe importance of the release point selection in this system. Our results show that thiscommunication system is expected to be a good solution between bio-nanomachinesthat are 1 to 10 m apart, beyond which the performance of the system degradesquickly. Lastly, we give an overview and future directions of a more controlled diffusionbased system, called Calcium Signaling, that is expected to be used in applicationswhere the distance between the transmitting bio-nanomachine pair is longer than 10m and there are many devices in the environment."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüz dünyasında, günlük hayatta, kişisel bilgisayarlar, kişisel dijital yardımcılar ve evlerimizdeki çeşitli makinalar gibi bilgisayar temelli aletlere sıkça rastlamaktayız. Bu aletler, yazı-tabanlı arayüzlere göre kullanım kolaylığı sebebiyle, grafiksel kullanıcı arayüzleri ile kullanılır olmuştur. Her gün bilgisayar kullananlar ve gençler için bu kullanıcı arayüzlerine alışmak oldukça doğal olsa da, bu grafiksel kullanıcı arayüzlerinin, hızla büyüyen bir kitle olan yaşlılar tarafından kabul edilebilirliği önemli bir mesele olarak karşımıza çıkmaktadır. Kullanıcı arayüzlerinin yaşlı kullanıcılar tarafından kabul edilebilirliğini arttırmak için arayüzlere basitlik ve sadelik kazandırmak bu alanda yapılan çalışmaların ana temasını teşkil etmektedir. Dolayısıyla, yaşlılar tarafından kabul edilebilecek arayüzlerin tasarlanması, yaşlıların önceliklerinin ve görsel, işitsel, bedensel ve zihinsel engellerinin temel tasarım parametreleri olarak göz önünde bulundurulmasını gerektirmektedir.Bu tezde, çevre destekli ev-içi sağlık gözetimi ortamında yaşlılar için grafiksel kullanıcı arayüzü tasarlanması problemi üzerinde bir çalışma gerçekleştirilmiştir. Gerçekleştirdiğimiz literatür taraması, görsel, işitsel ve psikomotor bozuklukların birçok arayüz tasarım süreci tarafından ele alınıp çözümler üretildiğini fakat bilişsel bozukluklar kısmının ise genelde ?sayfa karmaşıklığını azaltmak? olarak ele alındığını göstermiştir. Bu tezde ise, bir kullanıcı arayüzünün iki temel parametresi arasındaki ilişki üzerinde yoğunlaşılmıştır: bir sayfadaki arayüz elemanlarının yoğunluğu olarak ifade edilebilecek sayfa karışıklığı ve bir işlemi bitirebilmek için taranması gereken sayfa sayısı olarak açıklanabilecek sayfa hiyerarşisi. Bu iki fenomen arasındaki ikilik üzerinde çalışabilmek için iki farklı sürümde arayüz geliştirilmiştir: birincisi, sayfa sıradüzeni düşük olan fakat sayfa karmaşıklığı nispeten fazla olan sürüm, ikincisi ise sayfa karmaşıklığı düşük fakat sıradüzeni nispeten büyük olan sürüm.Bu sürümleri denemek ve hangisinin yaşlılar tarafından daha kabul edilebilir ve kullanışlı olduğunu anlamak için, farklı engelleri olan 18 yaşlı ile deney oluşturulmuştur. Hata oranı, toplam zaman, iki tıklama arasında geçen zaman, klavye kullanımı ve tıklama sayısı metrik olarak kullanılmış ve sonuçlar makul bir karmaşıklığa sahip olacak şekilde birinci sürümün daha iyi, yaşlılar tarafından daha kullanılabilir olduğunu göstermiştir. Bunun yanı sıra, ekrana dokunma veya tuş benzeri arayüzü elemanları algısı gibi, yaşlıların bir kullanıcı ara yüzü ile etkileşim anlayışı doğrultusunda değişik bulgulara ulaşıldı.","In today?s computerized world, we usually face various types of computerized devices such as notebooks, personal digital assistants (PDAs) and even several machines at home. These devices have started to be operated by graphical user interfaces because of their ease of use compared to the text-based interfaces. Adaptation of young people or everyday-computer-users to these interfaces is quite natural; however, acceptability of graphical user interfaces (GUI) by elderly, as a rapidly growing group in today?s world, has become a challenging issue. Providing simplicity for user interfaces in order to be acceptable by elderly people is the main concern of the studies that try to address this challenge. Thus, designing simple and hence acceptable user interfaces for elderly requires considering their preferences and impairments such as visual, audial, psychomotor and cognitive impairments as the main design parameters.In this thesis, we study graphical user interfaces for elderly people with different impairments in the context of in-home healthcare system that involves daily living monitoring, focusing on the relation between two main design parameters of a graphical user interface: page complexity which is the number of interface elements on each page and the page hierarchy which is the number of the pages to be traced in order to finish a task. In order to study the dichotomy between these two phenomena, we designed two versions of the interface: One version is the flat version which has less page hierarchy with more complex pages and the other version is the deep version which has deeper page hierarchy with less complex pages.We conducted experiments with 18 elderly people having different impairments in order to understand whether the flat version or the deep version would be more acceptable / preferable. We asked them to complete some tasks such as making a video-call to a friend and setting a reminder to the agenda. Using the errors, time, inter-touch time between two consequent interactions, key strokes and clicks as the experiment metrics, the results revealed that the flat version with a reasonable complexity level would be more acceptable by elderly. We also report different findings about elderly perception of interacting by a user interface such as touching phenomena and perception of interface elements like buttons and interactive sentences."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüz tanıma, bilimsel zorlukları ve olası uygulamaları dolayısıyla hem çeşitli araştırma toplulukları hem de piyasa tarafından yıllardır ilgi gören, popüler bir araştırma alanıdır. Gürbüz bir yüz tanıma sistemi sağlamak için çeşitli teknikler yoğun olarak incelenmiştir. Bu tekniklerin bir çoğu, kontrollü koşullar altında hali hazırda çok yüksek tanıma başarısı elde etmiştir. Buna karşılık, kontrolsüz koşullar altında yüz tanıma, hala çok zorlu bir problemdir. Bu zorluk, ifade ve aydınlanma değişimi, kısmi örtüşme, kullanılan eğitim ve test verileri arasındaki zaman farkı gibi etmenlerden kaynaklanmaktadır. Yerel öznitelik tabanlı yüz tanıma, örtüşmelerden ve ifadelerden kaynaklanan görünüm değişimlerine daha az hassas olduğu için bütünsel tabanlı yaklaşımlardan daha iyi sonuçlar göstermiştir. Bu tezde, gerçek-dünya koşulları altında güvenli bir şekilde çalışan yerel görünüm tabanlı bir yüz tanıma algoritması önerilmektedir. Önerilen algoritma, yüz imgelerini temsil etmek için farklı yerel görünüm modelleri kullanmaktadır. Sistem yüz imgelerini güçlü bir biçimde temsil etmeleri dolayısıyla yüzsel imge analizinde yaygın olarak kullanılan Gabor özniteliklerinden faydalanmaktadır. Klasik Gabor özniteliklerinin yanı sıra eğrisel Gabor özniteliklerinden de yararlanılmıştır. Sistem çoklu Gabor sınıflandırıcılarının seçilmesine ve birleştirilmesine odaklanmıştır. Son büyük Gabor sınıflandırıcısı, SFFS tabanlı sınıflandırıcı seçme algoritması kullanılarak seçilen sınıflandırıcıların LLR tabanlı tümleştirme ile birleştirilmesiyle elde edilmiştir. Ek olarak, sistem DCT özniteliklerini ekstra bulgu olarak kullanmaktadır. Son olarak, farklı yerel temsiller üzerinde eğitilen sınıflandırıcılar, PLSR tabanlı tümleştirme ile skor seviyesinde birleştirilmiştir. Sistem FRGC veritabanı 2.0 sürümü Deney 4 üzerinde test edildiğinde %0.1 yanlış kabul oranınında %94.16 doğrulama oranı yakalayarak literatürde şimdiye kadar raporlanan en yüksek başarımı elde etmiştir.","Face recognition is a popular research area due to its scientific challenges and potential applications. Therefore, it attracts attention from both diverse research communities and the industry for several years. Various techniques have been intensively investigated to provide a robust face recognition system. Many of these techniques have already achieved very high recognition accuracies under controlled conditions. On the other hand, face recognition under uncontrolled conditions is still a very hard problem. The difficulty arises from facial appearance variations caused by various factors, such as expression, illumination and partial occlusion, and the time gap between training and testing data capture. Face recognition based on local features usually outperforms holistic approaches because local representation is less sensitive to appearance variations caused by occlusions and facial expressions. In this thesis, a local appearance based face recognition algorithm, which works reliably under real-world conditions, is proposed. The proposed algorithm uses different local appearance models to represent face images. Fundamentally, it exploits Gabor features that have been extensively used for facial image analysis due to their powerful representation capabilities. It utilizes curvature Gabor features in addition to conventional Gabor features. The system focuses on selecting and combining multiple Gabor classifiers. The final Gabor classifier is obtained by LLR-based fusion of classifiers that are selected using SFFS-based classifier selection algorithm. In addition, the system uses DCT features as extra evidence. Finally, classifiers trained on different local representations are combined at score-level by PLSR-based fusion. The system is evaluated on FRGC version 2.0 Experiment 4, and achieves 94.16% verification rate @ 0.1% FAR, which is the highest accuracy reported on this experiment so far in the literature."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telsiz Çoklu Ortam Algılayıcı Ağlar (TÇAA) ucuz kamera donanımlarının ortaya çıkmasıyla önem kazanmıştır. TÇAA lara karşı artan bu ilgi, gözetleme ve nesne takibi gibi çoklu ortam uygulamalarının geliştirilmesine imkan sağlamıştır. Çoklu ortam verisi taşıdığı veri miktarından dolayı skalar veriden daha yüksek bant genişliğine gereksinim duyar. Tıkanıklık, gereksiz iletişime neden olup enerji verimliliğini azalttığından telsiz algılayıcı ağlar (TAA) için zorlayıcı bir problemdir. Çoklu ortam akışından kaynaklı fazla sayıdaki veriler TÇAA larda tıkanıklığın oluşma ihtimalini klasik TAA göre daha yüksek kılar. Bu tezde, TÇAA üzerinden çoklu ortam verisi taşırken oluşan problemler incelenmektedir ve SUIT adında tıkanıklık kontrol mekanizması sağlayan yeni bir çapraz katman kademeli resim taşıma protokolü önerilmektedir. SUIT bulanık mantık tabanlı tıkanıklık tespit etme yöntemi ve resimlerin algılayıcılar üzerinden ilerlerken kalitelerini kabul edilebilir derecede düşüren etkin bir tıkanıklık hafifletme yöntemi sağlamaktadır. Tıkanıklığın oluştuğu durumlarda SUIT resim çerçevelerinin bazı paketlerini akıllıca düşürerek, çerçeveleri daha düşük fakat kabul edilebilir kalitede iletir. Bu yüzden SUIT daha iyi çoklu ortam iletim başarımı sağlayarak video akışının sürekliliğini artırır. SUIT in başarımı TAA lar için geliştirilmiş iki farklı taşıma protokolü ile değerlendirilmiştir. Benzetim sonuçlarına göre, SUIT rakiplerinden daha iyi enerji tüketim, resim çerçevesi taşıma, resim çerçevesi kaybetme ve gecikme başarımı sağlamıştır.","The availability of low-cost camera hardware has enabled the Wireless Multimedia Sensor Networks (WMSNs), and has made it possible to develop multimedia applications such as surveillance systems, traffic control systems, environment monitoring and object tracking. Unlike scalar data, multimedia requires higher bandwidth due to the larger amount of information to be transmitted. Congestion is a challenging problem for Wireless Sensor Networks (WSNs) due to waste of scarce communication resources and reduction energy efficiency. Compared to traditional WSNs, the probability of congestion occurrence in WMSNs is higher due to the high volume of data arising from multimedia streaming. In this thesis, problems for multimedia transmission over WMSNs are examined and Sensor fUzzy-based Image Transmission (SUIT); a new cross-layer progressive image transport protocol is proposed as a solution. SUIT provides fuzzy logic based congestion estimation and an efficient congestion mitigation technique which decreases the image quality on-the-fly to an acceptable level. In case of congestion, SUIT drops some packets of the frames in a smart way and thus transmit frames to the sink with lower, but acceptable quality. In this way, SUIT improves the continuity of the video streaming. The performance of SUIT is evaluated by comparing it with two example transport protocols proposed for WSNs. According to the simulation results, SUIT provides better energy consumption, frame delivery, frame loss and frame latency performance than its competitors."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Merkezi Olmayan Kısmen Gözlemlenebilir Markov Karar Süreci(MO-KGMKS) modeli, çoklu etmen koordinasyonu ve karar vermede kullanılan yeni bir matematiksel çerçevedir. Buna rağmen, gerçek hayat uygulamaları kısıtlıdır. Robot futbolu, MO-KGMKS algoritmalarının potensiyelini araştırmak için en iyi sınama ortamlarındandır. Bu çalışmada, Eker ve Akın [1] tarafından geliştirilen MO-KGMKS algoritması kullanılmaktadır. Algoritma strateji arama algoritmasıdır. Strateji uzayını genetik algoritmayla arar. Genetik algoritma kromozomların uygunluğunu değerlendirmek için bir benzetici kullanır. İki strateji gösterimi vardır. Sonlu durum denetleyicisi gösterimi ayrık MO-KGMKS modelleri için kullanılmaktadır. Eker ve Akın'ın algoritmasına ek olarak, yapay sinir ağları gösterimi sürekli MO-KGMKS modelleri için kullanılmaktadır. Deneyler, Robocup 2B robot futbolu benzeticisinde ve TeamBots benzeticisinde uygulanmıştır. Algoritmanın, robot futbolu gibi karmaşık bir problemi çözebildiği gösterilmektedir. Değişik uygunluk fonksiyonları denenmiş ve oyun skorunun en iyisi olduğu bulunmuştur. MO-KGMKS algoritması, destekli öğrenme algoritması ile karşılaştırılmıştır. Sonlu durum denetleyicili MO-KGMKS algoritmasının destekli öğrenme algoritmasından daha iyi olduğu bulunmuştur. Ayrıca, Keepaway probleminde yapay sinir ağlar temsilini kullanan MO-KGMKS algoritması elle kodlanmış kriter stratejisinden daha iyi olduğu ve destekli öğrenme metoduna yakın sonuçlar elde edildiği gösterilmiştir.","Decentralized Partially Observable Markov Decision Process (Dec-POMDP) is a recent mathematical framework which has been used to model multi-agent coordination and decision making. However, its real life applications are limited. Robot soccer is one of the good testbeds to investigate the potential of Dec-POMDP algorithms. In this work, we use the Dec-POMDP algorithm developed by Eker and Akın [1]. The algorithm is a policy search algorithm. It searches the policy space with a genetic algorithm. The genetic algorithm uses a simulator to estimate the fitness of chromosomes. There are two policy representations. The finite state controller representation is used for discrete Dec-POMDP models. We extend Eker and Akın?s algorithm by using a neural network representation for continuous Dec-POMDP problems. The experiments are carried out in the RoboCup 2D robot soccer simulator and TeamBots simulator. We show that the algorithm is capable of solving complex problems such as robot soccer. We have experimented with different fitness functions, and we have found that the game score is the best one. We also compare the performances of the two methods, namely Dec-POMDP algorithm and reinforcement learning. It is found that the Dec-POMDP algorithm with the finite state controller representation is better than the reinforcement learning method. We also show that, in the case of the Keepaway problem, the Dec-POMDP algorithm with the neural network representation is better than a hand-coded benchmark policy, and is also comparable to the reinforcement learning method."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Merkezi Olmayan Kısmen Gözlemlenebilir Markov Karar Süreci (MO-KGMKS)modeli, kısmen gözlemlenebilir ortamlarda çoklu etmen planlama problemini adreslemektedir.Modelin NEXP-complete kompleksliğe sahip olmasından dolayı, sadece küçük boyutluproblemler optimal bir şekilde çözülebilir. Bu sebepten dolayı, birçok araştırmacıdaha büyük boyutlu problemler için en iyiye yakın çözüm üretebilecek yaklaşık çözümyordamları üzerine yoğunlaşmıştır. Bununla birlikte, şimdiye kadar geliştirilen yaklaşıkçözüm yordamları bile büyük boyutlu problemleri ancak az sayıda adım için çözebilmektedir.Bunun bir nedeni etmen stratejilerini temsil ederken ve strateji uzayını tararkenkiüssel hafıza gereksinimidir. Bu tezde sonlu adımlı MO-KGMKS problemlerini yaklaşıkolarak çözmek için dört yeni yaklaşım sunuyoruz. ?Ilk yaklaşım, MAP, MO-KGMKS problemleriniKGMKS problemi olarak modelleme ve daha sonrasında verimli bir KGMKSçözümcüsü ile çözme temellidir. Diğer yaklaşımların hepsi, yani ES-BV, ES-OH ve GAFSC,evrimsel yordamların uygulanması temeline dayanmaktadır. ES-BV, MAP yöntemindeolduğu gibi inanç vektörlerini kullanır ve strateji vektörlerini evrimsel stratejileri (ES)kullanarak bulmaya çalışır. ES-OH yaklaşımı gözlem tarihçesini kullanmayı, karar vermekiçin bunu bir sinir ağına girdi yapmayı ve sinir ağlarını eğitmek için ES kullanmayıönerir. GA-FSC yordamı ise stratejileri temsil etmek için sonlu durum kontrolcülerinikullanır ve genetik yordamları kullanarak en iyi stratejiyi arar. Bütün yordamlar en bilinenMO-KGMKS problemlerinde test edilmiştir. Sonuçlarımızı bu konudaki en ileritekniklerle ve birbirleriyle karşılaştırdık. MAP haricinde bu çalışmadan geliştirilen yordamlarınvarolan en iyi yordamlarla karşılaştırılabilir bir performansa sahip olduğunu veGA-FSC kullanılması durumunda problemler için çözüm adım sayısının artırıldığını gösterdik.","The Decentralized Partially Observable Markov Decision Process (DEC-POMDP)model addresses the multiagent planning problem in partially observable environments.Due to its NEXP-complete complexity, only small size problems can be solved exactly.For this reason, many researchers concentrate on approximate solution algorithms that canhandle more complex cases and produce near optimal solutions. However, even the approximatesolution techniques developed so far can handle large size problems only for smallhorizons. One reason for this is the exponential memory requirements while representingthe agent policies and searching the policy space. In this thesis, we propose four newapproaches to solve finite horizon DEC-POMDP problems approximately. The first approach,called MAP, is based on modeling DEC-POMDP problems as a POMDP problemand then solving using an efficient POMDP solver. The other approaches, namely ES-BV,ES-OH and GA-FSC, are all based on the application of evolutionary algorithms. The ESBVmakes use of belief vectors as in the case of MAP and tries to find policy vectors usingevolution strategies (ES). The ES-OH proposes to use the observation history and input itinto a neural network to make a decision and it uses ES to train the neural networks. TheGA-FSC algorithm makes use of finite state controllers for representing the policies andsearch for the optimal policy using genetic algorithms (GA). All algorithms were tested onthe major well-known DEC-POMDP problems. We compared our results with the currentstate of the art methods and we also compared our algorithms with each other. We showedthat all the algorithms developed in this study, except MAP, have comparable performanceto that of the existing top algorithms and in the case of the GA-FSC, the solution horizonfor the problems are extended at least an order of magnitude."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan eylemlerinin görsel ve hareket algılayıcı verileri ile tanınması konusu hareketli ve sürekli/yaygın hesaplama alanında çalışılan güncel araştırma konularından biri olarak yer almaktadır. Bu konu, temel olarak, farklı algılama teknolojileri kullanılarak insan eylemleri ile ilgili veri toplanmasını ve toplanan veri ile eylemlerin sınıflandırılmasını içermekte, aynı zamanda sağlık, destekli yaşam, spor ve eğlence gibi uygulama alanlarını hedeflemektedir. Bu alanda pek çok araştırma olmasına rağmen, mevcut sınıflandırıcıların başarımlarını karşılaştıran ve aynı zamanda eylemleri çevrimiçi eğitim ve sınıflandırma yöntemleri ile tanımlayan çok az örnek çalışma bulunmaktadır. Bu tezin amacı, insan eylemlerinin akıllı telefonlar üzerindeki ivmeölçer algılayıcısı kullanılarak tanınmasıdır. Amacımız, yürüme, koşma, oturma, ayakta durma, bisiklete binme gibi temel insan hareketlerinin telefon üzerinde veri işlenmesi ile sınıflandırılmasıdır. Literatürde yer alan çalışmalardan farklı olarak, veri toplama, eğitim kümesi modelleme ve aktivite sınıflandırması çevrimiçi olarak yapılmaktadır. Bunun yanında, Naif Bayes, kümelenmiş KNN ve Karar Ağacı sınıflandırma algoritmalarının çevrimiçi başarımları karşılaştırılmıştır. Bu amaçla hedeflediğimiz telefon modelleri ile uyumlu bir Android uygulaması geliştirilmiş ve literatürde yer alan çalışmalardan farklı olarak, birden fazla telefon modeli ile performans değerlendirmesi yapılmıştır. Sınıflandırma algoritmalarının başarımları, farklı deneklerle test edilmiş ve sonuçlara göre, kümelenmiş KNN tekniği diğer sınıflandırma algoritmalarını doğruluk ve çalışma süresi açısından daha yüksek başarım sergilemiştir. Ayrıca, örnekleme zamanı, pencere büyüklüğü ve bunun gibi önemli sistem parametrelerinin başarım üzerindeki etkisi de incelenmiştir.","Human activity recognition using sensory data has become an active field of research in the domain of pervasive and mobile computing. It involves the use of different sensing technologies to automatically collect and classify user activities for different application domains. In fact, smart phones with their sensing capabilities can also be used as a platform for human activity recognition. Although many studies have been introduced so far, there are few which consider online training and classification of activities as well as evaluating the online performance of existent classifiers. In this thesis, our aim is to analyse the performance of different classification methods for online activity recognition on smart phones using the built-in accelerometers considering important limitations of the phones, such as battery usage and limited computational power. For this purpose, we developed a mobile application on Android platform which performs online classification. We conducted experiments to investigate the performance of the system under the effect of several important factors including sampling rate and window size on several Android smart phones. The tests are performed on different subjects for activities of walking, running, sitting, standing and biking. We evaluated the performance of the activity recognition system using the Naive Bayes classifier, and next we utilized Clustered KNN and Decision Tree algorithms. According to the results, Naïve Bayes provides not satisfactory results whereas Clustered KNN gives promising results compared to the previous studies and even with the ones which consider offline classification. Additionally, Decision Tree results are also comparable with the results of Clustered KNN."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, Bilişsel Radyo (BR) ağlarında dahili ve harici algılamaya odaklanılmaktadır. Dahili algılamada BR'ler spektrum algılama ile fırsatları farkederler, halbuki haricialgılamada spektrum kullanım bilgisi harici bir birim tarafından sunulur. İlki için, düzgün nicemleyici ve etkili bir kaynaştırma stratejisi kullanan yeni bir yardımlaşmalı spektrum algılama öneriyoruz (UniQCS). Önerilen yöntem hatalı raporlama kanalı ve yanlış raporların varlığında, pek az ek bit bedeliyle, çoğunluk ve N-den M gibi sıfır-bir kararı veren algoritmalardan algılama ve yanlış alarm olasılıkları açısından daha iyidir. Ayrıca önerdiğimiz yöntem Eşit Kazançlı Birleştirici (EKB) ile karşılaştırıldı ve algoritmamız EKB'ye yakın bir başarım sergilemektedir (EKB kullanıcılar arasında ayrım olmadığı durumlarda üst sınırdır). Dahili algılamadaki zorluklar sebebiyle harici algılama farkedilir bir ilgi kazanmıştır. Harici algılamada bilişsel radyo spektrum erişimini durağan bilgi tutan konum belirleme veritabanı üzerinden gerçekleştirmektedir. Radyo Ortam Haritası (ROH) daha gelişmiş bir konum belirleme veritabanıdır ve TV boşkanallarında haberleşme konusundaki en son düzenlemelerle güncel bir konu olmuştur. ROH, algılayıcılardan toplanan spektrum ölçümlerini işleyerek dinamik bir sinyal gücüsıcaklık haritası oluşturur. Bu tezde, aktif gönderici konumunun kestiriminden yararlanan, LIvE ROH oluşturma tekniği önerilmiştir ve bilinen tekniklerle kırınımlı ve sönümlü kanallarda karşılaştırılmıştır. Benzetim sonuçları önerilen yöntemin kanal bilgisini kullanarak diğer yöntemleri karesel ortalama hata ve doğru algılama bölge oranı açısından aştığını göstermektedir.","In this thesis, we focus on both internal and external sensing in Cognitive Radio (CR) networks. In internal sensing, individual CRs discover spectrum opportunities via spectrum sensing whereas in external sensing, an external entity provides the spectrum occupancy and related information. For the first, we propose a novel cooperative spectrum sensing scheme, Uniform Quantization-based Cooperative Sensing(UniQCS) that uses uniform quantization and an effective fusion strategy. Numerical results demonstrate that under imperfect reporting channel and false reports, UniQCSperforms better than hard decision algorithms such as Majority and M-of-N in terms of probability of detection and false alarm at the expense of a marginal increase in overheadbits. We demonstrate that the performance of UniQCS is very close to that of equal gain combiner, which constitutes the upper bound for the decision performance. Due to the challenges in internal sensing, external sensing recently has gained noticeable interest. In external sensing, CRs access spectrum through geolocation databases, which keep relatively static information. Radio Environment Map (REM) is a kindof improved geolocation database and an emerging topic with the latest regulations on TV white space communications. It constructs a signal power temperature map of the CR operation area via processing spectrum measurements collected from sensors dynamically. In this thesis, transmitter LocatIon Estimation based (LIvE) REM construction technique is proposed and compared with the well-known REM construction techniques in shadow and multipath fading channels. The simulation results suggest that the LIvE REM construction outperforms the compared methods in terms of root mean square error and correct detection zone ratio."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Aykırılıklar verinin genelinden önemli farklılık gösteren örneklerdir. Gerçek yaşamda karşımıza çıkan pek çok uygulamada aykırı örneklerin bulunması hem kavramsal hem de eylemsel açıdan değerli bilgi taşıdıkları için önemlidir. İzgesel yöntemler yüksek boyutlu verilerdeki düşük boyutlu yapıları ortaya çıkarabilen gözetimsiz öğrenme yaklaşımlarıdır. Bu yöntemlerden Temel Bileşenler Çözümlemesi (TBÇ), Laplasyen Özharitalar (LÖH) ve Çok Boyutlu Ölçekleme incelenerek ortak bir çatı altında sunulmaktadır. Bu çalışmada, izgesel yöntemlerin boyut düşürme özelliklerinin aykırılık bulmakta değerli olduğu öne sürülmekte ve aykırılık bulma öncesinde izgesel yaklaşımla veriyi dönüştüren izgesel aykırılık bulma yöntemi önerilmektedir. Etkin-Aykırı, Yerel Aykırılık Etkeni, Tek Sınıflı Karar Vektör Makineleri ve Parzen Pencereleri aykırılık bulma yöntemleri olarak kullanılmakta ve bu yöntemler Temel Bileşenler Çözümlemesi (TBÇ), Laplasyen Özharitalar (LÖH) ve Çok Boyutlu Ölçekleme'yle birleştirilerek farklı veri kümeleri üzerinde aykırılık bulma başarımı sınanmaktadır. Deney sonuçları özellikle LÖH izgesel yönteminin başarımı artırdığını göstermektedir. Sonrasında, LÖH yöntemini aykırılık bulma için değerli kılan özgün özellikleri tartışılmaktadır. Önerdiğimiz yaklaşım yüz tanıma problemine de uygulanarak, öne sürülen yöntemin geçerliliği doğrulanmaktadır. Ayrıca, bu alandaki araştırmalarda kullanılmak için, aykırılık bulma ve izgesel yöntemlerin gerçeklenmesini içeren bir MATLAB kütüphanesi de bu tez ile paylaşılmaktadır.","Outliers are those instances in a sample that deviate significantly from the others. Their identification bears much importance since they carry valuable and actionable information in many real life scenarios. Spectral methods are unsupervised learning techniques that reveal low dimensional structure in high dimensional data. We analyze spectral methods, such as, Principal Components Analysis (PCA), Laplacian Eigenmaps (LEM), Kernel PCA (KPCA), Multidimensional Scaling (MDS) and present a unified view. We argue that the ability of such methods to reduce dimensionality is valuable for outlier detection. Hence, we propose spectral outlier detection algorithms where spectral decomposition precedes outlier detection. The four outlier detection methods we use are Active-Outlier, Local Outlier Factor, One-Class Support Vector Machine and Parzen Windows. We combine these methods with the spectral methods of LEM and MDS to form our algorithm. We evaluate the performance of our approach on various data sets and compare it with the performance of outlier detection without spectral transformation and with PCA. We observe that combining outlier detection methods with LEM increases the outlier detection accuracy. We discuss how the unique characteristics of LEM make it a valuable spectral method for outlier detection. We also confirm the merits of our approach on a face detection problem. Additionally, we provide an outlier detection toolbox in MATLAB that will be useful for researchers in this field containing the implementations of the outlier detection algorithms and the spectral methods discussed in this thesis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,Bankalar ve perakendeciler gibi birçok finansal kurum son zamanlardaki finansal krizler ve daha katı düzenlemeler nedeniyle ağırlıkla hesaplamalı kredi risk analiz (KRA) araçlarını kullanmaktadır. Bu strateji onların finansal kurumlar havuzundaki finansal ve operasyonel risklerini yönetebilmelerini sağlar. Yapay öğrenme algoritmaları özellikle ikili sınıflandırıcılar bu amaç için çok uygundur. Öznitelik seçme algoritmaları KRA benzeri uygulamalarda veri toplama maliyetini düşürmek ve karar mekanizmasının yorumlanabilirliğini artırmak için kullanılır. Öznitelik seçme yöntemlerinin KRA veri kümelerine doğrudan uygulanması medeni durum gibi kategorik değişkenler nedeniyle başarılı olmayabilir. Buna benzer değişkenler genellikle ikili özniteliklere çevrilir ve özniteliklerin belli bir kısmını elemek veri toplama maliyeti ya da yorumlanabilirlik açısından yardımcı olmaz. Bu tezde çoklu öznitelik seçimi için özel bir öncül dağılım kullanan probit sınıflandırıcı ve özel bir çekirdek hesaplama yöntemi kullanan çoklu çekirdek öğrenimi yöntemleri geliştirdik. İki standart KRA veri kümesi üzerindeki deneyler önerilen ikili sınıflandırma algoritmalarının geçerliliğini ve etkinliğini gösterdi. KRA sistemleri için başka önemli bir özellik ise para birimi değişiklikleri gibi dimanik koşullara dayanıklıktır. Buna benzer değişikliklerden sonra sınırlı miktarda veri ile makul bir şekilde çalışmaları beklenmektedir ve transfer öğrenimi ile mevcut veriden faydalanılması bunun için en iyi stratejidir. Değişik veri kümelerini ortak bir altuzaya taşıyarak ve burada ortak bir sınıflandırıcı öğrenerek probit sınıflandırıcıyı transfer öğrenimine uyarladık. İki standart KRA veri kümesi üzerindeki deneyler transfer öğreniminin benzer durumlardaki faydasını gösterdi.,"Many financial organizations such as banks and retailers use computational credit risk analysis (CRA) tools heavily due to recent financial crises and more strict regulations. This strategy enables them to manage their financial and operational risks within the pool of financial institutes. Machine learning algorithms especially binary classifiers are very popular for that purpose. In real-life applications such as CRA, feature selection algorithms are used to decrease data acquisition cost and to increase interpretability of the decision process. Using feature selection methods directly on CRA data sets may not help due to categorical variables such as marital status. Such variables are usually are converted into binary features using 1-of-k encoding and eliminating a subset of features from a group does not help in terms of data collection cost or interpretability. In this thesis, we propose to use the probit classifier with a proper prior structure and multiple kernel learning with a proper kernel construction procedure to perform group-wise feature selection. Experiments on two standard CRA data sets show the validity and effectiveness of the proposed binary classification algorithm variants. Robustness against dynamic conditions such as currency changes is another important property for CRA systems. They should perform reasonably good with limited data after such changes and the best strategy is to exploit existing data using transfer learning. We also extend the probit classifier towards transfer learning by mapping different data sets into a unified subspace and learning a common classifier. Experiments on two standard CRA data sets show the usefulness of transfer learning for such cases."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüz ifadelerinin otomatik olarak tanınması, geniş kullanım alanlarına bağlı olarak oldukça populer bir araştırma konusudur. Var olan çalışmalar, bu problemin farklı türlerinde oldukça yüksek başarı oranları elde ettiler. Bu problemin, üzerinde daha az çalışılmış bir alanı da çoklu açılardan yüz ifadesi tanımadır. Farklı bakış açıları, farklı kişilerden kaynaklanan değişikliklerden dolayı zaten zor olan ifade tanıma problemini daha da zorlaştırır. Bu çalışmada, bir kişinin farklı bakış açılarından altı temel yüz ifadesini tanımak için bir yöntem öneriyoruz. Farklı bakış açılarından yüz ifadelerini, aralarındaki korelasyonun en yüksek olduğu ortak bir alt uzaya atmak için Kısmi En Az Kare Farkı yöntemini kullanıyoruz. Son zamanlarda, KEAKF yöntemi, bakış açısından bağımsız yüz tanıma problemi için başarılı bir şekilde kullanıldı. Eğitimde, bir insanın farklı açılardan yüz ifadeleri arasında bir ilişki kurulması yoluyla, aynı yöntemin, yüz ifadesi tanıma problemi için de başarılı bir şekilde kullanılabileceğini gösteriyoruz. Bu tür bir eğitim, kişisel farklardan bağımsız bir şekilde bakış açısı farklarını modeller. Yüz imgelerini önce hizalama adımından geçiririz, daha sonra hizalanmış yüzler üzerinde, gözler ve ağızdan yerel bloklar halinde öznitelikler çıkarırız. Öznitelik olarak, Gabor öznitelikleri ve piksel değerlerini kullandık. Ön yüz girdi bakış açısı olarak kullanıldığında, Gabor ve piksel değerlerinin yakın sonuçlar ürettiğini, ama diğer bakıç açısı ikilileri için Gabor özniteliklerinin daha iyi sonuçlar verdiğini deneylerimizde gösterdik. Ayrıca, kullanılan parametrelerin sonuçlar üzerindeki etkisini göstermek ve en iyi değerlerini bulmak için, parametrelerin detaylı analizlerini içeren deneyler yaptık.","Automatic facial expression recognition is a popular research topic due to its interesting applications in a wide variety of areas. The existing studies have achieved high accuracies in various formulations of the same problem. One direction which is not fully explored is multi-view facial expression recognition. Variations caused by different poses impose extra burden on the task of recognizing expressions, which is already a difficult problem due to large differences across subjects. In this thesis, we present a method to recognize six prototypic facial expressions of an individual across different pose angles. We use Partial Least Squares (PLS) to map the expressions from different poses into a common subspace, in which correlation between them is maximized. Recently, PLS has been successfully used for pose invariant face recognition problem. We show that, PLS can be effectively used for facial expression recognition across poses by training on coupled expressions of the same identity from two different poses. This way of training lets the learned bases model the differences between expressions of different poses by excluding the effect of the identity. We first align the faces and then extract block features around two eyes and the mouth on the aligned image. We experiment with Gabor filters and direct intensity values for local face representation. We demonstrate that two representations perform similarly in case frontal is the input pose, but Gabor representation outperforms intensity representation for other pose pairs. We also perform a detailed analysis of the parameters used in the experiments to show their effects on the results and to find the optimal ones for the expression recognition problem."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gelisen bilgi teknolojileri, yuksek islem hacmi gerektiren bircok servis ve uygulamasaglamaktadr. Kullanclar tarafndan gereksinim duyulan veri aktarm hzlarnkarslayabilmek icin mobil teknolojilerin ekosistemi kapsama devrinden kapasite devrinegecis yapmaktadr. Daha yuksek kapasite ihtiyaclar, video ve yuksek hzl veri servisleriicin guclu ic mekan kapsamas saglayan kucuk hucre yaklasm ile karslanabilir.Hucresel Ag Mimarileri Devre-Anahtarlamal yapdan Paket-Anahtarlamal yaplaragecerken, kucuk hucreler en buyuk paket ag olan interneti kullandklar icin bu evrimedaha onceden adapte olmus haldedirler. Bu nedenle kucuk hucreler paket tabanlmimariye mukemmel uyum saglayarak, LTE (Uzun Donemli Evrim) icin kacnlmazolmuslardr. Kucuk hucrelerin mobil aglara yerseltirilmesi esnek ve dinamik; operasyon,idare, bakm ve provizyon tasarlarna ihtiyac duyacaktr. Ag yonetimi icin,kendi kendini optimize ve organize eden ag elemanlar bir gereksinim olarak ortayackmstr. Bu nedenle LTE kucuk hucrelerde SON (kendi kendini optimize ve organizeetme) algoritmalar ve tekniklerinin kullanm, uzerinde durulmas gereken onemli biralandr. Bu calsmada konunun baz temellerini inceledikten sonra kendi kendine iyilesme ve duzenlenme yeteneginin LTE kucuk hucrelerin performans uzerindeki etkisinitartsacagz.","Emerging information technologies provide a large number of services which requirehigh throughput for the users. In order to supply the data rate needed by the consumer,the evolving ecosystem of mobile technologies have been shifting from coverageto capacity era. Needs of higher capacity can be achieved by small cell approach thatprovides good indoor coverage for video and high speed data services. Whilst CellularNetwork Architecture is shifting from Circuit-Switched mode to Packet-Switched mode,small cells have begun to adapt this evolution earlier since they use the largest packetnetwork, \the Internet"", as a backhaul, that is why they perfectly t in the packet orientedarchitecture and they are inevitable in Long Term Evolution (LTE). Deploymentof small cells requires exible and dynamic operation, administration, maintenanceand provisioning schemes. Self-organization and self-optimization of network elementsemerge as a necessity for network management. Hence, using Self-Organizing Networks(SON) algorithms and techniques in LTE small cells is a key issue; in this study we aregoing to discuss the impact of SON in performance of LTE small cells after reviewingthe principles of the topic"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir gözetim kablosuz algılayıcı ağın başarımı genellikle, algılayıcı sayısı, algılayıcı menzili, alanın genişliği ve hedefin hareketlilik modeli gibi ¸ceşitli verilerden etkilenenhedef tespit kapasitesi ile ölçülmektedir. Hedeflerin rastgele bir hareketlilik modelini takip etmek yerine, coğrafi avantajları sebebiyle bir takım patikaları tercih ettiğini veburalardan geçtiğini varsaymaktayız. Bu patikalar ise genel olarak birbirinin yakınında bulunmakta ve belirli bir alan içinde sınırlandırılabilmektedir. Bu tezde, hedeflerinsık kullandıkları bölgeleri incelemekte ve bir sınır bölgesi içindeki yerlerini tespit etmek için bazı görüntü işleme araçlarını kullanmaktayız. Bunun ardından, hedeflerinsık kullandıkları patikalar olması durumunda, bir tespit kalite ölçütü olarak tespit olasılığını bir formül halinde sunmaktayız. Hedef tespit olasılığı eşleşme metodu ilegeometrik çizgi kesişim problemine dönüştürülmekte ve sınır alanı ve sık kullanılan alanlar içerisinde bulunan ve hedeflerin takip ettiği yolların geometrik sınır koşullarıtespit edilmektedir. Çizgi kesişim problemi integral geometri ve geometrik olasılık yöntemleri ile çözümlenmektedir. Sık kullanılan alanların farklı koşullar altında hedeftespit kalitesine etkileri olasılıksal modeller kullanılarak hesaplanmaktadır. Sunulan kalite ölçütünün doğruluğu analitik sonuçlar ve benzetim sonuçları ile gösterilmektedir.Ayrıca, gerçekçi senaryolar ile hedef hareketlilik modelinin ağ başarımı üzerindeki önemi gösterilmektedir. Sık kullanılan patikaların varlığının hedef tespit kalitesi üzerinebüyük etkisi olduğu gösterilmektedir. Çalışmamızı çoklu sık kullanılan alanlardan oluşan sınır bölgeleri için genelleştirmekte ve bu genel durum için tespit kalitesi ölçütükapalı matematiksel form halinde sunmaktayız. Ayrıca algılama modeli, uygulama senaryoları ve diğer sistem parametrelerinin tespit kalitesi üzerindeki etkileri de analitikaraçlar ve benzetimler ile sunulmaktadır. önerilen yöntem bir ağın beklenen tespit performansını öngörmek ve hedef hareketlilik modeline bağlı olarak ağın başarımınıiyileştirmek amacıyla kullanılabilecek araçlar sunmaktadır.","The performance of a surveillance wireless sensor network is generally measured with its detection capability which is affected by various parameters such as the sensor count, the sensor range, the area width and the target mobility model. We assume that intruders prefer some favorite paths because of their geographical advantages and pass through them instead of following a random mobility model. These paths are generally in close vicinity of each other and they can be bounded in a region. In this thesis, we inspect the travelers? favorite region notions and propose some image processing tools to detect their location within a border area. Following this, we present a closed form of the detection probability as the detection quality measure in the existence of travelers? favorite paths. The detection probability is reduced to the geometric line intersection problem using bijection and the boundary conditions of intruder trajectories for the border area and the favorite regions are determined. The line intersection problem is solved using tools from the integral geometry and geometric probability. The effect of the favorable region on the detection quality under different conditions is calculated using probabilistic models. The accuracy of the proposed quality measure is validated by both analytical methods and simulation results. Furthermore, the importance of the intrusion model on the network performance is presented using realistic scenarios. It is shown that the existence of favorite paths has significant impact on the detection quality of the network. We extend our work to border areas with multiple favorite path regions and present a closed form of detection probability for such generic cases. We also inspect the effects of various system parameters such as the sensing model and application scenarios on the detection quality measure using both analytical tools and simulations. The proposed detection quality measure provides analytical tools to forecast the expected detection performance and to optimize the network according to the intruder mobility model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz algılayıcı ağlarda, algılayıcı verilerinin çıkış düğümü etrafında yoğunlaşması bu bölgedeki düğümlerin pillerini çabuk bitirmelerine ve erken ölümlerine yol açar. Bu ölümler çıkış düğümlerinin ağla olan bağlantılarını koparır ve algılayıcı verilerinin toplanmasını engeller. Bu sorunu ortadan kaldırmak için hareketli çıkış düğümü kullanımı önerilmektedir.Hareketli çıkış düğümü, ek bir çabaya gerek duymadan ağda yük dağılımı ve tekdüze enerji sarfiyatı sağlar. Ancak hareketli çıkış düğümünün konumunu taze bir şekilde ağın geneline bildirmek, hem enerji hem de paket gecikmeleri açısından ek yüke yol açmaktadır. Bu tezde, bu ek yükü en aza indirgerken aynı zamanda hareketli çıkış düğümlerinin sağladığı avantajları koruyan yeni bir yönlendirme protokolü olan Halka Yönlendirme'yi öneriyoruz. Dağıtık ve enerji gözeten bir yönlendirme protokolü olan Halka Yönlendirme aynı zamanda veri iletim gecikmelerini en aza indirgemeyi hedefler ve bu özelliğiyle gerçek zamanlı uygulamalar için kullanılabilir. Halka Yönlendirmenin başarımını değerlendirmek amacıyla OPNET ortamında geniş kapsamlı benzetim deneyleri koşturulmuştur.","The concentration of data traffic towards the sink in a wireless sensor network causes the nearby nodes to deplete their batteries quicker than other nodes, which leaves the sink stranded and disrupts the sensor data reporting. To mitigate this problem the usage of mobile sinks is proposed. Mobile sinks implicitly provide load-balancing and help achieving uniform energy-consumption across the network. However, adver- tising the location of the mobile sink to the network introduces an overhead in terms of energy consumption and packet delays. In this thesis, we propose a new routing protocol, Ring Routing, which aims to minimize this overhead while preserving the advantages of mobile sinks. It is a distributed, energy-efficient mobile sink routing protocol that minimizes data reporting delays, and hence is suitable for real-time ap- plications. We evaluate the performance of Ring Routing via extensive simulations conducted in OPNET."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada kontrol mühendisliği yaklaşımlarının finansal portföy oluşturmadaki başarısı ampirik olarak incelenmektedir. Çoğu zaman, yatırımcıların amacı, yatırımın getirisini maksimize ederken yatırım üzerindeki riskleri minimum seviyede tutmaktır. Çalışmamızda Modern Portföy Teorisi kullanılarak yatırımcının problemi matematiksel olarak formüle edilmektedir. Formülasyondaki risk ve getiri parametreleri geçmiş finansal veriler kullanılarak kestirilmektedir. Yatırımcının yatırım stratejisi üç değişken ile karakterize edilmektedir. Bu değişkenlerden birincisi yatırımcının risk toleransıdır. Çalışmamızda, yatırımcılar risk iştahlarına göre üç gruba ayrılmaktadır: Riskten Kaçınanlar, Kontrollü Olarak Risk Alanlar ve Maceracılar. İkinci değişken yatırım ufku olarak adlandırılmaktadır. Yatırım ufku yatırımcının kazanç elde etmeyi ümit ettiği ileri bir tarihi belirtir. üçüncü değişken risk ve getiri parametrelerinin kestiriminde kullanılan geçmiş finansal verinin uzunluğunu belirler. En kullanışlı yatırım stratejisine karar verebilmek adına, bu değişkenlerin değerlerinin içice yuvalanmış bir `for' döngüsü içerisinde değiştirilmesi ile birçok yatırım stratejisi için benzeştirme yapılmaktadır. Ampirik olarak gözlemlenen en iyi yatırım stratejisi dinamik bir portföy üzerine uygulanmakta ve bu portföyün performansı belirlenen kıstas ile karşılaştırılmaktadır. Bütün analiz ve benzetimlerde İstanbul Menkul Kıymetler Borsası verileri kullanılmaktadır. IMKB30 endeksi kıstas olarak seçilmiştir. Benzetim ve analizler için MATLAB kullanılarak kapsamlı bir yazılım ve grafik ara yüz geliştirilmiştir.","In this study, the success of the application of control engineering approaches to the financial portfolio construction problem are investigated empirically. Often, the aim of the investor is to maximize the returns while keeping the risks at minimum possible level. In our work, the investor's problem is formulated mathematically by using Modern Portfolio Theory. The risk and return parameters in the formulation are estimated by using historical data. The investment strategy of an investor is characterized by three variables. The first of these variables is the risk tolerance of the investor. In our work, the investors are divided into three groups according to their risk appetites: Risk Avoiders, Controlled Risk Takers and Adventurers. The second variable is named as the investment horizon. The investment horizon denotes the future timeat which the investor hopes to get a return. The third variable determines the length of the historical data that is used for the estimation of the risk and return parameters. By changing the values of these variables inside a nested for loop structure, various investment scenarios are simulated to decide on the most useful investment strategy. The empirically best investment strategy is then applied onto a dynamically updatedportfolio and the performance of the portfolio is compared to a specified benchmark. In all analyses and simulations, the data from Istanbul Stock Exchange is used. The ISE30 index is chosen as the benchmark. A comprehensive software program with a graphical user interface is developed using MATLAB for simulations and analyses."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"In this research, we analyse the problem of predicting software reliability from AI perspective.We observe that existing models are built based on expert knowledge including defining aset of metrics through surveys and causal relationships. We overcometheir limitations by introducing new data collection, model construction and inferencemethodology. We propose a Hybrid Bayesian network that would estimate reliabilityof consecutive releases of software projects before a release decision, in terms of theirresidual (post-release) defects. We form this hybrid model by incorporating quantitativefactors of development and testing processes into qualitative factors of requirementsspecification and documentation process without the need for any transformation.As quantitative factors, we select popularly used product, in-process and people metricsas well as introduce new ones depending on the availability of local data in the organizations.We also identify qualitative factors representing requirements specificationprocess via surveys with development teams. Dependencies between software metricsand defects are determined according to correlation and independence tests andgraphical dependence analysis with chi-plots. We utilize a Monte Carlo technique toapproximate joint probability distribution of the model over conditionals by inferringunknown distribution parameters. Empirical analyses on two industrial datasets showthat (i) Hybrid Bayesian networks are capable of estimating reliability in terms ofresidual defects, (ii) proposed way of defining causal relationships, chi-plots, decreaseserror rates signicantly, (iii) expert judgement-based models may not achieve as goodprediction performances as statistical models, (iv) local data are so valuable and representativeas expert knowledge in software organizations that they should be usedprimarily and strengthened with expert knowledge in predicting software reliability."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kelimelerin anlamsal yönelimini belirleme, duygu analizinde, metin sınıflandırma ve yorum analizi gibi uygulamalarda kullanılan önemli bir konudur. Biz bu çalışmada, kelimelerin anlamsal yönelimini bulmak için çok dilli bir yaklaşım öneriyoruz. Bu yaklaşımda, ilgili dil için WordNet'te bulunan kelimeler arası ilişkileri kullanarak, kelimelerin ilişkisini gösteren bir ağ yapılandırıyoruz. Daha sonra bu ağı farklı dillerin WordNet'lerini bağlayarak genişletiyoruz. Bunu yapmak için İngilizce Wordnet baz alınarak geliştirilen diller arası indeks denilen kavramı kullanıyoruz. Ayrıca yabancı diller için önceden anlamsal yönelimi işaretli (positif ve negatif) kelimeleri üretmek için de yarı otomatik bir işaretleme yöntemi öneriyoruz. Bu yöntemde önceden işaretli İngilizce kelimelerden faydalanıyoruz. Önceden anlamsal yönelimi işaretli bu kelimeleri makina öğrenmesinde ve performans değerlendirmesinde kullanıyoruz. İşareti bilinmeyen bir kelimenim işaretini belirlemek için, bu ağ üzerinde rastlantısal yürüyüş modelini uyguluyoruz. Yakınlık ölçüsü olarak gidiş-geliş metriğini kullanıyoruz. Bizim çok dilli yaklaşımımızı Türkçe ve İngilizce için test ediyoruz ve iki dil için de tek dilli yaklaşımlara göre daha iyi bir performans gerçekleştiğini gösteriyoruz. Bildiğimiz kadarıyla bu çalışma Türkçe için kelimelerin anlamsal yönelimini belirleme alanındaki ilk çalışmadır.","Determining polarity of words is an important task in sentiment analysis with applications in several areas such as text categorization and review analysis. In this thesis, we propose a multilingual approach for word polarity detection. We construct a word relatedness graph by using the relations in WordNet of a given language. We extend the graph by connecting the WordNets of different languages with the help of the Inter-Lingual-Index based on English WordNet. We develop a semi-automated procedure to produce a set of positive and negative seed words for foreign languages by using a set of English seed words. In our approach, these seed words are used for semi-supervised learning and for evaluation purposes. To identify the polarity of unlabeled words, we propose a method based on random walk model with commute time metric as proximity measure. We evaluate our multilingual approach for English and Turkish and show that it leads to improvement in performance for both languages. To the best of our knowledge, we report the first word polarity detection results for Turkish."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde merkezi bilişsel radyo ağları için bir çizelgeleme modeli öneriyoruz. Modelimiz ikincil kullanıcıların veri iletimine odaklanan ve merkezi bilişsel baz istasyonuna hangi frekans, zaman dilimi ve veri hızıyla iletim yapacaklarını belirleyen çizelgeleyiciler kümesinden oluşmaktadır. Çizelgeleyicilerin ortak özellikleri merkezi bilişsel baz istasyonunun hizmet alanı içindeki birincil kullanıcıların rahatsız olmamalarını, ikincil kullanıcılar arasında çarpışma olmamasını ve ikincil kullanıcılar ile bilişsel baz istasyonu arasındaki iletişimin itimat edilebilir olmasını garanti etmeleridir. Çizelgeleyicilerimiz birbirlerinden temel olarak amaç fonksiyonlarıyla ayrılmaktadır. Hücredeki ikincil kullanıcıların toplam iş oranını azamileştiren, ikincil kullanıcıların çizelgeleme gecikmesini asgarileştiren, azami-asgari, ağırlıklı azami-asgari ve orantısal açıdan adillik sağlayan, iş oranı açısından tatmin olan ikincil kullanıcı sayısını azamileştiren ve farklı frekans bantlarına geçişin farklı gecikme maliyetlerini dikkate alan çizelgeleyiciler öneriyoruz. Buluşsal algoritmalara ve benzetim çalışmalarına ek olarak aynı zamanda çizge teorisi tabanlı bir yaklaşım öneriyor, NP-zorluk ve yaklaşıklanamama sonuçları ispatlıyor ve polinom zamanlı çizge algoritmaları ile yaklaşıklama algoritmaları öneriyoruz.","In this thesis, we present a scheduling model for centralized cognitive radio networks. Our model consists of a set of schedulers that focus on the data transmission of the secondary users and determine with which frequency, time slot and data rate each secondary user will transmit to the cognitive base station. Common features of the schedulers are that all of them ensure that the primary users in the service area of the cognitive base station are not disturbed, no collisions occur among the secondary users, and reliable communication of the secondary users with the cognitive base station is maintained. Our schedulers differ from each other mainly in terms of their objectives. We propose schedulers that maximize the overall cognitive radio cell throughput, minimize the average scheduling delay of the secondary users, provide max-min, weighted max-min and proportional throughput fairness, maximize the number of secondary users that are satisfied in terms of throughput, and take the different delay costs of switching to different frequency bands into account. In addition to heuristic algorithms and simulation based studies, we also present a graph theoretic approach and prove several NP-hardness and inapproximability results, propose polynomial time graph algorithms as well as approximation algorithms."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir insana ait el damarlarıın yapısının boyu dışındaki özelliklerinin zamanla değişmeyişi ve kişiye özgü oluşu,el damar verilerine dayalı biyometrik taıma sistemleri kurma fikrinin ortaya atılmasını sağlamıştır.Bu tezde el damar verilerinin geometrisine dayalı biyometrik taıma sistemlerinde kullanılmaküzere, yeni algoritmalar oluşturulmuştur. Yaklaşım, kayıtlı imgeler ve test imgeleri olarakherhangi bir kısıtlama olmadan, doğal pozlarında, yakın kızıl berisi bantlarda kaydedilmişel damar imgelerini kullanmaktadır. İmgelerdeki damar verilerinin görünürlüğünü arttırmakiçin Gabor filtre bankasından yararlanılmıştır. Gabor filtre bankasının bu amaç içinkullanılması el damar biyometrisinde bir yeniliktir. Dahası, yaklamımız yanlış çıkarılmış eldamar özniteliklerine karşı gürbüzdür. Sistemimiz öncelikle el damar imgelerinden ilgibölgesini çıkartır Bu bölgeye Gabor filtre bankası uygulanarak ilgili bölgedeki damarlardaha da görünür hale getirilir. Geliştirilmiş ilgili bölge üzerine eşikleme, iskelet çıkartmave Çizgi Kenar Haritası (LEM) çıkarma yöntemleri uygulanarak, damar yapısıLEM ve cizgeye dönüştürülür. Kimlik eşleştirmesinden önce, hatalı kayıtlamanın LEMüzerindeki etkilerini gidermek için tercihi iki farklı hizalama yöntemi kullanılır. Bunlardanbiri ana nokta eşleştirmesine, diğeri ise yinelemeli LEM aktarımına dayanmaktadır.Kimlik eşleştirmesi için çeşitli benzerlik puanı ölçme metrikleri kullanılmıştır. BunlarÇizgi Hausdor Mesafesi (LHD), Ağırlılı Çizgi Hausdorff Mesafesi (WLHD), DeğiştirilmişÇizgi Hausdorff Mesafesi (MLHD) ve Çizge Düzenleme Uzaklığı (GED)'dir. WLHD veMLHD, LHD metriğinin düzenlenmesi sonucu el damar verilerinde kullanılmak üzereözelleştirdiğimiz metriklerdir. GED metriğine dayalı hesaplama yapabilmek için biralgoritma geliştirilmiştir. GED, incelenen çizgenin model çizgeye benzemesi içinüzerinde yapmamız gereken en az maliyetteki değişikliğe verilen isimdir.Yaptığımız deneyler, çizgi mesafesine dayalı metriklerin, GED'ye göre dahaiyi sonuçlar verdiğini göstermektedir.","This thesis documents a study in which new algorithms are developed for geometrybased hand vein biometry. Hand vein patterns are assumed not to change overtime except in their size, and they are unique to each individual, hence researchers aimto construct a biometric control system based on hand vein patterns. The approachproposed here is using free-posture captured near infrared hand vein images for bothenrollment and test. We utilize Gabor filters banks to enhance the visibility of handvein segments which is a new thing in hand vein biometry literature. Furthermore, it isrobust against wrongly aligned hand vein features. The region of interests (ROIs) areextracted from hand vein images. In order to increase the visibility of hand veins inthese ROIs, Gabor filter bank approach is applied. Enhanced ROIs facilitate to extractvein line segments as geometric features. To extract these line segments; thresholding,skeletonization and line edge map (LEM) extraction methods are applied on enhancedROIs, respectively. These methods yield the LEM and the graph version of a hand veinstructure. Before identity matching, a preprocessing stage is configured to alleviate theefects of wrong registrations. There are two different methods for alignment correction.The first one is based on keypoint matching, whereas the other is based on translatingthe compared LEMs iteratively. Last but not least, identity matching is done by severaldistance measurement metrics, namely, line segment Hausdor distance (LHD),weighted line segment Hausdorff distance (WLHD), modified line segment Hausdorffdistance (MLHD) and graph edit distance (GED). WLHD and MLHD are different versionsof LHD, that we specialized for hand vein biometry. Additionally, an algorithmis developed to make a measurement on Graph Edit Instance (GED) metric. GED isdefined as the least cost graph edit operation sequence which is used to transform onegraph to another. By examining each metric, we notice that line segment matchingbased methods give more promising results than graph matching."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok indis üzerinden veri öbekleme, olası birçok uygulaması dolayısıyla popüler bir araştırma alanıdır. Bir data matrisinin farklı indislerini aynı anda öbekleyebilmek için farklı yöntemler geliştirilmiştir. Bu yöntemlerin çoğu, ortaya çıkarılacak öbek sayısının öbekleme işleminden önce bilindiğini varsaymaktadır. Ancak gerçek hayat problemlerinde, öbekler ortaya çıkarılmadan önce öbek sayısı hakkında eldeki bilgi sınırlıdır. Buna karşılık parametrik olmayan yöntemler ise iki indis üzerinden öbekleme işlemi ile eş zamanlı olarak öbek sayısını öğrenmektedir. Bu tezde, iki adet parametrik olmayan iki indis üzerinden Bayesci öbekleme yöntemi tanıtılmaktadır. İlk yöntemde iki indisli verinin satır ve sütunları Dirichlet Süreci Karışım Modelleri ile modellenip eş zamanlı olarak öbeklenirken, ikinci yöntemde ise satır ve sütunlar veri üzerinde İzgesel Matris Ayrıştırması uygulandıktan sonra ayrı ayrı öbeklenmektedir. İki indis üzerinden öbekleme yöntemleri farklı veri grupları üzerinde test edilmektedir. Bu veri grupları, üretici bir Gauss modeli ile oluşturulmuş simule bir veri grubu, çeşitli hayvanlar ve özelliklerini içeren bir veri grubu, ülkeler arası ticaret ve diplomasi ilişkilerini gösteren ve beş farklı ağdan oluşan bir veri grubu, ve akciğer kanseri üzerinde bir mikro cihaz çalışmasına ait biyolojik veri grubu olmak üzere dört tanedir. İki indisli verilerde gerçek öbekler genelde tanımsız olduğundan, algoritmaların öbekleme performanslarını değerlendirmek için bağlantı tahmini kullanılmaktadır. Veri noktalarının bir kısmı rastsal olarak seçilip kaldırılmakta, ve bu noktalar aynı öbekteki noktaların benzer olması gerektiği bilgisine dayanılarak tahmin edilmektedir. Tanıttığımız yöntemlerin ilkinde bilgi kaybı olmaksızın verinin tümü kullanıldığından ilk yöntem daha hassas sonuç vermektedir. Buna karşılık ikinci yöntemde veri noktası sayısı önsel olarak oldukça azaltıldığından ikinci yöntemin zaman ve bellek karmaşıklığı çok daha düşüktür.","Multiway clustering is a popular analysis method due to its several potential applications. Various techniques have been developed to cluster different entities of a data matrix simultaneously by taking relational entries into account. Many of those techniques assume that the number of clusters to be discovered is known prior to the clustering operation. However, in real-world problems we have limited knowledge about the number of clusters before discovering them. Nonparametric methods, on the other hand, perform biclustering and learn the number of clusters concurrently. In this thesis, we introduce two nonparametric Bayesian biclustering methods that are applicable on two-way data. In the first method we model the rows and columns of the two-way data using Dirichlet Process Mixture Models and cluster them simultaneously, whereas in the second one we cluster the entities separately after applying spectral matrix decomposition on the data. We apply the biclustering algorithms on four different datasets; a simulated dataset created by a generative Gaussian model, a dataset of animals and their attributes, a cross-national trade and diplomacy dataset with five different relational networks, and a biological dataset from a microarray study of lung cancer. Since there are few real world data annotated with ground truth biclusters, we generally utilize link prediction in order to evaluate biclustering performances. We randomly remove data entries and predict them based on the fact that the entries in the same bicluster are similar to each other. First biclustering method results in higher accuracy since it makes use of all relational information in the data while the spectral method reduces dimensionality of the data prior to the clustering operation. On the other hand, computational complexity of spectral method is far less due to the reduction in the data entries to process."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İstisnai durumlar insanların hayatında önemli bir yer oluşturmaktadır. Bir kişi göreviyle ilgili üzerine düşeni yapmadığından, veya bulunulan ortamdan kaynaklanan nedenlerden dolayı işler planlandığı gibi gitmediğinde, beklenmedik durumlar oluşur. İnsanların istisnai durumlarla karşılaştıklarında normal çalışmalarına geri dönebilmeleri için bunlarla başa çıkmaları gerekir. Fakat bu, insanlar için başarması kolay bir iş değildir. Öncelikle, bir şeylerin yanlış gittiğini anlamalıdırlar (tespit). Daha sonra, sorunun neden kaynaklandığını bulmalıdırlar (teşhis). Bunlara ek olarak, bazı durumlarda ileride istisnai bir durum oluşacağını önceden belirlemek bu durumu önlemek için gerekli adımların atılmasına yardımcı olur (öngörü). Bunlara dayanarak, bu tezde etmenlerin istisnai durumlar üzerine otomatik olarak akıl yürütmelerini öneriyoruz. Problem alanlarını çok etmenli sistemler olarak modelleyip, etmenler arasındaki etkileşimi taahhütler ile şekillendiriyoruz. İstisnai durumlarla başa çıkabilmek için mantık tabanlı otomatik metodlar sunuyoruz. Bu metodların geçerliliğini ve bütünlüğünü ispatlıyoruz. Bu metodları, oluşabilecek istisnai durumlar açısından farklı karakteristikleri olan sosyal ağlar ve e-ticaret alanlarında inceliyoruz. Bu tezdeki katkılarımız üç tanedir. İlk olarak, literatürde yer alan istisnai durumların kapsamını sadece taahhüt ihlali ile sınırlı kalmayacak şekilde genişletiyoruz. İkinci olarak, istisnai durumları daha oluşmadan fark edebilecek model denetleme tabanlı bir öngörü sistemi sunuyoruz. Son olarak, taahhütler arasındaki zamansal ilişkileri bir etmenin işleyişinde neyin yanlış gittiğini teşhis edebilmek için inceliyoruz.","Exceptions constitute a significant portion of people's lives. When things do not go as planned, due to environmental reasons or because one does not bring about his responsibility in a given task, unexpected situations occur. When faced with exceptions, people need to deal with them in a timely fashion in order to restore proper working. However, dealing with exceptions is not an easy task for people to accomplish. First, it requires understanding that something has gone wrong (detection). Second, the actual source of the problem needs to be identified (diagnosis). Moreover, in some situations, identifying that an exception will possibly occur in the future helps changing the course of previously planned actions in order to avoid the exception (prediction). Accordingly, this thesis proposes to use agents for automating the reasoning on exceptions. We model the problem domains with open multiagent systems, and use commitments to formalize agent interactions. We propose automated methods based on computational logic for detecting, predicting, and diagnosing exceptions. We prove that our methods are sound and complete.We study our methods on two domains, online social networks and e-commerce, which exhibit different characteristics forthe exceptions that may arise in them. Our specific contributions in this thesis are three-fold. First, we extend the scope of detected exceptions in the literature such that an exception is not limited to a commitment violation. Second, we provide a prediction system based on model checking that identifies exceptions before they even occur. Finally, we investigate the temporal relations among commitments in orderto diagnose what has gone wrong during an agent's execution."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde dağıtık kanal seçme ve merkezi kanal atama problemlerine odaklanıyoruz. İlk konu için spektrum paylaşım verimliliği ile ilgilenirken ikinci kısımda ayrıca enerjiverimliliğini de dikkate alıyoruz. Öncelikle, spektrum parçalanmasını azaltarak spektrum paylaşım verimliliğini arttıran bencil olmayan bir dağıtık kanal seçim algoritmasıöneriyoruz. Ayrıca, önerimiz için Sürekli Zaman Markov Zincirleri kullanarakbir analitik model sunuyoruz. Bu tezde ayrıca iş oranı açısından ciddi bir şekildeödün vermeden, sadece fırsatçı olan çizelgeleyicilerden enerji verimliliği ve adalet nosyonuaçısından daha iyi başarım gösteren çeşitli merkezi kanal atama algoritmalarıgeliştiriyoruz. Öncelikle, spektrum doluluk bilgisini beyaz spektrum veritabanındanalan bir BR Ağı'na (BRA) odaklanıyoruz. İletim, boşta bekleme ve hem süreklihem parçalı spektrum organizasyonunda kanal değiştirme sürelerini dikkate alarakbuluşsal algoritmalar geliştiriyoruz. Son olarak, BRlerin konuşmadan-önce-dinle erişim yaklaşımını uyguladıkları bir BRA'na odaklanıyoruz. Önceki önerimizden farklı olarak,bu çizelgeleyici, BRlerin oluşturduğu karışımın herhangi bir Birincil Kullanıcı (BK)kanalında tolere edilebilir limitleri aşmamasını garanti eder. Bununla birlikte, buçizelgeleyici birincil kanallar arasında boş olma ihtimallerine göre ayrım yaptığı gibimerkeze giden ve merkezden gelen hattaki kontrol için harcanan süreyi dikkate alır.Çizelgeleme kontrol yükü ve BK karışım ihtimali arasındaki ödünleşimi dikkate alarak yüksek iş oranını sağlayan çerçeve süresini belirliyoruz. Başarım çalışmaları önerdiğimizyöntemin iş oranını en iyileyen çizelgeleyiciye benzer iş oranı başarımı gösterdiğini ancakondan daha az enerji harcadığını göstermektedir.","In this thesis, we focus on distributed channel selection and centralized channel assignment in cognitive radio networks (CRN). For the former topic, we are concerned with the efficiency of spectrum sharing whereas in the latter, we also aim to improve energy efficiency of the CRN. First, we propose a non-selfish distributed channel selection scheme which improves the efficiency of spectrum sharing by mitigating thespectrum fragmentation. We also present an analytical model for our proposal using Continuous Time Markov Chains. In this thesis, we also devise various centralized channel assignment algorithms that outperform pure opportunistic schedulers in terms of energy efficiency and fairness notion without significantly trading off throughput efficiency. Initially, we consider a CRN which acquires channel occupancy informationfrom a white space database. We develop heuristic algorithms considering transmission, idling and channel switching periods in both contiguous and fragmented spectrum. Finally,we consider a CRN in which CRs apply a listen-before-talk access approach. Different from our previous proposal, this scheduler ensures that interference caused by CRs does not exceed the tolerable limits in any of the primary user (PU) channels. In addition, it considers the differences among the PU channels in terms of probabilityof being idle as well as the control messaging overhead in downlink and uplink. Considering the tradeoff between the scheduling overhead and PU interference probability,we identify the frame length achieving high throughput. Simulation results show that our proposal achieves high throughput performance comparable to a throughput maximizing scheduler but it consumes lower energy than the latter."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Belirli bir yazılım mimarisine uyan yazılım yapılarının belirtimi yazılım tasarımında atılan ilk adımdır. Belirli bir yazılım mimarisine uyan yazılım yapıları yazılım geliştikçe tutarsızlaşan ilk olgu olabilir. Bizce bu durumun iki mantıklı açıklaması vardır. İlk olarak, belirli bir yazılım mimarisine uyan yazılım yapılarının belirtimi basit bir iş değildir. Hatırı sayılır miktarda çaba gerektirir ve bu çaba yazılım geliştirme sürecinin ileriki aşamalarında önemsizleşebilir. İkinci olarak, belirli bir yazılım mimarisine uyan yazılım yapıları belirtildikten sonra tanımlanan yazılım bileşenleri ve birimleri, en başta seçilen yazılım mimarisine uymayabilir. Bu çalışmamızda, yeni bir alana özgü dil olan DSL-SA önerilmektedir. DSL-SA belirli bir yazılım mimarisine uyan yazılım yapılarının daha kolay belirtmek ve yukarıda bahsedilen sorunları çözmek için yapılan bir girişimdir. DSL-SA ile birlikte, DSL-SA Editor olarak adlandırlan bir yazılım aracı geliştirilmiştir. DSL-SA Editor belirli bir yazılım mimarisi biçemine karşılık gelen yazılım yapılarının belirtilmesinde kullanılabilir. DSL-SA Editor'u kullanılarak, ?pipes-and-filters? yazılım mimarisi biçemi, katmanlı yazılım mimarisi biçemi ve özgür yazılım mimarisi biçemine uyan yazılım yapıları belirtilebilir. DSL-SA Editor yazılım yapılarının belirli bir yazılım mimarisi biçemine uyup uymadığını denetleyebilir. DSL-SA Editor aynı zamanda yazılım yapısı belirtiminden üst düzey kaynak kodları üretebilir. Son olarak, bu çalışmada, DSL ve DSL-SA Editor'un belirli bir yazılım mimarisine uyan yazılım yapılarını belirtmede nasıl kullanılabileceğini göstermek amacıyla üç tane durum çalışması gösterilmektedir.","The specification of software structures that conform to specific software architectures is the first step in software design during software development. Software structuremay be the first design artifact that becomes inconsistent as software evolves. We believe this issue has two logical explanations. Firstly, specifying software structure that conforms to specific software architecture is not easy task. It requires considerable effort and this effort can be useless in future during software development. Secondly, once software structure that conforms to specific software architecture is defined, subsequent software components and modules may not conform to the software architecture that was selected. In this thesis work, a new specification language, called Domain-Specific Language for Software Architecture Specification(DSL-SA), is proposed. It is an attempt to specify software structure that conforms to a specific software architecture easily and to overcome problems mentioned above. In association with DSL-SA, a software tool, called DSL-SA Editor, has been developed. DSL-SA Editor will be used tospecify software components that correspond to specific software architecture styles. By using DSL-SA Editor, one can specify software structures that conform to pipes-and-filters architectural style, layered architectural style and free architectural style. DSL-SA Editor supports the validation of software structures, to see whether the software structure conforms to the selected architectural style. DSL-SA Editor also supports high-level source code generation from software structure specification. We present three case studies to show how DSL-SA and DSL-SA Editor can beused to specify software components that correspond to a specific software architecture."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma, EKG sinyallerindeki anormalliklerin tespiti için kural çıkarım ve öznitelik seçim sistemi sunar.Kardiyak aritminin varlığı ve yokluğu arasındaki ayrımın yapılması ve öznitelik seçimi için Genetik Algoritması-Yapay Sinir Ağı (GA-YSA) Yaklaşımı kullanılmıştır. Bu süreci takiben, aritmi teşhisine rehberlik etmesi amacıyla kural seti çıkarılmıştır. Bu kural setleri, seçilmiş özniteliklere dayanılarak çıkarılmaktadır; çünkü öznitelik seçimi olmadan yapılan kural çıkarımı insanın anlayabileğinden daha karmaşık sonuçlar üretebilmektedir. Kural çıkarımında, C4.5, RIPPER, PART ve HotSpot metotları uygulanmıştır. Bu çalışmada kullanılan EKG veri kümesi, UCI Aritmi Veritabanı'ndan elde edilmektedir. Bu veri kümesindeki tüm anomaliler, tek bir anormal sınıf altında toplanırken geriye kalanlar normal sınıfı oluşturacak şekilde düzenlenmiştir. Karşılaştırma amacıyla k en yakın komşu (k-NN), Destek Vektör Makineleri (SVM), Naive Bayes ve Bayes Ağları, EKG veri kümesine uygulanmıştır. Boyut indirgemek amacıyla ise, özyineli nitelik çıkarımı (RFE-SVM), korelasyon tabanlı nitelik seçimi (CFS), temel bileşen analizi (PCA) ve faktör analizi (FA) yöntemleri kullanılmıştır. Deney sonuçlarına göre, GA-YSA yöntemi, diğerlerinden daha iyi sonuç vermiştir.","This paper presents rule extraction and feature selection system to detect abnormality in ECG signals.Genetic Algorithm-Neural Network (GA-NN) Approach is used to distinguish between the presence and absence ofcardiac arrhythmia and perform feature selection. Following this process, rule sets are extracted in order to guide the diagnosis of cardiac arrhythmia. The rule sets are extracted based on selected features because rule extraction without feature selection may result in rules to be more complex than human may realize. C4.5, RIPPER, PART and HotSpot methods are used to perform rule extraction. The ECG dataset used in this study is obtained from UCI Arrhythmia Database. In this dataset, all the anomalies are grouped into one abnormal class and the rest is grouped into one normal class. As a comparison, k-Nearest Neighbor (k-NN), Support Vector Machines (SVM), Naive Bayes and Bayesian Networks have been tested on the arrhythmia dataset. For dimensionality reduction purpose, recursive feature extractor (RFE-SVM), correlation based feature selection (CFS), principal component analysis (PCA) and factor analysis (FA) have been applied. According to test results, GA-NN outperforms other techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dijital ortamdaki metinler ve yapay öğrenme tekniklerindeki büyük artış, metinleri otomatik sınıflandırma çalışmalarının artmasına neden oldu. Metin sınıflandırma, temel olarak, öğrenme modellerini kullanarak, daha önceden görülmemiş dökümanları önceden belirlenmiş sınıflara atamaktır. Geleneksel metin sınıflandırma, herbir dökümanı, istatistiksel olarak inceleyerek belirli bir dizi haline getirmeyi hedefler ve ardından, metinleri sınıflandırmak için yapay öğrenme tekniklerini kullanır.Bu tez kapsamında, geleneksel metin sınıflandırma yöntemlerine ek olarak, metinlerde bulunan kelimeleri türlerine gore gruplandırıyoruz ve her bir türün sınıflandırma başarısındaki katkısını hem ayrı ayrı hem beraberce değerlendiriyoruz.Bunların yanı sıra, metinlere WordNet kullanarak, anlamsal özniteliklerden(semantic features) olan; eş anlamı(synonym), genel anlamı(hypernym), özel anlamı(hyponym), parça anlamı(meronyms) ve konuyu(topic) ekliyoruz. Bu sayede metinlere anlam(semantic) eklemiş oluyoruz. Bu aşamada yaşanılacak sorunlardan bir tanesi, bu anlamlar için anlam belirsizliği(ambiguity) oluşmasıydı. Bu problemi geliştirdiğimiz bir yöntem ile ortadan kaldırmaya çalıştıkBu tezdeki temel amacımız, anlamsal özniteliklerin metin sınıflandırmaya olan katkılarını araştırmak ve bu sayede sınıflandırmadaki doğruluk başarısını arttırmaktır.","By the huge increase of data volume in the digital environment and the machine learning techniques, studies on automatic categorization of text documents is increased. Text categorization is simply assigning predefined label to unseen documents by using some learning models. Traditional text categorization is based on statistical analysis of documents to represent the document with some vectors. And then, one of the machine learning techniques is used for categorization of documents.In addition to the traditional text categorization techniques, in this thesis, we group words by their part of speech tag and investigate the effect of each part of speech individually and jointly in the classification accuracy.Furthermore, we incorporate semantic features such as synonyms, hypernyms, hyponyms, meronyms and topics into the documents by using WordNet. Thus we add meaning of terms. One of the problems faced in this study is that not all the semantic features really related to the document, in other words synsets generate ambiguity. To solve the problem we introduce a new method to eliminate the ambiguity.In this thesis the main objective is to investigate the contribution of semantic features. By incorporating semantic features we add meaning to the documents and thus the classification accuracy increased."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz Örgü Ağları örgü şeklinde birbirlerine bağlanmış radyo düğümlerinden oluşan haberleşme ağlarıdır. Son yıllarda bu tip ağlar üzerinde görüntülü denetleme, video konferans gibi pek çok uygulama gerçeklenmiştir. Kablosuz örgü ağları daha popüler hale geldiği ve boyutları ve karmaşıklığı artmaya devam ettiği için çoklu sekmesi olan örgü ağları, bant genişliği bozulması, radyo karışma ve ağ gecikmesi problemleri gibi sorunlara karşı daha hassas hale gelmiştir. Öyle ki ses ve video uygulamalarının yoğun olarak çalıştığı uç örneklerde gecikme ve RF karışımı kabul edilemez seviyelere ulaştığında tam bağlantı kopması meydana gelebilmektedir. Tez çalışmamızda geniş ölçekli alanlarda kablosuz örgü ağları kullanılarak video çoklu-gönderimi üzerinde çalışılmıştır. Çalışmanın odağı düşük kapasiteli muhtemel çoklu sekmeli kablosuz yollardan sakınmak için alternatif rota seçeneği sunan internet erişim giriş kapılarını kullanmaktır. Çalışmada genel olarak ?Kablosuz Örgü Ağlarında Erişim Giriş Kapısı Vasıtasıyla Kaynaktan Haberdar Video Çoklu Gönderimi? makalesindeki deneyimsel algoritma kümesinden ilham alınmıştır; iki aşamalı tümleştirilmiş yapı algoritması (TIA), ağırlıklandırılmış erişim giriş kapısı yükleme algoritması (WGU), bağlantı kontrollü yönlendirme ağacı algoritması (LCRT). TIA ve LCRT algoritmalarının her ikisi için de ikişer algoritma iyileştirmesi geliştirilmiş ve sonrasında yeni yapının katkılarını tespit edebilmek için performans analizi yapılmıştır.","Wireless mesh networks (WMN) are the communication networks made up of radio nodes organized in a mesh topology. In recent years there are many applications like video survelliance, video conferencing that have been implemented over these kind of networks. As wireless mesh networks become more popular and their size and complexity continues to grow, mesh networks that contain multiple hops become increasingly vulnerable to problems such as bandwidth degredation, radio interference and network latency. In extreme cases, where voice and video applications are heavily at work, a complete connection loss can occur when latency and RF interference reach unacceptable levels. This thesis work studies video multicasting in large scale areas using wireless mesh networks. The focus is on the use of internet access gateways that allow a choice of alternative routes to avoid potentially lengthy multi-hop wireless paths with low capacity. We mainly get inspired from the set of heuristic-based algorithms that were described at the paper named ?Resource aware video multicasting via Access Gateways in Wireless Mesh Networks?: the two-tier integrated architecture algorithm (TIA), the weighted gateway uploading algorithm (WGU) and the link-controlled routing tree algorithm (LCRT). Two enhancements were developed for both TIA and LCRT, and afterwards performance analysis have been made to obtain the contribution of the new scheme."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal ağlar İnternet'teki en önemli bilgi kaynaklarından biridir. İnsanlar her hangi bir konudaki bilgilerini, hislerini, görüşlerini ve ilginç bulduğu İnternet adreslerini bu ağlarda paylaşırlar. Bir mikroblog sistemi, kullanıcılarının oldukça kısa uzunlukta fakat sıkça yazdıkları özel bir çeşit sosyal ağdır. Kullanıcılar diğerlerine abone olarak yazdıklarını takip edebilir. Ancak bir konu ile ilgili takip etmeye değer mikroblog kullanıcısı bulmak bu tip sistemler için ciddi bir problemdir. Bu sorunun kaynağı yüz milyonlarca mikroblog kullanıcısının bu sistemlerde yaptıkları katkının, sistemin doğası gereği sınırlı uzunluktaki yazılarında dağınık bir biçimde yer almasından kaynaklanmaktadır. Bu tezde bir sorguya karşılık, sıralanmış olarak mikroblog kullanıcısı öneren içerik bazlı bir tavsiye sistemi modeli sunarak bahsettiğimiz problemi çözmeye çalışıyoruz. Bu model içeriğe odaklandığı kadar tavsiye istenen konu ile ilgili mikrobloga yapılan katkıya ilişkin bazı ölçümleri de sürecin içine dahil etmektedir. Tezde modelin formal yapısını ve örnek bir uygulaması ortaya konmaktadır. Çalışmanın sonunda bir grup kullanıcının kendi sorgularına karşılık uygulamanın ürettiği çıktıları değerlendirmesi istenmiştir. Bu testin sonucu ile hem modelin başarısını ortaya koyuyor hem de gelişim alanlarını tartışıyoruz.","Social networks are one of the most significant information sources on the Internet. People share information, their feelings, their opinions and interesting links. A microblogging system is a special kind of social network in which users post short but frequent update messages. Microbloggers subscribe (follow) to posts of others. However, finding relevant microbloggers to follow is a major problem, due to the massive quantity of users as well as the difficulty of mentally aggregating fragmented short contributions. In this thesis, a content based recommendation model is proposed, which given a query recommends a set of ranked microbloggers. This model focuses on the content of posts as well as other characteristics of microbloggers to evaluate the relevance of microbloggers to the query. This thesis describes the model and a prototype implementation. Finally the outcome of a test with 41 users is discussed along with observations and recommendations for improved recommendations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Arazilerin gölgelenmesi zor bir problemdir. Gölge hacimleri ve gölge haritalarıgibi genel algoritmalar yükseklik haritası geometrisi ile çok iyi çalışmamaktadır. Gölgehacimleri binlerce üçgene bölünmüş olan yükseklik haritaları için çok pahalı bir operasyonolan silüet çıkarımını gerektirir. Gölge haritaları daha iyi bir alternatif olmaklaberaber kendini gölgeleme ve kırpıklanma hataları ortaya çıkarır. İlaveten gölgeharitaları çalışmak için iki çizim geçişineihtiyaç duyar; bu da yükselik haritasının her sahnedeiki kez çizilmesi anlamına gelir. Biz bu tezde güneşin doğrusal ışığından kaynaklananarazi gölgelerini oluşturmak için yeni bir algoritma öneriyoruz. Bunun için yükseklikharitasının gölge hacminin ayrık bir versiyonu olan gölge yükseklik haritasının (GYH)kullanımını öneriyoruz. GYH'deki bir piksel gölgenin mevcut yükseklik haritası lokasyonuüzerindeki yüksekliğini temsil eder. Bu gölge haritalarından, gölge hacimlerindenve ışın izleme yöntemlerinin parçalarından oluşan hibrit bir metoddur. Her güneş ışığıyönü için arazi üzerine parallel güneş ışığı ışınları fırlatarak yeni bir GYH oluşturuyoruz.Araziye veya herhangi bir yüzeye ait bir piksel kendi yüksekliğini GYH'den örneklediğigölge yüksekliği ile karşılaştırır ve gölge yüzeyinin altında ise kendisini gölgede olarakişaretler. Gerçekçi yumuşak gölgeleri simüle edebilmek için iki model tanımlıyoruz.Bunlardan ilki sabit yarıgölge yükseliği, ikincisi de adaptif olarak değişebilen yarıgölgeyüksekliği kullanmaktadır. Testlerimize göre algoritmamız modern bir gölge haritasıtürevi olan Paralel Bölünmüş Gölge Haritaları (PBGH) yönteminden hem kalite hemde performans bakımından daha üstün çalışmaktadır.","Shadowing terrains is a challenging problem. Mainstream shadowing algorithmslike shadow volumes and shadow maps, do not work very well with height map geometry.Shadow volumes need silhouette extraction which is a very expensive operationfor a height map tessellated into thousands of triangles. Shadow mapping is a betteralternative, but it suffers from aliasing and self-shadowing artifacts. Additionally,shadow mapping needs two rendering passes to function, this means rendering theheight map twice in each frame. In this thesis, we propose a new specialized terrainshadowing algorithm to generate shadows caused by the directional light of the Sun.We propose the use of shadow height map (SHM), which is a discretized version of theshadow volume of the height map. A pixel in the SHM texture represents the height ofthe shadow on the current height map location. It is a hybrid method which borrowselements from shadow mapping, shadow volumes and ray casting. For each sunlightdirection we generate a new SHM, by casting parallel sunlight rays onto the terrain.We rotate the SHM texture, such that each ray corresponds to a single column of theimage and we apply a simple, iterative 2D shadow volume extraction algorithm on eachcolumn, storing the current height of the shadow to the current pixel in the column,as the algorithm progresses. A pixel of an arbitrary object or to the terrain comparesits world height with the sampled shadow height from the SHM and marks itself inshadow if it is below the shadow surface. We define two models to simulate realisticsoft shadows, first, by using a constant penumbra and second, by using an adaptivelyvarying penumbra height. According to our tests, our algorithm performed better thanthe state-of-the-art shadow mapping variant, Parallel Split Shadow Mapping (PSSM),both in the quality and performance aspects."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal ağ platformları ve Web X.0 gibi Web uygulamaları, ortalama Web kullanıcılarını bilgi tüketicileri sıfatından içerik yaratan kimlikler haline getirmişlerdir. İçerik bakımından düşünülürse bu geçiş başarılı gözükse de, aynı şeyi uygulama gidişatı oluşumu konusunda söylenemez. Ortalama Web kullanıcıları, Web üzerinde uygulama davranışlarını tanımlayacak bilgi birikimine sahip değillerdir. Web'in hesaplamaya yönelik kuvvetli tarafları, Web bilgi birikimine sahip bilgi teknolojilerini bilen kişilerce kullanılabilmektedir. Çok basit Web uygulamarı bile ortalama Web kullanıcıları tarafından tanımlanamamaktadır. Bir amaca yönelik bir araya gelen topluluklarda basit Web uygulamaları geliştirilmesi üzere WeFlow platformu geliştirilmiştir. Her topluluğun farklı hedefleri, farklı veri gereksinimleri ve farklı veri işleme kuralları vardır. Bu tür gereksinimler mevcut sosyal ağ platformları ile kısmi olarak gerçeklenirken, WeFlow uzun vadede oluşturulan içerikten anlam çıkarabilmeyi hedeflemektedir. Enteresan bir diğer uygulamalar insan gücünün kullanıldığı Human Computation alanıdır. Bu kapsamda, bir iş küçük parçalar haline getirilerek bir akış şeklinde ifade edilmektedir. Bu iş parçaları arasındaki sıra ve verinin akışı, bu iş parçalarının kimler tarafından yapılacağı tanımlanmaktadır. Amaç bir işi gerçeklemek ve gerekli verinin insan gücü kullanılarak bir araya getirilmesidir. Bu çalışmada, WeFlow isimli iş akışı modelimizi öneriyoruz. Sanal ortamdaki kullanıcılar, bu modeli kullanarak Web uygulamalarının nasıl davranması gerektiğini tanımlayabilecekler. İzlenen yol: (i) iş akışı tanımını oluşturmak, (ii) iş akışı tanımı doğrultusunda, Web uygulaması üretmek, (iii) iş akışı tanımı doğrultusunda, Web uygulamasını yürütmek, izlemek ve yönetmektir.","Web applications, such as social networking platforms and Web X.0 applications have transformed average users from consumers to producers of content. While this transition has been very successful with respect to content, the same can not be said for behavior generation. Non-savvy Web users have practically no ability to introduce any behavior on the Web. The computational powers offered by the Web are limited to those who are in the know or can afford to develop applications. Yet, there are many simple applications that average users could conceive and utilize if they were empowered to introduce behavior. This work aims to empower average web users with the ability to create simple web applications for purposeful communities. We suggest an environment with information and processes specific to a communities needs, as opposed to the ad hoc information sharing and coordination achieved via social networking platforms, in order to retain the long term value of the generated information. An interesting class of Web applications are human computation applications, where tasks are distributed among humans and computers based on their suitability for performing those tasks. Web based human computation applications seem appropriate for purposeful communities. This thesis presents a framework for the development of human computation applications for purposeful communities. In order to create such an environment, we propose a web based workflow framework. The WeFlow Framework, supports the specification, generation, and execution of community specific virtual environments. These environments are based on a workflow model, which are defined by the communities that use them. The environment is based on a workflow model, which consists of tasks, control and data flow among tasks, and people who perform those tasks. A WeFlow framework prototype is shown by examples and case studies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İngilizcede crawler diye adlandırılan İnternet Robotu yazılımları bir web sayfasındaki tüm bağlantıları gezerek bu sitenin haritasını çıkartan otomatikleştirilmiş yazılımlardır. Bir web sitesinin haritasının çıkartılması, o siteye yapılacak bir saldırı için temel teşkil edeceğinden otomatikleştirilmiş saldırılar için büyük önem taşımaktadır. Bu yüzdendir ki otomatik web açıklık tarayıcılarının hepsi, taramaya başlamadan önce mutlaka sitenin haritasını çıkartmak için bağlantı keşfi işlemi (crawling) gerçekleştirir. İnternet robotları, otomatik web açıklık taramalarına temel olmak dışında, içerik hırsızlığı için de sıkça kullanılmaktadır. Otomatikleştirilmiş bir şekilde bir sitenin tüm içeriğinin sayfa sayfa gezilerek başka bir web sitesine kopyalanması konusunda internet robotları büyük rol oynamaktadır.Bu tezde web sunucular için internet robotlarına karşı bağlantı keşfi önleyici yöntemleri içeren internet robotu engelleyici modülü geliştirilmiştir. mod_antiCrawl C dili ve Apache API'si kullanılarak yazılmış bir Apache modülüdür. mod_antiCrawl'ın internet robotu yakalama ve engelleme yetenekleri sayesinde sunucular, zararlı robot yazılımlardan korunmaktadır. Yapılan performans değerlendirme ölçümlerinde, modül aktif konuma getirildikten sonra internet robotlarının elde edebildikleri bulgu sayısında en az %70'lik bir düşüş sağlandığı görülmüştür. Bu oran mod_antiCrawl içerisindeki internet robotı karakteristiğine daha uygun fonskiyonların da yardımıyla %90 seviyesine çıkabilmektedir.","A web crawler can be defined as automated software that extracts website maps by visiting all the links in a website. Website map extraction process can be used to build a basis for a web attack. Hence, crawling plays an important role in automated attacks. The most automated vulnerability scanners perform crawling before vulnerability tests in order to determine overall map and attack surface. Besides automated scanning features, crawlers can also be used for content theft. By utilising a crawler, one can copy all the pages and content of a website by visiting all pages in an orderly manner.Anti-crawling can be defined as a set of mechanisms that prevents websites from being crawled by automated crawlers. In this thesis, a set of anti-crawling mechanisms are combined into an Apache web server module called mod_antiCrawl. mod_antiCrawl is developed in C language by using Apache API and it has crawler detection and inhibition capabilities to protect servers from malicious crawlers. The performance of mod_antiCrawl has also been studied and our results show that website map discovery by crawlers decreases at least 70% after mod_antiCrawl is activated. This ratio increases to 90% by enabling different functionalities of the module."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çok boyutlu veri yapıları için genel istatistiksel bir modelleme sistemi önermektedir. Kullandığımız yöntem istatistiksel grafik modelleri ile tensor ayrışımı arasında bir bağ kurarak çok boyutlu ayrışım modellerinin çeşitli maaliyet fonksiyonları için tasarlanmasını ve çözümlenmesini sağlar. Beklenti-En Büyütme (EM) tekniği ile Exponensiyal Sapma Modellerinin olabilirlik değerlerini en iyileyerek beta-divergence için yinelemeli güncelleme denklemlerini elde ediyoruz. Özel durum olarak Öklid, Kullback-Leibler ve Itakura-Saito maliyet fonksiyonlarını kullanıyoruz. Bu denklemleri, daha sonra, Çarpanlı Güncelleme Kuralı (MUR) ve Öklid maliyet fonksiyonu için Dönüşümlü En Küçük Kareler (ALS) denklemlerine dönüştürüyoruz.Ardından KL maliyet fonksiyonu kullanan pozitif parametreli alternatif modeller arasında seçim yapabilen bir yöntem geliştirdik. Bu yöntem marjinal olabilirlik değerini (doğrudan hesaplanamadığından) alt sınırdan yuvarlayan variational Bayes tekniğine dayanmaktadır.Ayrıca, EM yanında, Geneleştirilmiş Doğrusal Modeller (GLM) teorisinin Fisher Skoru olarak bilinen adım uzunluğunu sınırlandırarak pozitif ve reel sayılar için ayrı genel güncelleme denklemleri geliştirdik. Bu sistemi daha sonra birden fazla gözlem tensorlerin aynı anda çarpanlara ayrılma işleminde kullandık. Geliştirdiğimiz sistemi sentetik verilerle ve ayrıca müzik restorasyon problemini çözmek için kullandık.","This thesis proposes a unified probabilistic framework for modelling multiway data. Our approach establishes a novel link between probabilistic graphical models and tensor factorization, that allows us to design arbitrary factorization models utilizing major class of the cost functions while retaining simplicity. Using an expectation-maximization (EM) optimization for maximizing the likelihood (ML) and maximizing the posterior (MAP) of the exponential dispersions models (EDM), we obtain generalized iterative update equations for beta divergence with Euclidean (EU), Kullback-Leibler (KL), and Itakura-Saito (IS) costs as special cases. We then cast the update equations into multiplicative update rules (MUR) and alternating least square (ALS for Euclidean cost) for arbitrary structures besides the well-known models such as CP (PARAFAC) and TUCKER3.We, then, address the model selection issue for any arbitrary non-negative tensor factorization model with KL error by lower bounding the marginal likelihood via a factorized variational Bayes approximation. The bound equations are generic in nature such that they are capable of computing the bound for any arbitrary tensor factorization model with and without missing values.In addition, further the EM, by bounding the step size of the Fisher Scoring iteration of the generalized linear models (GLM), we obtain general factor update equations for real data and multiplicative updates for non-negative data. We, then, extend the framework to address the coupled models where multiple observed tensors are factorized simultaneously. We illustrate the results on synthetic data as well as on a musical audio restoration problem."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bağlantı tahmini gözlemlenen bağlantıların özniteliklerine göre iki varlık arasında bir bağlantının varlığı veya yokluğu sonucuna varılması problemidir. Literatürde, (i) gözlemlenmeyen ve (ii) zamansal olmak üzere iki tip bağlantı tahmini problemi bulunmaktadır. Her iki problem için de, bağlantı tahminini bir matris ve tensor tamamlama problemi olarak değerlendiren saklı özellik tabanlı modeller üzerinde çalışılmaktadır. Bu tezde, bağlantı tahmini için tensör ayrışım modellerinin olasılıksal yorumlanmasına dayalı çeşitli yaklaşımlar kullanmaktayız. İlk olarak veri kümelerini herhangi bir tensor ayrışım modeli ile analiz edebilen Olasılıksal Saklı Tensör Ayrışımı ile tanımlanmış, daha sonra ortak tensörler içeren modellerin eşzamanlı ayrışımı ile ortak saklı faktörler çıkarabilen bir algoritmik çerçeve olan Genelleştirilmiş Bağlaşımlı Tensör Ayrışımı dahilinde tanımlanmış farklı ayrışım modelleri önermekteyiz. Tensör ayrışım metodlarında varyasyonel Bayes yoluyla tam Bayesci çıkarım sunmakta, daha sonra çıkarımı geliştirmek için bağlaşımlı tensör ayrışımı için varyasyonel Bayesci çıkarım algoritması türetmekteyiz. Ek olarak, birden fazla gözlem tensörü mevcut olduğu durumlardaki modeller için eşzamanlı tensor ayrışımını gerçekleştirebilen güncelleme denklemleri oluşturmaktayız. Heterojen verilerin ayrışımında kullanılan önceki çalışmalar ya tek bir ıraksaya veya belirli bir tensör ayrışım modeline odaklanmaktadır. Ancak, heterojen veri analizinde temel zorluklardan biri doğru tensör modelini ve ıraksayı bulmaktır. Bu nedenle, bu çalışmada farklı tensör modelleri ve ıraksayları ele almaktayız.Sentetik ve gerçek veri kümeleri üzerinde gerçekleştirdiğimiz deneyler birden fazla kaynaktan gelen verilerin bağlaşımlı tensor ayrışım yöntemi ile ortak analizinin ve varyasyonel Bayesçi yaklaşımının bağlantı tahmin performansını artırmakta olduğunu ve doğru ıraksay ve tensör model seçiminin önemini göstermektedir.","Link prediction is the problem of inferring the presence, absence or strength of a link between two entities, based on properties of the other observed links. In the literature, two related types of link prediction problems are considered: (i) missing and (ii) temporal. In both cases, latent variable models have been studied for link prediction tasks that consider link prediction as a noisy matrix and tensor completion problem. By using a low-rank structure of a dataset, it is possible to recover missing entries for matrices and higher-order tensors.In this thesis, we use several approaches based on probabilistic interpretation of tensor factorizations: Probabilistic Latent Tensor Factorization that can realize any arbitrary tensor factorization structure on datasets in the form of single tensor and Generalised Coupled Tensor factorization that can simultaneously fit to higher-order tensors/matrices with common latent factors.We present full Bayesian inference via variational Bayes, then we derive variational inference algorithm for Bayesian coupled tensor factorization to improve the reconstruction over Bayesian factorization of single data tensor and form update equations for these models that handle simultaneous tensor factorizations where multiple observations tensors are available.Previous studies on factorization of heterogeneous data focus on either a single loss function or a specific tensor model of interest. However, one of the main challenges in analyzing heterogeneous data is to find the right tensor model and loss function. So, we consider different tensor models and loss functions for the link prediction.Numerical experiments on synthetic and real datasets demonstrate that joint analysis of data from multiple sources via coupled factorization and variational Bayes approach improves the link prediction performance and the selection of the right loss function and tensor model is crucial for accurate prediction of unobserved links."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"C izgeler ogeler arasındaki iliskileri ifade etmek icin herhangi tur ogeler arasındakiiliskileri ifade etmek icin oldukca farklı disiplinlerde kullanılan kuvvetli matematikselaraclardır. Bu calısmada, rassal obek cizgeleri ve rassal obek cizge serilerindesayısı bilinmeyen coklu degisim noktası algılama problemi uzerinde calstık. Rassalobek cizge modeli, iliskisel veri kumeleme algoritmalarının bir dalıdır. Bu modeluzerinde beklenti-en iyileme, degisimsel beklenti-en iyileme gibi Bayesci metodlar veGibbs rneklemesi gibi Monte Carlo metodların calıstık. Zaman serisi analizinde,saklı Markov modelleri calıstk, yaygın olarak kullanılan ileri-geri algoritmasını zamanserilerinde coklu degisim noktas alglama problemine uyarladk. Monte Carloyaklasımları ve gizli Markov modellerini (ileri filtreleme-geri ornekleme) birlestirenyaklasık cıkarım algoritması onerdik. Onerdigimiz modelimizde, ileri yonlu iletilerintamamı hesaplanır, son zaman dilimi icin hesaplanan ileri yonlu iletilerden degisimnoktası orneklenir, orneklenen degisim noktas icin geri yonlu iletiler hesaplanr, ileriyonlu iletilerle guncellenerek, bir onceki zaman dilimi icin degisim noktası orneklenir.İlk zaman dilimine kadar devam eden bu yontem geri yonde ornekleme olarak isimlendirilir.Bu yntemle, hesaplama maliyetini dusurulmus oldu. Ayrıca bu kullanımkolayca integral alamadıgımz icin tam ckarım algoritmaları gelistiremedigimiz zamanserileri analizinde Monte Carlo metodolojilerinin kullanm icin ornek bir motivasyondur.Sentetik veri uzerinde yaptıgımız deneylerde, onerdigimiz yaklasık cıkarımlama algoritmasınn degisim noktalarını ve kume atamalarının algılanmasında tam cıkarımlamametodolojisiyle yeterince ortusen sonuclar verdigini gozlemledik.","Graphs are powerful mathematical tools to express relationships between anykind of items in very diverse disciplines. In this work, we worked on stochastic blockmodels and multiple change-point detection problem for graph time series, where numberof change points is unknown. Stochastic block models is a branch of clusteringalgorithms for relational data. We studied bayesian approaches as expectationmaximization(EM), variational expectation-maximization, Monte Carlo methods asGibbs sampling for analysis of stochastic block models. For time series analysis, wehave studied Hidden Markov Models, applied well-known forward-backward algorithmto multiple change point analysis on network series. We have proposed an approximateinference algorithm that combines Monte Carlo approaches and hidden Markovmodels (forward ltering-backward sampling). In our model, we calculate the forwardmessages completely, sample a change point from those, calculate the backward messagefor the sampled changed point, update with the forward message and sample achange point for the previous time step. It continues in this way to the rst time step,named backward-sampling. By this way, we have simplied the calculation cost. Inaddition, it is a motivation to use Monte Carlo methodologies in time series analysiswhere we can not take integrals easily in order to do exact inference. On experimentswe have done on syntheic data, we have seen that our proposed approximate inferencealgorithm gives results in accordance with exact inference methodology, in detectingmultiple change points and category assignments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda paralel programlama kapasitesi yüksek GPU'ların ortaya çıkması ile araştırmacılar arasında ışın izleme hızlandırmalarına dair çalışmalar tekrar yaygınlaştı. Atılan her ışın birbirinden bağımsız olduğu için ışın izleme doğal olarak paralel programlamaya çok uygun bir mekanizmadır. Son on yılda ışın izleme endüstri içinde çoğunlukla çevirim dışı görüntü üretmek için kullanılıyordu ve paralelleştirmeye bağlı hızlandırmalar shader programlama veya dağınık bilgisayar kümeleri ile gerçekleniyordu. Shader dilleri scanline pikselleştirme yöntemi için özel dizayn edilmişlerdir ve genel programlama için limitleyici yönleri vardır. Öte yandan, dağınık bilgisayar kümeleri birden fazla bilgisayarın ağ üzerinden birlikte çalışması ile hızlandırma sağlarlar, ancak bu sistemler bir ev kullanıcısı için aşırı pahalıdır. Modern GPU'lar ve Cuda ve OpenCL gibi GPU üzerinde genel programlama platformları ışın izlemeyi kişisel bilgisayarlarımıza kadar taşıyıp onu daha ucuz, hızlı ve interaktif kılabilecektir. Bu bağlamda en çok kullanılan hızlandırma yöntemlerinden biri ışın atmanın paralelleştirilmesidir. Bu tezin konusu modern GPU'lar ve Cuda platformu üzerinde ışın izlemenin verimli bir şekilde paralleştirilmesi ve modern GPU'ların sunduğu hızlandırma gücüne dair çalışma ve deneyler yapılmasıdır. Tez kapsamında CPU ve Nvidia Cuda GPU üzerinde çalışan iki adet ikincil ışın kabiliyetli ışın izleyici gerçekledik. Daha sonra GPU paralelizasyonunun sunduğu performans artışını ve değişik Cuda mimarileri üzerindeki farklı optimizasyon yöntemlerini CPU ışın izleyicimiz ile karşılaştırdık.","With the increasing availability of massively parallel processing capable GPUs in recent years, research on the acceleration of ray tracers has become popular again. Since the rays shot into the scene are independent of each other, ray tracing mechanism itself is naturally suited to parallelization. Until the last decade, ray tracing in the industry has been used for mostly offline rendering and parallelization-based speed enhancements were accomplished by either shader programming on GPUs or distributed computer systems. Shaders are specificly designed for rasterization and impose limitations for general programming. On the other hand, distributed computer clusters allow multiple computers to work concurrently over networks to increase speed; but maintaining such systems is not affordable for the end user. Hopefully, modern GPUs and GPU general programming frameworks like Cuda and OpenCL will bring ray tracing to our personal computers and make it more feasible, faster and interactive in the near future. One of the major acceleration enhancement techniques in this context is the parallelization of the ray tracing process. This thesis focuses on efficiently parallelizing ray tracing and testing the raw computational power GPUs offer in terms of ray tracing. As our test bed, we have implemented two ray tracers with secondary ray capability that work on CPU and Nvidia Cuda supported GPU respectively. We then examined the dramatic performance gain of GPU parallelization along with various GPU specific optimizations and their benefits on different Cuda GPU architectures, compared to a CPU based ray tracer."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, dağıtık ortamda üretici ve tüketici etmenlerin belli bir servis üzerine pazarlık yaptığı iki taraflı otomatik servis pazarlığını çalışmaktadır. Otomatik servis pazarlığının bu tezde çalışılan ana hususları otomatik bir şekilde önerilerin oluşturulması ve karşı önerilerin değerlendirilmesidir. Pazarlık yapan etmenler, bunların üstesinden gelmek ve kullanıcılarının yerine etkin şekilde pazarlık yapabilmek için, kullanıcılarınıntercihlerini göstermeye ve bunların üzerine muhakeme yürütmeye gereksinim duyarlar. Literatürde yaygın bir şekilde kullanılan nicel tercih gösterimlerinin aksine, CP-net gibi nitel tercih gösterimlerini desteklemekteyiz. CP-net'ler tercihlerimizi derlitoplu ve nitel bir şekilde göstermemize imkan sağlamakla birlikte çoğu zaman sadece kısmi bir sıralama sağlarlar. Bu tez bu kısıtlamayla başetmek için, verilen bir CP-net'ten elde edilen kısmi sıralamadan faydalık açısından tam bir sıralama elde etmek amacıyla CP-net'ler için birtakım buluşsal yöntemler geliştirmektedir. Böylece, pazarlık yapan etmen faydaları tahmin ederek var olan fayda temelli pazarlık stratejilerini kullanabilir. Deneysel sonuçlarımız yüksek performansla makul, kısa sürede pazarlık etmek için CP-net'ler üzerinde etkin buluşsal yöntemleri kullanılabileceğini göstermektedir.Pazarlık yapan etmen başarılı pazarlıklara yol açan doğru öneriler oluşturmak için rakibinin ihtiyaçlarını da anlamaya gereksinim duyar. Fakat, çoğu pazarlık ortamında katılımcıların tercihleri gizlidir. Bundan dolayı, bu tez pazarlık sırasında öneri değiştokuşundan rakibin tercihlerini anlamak için yeni bir tercih tahmin algoritması geliştirmektedir. Bu algoritma ontoloji kullanımı ile geliştirilmiştir; böylece benzer servis önerileri teşhis edilebilmekte ve benzer bir şekilde muamele edilebilmektedir. Ayrıca, pazarlık ilerledikçe, pazarlık yapan etmen rakibinin tercihleri hakkındaki görüşünü yenileyebilmektedir. Sonuç olarak, etmen rakibinin kabul edilebileceği iyi hedeflenmiş önerileriler oluşturmaktadır. Bu da katılımcıların daha hızlı fikir birliliğine ulaştığı ve olası başarısızlığı erkenden fark ettiği başarılı pazarlıklar ile sonuçlanmaktadır.","This thesis studies automated bilateral service negotiation in which a consumer and a producer agent negotiate on a particular service in a distributed environment. The key challenges of automated service negotiation that are addressed here are the automatic generation of the service offers and the evaluation of the counter-offers. The negotiating agents need to represent and reason about their user's preferences in order to negotiate effectively on behalf of their users. Contrary to quantitative representations of preferences that are widely used in the literature, we advocate qualitative preference representations such as CP-nets. CP-nets enable users to represent their preferences in a compact and qualitative way but they almost always represent only a partial ordering. To cope with this limitation, this thesis develops a number of heuristics to be applied on CP-nets to estimate a total ordering of outcomes in terms of utilities from the partial ordering induced from a given CP-net. Consequently, the negotiating agent is able to employ existing utility-based negotiation strategies by means of estimated utilities. Our experimental results show that one can adopt effective heuristics on CP-nets to negotiate with a high performance in a reasonable time.A negotiating agent also needs to understand its opponent's needs in order to generate accurate offers leading to successful negotiations. However, in many negotiation settings the participant's preferences are private. Accordingly, this thesis develops a novel preference prediction algorithm to understand the opponent's preferences from bid exchanges during the negotiation. This algorithm is enhanced with the use of an ontology so that similar service offers can be identified and treated similarly. Further, as the negotiation proceeds, the negotiating agent is able to revise its belief about the opponent's preferences. As a result, the agent generates well-targeted offers that are more likely to be acceptable by the opponent. This results in successful negotiations in which the participants reach a consensus faster and detect failures early."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yongada Çoklu-İşlemciler (CMP), kişisel bilgisayarların yanı sıra büyük ölçekliparalel makinaların ve süper bilgisayarların standart ve temel yapıtaşlarını oluşturmayabaşlamıştır. Bu tezdeki temel amacımız, performansı arttıran haritalama ve optimizasyonyöntemleri geliştirerek, uygulama izleklerini çok çekirdekli mimarilere atamaktır.Bunu başarabilmek için üç farklı yöntem sunmaktayız, bunlar veri-çekirdek eşlememetodu, izlek-çekirdek eşleme metodu ve önbellek merkezli veri-izlek eşleme metodudur.Veri-çekirdek eşleme metodunda, Barnes-Hut algoritmasının bir CMP olan CellBroadband Engine Mimarisinin teknik özelliklerini ve limitlerini göz önünde bulunduraniki özgün paralel formulasyonunu önermekteyiz. Yapılan deneysel değerlendirme,Barnes-Hut metodunun Cell mimarisi üzerindeki performansının karşılaştırma yapılanreferans mimarisi olan Intel Xeon tabanlı sisteme göre belirgin oranda daha hızlıolduğunu göstermektedir. İzlek-çekirdek eşleme metodunu sunmak için, uygulamaizlekleri ile paralel çalışan yardımcı izlekler kullanan ve dinamik olarak uygulama izleklerinindavranışlarını ve eriştikleri veri düzenini gözlemleyen bir sistem önerilmiştir.Yardımcı izlekler uygulama izleklerinin veri paylaşım miktarını hesaplayarak, bunlarıçekirdeklere eşlenmeleri için gruplara ayırır, eşlemelerin verimliliğini hesaplayabilmekiçin ön bellek sayaçları kullanır, ve çalışma zamanı ihtiyaçlarına bağlı olarak eşlemekararını alır. önerilmiş olan son metodumuzda, benzer veri erişim şekline sahip olanhesaplamaları aynı çekirdeğe atamayı hedefleyen, veri yerelliğini sağlayan bir eşlemealgoritması tasarlanmıştır. önerilen algoritma verilen uygulamanın hesaplamalarınıyükün eşit dağılımını sağlayabilmek için parçalara ayırır ve veri yerelliliğini sağlamakiçin yüksek benzerliğe sahip olan parçalar gruplandırılırlar. Metodun performansınıölçmek için, referans uygulama olarak seyrek matris-vektör çarpımı kullanılmıştır.","Chip Multiprocessors (CMPs) are becoming standard and primary buildingblocks for personal computers as well as large scale parallel machines, including supercomputers.In this thesis, our main focus is on performance-aware mapping andoptimization of application threads onto multicore architectures. Specifically, we proposethree different approaches, which are data-to-core mapping methodology, threadto-core mapping methodology, and cache-centric data assignment methodology thatincludes data-to-thread mapping. For demonstrating data-to-core mapping methodology,we propose two novel parallel formulations for the Barnes-Hut method on the CellBroadband Engine architecture by considering technical specifications and limitationsof the Cell architecture. Our experimental evaluation indicates that the Barnes-Hutmethod performs much faster on the Cell architecture compared to the reference architecture,an Intel Xeon based system. To present thread-to-core mapping methodology,we propose a framework that uses helper threads running in parallel with applicationthreads, which dynamically observe the behavior of application threads and theirdata access patterns. These helper threads calculate data sharing among applicationthreads, cluster them to be mapped to available cores, use cache counters to calculatethe efficiency of a mapping, and make the mapping decision after considering the executionneeds. Our final methodology provides a locality-aware mapping algorithm,which targets to assign computations with similar data access patterns of an applicationto the same core. Our algorithm divides computations of the application intochunks to provide load balancing, and a set of chunks with high similarity is groupedinto bins to provide data locality. We consider the sparse matrix-vector multiplicationas the reference application."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Radyo Frekansı ile Tanımlama (RFID), son yıllarda düşük maliyeti ve kullanım alanının geniş olması nedeniyle büyük ilgi gören bir teknolojidir. Kablosuz teknolojilerde, algılanan sinyal gücü (RSS) kullanılarak yapılan konumlandırma sistemleri RFID teknolojisinin bu amaçlı kullanılabilirliğini gündeme taşıdı. Çalışmalarımızda, RFID teknolojisinde RSS değerlerinin bina içerisinde farklı konumlardaki değişimi hem aktif etiketler hem de pasif etiketler üzerindeki etkileri incelendi. Aktif etiketlerin kullanıldığı sistemde, konum tanımlama referans etiketleri kullanılarak yapıldı. Referans etikeleri sayesinde ortamın radyo haritası anlık olarak çıkartıldı. Konum tahmini en yakın komşu algoritması kullanılarak yapıldı. Fakat etiketlerin tahmin edilemez ve benzersiz davranışları nedeniyle yapılan konum tahminleri uygun olmadı. Pasif etiketlerin, gölgeleme etkisinden çok fazla etkilenmesinden ötürü, tahminler, gölgelenen etiketlerden yana sonuç verdi. İnsan vücudunun sinyalleri soğurması nedeniyle giyilen etiket farkedilemez olmaktadır. Kişinin etiketin yanından geçerken etiketin RSS değerlerinin düşmesine bağlı konum tanımlama algoritması geliştirildi. 2x2.5 m2'lik ortamda 0.25 m hata payı ile konum tahmini yapıldı.","Radio Frequency Identification (RFID) attracts considerable attention because of its low cost and various area of applications. Location estimations based on received signal strength (RSS) in wireless technologies took the topic of localization using RFID technology into agenda. In our study, changes in the RSS values according to distance have been investigated in an indoor environment based on both passive and active tags. For the system in which active RFID tags are used, localization has been made using reference tags. An online radio map of the environment is created with the help of deployed reference tags. A nearest neighbor algorithm is applied in order to localize the tracked tag. However, unpredictable and non-uniform behavior of tags resulted in inappropriate location estimations. Passive tags, on the other hand, severely suffers from shadowing effect, creating biases towards to shadowed tags. The tag worn by the subject was undetectable because of the signal absorption by the human body. We have developed an algorithm estimating the location based on the drops in RSS value of the tags as tracked subject is passing by. We achieved a mean error of 0.25 m in a 2x2.5 m2 indoor environment."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kredi Risk Analizi (KRA) finansal alanda faaliyet gösteren kuruluşlar için önemli ve bir o kadar da zor bir veri madenciliği problemidir. Global kredi hacminin önemli ölçüde büyümesi ve bu büyümenin yanında ekonomik dalgalanmaların yaşanması, bu problemi daha önemli ve güncel bir noktaya getirmiştir. KRA potansiyel riskleri değerlendirir ve gelecekteki kayıpları azaltmak amacıyla yeni gelen kredi tekliflerini daha önceden belirlenmiş bir tolerans değeri ile karşılaştırarak elemine eder. Tez çalışmasında, kredi risk analizi yararına kullanılan sınıflandırma ölçütlerinin performanslarını ufak dahi olsa geliştirecek bir kombine sınıflandırma yöntemi oluşturmak amaçlanmıştır. Performans değerlerini karşılaştırmak için tutarlılık oranı, Alıcı İşletim Karakteristiği (AİK) ve hassaslık metrikleri kullanılmıştır. Tutarlılık oranında ya da optimal sonuçta önemsiz gibi gözükecek en ufak iyileştirme bile borç portföyünde kayıpları azaltacak ve değeri milyar dolarlar ile ifade edilebilecek tasarruflar sağlayacaktır. Bu tez çalışmasında üç farklı veri tabanı kullanılmıştır. Bunlar Alman Veritabanı, bir bankadan elde edilen veri tabanı ve özel bir yazılımın içinde bulunan veritabanıdır. Deneyler WEKA ve GeneXproTools yazılımları üzerinde gerçekleştirilmiştir. Destek Vektör Makinesi (DVM) sınıflandırma tekniği Alman Veritabanına uygulanmıştır. Lojistik Regresyon (LR) tekniği, GeneXproTools yazılımı üzerinde bulunan veritabanına farklı çapraz doğrulama yöntemleri eşliğinde uygulanmıştır. Son olarak DVM, LR, Sinir Ağları (NN), Basit Bayes Yaklaşımı ve Dinamik Bayes Yaklaşımı; bankadan elde edilen veritabanı üzerinde farklı örneklemeler için uygulanıp ortalama değerler alınarak performans değerleri incelenmiş ve önceki sonuçlara göre daha iyi veriler elde edildiği görülmüştür. Bu çalışmada, basit oylama modellemesi ile performans açısından iyi sonuçlar veren sınıflandırma tekniklerini bir araya getirilerek, hibrid bir sınıflandırma tekniği oluşturulmuş ve bu yeni yaklaşımın diğer sınıflandırma teknikleri ile performans açısından karşılaştırıldığında birçoğundan daha iyi sonuçlar verdiği görülmüştür.","Credit Risk Analysis (CRA) is an important and challenging data mining problem in financial analysis domain which is commonly used by many financial organizations. It became one of the most important and hot concept in finance sector since the real market?s credit volume has significant growths while economies have fluctuations which has great impacts on financial organizations. CRA aims to decrease future losses by estimating the potential risk and eliminating the new credit proposal if the risk is higher than a defined tolerance value. In this thesis study, it is aimed to compose a combined classification model to have any little improvement of classification performance when it is compared with existing classifiers. This comparison is based on performance metrics such as accuracy, Receiver Operating Characteristics (ROC) and precision. Any little improvement in accuracy and optimality which seems insignificant, will reduce losses in a large loan portfolio and save very significant amounts which can be defined in terms of billions of dollars. Three different datasets are used in this study. Those are German Dataset, a national bank dataset and a synthetic dataset from a data mining tool. WEKA and GeneXproTools softwares are used to make experiments. Single classification techniques Support Vector Machine (SVM) is applied to German Dataset with different kernel functions. Logistic Regression (LR) is applied on synthetic data with different cross-validation. Finally, LR, SVM, Neural Networks, Naive Bayes and Dynamic Bayesian approaches are compared each other on real-life bank dataset. A hybrid approach proposed which combines best-performed single classifiers inside as a unique classifier. Results show that combined classification impact performance in terms of improvement among other single classification techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nümerik analizde örgü iyileştirme yöntemleri, sonlu eleman yöntemleri gibi birçok alanda kısmi diferansiyel denklemlerin çözümünde kullanılmaktadır. Halihazırda kümeler ve çok çekirdekli CPU işlemciler üzerinde hem seri hem de paralel uygulamaları olan birçok örgü iyileştirme yöntemi bulunmaktadır. Ancak, bugün grafik işlemcilerin (GPU) gerek hesaplama kapasitesi, gerekse hafıza bant genişliği olarak CPU'lardan daha iyi bir noktada olduğu ve daha hızlı geliştiği göz önünde bulundurulduğunda, yüksek hesaplama ve veri hacmi ihtiyacı olan genel amaçlı uygulamaları da grafik işlemciler üzerinde çalıştırmak önem kazanmıştır. Bu tezde, düzensiz üçgensel örgülerin (non-uniform triangular mesh) iyileştirilmesi konusunda, grafik işlemciler üzerinde uygulanabilecek yeni bir paralel algoritma sunuyoruz. Algoritmamızı NDIVIA CUDA mimarisi üzerinde uygulayarak, grafik işlemci üzerinde CPU'ya kıyasla çok daha hızlı çalıştığını gösterdik. Bu tez aynı zamanda uygulama detaylarını ve karşılaştırmalı çalışma zamanı ve performans analizlerini de içermektedir.","In numerical analysis, mesh refinement techniques are used in many different areas such as in Finite Element Methods for the solution of partial differential equations. Formerly, a variety of different mesh refinement techniques have been proposed including both sequential and parallel implementations on clusters and multi-core CPUs. Since, today, both computational capacity and memory bandwidth of GPUs are better and still developing faster than CPUs, general purpose computing on GPUs (GPGPU) has become important in many application areas that require high computation and data throughput. In this thesis, we focus on refining non-uniform triangular meshes and present a new parallel adaptive mesh refinement technique that can be easily implemented on GPU architectures. We also present an implementation of our algorithm on CUDA architecture that achieve significant speed-ups. This thesis includes the algorithm and implementation details, as well as running time analysis and performance comparison of sequential implemetation on CPU and parallel implementation on GPU."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Müşteri sadakatinin önemi uzun süreden beri bilinen bir konudur. Araştırmacılar, e-sadakatin önşartlarıyla ilgili bazı modeller geliştirmişlerdir. Bu çalışmada, bu modellerden Srinivasan, Anderson, Ponnavolu'nun 8C (2002) modelini seçilmiş, Türkçe'ye çevrilmiş ve uyarlamalar yapılmıştır. Ayrıca modele yeni bir değişken (Masraf Azaltması) eklenmiştir. Bunun yapılmasındaki amaç, e-sadakat ve ön şartları arasındaki ilişkiyi gözlemlemektir.Bu amaç için 328 kişinin katılımıyla gerçekleştirilen anket çalışmasından derlenen veriler, tanımlayıcı, güvenilirlik, korelasyon, kümeleme analizleri ve ANOVA analizleri kullanılarak test edilmiş ve sonuçlara ulaşmak amacıyla kullanılmıştır.Bu çalışmanın sonuçları e-sadakatin gereklerini tanımlamış, site tipleriyle sadakatin alttipleri ve e-sadakat gerekleri arasındaki ilişkileri ortaya koymuştur. Genel olarak tüketicilerin sadakat eğilimleri düşük bulunmuştur, aynı zamanda duygusal olarak bağlanma eğilimlerinin mantıksal olarak bağlanma eğilimlerinden de fazla olduğu gözlemlenmiştir. Tüketiciler 3 ayrı grupta toparlanabilecek sadakat eğilimleri göstermişler, bunlar ?Sadık Dostlar?, ?Rasyonel Savunucular? ve ?Bağımsız Yer Değiştiriciler? olarak belirlenmiştir. Diğer yandan, web sitesi tipleriyle ilgili farklılıklar da analiz edilmiştir.","The importance of consumer loyalty to the web sites has long been known. Researchers have introduced some models to explain the antecedents of and the factors that affect e-loyalty. Within the scope of this study, the research of Srinivasan, Anderson, and Ponnavolu?s (2002) is chosen and modified by adding C (Cost Reduction) as a variable. The of this thesis was to examine the relation between e-loyalty and its antecedents.For this purpose, the data has been collected via an online survey from 328 participants, and has been tested through descriptive, reliability, correlation, cluster analyses, and ANOVA analyses aiming to reach findings.Results of this study show the antecedents of e-loyalty and describes the relations between site types and subtypes of loyalty and the antecedents of e-loyalty seperately. Generally, overall loyalty tendency of the people has been found to be low, however their tendency to be emotionally loyal to a web site is higher than to be rational loyal as expected. Consumers show different loyalty tendencies which can be summarized in three groups, ?Loyal Friends?, ?Rational Advocates?, ?Independent Switchers?. On the other hand, differences based on the web site types have also been analyzed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez içerisinde üç adet müzayede ve takas tabanlı elektronik pazar modeli önerilmektedir. Birinci modelimiz üniversitelerdeki ders ekleme/bırakma süreci için bir doğrudan takas modelidir. Bu modelde öğrenciler ders ekleme/bırakma isteklerini takas teklifi olarak verebilmektedirler. Ayrıca, öğrencilerin isteklerini öncelik sırasına göre belirtebilmelerini ve öğrenciler arasında adaleti sağlayan iki seviyeli bir ağırlıklandırma sistemi de mevcuttur. İkinci modelimiz çok birimli farksal müzayede-takas modelidir. Bu model çift taraflı müzayede sistemine takas özelliği eklemektedir. Bu sayede katılımcılar alış ve satış tekliflerinin yanı sıra takas teklifleri de verebilmektedir. Ayrıca farklı fiyatlı ürünlerin takas edilebilmesini sağlayan, ürünler arasında fiyat farkı belirtme özelliği de sağlanmıştır. Bu özelliklere ilaveten katılımcıların karmaşık satın alma, satış ve takas isteklerini ifade edebilmelerini sağlayan güçlü ve esnek bir teklif dili geliştirilmiştir. Üçüncü modelimiz bütçe sınırlı çift taraflı müzayede modelidir. Bu modelde yeni ve ikinci el ürünlerin ticareti için ayrık zamanlı çift taraflı müzayede sistemi önerilmiştir. Bu model, her bir katılımcının bir bütçe sınırı belirtmesine izin vererek, katılımcının aldığı ve sattığı ürünler arasındaki fiyat farkının belirttiği bütçe sınırı dâhilinde kalmasını sağlar. Ayrıca, bu modelde katılımcıların ilgilendikleri ürünleri tek bir teklifte toplayabilmesini ve almak istediği ürün sayısını sınırlayabilmesini sağlayan bir mekanizma da mevcuttur. Bu üç model ve bu modellere ait eniyileme problemleri matematiksel olarak tanımlanmıştır. Birinci ve ikinci modellerin eniyilemesi için hızlı polinom zamanlı algoritmalar önerilmiş, üçüncü modele ait eniyileme probleminin ise NP-complete sınıfına dâhil olduğu ispatlanmıştır. Önerilen algoritmaların başarımları çeşitli test problemleri üzerinde gösterilmiştir.","We propose three auction and barter based electronic market models. Our first model is a direct barter model for the course add/drop process in the universities. We model the course add/drop process as a direct barter problem in which add/drop requests can be placed as barter bids. We also introduce a two-level weighting system that enables students to express priorities among their requests while providing fairness among the students. Our second model is the multi-unit differential auction-barter model which augments the double auction model with barter bids so that besides the usual purchase and sale activities, bidders can also carry out direct bartering of items. Our model also provides a mechanism for making or receiving a differential money payment as part of the direct bartering of items, hence, allowing bartering of different valued items. Furthermore, a powerful and flexible bidding language is designed which allows bidders to express their complex preferences of purchase, sell and exchange requests. Our third model is the double auction with limited cover money model. In this model, we propose the use of discrete time double auction institution for the trading of used goods as well as new ones. Our model allows declaration of an amount of cover money so that what is spent on purchased items minus the proceeds of sold items does not exceed this cover money amount. We also introduce a mechanism so that bidders may place multiple item requests in a single bid and limit the maximum number of items to be purchased. We formally define these three models and formulatethe corresponding optimization problems. We propose fast polynomial-time network flow based algorithms for optimizing the first and the second models and show that the decision version of the optimization problem for the third model is NP-complete. The performances of our algorithms are also demonstrated on various test cases."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Klasik islemci tasarmndaki snrlamalardan dolay, tek bir yongada birden fazlacekirdege sahip olan Yongada C oklu _Islemciler (CMP) performans gelisimi icin tekcekirdekli mimarilere umit verici bir alternatiftir. CMP kullanm ile elde edilebilirperformans arts, coklu cokizlekli (multi-threaded) uygulamalarda paylasml onbellekyapsndaki cekismeden dolay azalabilir. Bizim esas odak noktamz, coklu cokizlekliuygulamalar icin haritalama stratejileri sunmaktr. Biz bu tezde, yeni bir tahmintabanlharitalama stratejisi sunuyor ve gelistiriyoruz. Bu yontem, farkl uygulamalarnizleklerinin paylasml onbellek uzerindeki davranslarn analiz eder, farkl uygulamalarntum izlek kombinasyonlarn tahmin eder, ve farkl uygulamalarn en az onbellek karsklgnasebep olacak en iyi izlek kombinasyonunu bulmaya calsr. Tahmin tabanl cercevemiziniki bileseni vardr: statik bilesen ve dinamik bilesen. Tahmin surecinin egitim asamasstatik bilesende cevrimds olarak yaplr. Tahmin edilen degerler alndktan sonra, heruygulamadan kac adet izlegin ayn cekirdegi paylasabilecegi ayarlanr. _Ikinci bilesendeise, egri uydurma modeli ile iletisim kurulmas, tahmin sonuclarnn alnmas ve bu tahminsonuclarna gore en son haritalama izlemi belirlenmesi calsma zamannda yaplr.Uygulama kodu ile egri uydurma modeli arasndaki iletisim runtime modulu tarafndangerceklestirilir. Bu modul, egitim asamas icin gerekli olan bilgiyi uygulama kodundanalr, egri uydurma modeline iletir ve tahmin edilen bilgileri egri uydurma modelindenalr, uygulama koduna gonderir. Hicbir admnda programa karslmaz.","Due to the limitations in the conventional processor designs, chip multiprocessors(CMPs), which have multiple cores on a single chip, are a promising alternative to singlecorearchitectures for performance improvements. The potential performance gains thatcan be achieved by the using CMPs decline when there is contention for the sharedcache structure for multiple multi-threaded applications. Our main focus is to presentmapping strategies of multiple multi-threaded applications on multicore architectures.We propose and develop a novel prediction-based mapping strategy. Our approachanalyzes thread behavior of dierent applications on the shared cache by consideringall possible thread combinations of dierent applications. It nds the best threadcombinations of dierent applications that result in minimum cache disturbance. Ourprediction-based framework has two components: a static component and a dynamiccomponent. The collection of the training data which is given to the curve tting modelas an input is done o-line at the static component. After receiving the predicted values,the threads of each application that shares the same core are arranged. Communicationwith curve tting model, receiving predicted results, and nally mapping according tothese values are done on-line at the dynamic component. The communication betweenthe application code and the curve tting model is provided by a runtime module whichcollects the training data from the application code and sends them to the curve ttingmodel and receives predicted data from the curve tting model and sends them to theapplication code. Any interference with the program is avoided at every step of theexecution."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İvmeölçerli oyun kumandaları ve dokunmatik ekranlı akıllı telefonların popülerlik kazanması ile birlikte; bu yeni arayüzlerin erişilebilirlik seçeneklerine ihtiyaçlar önem kazanmaktadır. Önceki çalışmalar, ivme ölçer temelli el hareket tanıma sistemlerinin, ivmeölçerli dokunmatik ekran telefonlarda görme engellilerin dokunmatik ekran klavye kullanımları için yeni bir arayüz olarak kullanılması fikrini vermiştir. Ancak, yüksek tanıma oranlarına sahip hemen bütün çalışmalar kullanıcı bağımlı tanımalar yapmakta veya sınırlı bir hareket kümesine sahip bulunmaktadırlar.Bu çalışmada amacımız, Apple iPhone 3GS mobil cihazın ivmeölçeri kullanılarak 20 adet el hareketinin tanınmasına alternatif bir çözüm ve kullanıcı bağımsız yüksek tanıma oranı sunabilmektir. Metodumuz temeli, dinamik zaman bükmesi ile birlikte dinamik sarmal çerçeve boyutu kullanılmasına dayanmaktadır. Toplanan el hareket verileri üzerinde yapılan birinci deneye göre; 20 farklı el hareketi için 1062 veri toplan- mış ve %96.7 tanıma başarısı elde edilmiştir. İkinci deneyde, sistem yapılan hesap makinası ile 4 görme engelli tarafından denenmiştir. Toplanan 15 farklı el hareketi için toplam 720 örnek alınmış ve ortalama %95.5 tanıma başarısı sağlanmıştır. Bu çalışma ile birlikte; ivmeölçer temelli el hareket tanıma sistemi, sistemin pratik bir uygulaması olarak konuşan ve 4 işlem yapabilen basit bir hesap makinası ve deney sonuçları ver- ilmiştir.","Within the popularity of new interface devices such as accelerometer based game controllers or touch-screen smartphones, the need of new accessibility options for these interfaces have become emergent. Previous studies gave the idea of using accelerome- ter based gesture recognition system on touch-screen smartphones with accelerometer as a new interface for visually-impaired people to use touchscreen keyboards. How- ever, almost all studies, which have high accuracy results, are used user-dependent classifications or very limited gesture sets.In this study, our aim is to find an alternative approach to classify 20 differ- ent gestures captured by iPhone 3GS?s built-in accelerometer and make high accuracy on user-independent classifications. Our method is based on Dynamic Time Warping (DTW) with dynamic warping window sizes. The first experimental result, which is obtained from collected data set, gives 96.7% accuracy rate among 20 gestures with 1062 gesture data totally. The second experimental result, which is obtained from 4 visually-impaired people with implemented calculator as end-user test, gives 95.5% accuracy rate among 15 gestures with 720 gesture data totally. Within this work, a design of accelerometer-based recognition system is given as well as its implementation as a gesture recognition based talking calculator and experimental results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Elektronik ortamda bulunan bilginin miktarının hızla artmasıyla, kullanıcılara bu bilginin içindeki önemli içeriği ayırt etmekte yardımcı olacak araçlar önem kazandı. Otomatik metin özetleme, bir girdi metni alıp içindeki en önemli içeriği seçip çıkartarak bu probleme hitap etmeyi amaçlamaktadır. Ancak metindeki belli başlı bilginin belirlenmesi değişik unsurlara dayanmakta ve otomatik metin özetlemenin önemli sorunlarından birini oluşturmaya devam etmektedir. Literatürde bazı çalışmalar metindeki sözcüksel bağlılığın göstergesi ve metin özetlemenin ara gösterimi olarak sözcük zincirlerini kullanmıştır. Ayrıca, elle yaratılmış özetlerle en çok ilintili metin özelliklerini ayırt ederek, özetlere götüren kalıplar öğrenmek için genetik algoritmalardan faydalanan çalışmalar da bulunmaktadır. Bu çalışmada, özetlemenin bu iki yaklaşımını birleştiriyoruz. Öncelikle, metinde bulunan sözcüksel bağlılıktan yararlanmak için sözcük zincileri hesaplanıyor. Ardından, metinle ilgili bu derin seviyedeki bilgi, daha üst seviye analiz sonuçları ile birleştiriliyor. Sonunda, metinle ilgili değişik seviyelerde bilgi veren bütün bu sonuçlar, genetik algoritmalar kullanılarak birleştiriliyor.","With the rapid increase in the amount of online text information, it became more important to have tools that would help users distinguish the important content. Automatic text summarization attempts to address this problem by taking an input text and extracting the most important content of it. However, the determination of the salience of information in the text depends on different factors and remains as a key problem of automatic text summarization. In the literature, there are some studies that use lexical chains as an indicator of lexical cohesion in the text and as an intermediate representation for text summarization. Also, some studies make use of genetic algorithms in order to examine some manually generated summaries and learn the patterns in the text which lead to the summaries by identifying relevant features which are most correlated with human generated summaries. In this study, we combine these two approaches of summarization. Firstly, lexical chains are computed to exploit the lexical cohesion that exists in the text. Then, this deep level of knowledge about the text is combined with other higher level analysis results. Finally, all these results that give different levels of knowledge about the text are combined using genetic algorithms to obtain a general understanding."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Makine öğrenmesi yöntemlerinin metin sınıflandırmada kullanılmaya başlanması, sınıflandırma performansını arttıran önemli bir faktör olmasına rağmen yüksek boyutluluk sınıflandırma başarısı için hala önemli bir problem. Sınıflandırmada doküman vektörlerinin boyutunu azaltmak için birçok yöntem önerilmektedir. Öznitelik seçme yöntemi de boyut azaltmada kullanılan en yaygın ve etkili yöntemlerden biridir. Öznitelik seçme metodlarının sınıflandırmadaki performansını arttırmak için birçok araştırma yapılmış ve yapılıyor olmasına rağmen, incelenen öznitelik seçme metodlarının bir arada kullanılması ile ilgili araştırmalar dokuman sınıflandırma alanında çok kısıtlı.Farklı yöntemleri birleştirerek bilgi erişim alanında başarılı sonuçlar elde edilmesi, bizi bu çalışmada öznitelik seçme metodlarını birleştirerek metinleri sınıflandırmaya yöneltti. Bu amaçla, bu çalışmada özellik seçme yöntemlerinin ve bu yöntemlerin çeşitli ikili birleşimlerinin karşılaştırılmasına yönelik kapsamlı bir araştırma sunuyoruz. Beş farklı öznitelik seçme metodu ve birleşimlerini farklı özellikteki beş veri kümesi üzerinde yerel ve genel politika kapsamında SVM sınıflandırıcısı ile analiz edildi. Analiz sonucunda, birleştirilen öznitelik seçme metodlarının metodların tek kullanılmasına göre daha başarılı sonuçlar elde ettiğini gördük. Özellikle yöntemlerin skor değerlerini birleştirmek yerel politikada belirgin şekilde başarılıyı arttırırken, sıra değerlerini birleştirmek genel politikada daha başarılı sonuçlar elde edilmesini sağladı.Bu tezde amacımız öznitelik seçme metodlarını birleştirmenin metin sınıflandırma performansındaki başarısını incelemek ve karşılaştırmaktır. Bu kapsamda skor ve sıra birleştirme yöntemlerinin yanında yeni birleştirme yöntemleri de tezde önerildi ve incelendi. Çalışma sonucunda önerilen bazı yöntemlerin skor ve sıra birleştirme yöntemlerinin başarısını da geliştirdiği gözlemlendi.","Even though the arrival of the machine learning methods in text categorization is one of the essential factors that improves the effectiveness of text categorization, high dimensionality is still a challenge for classification performance. There are several ways to reduce the dimension of input vector in classification and feature selection is one of the most popular and effective methods of reducing dimension. Various researches have been done to improve the performance of feature selection methods on text categorization but they mostly deal with how to advance the performance of the individual feature selection methods whereas we know that combining the outputs of multiple algorithms/classifiers is one of the promising strategies that has been studied extensively in information retrieval.With this motivation, we present a comprehensive analysis of the comparison between the feature selection methods and their varied binary combinations for text categorization with a comparative discussion. We analyze the performances of five common feature selection methods with their combinations on five standard datasets with varied skewness in both global and local policies by using SVM. Comparing the performance of the individual methods with the performance of the combination methods shows that combining two feature selection methods significantly improves the performance of the individual methods. In addition, rank combination achieves better performance in the case of global policy on the other hand score combination significantly achieves better performance in the case of local policy.In this thesis, the main concern is to investigate the effectiveness of combining the individual metrics on the performances of text categorization. Thus, we also propose new combination methods that some of them clearly outperform the success of the score and rank combinations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda veritabanı teknolojisindeki gelişmeler, saklanan veri miktarlarındaönemli bir artışa yol açmıştır. Bu artış veri madenciliğini şirketlerin stratejilerini belirlemeleriaçısından önemli bir konu haline getirmiştir. Birliktelik kuralları çıkarımı, verikümeleri içerisindeki yararlı ama gizli olan örüntüleri ortaya çıkaran bir veri madenciliğiyaklaşımıdır. Bu metot geleneksel veritabanları üzerinde pozitif birliktelik kurallarınınçıkarımında yaygın olarak kullanılmaktadır. Fakat, bu konuda veri katarı madenciliğive negatif birliktelik kuralları çıkarımı gibi daha zor problemler de yer almaktadır.Günümüzde şirketlerin büyük kısmı kendi uzmanlık alanlarına odaklanmak ve diğerişlerinin servis sağlayıcılar tarafından yapılmasını istemektedirler. Bu yaklaşım ?dışkaynaklı veritabanı? konseptini ortaya çıkarmıştır. Bu konsept veri sahiplerine birçokfayda sağlarken aynı zamanda bazı güvenlik problemlerini de ortaya çıkarmaktadır.Biz bu çalışmada yukarıda bahsetmiş olduğumuz bu zor problemlerin çözümlerinibir araya getiren bir madencilik modeli önerdik. Literatürde bizim önerdiğimiz şekildebir yaklaşıma rastlanmamıştır. Bizim modelimiz XML veri katarlarında pozitif venegatif birliktelik kuralları çıkarımı işlemini dış kaynaklı veritabanları konsepti ile etkinbir şekilde gerçekleştirmektedir. Bu çalışmada verimli bir negatif birliktelik kuralıçıkarımı için bazı eleme teknikleri kullanılmıştır. Ayrıca etkin ve yeterli bir veri korumasıiçin bazı güvenlik teknikleri kullanılmıştır.Bu çalışmada önerilen modelin verimliliğini göstermek amacıyla farklı veri kümeleriylebirçok test yapılmıştır. Test sonuçları önerilen modelin veri kuralları çıkarımı işleminietkin bir şekilde yaptığını göstermiştir.","Due to the development of database technology and systems in recent years,there is an enormous increase in data size. This increase makes the data mining one ofthe hot topic for organizations to determine their strategies. Association rule miningis a data mining approach that discovers the useful, but hidden patterns in the dataset. This method uses widely in traditional databases and usually to find the positiveassociation rules. However, there are some other challenging rule mining topics likedata stream mining and negative association rule mining. Nowadays, organizationswant to concentrate on their own business and outsource the rest of their work. Thisapproach reveals the ?Database as a service? concept. This concept provides lots ofbenefits to data owner, but, at the same time brings out some security problems.In this research, we have proposed a mining model that combines the mentionedchallenging areas. To the best of our knowledge, our approach is unique in the literature.Our model provides efficient solution to find positive and negative associationrules on XML data stream in database as a service concept. We have adapted somepruning strategies for efficient negative rule mining. Also, we have applied some securitytechniques to provide efficient and sufficient data protection.We have run many experiments with some different synthetic data sets and withone real world data set to show the efficiency of our proposed model. The results haveshown that proposed system makes the association rules mining operation efficiently."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde bilgisayarla görme tabanlı otomatik işaret dili tanıma ve ilgili alt konular üzerine yoğunlaşmış çalışmalar yaptık. Çalışmada üzerinde yoğunlaşılan el alfabeleri, işaret dillerinin, işaret dilinde karşılığı olmayan kelimelerin sadece parmak hareketlerini kullanarak temsilini sağlayan bir alt kümesidir. El alfabeleri, kavramları ellerin şekillerini, yönelimlerini, konumlandırmasını ve hareketlerini kullanarak temsil eder. Bu çalışmada, çok kipli ve çok dilli sistemlerde kullanılabilecek, Türk, Çek ve Rus el alfabelerinde yarı gerçek zamanlı el alfabesi tanıma yapan bir sistem geliştirdik. Otomatik işaret dili tanıma problemi üzerine yaptığımız çalışmalarda, el izleme ve bölütleme, el özniteliklerinin temsili, sınıflandırılması ve zamansal bölütlenmesi gibi alt konularda yoğunlaşarak geliştirdiğimiz ve kullandığımız metotların karşılaştırmalı analizlerini yaptık. Geliştirdiğimiz el ve yüz izleme yöntemiyle kamera karşısında işaret dili icra eden bir kullanıcının ellerini dayanıklı ve verimli bir şekilde takip edebiliyoruz. Klasik Camshift algoritmasına yaptığımız çoklu obje izleme, otomatik renk modeli oluşturma, otomatik el bulma ve kesişip ayrışan objeleri işaretleme yöntemleriyle kesintisiz videolarda dayanıklı el işareti tanıması yapılmasına olanak sağladık. El hareketi temsil metotlarımızda Eliptik Fourier betimleyicileri, Hu momentleri, ışınsal uzaklık fonksiyonu, yerel ikili örüntüler gibi iki boyutlu imgelerden elde edilen görüntü kipli özniteliklere ağırlık verdik. Bu özniteliklerin tanıma performanslarını tek tek ve birlikte inceleyerek sistemin detaylı bir analizini gerçekleştirdik. İmge dizileriyle yaptığımız testlerde, izole el hareketleri için en iyi tanıma başarımını yüzde 92 ile yerel ikili örüntü betimleyicileri verdi. Kesintisiz el işareti dizilerinde, işaretlerin başlama ve bitiş zamanlarını bulmak için hareket ve harekete bağlı bulanıklığı bir öznitelik olarak kullandık. Son olarak zamansal ve görsel özniteliklerin, el işareti dizilerini tanıma için kaynaşımını gerçekleştirerek dizilerde ağırlıklı oylama, ayrık Saklı Markov Modelleri ve kesintisiz Saklı Markov Modelleriyle el hareketlerini modelledik. İşaret dili tanıma başarımını ölçmek için yaptığımız testlerde, kendi topladığımız Türk, Çek ve Rus el alfabelerinden oluşan çok dilli veritabanını kullandık. Bu tez kapsamında, çalışmalarda geliştirilen yöntemleri kullanan bir parmak alfabesinden sese tercüme uygulaması geliştirdik.","In this thesis, we focus on the problem of computer vision based automatic sign-language recognition and its related subtasks. The study focuses on the recognition of fingerspelling gestures, which are a subset of sign languages that provide manual representation for spoken alphabet letters. Fingerspelling gestures make use of hand shapes, orientation, location and movements. We perform the task of fingerspelling recognition of Turkish, Czech and Russian manual alphabets with the purpose of integrating these sign alphabets to multi-modal and multilingual deployable applications. In the thesis, we divide the automatic fingerspelling recognition task into sub-challenges and design methodologies to improve overall sign recognition performance. We describe an approach to tracking of hands and a face in an image sequence containing the frontal pose of a signing person. A classical Camshift algorithm is extended in this study to contain automatic skin color model initialization, hand re-detection and collision handling. The algorithm performs robust, close to real-time hand tracking. Secondly, we focus on hand gesture representation. We evaluate the usage of appearance based features for describing the manual component of Sign Languages; in particular Elliptic Fourier Descriptors, Hu Moments, Radial Distance Function and Local Binary Patterns. We test the recognition performance of individual features and their combinations. Local Binary Patterns show the best recognition performance on isolated gestures with a recognition rate of up to 92 per cent. We explore the usage of features such as hand motion and motion blur in the problem of temporal segmentation to separate gesture start and end locations in continuous gesture videos. We investigate the fusion of temporal and appearance features using sequence voting, discrete HMMs and continuous HMMs. We test the fingerspelling recognition accuracy of our system on a self collected multilingual fingerspelling dataset consisting of Turkish, Czech and Russian manual alphabets from multiple signers with multiple repetitions. Finally, we have demonstrated the applicability of our system in a prototype application that functions as a multi-lingual fingerspelling to speech translator."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hayatımıza yüksek teknoloji ürünü karmaşık cihazlar girdikçe, bu yeni cihazlarınsorunsuzca ve hissettirilmeden günlük yaşantımıza tümlenmesi ihtiyacı ortaya çıkar. Buihtiyacın giderilmesi için aynı anda her yere yayılmış, ortam zekası denilen yeni birzeka türü ortaya atılmıştır. Ortam zekası, insanların hayat kalitesini yükseltmek içininsan varlığına duyarlı ve tepki veren ortamları anlatır. Yazılım etmenleri, bu ortamlarıhayat geçirmek için önemlidir. Bugüne kadar yapılan araştırmalar bireysel etmenlerintepkilerine yoğunlaşmışken, etmenlerin insanlara bileşik servisler sunmak için iş birliğiyaptıklarında daha ilginç uygulamalar ortaya çıkacaktır. _ Iş birliği kaçınılmaz olduğunda,ortamın etmenler arasında etkileşimi düzenlerken etmenlerin özerkliklerine saygı duyacakdüzeneklere gereksinimi vardır.Bu çalışma bileşik servislerin sağlanmasında sözleşme tabanlı bir yaklaşım sunar.Sistem; alan ve çevre bilgisini saklayan iki ontoloji, kullanıcıları temsil eden etmenler veservis sunan etmenlerden oluşur. Gerçek hayatta olduğu gibi, bileşik servisi oluşturanbireysel servisler çoğu zaman farklı etmenlerce sunulur. Sözleşmelerde yer alacak etmenler,sağladıkları servislere göre seçilir. Yürütüm aşamasında seçilen etmenler sözleşmeleregirip girmeme konususnda özerk biçimde karar verirler. Etmenlerin bu kararı ontolojilerüzerinden mantık yürüterek elde ettikleri sonucu kendi iç durumlarıyla birleştirmeleriyleortaya çıkar. Sözleşmeler üzerinde anlaşma sağlandıktan sonra etmenler sözleşmeleringereklerini yerine getirmeye çalışırlar. Bu çok etmenli sistemi akıllı mutfak alanına uygulayıp iş birliği için sözleşmelerde nasıl faydalanılabileceğini gösteriyoruz. Uygulamamıziçin gerçekçi senaryolar kullanıyoruz.","As we are introduced with the more complex, high technology devices, the needto smoothly integrate these new devices to our lives grows. In order to satisfy this need,a new kind of pervasive and ubiquitous intelligence, Ambient Intelligence, is suggested.Ambient Intelligence (AmI) describes environments that sense and react to the humans intime to help improve their living quality. Software agents are thus important in realizingsuch environments. While existing work has focused on individual agent's reactions,more interesting applications will take place when agents cooperate to provide composedservices to humans. When cooperation is required, the environment needs mechanismsthat regulate agent's interactions but also respect their autonomy.Accordingly, this thesis develops a contract-based approach for oering composedservices. The system consists of two ontologies that keep knowledge about the environmentand the domain, agents that represent the user, and the agents that provide services.Similar to the real life, individual services are usually oered by dierent agents. Agentsthat are going to take part in the contracts are selected according to their capabilities. Atruntime, selected agents autonomously decide whether they enter contracts. The decisionis based on the knowledge which is described in the ontologies and the internal state ofthe agent. After the agents agree on the contracts, they then act to fulll their contracts.We apply this multiagent system on an intelligent kitchen domain and show howcommitments can be used to realize cooperation. We study our application on realisticscenarios."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Atik Proje Yönetimi (APY), günümüzde oldukça yaygın olarak kullanılan ve projelerdeki çeşitli belirsizlikleri ve önceden tahmin edilemeyen problemleri yönetebilmeye olanak sağlayan metotlar bütünüdür. Fakat, bu belirsizlikleri ve proje başlangıcında tahmin edilemeyen durumları iyi bir şekilde yönetebilmek çok kolay değildir. Projelerin büyük çoğunluğunda, tüm süreçlerin Atik metot ile doğru olarak planlanması da oldukça zordur. Bu tip projelerde kullanıcı gereksinimleri sürekli değiştiği ve proje başlangıcında kullanıcı gereksinimlerinin tamamı elde edilemediği için, proje planlarının sürekli kontrol altında tutulması ve gözden geçirilmesi gerekmektedir. Bu çalışmanın temel amacı, geliştirilmiş bir yazılım planlama tekniği sunularak, özellikle Atik yazılım projelerindeki problemlerin önüne geçilmesidir. Bu problemlerin önüne geçebilmek amacıyla, var olan çeşitli metotlar incelenmiş ve yeni bir yaklaşım geliştirilmiştir. Atik projelerde planlama, genelde sadece tahminlere dayanarak yapılmaktadır. Sunulan yeni yöntemde, projelerin sadece tahminlere dayalı olarak planlanması yerine, yazılım projesinin büyüklüğü ölçümlenmektedir. Bu ölçümlendirme, kullanıcıdan alınan gereksinimler üzerinde, COSMIC ölçümlendirme ve COSMIC doğrrulama metotları kullanılarak yapılmaktadır. Sonuç olarak, projenin gerçekleştirilmesi için gereken efor, geçmişe yönelik proje veritabanlarından da yararlanarak hesaplanacaktır. Geliştirilen metot, uygulanabilirliğini göstermek amacıyla, bir film kiralama projesi üzerinde uygulanmıştır. Elde edilen sonuçlar göstermektedir ki; geliştirilen metot kullanılarak, proje sonucunda ortaya çıkacak olan ürün en küçük parçasına kadar ölçümlenebilmekte ve proje planları daha güvenilir ve bakımı yapılabilir şekilde hazırlanabilmektedir. Ayrıca, kullanıcı gereksinimleri için hazırlanan döküman kalitesinin, ölçüm sonuçları üzerinde etkisi olduğu tespit edilmiş ve döküman kalitesinin tespit edilmesinin, ölçüm sonuçlarını değerlendirmede büyük fayda sağladığı belirlenmiştir.","Agile Project Management (APM) is the method of a series of commonly used project management approaches for better handling of uncertainty and unpredictability. In large portion of software projects, accurate planning of project lifetime with Agile is difficult. Since continuously change in requirements occurs as their incompleteness at project initialization, project plans must be under control and continuously revised. The purpose of this thesis is to help tackling difficulties of managing Agile software projects by proposing an improved software planning technique. In Agile projects, planning is mainly based on just guess estimation of global effort. In the proposed approach, instead of just guess estimation, there is measurement of size of the product. This measurement is implemented over user stories with COSMIC methods. Thus, needed efforts for the projects are calculated. The approach is applied on a film renting project to present its applicability. The results show that, by using the approach, sizes of all pieces of the product can be obtained and project plans can be prepared with higher reliability and maintainability. Project plans may be more reliable, because they depend on measurement results and they may be more maintainable, because if any requirement changes, just that requirement needs to be measured again. Also it is shown that, documentation quality has an impact on the measurement results. As documentation quality changes, measurement results change by depending on the information in the documentation. It is also presented that, identification of the quality of the documentation helps to criticize the measurement."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Göreceli olarak geniş bir dağarcığa sahip sondan eklemeli ya da çekimsel biçim-bilime sahip diller konuşma ve dil işlemede yüksek sayıda dağarcık dışı (DD) kelimenin görülmesine neden olduğundan bazı zorluklar sunmaktadır.Bu tezde, bu zorluklar ile otomatik konuşma tanıma (OKT) kapsamında çok üretken çekimli ve türevsel biçimbilime sahip olan Türkçe için ilgilenilmiştir.İlk olarak, Türkçe için gereken kaynakları ve araçları oluşturduk. Bunlar sonlu-durum biçimbilimsel çözümleyici, perceptron-tabanlı biçimbilimsel tekleştirici, ve metin derlemidir.İkinci olarak, DD kelime sorununu gidermek ve biçimbilimsel bilgiden kaynak olarak yararlanmak için birbirini tamamlayan iki dil modeli yaklaşımı geliştirilmiştir. İlk model, sıklıkla kullanılan kelime ve kelime-altı birimler yerine sözlüksel-dilbilgisel biçimbirimleri kullanan üretici n-birimli bir model olan biçim-sözlüksel dil modelidir. Ayrıca, sonlu durum dönüştürücü çerçevesinde biçimbilimi bir bilgi kaynağı olarak OKT sistemine bütünleştirmek için yeni bir yöntem sunulmuştur. İkinci model, üretici model ile elde edilen en iyi adayları tekrar sıralamak için biçim-sözlüksel ve biçim-dizimsel öznitelikleri kullanan kelime hata oranı (KHO) duyarlı algılayıcı bir algoritma ile ayırıcı olarak eğitilmiş doğrusal bir modeldir. Önerilen yöntemler haber kayıtlarının yazılandırılması için kullanıldı ve deneysel sonuçlar elde edildi. Biçim-sözlüksel model dağarcık dışı kelime sorununu nispeten gidermiş ve konuşma tanımada kelime hata oranını kelime ve istatistiki kelime-altı modellere göre sırasıyla %1.8 ve %0.8 oranında iyileştirmiştir. Ayırıcı olarak eğitilmiş model sistem başarımını %0.8 oranında daha da iyileştirmiştir. Son olarak, konuşma tanıma çıktısı olan kelime örgülerini tanıma yapılırken tekrar değerleyen bir algoritma geliştirilmiştir.","Languages with agglutinative or inflectional morphology have proven to be challenging for speech and language processing due to relatively large vocabulary sizes leading to a high number of out-of-vocabulary (OOV) words.In this thesis, we tackle with these challenges in automatic speech recognition (ASR) for Turkish which has an extremely productive inflectional and derivational morphology. First, we build the necessary tools and resources for Turkish, namely a finite-state morphological parser, a perceptron-based morphological disambiguator, and a text corpus collected from the world wide web.Second, we introduce two complementary language modeling approaches to alleviate the OOV word problem and to exploit morphology as a knowledge source. The first, morpholexical language model, is a generative n-gram model, where modeling units are lexical-grammatical morphemes instead of commonly used words or statistical sub-words. The second is a linear reranking model trained discriminatively with a variant of the perceptron algorithm, word error rate (WER) sensitive perceptron, using morpholexical and morphosyntactic features to rerank n-best candidates obtained with the generative model. We apply the proposed models in Turkish broadcast news transcription task and give experimental results. We also propose a novel approach for integrating morphology into an ASR system in the finite-state transducer framework as a knowledge source. The morpholexical model is highly effective in alleviating the OOV problem and improves the WER over word and statistical sub-word models by 1.8% and 0.8% absolute, respectively. The discriminatively trained model further improves the WER of the system by 0.8% absolute. Finally, we present an algorithm for on-the-fly lattice rescoring with low-latency."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tıkanıklık, kablosuz algılayıcı ağlarda düşük maliyetli kamera donanımlarının evrimleşmesi ile olanaklı hale gelen video uygulamalarının getirdiği yüksek hacimli veri trafiği sebebiyle kötüleşen, zorlu bir problemdir. Bu tezde, kablosuz video algılayıcı ağlarda tıkanıklık problemini hedef alan üç adet katmanlararası coğrafi iletim şeması öneriyoruz. Yük Dengeli Güvenilir İletim şemasında bir algılayıcının sonraki sıçrama noktasını, çıkış düğümüne pozitif ilerleme sağlayan alternatif komşular arasından, tampon doluluk seviyelerinin dengesini düşünerek, dinamik olarak belirlediği yerel yük dengelemesi kavramını tanıttık. Yönsel Yük Dengeli Serpme şemasında, yerel ve yön tabanlı (uzamsal) yük dengeleme yaklaşımlarını, her ikisinin de avantajlarından faydalanarak, daha güvenilir ve daha hızlı video iletimi sağlamak için birleştirdik. Çok-çıkışlı Yük Dengeli Güvenilir İletim şemasında yükün çoklu çıkışa dağıtımının avantajlarını araştırdık. İletim şemalarının başarımlarını OPNET üzerinde benzetimler vasıtasıyla değerlendirdik. Sonuçlar önerilen iletim şemalarının çerçeve iletim oranını iyileştirdiğini ve çıkış düğümlerine başarıyla iletilen çerçeve başına harcanan enerji açısından verimli video iletimi sağladığını gösterdi.","Congestion is a challenging problem in wireless sensor networks which exacerbates with the high volume of data traffic imposed by video applications that are enabled by the evolution of low-cost camera hardware. In this thesis, we propose three cross layer geographic routing schemes addressing the congestion problem in wireless video sensor networks. In Load Balanced Reliable Forwarding scheme, we introduced the notion of local load balancing where a sensor dynamically determines the next hop among the alternative neighbors providing positive advancement towards the sink by considering the balance of their buffer occupancy levels at the time of delivery. In Directional Load Balanced Spreading scheme, wecombine local and direction-based (spatial) load balancing approaches to provide more reliable and faster video delivery by benefiting from the advantages of both approaches. In Multi-Sink Load Balanced Reliable Forwarding scheme, we explored the advantages of load distribution to multiple sinks. We evaluated the performance of the routing schemes via simulations in OPNET. The results show that the proposed routing schemes improve the frame delivery ratio and provide efficient video delivery in terms of energy expenditure per successfully delivered frame to the sink(s)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüksek hızlı İnternet erişimine olan artan talepten dolayı, kablosuz örgü ağlar (KÖA) konuşlanma kolaylığı ve aynı anda çok yere hizmet verebilmeleri ile gözde bir seçim haline gelmiştir. KÖA konusunda yazında kapsamlı çalışmalar yapılmış olsa da, neredeyse tüm yaklaşımlar benzetimlere dayanmaktadır ve çözümlemeli yaklaşım ile matematiksel modelleme odaklı değildir. Bu tezde, altyapı tabanlı KÖA'larda zamanlamanın matematiksel modellemesi için ""Boğaziçi Bot Modeli"" (BoBo) adını verdiğimiz yeni bir matematiksel model önerilmektedir. Zamanda farklı noktalarda, kuyruk doluluğuna ilişkin olasılık dağılımları türetilmektedir. Bu dağılımlar değerlendirme ve gerçekleme için önemli ölçevlerin türetilmesinde kullanılmalarının yanı sıra, dağılımların davranışı da derin bir analiz için incelenmektedir. BoBo modelinin değerlendirmesi aynı zamanda benzetimlerle de gerçeklenmektedir. Sonuçlar, zamanda herhangi bir noktada kuyruk doluluğu olasılık dağılımının normal dağılıma benzediğini ve artan trafik yükünün değişintide artmaya sebep olduğunu göstermektedir. Ek olarak, bir paketin kaçıncı çerçeveye zamanlanacağı düşük değişinti ve neredeyse rastgele olmayan bir dağılıma sahiptir. Bununla birlikte, ağ kapasitesine ulaşılması durumunda, dağılım iki hop uzaklıktaki düğümlerde neredeyse eşit olasılıklı olmaktadır.","Due to the increasing demand for high-speed Internet access, wireless mesh networks (WMN) have become a popular choice for their ease of deployment and ubiquity. Although extensive research has been done in the literature regarding WMNs, almost all approaches rely on simulations and there is a lack of focus on analytical approach and mathematical modeling. In this thesis, a novel mathematical model called the ""Bosphorus Boat Model"" (BoBo) is proposed for the mathematical modeling of scheduling on infrastructure-based WMNs. Probability distributions regarding the queue occupancy at different points in time are derived. Not only are these distributions used for deriving important metrics for evaluation and verification, but also their behavior is investigated for a thorough analysis. The evaluation of the BoBo model is also verified with simulations. The results show that the probability distribution of queue occupancy at any given point in time resembles the normal distribution, and increasing traffic load induces an increase in variance. Also, the number of frame to which a packet is scheduled has an almost deterministic distribution with very low variance. However, under the condition of reaching network capacity, the distribution becomes almost equiprobable for the two-hop nodes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çok etki alanlı ağlarda gezgin bilgisayarların, kaynakların ve kullanıcıların hareketliliğigüvenlik açısından zorluklar meydana getirmektedir. Güvenlik etki alanları arasındahareketlilik içeren eylemler, etki alanında ve etki alanları arasında oluşturulmuş güvenlikpolitikaları bağlamında betimlenmeli ve doğrulanmalıdır. Bu tez kapsamında,FPFM (Gezginlik için Formal Güvenlik Politikası Çerçevesi) adında, çok etki alanlı gezginağlarda kullanıma yönelik, bir güvenlik politikası betimleme ve doğrulama çerçevesiortaya konulmaktadır. FPFM, gezginlik ve konum kısıtları, rol hiyerarşileri eşleştirme,etki alanları arası servisler, etki alanları arası erişim hakları ve görevlerin ayrımı unsurlarınıiçeren güvenlik politikalarının betimlenmesini desteklemektedir. Güvenlikpolitikalarının betimlenmesi için FPM-RBAC adı verilen bir formal güvenlik politikasımodeli ve XFPM-RBAC adı verilen XML tabanlı bir güvenlik politikası diliönerilmektedir. Güvenlik politikalarının doğrulanması, belirli bir ağ yapılandırmasıiçerisinde, güvenlik politikalarının sağlandığının onaylanmasını sağlar. FPFM bu kapsamdatanımlı ağ yapılandırması, etki alanı güvenlik politikası ve etki alanları arasıgüvenlik politikasından formal betimlemelerin üretilmesini sağlamaktadır. FPFM'inkatkı sağladığı alanlardan bir başkası, birden fazla etki alanı içerisindeki gezginlikkaynaklı bilgi akışlarının formal analizidir. Formal betimlemelerin otomatik doğrulanmasıiçin model denetleme ve teorem ispatlama yöntemleri kullanılmaktadır. Güvenlikpolitikaları içerisindeki konum ve hareketlilik kısıtlarının uzay-zaman tabanlı modeldenetlemesi için bir uzay-zaman tabanlı algoritma önerilmiş ve bir model denetlemearacı geliştirilmiştir. Coq etkileşimli teorem doğrulama aracı kullanılarak güvenlikpolitikaları içerisindeki çelişkilerin çözümlenmesi sağlanmıştır.","We present a framework called Formal Policy Framework for Mobility (FPFM)for the specification and verification of domain and inter-domain security policies ina multi-domain mobile network environment. FPFM supports the specification ofsecurity policies with mobility and location constraints, role hierarchy mapping, interdomainservices, inter-domain access rights and separation of duty. The specification of securityolicies in FPFM is based on a formal security policy model, called FPM-RBAC (Formal PolicyModel for Mobility with Role Based Access Control) and a XML based security policyspecification language called XFPM-RBAC (XML Based FormalPolicy Language for Mobility with Role Based Access Control). Formal verification ofsecurity policies ensure that the security policy is satisfied by the network elements in agiven network configuration. FPFM supports extraction of formal specifications fromdefined network configurations, domain and inter-domain security policies. Anothernovel aspect of FPFM is the support for formal information flow analysis related tomobility within multiple security domains. Automated verification of formal specificationsare carried out through model checking and theorem proving. A spatio-temporalmodel checking algorithm has been proposed and a model checking tool has beendeveloped for spatio-temporal model checking of location and mobility constraints insecurity policy rules. Conflicts within security policy rules are resolved through theoremproving with the help of the Coq interactive theorem prover."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayarla görme temelli insan hareketi tanıma, güvenlik, gözetim, destekli yaşam ve eğlence gibi bir çok alanda uygulaması olan çok aktif bir araştırma konusudur. Bu tezde, bilgisayarlı görme temelli insan hareketi tanıma için yeni bir sistem sunulmaktadır. Önerilen sistem girdi olarak videoları kullanmaktadır. Yaklaşım, hareketin konumuna, ölçek seviyelerine, kişinin görünümüne, kendini örtmeler de dahil olmak üzere kısmi örtmelere ve bir takım görüş açısı değişikliklerine karşı değişimsizdir. Zamansal uzunluk değişimlerine karşı gürbüzdür. Anahtar noktalar zaman boyunca takip edilmektedir ve takip edilen anahtar noktaların gezingeleri videodaki insan hareketini yorumlamak için kullanılmaktadır. Ardından, videolardan öznitelikler çıkarılmaktadır. Gezingeyi tanımlamak için bir grup öznitelik önerilmektedir. Gezingeler, bu gezinge öznitelikleri kullanılarak öbeklenmektedir. Öbeklenen gezingeler bir imge dizisini tanımlamak için kullanılmaktadır. Imge dizisi tanımlayıcıları, gezinge öbeklerinin düzgelenmiş histogramlarıdır. Son aşamada, önerilen sistem, imge dizilerinin tanımlayıcılarını bir güdümlü öğrenme yönteminde kullanır. Önerilen yönteme dayalı bir uygulama geliştirilmiştir ve çeşitli veri kümelerine uygulanmıştır. WeCare adını verdiğimiz yaşlı bakım sistemleri odaklı yeni bir çok kipli veri kümesi sunulmuştur. Veri kümesinin asıl amacı insan düşmelerinin saptanmasıdır. Bu amaca ulaşmak için düşme hareketiyle karıştırılabilecek bazı başka hareketler de veri kümesine dahil edilmiştir. Önerilen yöntem KTH İnsan Hareketi Veri Kümesi ve URADL Veri Kümesi adlı iki ilave veri kümesi ile de değerlendirilmiştir. Önerilen yöntem yazındaki yöntemlerle kıyaslanabilir başarımdadır. KTH veri kümesinde yüzde 87,25 ve URADL veri kümesinde yüzde 88 hatasızlık başarımına sahiptir. WeCare veri kümesinde hatasızlığı yüzde 98,75'tir.","Computer vision-based human action recognition is a highly active research area which has many application areas including security, surveillance, assisted living, and entertainment. In this thesis, a new system for computer vision-based recognition of human actions is presented. The proposed system uses videos as input. The approach is invariant of the location of the action and zoom levels, the appearance of the person, partial occlusions including self-occlusions and some viewpoint changes. It is robust against temporal length variations. Keypoints are tracked through time and the trajectories of tracked keypoints are used for interpreting the human action in the video. Then, features from videos are extracted. A group of features for describing a trajectory are proposed. Trajectories are clustered using these trajectory features. The clustered trajectories are used for describing an image sequence. Image sequence descriptors are the normalized histograms of the clusters of trajectories. At the final stage, the proposed system uses the descriptors of the image sequences in a supervised learning approach. An application based on the proposed method has been developed and applied to various datasets. A new multi modal dataset, called WeCare, which is focused on elderly care systems is introduced. The main objective of the dataset is to detect falls of humans. For attaining this goal, some other actions that can be confused with the falling action are included in the dataset. The evaluation of the proposed approach is done using two datasets: KTH Human Action Dataset and URADL Dataset. The proposed technique performs comparable to the methods in the literature. It has 87.25 per cent accuracy on the KTH dataset, 88 per cent accuracy on the URADL dataset. It has an accuracy of 98.75 per cent on the WeCare dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Düşük maliyetli bilgisayar ekipmanları ile yüksek bant genişliğine sahip ağ bağlantılarınıngiderek artması, hizmet odaklı ortamların da kullanımının artmasına neden olmaktadır.Gelişen hizmet odaklı ortamların açık ortamlar olması beklenmektedir. Bu tür ortamlarson derece dinamiktirler ve çeşitli servisler ile otonom etmenler içerirler. Ancak,ortamların açıklığı, güvenlik sistemleri ile ilgili güven problemlerine neden olmaktadır.Bu problemlerle başa çıkmak için güven ve güvenliğin hassas olarak modellenmesineve kurallı olarak gösterimine ihtiyaç vardır. Bu tez, çekirdek kabuk yaklaşımı ile açıkortamlardaki bilgisayar güvenliği ile ilgili güveni inceler, modeller ve nasıl temsiledileceğini gösterir. Bu tezin dört ana katkısı vardır. Öncelikle, bir etmeninbakış açısından bir servisin güvenlik sisteminin güvenini değer biçecekçekirdek modeli sunuyoruz. Bu model açık ortamlardaki neredeyse tümetmenlere uygulanabilir. İkinci olarak, belirli bir etmenin ihtiyaçlarına görebir servisin güvenlik sisteminden güven bilgisini çıkarmak için bir kabukmodel öneriyoruz. Sonraki ana katkımız, etmenler üzerinden geçengüvenlik değerlendirme bilgisine göre güveni tayin eden bir kabukmodeldir. Bu modelin amacı, güven değerlendirmelerinde kullanılmaküzere güvenlik değerlendirme bilgi miktarını arttırmaktır. Son olarak,ağlarda servis yakınsaması için güvene dayalı güvenliğin birlikte çalışabilirliğisağlayacak bir kabuk model öneriyoruz. Son model, güven değerlendirmeleriiçin modellerin bizim temel modelimize nasıl ekleneceğini gösteriyor.Ayrıca, her modelin uygulanabilirliğini örnek olaylar ve benzetimler ile gösteriyoruz.","The increasing availability of high bandwidth network connections with low-costcomputing equipments has stimulated the use of service-oriented environments. Emergingservice-oriented environments are expected to be open environments. Such environmentsare highly dynamic and contain diverse number of services and autonomousentities. However, their openness reveals trust problems related to security systems.To cope with the problems, precise models and representations of trust and securityare needed. This thesis examines, models, and represents trust in relation to computersecurity in emerging open environments with core-crust modeling approach. The thesiscontains four main contributions. First, we introduce the core model for trust assessmentof the security system of a service from an entity point of view. The model couldbe applied to almost all entities in open environments. As the second main contribution,we propose a crust model for extracting trust information from the security systemof a service, based on needs of a specific entity. Our next main contribution is a crustmodel for trust assessment based on flow of security evaluation information on entities.The aim of this model is to increase the amount of security evaluation information tobe used in trust assessments. Finally, we propose a crust model for trust based securityinteroperability for service convergence in networks. The last model aims to show howour proposed models can be integrated to our core model for trust assessments. Wealso show the applicability of each model with case studies and simulations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüksek performanslı yazılım ihtiyaçlarının sürekli artmasıyla beraber çok çekirdekli yazılım geliştirme ihtiyacı da artmaktadır. Bu durum, çok çekirdekli yazılımların potansiyel olarak birden fazla yürütme çizelgesine sahip olması nedeniyle, yazılımların güvenilirliğini azaltır ve doğrulanmaya harcanan çabayı artırır. Ardışıl yazılımlardaki hataları ortadan kaldırmak için kullanılan doğrulama yaklaşımları çok çekirdekli yazılımlarındaki hataları bulunması için yeterli değildir. Çok çekirdekli yazılım doğrulama yöntemlerinin koşutzamanlılığın yanısıra verimli ve ölçeklenebilir olmasına ihtiyacımız vardır. İleti geçirme kütüphanelerini kullanarak iletişim kuran çok çekirdekli yazılımlar için doğrulama ve kapsama teknikleri sunuyoruz. Özellikle yeni endüstri standartı olan ve Multicore Association tarafından geliştirilen Çok Çekirdekli İletişim Uygulama Programlama Arayüzü'nü (MCAPI) kullanan yazılımların güvenilirliğini arttırmak için teknikler sağlıyoruz. Çok çekirdekli yazılımlardaki mevcut ve potansiyel hataları bulmamızı sağlayan dinamik, öngörücü teknikler geliştirdik. Bu hata türlerinden bazıları kilitlenmeler, yarış durumları ve zamansal doğruluk savlarının ihlalleridir. Doğrulama tekniklerini, mutasyon sınaması temelli kapsama ölçümü ile tamamlanır. Kapsama ölçümleri doğrulama testlerinin kalitesinin ölçülmesine imkan sağlar. Tekniklerimiz için araçlar geliştirdik ve MCAPI standartını kullanan bir takım çok çekirdekli program üzerinde araçlarımızın geçerliliklerini denetledik. Tekniklerimizin deneysel olarak etkinliklerini gösterdik. Doğrulama aracımızın otomatik olarak çok çekirdekli programları doğruladığını ve zamansal doğruluk savlarının ihlalini, olası kilitlenme ve yarış durumlarının listesini bulduğunu gördük. Geleneksel dinamik doğrulama teknikleri kullanılarak bulunamayan hataları bulduk. Kapsama aracımız çok çekirdekli programların doğrulanması için kullanılan test kümelerinin kalitesinin iyileştirilmesinde yardımcı olur. Ayrıca kapsama aracımızla orijinal yürütme çizelgesinden farklı potansiyel yürütme çizelgelerini de keşfedebiliriz.","As the demand for high performance software is constantly increasing, the need to develop multicore software is increasing, too. This results in degraded reliability of software and increased verification effort since multicore software has potentially more than one execution schedule. Verification approaches for eliminating errors in sequential software are not adequate for full coverage of errors in multicore software. We need not only concurrency aware but also efficient and scalable verification methods for multicore software. We present verification and coverage methods for multicore software that uses message passing libraries for communication. Specifically, we provide techniques to improve reliability of software using the new industry standard Multicore Communication API (MCAPI) by the Multicore Association. We develop dynamic predictive verification techniques that allow us to find actual and potential errors in a multicore software. Some of these error types are deadlocks, race conditions, and violation of temporal assertions. We complement our verification techniques with a mutation testing based coverage metric. Coverage metrics enable measuring the quality of verification test sets. We implemented our techniques in tools and validated them on several multicore programs that use MCAPI standard. We experimentally show the effectiveness of our methods. We show that our verification tool automatically verifies multicore programs and finds violation of temporal assertions, list of potential deadlocks, and race conditions. We find errors that are not found using traditional dynamic verification techniques. Our coverage tool helps to improve the quality of verification test sets for multicore programs. Furthermore, we can potentially explore execution schedules different than the original execution with our coverage tool."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çevresel zeka sistemleri, gerekli olduğunda bulundukları ortamları duyumsayarak vebu ortamlara tepki vererek insanların günlük hayatlarına destek olurlar. Çevresel zekasistemlerindeki araçlar, ortamdan aldıkları bilgiler ve içselbilgileriyle, ortak bir görevi yerine getirmek için birbirleriyle iş birliği yaparlar.Bu araçlar, kararlarını kendi değerlendirme süreçlerine ve stratejilerine dayanarak verirler.İşitsel, görsel, sağlıkla ilgili ve çeşitli uygulamalar birbirleriyle etkileşip,kullanıcının memnuniyetini arttırmak için birlikte çalışırlar. Araçlar arasındakibu ortaklaşa çalışma, kullanıcıya açık değildir.Bu tez, çevresel zeka sistemlerindeki araçları, her birinin kendilerine aityetenekleri ve amaçları olan özerk etmenlerle temsil eder. Bu araçlarınoluşturduğu sistem de dağıtık çok etmenli sistem olarak ele alınır. Amaçlar, etmenlerinulaşmayı arzuladıkları durumları gösterir. Çevresel zeka ortamlarındaki araçların proaktifdavranışları, amaçlar ile modellenir. Her etmen amaçlarına ulaşmaya motive olmuştur vekendisini amaçlarına yaklaştıracak eylemleri gerçekleştirir.Etmen, eğer kendisi amacını gerçekleştirecek yeteneğe sahipse bu yeteneğini kullanır; aksi halde dediğer etmenlerden yardım ister. Bu iletişim, etmenlerinbirbirleriyle sözleşme yapmasıyla oluşturulur. Bu sözleşmeler taahhüt tabanlı yöntem ile düzenesokulur. Biz, etmenlerin gereken durumlarda diğer etmenlerle taahhüt oluşturmalarıve kendilerine yapılan taahhütlere anlamlı cevaplar verebilmeleri için algoritmalarve kurallar geliştirdik. Geliştirdiğimiz sistemi, kahve makinesi, buzdolabı gibi araçları ve kullanıcıları temsil edenetmenlerden oluşan akıllı mutfak alanında uyguladık. Son olarak da bu yaklaşımımızı, var olan etmenler arasında olabilecekgerçekçi senaryolar üzerinden doğruladık.","Ambient Intelligence (AmI) systems support everyday lives of humans by sensingand reacting to the environment when necessary. Devices of the AmI world cooperatewith each other to achieve a common task by using the information they capture fromthe environment and through their internal knowledge. They make their decisionsbased on their reasoning processes and strategies. To increase the satisfaction of theuser, several types of applications cooperate with each other such as audio, visual andhealth care related applications. This cooperation is hidden from the user.This thesis proposes to view AmI devices as autonomous agents with dierentcapabilities and goals and the entire AmI system as a distributed multiagent system.Goals refer to the states that the agent desires to achieve. The proactive behaviorof the AmI devices are modeled with the goals of the agents. Each agent within thesystem is motivated to satisfy its goals. The agent selects its actions that will havepositive consequences on satisfying its goals. The agent decides and initiates relevantactions to satisfy its goals one by one. If the agent has the capability to achieve its goal,it just executes it. If the agent's capabilities are inadequate for satisfying its goal, thenit asks for help from other agents. Agents use contracts to interact with each other,which are regulated with a commitment-based methodology. We provide algorithmsand reasoning rules to help agents create and respond to the commitments in dierentsituations. We apply our approach on an intelligent kitchen domain consisting of smartkitchen devices such as a coee maker, a refrigerator and a user agent representing theresident of the kitchen. We demonstrate how our approach can accommodate severalrealistic cooperation scenarios."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz algılayıcı ağlar (KAA) için geliştirilen yeni çoklu ortam uygulamaları gecikme ve net veri iletim hızı cinsinden farklı hizmet kalitesi koşulları olan farklı trafik tiplerinin bir arada bulunmasını gerektirir. Önceliklendirmeye dayalı hizmet ayrım mekanizmaları, her trafik sınıfının hizmet kalitesi ihtiyaçlarını karşılayabilmek için bütün iletişim katmanlarında uygulanmaktadır. Çekişme önceliklendirmesi, ortam erişim katmanında uygulanan ayrım metodlarından biridir. Bu tezde, öncelik sınıflarının kullanımına tahsis edilen çekişme bölmelerinden oluşan öncelikli çekişme yapısında, farklı sınıfların çekişme gecikmelerini ve güç tüketimlerini bulabilmek için analitik bir model öneriyoruz. Analizde, her bir öncelik sınıfı için çekişme gecikmesi ve komşuluktaki toplam güç tüketimi bakımından en uygun bölme boyutlarını araştırıyoruz. Bu analitik model aynı zamanda KAAlar için geliştirilmiş çeşitli güncel çekişme önceliklendirme şemalarının değerlendirilmesi için kullanılabilir. Bu genel analiz, enerjiverimliliği için düşük görev döngülü işleyişi tanıtan SMAC protokolüne uyarlanmıştır. Görev döngüsü, çekişme penceresi boyutu ve veri boyutunun tek ve çok trafik tipi taşıyan ağların başarımına etkisi araştırılmıştır. Iletişime dayalı hizmet kalitesinden ayrı olarak, ağın algılama kalitesi KAAlarda yerleştirme kalitesini göz önüne alan başka bir hizmet kalitesi bakış açısını beraberinde getirir. Yerleştirme için algılayıcı düğümlerinin veya sinyal bozucular yüzünden iletişmin kaybını hesaba katan ağ parametreleri cinsinden bir kalite ölçüsü sağlayan teorik bir analiz sağlanmışır.","Emerging multimedia applications for wireless sensor networks (WSN) require the co-existence of different types of traffic with different quality of service (QoS) provisions in terms of latency and throughput. Prioritization based service differentiation mechanisms are applied in all layers of communication to satisfy the QoS requirements of each traffic class. The prioritization in contention is one of the differentiation methods applied in the medium access layer. In this thesis, we propose an analytical model for the contention latencies and energy expenditures of different classes in a prioritized contention structure consisting of contention partitions allocated to priority classes. In the analysis, we explore the optimum sizes of these partitions in terms of contention latency and the total energy expenditure in the neighborhood for each priority class. This analytical model is also useful for the evaluation of various recent contention prioritization schemes in WSNs. We adapt this generic analysis to SMAC protocol whichintroduces the low-duty-cycle operation for energy efficiency. We explore the effects of the duty cycle, the contention window size and the data size on the performance of networks with single and multiple types of traffic. Apart from the communication based QoS, the sensing quality of the network brings about another perspective to the QoS in WSNs regarding the quality of the deployment. We provide a theoretical analysis which derives a quality measure for the deployment in terms of network parametersaccounting the loss of sensors or loss of communication due to jamming."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Baz istasyonu yerleştirme ve uçbirim atama problemleri ağırlıklı bir şekilde çalışılmış olmasına rağmen literatürdeki çalışmalar WiMAX gibi birden fazla bağlantı sınıflarını destekleyen kablosuz ağlar üzerine doğrudan uygulanamamaktadır. Bu durum, WiMAX'te her abonenin servis kalitesini artırmak için birçok servis akışının kapsanmasından ileri gelmektedir. Bu tezde, kullanıcı ihtiyaçları ve problem kısıtlamaları ikil hızı gibi klasik birimlerin aksine zaman dilimleri kullanılarak temsil edilmiştir. Hem baz istasyonu yerleştirme hem de uçbirim atama problemlerini kapsayan bir optimizasyon problemi tasarlanmıştır. Çözüm olarak iki adet rastgele olmayan deneysel algoritma, DEAR ve CLEAN, önerilmiştir. Bu algoritmalar sırasıyla, eleme ve böl-ve-yönet tekniklerini kullanmaktadır. Tam sayı programlama çözümleri gerçek hayattaki sorunları önerilen şekilde formülleştirmek ve önerilen çözümleri uygulamak makul ve yerinde olduğunu göstermektedir.","Although the base station location and terminal assignment problem in cellular networks has been extensively studied, the previous work in the literature cannot be directly applied to wireless networks that support multiple classes of connections, such as WiMAX. This situation arises from the fact that WiMAX incorporates several service flows at each subscriber station for QoS provisioning. In this thesis, time slots are used to represent the requirements and the constraints as opposed to the classical representation that uses the bit rates. An optimization problem, which includes both the base station location and the terminal assignment problems, is defined and formulated. As the solution, two deterministic heuristic algorithms, DEAR (DEploy-Assign-dRop) and CLEAN (Cluster-dEploy-AssigN), are proposed, which follow elimination and divide-and-conquer techniques, respectively. Integer linear programming (ILP) solutions show that formulating real life cases with the defined formulation and using heuristic algorithms are suitable and reasonable."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde ülkemizde ve dünyada meydana gelen trafik kazalarının büyük bir kısmısürücü hatalarından kaynaklanmaktadır. ADES (Otomatik Sürücü Değerlendirme Projesi) projesininamacı, sürücüler tarafından yapılan trafik kural ihlalerinin araç içerisinde bulunan bir cihaztarafından algılanmasını sağlamak amacı ile geliştirilecek olan uygulamalar için bir altyapıoluşturmaktır. Tasarlanan sistem temel olarak iki kısımda incelenebilir. İlk kısım araç içerisindebulunan çeşitli algılayıcılar tarafından edinilen verileri işleyip bu verilerden değerli bilgilerçıkaran uygulamaları kapsamaktadır. Bu algılayıcılar GPS, kamera gibi yeni nesil araçlardabulunan cihazların yanı sıra RFID okuyucuları gibi araç içerisine sonradan eklenebilecek cihazlardanda oluşabilmektedir. İkinci kısım ise bu algılayıcılardan gelen bilgileri kullanaraksürücünün davranışlarını değerlendirmekle görevli olan çıkarım motorudur. Proje kapsamındabu amaç için tasarlanmış iki uzman sistem örneği verilmiştir. Tasarlanan çözüm gerçek kamerakayıtları üzerinde ve gelişmiş bir benzetim ortamında test edilmiş ve sonuçlar incelenmiştir.","Most of the traffic accidents occurred in the world and in our country are caused by thedrivers. ADES (Automatic Driver Evaluation System) project targets to present a frameworkfor integrating different applications for driver evaluation purpose. The proposed system canbe divided into two main modules. The first one, which is the data acquisition and processingmodule, acquires the sensor information from the outside world and processed this datato present valuable information to the decision system. The system may benefit from built-insensors like cameras or GPS (Global Positioning System) systems as well as non standard deviceslike RFID (Radio Frequency Identification) readers. The second module is the inferenceengine, which processes the information provided by the first module and makes judgmentsabout the actions of the driver. Two sample expert system designs are proposed in the project.The developed solution is tested in simulation environment and by using real video recordings."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, kablosuz ortamda IPTV yayını için alternatif bir çözüm önerilmektedir. IPTV servisi için gereken veri aktarım hızları ve kablosuz yayınlarda karsılaşılan güçlükler düşünülerek, modelimiz WiMAX olarak da bilinen IEEE 802.16 standartının ağ çalışma modu üzerine kurulmuştur. WiMAX teknolojisi ile sağlanılan yüksek veri aktarım hızlarının yanında, aktarımları iletme becerisi ve değişen çevreye adaptasyon kabiliyetiWiMAX ağ çalışma modunu altyapı tabanlı modellere karşı uygulanabilir bir alternatif haline getirmektedir.Önerilen modelde, standart WiMAX ağ çalışma modu, sıkı gecikme gereksinimlerini karşılayabilmek için değiştirilmiştir. Buna göre, aktarımlar sadece yüksek veri aktarım hızına sahip bağlantılar üzerinden yapılmaktadır ve baz istasyonuna en fazla iki adımda olan bağlantılara izin verilmektedir. Ek olarak, alansal ayrıklık bilgisinden yararlanılarak, efektif olarak daha çok kullanıcıya hizmet vermede kullanabilecek aktarım dilimleri kazandırmak için, eş zamanlı aktarımlar düşünülmüştür. Sonuçlarımız, kanal kalitesi kötü olduğu için sadece daha gürbüz modülasyon düzenleri kullanılarak ulaşılabilen az sayıdaki (%1'den daha az) düğümün ihmal edilmesi karşılığında, standart WiMAX ağ çalışma moduna göre daha fazla kullanıcıya hizmet verilebildiğini göstermektedir.","In this thesis, an alternative model is proposed for the distribution of IPTV in wireless environment. Considering the data rate requirements of the IPTV service and challenges in distribution of the service due to wireless environment, our proposed model is built on the Mesh operating mode of the standard IEEE 802.16 (a.k.a, WiMAX). Besides the high data rates provided by the WiMAX technology, the capability of relaying transmissions and the adaptability to changing environment brings the WiMAX Mesh mode as a viable alternative to the infrastructure based models.In our proposed model, the standard WiMAX Mesh mode is modified in order to meet the strict delay requirements of the IPTV service. Accordingly, transmissions are carried over only high data rate links and connections with up to two hops to the BS are allowed. Additionally, beneting from space diversity information, parallel transmissions are utilized to save transmission slots, and allow serving more users. The simulation results show that, for the given delay constraints, the proposed model improves capacity compared to the standard WiMAX Mesh mode at the cost of omitting a few nodes (less than 1%) for which the experienced channel quality is too low for IPTV service anyways."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgi Teknolojileri ülkelerin ekonomilerine önemli fırsatlar yaratarak, son yıllarda en hızlı büyüyen endüstrilerden biridir. Yazılım endüstrisi, bilgi teknolojisi alt alanı olup, tüm dünyada olağanüstü ilerleme göstermektedir. İsrail, Hindistan ve İrlanda yazılım endüstrisi dünya ticaretinin önemli bölümüne hakim olmasına rağmen, gelişmiş ülkeler yazılım endüstrisi aracılığıyla büyük gelirler sağlamaktadırlar.Yazılım endüstrisi, Türkiye'de diğer ülkelere nazaran daha geç gelişmeye başlamış olup, gelecek yıllarda yazılım endüstrisinin hızlanarak büyüyeceği öngörülmektedir. Yazılım endüstrisinin başarısı ve gelişmesi ekonominin büyümesi için kritik öneme sahiptir. Bu çalışmanın amacı, Türkiye'deki yazılım endüstrisinin örgütsel verimliliğini etkileyen örgütsel yapı faktörlerini tesbit etmektir. Bu çalışma kapsamında, literatür incelemesi yapılarak bir araştırma modeli geliştirilmiştir. Araştırma modeline göre anket hazırlanmış ve yazılım firmalarına anket uygulanmıştır.Anket sorularının geçerliliği ve güvenilirliği, Cronbach'ın alpha katsayısı kullanılarak test edilmiştir. Örgüt yapısının, örgütsel verimliliğe olan etkisini belirlemek için regresyon analizi yapılmıştır. Regresyone analizine ek olarak, örgütsel yapı ve verimlilik, firmaların yaşına, büyüklüğüne, denetlenme zorunluluğuna ve hiyerarşi derecesine göre değerlendirilmiştir.","Information Technology is one of the fastest growing industries in recent years, creating significant opportunities to the economies of countries. The software industry, a sub-field of information technology, performs extreme progress in all over the world. Even though Indian, Israeli, and Irish software industry have captured the essential portion of the world trade, well-developed countries provides a large revenues through software industry.Even though the software industry in Turkey has started to develop later than other countries, it is expected that the software industry will enhance accelerated growth in the future years. The success and development of software industry is critical for the growth of economy. The purpose of this study is to determine the organizational structural determinants affecting the organizational effectiveness of the software industry in Turkey. In this study, a research model is developed based on the examination of the literature. The research survey has been prepared regarding the conceptual model and software companies were surveyed.The validity and reliability of the questionnaire, Cronbach's alpha coefficient was tested. Regression analysis was conducted to determine the affect of organizational structural determinants on organizational effectiveness. In addition to regression analysis, the organizational structure and effectiveness are assessed regarding organizational age, and size, obligation to regular audit and the level of hierarchy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hata tahmini modelleri, yöneticilere bir yazılımda test edilmesi gereken kısımların önceliklendirilmesinde yardımcı olur. Yazılımda hata tahmini için kullanılan algoritmalar performans sınırılarına ulaşmıştır, öyleki daha ileri gelişmeler ancak giriş veri-lerinin içeriğini arttırmakla olabilir. Bu tezin amacı, yazılımcıların doğrulama sapması seviyelerini kullanarak performans limitini aşan hata tahmini modelleri oluşturmaktır. Doğrulama sapması metriklerini elde etmek için bir metodoloji tanımladıktan sonra sırası ile şu aşamaları gerçekleştirdik: i) yazılımcı ve testçilerin doğrulama sapması seviyelerini etkilemesi olası faktörlerin incelenmesi, ii) doğrulama sapmasının yazılımcı ve testçi performansını nasıl etkilediğine dair deneysel analizlerin yapılması, iii) statik kod ve doğrulama sapması metrikleri ile kaynak kod dosyalarında yapılan değişikliklerden elde edilen metriklerin değişik kombinasyonlarda kullanılmasıyla oluşturulan hata tahmini modellerinin karşılaştırmalı performans analizinin yapılması, iv) eksik doğrulama sapması metrik değerleri ile hata tahmini modellerini oluşturma metodolojisinin tanım-lanması. Endüstriyel verileri kullanarak şu sonuçları elde ettik: i) yazılım geliştirme ve test etme deneyiminin doğrulama sapması üzerinde etkisine rastlanmamıştır, öte yandan hipotez test etme ve muhakeme becerilerinin doğrulama sapması üzerinde etkileri gözlemlenmiştir, ii) yazılımcıların doğrulama sapması, yazılımda hata miktarı artışına neden olurken, testçilerin doğrulama sapması sürüm sonrası hata miktarının artmasına neden olmaktadır, iii) sadece doğrulama sapması metrikleri ile elde edilen hata tahmin performansının sadece statik kod veya kaynak kod dosyalarında yapılan değişikliklere ilişkin metriklerle elde edilen hata tahmini performansından daha iyi ya da bu değerlere yakın olduğu gözlemlenmiştir, iv) Eksik doğrulama sapması metrikleri ile kayda değer hata tahmini performansı elde edilmiştir.","Software defect prediction models help managers to prioritize their testing effort. Algorithms, which are used to learn defect predictors, have reached a ceiling such that further improvements may only come from increasing information content of input data. The main goal of this research is to build defect predictors which are learnt from developers' levels of confirmation bias, which is defined as tendency of people to seek for evidence to verify hypotheses rather than seeking for evidence to refute them. Our main goal is to overcome the ceiling effect in defect prediction performance. As a first step, we define a methodology to measure/quantify confirmation bias and then we perform the following empirical analysis: i) investigation of factors which have the potential to affect confirmation bias levels of software developers and testers, ii) empirical analysis of how confirmation bias affects software developer and tester performance, iii) a benchmark analysis comparing performance of defect predictors which use combinations of static code, confirmation bias and churn metrics, iv) defining a methodology to build defect predictors which can learn using incomplete confirmation bias metric values as input. Our results on industrial data show that: i) no effect of experience in software development/testing has been observed on confirmation bias, whereas hypotheses testing and reasoning skills affect confirmation bias, ii) confirmation biases of developers lead to an increase in defects, while testers' confirmation bias causes an increase post-release defects, iii) using only confirmation bias metrics, we can build defect predictors with higher or comparable prediction performance when compared to defect predictors that are learnt by using only churn metrics or only static code metrics, iv) promising results can also be obtained by using incomplete confirmation bias metric values to learn defect predictors."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Rastgele sayılar, simülasyon ve modellemede kullanılan en gerekliunsurlardandır. Rastgele sayıları üretmek için en güncel ve yaygın yöntem doğrusaleşleşiksel üreteçlerdir. Bu üreteçler, doğrusal bir fonksiyon ve mod alma işleminikullanarak sayıları üretir. Bu çalışmada ise, kaotik özelliği olan fonksiyonlarıkullanarak rastgele sayılar üretilebilmesi araştırılmaktadır. Kaotik özelliktekifonksiyonların tahmin edilemezlik özelligine dayandırılarak; çadır fonksiyonu,lojistik fonksiyonu ve birleştirme fonksiyonundan üretilmiş beş farklı rastgele sayı üreteciönerilmektedir. Bu üreteçlerin ürettigi sayıların, [0; 1] aralığında düzgün dağıldığıve bağımsız sayılar ürettiği üç aşamada test edilmiştir. Öncelikle, üretilen sayılarınhistogramları ve dizisel grakleri görsel olarak incelenmiştir. İkinci olarak, üretilensayıların istatistiksel olarak düzgün dağıldıkları Ki-kare testi ve Kolmogorov-Smirnovtesti kullanılarak test edilmiştir. Son olarak, ""Run"" testi ve otokorelasyon testi ileüretilen sayıların bağımsızlığı test edilmiştir. Ayrıca bu testler; önerilen beş üretecin,çok iyi bilinen ve sıklıkla kullanılan doğrusal eşleşiksel üreteçlerle kıyaslanırken dekullanılmıştır. Sonuç olarak, önerilen rastgele sayı üreteçlerinin görsel ve istatistikseltestlerde dogrusal eşleşiksel üreteçler kadar başarılı oldukları ve bu üreteçlerin rastgelesayı üretmek için kullanılabilecekleri ortaya çıkmıştır. Önerilen bu üreteçlerin; dahadetaylı matematiksel, istatistiksel ve işlemsel özelliklerinin araştırılması ve incelenmesigelecekte yapılacak yararlı araştırma konuları oluşturmaktadır.","Random numbers are necessary basic ingredients for simulation and modeling.Currently, linear congruential generators (LCGs) are typically used as random numbergenerators (RNGs), which generate pseudorandom numbers (PRNs) by using linearfunctions and modulus. In this study, we propose some chaotic functions to generatePRNs, using the unpredictability property of dynamical chaotic maps. We suggestve dierent RNGs that are derived from three dierent chaotic maps: tent map,logistic map, and family of connecting maps. The uniformity and independence of thenumbers generated through the ve suggested RNGs are checked in three steps. Firstly,the histograms and serial plots are visually checked. Secondly, chi-square andKolmogorov-Smirnov tests are applied to statistically test the uniformity of thegenerated numbers. Finally, runs tests and autocorrelation test are applied inorder to check the independence of the numbers. The same tests are applied tocompare the ve suggested chaotic generators with some well-known conventionallyused LCGs. It is concluded that the suggested generators perform nearly as well asLCGs and can lead to an alternative way of generating random numbers. More detailedmathematical, statistical, and numerical properties of the suggested generatorsconstitute useful further research topics."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde genel kuantum operatörlerini destekleyen yeni bir kuantum Turing makine modeli ile birlikteonun yığıt-bellekli, sayaçlı ve sonlu bellekli modelleri tanımlandı ve az belleğe sahipklasik ve kuantum makinelerin hesaplama güçleri bir çok durum için incelendi.Temel katkılarımız aşağıda özetlenmiştir.İlk olarak kuantum Turing makineleri sınırlı olmayan hata açısından ele alındı:(i) logaritma-altı bellek kullanılan bazı durumlarda hesaplama gücü açısındankuantum Turing makinelerinin klasik muadillerinden üstün olduğu gösterildi;(ii) aynı sonuç sonlu belleğe sahip kısıtlı kuantum Turing makineleri için de elde edildi;(iii) gerçek-zamanlı sonlu belleğe sahip belirlenimci olmayan kuantum Turing makinelerinintanıdığı dil ailesi belirlendi.İkinci olarak, sonlu belleğe sahip kuantum Turing makineleri sınırlı hata açısından ele alındı:(i) sola gitme veya durma hakkı yasaklanmış fakat kendisini başlangıç noktasına taşıyabilenözel kafaya sahip yeni çift-yönlü kuantum ve olasılıksal sonlu durumlu makineler tanımlandı;(ii) hesaplama gücü açısından bu tür kuantum makinelerin olasılıksal olanlardan daha güçlü olduğu gösterildi;(iii) bu modeller temelinde, çift-yönlü olasıksal ve klasik kafaya sahip kuantum sonlu durum makinelerin,çift-yönlü belirlenimci olmayan sonlu durum makineler ile kendi tek-yönlü muadillerindendaha az sonlu bellek kullandıkları gösterildi;(iv) ayrıca olasılıksal ve kuantum sonseçimli sonlu durumlu makineler ile sınırlı hata payıile tanıdıkları dil sınıfları tanımlandı ve bir çok özellikleri gösterildi.Üçüncü olarak, sadece yazma hakkı olan bir hafıza eklenen gerçek-zamanlı kuantum sonlu durumlumakenelerin hesaplama gücü, farklı türdeki sayaçlı makineler üzerinden yapılan bir çok benzetim ile incelendi.Paralel olarak, sayaçlı ve yığıt-bellekli makinelere dair bazı sonuçlar elde edildi.Son olarak, literatürde geçen bazı alt sınırların,düzenli olmayan bir dili tanıyan gerçek-zamanlı klasik Turing makineler için mümkün olan en iyi sınırlar olduklarıgösterildi.Ek olarak, benzer soru diğer tür gerçek-zamanlı makineler için araştırıldı veonlar tarafından az bellek ile tanınan birçok düzenli olmayan dilin varlığı gösterildi.","In this thesis, we introduce a new quantum Turing machine model that supportsgeneral quantum operators, together with its pushdown, counter, and finite automaton variants,and examine the computational power of classical and quantum machines using small space boundsin many different cases. The main contributions are summarized below.Firstly, we consider quantum Turing machines in the unbounded error setting:(i) in some cases of sublogarithmic space bounds, the class of languages recognized by quantum Turing machinesis shown to be strictly larger than that of classical ones;(ii) in constant space bounds, the same result can still be obtained for restricted quantum Turing machines;(iii) the complete characterization of the class of languages recognized byrealtime constant space nondeterministic quantum Turing machines is given.Secondly, we consider constant space-bounded quantum Turing machines in the bounded error setting:(i) we introduce a new type of quantum and probabilistic finite automatawith a special two-way input head which is not allowedto be stationary or move to the left but has the capability to reset itselfto its starting position;(ii) the computational power of this type of quantum machineis shown to be superior to that of the probabilistic machine;(iii) based on these models, two-way probabilistic and two-way classical-head quantumfinite automata are shown to be more succinct than two-way nondeterministic finite automataand their one-way variants;(iv) we also introduce probabilistic and quantum finite automata with postselection with theirbounded error language classes, and give many characterizations of them.Thirdly, the computational power of realtime quantum finite automata augmented with awrite-only memory is investigated by showing many simulation results for different kinds of counter automata.Parallelly, some results on counter and pushdown automata are obtained.Finally, some lower bounds of realtime classical Turing machines in order to recognize a nonregular languageare shown to be tight. Moreover, the same question is investigated for some other kinds of realtime machines andseveral nonregular languages recognized by them in small space bounds are presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kanser gunumuzun en sık gorulen ve en olumcul hastalıklarından biridir. Bu nedenle,kanserin nedenleri en cok araştırılan konulardandır. Kanserin nedenlerinden birtanesi, cesitli sebeplerle, tumor baskılayıcı proteinlerin, işlevlerini gerektiği gibi yerinegetirememesidir. Bu proteinler genellikle işlevlerini karşılıklı etkileşimlerle gerçekleştirirler.Bu sebeple, baskılayıcı proteinleri anlamak için , bu etkileşimleri incelemek önemlidir.Bu incelemenin sonuçlarının, kanser aratırması, ilaç tasarımı ve protein mühendisliğigibi alanlarda önemli etkileri olacaktir. Bu nedenle, protein etkileşimleri ProteinEtkileşim Haritalarının aracılığıyla görselleştirilmekte ve bu sayede daha iyi incelenebilmektedir.Günümüzde protein etkileşimlerinin toplu ifadesini gösterecek bir sembol standardınaihtiyacı vardır. Bu sebepten, Kohn ve grubunun MIM notasyonunun, buihtiyacı karşılayacağı ön görülmektedir. Protein etkileşimlerinin grafik gösterimi içinyazılmış bazı yazılımlar olmasına rağmen, MIM notasyonunu tüm ayrıntıları ile destekleyenbir araç daha geliştirilmemiştir. Bu nedenle, bu tezde, Kohn notasyonu ile proteinetkileşimlerini çizebilen bir araç geliştirmeyi hedefledik. Öncelikle, elle çizebilen biraraç geliştirdik. Daha sonra bu araca, araştırmamızın en önemli kısımlarından biriolan, yarı otomatik grafik çizme kısmını ekledik. Bu kısımda Dijkstra'nın en kısayol bulma algoritmasını kullandık. Bu sayede, fiziksel varlıklar arasındaki etkileşimlerotomatik olarak çizilebiliniyor.Bu araç sayesinde, Protein Etkileşim Haritalarınıçizmek, güncellemek ve değiştirmek çok daha hızlı olacak. Bu da, harcanan zamanı vegereksiz iş yükünü azaltacaktır.","Cancer is one of the most lethal and common diseases of today. Causes of cancerhave been studied widely as it is an essential part of cancer research. Cancer is mainlycaused by malfunctioning of the tumor suppressor proteins. Generally, these proteinstake part in protein-protein interaction networks. Hence, to understand the suppressorproteins, it is important to study these networks. Results from this study will havegreat impact on the cancer research, drug design and protein engineering. For thatreason, these networks are represented in network diagrams called Protein InteractionMaps to visualize and understand them better.Today, there is still a need for the standard for visualization of the protein interactions.For this reason, Kohn and his group?s MIM (Molecular Interaction Map)notation is considered to be the answer to that need. Even though there are some toolsfor graphical visualization of protein interactions, there is no tool that can draw proteininteractions with MIM notation with full support. Thus, in this study we aimed todesign a tool that can draw with Kohn?s notation. We developed MIMTool; a drawingtool for manually drawing protein interaction maps in Kohn notation. Later, as one ofthe most important part of our study, we added a semi-automatic map drawing featureto the tool. This feature automatically draws the interactions between physical entitiesusing Dijkstra?s shortest path algorithm.With MIMTool, it will be much faster to draw, update and exchange molecularinteraction maps. Use of this tool will save time and decrease work load."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tasarsız arac ağlari arasında konuma dayalı en bilinen yonlendirme protokolu Greedy PerimeterStateless Routing (GPSR) protokoludur. GPSR iki farklı tarzda calısır. Fırsatcı algoritma modu vekurtarma algoritma modu. Yonlendirme kararı icin GPSR kendi arac komsu dugumleri arasındabir liste olusturur. Sonraki dugum secimi icin, fırsatcı modunda, komsu dugumler arasındahedefe en yakın cografi noktadabulunan dugum secilir. Fakat bazı zamanlarda cografi olarak yakın olan dugum secildigi haldeveri iletiminde basarısız olur. Bu durumda ileriye dogru gonderim yapılması olanaksızdır. GPSRalgoritmasi kurtarma moduna gecer, bu mod GPSR'ın tamir stratejisini tanımlar. Diger taraftan,tasarsız arac aglarının topolojisi sebebiyle, GPSR bircok farklı olası yolların ve kavsakların olustugusehir ortamında yeterince etkin degildir. Simdiye kadar bir cok GPSR'ı gelistirme calısmaları yapılmıstır,ornek olarak Greedy Perimeter Coordinator Routing (GPCR) ve Greedy Border Superiority Routing (GBSR) verilebilir.GPCR data paket yonlendirimi icin, yol topolojisinde bulunan kavsaklar uzerindeki dugumleri kullanır vehep yonlenimi kavsaklar uzerinden yapar. GBSR ise yerel maksimum durumuyla karsılastıgı sıradaduzlemsel cizge yaratmak yerine sınır ustunluklu cizge yaratır. Bu tez icerisinde sehir topolojisini vearacların gercek hareketlerini dikkate alan bir yonlendirme protokolu onerilmektedir. Tasarsız aracagları icin uyarlanabilir yol saptama algoritması (ARAV) cozumu ile GPSR'a gore paket iletim oranıartmıs, gecikme zamanı kısalmıs, cıkan is oranı artmıs ve firsatcialgoritmanın calısma oranı GPSR'a gore artmıstır. ARAV algoritmasının fırsatcı modundaGPCR ile birlikte tasıt yogunluk algoritması kullanılmıstır. ARAV, GPCR ve GBSR'dan uyarlanabiliryonlendirme algoritması ile farklılık gosterir. ARAV fırsatcı modunda GPCR algoritmasının eksiklerinitasıt yogunluk algoritması ile gelistirmektedir.","The most known position based routing protocol for high mobile vehicular ad-hocnetworks is the Greedy Perimeter Stateless Routing (GPSR) protocol. This protocolcontains two routing modes, the greedy mode and the recovery mode, and creates aneighbor list to make a routing decision. The GPSR uses the greedy forwarding methodwhereas hops that follow are chosen based on nodes which are geographically closerto the destination node among the neighboring nodes. Nevertheless, forwarding failsif the current node is geographically the closest but unable to forward the packets tothe destination. In this situation, the GPSR algorithm acts in recovery (perimeter)mode which is the repair strategy of this algorithm. Some enhancements such as theGreedy Perimeter Coordinator Routing (GPCR) and the Greedy Border SuperiorityRouting (GBSR) have been proposed. In this thesis, a routing protocol which workson real city maps and takes into account the actual movements of vehicles in cityenvironment is recommended. We describe Adaptive Routing Algorithm For VehicularNetworks (ARAV) as a solution that improves the packet delivery ratio of GPSR andalso improves the GPCR with road vehicle density information. ARAV differs fromGPCR and GBSR, in that it uses routing algorithms adaptively in two routing modes.In ARAV greedy mode, we address the shortcomings of GPCR by considering thedensity of the paths. Packets are routed from one junction to another, the direction andposition of hops are determined by taking the density of the paths into consideration.Our simulation results show that the proposed ARAV protocol outperforms the GPSRprotocol in terms of packet delivery, throughput, delay in one successful transmissionand greedy/perimeter ratio."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Erişilebilir elektronik verinin ve ortamın son zamanlarda hızla artmasıyla, elektronik dokümanları otomatik olarak analiz etme ihtiyacı da artmıştır. Bir dokümanın işe yarar bilgi içerip içermediğini değerlendirmek için dokümanın ana fikri, anahtar kelimeleri ya da kavramları biliniyor olmalıdır. Türkçe için anahtar kelime çıkarma ve ana fikir çıkarma üstüne yapılmış birkaç çalışma bulunmaktadır. Kavram çıkarma çalışmaları, birkaç yabancı dil için yapılmış olmasına rağmen kaynaklarımıza göre Türkçe için henüz böyle bir çalışma yapılmamıştır.Bu tezde, Türkçe için kavram çıkarma sistemi ortaya konulmuştur. Türkçe karakterlerin bilgisayar diline uymaması ve Türkçenin sondan eklemeli karmaşık yapısından dolayı öncelikle bir ön işleme aşaması gereklidir. Ön işlemenin sonucunda, çekim eklerinden de ayrılmış olan kelimelerin sadece isim türünde olanları kullanılmıştır. Çoğu kavramın tanımı isim türünde kelimeleri kullanarak yapılabilir. Bunun için, benzer kelimeleri sınıflandırmanın kavram çıkarma çalışması için yararlı olabileceği düşünülmüştür. Bu istatiksel metotların ardından doğal dil işleme yöntemleri de uygulanıp test derlemindeki dokümanlar kavramlarla tanımlanmıştır. Derlem üzerinde kelime, sınıf ve kavram bazında olmak üzere çeşitli denemeler yapılmıştır. Sonuç olarak, sistem üretmesi gerekenden daha fazla kavram üretmiş olmasına rağmen, yüzde 51 başarı ile dokümanlara ait kavramları bulmuştur. Kavramların yapı itibariyle dokümanlarda aynen geçmeme ihtimali ve Türkçenin karmaşık yapısı düşünülürse bu sonuç oldukça başarılı olarak değerlendirilebilir.","In recent years, due to growing vast amount of available electronic media and data, the necessity of analyzing electronic documents automatically is increased. In order to assess if a document contains valuable information or not, concepts, key phrases or main idea of the document have to be known. There are some studies on extracting key phrases or main ideas of documents for Turkish. However, to the best of our knowledge, there is no concept extraction system for Turkish although there are some studies for foreign languages.In this thesis, a concept extraction system is proposed for Turkish. Since Turkish characters do not fit with the computer language and Turkish is an agglutinative and complex language a pre-processing step is needed. After pre-processing step, only nouns of corpus, which are cleared from their inflectional morphemes, are used because most concepts are defined by nouns or noun phrases. In order to define documents with concepts, clustering nouns is considered to be useful. By applying some statistical methods and NLP methods, documents are identified by concepts. Several tests are done on the corpus that is tested in the bases of words, clusters, and concepts. As a result, the system generates concepts with 51 per cent success, but unfortunately it generates more concepts than it should be. Since concepts are abstract entities, in other words they do not have to be written in the texts as they appear, assigning concepts is a very difficult issue. Moreover, if we take into account the complexity of the Turkish language this result can be seen as quite satisfactory."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde bilişsel radyo ağı (BRA) modelinde çizelgelemeiçin buluşsal algoritmalar önerilmistir. Kullanılan BRA planında, merkezi bir baz istasyonufrekans zaman dilimi kaynak çiftlerini birden fazla anteni olabilecek ikincil kullanıcılara (İK) atamaktadır. Önerilen algoritmalar servis alanındaki birincil kullanıcılarınrahatsız olmamasını, İK' ler arasında çarpışma yaşanmamasını, her İK' nin her çizelgelemedöneminde en az bir zaman dilimi almasını ve İK' lerin baz istasyonuyla güvenilir birbiçimde iletişim kurmasını garanti etmektedir. İlk algoritmanın amacı ağ üretilen işiniarttırmaktır ve bunu yaparken probleme özgü geliştirilmiş açık arttırma yöntemleri kullanılmıştır. Diğer algoritmalarda ise istediği veri hızını elde etmiş memnun İK sayısınıarttırmak hedef alınmıştır.","In this thesis we propose heuristic scheduling algorithms for the centralized, timeslotted cognitive radio network (CRN) model in [1]. In the considered CRN scheme, afrequency f and time slot t pair constitutes a resource r and a centralized cognitive basestation (CBS) coordinates the assignment of the resources to the secondary users (SUs)possibly with multiple antennas. The proposed algorithms dier in their problem objectives,but they all make sure that none of the primary users in the service area of theCBS is disturbed, no collisions occur among the SUs and each SU gets at least one timeslot per scheduling period. For the throughput maximizing scheduling (TMS) problem,an auction theory based algorithm is proposed whereas Best First Resource Assignment(BFRA) and Resource Assignment With Partial Backtracking (RAPB) algorithms areproposed for the maximizing the number of satised users (MNSU) problem whose objectiveis to increase the number of satised SUs where an SU is satised only if its minimumdata rate requirement is met."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Verilerdeki belirsizliklerin zorluklarından ötürü olasılıksal veritabanları, akademik literatürde yavaş yavaş kabul görmeye başladı. Henüz çok yeni bir araştırma konusu olduğu için hala birçok açık problem bulunmakta. Olasılıksal veritabanlarının dış kaynak olarak kullanılması daha önce hiç çalışılmadı, çünkü henüz ticarileşmiş bir olasılıksal veritabanı yönetim sistemi yok. Bu çalışmanın amacı dış kaynak olarak kullanılmış olasılıksal veritabanlarındaki sorguların doğrulanması. Doğrulama işlemlerine geçebilmek için öncelikle indeksleme yöntemlerinin incelenmesi gerekir. Bu amaçla literatür taraması yaptık ve pdr-Ağaç üzerinde çalışmaya karar verdik, çünkü bu yapılar hem olasılıksal veritabanları üzerinden çok etkili çalışıyor, hem de doğrulama yöntemleriyle başarılı bir biçimde örtüşüyor. Bu çalışmada, pdr-Ağaç ile MH-Ağaç'ları birleştirerek PH-Ağaç diye adlandırılan yeni bir doğrulama veri yapısı önerdik. Bu birleştirmeyi daha da geliştirmek amacıyla önişlemci olarak k-orta kümeleme tekniğini kullandık. Bu sayede algoritmalarımızın düşük performanslı çalışmasını engelledik. Önerdiğimiz veri yapısını MR-Ağaç ile karşılaştırdık ve PH-Ağaç'ların MR-Ağaç'lardan çok daha iyi çalıştığını deney sonuçlarıyla ispatladık.","Probabilistic databases are beginning to expand in the database literature because of the upcoming challenges of uncertainty. It is a very new topic for the community and there are still some open problems for the researchers. Outsourcing probabilistic databases has never been worked before since there are no commercial probabilistic database management systems yet. The aim of this research is to introduce authenticated query processing in outsourced probabilistic databases. In order to proceed with the authentication, indexing methods should be analyzed first. We have surveyed the existing structures for this purpose and decided to use pdr-Tree as the indexing method, because it works very efficiently on probabilistic databases and fits really well with the authentication techniques. We have proposed a novel authenticated data structure (ADS) called PH-Tree, which is an hybrid model of pdr-Tree and MH-Tree. Straightforward approach is not competent for hybridization and produce very poor results. By this reason, we have also implemented k-means clustering as a preprocessor. We have compared our algorithm with an existing ADS called MR-Tree and proved that PH-Trees outperform MR-Trees significantly."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Robotlar kendilerinden hangi görev ve becerileri icra etmeleri beklendiği ve bu görev ve becerileri nasıl gerçekleştirecekleri konusunda bilgilendirmeye ihtiyaç duyarlar.Bu bilgilendirmenin nasıl yapılacağı konusunda üzerinde anlaşılmış evrensel bir metod henüz bulunmamakla birliktepopüler olarak kullanılan metodlar arasında en yaygın olanı ilgili görev ya da beceriyi gerçekleştirebilecek bir algoritmanın geliştirilmesidir.Böyle bir algoritma geliştirmek, sistemin bir modelinin bulunmasını gerektirir.Dahası, basit durumlar için görevi yerine getirecek bir algoritma geliştirmek kolay olsa da, algoritmanın varsaydığı modeli daha karmaşık durumları da kapsayabilecek şekildegüncellemeye devam etmek giderek daha çok zaman alan bir sürece dönüşmektedir.Gösterimden öğrenme (GÖ), robotu programlamadan görev ve beceri bilgisini aktarmak için kullanılan bir yöntemdir.Bu yöntemde robotu programlamak yerine bir öğretmen görev ya da becerinin nasıl icra edileceğini robota gösterir ve robot bu gösterimleri sistemin o anki durumu ile birlikte kaydeder. Bu işlemi takiben gösterilen görev ya da beceriyi tekrarlayabilmek için kaydedilen veri üzerinden bir icra politikası oluşturulur.Söz konusu görev ya da becerinin karmaşıklığına bağlı olarak düzgün genelleştirilmiş bir icra politikası oluşturabilmek için gereken sayıda gösterimirobota sunmak çok zaman alıcı bir süreç olabilir.Bu tez, yeni bir tamamlayıcı düzeltici gösterim anlayışı olan Model Artı Düzeltme (M+D) paradigmasını bir görev ve beceri başarım iyileştirme yöntemi olarak sunmaktadır.M+D yöntemi model-tabanlı ve veri-güdümlü yaklaşımlar arasında bir denge kurarak bu yöntemleri birbirlerini tamamlayacak şekilde birleştirmektedir.Bu yöntemde, söz konusu görev ya da beceriyi sınırlı bir başarım ile gerçekleştirebilen bir algoritmanın var olduğunu varsayıyoruz. Yaklaşımımız, söz konusu görevi mevcut algoritma ile icra eden robotun eylemini algoritmanın yanlış bir karar alması halinde devreye girerekdüzeltecek bir insan öğretmen kullanmaktadır. Sistemin o anki durumu ile damgalanarak saklanan gösterim bilgisi daha sonra bir düzeltim kullanımı fonksiyonu ve sistemdurumuna gore varsayılan algoritmanın hesapladığı eylemin uygun bir şekilde değiştirilmesinde kullanılır.Bu tez ayrıca aynı tamamlayıcı düzeltici gösterim yaklaşımının birden fazla detay çözünürlüğünde kullanılabilmesi için de bir algoritma sunmaktadır.Çoklu-Çözünürlüklü Model Artı Düzeltme (ÇÇM+D) algoritması her biri ayrı detayda durum ve eylem tanımlarına ve değişik karmaşıklıkta varsayılan algoritmalara sahip bir dizidetay çözünürlüğü tanımlanmış olduğunu varsayar. Daha az detaylı bir durum ve eylem tanımı ve daha az karmaşık bir algoritmanın kullanılması, durum uzayının daha büyük bir kısmınındaha az hesaplama maliyeti ile kapsanmasını sağlar. Gosterim sırasında öğretmen robota o anki detay çözünürlüğünde düzeltici gösterim yapmasının yanında hangi durumda hangi detay çözünürlüğünün kullanılması gerektiği konusunda da gösterimde bulunur.Farklı karmaşıklık seviyelerine sahip birden çok detay çözünürlüğünün bulunması, sistemin daha detaylı durum ve eylem tanımları ve daha karmaşık algoritmaları ancak gerektiğinde kullanabilmesini sağlar.Öğrenilen detay seçim politikası ön tanımlı olarak en düşük detay çözünürlüğünü kullanmaya çalışır ve daha yüksek bir detay çözünürlüğüne ancak daha önce benzer bir durumda öğretmen tarafından detay çözünürlüğünü arttırma komutu verilmişse geçer.Sunduğumuz deney sonuçları M+D yönteminin önce beceri iyileştirmeye bir örnek olarak karmaşık bir iki ayaklı yürüme eyleminin dengesini iyileştirme problemine uygulanmasının,sonra da görev iyileştirmeye bir örnek olarak robot futbolu ortamında tanımlanmış bir top sürme problemine uygulanmasının sonuçlarını içeriyor.Bunlara ek olarak, ÇÇM+D yönteminin bir insansı robotun bir robot futbolu sahasında engel savuşturması problemine uygulanması ile ilgili deney sonuçları da sunuyoruz.Son olarak, önerilen algoritmaların ortamdaki belirsizlikten ne kadar etkilendikleri ve birden çok detay çözünürlüğü kullanmanın tek bir çözünürlük kullanmaya göre hesaplamasal maliyet karşılaştırmaları üzerine bir deneysel analizi insansı robot engel savuşturması probleminin benzetim ortamında modellenmiş bir halini kullanarak sunuyoruz.","Robots need to be taught what type of tasks or skills they are expected to perform, and how to perform those particular tasks or skills.However, there is no universally accepted single approach for transferring the task and skill knowledge to a robot.Among several popular approaches, the most widely adopted method for transferring the task or skill knowledge to the robot is to developan algorithm for performing the task or skill in question.Such development require a model of the system to be available.Moreover, despite that it usually is easier to develop a simple algorithm tohandle trivial cases, it becomes a time consumingprocess to keep refining the algorithm by modifying the underlying model to handle more complex situations.Learning from Demonstration (LfD) is another populer approach for transferring the task andskill knowledge to the robot.Instead of explicit programming, a teacher demonstrates the robot how to perform the task or skill andthe robot records the demonstrated action together with the perceived state of the system at the time of demonstration.An execution policy is then derived out of the recorded demonstration data for reproducing the task or skill.Depending on the complexity of the task or skill in question and the robotic platform to be used, providing sufficient number of examplesin order to be able to extract a generalized execution policy can be a very time consuming process.\newpageThis thesis contributes a novel complementary corrective demonstration para-digm called Model Plus Correction (M+C) for task and skill refinement on autonomous robots.The M+C approach strikes a balance between model-based and data-driven methods by combining them in a complementary manner.We assume the availability of an algorithm capable of performing the task or skill in question with limited success in termsof performance. Our approach utilizes a human teacher who observes the partially successful execution of the task, and corrects the action of the robot when the default algorithmis unable to select an appropriate action to be executed. The collected demonstration data stamped with the state of the system at the time of demonstration is then usedto augment the default algorithm by modifying the action computed by the algorithm according to a correction reuse function, and the state of the system.This thesis also introduces an algorithm for using the same complementary corrective demonstration approach at multiple detail resolutions.The Multi-Resolution Model Plus Correction (MRM+C) algorithm assumes that a set of detail levels are defined with different state and action representations together with a different model-based controller for each detail level are available at hand.The teacher provides demonstration for which detail resolution to use at a particular state of the system in addition to delivering corrective demonstration for the controller associated with the current detail resolution.Having multiple detail resolutions with different complexities allows the system to use more detailed state and action representations and more complex model-based controllers only when needed.Using a less detailed state and action representation with a simpler controller makes it possible to cover the solution space at a lower computational cost and using fewer number of demonstrations.The learned detail resolution selection policy favors the least detailed resolution by default and switches to a more detailed resolution if commanded to do soin a similar state before.We present experiment results where the M+C approach is first applied to a complex biped walk stability improvement problem as an example to the skill refinement,and to a ball dribbling problem in a robot soccer environment as an example to the task refinement. We also present experiment results where the MRM+C approach is appliedto a humanoid obstacle avoidance task on a robot soccer field. Finally, we present an experimental analysis of the proposed algorithms in termsof their robustness against uncertainty and the cost analysis of using multiple detail resolutions over using a single detail resolution in a simulated version of the obstacle avoidance task."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde tüp bebek tedavisinde klinik başarı oranlarının arttırılması için karar verme problemleri yapay öğrenme bakış açısı ile ele alınmıştır. İlk olarak, embriyo bazlı implantasyon tahmini için sınıflandırma tekniklerinin kapsamlı ve karşılaştırmalı bir analizi sunulmuştur. Aynı zamanda, özniteliklerin belirleyici etkileri değerlendirilmiş ve gereksiz değişkenler elenerek en iyi kestirim performansı oluşturan ideal öznitelik alt kümesi belirlenmiştir. Literatürde yer alan az sayıdaki ilgili çalışmada ifade edilenlerin aksine, başlangıç deneyleri sınıflandırıcı yöntemlerin tüp bebek tedavisinde potansiyel karar destek araçları olabileceğini göstermektedir. Çalışmanın devamında, metodolojik iyileştirmeler ya da veri kümesinin bilgi içeriğinin genişletilmesi ile tahmin performansının arttırılması üzerinde yoğunlaşılmıştır. İlk olarak, dengesiz sınıf dağılımı problemi ele alınmış ve karar eşik değerinin optimize edilmesi ile öğrenme kümesinin tekrar örneklenmesi benzer sonuçlar oluşturmuştur. İkinci olarak, kategorik özniteliklerin sürekli sayısal değerlere dönüştürülmesi için frekans tabanlı bir kodlama yöntemi önerilmiştir. Üçüncü olarak, hasta ve embriyo özelliklerine ek olarak, doktorların deneyimlerinin tedavi sonucuna olan etkisi incelenmiştir. Son olarak, blastosist skoru tahmini için Bayes Ağları yöntemi kullanılarak embriyo gelişim süreci modellenmiştir. Koşullu olasılık tablolarındaki parametrelerin daha iyi öğrenilebilmesi için yeni bir yöntem önerilmiştir. Deneylerde i) standard yapay öğrenme yöntemlerinin implantasyon ve blastosist skoru tahmininde kabul edilebilir başarı oranı elde ettiği ve ii) bu çalışmada önerilen yöntemler kullanılarak tahmin performansının arttırılabileceği görülmektedir. Bulgular klinik açıdan çoğul gebeliklerin azaltılması, embriyo kayıplarının azaltılması ve transfer iptallerinin engellenmesini sağlayacaktır.","In this thesis, we address the decision-making problems in in vitro fertilization treatment from the machine learning perspective aiming to increase the clinical success rates. Initially, we present a comprehensive and comparative analysis of the classification techniques in embryo-based implantation prediction. In parallel, we evaluate the predictor effects of input features in order to eliminate the redundant variables and decide the optimum feature subset leading to the highest prediction performance. In contrast to the limited relevant literature, our preliminary experiments demonstrate the potential of machine learning classifiers as an automated decision support tool in critical decisions affecting the success of the treatment. Later, we focus on improving the classification performance either by algorithmic enhancements or by improving the information content of the data. First, we handle the problem of imbalanced class distribution and show that decision threshold optimization and re-sampling the trainingdata produce similar results. Second, we propose a frequency based encoding technique to efficiently transform categorical variables into continuous numeric values. And third, in addition to the patient and embryo characteristics, we investigate the effect of individual physicians as a human factor on the pregnancy outcome. Finally, we apply Bayesian Networks to model the embryo growth process with the objective of blastocyst score prediction. We propose a novel approach to adjust the frequency estimatesfor parameter learning in conditional probability tables. The results of the experiments show that (i) the standard machine learning algorithms enable acceptable prediction of implantation and blastocyst score and ii) the prediction performance can be improved by using the proposed techniques in this study. From the clinical perspective, our results have practical implications in reducing multiple pregnancies, preventing waste of embryos and cancelation of transfers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Konum belirleme yeteneklerine sahip mobil cihazların artmasıyla konum tabanlıservisler büyük fırsatlar vaat etmektedir. Bunun yanısıra, servis sağlayıcılar sunucuların bakım ve yönetimleri ile uğraşmak yerine sağladıkları servislere odaklanabilmeyiistemektedir. Servis sağlayıcıların bir diğer gereksinimi de bilişim altyapılarını pazarihtiyaçlarına göre ayarlayabilmektir. Bu nedenlerden dolayı dış kaynaklı mekansal veritabanlarına olan ilgi artmaktadır. Mekansal dış kaynaklı veri tabanlarında kişisel bilgilerikorumaya yönelik çeşitli sorgular için geliştirilmiş yöntemler literatürde mevcuttur.Bu sorgulara örnek olarak, en yakın komşuyu bulma veya en yakın K tane komşuyubulma verilebilir. Bu tez çalışmasında ise kapasite ve kapsama kısıtları olan bir atamasorgusu dış kaynaklı veri tabanları için uyarlanmıştır. Diğer atama sorgularından farklıolarak, konum tabanlı servisler için daha gerçekçi olması nedeniyle, seyrek diyagramlıatama sorgularına yoğunlaşılmıştır. Yaklaşık sonuçlar için hem gizlilik hem de performansgereksinimlerini karşılayan yeni bir mekansal transformasyon stratejisi (kare spiralkodlama) tanıtılmıştır. Sonucun isabetliliği ile konum gizliliği ve hesaplama maliyetiarasında bir denge mevcuttur. Örneğin, konum gizliliği artarsa, hesaplama maliyetive sorgu sonuçların doğruluk oranı azalmaktadır. Kesin sonuçlar için kullanılabilecekyeni bir yöntem daha önerilmiştir. Bu yöntem ile şifrelenmiş mekansal veriler arasında,şifre çözme işlemi yapmaya gerek kalmadan uzaklık hesaplanabilmektedir. Deneylerdeher iki metot karşılaştırılmış, performans ve maliyetleri incelenmiştir.","With the growth of mobile devices that have positioning capabilities, locationbased services promises great opportunities. Moreover to this, service providers wouldlike to focus on their services instead of managing servers and they require exibility toexpand or shrink their infrastructure according to the market. These are the two strongdrives for outsourced spatial databases. In the literature, several different queries suchas nearest neighbor, K-nearest neighbor, proximity and privacy preserving techniqueshave been studied in outsourced spatial databases. In this thesis, the capacity and coverageconstrained assignment query is adapted to the outsourced databases. Unlike theother assignment queries in fully connected graphs, we focused on sparse graphs whichis more realistic for location based services. A novel spatial transformation strategy(square spiral encoding) is introduced to achieve privacy and performance requirementswith approximate results. Approximate solution provides a trade off between resultaccuracy, location privacy and computation cost . For exact results, we also introducea new method to calculate distance over encrypted spatial data. In the experiments, wecompared the both methods and investigate their performance and costs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Düşme, özellikle yaşlılar için, önemli bir risk ve yaşlıların bağımsız yaşamı önündebir engel olarak belirlenmiştir. Bir düşme durumunda hızlı müdahale gerekmektedir,fakat düşmeden kaynaklanan sebeplerle düşen kişi kendi başına yardım çağıramayacakdurumda olabilir. Düşme durumlarının hızlı ve otomatik bir şekilde algılanması, düşmekaynaklı sağlık risklerini azaltacağı gibi yaşlılar için bağımsız ya¸ santıyı daha güvenlihale getirecek ve bağımsız yaşam önündeki bu engeli kaldıracaktır. Bu tezde otomatikdüşme sezme amacı ile giyilebilir ivmeölçer kullanan dalgacık dönü¸ sümü tabanlı biryöntem önermekteyiz. Ayrıca çeşitli etmenlerin düşme sezme yönteminin başarımınaolan etkisini incelemek amacı ile çok sayıda deney yapılmış olup, bunların sonuçlarıda bu tezde verilmektedir. Sonuçlar önerilen yöntemin pek çok farklı etmenin etkisialtında yüksek başarım gösterdiğine işaret etmektedir.Bahsedilen düşme sezme yöntemi, WeCare adı verilen bir sağlık gözetimi ortamınınparçası olan giyilebilir ivmeölçerler kullanılarak gerçeklenmiştir. WeCare düşmesezme için gereken algılama yeteneklerini sunmakla kalmayıp, çeşitli iletişim ve uyarıyöntemlerini de kullanıma açmaktadır. Bu yöntemleri kullanarak düşme sezilmesi durumundabakıcılara ve ilgili kişilere uyarı gönderilerek bu kişilerin hızla durumdan haberdaredilmesi sağlanmaktadır. Bu tezin bir parçası olarak WeCare ortamının yapısıve düşme sezme yönteminin bu ortama eklenmesi de anlatılacaktır.","Falls are identi ? ed as a major health risk, especially for the elderly people and areconsidered a major obstacle to independent living. Quick medical response is desired incase of a fall event. However, the fall may leave the elderly person in such a state thatthe elderly may be unable to call for help on his/her own. Automatic and fast detectionof falls would decrease the health risks associated with the falls and would make inde-pendent living safer for the elderly people. In this thesis, we propose an automatic falldetection system that uses a wearable accelerometer and incorporates wavelet trans-form as a feature extraction method. We conducted experiments to investigate theperformance of the system under the e ? ect of several factors including fall properties,selection of wavelet transform parameters and sensor platform types. Results indicatethat our proposed approach is robust with high fall detection performance.The fall detection mechanism was realized using the wearable sensors that werepart of an indoor monitoring environment, namely WeCare. WeCare not only providedthe necessary sensing capabilities for the fall detection but it also made available severalcommunication and noti ? cation methods. Using these methods, we were able to notifycaregivers in case of fall detection. In this thesis, we also describe the WeCare systemand the integration of our fall detection study into it."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,Bu tez etkileşimli çalışma tezgahı üzeride geliştirilmiş bir arazi görüntüleme uygulamasını ortaya koymaktadır. Uygulama arazinin fiziksel bir maketinin gerçek bir masa üzerinde bulunuyormuşçasına stereo olarak görüntülenmesini sağlamaktadır. Kafa takip sistemi kullanıcının arazi modeli etrafında hareket etmesine izin vermektedir.Geliştirilen arazi görüntüleme sistemi çoklu kaplama ve detay seviyesi yeteneklerine sahiptir. Bu sistem aynı zamanda kültür özellik verisini çıkartan ve görüntüleyen gereçlere sahiptir. Uygulama aynı zamanda arazi üzerinde görülebilirlik analizi yürüten bir gerece de sahiptir. Sistemin kontrol edilmesi ve kullanıcıya daha fazla esneklik vermek için bir uzaktan kumanda kullanılmıştır.Göz aralığı gibi çeşitli stereo görüntüleme parametreleri sistemin kullanılabilirlik değerlendirmesinin bir parçası olarak analiz edilmiştir.,This thesis presents a terrain visualization application developed on a responsive workbench system. The application enables stereo viewing of a terrain as if a physical mock up model of it is actually on a real table. Head tracking system allows the user to move around the terrain model.The terrain visualization system developed has multi-texturing and level of detail capabilities. It also has tools that extracts culture feature data and displays it. Application also has a tool that performs visibility analysis on terrain. A remote controller is used to control system to give user more flexibility.Effect of various stereo visualization parameters like eye separation is analyzed as part of evaluation in system usability.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir yazılım kalite modeli üç ana unsurdan olusur. Bunlar `ürün', `süreç' ve `insan`dır. Literatürde `süreç' ve `ürün' ile ilgili çalışmalar pek çok yazılım kalite modelinde çalışılmaya değer bulunmuştur; ama `insan'ı modelleyen calışmalar azdır. Açık Kaynaklı Yazılım Geliştirme Projeleri'nde yazılımcılar arasındaki etkileşim ile yazılımcılar ve yazılımla ilgili etkileşimleri, kapalı kaynak kodlu projelerdeki etkileşimlerden daha da onemlidir.Açık kaynaklı yazılımda kesin olarak tanımlanmamış süreçler, genellikle insanın önemini artırmaktadır. Bu araştirmada açik kaynaklı yazılım geliştirme projelerinde insan`ın sosyal ağını keşfetmeyi amaçladık. Yazılımcıların yazılım kalitesiyle olan ilişkisini araştırmak amaciyla sosyal ağ metriklerini dört geniş ölçekli açık kaynaklı yazılımdan cıkarttık ve iki deney yapıldı. İlk olarak: sosyal ağ metriklerinin kod hatalarini ne derecede dogru tahmin ettiğini incelendi. İkinci olarak; sosyal ağın, açik kaynaklı yazılımdaki hataları belirlemek üzerine etkisini incelendi.Deney sonuçlarımız; sosyal ağ metriklerinin hataları belirlemede, ?statik kod? veya ?churn metrikleri? uzerine kayda değer bir etkisinin olmadığını göstermektedir. Öte yandan, sonuçlarımız sosyal ağın karmaşıklıgı ile hata bulma olasılığı arasinda olumlu bir ilişki olduğunu ortaya koymaktadır.","A software quality model consists of three pillars: 3Ps (Product, Process, and People). Many software quality models in the literature has so far taken process and product related attributes into consideration, but there are very few studies that model people. In Open Source Software (OSS) development projects developers and their interactions with each other and the software product are even more important than closed loop projects.In open source software loosely defined processes usually increase the significance of people. In this research we are motivated to explore the social network of people in OSS projects. We extracted the social network metrics of developers in four large-scale open source software to examine their relation to software quality in twofold. First, we analyzed the effect of social network metrics in predicting post release defects. Second, we explored the effect of social networks to defect proneness of open source software.Our experiment results showed that social network metrics do not have a distinct impact over and above static code and churn metrics in predicting defects. On the other hand, our results revealed that there is a positive correlation between social network complexity and defect proneness."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet'teki bilgi kaynaklarındaki büyük artışla birlikte, dünyada değişik arka planlara sahip insanlar aynı problemi paylaşmaktadır: Gerçek ihtiyaçlarına uygun bilgileri bulmak. Arama motorları, kullanıcıların, bilgi istekleri vasıtasıyla İnternet'teki dokümanları bulmaları için bir araç sağlamaktadır. Ancak, kullanıcıların eleme işlemini, yani her bir dokümanın gerçek bilgi ihtiyaçlarıyla ilgisine karar verme işlemini, halen kendilerinin yapması gerekmektedir. Bu noktada, otomatik özetleme yöntemleri, arama motorlarının görevini tamamlayabilir.Günümüzde mevcut arama motorları, örneğin Google ve AltaVista, İnternet dokümanlarını özetlemede, sadece bilgi isteğindeki kelimeler ve çevrelerindeki metni içeren iki ya da üç satırlık özetler sunmak gibi, sınırlı bir yetkinlik göstermektedir. Literatürde, otomatik özetleme konusundaki araştırmaların çoğu, kullanıcı ihtiyaçlarını dikkate almayarak genel amaçlı özetler oluşturma üzerine odaklanmıştır. Ayrıca, özetleme yaklaşımları bir dokümanı çoğunlukla düz bir cümle dizisi olarak görmekte ve dokümanlardaki yapıyı göz ardı etmektedir. Özetleme literatüründe, bilgi isteğine dayalı yöntemler ve doküman yapısı sadece az sayıda çalışmada ve ayrı ayrı ele alınmıştır. Bu çalışma, önceki çalışmalardan bu iki yönü tutarlı bir çerçevede bir araya getirmesiyle ayrılmaktadır. Bu tezde, İnternet araması için özgün bir özetleme yaklaşımı öneriyoruz: Bilgi isteği ve doküman yapısına dayalı özetleme.Önerilen sistem, iki temel aşamadan meydana gelmektedir. İlk aşama, İnternet dokümanlarının bölüm ve alt bölüm hiyerarşilerinin ilgili başlık ve alt başlıklarla birlikte ortaya çıkarılması için yapısal olarak işlenmesidir. Sistemdeki her bir doküman, başlıklar, alt başlıklar ve diğer metin birimlerinden oluşan sıralı bir ağaç yapısı ile temsil edilmektedir. İlk olarak, buluşsal yöntemler ve HTML Belge Nesne Modeli'ndeki ağaç yapısının işlenmesine dayalı kural tabanlı bir yaklaşım oluşturduk. Daha sonra, destek vektör makineleri ile algılayıcı algoritmalarını kullanan ve ağaç gösterimine dayalı bir makine öğrenmesi yaklaşımı geliştirdik. Yöntemler, başlık ve hiyerarşi çıkarma işlemlerinin başarımına göre değerlendirildi.Çalışmanın ikinci aşaması, ilk aşamada elde edilen doküman yapılarından faydalanılarak otomatik özetleme yöntemlerinin geliştirilmesidir. Önerilen yöntemde, özet cümleleri, bilgi isteğine dayalı olarak iki seviyede değerlendirmeyle seçilmektedir: Cümle bazında puanlama ve bölüm bazında puanlama. Doküman yapısı, hem özetleme işlemi sırasında hem de üretilen özetlerde kullanılmaktadır. Sistemin başarımı, göreve yönelik değerlendirmelerle belirlenmiştir. Değerlendirmeler, özetlerin gerçekte kullanılacağı gibi bilgiye erişim görevleri içermektedir. Türkçe ve İngilizce dokümanlar üzerinde yapılan deneylerin sonuçları, önerilen sistemin özetlerinin, Google özetleri ve aynı boyutlardaki doküman yapısı bilgisini kullanmayan bilgi isteğine yönelik özetlere göre, makul karar süreleriyle, doğruluk açısından üstünlük sağladığını göstermektedir. Kullanıcı derecelendirmeleri de, bilgi isteği ve doküman yapısına dayalı özetlerin kullanıcılar tarafından daha faydalı bulunduğunu doğrulamaktadır.","With the drastic increase of available information sources on the Internet, people with different backgrounds in the world share the same problem: locating useful information for their actual needs. Search engines provide a means for users to locate documents on the Web via queries. However, users still have to perform the sifting process by themselves; i.e., to decide the relevance of each document with respect to their actual information needs. At this point, automatic summarization techniques can complement the task of search engines.Currently available search engines, such as Google and AltaVista, only show a limited capability in summarizing the Web documents; e.g. displaying only two or three lines of text fragments which consist of the query words and their surrounding text as the summary. In the literature, most of the research in automatic summarization has focused on creating general-purpose summaries without considering user needs. Also, summarization approaches have mostly seen a document as a flat sequence of sentences and ignored the structure within the documents. In the summarization literature, the effect of query-biased techniques and document structure have been considered only in a few studies and separately investigated. This research is distinguished from previous work by combining these two aspects in a coherent framework. In this thesis, we propose a novel summarization approach for Web search, i.e., query-biased and structure-preserving document summarization.The proposed system consists of two main stages. The first stage is the structural processing of Web documents in order to extract their section and subsection hierarchy together with the corresponding headings and subheadings. A document in the system is represented as an ordered tree of headings, subheadings and other text units. First, we formed a rule-based approach based on heuristics and HTML Document Object Model tree processing. Then, we developed a machine learning approach based on the tree representation using support vector machine (SVM) and perceptron algorithms. The methods were evaluated based on the accuracy of heading extraction and hierarchy extraction.The second stage of the research is to develop automatic summarization methods by utilizing the document structures obtained in the first stage. In the proposed method, the summary sentences are extracted in a query-biased way based on two levels of scoring: sentence scoring and section scoring. Document structure is utilized both in the summarization process and in the output summaries. The performance of the proposed system has been determined using several task-based evaluations. These include information retrieval tasks where the summaries will actually be used. The results of the experiments on Turkish and English documents show that the proposed system summaries are superior to Google extracts and unstructured query-biased summaries of the same size in terms of accuracy with reasonable judgment times. User ratings verify that query-biased and structure-preserving summaries are also found to be more useful by the users."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz algılayıcı ağlar birbirinden farklı ortamlarda verilen algılama görevini uzun süre yapmak konusunda en uygun aday olarak ortaya çıkmaktadırlar. Bu tür ağlar özellikle zorluk derecesi fazla algılama görevleri için uygun görülmektedirler. Ağların en büyük avantajları, dağıtık bir yapıda, asgari dış etmen kullanarak ve artıklık sağlayarak çalışmasıdır. Ancak veri toplama düğümünün yeri, algılayıcı düğümlerin alana yollanma şekli ya da dış saldırılar ağ ömrünü önemli ölçüde azaltmaktadır. Bu tür faktörler yüzünden oluşan birbiçimsiz ağ şekli ağ kaynaklarının yeteri kadar kullanılamamasına sebep olmakta ve ağ içerisinde hala ayakta bulunan ancak ara alanlarda oluşan kesintiler yüzünden toplama düğümüne erişemeyen kısımlar oluşmaktadır.Bu tez içerisinde birbiçimsiz dağılımın etkileri incelenmekte ve oluşan problemlere uygun çözümler önerilmektedir. Toplama düğümünü uygun ve güvenli bir noktaya koymak için bir düğüm yerleştirme yordamı önerilmiştir. Sıkışma noktalarını ve ağ boşluklarını bulma yöntemleri ve sınır takibi gibi yüksek seviye algılama ihtiyacı olan ortamlara uygun ağ ömrünü uzatan boşluk kapatma yordamı sunulmaktadır. Kayıplı ortamlarda oluşan algılama kalitesini ölçmek için, analitik bir kalite ölçme hesaplaması tez içerisinde önerilmiş ve ayrıntılı olarak incelenmiştir. Sunulan yöntem ve modellerin uygunluğu benzetim yöntemleri ile teste tabi tutulmuş ve sonuçlar tez içerisinde sunulmuştur.","Deemed as suitable for various challenging sensing tasks, wireless sensor networks evolve as candidates for deployment to different environments to perform the given task for as long as possible. Those networks operate redundantly in a distributed manner, requiring little intervention. However, various factors such as the sink location, node deployment characteristics or external impacts such as intentional destructions can severely limit the lifetime of the overall network. The nonuniformity of the networks caused by such factors may result in underutilized network deployments where some parts of the network is still alive yet unable to reach the sink due to disconnections in the intermediate sections.In this thesis, the effects of deployment nonuniformity is analyzed and methods for mitigating the problems are presented. A sink placement algorithm is presented to find a safe and optimal location for the sink node. Methods to find the bottleneck nodes and sensing holes inside the network are provided. Redeployment based hole mitigation techniques are proposed to prolong the network lifetime under strict quality requiring situations such as border surveillance. An analytical quality metric is also presented to understand the sensing quality under lossy assumptions. The presented methods and models are tested using simulations and the results for different parameter sets are given to see the suitability of each."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Otomatik Teorem İspatlama sistemlerinde başlıca zorluk, arama süreçlerini kısaltacak bir yöntem bulmaktır. Arama süreçlerini kısaltmak için, buluşsal yöntemleri kullanmak önemli bir rol oynar. Bu konuda yapılan çalışmaların sonucunda, çesitli buluşsal yöntemlerle başarılı sonuçlar alınmışsa da, tek bir buluşsal yöntemin tüm problem tiplerinin üstesinden gelemediği gösterilmiştir. Her problem tipinin değişik yaklaşım gerektirmesi, evrensel olarak en iyi buluşsal yöntemin bulunmasını imkansızlaştırır. Bir problem için doğru buluşsal yöntemin belirlenmesi, insan uzmanlar için bile çok zordur. Yeni bir buluşsal yöntem geliştirmek için makina öğrenmesi yöntemlerini kullanabiliriz. Bu tezde önerdiğimiz yaklaşım, sıfırdan yeni bir buluşsal yöntem geliştirmek yerine, uzmanların karışımı yöntemini kullanarak, var olan buluşsal yöntemlerin birleşiminden yeni bir buluşsal yöntem geliştirmektir. Her problem yeni bir yaklaşım gerektirdiği için, önerdiğimiz metot benzer problemlerin çözümlerini öğrenme verisi olarak kullanmaktadır. Çalışmamızın sonuçları, birleşik buluşsal yöntemin, karışımda kullanılan tekil buluşsal yöntemlerin her birinden daha iyi olduğunu göstermiştir.","The main challenge of automated theorem proving is to find a way to shorten the search process. Therefore using a good heuristic method is essential. Although there are several heuristics that improve the search techniques, studies show that a single heuristic cannot cope with all type of problems. The nature of theorem proving problems makes it impossible to find the best universal heuristic, since each problem requires a different search approach. Choosing the right heuristic for a given problem is a difficult task even for an human expert. Machine learning techniques were applied successfully to construct a heuristic in several studies. Instead of constructing a heuristic from scratch, we propose to use the mixture of experts technique to combine the existing heuristics and construct a heuristic. Since each problem requires a different approach, our method uses the output data of a similar problem while learning the heuristic for each new problem. The results show that the combined heuristic is better than each individual heuristic used in combination."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, tekstil doku imgelerindeki hataların, parçacık filtresi ile tespit edilebilmesi amaçlanmaktadır. Bunun için probleme Bayesçi perspektiften yaklaştık ve modelimizi durum uzayı formülasyonu ile ifade ettik. Durum uzayı formülasyonunu tanımlayabilmek için de; doğrusal, iki boyutlu doğrusal ve Markov rassal alan gibi örüntü modellerini; Gauss, Gauss karışımı ve alfa durağan gibi de gürültü çeşitlerini doku imgelerini en iyi şekilde temsil edebilmek için inceledik. Elde ettiğimiz sonuçları; diğer Kalman, genişletilmiş Kalman ve kokusuz Kalman filtelerinden elde edilen sonuçlarla karşılaştırdık. Son olarak da filtrelerin zaman ve performans analizi yapıldı.","The purpose of this thesis was to detect the defects on textile fabric images using the particle filters. We approached the problem from a Bayesian perspective and represented the model in a state space formulation. To describe the state space formulation; the texture models such as linear, 2-D linear and Markov Random Field models and the noise types like Gaussian, mixture of Gaussian and alpha-stable noise are investigated to find the best representation that is appropriate for our textile images. The implementation results are compared with Kalman, Extended Kalman and Unscented Kalman filters. Finally time and performance analysis of the filters is given."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Foton haritalama, gerçekçi görüntü üretimi için sıklıkla kullanılan bir genel aydınlanma metodudur. Monte-Carlo örnekleme tabanlı bir tekniktir ve gürültü, üretilen imajda potansiyel bir problemdir. Yüksek sayıda foton izleme gürültüyü azaltır ama bu hesaplama açısından pahalı bir işlemdir. Önemlilik tabanlı yöntemler, gürültüyü göreceli olarak az sayıda foton izleyerek azaltma yolları sağlar. Bu metodlar iki kategoride incelenebilir: görüntü oluşturma fazında kullanılıp son toplama ışınlarının yönlerinin örneklenmesini geliştiren önemlilik örnekleme yöntemleri, ve foton izleme fazında görünen alanlara daha çok foton yollamak için kullanılan görsel önem yöntemleri. Bu çalışmada, birkaç önemlilik yöntemini uyguluyor ve avantaj ve dezavantajlarını tartışıyoruz. Foton yoğunluğunu kullanan bir önemlilik örnekleme metodu sunuyoruz, ve özellikle düzensiz aydınlanmalı sahnelerde gürültüyü nasıl azalttığını gösteriyoruz. Hibrit bir görsel önemlilik yöntemi sunuyor ve verimliliğini tartışıyoruz. Aynı zamanda değişken foton güçlerine sahip görüntülerde iyi sonuç veren bir foton güç dağıtımı yöntemini, görsel önemlilik yöntemlerine ekleme olarak öneriyoruz.","Photon mapping is a global illumination method widely used in realistic image synthesis. It is a Monte-Carlo Sampling based technique and noise is a potential problem in the rendered image. Tracing high number of photons reduces the noise but this is computationally expensive. Importance based methods provide a means to reduce the noise using a relatively low number of photons during tracing. These methods can be classified into two categories: importance sampling methods, used at the rendering phase to improve the sampling of final gather ray directions, and visual importance methods, used at the photon tracing phase to send more photons in visible areas. In this work, we implement a number of importance based methods, and discuss their advantages and disadvantages. We present an importance sampling method that uses photon densities, and show how it reduces noise especially in scenes having non-uniform illumination. We provide a hybrid visual importance method and discuss its effectiveness. We also propose a photon power distribution method as an add-on to visual importance methods, which gives good results when used in images with highly-varying photon powers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı Taşıma Sistemleri üzerine araştırmalar hızla ilerlemekte. Bu sistemlerin nihai amacı tamamen otonom araçları gerçek hale getirmek. Bu alandaki araştırmalar, hem güvenlik ve hem de operasyonel verimlilik açılarından önemli potansiyel arz ediyor.Şerit takibi, otonom araç seyrinin (navigasyon) önemli bir parçası olarak öne çıkıyor. Bunun nedeni, seyredilecek yolun, özellikle kentsel yollarda, şeritler arasındaki bölge olması. Bu amaçla birçok bilimsel yaklaşım ileri sürülmekle birlikte, bunların arasında Hough dönüşümü öne çıkmakta. Verideki gürültüyü azaltmak ve sınırlı işlem süresinde sonuca ulaşmak için sağlam bir metod tasarlamak gerekiyor. Bu çalışmamızda resmi bölümlere ayırmak kaydıyla Çok Aşamalı Hough Dönüşümü gerçekleştiren bir şerit takip sistemi sunuyoruz. Şerit tespit aşamasının ardından Saklı Markov Modeli temelli bir şerit takip sistemi öneriliyor.Trafik tabelaları ise yollardaki kuralları belirten önemli enstrümanlardır. Bu sebeple otonom araç çalışamalarının önemli parçasıdırlar. Tabelaların kapsam dışı bırakılmasıgerçekçi sonuçlar alınmasını imkansız kılacaktır. Otomotiv üretici firmaları yeni modellerinde trafik tabelası tanıyabilen akıllı sistemler sunmaya başladılar. Fakat yollardaki beklenmedik durumlar ve tabelaların önemli farklılıklar göstermesi sebebiyle çok daha güvenli ve hızlı tabela tanıma sistemlerine ihtiyaç duyuluyor. Bu sistemler için yerelleştirme de gerekli çünkü trafik tabelaları ülkeden ülkeye farklılıklar arz edebilmekte. Bu çalışmamızda tabela tespit ve takibi için de bir yöntem sunmaktayız. Radyal simetri tabanlı geometrik dönüşümler ve genetik algoritma kullanarak tabelaları tespit ediyoruz. Tespit edilen tabelalar, SURF niteliklerini Yapay Sinir Ağları veya Destek Vektör Makinelerine besleyerek sınıflandırılıyor. SURF'a alternatif olarak bir sezgisel bir yöntem de deneniyor. Zaman ve doğruluk analizleriilgili bölümlerde bulunabilir.Bu çalışma Boğaziçi Üniversitesi Yapay Zeka Laboratuvarı'nda yürütülen Otonom Sürüş Değerlendirme Projesi'nin bir parçası olarak ortaya çıkmıştır.","The field of Intelligent Transport Systems (ITS) is advancing rapidly in the world. The ultimate aim of such systems is to realize fully autonomous vehicles. The researches in the field offer the potential for significant enhancements in safety and operational efficiency.Lane tracking is an important topic in autonomous navigation because the navigable region in a road usually stands between the lanes, especially in urban environments. Several approaches have been proposed, but Hough transform seems to be the dominant one among all. A robust lane tracking method is also required for reducing the effect of the noise and satifying processing time constraints. In this study, we present a new lane tracking method which uses a partitioning technique for obtaining Multi-resolution Hough Transform (MHT) of the acquired vision data. After the detection process, a Hidden Markov Model (HMM) based method is proposed for tracking the detected lanes.Traffic signs are important instruments to indicate the rules on roads. This makes them an essential part of the ITS researches. It is clear that leaving traffic signs out of concern will cause serious consequences. Although the car manufacturers have started to deploy intelligent sign detection systems on their latest models, the road conditions and variations of actual signs on the roads require much more robust and fast detection and tracking methods. Localization of such systems is also necessary because traffic signs differ slightly between countries. This study also presents a fast and robust sign detection and tracking methodbased on geometric transformation and genetic algorithms (GA). Detection is done by a genetic algorithm (GA) approach supported by a radial symmetry check so that false alerts are considerably reduced. Classification is achieved by a combination of SURF features with NN or SVM classifiers. A heuristic alternative to the SURF usage is also presented. Time and accuracy analysis can be found in relevant sections.This work is a part of the Automatic Driver Evaluation System (ADES) Project in Artificial Intelligence Laboratory of Boğaziçi University."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sığalı ağlarda, iki düğüm arasındaki en büyük akışı hesaplayacak, paralel bir algoritma sunuyoruz. Algoritmamız, Goldberg'in itele-tekrar-etiketle (push-relabel) algoritması temel alınarak geliştirilmiştir. Etkin düğüm seçimi için, paralel yürütülmeye uygun, değiştirilmiş bir ""ilk giren ilk çıkar"" (FIFO) yöntemi kullanılmaktadır. Algoritmamız, pratikte oldukça hız kazandıran global-tekrar-etiketleme (global relabeling) buluşsal (heuristic) yöntemini kullanmaktadır. Çok çekirdekli işlemcileri hedefleyen algoritmamız, görev çalma yöntemi ile, iş yükünü farklı iş parçacıklarına dağıtmaktadır. Çekirdeklerin ortak kullandığı belleğe erişimin senkronizasyonu için, hesaplama açısından pahalı genel amaçlı kilitler yerine, hızlı atomik (atomic) değişkenler kullanılmıştır. Algoritmamızı itele-tekrar-etiketle tabanlı seri algoirtmalar ile karşılaştırdık ve başarımının iyi olduğunu gösterdik.","We provide a parallel algorithm for calculating maximum flow between two nodes, in a capacitated network. The algorithm we propose is based on push-relabel algorithm due to Goldberg and uses a modified first in first out selection strategy together with global relabeling heuristic. Our implementation targets multi-core processors, implements task stealing to balance load between multiple threads of execution and uses fast atomic variables for synchronization instead of costly general purpose locks. We compare our algorithm to other push-relabel based algorithms and demonstrate that it performs well in practice."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sistem performansı açısından çok önemli olan , işlemcilerin yüksek verimde kullanımı bilgisayar bilimindekiaraştırmalarda oldukça popüler bir hedef haline geldi. Son derece hızlı ve pahalı olan işlemcileri mümkünolduğunca çalışır durumda tutmak bilgisayar sistemlerinin verimliliğini arrtıran en kritik faktörlerden birisidir.İşlemcilerin boş durumda beklemesine yol açan en önemli sebeplerden biri , bellekten herhangibir veri yada komut okuma esnasında yaşanan gecikmelerdir. Bu gecikmeleri minimumaindirmek için en hızlı bellek bileşenleri kullanılsa bile, işlemci hızı ile bellekokuma yazma hızları arasındaki fark günden güne daha da açılmakta. Bu problemleilgili, çalışmaların bir kısmı okuma yazma gecikmelerini azaltacak daha hızlıbileşenlerin üretilmesine yoğunlaşmış olmakla birlikte, diğer bir kısmı ise ön belleklerdekiisabet oranını arttırıcı teknikler geliştirmek üzerine devam etmekte. İşlemcininbellekten okuyacağı bilgiyi daha öncesinden tahmin edip okumak ve bu şekilde bellekseviyesinde paralelizm sağlamak bu çalışmalardan birisi. Bu sayede önbellek isabetoranının yükseltilmesi ve önbellekler en hızlı bellek bileşeni oldukları için işlemci beklemesüresinin azaltılması hedeflenmektedir. Sistemde yapılacak iş parçacıklarınınbellek kullanımları göz önüne alınarak çalıştırılma sırasının belirlenmesi bir diğer çalışmaalanını oluşturmakta ve işler arası veri paylaşımını ve önbellek kullanımını arttırmayıamaçlamaktadır. Bu çalışmada bu iki çalışma alanıyla ilgili iki metod önerildi. Buönerilerimizin denenmesi ve sonuçlarının incelenmesi amacıyla bir de çok katmanlıbellek simülatörü geliştirildi.","High processor utilization ,which has signicant impact on the total systemperformance, is becoming the most popular target of many researchers in computerscience. Since processors are extremely fast and much more expensive than otherhardware components increasing their utilization is critical for eciency of computersystems. One of the main reasons that cause processors to wait idle is memory stallsduring a data or an instruction reference from the memory hierarchy. Although thefastest memory components and caching technologies are used to decrease access latency, the gap between memory system and cpu speed has been rapidly increasing.In addiditon to development of fast memory components which decrease miss latencyand increase bandwidth, many techniques have been proposed to increase hit ratio.Prefetchers are one those which provides memory level parallelism by fetching blocksof data to the cache in advance of cpu requests hoping to increase cache hit ratio. Sincecaches are the fastest components in the memory hierarchy increasing hit ratio of thecaches hides memory latency and therefore increase processor utilization. Schedulingthreads according to their cache locality also increases data sharing and cache utilizationin multithreaded systems. In this work, we focused these two areas of memoryoptimization techniques. We proposed a new hardware prefetcher model and a contextswitching heuristic among threads in multithreaded systems. We also implemented amultilevel cache simulator to test those ideas."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bileşik servisler birbiriyle etkileşim içinde olan servislerden meydana gelir. Genellikle bileşik servislerde her bir servis farklı bir servis sağlayıcısı tarafından sağlanır. Bileşik servisin kalitesi sadece servis sağlayıcılarının yeteneklerine değil birlikte ne kadar iyi çalıştıklarına da bağlıdır. Başarılı takımlar kurabilmek için araştırmacılar güven, kişilik, liderlik gibi birçok faktörü incelemişlerdir. Bu tezde güven ve kişilik faktörlerinin takım performansına olan etkisi incelenmiştir. Varolan güven modelleri bileşik servisler yerine tek servisleri gözönünde bulundurmuştur. Ancak, bir bileşik servis için güvenilecek bir takımın bulunması çoğu zaman önemlidir. Bu durumu ele almak amacıyla, bir bileşik servis için bir grup servis sağlayıcısına güveni gösteren bir model öneriyoruz. Yaklaşımımız farklı bileşik servisler arasındaki ilişkiye dayanmaktadır. Önerdiğimiz modeli litaratürde varolan modellerle kıyasladığımızda, önerilen modelin seçtiği servis sağlayıcısı grupların daha başarılı olduğu gözlenmiştir. İkinci faktör olarak, takım kişiliği ve takım çalışması performansı arasındaki ilişkiyi inceledik. Kişilik modellemesi için psikoloji literatüründe çok popüler olan Beş Büyük Faktör kuramını kullandık. Beş Büyük Faktör kişilik özelliklerini beş sınıfa ayırır: uyumluluk, sorumluluk, duygusal denge, dışadönüklük ve açıklık. Bu özelliklerin çok etmenli ortamlarda takım çalışmasına etkisini deneysel olarak çalıştık. Bunu gerçekleştirebilmek için, kişiliğe sahip etmenleri bağımlılık özelliğini gösteren takım çalışması ortamında geliştirdik. Bu ortamda, takım başarısı için hangi kişilik özelliklerinin önemli olduğunu, güveni yüksek takımların başarılarının da yüksek olup olmadığını, ve aynı yapılı olan takımların daha başarılı olup olmadığını inceledik. Bu çalışmayı gerçekleştirmek için tek servisleri içeren Agent Reputation and Trust (ART) Testbed, bileşik servisleri içerecek şekilde değiştirilerek güven ve kişilik modelleri geliştirilmiştir.","Composed services consist of interacting services. Generally each service in a composed service is brought out by a different service provider. The quality of the composed service depends not only on the individual capabilities of the providers but also on how well they work together. In the pursuit of establishing effective teams, researchers propose several cognitive factors such as personality, trust, and leadership to model teams. In this theses, we study two significant factors: trust model and team personality. Existing trust models are geared towards identifying single services rather than composed services. However, in many settings it is important to find a group of service providers that can be trusted for a composed service. To address this, we propose a trust model that captures how trustworthy a group of service providers is for a particular composed service. The approach is based on capturing relations between services. Our proposed approach is tested on a modified version of ART Testbed. We compare our proposed model with an existing approach in the literature and show that capturing relations between services pays o® in finding useful groups of service providers. For the second factor, we investigate the relationship between the team personality and teamwork performance. A promising personality model is composed of what is called Big Five Personality Traits: Agreeableness, Conscientiousness, Emotional stability, Extraversion, and Openness. We experimentally study the effect of these traits on multiagent teamwork. To do so, we model these traits and implement them in agents that can participate in ART Testbed by including interdependency attributes of teamwork. In this setup, we specifically study which traits are more significant than others for better performing teams, whether more trusted teams actually achieve a higher success rate than others, and whether heterogeneous teams perform better than homogeneous teams."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"EKG, elektrokardiyografinin kısaltmasıdır. Kalpteki elektriksel aktivitenin zamana bağlı değişiminin göstergesidir. Elektrotlar vücutta belli noktalara yerleştirilir. Kalp aktivitesi EKG kağıdına 12 derivasyon olarak aktarılır. Herbir derivasyon farklı bir kesitten alınan aktiviteyi gösterir. Kalbin kan dolaşımının merkezi olması sebebiyle; döngüsündeki bir işlev bozukluğu, büyük bir hasara sebep olabilir veya vücudun başka bir bölgesindeki işlev bozukluğunun göstergesi olabilir. Bu sebeple, kalp aktivitesinin kontrol edilmesi hayati önem taşır. EKG, kullanılan en yaygın tekniktir. Uzmanlar EKG makinesinden çıkan ölçekli kağıt çıktısını kullanarak EKG analizi yaparlar. EKG analizindeki en önemli husus, anormallikleri doğru tespit etmektir.Bu tezde, EKG analizinde bulanık yaklaşım kullanılmıştır. UCI veritabanındaki EKG veriseti kullanılmıştır. Bu veriseti, normal ve anormal EKGlerden oluşur. Tüm anormal EKGler bir sınıf ve normal EKGler bir sınıf oluşturacak şekilde düzenlendi. Sistemin esas amacı; anormallikleri doğru tespit etmektir. En iyi performansı elde edebilmek için birçok bulanık üyelik fonksiyonu denendi. Sistemin çıktısı diğer sınıflandırma yöntemleri ile karşılaştırıldı. Sonuçlar bulanık destek vector makinesinin diğer yöntemlerden daha başarılı olduğunu gösterdi.","ECG stands for electrocardiography. It is an interpretation of the electrical activity of the heart over time. Electrodes are placed on the skin in specific coordinates. The activity of the heart is extracted on the ECG paper as 12 leads. Each lead represents the activity from a different section of the heart. For the heart being the center of blood circulation, a malfunction in the working cycle of the heart may cause big damage or be an indicator of a malfunction in another area of the body. Hence, examination of the heart activity has vital importance. ECG is the most common technique. Experts perform ECG analysis using the scaled paper output of the ECG machine. The most important point in ECG analysis is to correctly detect anomalies.In this thesis, fuzzy approach is used for ECG analysis. The ECG dataset in the UCI database is used. This dataset contains of inputs from normal and abnormal ECGs. All the anomalies are used to construct one class and normal ECG data is used to construct another class. The main purpose of the system is to detect anomalies correctly. In order to achieve this goal, a fuzzy support vector machine is constructed. Different fuzzy membership functions are tested to reach the best performance. The output of the fuzzy support vector machine system is compared to other classification methods. Results show that the fuzzy support vector machine outperforms other methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çalışmasında, uydu sistemleri yönetimindeki biliisel ağlarda spektrum algılama ve karar verme prosedürü için bir güvenlik mimarisi tanımlıyoruz. Biliisel ağların temel amacı spektrum kullanımına ve operasyon parametrelerine çeviklik getirmektir. Böylece, kablosuz iletiiimin performansı arttırılmaktadır. Buna ek olarak, biliisel ağlar, yeni gelişen bir paradigma olan her zaman her yerde iletişim için olmassaolmaz olan verimli spektrum kullanımını sağlamaktadır. Spektrum kullanımında çeviklik sağlayabilmek için biliisel ağlar koblosuz ağlardan farklı olarak, yeni özellikler ( uzaktan ayarlanabilme, spektrumu analiz etme ve kullanım kararı verme, lisanslı kullanıcının iletişimini algılama v.b.) barındırmaktadırlar. Bu yeni özellikler, spektrum yönetimi ve güvenilir lısanslı kullanıcı bulma gibi yeni sorunlar ile gelmektedir. Ağ yapısının hücrelere bölündüğü bilişsel ağlarda, spektrum yönetimi ve kaynak kullanımı her hücrenin baz istasyonu tarafından gerçekleşmektedir. Bu yapının yerine, baz istasyonlarını geniş kapsama alanı ile uydu kontrol ederek, spektrum için daha güvenilir bir çevre haritası çıkarabilmektedir. Bunlara ek olarak, uydu yayınyaparak yönetimsel yararlılık ve politika güncellemeyi sağlamaktadır. Uydu sistemleri yönetimindeki bilişsel ağlar olarak tanımladığımız yapımız, geleneksel kablosuz ağlara göre yeni güvenlik açıklarına yol açmaktadır. Biz, bu yeni güvenlik ataklarını, risk derecelerini ve bu ataklara karşı alınabilecek önlemleri araştırdık. Yapılan bu araştırma ile geliştireceğimiz güvenlik mimarisi güçlü kılmak için gerekli olan tüm güvenlik servislerini belirledik. Bilişsel ağlardan oluşan kısım ile uydu ağlarından oluşan kısmın özelliklerini ve kısıtlarını göz önünde bulundurarak, iki katmanlı bir ağ yapısı tanımlıyoruz. Tasarlanan güvenlik mimarisinde, gizlilik, taraf ve veri kaynağı asıllama, kriptografik pul ve bütünlük servislerini kullanıyoruz. Bu güvenlik servisleri farklı yöntemler kullanılarak sağlanabildiğinden, detaylı performans ve güvenlik değerlendirmesi yapıyoruz. Önerilen mimarinin performansı, değisen bilişsel radyo sayısı ve bu radyoların hücre değiştirme sıklığı kullanılarak analiz edilmektedir. Yapılan performans analizleri gösteriyor ki, önerilen mimari band genişliği kullanımı ve işlem maliyetine göre verimli ve güvenli olduğunu göstermektedir.","In this thesis study, we propose a security structure for spectrum sensing and decision scheme for a satellite assisted Cognitive Radio Network (CRN). The main goal of Cognitive Radio (CR) is to provide agility in the spectrum access and operations parameters. Hence, performance of wireless transmission can be optimized. Additionally, CR facilitates more efficient spectrum utilization which is a fundamental issue in the emerging communications paradigm of anytime-anywhere access. In order to providespectrum agility, CRs have some additional functionalities (eg. remote configurability, spectrum analysis, primary user detection) different from the ones in wireless networks. These functionalities come at the expense of various challenges such as spectrum management and reliable primary user detection. In an infrastructure-based CRN where the network is divided into cells, spectrum management and resource allocation in each cell is managed by the base station (BS) of each cell. However, these may require extensive message exchanges among the BSs. Instead, a satellite with its wide coverage can assist the BSs to provide a more reliable spectrum environment map. Additionally, it can provide the management functionalities and regular policy updates by message broadcasts. Different from the conventional wireless networks, this structure?referred to as satellite assisted CRN, may be exposed to new security attacks. We investigate these security threats, evaluate their risk levels and provide cryptographic and noncryptographic counter-measures. This investigation points out which security services need to be employed in order to design a robust security scheme for this structure. Considering the properties and the restrictions of the CRN segment and the satellite segment, we design a two-tiered security structure. We apply confidentiality, entity and data origin authentication, cryptographic nonce and integrity security services to our security structure. Since these security services can be provided by using different security solutions, we present a detailed security and performance evaluation of the proposed security solution. The performance of proposed structure is analyzed under varying number of CRs in the network and varying CR handover frequency. The performance results show that the proposed approach is secure and efficient in terms of bandwidth usage and processing cost."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Algılayıcıların kullanıldığı uygulamaların artan gereksinimleriyle birlikte; Telsiz Algılayıcı Ağların (TAA) bir altkümesi olan Telsiz Çoklu Ortam Algılayıcı Ağlar (TÇAA) ortaya çıkmıştır. TÇAA genellikle Servis Kalitesi (SK)-kısıtlı veri taşırlar ve bu veriyi kaynakların bir hayli kıt olduğu TÇAA larda taşımak için SK sağlamak kaçınılmaz bir hal almaktadır.İlk olarak algılayıcı ağlarda SK sağlanmasıyla ilgili geniş bir inceleme yapılmıştır. SK bakış açıları ve parametreleri ile birlikte karşılaşılması muhtemel sorunlar açıklanmıştır. Ardından mevcut SK-bilinçli Ortama Erişim Protokolleri (MAC) incelenip, SK-bilinçli MAC protokol tasarımında verilmesi gereken kararlar fayda ve zararlarıyla anlatılmıştır. Bununla birlikte, iyi tasarlanmış bir SK-bilinçli MAC protokolün hangi özelliklere sahip olması gerektiği de değerlendirilmiştir.Bu tezde, TÇAA için Diff-MAC isminde yeni bir SK-bilinçli ve karma öncelik tabanlı MAC protokol önerilmektedir. Diff-MAC adaletli ve hızlı bir şekilde veri taşırken, kanal kullanımını da arttırmayı hedeflemektedir. Gerçek hayatta uygulanabilirliği olan örnek bir senaryo çatılmış ve tüm benzetimler bu senaryoya sadık kalınarak yapılmıştır. Başarım testleri sonuçları, Diff-MAC in varolan MAC protokollerinden daha başarılı olduğunu göstermiştir.","Growing necessities of the sensory applications has emerged a new subset of Wireless Sensor Networks called Wireless Multimedia Sensor Networks which commonly carry Quality of Service (QoS)-constrained heterogeneous traffic. In order to deliver this heterogeneous traffic in highly resource constrained sensor networks and satisfy their QoS requirements properly, QoS-provisioning becomes unavoidable.As a result of an extensive survey about QoS-provisioning in sensor networks, QoS perspectives and parameters are investigated and challenging issues are pointed out. Existing MAC protocols are surveyed and followed by QoS-aware MAC protocol design tradeoffs with their advantages and disadvantages. Moreover, Properties of a well-designed QoS-aware MAC protocol are defined.In this thesis, we propose Diff-MAC; a novel QoS-aware and hybrid priority-based MAC protocol for Wireless Multimedia Sensor Networks. Diff-MAC aims increasing the utilization of the channel with effective service differentiation mechanisms while providing fair and fast delivery of the data. A real-life scenario framed for performance evaluation of Diff-MAC and results obtained through extensive simulations show significant improvements on the performance of the network compared to existing protocols."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Aritmetik devreler tümleşik devre tasarımında önemli bir yere sahiptir. Genellikle aritmetik bloklar bir sistemde en yüksek güç harcayan birimlerdir. Bunun nedeni, bu devrelerin anahtarlama aktivitelerinin oldukça yüksek olmasıdır. Alternatif aritmetik uygulamalarla tüm sistemin güç gereksinimi azaltılabilir ve sistem performansı arttırılabilir.Statik CMOS sayısal tasarım dayanıklı çalışma performansına sahiptir. Bunun nedeni lojik seviyelerin iki uç değer olan besleme gerilimi ve toprak arasında korunmasıdır. Buna karşılık tüm düğümlerin besleme voltajı değeri miktarı salınması yüksek güç tüketimine ve devrelerde gürültüye neden olmaktadır. Bu durum özellikle karma sinyal devrelerinde istemeyen bir durumdur. Özellikle anahtarlama yoğunluğunun fazla olduğu durumlarda akım modlu sayısal tasarım bu duruma bir çözüm olabilir. Tezin ilk kısmında alternatif akım modlu aritmetik yapılar çok değerli mantık devreleri kullanılarak geliştirilmiştir. Çok değerli mantık devreleri ile beraber işaretli sayılar ve yedekli sayı sistemleri de ele alınmıştır. Çok değerli mantık devrelerinin tasarım gereksinimleri ele alınmış ve özgün çok terimli toplama devreleri önerilmiştir.Tezin ikinci kısmında yeniden yapılandırılabilir sistemler için yedekli sayı sistemlerinin kullanımı incelenmiştir. Burada önerilen teknikler yeni nesil 6-girişli hafızalı sahada programlanabilen kapı dizisi (FPGA) sistemleri üzerinde etkin olarak gerçeklenebilmektedir. FPGA sistemleri için yedekli çift saklamalı toplama tekniği önerilmiştir. Önerilen teknik kullanılarak yeniden yapılandırılabilir sistemler üzerinde etkili çarp-topla işlemleri ve sonlu dürtülü filtre yapıları gerçeklenebilmektedir.","Arithmetic circuits play a crucial role in VLSI technology. Arithmetic blocks are usually the most power consuming parts in a system since the switching activity is quite high. Alternative arithmetic implementations can be a solution to reduce power consumption and to increase the performance of the whole system.Static CMOS digital design has robust working performance, where logic levels are kept at the two extremes, either the ground voltage or supply voltage. However, the voltage excursion between the supply voltage and ground at all nodes causes excessive power dissipation. This condition also generates noise over the whole circuitry, which is not desirable especially in mixed signal designs. Current-mode digital design techniques can be a solution for this issue especially whenever the switching activity is high. In the first part of the thesis, alternative current-mode arithmetic structures are built focusing on multi-valued circuits. Together with multi-valued logic implementations, signed-digit numbers and redundant number systems are also analyzed. The design issues of multi-valued circuits are discussed and novel building blocks for multi-operand addition are developed.In the second part of the thesis, redundant arithmetic schemes for new generation reconfigurable systems are also analyzed. These techniques proposed here can be implemented efficiently by using recently introduced 6-input look-up table based field programmable gate array (FPGA) systems. A redundant double carry-save mode addition technique is proposed for the new generation FPGA devices. Using the proposed technique, efficient multiply-accumulate operations and finite impulse response filter structures for reconfigurable systems are developed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Web 2.0 kavramı, güncel İnternet uygulamalarının geliştirilmesinde kullanıcıların katılımını önemli bir unsur haline getirdi. Artık kullanıcılar İnternette sunulan servisleri sadece kullanmakla kalmıyor, aynı zamanda bu servislerle etkileşime girerek servisin içeriğinin oluşturulmasına katkıda bulunuyorlar. Microblog'lar son zamanlarda İnternet üzerinde bulunan en ilgi çekici uygulama konumundalar. Alışılageldik blog'larla karşılaştırıldıklarında, hızlı, basit ve kullanımları kolay olan Microblog'lar, bu özellikleri ile kullanıcıların dikkatini çekiyor. Twitter en popüler microblog konumunda ve her gün milyonlarca ileti gönderen milyonlarca kullanıcıya sahip. Bu nedenle, Twitter üzerinde muazzam derecede büyük bir veri bulunuyor ve bu veri büyümeye devam ediyor. Bu yüksek lisans tezinde yaptığımız çalışma, gerçekten değerli bilgileri içeren bu verinin kategorilere ayrılması ve analiz edilmesi, kullanıcıların Microblog'a yaptıkları katkının anlaşılabilir olması ve değerli bilgilerin ortaya çıkartılabilmesi için bir yöntem sunmak şeklinde özetlenebilir. Ancak microblog'larda özellikle içerik boyutu konusunda bazı sınırlamalar bulunuyor. Analiz yapabilmek için elimizde bulunan tek veri, kullanıcının mesajlarında bulunan kelimeler olduğundan, bu özellik Twitter üzerinde bulunan verinin analiz edilmesini zorlaştırıyor. Modelimizde ilk adım, kullanıcıların mesajlarının alınıp kelimelere ayrılması, sonraki adımda ise bu mesajların analiz edilmesi ve anlaşılmaya çalışılması olarak sıralanabilir. Mesajların analiz edilmesi aşamasında semantik ağ kaynakları kullanılıyor. Bu tez çalışmasında, Linked Data girişiminin merkezi bir bileşeni olan DBpedia, semantik ağ kaynağı olarak seçildi. DBpedia, WikiPedia'da bulunan verileri RDF formatında sunar ve bu veri seti üzerinde karmaşık SPARQL sorguları yapabilmek için bir arayüz sağlar. Bu tez çalışmasında sunduğumuz model, kullanıcıların mesajlarında en sık kullanılan kelimeleri alır, semantik ağ kaynaklarında sorgular ve bu kaynaktan dönen kategorileri eşleştirir. Analiz işleminin sonunda, kullanıcıların microblog'a yaptıkları katkıları anlamamıza yarayan grup kategori ismi ortaya çıkmış olur.","User collaboration became the key factor in the development of today?s Internet applications with the emergence of Web 2.0. Users not only consume the services available on the Internet, but also interact with them and collaborate to provide content generation for the services. Microblogs are recently one of the most interesting applications in the Internet. They are rapid, simple and easy to use when compared to the traditional blogs. These properties of microblogs create user interest and increase the popularity of these services. Twitter is the most popular microblog and it has millions of users posting millions of messages every day. The data available on Twitter is massive and it is growing continuously. This massive data contains valuable information. The work done in this M.S. thesis is to provide a methodology to categorize, analyze this data, understand the user contributions made to microblogs and export valuable information. However, microblogs have some limitations, especially on the size of the content. Same situation also applies for the user posts in Twitter, which are also known as ?tweets?. This makes the analysis of the data on Twitter more challenging, since the only information we have for performing an analysis are the words in user tweets. First step in our method is to retrieve user tweets and parse them into words. Next, we need to analyze and understand the content of the user posts. To achieve this goal, we utilized Semantic Web resources. DBpedia, which is a central node on Linked Data effort, is selected as Semantic Web resource in this thesis work. DBpedia provides the data on WikiPedia in RDF format and it has an interface that enables us to perform complex SPARQL queries on the data set available on it. The model we proposed in this thesis work takes the words which are used frequently on users? posts as input, queries them on Semantic Web resources and finds out the matching categories defined on this resource for these words. At the end of the analysis process, we have a group of category names for the users, which enables us to understand their contributions made to microblogs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar ile işaret dili canlandırması, işaret dili öğrenimi için önemli bir araç olma potansiyeli taşımaktadır. Özellikle işaret tanıma özellikleri de içeren bir paketin içerisine eklenirse, öğrencilere en önemli eksiklerini, geri beslemeyi gideren bir araç elde edilebilecektir.İnsan vücudunun canlandırılması ve hareket yakalanması teknolojileri gerçekçi sanal aktörlerin, gerçek zamanda inandırıcı hareketleri yaptığı uygulamaları artık mümkün kılmaktadır. Bunun için hareketler sanal bir iskelet üzerinden tasarlanabilir ya da yakalanabilir. Bu iskelet doğru bükülmeleri yapabilen de gerçekçi bir deri modelini yürütmek için kullanılabilir.Bu çalışmada Türk işaret dili harf alfabesini yakaladık ve yarı otomatik şekilde görsel olarak da çekici olan bir modele taşıdık. Hareketleri yakalamak için manyetik bir sistem kullandık. Daha sonra sunumlar bu iş için yazılmış bir uygulama ile etkileşimli ve gerçek zamanda, 3B ortamda oluşturuldu.","Demonstration of sign languages with the computer is a potentially useful learning aid for sign language learners. If implemented as a part of a learning tool, one that includes sign recognition as well, it will invaluable for providing feedback to the learners, a most needed contribution.Human body animation and motion capture technologies have reached a point where realistic virtual actors can perform plausible human movements in realtime. For this, the motion can be defined on a virtual human skeleton, either by design or by motion capture methods, and then displayed over the skeleton which drives a realistic skin model, visualizing the human body.In this work we capture Turkish sign language finger spelling alphabet and semi-automatically translate it into a visually appealing model. For capturing the sign language we use a magnetic motion capture system. Then, a playback tool generates sign language demonstrations interactively and in realtime in 3D."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Öğretim metodlarının değerlendirilmesi ders kalitesinin arttırılması bakımından büyük önem taşır. Program geliştirme süreçlerine odaklanmış dersler öğrencilerin problem çözme yöntemlerinin gözlemlenmesini gerektirdiği için öğrenim metodlarının değerlendirilmesi bu derslerde daha zordur. HtDP de bu tarz bir sürece odaklanan ""tasarım reçetesi"" önermektedir. Bu yaklaşımın kalitesini ölçmek için yapılmış çalışmalar olmasına rağmen nicel analizine ilişkin bir çalışma henüz yapılmamıştır.Bu çalışmada ben öncelikle program geliştirme sürecinin kaydedilmesi, tekrar oynatılması ve üzerine notlar alınmasını sağlayan bir araç (Screen-Replay) modeli ve uygulaması ortaya koymaktayım. Bu araç DrScheme ortamı için Scheme programlama dili kullanılarak yazılmıştır. Program geliştirme sürecini kaydederek aynen tekrar oynatılabilmesini sağmaktadır. Ayrıca, süreci tekrar oynatan bir gözlemci belirli zaman aralıklarını HtDP tasarım reçetesi adımları ile eşleştirmek sureti ile süreci yorumlayabilir. Sonuçta ortaya çıkan yorumlar, geliştirme sürecini tanımlayan tasarım aktivitelerinin dizisidir. Bu dizileri değerlendirebilmek için bir süreç değerlendirme algoritması geliştirildi. Son olarak, 61 farklı program geliştirme sürecinden elde edilen süreç skorları ve sınav notları incelenerek tasarım reçetelerinin sınav notları üzerindeki etkisi avramaya çalışıldı.Screen-Replay, öğrencilerin nasıl program geliştirdiğini gözlemlemek için etkili bir araçtır. Kişisel gözlemleme yöntemlerine karşın öğrencilerin geliştirme süreçlerinin tutarlı ve nesnel bir yöntemle gözlemlenmesini sağlamıştır.","Evaluation of the teaching method has great importance in improving the course quality. This evaluation is harder in courses which focus on the process of program development, since it requires observation of the students' approach to problem solving. HtDP offers a ""design recipe"" which focuses on the process of program development. While there have been a number of studies focusing on the quality of this approach, there has not been any quantitative analysis.In this study, I first introduce a model and implementation of a tool (Screen-Replay) that enables the recording, replaying and annotation of programming sessions. This tool is implemented for DrScheme environment using Scheme programming language. It records and replays a programming session exactly as it occurred. Furthermore, while replaying, an observer may annotate the programming session by associating HtDP design recipe steps with specific time intervals. The resulting annotations form a sequence of design activity descriptions which describe the development process. In order to assess these sequences, a process scoring algorithms is proposed. Finally, the process scores and exam grades from a set of 61 development sessions are examined to gain insight into the impact of following design recipe on exam grades.Screen-Replay was effective for observing how students develop their programs. In contrast to personal observation, this approach provided consistent and objective observation of students development processes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gerçek objelerin üç boyutlu (3B) matematiksel modellerini oluşturma ihtiyacının ve girişimlerinin uzun bir geçmişi var. Eskiden modelin kendisini oluşturmak başlı başına problemin kendisi iken, 3B geriçatma teknolojisindeki gelişmelerle, hassas, fotogerçekçi ve fotogrametrik modeller oluşturmak daha önemli hale geldi. Bu çalışmada önceden tanımlı mimari modellerin görünümüne odaklanarak interaktif bir doku eşleme sistemi geliştirdik. Sistem, standart tükeci fotoğraf makineleri ile çekilen fotoğraflar kullanılarak verilen 3B model için uygun dokuların ayıklanması, düzeltilmesi ve eşlenmesi için yarı-otomatik bir yöntem önermektedir. Doku adaylarının ayıklanması ve düzeltilmesinde izdüşümsel geometri kullanılırken, bu adaylar kullanılarak kesintisiz doku bileşimleri oluşturmak için popüler grafik kesme eniyileme yöntemi kullanılmıştır. Bu süreci kesintisiz klonlamada kullanılan Poisson imge işleme yönteminin de aralarında olduğu bir çok yardımcı aracın bulunduğu bir iyileştirme aşaması takip etmektedir. Test amacıyla kendi oluşturduğumuz imge setlerinin yanı sıra bazı kullanıma açık veri setlerini de kullandık. Yapılan denemeler sonucu veri setleriyle ilgili herhangi bir önbilgi kullanmadan binaların hemen hepsine makul fotogerçekçi kalitelerde doku eşleşmesi yapıldığını gözlemledik. Ayrıca, doku eşleştirme zamanlarının, detaylı bina modelleri için bile, oldukça düşük olduğunu gösterdik. Bu çalışmada modellerin detaylı ve yüksek kalitede fotogerçekçi görünümlerini elde etmeyi amaçladığımız için yakın ölçekli ve zemin seviyesinden fotoğraflama yöntemini temel aldık. Fakat, kullanılan yöntem kolayca havadan ve geniş ölçekli geriçatma sistemlerini de içine alacak şekilde genişletilebilir.","The need and attempt for creating mathematically-defined three dimensional (3D) models of real world objects has a long history. While, in the past, creating the model was a problem itself, with recent developments in 3D reconstruction, creating accurate, photorealistic and photogrammetric 3D models of the objects has become the focus point. Starting from the architectural models, an interactive texture mapping system was developed concentrating on the visual appearance of the predefined models. The system presents a semi-automatic way of extracting, correcting, and mapping the appropriate textures to the given 3D building models using the images obtained by standard consumer-level digital cameras. Projective geometry takes place in extraction and rectification of texture candidates while popular graph cut optimization approach was utilized to create seamless texture composites using these candidates. A refinement phase was adopted for this procedure with a series of refinement tools including Poisson image editing in terms of seamless cloning. For testing purposes some publicly available datasets were used besides the imagesets that were created by photographing real world objects. It was shown that most buildings could be textured in an acceptable photorealistic quality without any predefined information about the datasets. Furthermore, it was observed that the texture mapping times, even for detailed building models, were quite low. This work mainly focuses on close-range or ground level imagery since the aim is to create detailed and high quality photorealistic view of the models. However, the approach could easily be extended towards the needs of aerial imagery or large scale reconstruction."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"WiMAX standardında Noktadan-Çoklu-Noktaya Bağlantı moduna ek olarak tanımlanan Çokgen Bağlantı modu, Baz İstasyonundan gelen internet trafiğinin yanısıra, Abone İstasyonları arasında da haberleşmeyi mümkün kılmaktadır. Çokgen Bağlantı modu çerçeve yapısına göre, kaynak paylaştırmak için Merkezi Planlama (MP), Dağıtımlı Planlama (DP) veya her ikisinin birden bulunduğu veri alt çerçevelerinden birisi kullanılır. MP, Baz İstasyonu tarafından koordine edilir ve internet trafiği için tasarlanmıştır, fakat hücre içi trafik olduğu durumlarda DP daha iyi sonuç verir. MP sisteminin uzaysal kullanımdan yoksun olması, beraberinde ölçeklenebilirlik ve başarım sorunları getirmektedir. Bu tezde sunulan Melez Çerçeve Yapısı (MÇY) metodu, Abone İstasyonlarının Baz İstasyonuna olan uzaklıklarına göre farklı görevler üstlenmelerini önerir ve bu şekilde standartta tanımlanmış olan MP ve DP yöntemlerinden faydalanmayı amaçlar. Simülasyon sonuçlarına göre, DP'nin uzaysal kullanım olanakları sayesinde, MÇY kabul edilebilir gecikme değerlerini aşmadan, ağ verimliliği açısından önemli bir artış sağlamaktadır.","In addition to the Point-to-Multipoint mode, WiMAX standard defines the Meshmode of operation, allowing Subscriber Stations (SS) to exchange data packets directlywith each other besides the Internet traffic through the Base Station (BS). The Framestructure defined for the Mesh mode can either use Centralized Scheduling (CS), DistributedScheduling (DS), or both CS/DS data subframes for resource allocations. CSis coordinated by the BS, thus designed for Internet traffic, whereas DS is more suitablefor intranet traffic. The lack of spatial reuse in CS causes scalability issues andperformance limitations. In this thesis, a Hybrid Frame Structure (HFS) method isproposed, which sets specific roles to the SSs according to their hop counts to theBS, taking advantage of both CS and DS schemes defined in the standard. Simulationresults suggest that by exploiting the spatial reuse property of DS, HFS providessignificant improvement in network throughput, while maintaining acceptable latencyvalues."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"EKG (elektrokardiyogram) insan vücuduna iliştirilen elektik algılayıcılarla kaydedilen elektriksel aktivitenin sinyal grafiğidir. Kardiyologlar tarafından teşhiste kullanılan en önemli biyosinyallerden birisidir. Bu çalışmada temel amacımız, teşhiste yardımcı olabilecek aritmik sinyal anormalilerini otomatik olarak tespit etmektir. EKG'deki bu anormalilerin insanlar tarafından tespiti hem zor hem de hataya açıktır. Bu nedenler, araştırmacıları kalple ilgili aritmi düzensizliklerini otomatik olarak tespit etmeye yönelik araştırma yapmaya yönlendirmiştir. Özdevimli öğrenme teknikleri kullanan bilgisayar yazılımları, karmaşık EKG sinyallerini kolayca analiz edebilir, bunları dönüşütrebilir, aritmi varlığı hakkında tahminlerde bulunabilir ve insanlara kararlarında destek olabilecek bilgiler sağlayabilirler. Bu çalışmada, sinir ağlarına dayanan öğrenme tekniklerinden birisi olan, Çok Katmanlı Geriye Yayılma Algoritması (ÇGY) ve Sınıf-Modülü kavramı iki EKG veri kümesine uygulanmıştır. Sınıf-Modülü kavramı, sınıfa dayalı özellik seçimiyle kullanılarak aynı zamanda boyut azaltma da sağlayan dayanıklı modüller elde edilmesi hedeflenmiş ve bunun için RELIEF tekniği kullanılmıştır. Veri kümelerinden birisi UCI veri havuzundan alınmış daha önce benzer çalışmalarda kullanılmıştır. Bulunulan ülkeye ait bir veri kümesi ise Türk hastalardan toplanan gerçek EKG kayıtlarından yaratılmıştır. Bu kayıtlar dijital ortama aktarılmış ve bir tıp doktoru tarafından incelenmiştir. Özellik seçme (Karar Ağaçları, DVM-Döngüsel Özellik Azaltılması) ve özellik genişletme (Asıl Bileşen Analizi) boyut azaltma teknikleri kullanılarak öğrenme tekniklerinin performansı arttırılmaktadır. Karşılaştırma amaçlı olarak Karar Ağaçları ve Destek Vektör Makineleri aritmi veri kümelerinde test edilmiştir. Weka ve Matlab çalışmalar sırasında özdevimli öğrenme araçları olarak kullanılmışlardır. Yapılan test sonuçlarına gore, ÇGY her iki EKG veri kümesi üzerinde de Karar Ağaçlarından daha iyi, DVM'yle yaklaşık sonuçlar vermektedir. Sınıf-modüler ÇGY'nin biraz daha az başarılı olsa da ÇGY'ye gore sunduğu ek avantajlar vardır.","ECG (Electrocardiography) is a graphical signal of electrical activity recorded from electrodes on the body surface. It is one of the most important biosignal used by cardiologists for diagnostic purposes. In this study, our main objective is automatically recognition of arrhythmic signal abnormalities, which may be a clue for diagnosis. The detection of an abnormality in ECG signals by human is both complex and error-prone. This motivated researchers to study automatic detection of cardiac arrhythmia disorders, using intelligent data analysis techniques. Computer software using machine learning techniques could easily analyze complex ECG signals, transform signals, make some predictions about the presence of arrhythmia, and provide decision-support information to humans. In this study Multilayer Perceptron (MLP), which is a neural network-based machine learning technique and Class-Modularity concept were applied to two ECG datasets for arrhythmia classification. Class-modularity was also used by class-dependent feature selection to obtain robust modules also providing dimensionality reduction. RELIEF was selected as a well-known technique for class-specific feature list creation. One of the datasets is from UCI repository and it was used on similar studies before. A local dataset is created using real-life ECG recordings collected from Turkish patients. These records are digitized and examined by a medical doctor. The performances of learning methods are improved by feature selection (Decision Trees, SVM-RFE) and feature extraction (PCA) dimensionality reduction techniques. As a comparison, Decision Tree and SVM algorithms have been tested on the arrhythmia dataset. Weka and Matlab were used as machine learning tools during the study. According to test results, MLP performs better than decision trees and similar to SVM on both ECG datasets. The class-modular MLP has slightly less performance, while providing several advantages over MLP."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sosyal ağlar benzer ilgi alanlarına sahip olan yada belirli bir alanda bilgi sahibi olan kişileri bulmak için kullanılabilmektedir. Günümüzde sosyal ağlarin bilgi paylaşımı amacıyla kullanılması, doğru bilgiye verimli şekilde ulaşmak yada temel olarak sorularımıza doğrudan yanıtlar bulmak için kullanılabilecek bir yöntemdir. Mevcut sosyal ağlar üzerinde benzer kişileri yada belirli bir bilgiye sahip doğru kişileri bulmak oldukça zordur. Bu sistemler üzerindeki kişi arama yada benzer kişileri bulma uygulamaları ya kullanıcıların kendi verdikleri kişisel bilgilere dayanmakta yada kullandıkları bir kelime ile metin bazlı esleştirme yaparak çalışmaktadır. Kullanıcılar sosyal ağlarda kendilerine ait tüm bilgileri paylaşmayabilmekte, ya da kendileri hakkında yanlış bilgiler verebilmektedirler. Kullanıcıların paylaştıkları içeriği değerlendirerek kullanıcılar arasında benzerlik bulmaya çalışan uygulamalar henüz gerçekleştirilmemiş durumdadır.Bu çalışma kapsamında, sosyal ağ uygulamalarının bir türü olan mikrobloglar üzerinde, kullanıcıların sağladıkları içeriği değerlendirerek sahip oldukları bilginin yada ilgilendikleri konuların hangi ilgi alanlarına ait olduğunu tespit etmek, bunun ötesinde diğer kullanıcılarla ortak ilgi alanlarına göre ilişki kurmak amaçlı bir model önerilmektedir. İçerik olarak kullanılan metin cümlecikleri içinde birlikte gecen kelimeler baz alınarak bu kelimeler arasında anlamsal bütünlük oluşturulmaya çalışılmakta, böylece kişilerin kendileri kullanmadıkları halde ilgi alanları ile ilişkili olabilecek olan diğer kelimeler tespit edilmektedir.Çalışmamızın sonucunda kullanıcıların sosyal ağlarda paylaştıkları içerik dikkate alınarak ortak ilgi alanlarına sahip kullanıcılar arasında bağlantılar kurulabileceği, ayrıca kişiler kullanmamış olsa bile bu ilgi alanları ile ilgili diğer sözcüklerin de tespit edilebildiği gösterilmiştir.","Social networks can be used to find people who share similar interests or people who have knowledge in a specific domain. Using social networks to share knowledge is a very efficient way of reaching information. Current social networking tools provide many ways to search people with similar interests. However, they are either based on keyword search or ranking users based on popularity. Keyword search is limited to information explicitly declared by users such as name, location, marital status, interests etc. Since users often do not declare their interest areas or the content they contribute is not aligned with the area of interest they declare, it is usually a time consuming task to locate those who are of interest. User ranking methods, on the other hand, hides users who provide valuable information but not so popular. In this study we propose a model for determining the area of interests of users based on their contributions. In other words, we examine what they contribute rather than what they declare about themselves. The idea is that their value depends on what they contribute. Areas of interests are determined based on the co-occurrence of related words in user contributions. In addition, we explore communities of different interests, based on the common context different people use in their contributions. In order to put some semantic grounding to what we have found as interest areas, we map the content we extracted from the users? contributions to other resources such as DBpedia[84], Wikipedia[82] and Google[83]. We show that interest areas of people can be extracted from the dynamic content they provide. Besides, common interest networks of users can be generated by implementing our model. Furthermore, we can also generate networks of words which provide us a way to put semantics into the search queries instead of solely keyword based inquiries."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, metin sınıflandırma problemi için öznitelik çıkarımı ve öznitelik seçimi konuları üzerine çok yönlü çözümlemeler yapılmaktadır. Sınıflandırmanın çözümünde daha küçük boyutta öznitelik çözüm vektörü kullanarak daha başarılı sonuçlara ulaşmak hedeflenmiştir. Öznitelik çıkarımı konusunda, 36 değişik sözcüksel bağımlılık incelenmiş ve geleneksel sözcük-torbası dizisine en uygun halde eklenmiştir. Öznitelik seçimi ise iki aşamalıdır. İlk aşamada budama uygulaması yapılmış ve veri kümesi özelliklerine ve öznitelik çeşitlerine (sözcük, bağımlılık ve bağımlılık bileşenleri) göre en uygun budama düzeyleri bulunmuştur. İkinci adımda veri kümesi tabanlı ve sınıf tabanlı öznitelik seçimi yaklaşımları karşılaştırılmış; sonrasında budama işlemi, en başarılı olduğu tespit edilen sınıf tabanlı öznitelik seçimi ile geliştirilmiştir. Tezin son deneyinde; en başarılı bağımlılık tipleri, iki aşamalı öznitelik seçimi ile beraber kullanılmaktadır.Başarı değerlendirmesi için, metin sınıflandırma problemlerinde kullanımı herkesçe kabul edilen iki ölçüm ve ek olarak üç değişik önemlilik testi uygulanmaktadır. Belirtilen değerlendirme ölçütlerine göre, önerilen her yeni yöntem, başarıyı önemli ölçüde arttırmaktadır. Bu duruma paralel olarak; sözcüksel bağımlılıkların en uygun kullanımını, iki aşamalı öznitelik seçiminin en başarılı düzeniyle birleştirdiğimiz son deney, genel olarak en başarılı sonucu vermektedir. Bu çalışma, bilgimiz dahilinde, metin sınıflandırmada ve genelde metin temelli problemlerde sözcüksel bağımlılıkların ve iki aşamalı öznitelik seçiminin çözümlemesi ve eniyilenmesi ile ilgili ilk detaylı çalışmadır.","In this thesis, we present a comprehensive analysis of the feature extraction and feature selection techniques for the text classification problem in order to achieve more successful results using much smaller feature vector sizes. For feature extraction, 36 different lexical dependencies are included and analyzed independently in the feature vector as an extension to the standard bag-of-words approach. Feature selection analysis is twofold. In the first stage, pruning implementation is analyzed and optimal pruning levels are extracted with respect to dataset properties and feature variations (words, dependencies, combination of the leading dependencies). In the second stage, we compare the performance of corpus-based and class-based approaches for feature selection coverage and then, extend pruning implementation by the optimized class-based feature selection. For the final and most advanced test, we serialize the optimal use of the leading dependencies for each experimented dataset with the two stage (corpus and class-based) feature selection approach.For performance evaluation, we use the state-of-the-art measures for text classification problems: two different success score metrics and three different significance tests. With respect to these measures, the results reveal that for each extension in the methods, a corresponding significant improvement is obtained. The most advanced method combining the leading dependencies with optimal pruning levels and optimal number of class-based features mostly outperform the other methods in terms of success rates with reasonable feature sizes. To the best of our knowledge, this is the first study that makes such a detailed analysis on extracting individual dependencies and employing feature selection with two stage selection approach in text classification and more generally in text domain."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kişisel bloglar çevrimiçi günlüklerdir. Blogsahipleri yorumlarını, fikirlerini, duygularını ve tecrübelerinibloglarında paylaşırlar. Birbirini kişisel olarak tanımayan, ancakbenzer ilgi alanlarına sahip kişiler birbirlerinin güncellemelerinibloglar aracılığı ile takip ederler.Microblog, güncellemelerin daha kısa mesajlardan oluştuğu bir blogtürüdür. Kullanıcılar microbloglarında ne yaptıklarını, nedüşündüklerini belirtebilirler, ya da bir haber, etkinlik hakkında bilgiverebilirler. Microblog kullanımı, mobil kullanıma uygun olduğundan vekısa microblog güncellemeleri, uzun, iyi yapılandırılmış bloggüncellemeleri kadar özen gerektirmediğinden, microblog kullanıcılarıblog kullanıcılarına göre daha sık güncelleme yapmaya eğilimlidirler. Buda çok büyük sayılarda microblog güncellemelerine neden olur. Sonuçolarak microblog sistemlerinde, çok büyük miktarda, çok yüksek hızlabiriken küçük güncellemeler oluşur.Microblog sistemlerinde aynı ilgi alanlarına sahip kullanıcıları bulmakbir sorundur. Çünkü kullanıcılar genelde birden çok alan hakkındayazarlar, ve bir çok kullanıcı gözden kaçabilir. Bir arkadaşımızın takipettiği, ya da bizi takip eden bir kullanıcıyı takip edip etmemeye kararverirken, onun hakkında bir şeyler bilmek faydalı olur. Bir microblogkullanıcısı hakkında fikir edinmek isteyen bir kişi, microblogsisteminin o kullanıcı hakkında sağladığı bilgiyi, ya da o kullanıcınıniletişim halinde olduğu diğer kullanıcıları inceleyebilir, ya da okullanıcının güncellemelerini okuyabilir. Bir kullanıcının devingen vesürekli yenilenen güncellemeleri, o kullanıcının ilgi alanlarını ortayaçıkarır. Ancak microblog güncellemelerini incelemek, bloggüncellemelerini incelemekten daha zordur. İyi yazılmış, iyiyapılandırılmış blog güncellemeleri ile karşılaştırıldığında microbloggüncellemeleri boyut olarak daha kısıtlı ve sayı olarak daha çoktur.Microblog güncellemelerinin sayıca çokluğu, ve dağınık yapısı, microblogkullanıcılarının ilgi alanlarını tayin etmeyi zorlaştırır.Sayıları ve dağınık yapıları dolayısıyla microblog güncellemelerinin birkişi tarafından incelenmesi yorucudur. Bu çalışmada, microblogkullanıcılarının karakteristiklerinin ve ilgi alanlarının otomatikolarak anlaşılabilmesi için bir model önerilmektedir. önerilen yöntemaşağıdaki adımları içerir:-güncellemelerde kullanılan dikkate değer kelimelerin incelenmesi,-güncellemelerde geçen harici referansların incelenmesi,-güncellemelerde geçen dahili referansların incelenmesi, ve- microblog sistemi tarafından kullanıcı hakkında verilen bilgininincelenmesiBu modelin, çok başarılı ve yaygın olarak kullanılan bir microblogservisi olan Twitter'ın uygulama programlama arayüzünü kullanan biruygulaması sunulmaktadır.Bu çalışmanın sonucunda, belirli grup kullanıcıların karakteristikleribelirlenmiş, ve bireysel kullanıcıların microblog güncellemelerikarşılaştırılmıştır. Bu şekilde bir bilgi hangi microblogkullanıcısının, hangi amaçla takip edileceği kararını verirkenkullanılabilir.","Personal blogs are online diaries. Bloggers sharetheir comments, opinions, feelings and experiences on their blogs.People, who share similar interests but typically do not know each otherin person, follow each other's updates through their blogs.Microblogging is a kind of blogging in which users' contributionsconsist of shorter messages. Microblogs may express what themicroblogger is doing or thinking, or inform about something like news,entertainment, good deals, etc. Since microblogging is suitable formobile use, and short microblog contributions do not require muchattention as long, well-structured blog posts, microbloggers tend topost their updates more frequently than regular bloggers, which resultsin a larger number of microblog posts. As a result, the microblogospherepresents a vast amount of short messages that arrive at high speed.In microblogging systems, there is the problem of finding users ofinterest -- as people are multifaceted and often escape notice. Whendeciding whether to follow a user who may be following us or followed bya friend, it would be useful to know something about them. Usually, aperson who wants to get an opinion about a microblogger can look at themetadata supplied by the system, examine other microbloggers incommunication with that particular microblogger, or read hercontributions. A user's dynamic and continuously updated contributionsreveal her interests in that particular system. However analyzingmicroblog posts is more difficult than analyzing blog posts. Compared towell written, structured blogger posts, microblogger posts arerestricted in size and plenty. The sheer volume and fragmented nature ofmicroblogs make it difficult to assess the characteristics andinterests of a user.Manually analyzing microblog contributions would be overwhelming due totheir quantity and fragmented nature. In this study, a model forautomatically revealing microbloggers' characteristics and interests isproposed. Proposed approach supports the following:- analyze all significant words uttered in posts,- analyze external references existing in posts,- analyze internal references existing in posts, and- examine user meta information in the microblogging systemAn implementation of this model, which uses the API of the highlysuccessful and widely used microblogging service Twitter is presented.The results of this work are discussed in terms of determining thespecific characteristics of particular groups of users as well as thecomparison of individual microblogger contributions. Such informationcould be utilized in deciding who to follow for what purpose."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı kart teknolojisi, gelişen uygulamalarıyla artık daha da popüler. Bu kartlardünyada bir çok alanda kullanılmakta. Bunlardan bazıları şunlardır; Sağlık Sistemleri,Bankacılık Sistemleri, Taşınabilir İletişim Sistemleri, NFC (Near Field Communication- Yakın Alan İletişimi) Uygulamaları, Ulaşım ödeme Sistemleri, Ulusal Kimlik KartıUygulamaları, Elektronik Pasaport Sistemleri.Bu projede, küçük ,taşınabilir aletler olan akıllı kartlar için yeni bir sistem tasarlanmıştır.Bu sistemin bir Akıllı Kart Durumdan Haberdar Akan Veri Yönetim Sistemi'dirve adı Akıllı Kart Akan Veri Yönetim Sistemi'nin ingilizce kısaltması olanSCDSMS olarak verilmiştir.","Smartcard Technology is becoming very popular than before via the extendedapplications on it. They are widely used in many areas in the world. Health CareSystems, Banking Systems, Mobile Communication, NFC (Near Field Communication)Applications, Travel Payment Systems, National ID Card Systems, Electronic PassportApplications and many other areas can be counted that use smartcards as its maindevice.In this project, a new system for this widely used little, portable and usefuldevices is oered. This system is a ""Data Stream Management System based on aContext Awareness on Smart Cards"" called Smart Card Data Stream ManagementSystem (SCDSMS). SCDSMS is a context aware database management system forsmart cards."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı ulaşım teknolojilerinin hızla gelişmesiyle birlikte çok yakın bir gelecekte akıllı kara araçlarının trafikte seyrettiğini görmek mümkün olacaktır. Dahası insansız akıllı araçlar trafik kazalarını aza indirgeyerek ve karbon gazları salınımını azaltarak ulaşım endüstrisinde devrim niteliğinde bir etki yapacaklardır. Halihazırda birkaç ülkede insansız kara aracı geliştirme projeleri devam etmekte ve bununla da kalmayıp otomobil üreticilerinin araştırma geliştirme bölümlerinde de trafik güvenlik sistemleri ve otonom ulaşım uygulamaları için otonom sürüş alanlarında çalışılmaktadır. Bu tez otomobilerde kullanılan trafik güvenliği sistemlerinin en önemlerinden biri olan ve aynı zamanda insansız kara araçlarının algılayıcı alt sisteminin kritik bir parçası olan Şerit Tanıma üzerine odaklanmıştır.Şerit tanımanın esas amacı kamera görüntüsünde şeritlerin yerini belirleyerek, şeride olan uzaklık ile yol ve arabanın yönünün hesaplanmasını sağlamaktır. Bilgisayarla görme yeteneğine dayanan metodlar hava şartları, farklı aydınlanma koşulları ve yol şartlarının görüntü üzerinde neden olduğu problemleri çözmeye çalışmaktadır. Bu tez kapsamında hava ve yol durumunun zorlu şartlarında başarılı sonuçlar üreten yeni bir şerit tanıma metodu geliştirilmiştir. Metodun üç ana safhası bulunmaktadır; şerit özniteliklerini bulma, şeritleri ayrıştırma ve yol modelini oturtma. Bu çalışmadaki şerit özniteliklerini bulma yöntemi simetrik yerel eşik yöntemine dayanmaktadır, ancak silinmiş şeritleri ve yol kenarlarının bulunmasında çok daha başarılı çalışmaktadır. Aracın sağ ve sol yanındaki şeritlerin tanımlanması ve ayrıştırılması için RANSAC algoritması ile belirli bir hata varyansıyla her iki tarafta bir doğru denklemi tanımlanır. Doğru denklemini sağlayan pikseller kullanılarak en uygun hiperbol yol modeli ile yol ve aracın parametreleri hesaplanır. Geliştirilen metod ile üretilen sonuçlar yol imajları içeren ROMA referans veritabanı üzerinde gösterilmiş ve ROC, DSC metrikleri grafik olarak sunulmuştur. Metodun başarısı ayrıca sentetik imajlar üzerinde de gösterilmiştir.","As the intelligent transportation technologies have rapidly been improving, it isplausible to state that intelligent ground vehicles will be on the roads driving throughthe traffic in the near future. Moreover, intelligent vehicles will have a revolutionaryeffect in transportation industry, while eliminating accidents, and reducing the emissionof carbon gases. Not only presently multiple intelligent vehicle projects are in progressin several countries but also the research and development departments of automobilemanufacturers work on the traffc safety applications as well as autonomous navigationfor future autonomous transportation. This study focuses on one of the most importanttraffic safety applications which is also a crucial part of a perception subsystem of anautonomous ground vehicle, that is, Lane Detection.Main purpose of lane detection is to estimate the position of the road lane markswith a camera in order to calculate the distance to the lane and relative direction of thevehicle. Vision-based lane detection systems try to overcome the challenges of weather,lighting, road conditions to detect the lane marks. Within this thesis, we have proposeda novel lane detection method which produces successful results under challengingconditions. The method has three important phases; lane feature extraction, laneselection and road model fitting. The lane feature extraction method in our work issimilar to the symmetrical local threshold. However, it is more powerful to detecteroded lane marks and road borders. In order to estimate the lane on the left and rightside of the vehicle, Random Sample Consensus (RANSAC) algorithm fits a line withan error variance for lanes on both sides. Using the lane pixels on the estimated lines,a hyperbola-pair model is generated and the parameters of the road and the vehicle iscalculated for the navigation subsystem. Results are presented on a reference image database Road Marking database (ROMA) and evaluated with Receiver OperatingCharacteristic (ROC) and Dice Similarity Coefficient (DSC) curves. Synthetic imagesare also used to evaluate the performance of the lane detection technique."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüz endüstrisinde pek çok uygulama tarafından kullanılmakta olan proseslerin modellenmesi ve kontrol edilmesi üzerine yapılan araştırmalarda önemli bir artış gözlemlenmektedir. Ancak asimetrik proses kontrolünde yapılan sınırlı sayıda araştırma mevcuttur. Sıcaklık kontrolü bu proseslerin sık kullanılan bir örneğidir. Buna örnek olarak endüstriyel ocak ve fırın, klima ortamları, plastik enjeksiyon baskı makineleri, ilaç ve boya fabrikaları, yemek endüstrisi, ısıtma ve soğutma sistemleri gibi uygulamaları verebiliriz. Asimetrik sistemler, sistem dinamikleri yöne göre değişen sistemlerdir. Bu sistemlerde güçlü ısıtıcılar dolayısıyla ısınma hızlı olurken, soğuma daha yavaş gerçekleşmektedir. Bununla birlikte, sistemin belirlenen hedef değerine oturması gerekmektedir. Bu sebeple klasik PID kontrol metodu istenen hedeflere ulaşmada yeterli olamamaktadır.Bu projede, bir sistem üzerindeki asimetrik etkiyi ortadan kaldırmak üzere, tam güç ve PWM modları yardımıyla ilk olarak, aşımı engelleyip oturma zamanını mimimuma indirdik. Sonrasında sistemin kararlı-hal bölgesinde çalışarak, simetrik davranışa sahip bir sistem çıkışı elde etmek üzere PID kontrol metodu üzerinde bazı iyileştirmeler yaptık.Uygulanan modeli test etmek için, mikrodenetleyici kontrollü bir tümleşik devre ve kullanıcı tarafından PC üzerinden kontrol edilmek üzere bir kullanıcı arayüzüne sahip tam donanımlı bir kontrol sistemi tasarladık. Sistem ana olarak bir ısıtma rezistansı, termokuple, mikrodenetleyici temelli bir devre ve görüntüleme amacıyla bir PC'den meydana gelmektedir.Bu projede ilk olarak asimetrik proseslerin genel karakteristikleri anlatıldıktan sonra birçok metottan meydana gelen yeni bir kontrol modeli sunulmaktadır. Sonrasında projenin yazılım ve donanım modelleri açıklanmakta ve sonunda sonuçlar tartışılmaktadır.","In today?s industrial environments, there is an increasing number of modelling and controlling researches of the processes which are used in many types of applications. However, there are only some limited researches on asymmetrical processes. Temperature control system is a common example of those processes. Some examples to that are industrial oven and furnace, air conditioned mediums, medicine and dye factories, food industry, heating and cooling systems and so on. The asymmetrical processes are the systems whose dynamics may change depending on the direction. In those systems, since the powerful heaters, the heating process realizes rapidly but that the cooling process slowly. That?s why, the classical PID control method may not be enough to get the desired results.On this project, we developed a new model by firstly reducing the overshoot and minimizing the settling time with Full power and PWM modes. Then, we made some improvements on the standard PID method to get a system output like symmetrical behaviour.In order to test the applied model, we developed a full control system with a microcontroller based embedded board and a user interface on PC to be controlled by the user. The system mainly consists of a heating rezistance, thermocouple, microcontroller based board and a PC to visualize the system.In this project, firstly the general characteristics of the asymmetrical processes are discussed and then a new control model is presented with some complicated methods. After talking about the software and the hardware models, the results are discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Belgelerin katlanarak büyümesi mevcut arama ve içerik yönetim teknolojilerini zorlamaktadır. Bu sorunu azaltmak için bir yaklaşım belgeların kullanıcılar tarafından seçilen belgelerde geçen önemli kelimelerle etiketlenmesidir. Ancak bu yaklaşımın etiketleri sınırlıdır çünkü etiketler i) bağlam ve form özgür, ii) belgeleri tanımlamadan farklı amaçlarda kullanılabiliyor iii) genellikle belirsiz kalıyorlar. Etiketleme gönüllü bir eylem olduğundan dolayı çok sayıda belge etiketlenmemektedir. Son olarak, belgelere atanan etiketlerin yorumlanmasıda ayrı bir zorluktur.Anlamsal web kaynakları ve teknolojileri, bu zorlukları aşmak ve otomatik olarak semantik etiketler oluşturmak için kullanılabilir. Semantik etiketler belgelerin içeriğini daha iyi ifade etme dışında, daha iyi arama sonuçları elde etmemizi sağlamaktadır. Ontoloji kapsamı, terimlerin ontolojide doğru kavramlarla ilişkilendirilmesi ve anlamsal etiketlerin ağırlıklarının belirlenmesi anlamsal etiketleme sistemlerinde çözülmesi gereken önemli sorunlardır.İngilizce için önde gelen ontoloji olan WordNet başarıyla anlamsal etiketleme için kullanılmaktadır. Ancak bu yaklaşım yeni kavramlar içeren belgeleri etiketlemede yetersiz kalmaktadır.Bu çalışma belgeler için otomatik olarak anlamsal etiketler oluşturan bir sistem önermektedir. Bu amaçla, ilk katkımız ontolojik bilgi tabanı platformu olan UNIpedia' dır. UNIpedia çağdaş referansları içeren bir bilgi tabanı sağlamaktır. Burada, çağdaş kelimesi web de geçen güncel kelimeler bağlamında kullanılmaktadır. UNIpedia çeşitli ontolojik bilgi tabanlarını WordNet kavramlarıyla ilişkilendirmektedir. Güncel ve güvenilir bilgi içeren Wikipedia ve OpenCyc bilgi tabanları WordNet kavramları ile eşleştirilmiştir. Bilgi tabanlarını ilişkilendirmek için kavramların ontolojik ve istatistiksel özelliklerini kullanan kural tabanlı sezgiseller kullanılmıştır.Konuşma dillerinin çok anlamlılığından dolayı UNIpedia' da tanımlı terimler birden fazla anlam içerebilmektedir. Bu çok anlamlı kelimeler dökümanın içeriğine göre farklı anlamlar alabilmektedirler. Belgede geçen terimler çok anlamlıysa doğrudan UNIpedia kavramlarıyla ilişkilendirilememektedir. Terimlerin doğru anlamlarını bulabilmek için otomatik anlamsal etiketleme sistemi olan Semantic TagPrint geliştirilmiştir. Bu eserin ikinci katkısı olanSemantic TagPrint anlam belirginleştirmesi için doğrusal zamanda çalışan kelime zincirlerini kullanmaktadır. Buna ek olarak, Semantik TagPrint belgenin içeriğini açıklayan anlamsal etiketlerin önemini belirler ve önerir. Anlamsal etiketleme ve önerme algoritmaları UNIpedia da tanımlı olan kavramların istatistiksel ve anlamsal özelliklerini kullanmaktadır. Semantik TagPrint sisteminin potansiyel yararlarını göstermek için Anlamsal Bilgi Yönetimi Aracı (SKMT) uygulanması tasarlanmış ve geliştirilmiştir. Bu eserin üçüncü katkısı olan SKMT semantik belgeleri etiketlemek için Semantik TagPrint için erişilebilir bir platform sunar ve semantik arama yapar.","The exponential growth of documents is challenging the existing search and content management technology. An approach for mitigating this issue is user-generated tags, a simple method by which users associate keywords to documents. However, the improvements, from this approach are limited because tags are i) free from context and form, ii) used for purposes other than description, and iii) often remain ambiguous. Since user tagging is a voluntary action, many documents remain untagged. Finally, the interpretation of the tags associated with documents also remains a challenge.To overcome these challenges, semantic web resources and technologies can be utilized to automatically generate semantic tags. Semantic tags not only reflect document content more accurately, they also enable better search results. Ontology coverage, word sense disambiguation and weighting significant ontological entities within a context are key challenges in semantic tagging systems.The leading ontology for the English language, Wordnet, has been successfully used for semantic tagging. However, this approach falls short in tagging documents that refer to new concepts and instances.The main focus of this work is automatically generating semantic tags for arbitrary documents. For this purpose, the first contribution is an ontological knowledge base plat- form called UNIpedia. UNIpedia aims to provide a knowledge base with contemporary references. Here, contemporary should be understood as in line with web pace. UNIpedia maps various ontological knowledge bases to WordNet concepts. The Wikipedia and OpenCyc knowledge bases, which are known to contain up to date instances and reliable metadata about them, were mapped to WordNet. A rule based heuristics, which uses the ontological and statistical features of concepts and instances, is introduced for the mapping process.UNIpedia terms may have several senses because of the natural language ambiguity. These so called polysemous terms get different meanings according to the context. A term passing in a document cannot be mapped to an UNIpedia concept or instance directly, if the term is polysemous. In order to identify the correct sense of the polysemous terms, an automated semantic tagging system called Semantic TagPrint was devised. Semantic TagPrint is the second contribution of this work that uses a linear time lexical chaining Word Sense Disambiguation algorithm for semantic annotation. In addition, Semantic TagPrint weighs and recommends semantic tags which describe the content of a document well. The semantic annotation and semantic tag weighting algorithms use both semantic and statistical features of UNIpedia.The potential benefits of Semantic TagPrint are demonstrated by the design and implementation of the Semantic Knowledge Management Tool (SKMT). SKMT is the third contribution of this work that provides a user accessible platform for Semantic TagPrint to semantically tag documents, and performs semantic searches."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet ağında yaşanan son gelişmeler, içerik bakımından geniş çaplı birkatılım sağlamaya zemin hazırlamış ve bizim iletişim biçimimizi ve bilgiyeerişim şeklimizi değiştirmiştir.Önceleri habere ulaşmak için insanlar gazete vetelevizyona bağlıydılar. Katılımıcı ağın ortaya çıkmasıyla, vatandaşgazeteciliği kendini İnternette göstermiştir. İnternet ağında yayın yapmanın enson örneği microbloglardır. Microbloglar, bloglara benzerler ve zaman değeribulunan gönderilerden oluşup genellikle üyelik yoluyla kullanılırlar. Fakat,ufak boyutlarıyla(140 karakter) ve yüksek mesaj gönderme sıklıklarıylageleneksel bloglarlardan farklılık gösteriler.Microblogların çeşitli kullanılma sebepleri vardır. Sosyal etkileşim, bilgitoplama, bilgi paylaşımı, pazarlama ve spam önemli kullanımlar arasındadır.Küresel olaylar ile ilgili fikirler ve duygular microbloglardayansıtılmaktadır.Oldukça yüksek seviyedeki mesaj miktarı bu platformları haber bilgi paylaşımözellikleri açısından incelemek için ilgi çekici hale getirmektedir. Aynızamanda, yüksek miktardaki veri, bilgi içeriği olan mesajları tanımlamaaçısından epey zorlayıcı olmaktadır.Bu tez haber mesajlarını tanımlamak için bir yaklaşım önermektedir. Bu yaklaşımbenzer mesajları yakalamak ve onların zamansal ve nicel özelliklerini analizedip üzerinde çalışmak için uygulanmıştır.Haber sağlayıcılar mikroblogları nasıl kullanıyor?Bireysel kullanıcılar haber yayıyor mu ? Yayıyorsa nasıl yayıyorlar?Zamana ait ve niceliksel özellikler nelerdir?Twitter, en popüler mikroblog sistemi (bu tez yazılırken) mikroblog sistemiolarak kullanılmıştır. Hem haber olayları hem de bireyler açısından, iletiler(tweets olarak adlandırılır) haber tweetlerini ayırt etmek için filtrelenmiştir.60 kullanıcı ve çeşitli haber olaylarına dayanan sonuçlar sunulmuştur.Bu tez çalışmasında, haber paylaşımlarını belirlemek için bir haber modelitanıtılmıştır. Twitter microlog kaynağı olarak seçilmiştir. Bir kısım, farklıküresel olaylara ait ve bireysel microblog kullanıcı mesajları incelenmiştir.","Recent advancements in Web have enabled the wide scale participation incontent, which has changed the way we communicate and access information.Traditionally people were subject to accessing news from main stream media suchas newspapers and televisions. With the advent of participatory web, citizenjournalism has emerged, which manifests itself on the Web. The most recent formof Web publication are microblogs. Microblogs are similar to blogs, which aretimestamped posts that are most typically consumed through subscription. Unlikeconventional blogs, however, microblogs differ in their tiny size (140characters) and the frequency of posting.Microblogs are used for a variety of reasons. Social interaction, informationgathering, information sharing, marketing, and spam are among the key uses.Thought and feelings regarding global events are sure to reflect on microblogs.The massive quantity of posts make these platforms interesting to explore withrespect to news information sharing behavior. At the same time, the massivequantity also makes it a challenge to identify posts that are informative.This thesis proposes an approach for identifying news posts. This approach isimplemented in order to fetch and analyze such tweets to study temporal andquantitative properties of such posts.How do main stream media use microblogs?Do individuals share news If so, how?What are the temporal and quantitative properties?Twitter, the most popular microblogging system (at the time of the writing ofthis thesis) was used as microblogging system. The posts (called tweets) werefiltered to identify news tweets, both for news events as well as individuals.The results based on 60 users and various news events are presented.In this thesis, a news pattern to identify news contributions was introduced.Twitter was chosen as a microblog source.A number of tweets related todifferent global events and individual microblog user posts were examined."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, notaların gerçek zamanlı perde takibi için Bayes'çi yöntemler ele alınmıştır. Burada ses perdesini, sesin frekans yapısıyla yakından ilgili, fiziksel bir öznitelik olarak ele alıyoruz.Nota takibi, bir notanın perdesinin çevrimiçi bir şekilde belirlenmesi görevidir. Motivasyonumuz, kalın sesi müzik aleti çalan müzisyenler için faydalı olabilecek, hassas ve düşük gecikmeli bir nota takip sistemi geliştirmekti. Ancak hassaslık ve gecikme çelişen iki nicelik olduğu için aynı anda hassasiyeti enbüyütmek ve gecikmeyi enküçültmek zor bir görevdir.Bu çalışmada, çevrimiçi nota takibi için iki olaslıksal model öneriyoruz: Saklı Markov Modeli (SMM) ve Değişim Noktası Modeli (DNM). Bu alanda yapılan önceki çalışmalarda genel, müzik aletine bağlı olmayan nota takip modellerine odaklanılmıştı. Bunun aksine, bizim modellerimiz müzik aletine göre özelleştirilebilir ve belirli bir enstrumana göre eniyilenebilir.Modellerimizde, her notanın spektral şablon adını verdiğimiz bir spektral yapıya sahip olduğunu varsayıyoruz. Üretici modellerimizi, ses spektrumunun bir zaman diliminin, bu şablonlardan birinin bir gürlük katsayısıyla çarpılarak oluştuğu varsayımıyla kurduk. Bu açıdan, nota takibi problemini bir çeşit şablon eşleme problemi olarak ele alıyoruz. Amacımız, ses verisini gözlemledikçe hangi şablonun etkin olduğu ve gürlük katsayısının ne olduğu çıkarımını yapabilmek.SMM'de, notaların bir önceki notaya bağımlı olduğu bir zamansal yapıya sahip olduğunu varsayıyoruz. Gürlük değişkenini zamandan bağımsız ele alıyoruz. Ancak müzik seslerini göz önünde bulundurursak bu varsayım doğal değil. Diğer bir yandan, bu modellerde çıkarım yapmak için standart ve hızlı yöntemleri kullanabiliyoruz.DNM'de, gürlük değişkenleri için de bir zamansal yapı öneriyoruz. Bu şekilde, DNM ile bir müzik aletinin sönümlenme yapısını açık şekilde modelleyebiliyoruz. Ancak ödünleşim sonucu, bu modelde çıkarım yapmak için çok daha karmaşık çıkarım yöntemleri kullanmamız gerekiyor. Ayrıca, bir noktadan sonra gerçek çıkarım uygulanamaz oluyor. Bu yüzden bu model için yaklaşık bir çıkarım şeması geliştirdik.Bu çalışmanın temel hedefi, nota takip sisteminindeki gecikme ve hassasiyet arasındaki ödünleşimi incelemektir. C++ dilinde geliştirdiğimiz bir uygulamayı kullanarak çeşitli deneyler yaptık. Modellerin başarılarını süzgeçleme ve sabit gecikmeli düzleştirme dağılımlarından elde ettiğimiz en muhtemel yolları kullanarak hesapladık. Değerlendirmeyi tek sesli bas gitar ve tuba kayıtları üzerinde ve dört farklı ölçüt kullanarak yaptık. Ayrıca sonuçlarımızı standard bir perde takip algoritması olan YIN ile karşılaştırdık. İki modelimizden de YIN'den daha başarılı sonuçlar elde ettik. En yüksek hassasiyeti DNM, en yüksek hesaplama hızını ise SMM ile elde ettik.","In this thesis, we deal with probabilistic methods to track the pitch of a musical instrument in real-time. Here, we take the pitch as a physical attribute of a musical sound which is closely related to the frequency structure of the sound.Pitch tracking is the task where we try to detect the pitch of a note in an online fashion. Our motivation was to develop an accurate and low-latency monophonic pitch tracking method which would be quite useful for the musicians who play low-pitched instruments. However, since accuracy and latency are conflicting quantities, simultaneously maximizing the accuracy and minimizing the latency is a hard task.In this study, we propose and compare two probabilistic models for online pitch tracking: Hidden Markov Model (HMM) and Change Point Model (CPM). As opposed to the past research which has mainly focused on developing generic, instrument-independent pitch tracking methods, our models are instrument-specific and can be optimized to fit a certain musical instrument.In our models, it is presumed that each note has a certain characteristic spectral shape which we call the spectral template. The generative models are constructed in such a way that each time slice of the audio spectra is generated from one of these spectral templates multiplied by a volume factor. From this point of view, we treat the pitch tracking problem as a template matching problem where the aim is to infer the active template and its volume as we observe the audio data.In the HMM, we assume that the pitch labels have a certain temporal structure in such a way that the current pitch label depends on the previous pitch label. The volume variables are independent in time, which is not the natural case in terms of musical audio. In this model, the inference scheme is standard, straightforward, and fast.In the CPM, we also introduce a temporal structure for the volume variables. In this way, the CPM enables explicit modeling of the damping structure of an instrument. As a trade off, the inference scheme of the CPM is much more complex than the HMM. After some degree, exact inference becomes impractical. For this reason, we developed an approximate inference scheme for this model.The main goal of this work is to investigate the trade off in between latency and accuracy of the pitch tracking system. We conducted several experiments on an implementation which was developed in C++. We evaluated the performance of our models by computing the most-likely paths that were obtained via filtering or fixed-lag smoothing distributions. The evaluation was held on monophonic bass guitar and tuba recordings with respect to four evaluation metrics. We also compared the results with a standard monophonic pitch tracking algorithm (YIN). Both HMM and the CPM performed better than the YIN algorithm. The highest accuracy was obtained from the CPM, whereas the HMM was the fastest in terms of running time."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu ç?alış?mada, araş?tırmacılara ve kullanıcılara hem temel, hem de deneysel yapay öğrenme algoritmaları iç?eren web tabanlı, platform ba ?ımsız ve kapsamlı bir görselleştirme ve analiz aracı sunuyoruz. Sınıflama, kümeleme, gerileme, ön-işleme ve görselleştirme algoritmalarını bir arada sunan bileşen tabanlı uygulamalar daha once bir çok programlama dilinde, değişik platformlar üzerinde çalışacak şekilde ve değişik veri formatları üzerinde gerçekleştirildi. Ancak platform bağımlı bu uygulamalar, kullanıcılara değişik yapay ogrenme algoritmalarını hızlı ve kolay bir şekilde deneme ve karşılaştırma imkanıvermemektedir. ML-Lab ornekleme, ozellik seçme ve çıkarma, sınıflama, görsel olarak karşılaştırma ve istatistiksel testler gibi bir çok metoda imkan vermektedir. ML-Lab kullanıcılara sunduğu geniş algoritma seçeneklerine ek olarak, kullanıcı dostu ve şık bir arayüz sunmaktadır. ML-Lab'ın bileşen tabanlı uygulama çatısı hem deneyimli kullanıcıları ve araştırmacıları, hem de yapay ogrenme alanına yeni adım atmış kullanıcıları hedeflemektedir. Bu çalışmadaki yapay öğrenme algoritmaları kullanımı kolay ve gelişmiş bir sözdizimine sahip olan Python betikleme dilinde gerçeklenmiştir. ML-Lab sisteme kolayca yeni algoritmalar ve eklentiler yaplabilmesi için genişletilebilir bir mimaride tasarlanmıştır.","We propose a comprehensive and interactive web-based machine learning suite that will allow researchers and practitioners to use a wide collection of basic and experimental learning algorithms and sophisticated visualization and analysis tools. Component based frameworks incorporating data input/output, pre-processing, classification, clustering, regression and visualization schemes have been implemented before in various programming languages, for use on different platforms, to operate using a variety of data formats. ML-Lab includes a large variety of machine learning algorithms for resampling, feature selection and extraction, classification and ensemble methods, as well as tools to visualize the experimental results of statistical comparison and testing. It provides a sophisticated and easy-to-use interface for creating workflows and a component-based framework intended for both experienced users and also those who are just entering the field. The collection of machine learning algorithms are implemented in Python, a modern easy-to-use scripting language with clear but powerful syntax and extensive set of additional libraries. ML-Lab has an extensible architecture and allows adding new capabilities to the system infrastructure easily."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda yapay öğrenme için çeşitli çoklu çekirdek yöntemleri önerilmiştir. Değişik çekirdekler değişik benzerlik ölçütleri tanımlamaktadır, ve çoklu çekirdek öğrenimi farklı benzerlik ölçütlerini birleştirmek için kullanılabildiği gibi farklı veri gösterimleri üzerinde hesaplanan çekirdek fonksiyonlarını kullanarak farklı kaynaklardan gelen veya farklı özelliklerdeki verileri birleştirmek için de kullanılabilir. Bu tez, çoklu çekirdek öğrenimi için yeni yöntemler önermekte ve bu yöntemlerin kullanılabilirliğini standart karşılaştırma veri kümelerinin yanısıra görüntü tanıma ve biyoinformatik veri kümeleri üzerinde alınan deneysel sonuçlarla desteklemektedir.Bu tez, çoklu çekirdek öğreniminde düzenli sonuçlar elde etmek için, tepki yüzeyi yöntemini kullanarak, geçerleme verisi üzerinde en iyi düzen parametrelerinin seçimi için yeni bir çoklu çekirdek öğrenim yöntemi önermektedir. Düzen parametrelerinin eniyilenmesi elimizdeki sınıflandırma problemi için daha iyi karar fonksiyonları elde etmemizi sağlamaktadır. Sınıflandırma başarısına katkıda bulunmayan çekirdekler düzen parametrelerinin bu doğrultuda seçilmesiyle elenmekte ve daha iyi ayırtaçlar elde edilmektedir. Bazı çekirdelerin kullanılmaması veya daha az destek vektörü saklanması ile yeni örnekler için deneme zamanı azalmaktadır.Bu tez, aynı zamanda, çekirdek hesaplama ve veri toplama/işleme maliyetlerini dikkate alan maliyet-bilinçli bir çoklu çekirdek öğrenimi yöntemi önermektedir. Sonuçlar maliyet etkeninin modele eklenmesinin deneme aşamasında yalnız gerekli çekirdeklerin kullanılabilmesini ve bazı veri gösterimleri için maliyetli çekirdek hesaplamalarından ve veri üretim aşamasından kaçınılabilmesini sağladığını göstermektedir.Bu tezin ana katkısı, çekirdek-tabanlı bir öğrenme algoritması ve çekirdek fonksiyonlarına veriye bağlı ağırlıklar atayan bir geçit modelinden oluşan yerel çoklu çekirdek öğrenim yöntemi önermesidir. Öğrenme algoritmasını üç değişik geçit modeli için geliştirdik ve yerel çoklu çekirdek öğrenimini iki sınıflı sınıflandırma, regresyon, çok sınıflı sınıflandırma ve tek sınıflı sınıflandırma problemlerine uyguladık. Önerilen yöntem, değişik veri gösterimleri üzerinde tanımlanan sınıflandırma problemlerinde, bu veri gösterimleri üzerinde hesaplanan çekirdekleri yerel olarak birleştirerek daha iyi sınıflandırıcılar üretmektedir. Bilinen çoklu çekirdek öğrenim yöntemiyle karşılaştırıldığında, önerdiğimiz yöntem daha yüksek ortalama sınıflandırma başarısı elde etmekte ve daha az destek vektörü saklamaktadır. Beklendiği gibi, farklı veri gösterimlerinin birleştirilmesinin aynı veri gösteriminin birçok kopyasının birleştirilmesine göre daha üstün olduğunu gördük. Önerilen yöntem, görüntü tanıma problemlerinde geçit modeli ile görüntü parçaları üzerinde hesaplanan çekirdekler içinden seçim yaparak her bir örnek görüntünün belirgin parçalarını bulabilmektedir. Ayrıca, genel çekirdek ağırlıkları kullanan yöntemlerden farklı olarak aynı çekirdeğin birçok kopyasını birleştirebilmektedir. Gerekenden fazla çekirdek verildiği durumda bile, modelin gerektiği kadar destek vektörü kullandığını ve aşırı öğrenmediğini gösterdik.Yerel izdüşüm çekirdekleri öğrenen ve çekirdek-tabanlı öğrenme algoritmaları ile birleşik, gözetimli ve yerel bir boyut azaltma yöntemi önerdik. Bu yöntem, görselleştirme görevlerinde bir sınıfın çoklu biçimli yapısını, bu sınıfın örneklerini ayırtacın aynı tarafına koyarak ve aralarındaki ayrımı koruyarak sürdürebilmektedir. Sınıflandırma görevlerinde ayırtaç parametlerinin ve boyut azaltmada kullanılan yerel izdüşüm matrislerinin birlikte eniyilenmesiyle, diğer yöntemlere göre daha yüksek sınıflandırma başarısı elde edilmekte ve daha az destek vektörü saklanmaktadır.","In recent years, several multiple kernel learning methods have been proposed in the machine learning literature. Different kernels correspond to different notions of similarity and multiple kernel learning can be used to combine them. It can also be used to integrate different inputs coming from different representations, possibly from different sources or modalities, by combining kernels calculated on these representations. This thesis contains a number of extensions to the original multiple kernel learning framework, together with experimental results that support their utility on benchmark data sets from the UCI Machine Learning Repository as well as several image image recognition and bioinformatics data sets.This thesis introduces a regularized multiple kernel learning framework and proposes to use the response surface methodology to search for the best regularization parameter set using validation data. Optimizing such regularization parameters allows us to obtain more robust decision functions for the classification task at hand. Kernels that do not help increase the classification accuracy are pruned by selecting their regularization parameters accordingly, obtaining smoother discriminants. Eliminating some of the kernels directly or decreasing the number of stored support vectors reduces the testing time for new instances.This thesis also proposes a cost-conscious strategy to include the cost of kernel computations and data acquisition/generation into the multiple kernel learning framework. The results show that incorporating a cost factor into the model enables us to use only the necessary kernels, avoiding costly kernel computations and input generation for some data representations in the testing phase, when possible.The main contribution of this thesis is formulation of a localized multiple kernel learning framework that is composed of a kernel-based learning algorithm and a gating model to assign data-dependent weights to kernel functions. We derive the learning algorithm for three different gating models and apply localized multiple kernel learning to binary classification, regression, multiclass classification, and one-class classification problems. For classification problems that use different feature representations, our proposed method is able to construct better classifiers by combining the kernels on these representations locally. This localized formulation achieves higher average test accuracies and stores fewer support vectors compared to the canonical multiple kernel combination with global weights. We also see that, as expected, combining heterogeneous feature representations is more advantageous than combining multiple copies of the same representation. For image recognition problems, our proposed method identifies the relevant parts of each input image separately by using the gating model as a saliency detector on the kernels calculated on the image patches. Different from the multiple kernel learning methods proper, our proposed method can combine multiple copies of the same kernel. We show that even if we provide more kernels than needed, our proposed approach uses only as many support vectors as required and does not overfit.We also introduce a supervised and localized dimensionality reduction method that trains local projection kernels coupled with a kernel-based learning algorithm. On visualization tasks, our proposed method is able to maintain the multimodality of a class by placing clusters of the same class on the same side of the hyperplane while preserving a separation between them. On classification tasks, it achieves better results than other methods by attaining both higher test accuracy and storing fewer support vectors due to the coupled optimization of the discriminant and the local projection matrices used in dimensionality reduction."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bazen Beyin Makina Arayüzü (BMI) olarak da anılan bir Beyin Bilgisayar Arayüzü(BCI), beyin ile genelde bilgisayar olmak üzere harici bir cihaz arasındaki bir haberleşmearacıdır. BCI sistemlerinin amacı; Beynin sentetik cihazları, imleçleri ya da robot kollarınıkontrol etmesiyle insanların motor-algılama fonksiyonlarını onarmak veya desteklemektir.Beyinden bu sekilde bilgi çıkarabilmek için öncelikle bilginin fiziksel kaynağıseçilmelidir. Bu uygulamanın potansiyel bilgi kaynakları Elektroensefalogram (EEG),Magnetoensefalogram (MEG) ve Fonksiyonel Manyetik Rezonans Görüntüleme (fMRI) olabilir.Bu tezde, iki kanallı EEG tabanlı bir beyin bilgisayar arayüzünün hem enstrümantasyondonanımı hem de yazılımı tasarlanmıstır. EEG tabanlı BCI sistemleri genelde olay ilişkili yada spontane EEG aktivitesi içerisindeki belirli örüntü ya da özelliklerin analizi vesınıflandırılması ile gerçeklenir. EEG içerisindeki komponentlerin incelenmesi sonucutasarlanan sistemin bilgi kaynağı olarak hareket hayaline bağlı olan mu ve beta ritimleriseçilmiştir.Sol ve Sağ el hareket ettirme hayalini ayırabilmek için bu metodlar kullanılarak üç ayrıözellik çıkarma yöntemi geliştirildi: Ayrık dalgacık dönüşümü, Güç spektrumu dönüşümüve Mu ve Beta ritimleri için bant geçiren FIR filtre. Bu özellikler sınıflandırmaamacıyla iki katmanlı bir geriyayılım yapay sinir ağına girdi olarak kullanılmışlardır.Geliştirilen sistem 2. BCI yarışmasına ait veriler ile eğitilmiş ve simüle edilmiştir. Sonuçlarınışında TI MSP430 mikrokontrolörü ile FIR filtreler veyapay sinir ağı kullanılarak düşük güçlü bir sistem gerçeklenmiştir.","A Brain Computer Interface (BCI), sometimes called a Brain Machine Interface (BMI)is a communication device between the brain and an external device, usually a computer. Themain purpose of BCI systems is repairing or assisting human motor-sensory functions byasking the brain to control synthetic devices, computer cursors or robot arms. In order toextract information from the brain,physical source of information must be selected first. Electroencephalography (EEG),Magnetoencephalography (MEG) and FunctionalMagnetic Resonance Imaging (fMRI) could be the sources of information.In this thesis, both acquisition hardware and software of a two channel EEG based brain computerinterface was designed. EEG based BCI systems are usually implemented by analysis andclassification of specific features or patterns in the spontaneous or event related EEG activity.After investigation of the components in EEG, motor imagery related mu and beta rhythmswere selected for the information sources of the system.In order to discriminate left and right hand movement imagery, three different feature extractionmethods were developed using: Discrete wavelet transform, power spectrum transform and bandpass FIR filters for Mu and Beta rhythms. These features were used as inputs to a two layer feedforward back propagation neural network for classification. Designed system was trained and simulatedwith the data provided in BCI Competition II. With the direction of the results, a low power systemwith the TI MSP430 microcontroller using FIR filters and a neural network was implemented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsanlar hayatları boyunca kendilerine uygun bir eş ararlar. İnternetin hayatımızda daha çok yer edinmesiyle birlikte, geleneksel eş bulma yöntemleri daha az tercih edilmeye başlandı. Artık internetten eş aramak daha popüler hale geldi.Elimizde toplam üye sayısı 4 milyondan fazla olan ve Türkiye'de faaliyet gösteren bir arkadaşlık sitesinin verileri mevcuttur. Bu çalışmamızda eş bulma kriterleri açısından kadınlar ile erkekler arasındaki farklılıkları araştırdık. Ayrıca bazı özelliklerin daha baskın olup olmadığını inceledik. Hangi özelliklerin birbirleriyle alakalı olduğunu gösterdik. Yaptığımız çalışmalara göre eğitim düzeyi ve aylık gelir arasında pozitif bir ilişki bulunmaktadır.Bazı erkekler, beğendikleri kadını etkileyebilmek için daha çok emek harcarlar. Bu ısrarların, kadınların ilgisini çekebilme üzerindeki etkisini inceledik. Güzelliğin hem kadınlar hem de erkekler için ne kadar önemli olduğunu gösterdik. Yaptığımız çalışmanın sonucuna göre, çekici bir erkek daha kolay eş bulabiliyor.Kullanıcıların arkadaşlık sitesini kullandıkları saat dilimlerini cinsiyetlerine, eğitim seviyelerine ve aylık gelirlerine göre kıyasladık. Daha düşük eğitim seviyeli ve aylık kazancı daha az olan erkeklerin sisteme daha çok akşam 8'den sonra girdiklerini analiz ettik. Fiziksel mesafenin de eş ararken önemli bir kriter olduğunu gösterdik. Erkekler kendilerine daha yakın oturan kadınları tercih ediyorlar.","People seek their love partner throughout their lives.As the internet grows rapidly, the traditional mate finding ways start to change.The new trend of finding a mate is to join the online dating services.We work on the dataset of an online dating system in Turkey which has more than 4 million registered users.We investigate the asymmetries of men and women in selecting partner.We find out that some criteria are more crucial.The correlation between some properties are also studied.It is found that educational level and salaries are highly correlated.Some men do not give up until he gets a message from the woman who impressed him up.We investigate whether the insisting is effective to get attention of women.We also investigate the effect of beauty for both men and women.If a man is handsome, not surprisingly, finding a mate is easier.It is found that login times according to the gender, educational level and salary are asymmetric.Men with lower educational level or lower salary prefer to login to the system after 8 pm.The physical distance is also an important factor when selecting partner.We showed that men prefer women who lives nearby."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gömülü sistemlerin diğer sistemlerle etkileşme ihtiyacının sürekli artmasıyla beraber gömülü sisteme ait modelin etkileşilen diğer sistemleri içine alacak şekilde genişlemesi ihtiyacı da artmaktadır. Bu tüm modelin doğruluğunu azaltır ve modelleme eforunu arttırır. Genel model doğruluğunu azaltmadan tasarım eforunu düşürecek yeni tekniklerin geliştirilmesi gerekmektedir.Öte yandan, karmaşıklık ve piyasaya sürme süresi kısıtları; sistemlerin erken benzetim, doğrulama ve mimari keşifini gerektirmektedir. Dolayısıyla, bu tezde SystemC'nin modelleme ortamı olarak kullanıldığı gömülü sistemlerin donanım/yazılım ortak geliştirme alanında, döngü içinde donanım tekniğinin uygulanmasını sağlayacak yeni tasarım anlayışı ve metotlar önerilmiştir. Bunun için, öncelikle, gerçek ve sanal (modellenmiş) altsistemlerin arasındaki iletişimi açık bir şekilde tanımlayabilmek üzere melez kanal kavramı geliştirilmiştir. Gerçekten sanala iletişimde harici olayları SystemC benzetimine dahil edebilmek üzere özgün yöntemler öne sürülmüştür. Ek olarak, sanal altsistemlerden gerçek altsistemlere eşzamanlı çıktıların gerçeğe mümkün olan en yakın şekilde üretilmesi için bir yöntem önerilmiştir. Ayrıca, sıkı gerçek zamanlı çalışma için SystemC çekirdeği yamalanmıştır ve genel sistem gecikmesi için bir üst sınırı garantilemek üzere üzerinde çalışılan işletim sistemi iyileştirilmiştir. Ek olarak verili bir modelin çalışma başarımını tahmin etmek üzere bir matematiksel model geliştirilmiştir. Önerilen metotlar kümesinin başarımı bir dizi endüstriyel gömülü sistem üzerinde denenmiştir. 10 KHz kararlı çalışma frekansı ve Ethernet üzerinde bir mi-lisaniyenin altındaki gidiş-dönüş süresinde bir Giriş/Çıkış başarımı sağlamıştır. Ayrıca yöntemin başarımını bir gerçek hayat ortamında gözlemek üzere yapılan deneyde, gerçek aygıtlarla etkileşen bir BACnet Broadcast Yönetim Aygıtı'nın (BBMD) zamanlamasız işlem-seviyesi modeli, rakip gerçek sistemi azami yanıt süresinde 80 kata dek geçmiştir.","As the demand for interaction of embedded systems with other systems is constantly increasing, the need to extend the model of the embedded system to include the other systems that are being interacted with is increasing, too. This results in degraded accuracy of the whole model and increased modeling effort. New modeling techniques have to be developed to reduce design effort without decreasing overall system accuracy.On the other hand, complexity and time-to-market constraints demand early simulation, verification, and architectural exploration of systems. Hence, in this dissertation, a new design concept and new methods have been proposed to apply the hardware-in-the loop technique to the field of hardware/software co-design of industrial embedded systems using SystemC as the modeling environment. First of all, the hybrid channel has been conceptualized to clearly define the communication between real and virtual (modeled) subsystems. For real to virtual communication, novel methods have been developed for incorporating external events to the SystemC simulation. Additionally, a method has also been proposed for generating concurrent outputs from virtual to real subsystems as timely as possible. SystemC kernel has been patched for hard real-time execution and the underlying operating system has been ameliorated to guarantee an upper bound for the overall system latency. Furthermore, a mathematical model has been set up to estimate the execution performance of a given model. The performance of the proposed set of methods has been experimented on some industrial embedded systems. A stable operating frequency of 10 KHz and an I/O performance of sub-millisecond round-trip time over Ethernet have been observed. In an experiment to observe the method's performance in a real-life environment, a non-timed transaction-level model of a BACnet Broadcast Management Device (BBMD) interacting with real devices outperformed a competing real system up to 80 times in maximum response time."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Araştırmacılar yazılım ürünlerinin kusura yatkınlığını tahmin etmek için zeki uzman sistemler yapmaktalar. Bu modeller ürün ve süreçle ilgili özellikleri girdi olarak kullanır ve onların zekaları kullandıkları makine öğrenme algoritmalarından gelir. Geçen yıllarda araştırmacılar algoritmaların performanslarını iyileştirmek için emek harcamaya değmeyeceği bir tavana ulaştığını ve bu tavan etkisini bertaraf etmek için girdinin bilgi içeriğinin başka türde ölçütleri içerecek şekilde zenginleştirilmesi gerektiğini vurgulamaktalar. Bir ölçüt seti insanla ilgili ölçütlerdir. İnsanlar yazılım geliştirme sürecinin en önemli bileşenleridir. Onların birbiriyle nasıl etkileşime girdiğini ve bu etkileşimlerin son ürünün kalitesini kusur bakımından nasıl etklediğini anlamak kritiktir. Biz bu araştırmada kusur tahminlerinde sosyal ağ ölçütleri olarak da bilinen yeni bir ölçüt seti eklemeyi öneriyoruz. Bu işlem iki aşamadan oluşmaktadır. İlk önce yazılım geliştirme sürecindeki herhangi bir periyodda iletişim ağı yapısı ve düzeltilen kusur miktarı arasındaki ilişkiyi gözlemledik. Bu gözlemde kayda değer bir ilişki bulmada başarısız olduk. Bundan sonra sosyal ağ ölçütlerini kullanarak dosya seviyesinde kusur tahmini uyguladık. önerdiğimiz modelin sonuçları gösterdi ki kod geçmişi ölçütleri gibi diğer ölçüt grupları ile karşılaştırıldığında sorun depoları üzerinde sosyal ağ ölçütleri ya kusur bulma oranlarına gölge düşürmeden kayda değer şekilde yanlış alarm oranını azaltıyor ya da yanlış alarm oranını değiştirmeden düşük kusur bulma oranlarını kayda değer şekilde yükseltiyor. Bundan dolayı, biz pratisyenlere insanla ilgili bilgiler herhangi bir takımdaki geçmiş düzenlerin güçlü bir göstergesi olduğu için, sorun depolarında sosyal ağ ölçütlerini toplamayı öneriyoruz.","Researchers have been building intelligent oracles to predict defect proneness of software products. These models use product and process related attributes as their input and their intelligence come from the machine learning algorithms they employ. In recent years researchers emphasize that the algorithms reached a ceiling that it is not worth the effort in working to increase their performance and information content of input data should be enriched to include different kinds of metrics to eliminate this ceiling effect. One set of metrics is people related metrics. People are the most primary elements of software development process. It is critical to understand how they interact with each other and how these interactions affect the quality of the end product in terms of defects. In this research we propose to include a new set of metrics, a.k.a. social network metrics on issue repositories in predicting defects. This process consisted of two different stages. First of all we observed relation between communication network structure and number of defects fixed in a time period during development of software. We were unable to find a significant relation in this observation. Then we conducted file level defect prediction using social network metrics. Results of our proposed model revealed that compared to other set of metrics such as churn metrics using social network metrics on issue repositories either considerably decreases high false alarm rates without compromising the detection rates or considerably increases low prediction rates without compromising low false alarm rates. Therefore we recommend practitioners to collect social network metrics on issue repositories since people related information is a strong indicator of past patterns in a given team."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilimsel ve tıbbi amaçlar için görüntü kalitesi, istenilen bilginin görüntüden ne derece iyi elde edilebildigi seklinde tanımlanabilir. Bu baglamda tıbbi görüntülemede amaç klinik açıdan basarılı teshis koyulmasını saglayacak görüntüye ulasmaktır. Ultrason ile görüntüleme, gerek donanımsal gerekse yazılımsal yönden, rahatsızlıklara özel yaklasımları, görüntü kalitesi ve görüntülerin hafızada saklanabilmesi açısından, son dönemde büyük ilerleme göstermistir. Günümüzde, rahatsızlıklar, bölgeye uygun, belirli bir frekans aralıgında çalısan prob seçimi ile, yada ilgili görüntülerin farklı filtrelerden geçirilerek, hasta veya dıs kaynaklı gürültü, bulanıklık ve bugunun kaldırılması suretiyle daha basarılı bir sekilde gözlenebilmektedir. Uzun dönemli takip gerektiren rahatsızlıklar, ileriki bir tarihte incelenebilmek üzere arsivlenebilmekte yada dünyanın herhangi bir yerinden internet aracalıgıyla yollanan görüntüler, uzmanların görüslerine sunulabilmektedir.Bu çalısmanın amacı, gerçek ve simule edilmis ultrason görüntülerinden faydalanarak, kayba yol açan arsivleme algoritmalarını, bahsi geçen simulasyon metodunun bu tür çalısmalar için ne derece güvenilir olabilecegini tespit etmek ve çesitli hata kaynaklarının görüntü kalitesindeki etkilerini, sıkıstırma esnasında gerçeklesen hatalarla karsılastırmaktır.Anahtar Sözcükler: Görüntü sıkıstırma, ultrason görüntü kalitesi, bilgisayar simulasyonu","Image quality, for scientific and medical purposes is defined as how well thedesired information can be extracted from the image thus the principal research goal inmedical imaging is the development of data acquisition and reconstruction proceduresthat can produce consistently good clinical images to be able to make precise andaccurate diagnoses.Parallel to other imaging modalities, ultrasound imaging made also massivebreakthroughs in the last decade in terms of its image quality and archiving modalitiesabnormalities in the body are better observed with a region specific ultrasound probe,which works within a certain frequency border and the images yielded are subjectedto certain filters to remove the noise, blur or clock that arise because of reasons suchas body fat, location of the lesion or minor malfunctions in the hardware etc. Fordiseases with long term follow-up, the images are compressed and stored, for beingable to examine later on or some images obtained in a distant part of the world aretransmitted via internet for telemedicine applications.This work intends to make an evaluation of medical images, using real and simulatedultrasound images compressed via lossy algorithms, to examine the feasibilityof a simulation procedure for assessing compression algorithms, to investigate the performanceof those and to make comparisons between the different sources of errors andthe compression errors that effect the image quality.Keywords: Image compression, ultrasound image quality, computer simulatio"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüz tanıma, iris tanıma ve parmak izi tanıma gibi birçok biyometrik sistem, kimlik tanıma ve doğrulama amacıyla yaygın bir şekilde çalışılmıştır. Deri altındaki damar ağını kullanan, damar örüntüleriyle biyometrik tanıma, yeni bir yaklaşımdır. Eldeki bu örüntülerin kişiye özgü olduğu ve büyüklükleri haricinde değişmediği sanılmaktadır. Damarlar deri altında gözlemlendikleri ve zengin ayırtedici özelliklere sahip olduklarından, bir kimliği kopyalama girişimi son derece zordur. Teklik, değişmezlik ve taklit edilemezlik gibi özelliklerinden dolayı damar örüntüleri güvenilir ve inandırıcı bir biyometrik tanıma adayıdır. Bu tezde, el damar örüntülerinin istatistiksel işlenmesine dayalı bir biyometri tekniği sunulmuştur. El damar veritabanı, kullanıcıların çanta taşıma, elastik bir topu sıkma, eli buz ile soğutma gibi damar örüntülerini değişmeye zorlayan işlemlere tabi tutulduğu gerçekçi koşullar altında toplanmıştır. Tanıma için şekil bilgisi ve görünüme dayalı yöntemlerin karışımı kullanılmıştır ve veritabanı üzerinde umut vaad edici sonuçar elde edilmiştir.","Many biometric systems, such as face, fingerprint and iris have been studied extensively for personal verification and identification purposes. Biometric identification with vein patterns is a more recent approach that uses the vast network of blood vessels underneath a person's skin. These patterns in the hands are assumed to be unique to each individual and they do not change over time except in size.As veins are under the skin and have a wealth of differentiating features, an attempt to copy an identity is extremely difficult. These properties of uniqueness, stability and strong immunity to forgery of the vein patterns make it a potentially good biometric trait which offers greater security and reliable features for personal identification. In this thesis, we present a novel hand vein database and a biometric technique based on the statistical processing of the hand vein patterns. The hand vein database has been collected under realistic conditions in that subjects had to undergo the procedures of holding a bag, pressing an elastic ball and cooling with ice, all exercises that force changes in the vein patterns. The applied recognition techniques are a combination of geometric and appearance-based techniques and good identification performances have been obtained on the database."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz ağlar için geliştirilen teknolojilerin özellikleri değişiklik gösterse de, hepsi kablosuz iletişim temellidir ve hepsi aynı frekans spektrumunu kullanırlar. Frekans spektrumu, tüm bu teknolojiler arasında düzgün, adil ve etkin bir biçimde paylaştırılmalıdır. Her bir teknolojiye ait donanım, veri aktarımı için aynı ortamı kullandıkları için, birbirleri üzerinde girişim yaratmaktadırlar. Dolayısıyla, spektrum yönetiminin vazgeçilmez bir bileşeni güç yönetimi olmalıdır. Ayrıca zaman içinde yapılan ölçüm çalışmalarıyla, spektrum kullanımının hiç etkin olmadığı görülmüştür.Bu araştırmada, bu sorunlara çözüm bulmayı hedeflenerek, bilişsel ağlar için farklı mimariler önerilmiştir. Araştırmanın ana amacı, spektrum ticareti pazarında, her tip kullanıcının hem bant genişliği, hem de kalite seviyesiyle ilgili beklentilerini karşılayabilecek bir altyapı ortaya koymaktır. Ayrıca, birim spektrum fiyatlarının belirlenmesi de, bilişsel ağlar için önemli bir problemdir. Ağda iletişim yapan her bir yeni kullanıcı, diğer kullanıcılar üzerinde girişim yaratmaktadır. Yarattığı girişim, kullandığı güç seviyesiyle doğru orantılıdır. Dolayısıyla, bilişsel ağlarda güç yayılımının kontrolünü sağlamak, servis sağlayıcıların en önemli amaçlarından biri olmalıdır. Modellenilen bilişsel ağda, birden fazla Birincil Servis Sağlayıcı (BSS) olduğu varsayılmıştır. Birçok pazarda, özellikle telekomünikasyon pazarında, müşteriler gittikçe daha talepkâr bir hale gelmektedirler. Bununla birlikte, rekabetin sürekli artması, kullanıcılara servis sağlayıcılarını her an değiştirebilme özgürlüğü vermiştir. Verilen problemde birden fazla satıcı olduğundan ve her bir satıcının kendi kârını ençoklamak istemesinden dolayı, klasik eniyileme yöntemleri yetersiz kalmaktadır. Bu yüzden önerilen fiyat belirleme modelleri, oyun teorisi temellerine dayandırılarak, işbirliksiz bir oyun biçiminde çözülmüştür.","The underutilization of spectrum coupled with developments in network technologies has prompted a number of proposals for managing spectrum. Dynamic spectrum access radio technology, which is based on cognitive radio technology, promises to increase spectrum sharing and thus overcome the lack of available spectrum for new communication services. It allows unlicensed secondary systems to share the spectrum with the licensed systems. In this dissertation, different architectures are investigated in a cognitive radio environment. The considered network is assumed to consist of multiple primary service providers which have some unutilized bandwidth, and multiple secondary users that require bandwidth. Secondary users are assumed to pay the primary service providers for short term usage of their available spectrum bands; which is referred as the spectrum trading. The proposed architectures all aim at establishing a framework where each type of users satisfies with the services. As each new entrant secondary user creates interference on the incumbent users, controlling the power emission in a cognitive radio network is crucial in spectrum trading. Furthermore, proposed architectures examine the unit spectrum prices that primary service providers set in the multiple-seller and multiple-buyer environment.Modeling the competitive relationships among network elements as games ensures analyzing all elements? behaviors and actions in a formalized way. The existence of various network elements that want to maximize its own profits makes the problem very complex, with usually conflicting objective functions. Therefore, the proposed pricing models have their basis on the game theory in order to deal with the severe competition in spectrum trading markets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telsiz algılayıcı ağlar, algılama ve işbirliği içerisinde bilgi paylaşımı işlemlerini gerçekleştirebilen küçük algılayıcı düğümlerden oluşur. Hedef takip etmek de dahil olmak üzere telsiz algılayıcı ağların kullanılabildiği geniş bir uygulama alanı vardır.Hedef takibi, bir hedefe ait ölçümler yapılarak ve bunlar kullanılarak hede ? n bir sonraki durumunun tahmin edilmesi sürecidir. Telsiz algılayıcı ağlarda hedef takibi, enerji korunması ve takip kalitesi arasında iyi bir dengede çalışabilecek enerji etkin modelleri içerir.Bu çalışma kapsamında hedef takibinin en önemli parçalarından biri olan yer belirleme yöntemlerini inceledik. Motivasyonumuz, daha iyi hedef takip kalitesini ve yer belirleme doğruluğunu aynı ya da daha az enerji harcayarak başarmaktır.Dağıtık hedef takibi için kullanılacak iki yeni yer belirleme algoritması önerdik. Bu algoritmalar var olan yapıya kolayca uygulanabilir. Sistem başarım değerlendirmesinde kullanılan benzetim yöntemleri, önerilen algoritmaların var olan yer belirleme yöntemlerinden belirli durumlarda daha iyi olduğunu göstermektedir.","A wireless sensor network (WSN) is a group of tiny wireless sensor nodes which perform sensing and sharing this information in collaboration. WSNs have a wide application area including target tracking.Target tracking is the process of estimating a target?s state with the measurements obtained from the target. Target tracking with WSNs involves the design of energy efficient models that can work with a good trade-off between the energy conservation and the tracking quality.In this thesis, we focused on the localization methods, which are one of the key parts in the target tracking process. Our motivation has been to provide better target tracking quality and localization accuracy while consuming similar or less energy.Two new localization algorithms are proposed for an existing distributed collaborative target tracking framework. Our algorithms are easily applicable to this framework. We used simulations to evaluate the performance of these algorithms. The performance results shows that our algorithms perform better than existing localization methods under some conditions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kaynak ayrıştırma veya gürültü temizleme gibi ses işleme problemlerinde ses sinyallerinin fiziksel özelliklerini yansıtabilecek modellere ihtiyaç vardır. Bayesçi yaklaşımda, bu, gerçekçi önsel dağılımlar tanımlamayarak gerçekleştirilebilir. Biz, bu tezde, ses sinyallerinin zaman-frekans bölgesi gösterimlerindeki yerel ilintileri içerecek iki model geliştirdik: Gamma Markov zincirleri (GMZ) ve Gamma Markov rasgele alanları (GMRA). Önerdiğimiz ses modellerinde, zaman-frekans katsayılarının değişintileri bu yapılar kullanılarak birbirlerine bağlı olarak modellenirken, katsayılar bu değişintilere koşullu olarak, bağımsız Gauss dağılımlarından gelmektedir. GMZ ve GMRA modellerinin kullanım alanı, ses kaynaklarının değişintilerinin modellenmesiyle sınırlı değildir. Değişkenler arasında bağımlılık olan herhangi bir problemde, mesela Poisson serilerinde, de kullanılabilirler. Bunu göstermek için, negatif olmayan matris ayrıştırma (NOMA) kullanarak tek kanaldan kaynak ayrıştırma probleminde, frekans şablonları ve uyarma vektörlerindeki bağımlılığı modellemek için GMZ'leri kullandık.GMZ'ler ile değişinti değişkenlerinin sadece zaman ya da frekans ekseni boyunca olan bağımlılıklarını modelleyebiliriz. GMRA'lar ise değişkenlerin tüm komşularına bağımlı olduğu düzgelenmemiş bir dağılım tanımladıkları için iki yöndeki bağımlılıkları da içerebilir. İki model de değişinti değişkenleri arasında pozitif ilinti olacak şekilde tanımlanmıştır. Böylece, sinyalin enerjisi hem zaman hem de frekans ekseni boyunca yavaşça değişmektedir. Değişkenler arasındaki ilintinin büyüklüğü ise modelin hiper parametreleri ile belirlenmektedir.Bu tezde, GMZ ve GMRA temelli ses modellerimizi gürültü temizleme ve tek kanaldan kaynak ayrıştırma problemlerinde kullandık. Ayrıca bir öğrenme kümesine ihtiyaç duymadan, sadece gözlemlenen sinyalin varlığında, kestirim ve eniyileme içiçe gerçekleştirilerek tonal ve vurmalı ses kaynakları birbirlerinden ayrılmaktadır. Bu iki modelle, hem gürültü temizleme, hem de kaynak ayrıştırma problemlerinde başarılı sonuçlar elde ettik. GMRA'lara dayalı olan modelle geri çatılan sinyaller hem biraz daha başarılı, hem de daha doğaldır.Önerdiğimiz üçüncü bir modelle de Gamma ve GMZ önsel dağılımları kullanarak, NOMA ile tek kanaldan kaynak ayrıştırma yaptık. Burada da hiper parametreler kestirim sırasında eniyilenmekte ve kullanıcının hemen hemen hiçbir kritik karar vermesine gerek kalmamaktadır. Bu modelle elde edilen sonuçlar önceki iki modelle elde edilenlerden daha başarılıdır. Ayrıca, bu modelde kestirim ve eniyileme daha hızlı bir şekilde yapılabilmektedir. Buna rağmen, bu model sadece kaynak ayrıştırma problemi için önerildiğinden, önceki iki model gibi genel uygulanabilirliği yoktur.","In many audio processing tasks, such as source separation, denoising or compression, it is crucial to construct realistic and flexible modelsto capture the physical properties of audio signals. This can be accomplished in the Bayesian framework through the use of appropriate prior distributions. In this thesis, we describe two prior models, Gamma Markov chains (GMCs) and Gamma Markov random fields (GMRFs) to model the sparsity and the local dependency of the energies of time-frequency expansion coefficients. We build two audio models where the variances of source coefficients are modelled with GMCs and GMRFs, and the source coefficients are Gaussian conditioned on the variances. The application area of these models are not limited to variance modelling of audio sources. They can be used in other problems where there is dependency between variables, such as the Poisson observation models. In single-channel source separation using non-negative matrix factorisation (NMF), we make use of GMCs to model the dependencies in frequency templates and excitation vectors.A GMC model defines a prior distribution for the variance variables such that they are correlated along the time or frequency axis, while a GMRF model describes a non-normalised joint distribution in which each variance variable is dependent on all the adjoining variance variables. In our audio models, the actual source coefficients are independent conditional on the variances and distributed as zero-mean Gaussians. Our construction ensures a positive coupling between the variance variables, so that signal energy changes smoothly over both axes to capture the temporal and/or spectral continuity. The coupling strength is controlled by a set of hyperparameters.We tested our audio models that are based on GMC and GMRF models in denoising and single-channel source separation problems where all the hyperparameters are jointly estimated given only audio data. Both models provided promising results, but the reconstructed signals by the GMRF model were slightly better and more natural sounding.Our third model makes use of Gamma and GMC prior distributions in an NMF setting for single-channel source separation. The hyperparameters are again optimised during the inference phase and the model needs almost no other design decisions. This model performs substantially better than the previous two models. In addition, it is less demanding in terms of computational power. However, it is designed only for source separation, i.e., it is not a general audio model as the previous two models."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Akıllı radyo kablosuz iletişim teknolojilerinde yeni bir açılıma öncülük etmektedir. Akıllı radyo ağları doğası gereği sonsuz öncelikli düzenceye sahiptir. Bu nedenle her kaynağın hücre bazlı olarak takip edilmesi zorunludur. Bu tezde altyapı destekli akıllı radyo mimarisi için analitik model önerilmiş ve bu modelin tektürel ve çoktürel trafik senaryoları altında, çok hücreli ortamda performansı incelenmiştir. Performans ölçütleri olarak, birincil ve ikincil kullanıcılar için bloke olma ve bağlantı kopması olasılıkları, ikincil kullanıcılar için ayrıca zorunlu sonlandırma ve zorunlu frekans değiştirme olasılıkları incelenmiştir. Analitik model simulasyonlarla doğrulanmıştır. Analitik modele ek olarak çoktürel trafiğin etkilerini telafi etmek için yeni bir kapasite planlama yöntemi önerilmiştir. Önerilen yöntem sunulan trafik, ağır yüklü hücreye hoplama uzaklığı ve hareketli kullanıcıların hızını dikkate alarak atama yaparak bloke olma, bağlantı kopması ve zorunlu sonlandırma ölçütlerinde daha iyi sonuçlar elde etmektedir.","Cognitive radio heralds the next step in the evolution of wireless communications. Cognitive radio networks are inherently priority based and preemptive. Hence, keeping track of each resource in each cell is mandatory. In this thesis, an analytical model for infrastructure based cognitive radio systems is proposed, and its performance is evaluated under even and uneven traffic scenarios in a multiple cell environment. Performance metrics like probabilities of dropping and blocking for primary and secondary users as well as forced termination and forced frequency handoff for secondary users are investigated, and the analytical model is verified with simulations. In addition to the analytical model, a new capacity assignment method is proposed to compensate for uneven traffic load distribution. The proposed method considers offered traffic, hop count to the heavily loaded cell, and velocity of mobile users during capacity assignment and performs better in terms of probability of blocking, dropping, and forced termination."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Video algılayıcı ağlar geleneksel algılayıcı ağlar ile oluşturulmuş uygulamaların başarımlarını iyileştirmek ve yeni uygulama alanları yaratmak için geliştirilmiştir. Örnek olarak, bir gözetim uygulamasının güvenilirliliği olaylardan elde edilen video aktarımlarıyla önemli ölçüde artırılır. Ses ve manyetik alan ölçer gibi geleneksel algılayıcılar kullanarak yapılan hedef sezme yerine, gözetim alanından elde edilen bir imge daha detaylı inceleme yapabilmemizi sağlar. Fakat, bir video algılayıcı ağ oluşturmak için sadece düğümler üzerine takılan bir kamera yeterli olmayabilir. Bu tezde, varolan algılayıcı ağ mimarilerinde, gözetim uygulamaları için tasarlanmış benzetimlerle başarım testleri yaparak, eksiklikler açığa çıkarılmıştır. Başarım testleri sonucunda da OSI yığıtındaki birden çok katmanda iyileştirmelerin yapılması gerektiği ortaya çıkmıştır. Bu nedenle, ilk olarak algılayıcı ağlardaki ortam erişim kontrol protokollerinde büyük veri parçalarını ve video gibi veri akışlarını iletmede kullanılan parçalara ayırma yöntemleri incelenmiştir. Uygun parçalama desteğiyle uygulama başarısının, düşürülmüş gecikme ve artırılmış çerçeve hızı bakımından iyileştiği gözlemlenmiştir. İyileşmenin nedeni de kontrol amacıyla yapılan ek yüklerin azalması ve uyarlamalı uyuyup uyanma çevrimleri olarak tespit edilmiştir.Ek olarak, olay tabanlı uygulamalarda adil kuyruklama konusu incelenmiştir. Olay raporlama gecikmesini (ortalama tepki zamanı) azaltmak ve genel görsel bilgiyi artırmak amacıyla, en az alınan servis çizelgelemesine dayanan bir adil kuyruklama yöntemi önerilmiştir. Yöntemin etkisini gözlemlemek için benzetimlerde gerçekçi gözetim senaryoları kullanılmıştır. Sonuçlar raporlanma zamanının düşürüldüğünü ve her olaydan alınan en az çerçeve sayısının artırıldığını göstermiştir. Video trafiğinin yüksek bant genişliği isteklerini karşılayabilmek için çokyollu yönlendirme yordamları kullanılmıştır. Başarım kazanımları gösterilse bile, çerçeveleri farklı yollardan giden olaylar arası adalet konusu halen bir sorundur. Bu yüzden, en az alınan servis yöntemi dağıtık olarak olay akışlarına uygulanmıştır. Ek olarak, sınıflandırılmış çekişme penceresi boylarının, düğümler arası olay adaleti üzerindeki etkileri araştırılmıştır.","Video Sensor Networks are developed with the aim of advancing the applicationperformance of the traditional sensor networks and creating new applications. For instance,the reliability of surveillance applications is significantly improved with videostreams captured from the events. Rather than detecting an intruder with traditionalscalar sensors such as audio and magnetic, an image captured from the surveillancearea offers a more detailed inspection of the event. However, for building a video sensornetwork, mounting CMOS cameras on top of the sensor nodes may not be sufficient.In this thesis, in order to clear up this matter, performance tests on the existing sensornetwork architectures are conducted by simulations designed for surveillance applications.The performance evaluations indicate that there is a need for enhancements inseveral layers of the OSI stack. Therefore, firstly, the fragmentation support of sensorMAC protocols which are designed for relaying large data units and data streams suchas video are investigated. The improved application quality is observed with properfragmentation support in terms of reduced latency and increased frame rates. Thereason behind the improvements are discovered as the decreased control overhead andthe adaptive duty cycle mechanisms.Additionally, the fairness issue in the event based applications are investigated. Inorder to decrease the event reporting latency (mean response time) and to maximizethe overall visual information, a fair queueing method based on the least attainedservice scheduling is proposed. Realistic surveillance scenarios are implemented inthe simulations to observe the effect of the method. The results indicate that thereporting delay is decreased and the minimum number of frames received from eachevent is increased.In order to handle high bandwidth demands of video traffic, multi-path algorithmsare deployed. Although the performance gains are reported, fairness among the eventswhose frames follow different paths is still an issue. Therefore, we apply the leastattained service method in a distributed manner to the events flows. Additionally, theeffect of differentiated contention window sizes on the inter-node fairness of the eventsis investigated."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yaşam kalitesini iyileştirmede kullanılabilecek seviyeye gelen kablosuz telsiz ağteknolojileri, bilgisayar ve sağlık uygulamaları sektörlerinde önemli bir araştırma alanıhaline gelmiştir. Ev içi yaygın sağlık sistemleri, sürekli izleme sayesinde, zengin içerikselbilgi sağlama yanında, uyarı düzenekleri ile olası sıradışı durumları tespit edebilmektedir.Bu durum, yaşlı ve hastaların bakıcılara olan bağımlılıklarını en aza indirmeninyanı sıra, ebeveynleri çalışmak durumunda olan küçük çocuklar ve bebekler için dedaha kaliteli bir bakıma olanak vermektedir. Bu tezde, çok kipli algılayıcılardan oluşanağların sağlık gözetimi uygulamalarında uygulanabilirliğini göstermek için WeCareisimli bir izleme ortamı yarattık. Bunun yanında, video algılayıcı ağların, açık alanlardakisağlık gözetimi uygulamalarında kullanılabilme yeterliklerini benzetim yoluylasınadık. Sonuçlar video algılayıcı ağların kabiliyetlerinin sınırlı olduğunu göstermektedir.Bu nedenle, ağda oluşturulan video çerçevelerinin sayısını azaltmak önem kazanmaktadır.Ağdaki trafik yoğunluğunu azaltarak başarımı iyileştirmek için çeşitli iyileştirmelerönerilmiştir.RFID birçok alanda kullanılan olgunlaşmış bir teknolojidir. Video algılayıcıağların RFID tarafından geliştirilmesi ağdaki trafik yoğunluğunu azaltmak için kullanılmıştır. Bununla birlikte, gözetim alanında bulunan sağlık görevlilerinin hastalarayakınlığı da video çerçeve sayısını azaltmak için kullanılan teknikler arasındadır.Son olarak, aciliyet gerektiren durumlarda üretilen video çerçevelerini hızlı ve güvenilirşekilde ulaştırmak için bir kuyruklama yöntemi önerilmiş ve başarımı benzetim yoluyladeğerlendirilmiştir.","Becoming mature enough to be used for improving the quality of life, wirelesssensor network technologies are considered as one of the key research areas in computerengineering and healthcare application industries. In-home pervasive healthcaresystems provide rich contextual information and alerting mechanisms against odd conditionswith continuous monitoring. This minimizes the need for caregivers and helpthe chronically ill and elderly to survive an independent life, besides provides qualitycare for the babies and little children whose both parents have to work. In this thesis,we designed an indoor monitoring environment, namely WeCare, and showed the applicabilityof multi-modal sensor network technologies on healthcare monitoring. Besides,we performed several simulations on the capabilities of the Video Sensor Networks forhealthcare monitoring in an outdoor setting. The results exhibit that their capabilitiesare limited. Therefore, reducing the number of the frames carried by the network isthe primary objective. For this reason, we proposed several enhancements for reducingthe traffic load on the network for better performance.RFID is a very mature technology that has already been used in many areas. TheRFID enhanced Video Sensor Networks reduces the network traffic load. Moreover,the proximity of the healthcare professionals who are also moving in the surveillanceis also used as a frame reduction mechanism. Finally, for assuring the reporting of theemergency events in low latencies, we propose a queueing mechanism and evaluated itsperformance through simulations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım geliştirme maliyetindeki payı açısından bakım maliyetleri, özellikle de modüllerin sıkı eşleştirmesine bağlı olan telekomünikasyon alanındaki gibi çoklu versiyonlu gerçek-zamanlı sistemlerde çok yüksek olabilir. Karmaşık sınıfların geliştirilmesi ile birlikte kodun okunabilirliği çok zor bir hale gelebilir, bu yüzden yeni yazılım geliştiricilerin projeye katılma süreci zorlaşır ve projenin bakımı zor bir iş haline gelir. Bu problemin üstesinden gelmenin bir yolu; sistemin hangi kısımlarının bakımının zor olduğunu ya da hangi kısımların değişime eğilimli olduğunu tahmin etmektir. Tekrar tasarım kararları; yazılım geliştiricilerin deneyimini temel alan maliyeti yüksek, manuel kod incelenmesine dayalı olarak alınır. Bu durum sistemi süreçlerden çok insanlara bağımlı kılar. Aynı zamanda manuel inceleme, proje maliyetlerini de yükseltecektir. Yöneticiler genel olarak kodun kalitesinden çok projenin zamanında ve bütçe sınırları dahilinde tamamlanmasıyla ilgilenirler. Fakat, projeyi düsük maliyetli ve son teslim zamanından önce bitirmekle birlikte aynı zamanda kodun kalitesinin ve yapısının korunması ve hatta geliştirilmesi, daha tercih edilen bir durum olacaktır.Bu araştırmada projeleri, versiyon geçmişiyle kod karmaşıklığını analiz ederek tekrar tasarlanması gereken sınıfları belirlemeyi hedeflemekteyiz. Biz, tekrar tasarlanması gereken sınıfları özelliklerine göre önceliklendiren makina öğrenme temelli bir model öneriyoruz. Bizim öngörü sonuçlarımız gösteriyor ki, belirli özelliklere ağırlıklar vermek: sınıf bazlı ortalamada %71 doğru tahmin ve %18 yanlış alarm oranlarında, performans modeli öngörüsünü oldukça geliştirmektedir. Ayrıca önerdiğimiz model, bakıma dayalı çalışmalarda; manuel kod incelemesine göre, ortalama olarak fazladan %81 verimlilik üstünlüğü sağlamaktadır.","Maintenance costs as a proportion of software development cost could be very high, especially in multi version real-time systems such as in telecommunications domain due to tight coupling of modules. The readability of the code becomes very hard with the development of complex classes, so the maintenance and the adaptation of the new developers to the project becomes a diffucult job. One way to overcome this problem is to predict what parts of the system are difficult to maintain and likely to change. Refactoring decisions are taken through a costly manual inspection of the code based on developer experience. It makes the system dependent to people rather than processes. Also, manual inspection increases the cost of the project. The managers are generally interested in projects which are completed on time and within budget rather than code quality. However, it would be preferable to make the project less costly and finish it before deadline by also preserving or enhancing the code quality and structure.In this research we aim to detect the modules that need to be refactored by analyzing the code complexity of the projects with version history. We propose a machine learning based model that prioritizes attributes to predict modules to be refactored. Our prediction results revealed that assigning weights to certain attributes considerably improves the prediction performance of the model as high as 71% of probability of detection and as low as 18% of false alarm rates on the average in class-level. Further our proposed model provides on average as high as 81% efficiency in maintenance effort, over and above the manual code inspection."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telekomünikasyon endüstrisinin hızlı bir küreselleşme sürecine girmesi ile, geniş coğrafi kapsama alanı ve çoğa gönderim kabiliyetleri gibi önemli özellikleri bulunan uydu sistemlerinin iletişim alanındaki rolü giderek artmaktadır. Yerdurağan-yörüngedeki (GEO) bireysel uyduların kullanılmasıyla başlayan uydu iletişimi, bu uyduların yerden uzaklığından kaynaklanan yayılım gecikmesi gibi nedenlerden dolayı gerçek-zamanlı ve interaktif uygulamalar için elverişli değildir. Dolayısıyla son yıllarda uydu piyasasında orta-yörünge (MEO) ve bilhassa alçak yörünge (LEO) uydu sistemlerine yönelmeler olmuştur. Yerdurağan olmayan (NGEO) bu uydu sistemlerinin düşük yayılım gecikmesi, düşük sinyal kaybı ve frekansların daha verimli kullanılabilmesi gibi avantajları vardır. Fakat bu avantajlar, bir takım zorlukları da beraberinde getirir. LEO uydularının kapsama alanlarının GEO uydularına kıyasla az olması nedeniyle, global kapsama için birbirleriyle iletişim bağları olan çok sayıda uydu gerekmektedir. Ayrıca, alçak yörünge uydularının yere göre yüksek bağıl hızları, uydu ağ topolojisinin hareketli olmasına neden olur. Uydu ağının hereketliliği, verimli yol atama ve servis kalitesini sağlamak için en önemli problemi teşkil etmektedir. Diğer taraftan, uydu ağlarının simetrik ve düzgün bir yapıya sahip olması, ağ hareketliliğinin önceden tahmin edilebilir ve periyodik olması gibi bir takım özellikleri vardır. Uydu ağları üzerinden verimli bir iletişim sağlamak için bunlar gibi bütün özelliklerin hesaba katılması gerekmektedir.Bu tezde, öncelikle uydu sistemlerini yer ağlarından ayıran temel özellikleri, bu özelliklerin doğurduğu ihtiyaçları ve getirdiği sonuçları sınıflandırarak ortaya çıkardık. Ardından, yeni yol atama ve ağ hareketliliğinin yönetim teknikleri önerdik. Birinci olarak, ağ yapısının geometrik özelliklerinden faydalanarak öncelik tabanlı uyarlamalı bir yol atama tekniği geliştirdik. İkinci olarak, ağ yapısının hareketliliğinin üstesinden gelmek için yersabit ayak izli uydu sistemlerini ele aldık. Bu sistemlerde hareketliliği yönetmek için çok bilinen bir yöntem olan sanal düğüm (VN) tekniğininin eksiklerini telafi eden çok durumlu bir sanal ağ mimarisi (MSVN) önerdik. MSVN tabanlı uydu sistemlerinde verimli el değiştirme ve ışın huzmelerinin yönlendirilmesi teknikleri geliştirerek önerilen mimarinin olası avantajlarını ortaya koyduk. Son olarak, yerdurağan olmayan uydular ile yüksek platformların (HAP) yüksek kapasiteli optik bağlar kullanarak verimli entegrasyonu problemine yöneldik. Uyduların hareketliliğini ve kaynak limitlerini göz önünde bulundurarak hangi uydular ile hangi HAP'lar arasında optik bağ kurulacağına karar verme problemine çözüm getirdik.","Satellite networks are an attractive option to provide broadband telecommunication services to globally scattered users, due to their extensive geographic coverage, high bandwidth availability, inherent broadcast capabilities, etc. Satellites rotating in geostationary orbit (GEO) are very well suited for broadcast services, but they suffer from high free space attenuation and long delays. On the contrary non-geostationary (NGEO) systems consisting of Medium Earth Orbit (MEO) and Low Earth Orbit (LEO) satellites offer smaller latency, lower free space loss, and better re-use of available ground-space communication frequencies, hence they are more suitable for most applications (especially for those running in real-time). However, these advantages come with a price: Footprints of satellites at lower altitudes are smaller, and global coverage can be provided by higher number of satellites that are connected each other with inter-satellite links (ISL). Moreover, lower orbit satellites move with higher speeds relative to the Earth?s surface, resulting in high dynamic in the network topology. Dynamics of the satellite constellation constitute major challenge in providing efficient routing and quality of service (QoS) for rapidly-growing real-time multimedia services. On the other hand, regular NGEO satellite networks has some facilitating features like periodicity, predictability and having highly symmetric and regular topology. For efficient networking in NGEO satellite networks, all these features should be considered.In this thesis, we clarify features of satellite systems that differ them from their terrestrial counterparts and propose novel routing and network mobility management techniques in NGEO satellite networks. Firstly, we make use of geometrical properties of the network topology, and propose a priority-based adaptive routing (PAR) algorithm. Next, we focus on handling the mobility of network by utilizing satellites with Earth-fixed footprints, and extend a well-known mobility handling technique called Virtual Node (VN). We propose Multi-state Virtual Network (MSVN) topology that alleviates deficiencies of VN concept. We clarify potential advantages of MSVN by developing efficient handover mechanisms and beam management techniques in MSVN-based satellite systems. Finally, we investigate efficient integration of NGEO satellites with High Altitude Platforms (HAPs) via high-capacity free-space optical links for carrying dense and real-time multimedia traffic. Considering the mobility and resource limitations of satellites, we propose an efficient solution for the optimal link establishment problem between HAPs and satellites."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kredi risk analizi, finansal alanda ilgi duyulan problemlerden biridir ve müsteriyekredi verildiğinde olusacak riski tahmin etmeyi hedefler. Risk tahmini hem müsteridavranısına, hem de ekonomik duruma bağlıdır. Buradaki zorluk, kredi uzmanlarınınmüsterilerden hangi verileri toplaması gerektiği, hangi kosullarda müsterilerin iyi olaraksınıflandırıldığı ve müsteriye kredi verildiğinde ne kadar risk alındığının tahminedilmesidir. Bu nedenle, kredi uzmanları ilgili kararları verirken müsteri tipine özel riskanaliz modüllerine ihtiyaç duyarlar.Bu tezde, gerçek Küçük ve Orta Boylu ?sletmeler (KOBI) için, kademeli çok tabakalıyapay sinir ağı-sinirsel kural çıkarıcı ve lojistik regresyon modeli sunuyoruz. Önhazırlıkasamasında, KOBI veritabanının öznitelikleri; karar ağacı, özyinelemeli öznitelik çıkarıcı,faktör analizi ve temel bilesen analizi ile seçiliyor. En iyi öznitelik kümesi özyinelemeliöznitelik çıkarıcı ile elde ediliyor. Ilk modülde, sınıflama metodu çok tabakalı yapay sinirağı, k-yakin komsu ve destek vektör makinesi arasından seçilmistir. Optimal sınıflayıcıolarak çok tabakalı yapay sinir ağı elde edilmis ve takip eden modüller bunun üzerinekurulmustur. Ikinci modülde, sınıflandırma amacıyla çok tabakalı yapay sinir ağını sinirselkural çıkarıcı takip etmektedir. Sinirsel Kural Çıkarıcı, müsteriler için ?iyi? kararının nasılverildiğini ortaya çıkarır. Temerrüt olasılığının tahmin edilmesi için, üçüncü modülde,lojistik regresyon tarafından takip edilen kademeli çok tabakalı yapay sinir ağı modeliniöneriyoruz. Son modülde, skor kartı elde etmek için, çok tabakalı yapay sinir ağı-lojistikregresyon modeli kümeleme metodu tarafından takip edilmistir. Deneylerde, özel TürkKOBI veritabanı kullanılmıstır. Kademeli çok katmanlı yapay sinir ağı-lojistik regresyonmodeli yüksek doğruluk oranı sağlamaktadır ve genel olarak kullanılan klasik lojistikregresyondan daha üstündür.","Credit risk analysis is a challenging problem in financial analysis domain. It aims toestimate the risk occurred when a customer is granted. The risk estimation depends on bothcustomer behavior and economical condition. The challenge is how the credit expert willdetermine which information should be collected from applicants, under which condition acustomer will be classified as good and how much risk will be taken if the credit is grantedto the customer. Consequently, credit experts need intelligent customer-specific riskanalysis modules to support them when they make these decisions.In this thesis, we present a cascaded multilayer perceptron (MLP) rule extractor anda logistic regression (LR) model a for real-life Small and Medium Enterprises (SMEs). Inthe preprocessing phase, the features of Turkish SME database are selected by decisiontree (DT), recursive feature extraction (RFE), factor analysis (FA) and principalcomponent analysis (PCA) methods. The best feature set is obtained by RFE. In the firstmodule, the classifier is selected among MLP, k-nearest neighbor (KNN) and supportvector machine (SVM). The optimal classifier is obtained as MLP and the followingmodules are built on MLP. For classification purpose, MLP is followed by neural ruleextractor (NRE) in the second module. NRE reveals how the decision is made forcustomers as being ?good?. For the probability of default estimation (PD), we propose acascaded MLP which is followed by a LR model in the third module. MLP-LR model isfollowed by clustering method in the last module for scorecard development purpose. Inexperiments, confidential Turkish SME database is used. The cascaded MLP-LR modelprovides high accuracy rate and outperforms commonly used classical LR"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde kablosuz bağlantı teknolojileri iletişimde önemli bir yere sahiptir. Kullanıcıların daha hızlı, daha yaygın ve kesintisiz bağlantı talepleri, bu alandaki çalışmaların hızla artmasını ve ilerlemesini sağladı. Sonuç olarak, kullanıcılara hizmet vermek üzere kurulan ve kullanılan bir çok farklı altyapı ortaya çıkmıştır. Bu farklı altyapıları kullanırken, ortak desteklenen bir sistem ile kullanıcının altyapı türünden bağımsız olarak sürekli bağlı kalmasını sağlayacak bir teknoloji ihtiyacı doğmuştur. Bu sorunlara kalıcı çözüm bulmak için bir çok model geliştirildi ve hala geliştirilmektedir. Mobil IP bu modeller içinde sıyrılan ve IETF tarafından standartlaştırılıp kullanıma açılan, sektörde ve akademide kabul görmüş bir protokoldür. Mobil IP, kullanıcının aktif TCP baglantılarını baştan kurmasına gerek bırakmayacak şekilde IP tabanlı her hangi iki ağ arasında, altyapıdan bağımsız bir şekilde dolaşmasına olanak sağlar.Son kullanıcı ve servis sağlayıcı açısından kullanılabilirliğini ve esnekliğini arttırmak için Mobil IP ile AAA iletişimi entegre edilmiştir. AAA protokülün desteğiyle kimlik denetimi, ilgili anahtarların dağıtımı ve muhasebe için data toplanması mümkün olmaktadır. Fakat AAA entegre edilmiş Mobil IP'de yeni bir oturum açmak için gereken zaman, Mobil IP kayıdı öncesinde AAA mesajlaşmaları gerçekleşmesi gerekli kılındığından önemli ölçüde artmıştır.Biz bu çalışmada ilgili AAA ve Mobil IPv4 iletişimlerini paralel gerçekleştirerek yeni bir çözüm önermekteyiz. Bu önerimizde AAA ve Mobil IPv4 standartlarını bozmadan, yeni bir oturum açmak için gereken zamanı kısaltmaktayız. Bu tezde önerdiğimiz çözümün analatik olarak incelemesi sunulduktan sonra servis sağlayacaların kullanacağı alt ve üst yapıya uygun parametrelerle yaptığımız simulasyon çalışmalarının sonuçları gösterilmektedir. Önerdiğimiz çözüm, kayıt zamanı olarak daha iyi performans sergilemekte ve ölçeklenebilirlik açısından şu an kullanılan standard'a gore yakın ve daha iyi şartlar sunmaktadır.","An important part of the communication technology currently depends on the wireless networking. With the increase in the connectivity needs, many types of wireless technologies have been deployed to ensure the coverage of the living areas using short and long range networks. Due to the access needs for efficient and continuous connectivity, interoperability became a very important issue. Mobile IPv4 is a well accepted protocol, standardized by IETF for such needs. Mobile IPv4 enables a wireless node to move from one infrastructure to another without disrupting the end-to-end TCP communication. Almost all IP based wireless technologies that are already developed or under development aim Mobile IP support.Support for Authentication, Authorization and Accounting (AAA) architectures are also included in latter Mobile IP standards. IETF draft standard ?RADIUS Mobile IPv4 extensions? defines new attributes and methods to provide AAA support for Mobile IPv4. This standard defines new interactions before starting the Mobile IP registration between a mobile node and RADIUS servers. The preliminary RADIUS server interactions increase the overall time needed for Mobile IP with RADIUS registration significantly.In this thesis work, a new solution, named ?Parallel AAA and Mobile IP Registration? is proposed to decrease the communication overhead associated with preliminary RADIUS server interactions. In the proposed solution, the existence of pre-established Foreign Agent - Home Agent security associations are assumed. A simulation model of the proposed solution and the RADIUS Mobile IPv4 extension standard is developed to compare their overall registration time performance. The simulation model also provides a scalability analysis of overall registration time. It is also shown that the proposed solution performs better under various communications link and server hardware settings."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Katma değerli yeni servislerin sayısının artması ile beraber konuma dayalı servislerin önemi artmaktadır.Acil aramaların nereden yapıldığının belirli bir hata payı içinde tespit edilmesini şart koşan Uluslararası İletişim Komisyonu da konuma dayalı servisler üzerinde anahtar bir etken olmuştur. Bu nedenle konum belirleme anahtar bir araştırma sorunu olmuş ve birçok sayıda konum belirleme çözümü sunulmuştur.Bu çözümlerden bazıları hücre numarası, varış zamanı ve açısı, istatistiksel ve parmak izi yöntemleridir. Bu tez parmak izi yöntemine dayalı bir konum belirleme yöntemi öne sürmektedir.Parmak izine bağlı konum belirleme bir kullanıcının yerini bulabilmek için daha önce toplanmış sinyal ölçümlerinden yararlanır. Önceki sinyal ölçümleri sonradan sinyal izi eşleştirmede kullanılmak için bir veritabanına kaydedilir ve bu veritabanına sinyal izi veritabanı denir. Sinyal izine bağlı konumlandırma dört aşamadan oluşmaktadır, bunlar ölçüm toplama, sinyal izi filtreleme, sinyal izi eşleştirme ve konum hesaplamadır.Bu tezde konuma dayalı servislerin hassaslığını artırmak için yeni bir sinyal izi eşleştirme yöntemi önerilmektedir. Bu yeni yöntem en çok bilinen ve en çok kullanılan yöntemler ile kıyaslanmıştır ve performansı bu algoritmalar ile karşılaştırılmıştır. Önerdiğimiz yöntem hücresel ağda veya cep telefonlarında fazladan bir donanım yada yazılıma ihtiyaç duymadan çalışabilmektedir. Sistem mobil kullanıcının sinyal değerlerini ve hücresel ağ tarafından yapılan ölçümleri kullanarak kullanıcının yerini tespit edebilmektedir. Bu tezde önerilen yöntemin karşılaştırılan yöntemlerden konum hassasiyeti açısından daha iyi sonuçlar verdiği gösterilmiştir.","Location based services have attracted too much attention recently due to the increasing number of new value-added services. Also, the requirement set by Federal Communications Commission (FCC) to locate emergency calls according to certain accuracy criteria has been the key factor for the development of location methods. Hence, location positioning has been a key research problem and numerous localization solutions have been proposed. These include technologies such as Cell ID, angle and time of arrival methods, statistical methods and fingerprinting methods. This paper proposes a fingerprinting based positioning method.Location fingerprinting is a novel method that benefits from the previous signal measurements to find the location of a user. The previous signal measurements are stored into a database, called fingerprint database, to be used for fingerprint matching. Fingerprinting consists of four phases such as data collection, fingerprint filtering, fingerprint matching, and location estimation algorithms.In this thesis, a new fingerprint matching algorithm is proposed to increase the accuracy of the location based services. This new fingerprint matching algorithm is compared with the most frequently used and well-known algorithms. The proposed algorithm does not require any hardware modifications. It does not require any modifications in the software on the mobile devices, either. By exploiting the measurements that are already being performed by the cellular network, the system can estimate the location of the mobile station using the RSS values of the MS. It is shown that the proposed algorithm gives better results than the compared algorithms in terms of accuracy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnsan toplumunda becerileri bireyden bireye aktarmanın en önemli yollarından biri taklittir. Robotların sosyalle¸sip insan toplumuna katılabilmesi için, etra ? arındaki diğer insan ve robotları taklit etme yeteneğine sahip olmaları gerekmektedir.Bu çalışmada, bir insansı robotu insan kol hareketlerini taklit etmek üzere programladık. Çözmemiz gereken başlıca problemler insan kol hareketlerinin tek kamera aracılığıyla algılanması ve robotun bu hareketlere en benzer hareketleri yapabilmesi icin gerekli olan kol eklem açılarını bulabilmekti. İnsan kol hareketini algılamak için kol eklemlerine renkli belirleyiciler yerleştirdik ve bunları izledik. İnsan ve robot kolundaki ? ziksel farklar nedeniyle insan eklem açılarını birebir olarak robota aktarmak mümkün olmadığından, her iki kol icin ortak bir temsil yöntemi bulmamız gerekti. Daha sonra kollar arasındaki benzerliği bu model üzerinden karşılaştırabildik.Yaptığımız üç gerçek dünya deneylerinde robot tahtaya dikey ve yatay çizgiler ve de bir daire çizen bir göstericiyi izledi. Daha sonra robot çizgileri ve daireyi başarıyla çizdi.","A sociable robot must have the capability to imitate agents around it. In a human society, people generally teach new skills to other people by demonstration. Hence, our arti ? cial partners should be able to learn from us by watching what we do.In this thesis, we programmed a humanoid robot to imitate human arm movements. The main problems we dealt with is the perception of the human arm movement and ? nding a corresponding motor sequence that will make the robot?s movement as much the same as human?s. We placed colored markers on the arm joints of the human demonstrator for tracking the arm. The physical di ? erence between the human and the robot?s arms made it di ? cult to directly extract the necessary joint angles for the robot. Instead, we employed a shared representation of movement which is neither thejoint values of the human nor the robot. We made our comparisons on that commonmodel.We have conducted real world experiments where the robot watched a humandemonstrator drawing horizontal and vertical lines and circle on the board. The robotsuccessfully drew the lines and the circle."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde insansı robotların futbol oynayabilmeleri için kullanılmak üzere sinyal-tabanlı çok yönlü iki ayaklı yürüme algoritması önerildi. Sistemin diğer sinyallerini senkronize etmek için kullanılan periyodik bir sinyal oluşturulmaktadır. Sistemi daha net bir şekilde modelleyebilmek için sistemi dört farklı mekanizmaya böldükc ve her mekanizmayı birer sinyalle ifade ettik. Hareket sistemini modellerken, sistemi mümkün olduğunca parametrik tutmaya çalıştık. Böylece mekanizmaların karakteristik özellikleri değiştirilebilir bir hal aldı. İki ayaklı yürüme algoritmasına ek olarak Evrimsel Stratejiler yöntemi yürüme algoritmasının en düzgün parametrelerinin bulunması için kullanıldı. Yürüme modülünün amacı olan belirli bir noktaya daha kısa zamanda ulaşmak optimizasyon sürecinde kullanılacak olan iyilik fonksiyonunun kriteri olarak alındı.Bu çalışmamızın sonucunda Aldebaran Nao insansı robotları için parametrik çok-yönlü iki ayaklı yürüme algoritması elde etmenin yanında, yürüyüş parametrelerini hem benzetim hem de gerçek dünya ortamı için farklı nüfus değerleri kullanarak optimize ettik. Her ne kadar benzetim ortamında çok ciddi bir ilerleme etmiş olsak da, gerçek dünya deneylerinde sadece ince ayar yapılmış oldu. Benzetim ve gerçek dünya ortamları arasında farkların yanı sıra nüfus büyüklüğünün eğitim prosedürünü de inceledik. Kalabalık popülasyonların kullanıldığı deneyler daha ayrıntılı bir araştırma yapmaktadır ve her ne kadar ortalama iyilik değerleri çok yavaş yükselse de o ana kadar elde edilmiş en yüksek iyilik değerinde çok hızlı bir artış gözlenmektedir.","In this thesis, we proposed a signal-based omni-directional bipedal walking algorithm which will be used in humanoid robot soccer domain. We generate a central periodic signal which is used to synchronize other signals in the system. In order to model the system more clearly, we divide the main motion into four di ? erent components and each component is represented with a signal. While modeling the locomotion system, we tried keeping it as much parametric as possible. Hence, it is possible to change the characteristics of the motions. In addition to the implementation of the bipedal walking algorithm, an optimization algorithm, Evolutionary Strategies is used to ? nd the optimal parameters to the locomotion system. The aim of the system constitutes the ? tness function of the optimization algorithm: reach the destination point as quick as possible.As a result of this work, we could achieve a parametric omni-directional bipedal walking algorithm on Aldebaran Nao Humanoid robots and optimize the parameters in both simulation and real world environments with di ? erent population sizes. Although a signi ? cant improvement is achieved for the simulation environment, it works as a ? ne-tuning process in real world experiment. In addition to the di ? erences for simulation and real world environment, we analyzed the e ? ects of population size on the training procedure. Training with bigger population sizes makes a deeper search and although its average ? tness value increases slowly, overall best ? tness value increases rapidly."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çeviri hafızası sistemleri ve Türkçe'den İngilizce'ye bir çeviri hafızası sistemi oluşturulması üzerine çalışmaktadır. Bir çeviri hafızası sistemi çevirmenlere çeviri esnasında yardımcı olması için tasarlanmış bir araçtır. Çeviri hafızası sistemi bir veritabanı kullanır ve bu veritabanı kaynak dilde bloklar, paragragraflar, cümleler veya deyimlerden ve bunların hedef dildeki çevirilerinden oluşur. Çeviri hafızası sistemi çevrilecek kaynak cümleye en yakın cümleyi bulmak için veritabanını araştırır. Çevirmen tarafından kullanılacak en iyi seçenekleri çevirmenin gözden geçirmesi için sunar. Çevirmen cevabı ya kabul eder, ya reddeder, ya üzerinde bazı düzenlemeler yapar, ya da bir sonraki en iyi sonucu ister. Çeviri hafızası sistemleri Türkçe için pek popüler bir kavram değildir. Bizim bilgilerimize göre daha önce Türkçe'den İngilizce'ye çeviri için oluşturulmuş bir çeviri hafızası sistemi yoktur. Bu sistem Türkçe İngilizce çeviri üzerine oluşturulan ilk çeviri hafızası sistemidir. Daha önce yapılmış bir örneğe dayalı makine çevirisi sistemi vardır, bu benzer ama farklı bir sistemdir. Önerilen sistem cümle bazlı bir veritabanı kullanır ama kelimelerden ve dilin bir çok dilbilimsel özelliğinden yararlanır. Benzerlik arama algoritması çok eklemeli kelime yapılarından,Türkçe'nin çekim ve yapım eklerinden yararlanır. Sunulan sistem dilin yazımsal,kökensel, dilsel, anlamsal ve sözdizimsel özelliklerini göz önünde bulundurur. SistemTürkçe üzerinde iyi başarı oranı elde ediyor (yaklaşık 0.40 BLEU puanı) ve dilsel yapısıTürkçe'ye benzeyen Macarca ve Fince gibi dillerin çevirilerinde de yardımcı olacağı düşünülüyor.","This thesis studies translation memory systems and development of a translation memory system from Turkish to English. A translation memory system is a tool that is designed for helping human translators during translation. It uses a database that consists of text parts such as blocks, paragraphs, sentences, or phrases in one language that is called source language and their translations in another language called target language. The translation memory system searches its database to and theclosest sentence for the source sentence that has to be translated. Translation memory systems that are used by human translators offer the best matches for the review of the translator. The translator either accepts it, or edits it, or rejects it and asks for the second best result. Translation memory system concept is not popular for Turkish. To the best of our knowledge, there is no translation memory system developed for Turkishto English. This is the first translation memory system from Turkish to English, noting the existence of a previous example based machine translation system for Turkish to English, a similar but different concept. The proposed system uses a sentence level memory but exploits words and various linguistic features of the language. The similarity search algorithm takes advantage of highly agglutinative word structures, inectional and derivational affixes of Turkish. The presented framework considers orthographic, morphologic, lexical, semantic and syntactical features. It gains good success rate on Turkish (about 0.40 BLEU score) and is expected to be helpful on the translation of languages that have similar linguistic structure such as Hungarian or Finnish."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bütün otonom robotlar verilen görevlerine bulundukları ortamdan algılar toplayarak başlarlar. Algılar kesin olarak bilinebilirse, insan robot iletişiminden üst seviye görev planlama gibi bir çok ileri araştırma alanı üzerinde çalışılabilir. Ancak önceki çalışmalar algıları eksiksiz ve kesin olarak toplanmasının oldukça güç olduğunu göstermiştir.Başta gelen problemlerden birisi ortamda bulunan ilgilsiz nesnelerin işaretçiler olarak algılanmasıdır. Temelde algılayıcıların mükemmel olmayan doğası gereği oluşan, alt seviye algılama algoritmalarındaki belirsizliklerin telafi edilmesi için çeşitli yöntemler uygulanması gereklidir. Bu açıdan bakıldığında robot pozisyonlaması literatürünün tamamının alt seviye algılayıcılarının getirdikleri belirsizliklerin çözülmesi amacı taşıdığı söylenebilir. Zira mükemmel algılar var olabilseydi, pozisyonlanma en basit yöntemlerle bile çözülebilirdi.Bu tezin amacı alt seviye görsel algılama birimleri ile yüksek seviye birimler arasında çalışarak, hatalı algılanmış nesneleri seçip ilgili algıları silebilecek bir algoritma geliştirilmesidir. Belirli bir grup nesneden ve hatalı algılardan bahsetmek ilk bakışta önerilen çözümün son derece ortam bağımlı olduğunu düşündürebilir. Ancak gerçek pozisyon bilgisi yerine meta posizyon bilgisinin kullanılması önerilen yöntemin olasılıksal alt yapısındaki birkaç parametrenin ayarlanamsıyla kolayca başka ortamlarda da kullanılabilmesini sağlar. İki farklı ortamda gerçekleştirilmiş deneyler önerilen yöntemin kolayca genellebildiğini göstermektedir.","All autonomous robots need to gather information about their surroundings. Once information about the environment is accurately extracted a great deal of further research is possible ranging from human computer interaction to high level action planning. However experience indicates achieving accurate perception can be a challenging problem.One of the problems is erroneous perception of the unrelated features of the environment as landmarks. Due to imperfect nature of sensors, methods should be developed to compensate for the uncertainties introduced by the low level perception algorithms. Looking from this point of view, the self localization literature may be seen as an effort to resolve the uncertainties introduced by lower level perception algorithms.This thesis proposes an algorithm to work between low level visual detection algorithms and higher level modules of a robot. The algorithm aims to select and remove erroneous perception information generated due to misplaced landmarks. Defining landmarks and correct locations for landmarks might sound very environment dependent at first. However this is not the case due to the generic definition of a landmark and correct location. Using the meta pose instead of a specific pose as the state space, the method becomes easily portable with a few alterations in the parameters of the underlying probabilistic framework. Experiments are performed in two different environments to show general nature of the proposed algorithm."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşaret dili duyma engellilerin doğal iletişim aracıdır. İşaret diliel hareketleri, yüz ifadesi ve kafa hareketlerinin bir karışımı olanişaretlere dayalıdır. Bu görsel dilleri başkalarına öğretmek zor fakatönemli bir iştir. İşaret dillerinin verimli öğrenilmesi bir uzmanınsıkça geri bildirimde bulunmasıyla mümkündür. Uzman kimse,gerçekleştirilen işareti izlemeli, ve işaret hakkındaki varolan bilgisinegöre işaretin doğru gerçekleştirilip gerçekleştirilmediğine kararvermelidir. Uzmanların rolü, gerçekleştirilen işaret hakkında kararvermek için bir eğitim kümesini bilgi dağarcığı olarak kullanıp birsınıflayıcı eğiten, otomatik bir sistem tarafından taklitedilebilir. Fakat, otomatik sistemin, yeterli eski tecrübesi olmadığıtakdirde, vereceği kararlar isabetli olamayacaktır.Bu problemi çözmek için etmenlerin işaret dili uzmanlarını temsil ettiği vekendi aralarında işbirliği yaparak gerçekleştirilen bir işaretin doğrusınıfına karar verdikleri, çok etmenli bir mimariöneriyoruz. Geliştirilen mimari üzerinde çeşitliişbirliği stratejileri uyguluyor ve bunların performansını değişenkoşullarda test ediyoruz. Daha sonra, bu stratejilerin ne kadar sağlamolduklarını inceliyoruz. Sonuçlarımıza göre en iyi performansısergileyen strateji bizim önermiş olduğumuz Bayesçi modellemestratejisidir. Bir sonraki adım olarak, çok etmenli sistem üzerindegerçekleştirdiğimiz analizlerle, işaret dilinin içerdiği dialektlerinvarlığı gibi bir takım özellikleri keşfediyoruz.","Sign language is the natural means of communication for thehearing-impaired. Sign languages are based on signs, which are acombination of hand gestures, facial expressions, and headmovements. Teaching these visual languages to others is animportant, but a difficult task. Sign languages can be learnedeffectively only with frequent feedback from an expert in the field.The expert needs to watch a performed sign, and decide whether thesign has been performed well based on her previous knowledge aboutthe sign. The experts role can be imitated by an automatic system,which uses a training set as its knowledgebase to train a classifierthat can decide whether the performed sign is correct. However, whenthe system does not have enough previous knowledge about a given sign,the decision will not be accurate.Accordingly, we propose a multiagent architecture in which agentsrepresent sign language experts, and they cooperate with each other todecide on the correct classification of performed signs. We applydifferent cooperation strategies and test their performances invarying environments. We further study the robustness of ourstrategies. Our results also show that the best performingstrategy is our proposal, the Bayesian modeling strategy. Further,through analysis of the multiagent system, we discover inherentproperties of sign languages, such as the existence of dialects."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz algılayıcı ağlarda dengesiz enerji tüketimi sistem ömrünü ciddi şekildeetkileyebilir. Tek bir veri toplama merkezine bağlı olan algılayıcılar merkez etrafındakialgılayıcıların yüksek bir veri trafiğine maruz kalmalarına sebep olurlar. Yüksek trafik,algılayıcıların enerjisinin daha hızlı tüketilmesine sebep olur ve merkez etrafında delikleroluşmaya başlar. Bu problem, enerji deliği problemi olarak bilinir. Her ne kadar buproblem ağ topolojisine bağlı bir problem olsa da, ağ ömrünü uzatmak ve deliklerinoluşmasını geciktirmek icin değişik stratejiler geliştirilebilir.Bu çalışmada, gözetim amaçlı telsiz algılayıcı ağlarda enerji deliklerinin etkisiniazaltmak için geliştirdiğimiz üç yaklaşımın başarımını inceledik. Farklı ağ ayarları vestratejilerinin sistem gözetim kalitesine etkilerini analiz edebilmek için benzetimlerim-izde gerçekçi bir algılayıcı modeli, ortama erişim kontrolü ve yönlendirme protokollerikullandık.","Uneven energy consumption in wireless sensor networks can drastically reduce the network lifetime. The large number of sensors reporting to a single data collection sink exposes the sensors around the sink to a higher traffic load. This causes the energy at these nodes to be consumed more rapidly which is known as the energy hole problem in wireless sensor networks. Although this problem is inherent to the network topology, several strategies can be developed to delay the hole formation and thus extend the network lifetime.In this work, we measure the performance of three different approaches used to mitigate the energy hole problem in surveillance wireless sensor networks. We evaluate the surveillance quality of the network over time for different network configurations and mitigation strategies using realistic sensor models, MAC and routing protocols in simulations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bazı problemler bilgisayarlar için çok zor, insanlar içinse kolaydır. İnsan bilgisayar ilişkisini karşılıklı fayda temeline, insanların kendi iyi yaptıkları işleri, bilgisayarlarınsa kendi iyi yaptıkları işleri yapmalarını sağlayarak dönüştürebiliriz. Bilgisayar oyunları, insan hesaplamasında kullanılan, önde gelen bir motivasyon aracıdır.Bir amaç için oyunlar, insan hesaplamasını kullanma adına ortaya atılmış bir konsepttir. Bunlar eğlenceli küçük oyunlardır. Oyunlar oynanırken arkaplanda büyük kompleks bir problemin çözümüne katkıda bulunurlar. TURC, Kullanıcı Hesaplamasıyla çeviri, web üzerinden oynanan çok kişilik bir oyundur.TURC İngilizce'den Türkçe'ye çeviriye odaklanmaktadır. İnternet üzerinde çok sayıda İngilizce kaynak olmasının yanında, Türkçe kaynaklar oldukça sınırlıdır. İki dil arasında Google Translate gibi makina çevirisi programı denemeleri mevcuttur. Fakat iki dili de iyi konuşan biri için, bu programların çevirilerinin yetersizliği aşikardır. Bizim modelimizde, rekabet faktörüyle oyuncular eğlenirken, kolay anlaşılabilen bir arayüzaracılığıyla çıktı olarak makina çevirisini geliştircek önerilerde bulunmaktadırlar. Birbiriyle iletişimi olmayan iki oyuncuya İngilizce bir cümlenin makina çevirisi sunulur. Kelime ekleme, çıkarma, düzenleme ya da yer değiştirme seçenekleri mevcuttur. Oyuncuların hedefleri birbirleriyle aynı değişiklikleri yapmaktır. Bunun en kolay yolu da çeviriyi düzeltmekte yatar. Oyuncuların hamlelerinin benzerliği baz alınarak bir skor üretilir. Bu sistemin uygulandığı bir prototip internette sergilenmiştir. Bu çalışmada oyun modelimiz ve çalışmalarımızın sonuçları anlatılmaktadır.","Human Computation aims to solve problems by means of combining the power of human and computer computation. The typical approach is to assign tasks to computers and humans based on what they are better capable of performing. The aim is to bring human-computer relationship into a symbiotic mutualism, where humans compute what they are good at and vice versa.Games with a purpose introduced a concept that harvests human brain power. They try to solve a large scale complex problem with a game structure. In our work, we present a model with an objective of improving machine translation. TURC, Translation with User Computation, is a web-based multiplayer online game.TURC focuses English-Turkish translation. As there are large amounts of English data available in the web, the lack of Turkish is disappointing. There are available machine translation efforts between these languages, such as Google Translate. However a speaker of both languages can easily tell that these efforts are insufficient. Our model is designed to generate output to help improving machine translation while making people enjoy translation with the element of competition. Two non-communicatingplayers are presented a machine translation of an English sentence. They have the options of adding, editing, deleting or moving a word available. Their aim is trying to make the same actions. A score value is generated according to the correspondence of these actions. A prototype of our game model is hosted on a server for two weeks and the results are discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Doğal dil işleme görevlerini gerçekleştirmek için geliştirilmiş en gelişkin sistemler modellerini kurarken çoğunlukla makine öğrenmesi yöntemleri kullanırlar. Çoğunun öğreticiyle öğrenme yolunu seçtikleri düşünüldüğünde, ilgili doğal dil işleme sorununa uygun olarak işaretlenmiş bir derlemin zorunluluğu ortaya çıkar. İşaretlemede kullanılan güncel yöntem, konusunda uzmanlaşmış kişilerin işlemi elle veya yardımcı bir yazılım kullanarak gerçekleştirmesidir. L\^akin, bu, yer yer hatalara yol açmasının yanında, masraflıdır ve uzun zaman gerektirir. Yöntemimiz bu sorunların hepsini bir anda çözmeyi hedefler. Herhangi bir internet kullanıcısının oynayabileceği yardımlaşma\-cı ve eğlence amaçlı bir oyunu oynatmak marifetiyle açığa çıkmamış işgücünün derlem işaret\-lenmesi yönünde değerlendirilebileceğini düşünüyoruz. İnsanlar, sosyal ağ sitelerinden devşirilmiş bazı özellikleri de taşıyan bir sitedeki belirli bir sözcük hakkında\-ki sorulara cevap vererek işaretlemeye katkıda bulunmaya teşvik ediliyor. Tezde verilen sonuçlar gerçekleştirilen deneyin ilk on bir gününden oluşturulmuştur. Deney belirsiz bir tarihe kadar devam etmek üzere hala çalışmaktadır. Sonuçlara göre, halihazırdaki 74 soru çeşidinin iki fazdan oluşan değerlendirmesine göre yüzde 63.5'lük bir başarı oranı yakalanmıştır. Bahsi geçen soru çeşitleri derlemin yüzde 58.3'ünün biçimbilimsel çözümlemesini yapabilmektedir. Soru çeşidi sayısını 100'e çıkarmak, bu oranı yüzde 70.7'e çıkaracaktır. Zaman kısıtı ve ziyaretçi azlığından dolayı bahsedilen düzeyde bir işaretle\-me yapılamamasına rağmen, ulaşılacak başarı oranı üzerine bir tahmin yapmak gerekirse yüzde 51.4 oranı elde edilecektir. Bu işlemin, büyük bir ulusal gazetenin web sayfasında gerçekleştirildiği takdirde, iki buçuk ay içinde tamamlanacağı düşünülmekte\-dir. Bu, bu çaptaki bir işaretleme işi için göreli olarak kısa bir süredir.","In most of the natural language processing tasks, state of the art systems usually rely on machine learning methods for building their mathematical models. Given that the majority of these systems employ supervised learning strategies, a corpus that is annotated for the problem area is essential. The current method for annotating a corpus is to hire several experts and make them annotate the corpus manually or -in its best practice- by using a helper software. However, this method is costly and time-consuming if not error free. We propose a method that aims to solve these problems at once. By employing a multiplayer collaborative game that is playable by ordinary people on the Internet, it seems possible to direct the covert labour force so that people can contribute by just playing a fun game. Through a game site which incorporates some functionality inherited from social networking sites, people are motivated to contribute to the annotation process by answering questions about the underlying morphological features of a target word. The results reported in the thesis are compiled from the first eleven days of the experiment which is planned to continue until an indeterminate date. It is reported that the 63.5 per cent of the actual question types are successful based on two phases. The current 74 question types cover 58.3 per cent of the corpus completely while increasing this number to only 100 types increases the coverage rate to 70.7 per cent. Due to the time constraints and the relatively low traffic to the site, we were not able to annotate the corpus completely, but we can nevertheless estimate a hypothetical rate of successful morphological disambiguation as 51.4 per cent of the whole corpus which is calculated to be completed in two and a half months if the game were to be hosted on a major web site. This is indeed a relatively short duration for a bootstrapping of this size when compared with the current methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez noktalardan oluşmuş geometrileri doğrudan ışın izlemeyle görselleştirmeyi sağlayan bir metod sunmaktadır. Böylece düzensiz nokta kümelerinden yüksek kaliteli görüntüler elde edilir. Bu yöntemde her noktaya bir disk yerleştirilir ve ışınlar bu disklerle kesişim testine sokulur. Kesişim olması durumunda ışından belirli bir uzaklıktaki noktalar da kullanılarak konum, normal gibi özellikler için interpolasyon yapılır.Işın-Disk kesişim testleri octree gibi hiyerarşik bir data yapısı kullanılarak hızlandırıldı. Octree kullanmak hesaplamaları O(n log n) karmaşıklığına indirger. Ayrıca ışın çevresindeki kesişime uğramış octree hücrelerini bulmak, bütün nokta kümesini taramaktan çok daha hızlıdır. Bütün kesişime uğramış diskler bu octree hücrelerinin içinde bulunabilir.Normalleri olmayan noktalar içinse, her bir noktaya tanjant düzlemi koyarak ihtiyaç duyulan normaller hesaplandı.Bu yöntemi geliştirmek için disk yarıçapları en yakın k kadar komşu noktayı kullanarak değiştirildi ve lokal nokta yoğunluğuna uyumlu hale getirildi. Değişken disk yarıçapı kullanmak nokta kümesindeki boşlukları detay seviyesinde kayıp olmadan doldurdu. Değişken disk yarıçapı yaklaşımı normal hesaplamasına da uyarlandı. Hesaplamalarda sabit bir komşuluk yarıçapı içindekiler yerine en yakın k kadar komşu nokta kullanıldı.","This thesis presents a method for direct ray tracing of point sampled surfaces. This allows to render high quality images using unstructured point-sampled data. An oriented disc is placed at each point and rays are tested for intersection with these discs. In case of intersection, all points within a fixed distance of the ray are used to interpolate the position, normal and any other attributes.Ray-Disc intersection tests are accelerated using a hierarchical data structure namely an octree. This provides a computation complexity of O(n log n). Also searching for intersected octree nodes around ray is much more faster than scanning whole point data. All of the intersected discs can be located inside the nodes which are intersected by the ray.For data without point normals, required normals are calculated from point data by fitting a tangent plane to each point.An improvement is proposed for adapting disc radius to the local point density by determining k nearest neigbours. Using variable disc radius fills empty holes within the point cloud without loss of detail. Variable disc radius approach is also used in normal estimation process where the k nearest neighbours are used in calculations instead of neighbours within a fixed radius."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sözdizimsel ayrıştırma doğal dil işlemede temel bir problemdir. Cümleye bir yapı atamak olarak tanımlanabilir. En yaygın iki ayrıştırma, öbek yapısı ayrıştırma ve bağımsallık ayrıştırmasıdır. İlgili bir konu ayrıştırıcı değerlendirmesidir. Bu tez, ayrıştırmanın Metinsel Gerektirimleri Tanıma görevinde olduğu gibi bir dizi basit cümle ile ifade edildiği bağımsallık tabanlı bir değerlendirme olan Metinsel Gerektirimler ile Ayrıştırıcı Değerlendirmesini önermektedir. Her gerektirim bir bağlantıya odaklanmaktadır. Yorumcuların önceden eğitilmesine gerek yoktur. Bir program bağımsallık ayrıştırmasından gerektirimleri üretmektedir. Öbek yapısı ayrıştırmaları gerektirim üretmek için bağımsallık ayrıştırmasına çevrilmektedir. Öbek yapısı eşgüdümlerinden ek gerektirimler üretilmektedir. Bir işlev etiketçi ile deneyler yapılmıştır. Ayrıştırıcılar Penn Treebank WSJ ve Brown test kısımlarından üretilen gerektirim kümesi üzerinde değerlendirilmiştir. Bir öbek yapısı ayrıştırıcı en yüksek puanı almıştır.","Syntactic parsing is a basic problem in natural language processing. It can be defined as assigning a structure to a sentence. Two prevalent approaches to parsing are phrase-structure parsing and dependency parsing. A related problem is parser evaluation. This thesis proposes Parser Evaluation using Textual Entailments as a dependency-based evaluation where a parse is represented as a list of simple sentences, similar to the Recognizing Textual Entailments task. Each entailment focuses on one relation. A priori training of annotators is not required. A program generates entailments from a dependency parse. Phrase-structure parses are converted to dependency parses to generate entailments. Additional entailments are generated for phrase-structure coordinations. Experiments are carried out with a function-tagger. Parsers are evaluated on the set of entailments generated from the Penn Treebank WSJ and Brown test sections. A phrase-structure parser obtained the highest score."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın temel amacı kredi müşterilerini kesin bir şekilde iyi (kredi borcunu geri ödeyen) ya da kötü (kredi borcunu aksatan) diye ayıran bir sınıflandırma yöntemini ve bu yöntemden farklı olarak müşterilerin kredi borcunu geri ödememe (iflas etme) olasılığını hesaplayan temerrüt olasılığı (TO) yöntemini kullanarak Saklı Markov Modeliyle kredi risk analizi yapılabilirliğinin araştırılmasıdır. TO süreci, kredi müşterilerinin bazı verilerini kullanarak kredi verme ya da vermeme kararından önce müşterinin kredi borcunu zamanında ödememe olasılığını hesaplamak suretiyle kredi verilmesi kararı konusunda banka ve kredi şirketlerine ışık tutar. Bu çalışmanın ilk bölümünde HMM yönteminin sınıflandırma kabiliyeti geleneksel yöntemler olan Lojistik Regresyon (LR) ve Yakın k Komşu (YkK) yönteminin sınıflandırma kabiliyetiyle karşılaştırılmaktadır. İkinci bölümde ise HMM yöntemiyle TO modellemesi yapılmış ve oluşturulan modelin performansı en popüler yöntemlerden biri olan LR kullanılarak oluşturulmuş TO modellemesiyle karşılaştırılmıştır. Serbest erişime açık olan Alman ve Avusturalya Kredi Veri tabanları bu tez çalışmasında kullanılmıştır. Yukarıda bahsedilen yöntemlerin sınıflandırma işlemindeki etkinlikleri doğruluk, hata maliyeti ve Alıcı İşletim Karakteristiği (AİK) ölçütlerine göre altılı çapraz doğrulama testleriyle belirlenmiştir. LR ve HMM yöntemleriyle oluşturulan TO modellerinin performansları ise iyi ve kötü müşterilerin ortalama TO değerlerine bakılarak belirlenmiştir. Matlab'ın Kevin Murphy tarafından geliştirilen HMM paketiyle HMM analizleri yapılırken, LR analizleri için internet tabanlı LR hesaplayıcı kullanılmıştır. YkK analizi için yine Matlab kullanılmıştır. Bu çalışmada HMM yöntemi kullanarak geleneksel yöntemlerle rekabet edecek düzeyde kredi risk analizi yapmaya yarayan algoritmaların bulunması hedeflenmiştir. Deneylerin gösterdiği kadarıyla HMM oldukça etkin bir kredi risk analizi yöntemidir ve finansal kuruluşlarca da kullanılabilir.","The purpose of this study is to investigate the performance of Hidden Markov Model (HMM) for credit risk analysis in terms of classification and probability of default (PD) modeling where PD modeling assigns default bankruptcy probabilities to credit customers instead of strictly classifying them as good (solvent) borrowers and bad (insolvent) borrowers. PD modeling process makes use of some data belonging to credit applicants and helps banks or credit companies compute a probability that the customer should not pay his/her debts in a timely manner, prior to the decision of granting credit. In the first part of this study, classification ability of HMM is compared to that of Logistic Regression (LR) and k-Nearest Neighbors (k-NN) which are two conventional methods for classification. In the second part, PD modeling performance of HMM is analyzed and compared to that of LR which is known to be one of the most popular PD modeling methods so far. Australian Credit Database and German Credit Database are two public datasets utilized in this thesis study. Classification performances of the aforementioned methods are judged according to accuracy, error cost and Receiver Operating Characteristics (ROC) analysis with supporting experiments using six-fold cross validation. PD modeling performances of HMM and LR are also compared by directly examining the average PD values for solvent and insolvent borrowers. Matlab?s HMM toolbox by Kevin Murphy is used for HMM computations whereas a web based tool is utilized for LR analysis. Matlab is also used for k-NN analysis in classification experiments. The aim of this study is to build appropriate algorithms for HMM to make it an effective way of credit risk analysis as well as conventional methods. The results of the experiments show that HMM is a powerful and effective method for credit risk analysis and can be utilized by financial institutions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Radyo spektrumu sınırlı bir kaynaktır ve kablosuz ağlardaki artan kullanıcı sayısı ile birlikte radyo spektrumunun etkili bir şekilde kullanılması kilit bir problem olmuştur. Artan bant genişliği kullanımı göz önüne alındığında var olan kablosuz ağların yetersiz kalacağı sonucuna varılabilir. Bu durumun temel nedeni her kablosuz ağın kendi çalışma parametrelerine sahip olduğu sabit spektrum atama politikasından kaynaklanan spektrum yönetimindeki verimsizliktir. Günümüzde kullanılan donanım tabanlı teknoloji dinamik kullanıma izin vermez ve oldukça hantaldır.Dinamik spektrum tahsisi, verimli spektrum kullanımı için umut verici bir çözümdür ve gerçeklenmesi ancak yazılım tabanlı telsiz (YTT) mimarisine dayanan akıllı radyo (AR) teknolojisi ile mümkündür. Akıllı radyo, spektrumun boş kısımlarını otomatik olarak algılayan ve dinamik olarak kullanılmasına sağlayan akıllı bir cihazdır. Akıllı radyo bu dinamizmi çalışma esnasında kanal değişimleri yaparak sağlar. Ancak, kanaldeğiştirme pahalı bir operasyondur. Çünkü devam eden iletişimin bekletilmesini, yeni bir kanal seçilmesini ve AR'nun seçilen kanala göre yeniden ayarlanmasını gerektirir. Ayrıca, iletişim problemlerinin engellenmesi için bütün bu operasyonlar en kısa zamanda gerçekleştirilmelidir. AR'nun etkili bir biçimde çalışabilmesi için kanal değiştirme sayısının azaltılması çok önemlidir.Kanal değiştirmeye yönelik ilk çalışmalar hali hazırdaki spektrum gözlemlerine dayalı algıla-ve-tepki ver yaklaşımına dayanır. Bu yaklaşım kullanıcıların gelecekteki kanal durumu hakkında öngörüde bulunamamaları dolayısı ile iletişim problemlerine neden olabilir. Diğer kanal değiştirme algoritmaları ise genellikle kanal değiştirme zamanının belirlenmesi, bant genişliği kullanımının arttırılması, daha hızlı kanal keşfetme ve birincil kullanıcılara verilen zararın en aza indirilmesine odaklanmaktadır ancak ""Kullanıcı davranışı göz önüne alarak kanal değiştirme sayısı nasıl azaltılabilir?"" sorusuna cevap vermemektedir. Ayrıca, var olan kanal seçme algoritmaları sadece yazılım simülasyonu ya da donanım test ortamı sonuçları sunmaktadır ve sunulan yaklaşımların gerçek bir YTT üzerinde yazılımsal olarak nasıl gerçekleneceğine değinmemektedirler. Bu tezde, belirtilen eksikliklere cevap verebilmek için iki adet kanal seçme algoritması önerilmiş ve altyapı tabanlı bir YTT uygulaması gerçeklenmiştir. Önerilen kanal seçme algoritmaları kullanıcı davranışlarını ve kanal kullanım geçmişlerini öğrenmeyi ve bunlardan faydalanarak seçilecek yeni kanalı belirlemeyi hedeflemektedir. Tezin gerçekleme bölümünde ise, YTT temelli bir AR'nun yazılımsal tasarım problemleri irdelenmiş ve bazı yazılım tasarım desenleri önerilmiştir. Ayrıca, yazılım katmanları ve her katmandaki bileşenler açıklanmış, sonuçlar yazılım mühendisliği bakış açısı ile değerlendirilmiş ve son olarak öğrenilen dersler ve gerçekleme sırasında karşılaşılan sorunlar sunulmuştur.","Radio spectrum is a finite resource and effective utilization of it in wireless networks is a key challenge as the number of users increase. Current wireless networks are expected to fail to satisfy increasing user demands due to inefficient spectrum management resulting from the fixed assignment policy in which each wireless network has its own running parameters. Current hardware-based technology does not allow dynamic usage and is very cumbersome.Dynamic spectrum allocation, which can be achieved by cognitive radio (CR) technology that is based on software defined radio (SDR) architecture is a promising solution for efficient spectrum utilization. CR is an intelligent device that automatically senses, recognizes, and makes wise use of idle parts of the spectrum dynamically. CR achieves dynamism by making handoffs to underutilized bands. Handoff is an expensive operation. Because, it requires suspending an ongoing communication, searching and selecting a new channel, and reconfiguring CR to switch that channel. Also, all of these operations should be performed in the shortest time to avoid communication problems. Decreasing number of handoffs is a key challenge for efficient operation of CR.Initial studies for handoff are based on sense-and-react approach where handoff is made solely based on current spectrum observations. This approach may lead to possible communication failures because users cannot foresee future channel status. Other handoff algorithms mostly focus on determining the handoff time, increasing bandwidth usage, achieving faster channel discovery, and minimizing disturbance to primary users but do not answer the question of ``how to minimize number of handoffs by considering user behavior?"" In addition, existing channel selection algorithms provide only software simulation or hardware testbed results and neglect the software design and implementation details of their approach on a real SDR. In this thesis, two channel selection algorithms are proposed, and an infrastructure based SDR implementation is provided to answer these questions. Proposed channel selection algorithms aim to learn user behavior and use channel utilization histories for predicting the new candidate channel for handoff. In the implementation section of the thesis, software design challenges of a SDR based CR are discussed and several software design patterns are proposed, the layers of the software and components in each layer is explained, the results from a software engineering point of view are examined and finally, the lessons learned and troubles encountered during the implementation are presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Literatürdeki istatistiksel testler genelde hata oranını kullanırlar ve yanlış pozitifand yanlış negatiflerin maliyetlerinin aynı oldugunu varsayarlar. ROC eğrileri ve/veyaROC Eğrilerinin Altındaki Alan (AUC), çeşitli maliyet değerlerine göre sınıflandırıcılarınperformanslarını karşılaştırmak için kullanılabilir. Bir ROC eğrisi ve bir ROC eğrisininaltındaki alan genellikle bir öğrenme/sınama çiftinden hesaplanır ve verideki rastsallığınortalamasını almak için ve dağılım oturtabileceğimiz ve üzerinde hipotez testi yapabileceğimiz bir ROC eğrileri kümesi ve AUC değerleri oluşturmayı öneriyoruz. 15veri kümesi üzerinde 5 farklı sınıflandırma algoritması kullanılarak bulduğumuz deneyselsonuçlar gösteriyor ki bizim önerdiğimiz AUC testi hata oranını kullanan eşli ttestine göre daha üstündür¸cünkü AUC testi hata testinin fark edemeyeceği eşitlikve farklılıkları fark edebiliyor. ROC eğrileri için kullandığımız yaklaşım, Doğruluk-Anımsama eğrilerinin altında kalan alana k-kat¸capraz-geçerleme uygulayarak da kullanılabilir.Birden çok sınıflandırıcıyı bir veri kümesi veya birden çok veri kümesi üzerindekarşılaştırımak için Varyans Analizi (ANOVA) kullanabiliriz. Birden çok performansmetriği üzerinden karşılaştırma yapmak için, çok değişkenli ANOVA, MANOVA, kullanırız.ANOVA'nın performans metrikleri hata veya AUC olabilir. MANOVA'nınperformans metrikleri doğru pozitif, yanlış pozitif, doğru negatif ve yanlış negatifdeğerleridir. ANOVA'nın parametrik olmayan versiyonu olan Friedman testini deyapıyoruz. Çoklu sınıflandırıcıları çoklu veri kümeleri üzerinden karşılaştırırken İşarettesti uyguluyoruz. Birden çok performans metriği kullanmanın onların korelasyonlarınıiçerdiğini ve bu yüzden daha güvenilir sonuçlar ürettiğini gözlemliyoruz.","Statistical tests in the literature mainly use error rate for comparison and assumeequal loss for false positives and negatives. Receiver Operating Characteristics (ROC)curves and/or the Area Under the ROC Curve (AUC) can also be used for comparingclassifier performances under a spectrum of loss values. A ROC curve and hence anAUC value is typically calculated from one training/test pair and to average overrandomness in folds, we propose to use k-fold cross-validation to generate a set ofROC curves and AUC values to which we can fit a distribution and test hypotheseson. Experiment results on 15 datasets using 5 different classification algorithms showthat our proposed test using AUC values is to be preferred over the usual paired t teston error rate because it can detect equivalences and differences which the error testcannot.The approach we use for ROC curves can also be applied to Precision-Recallcurves, used mostly in information retrieval by applying k-fold cross-validated test onthe area under the Precision-Recall curve.When multiple classifiers are to be compared over one dataset or multiple datasets,we can use Analysis of Variance (ANOVA). When we use more than one performancemetric, we use the multivariate ANOVA, that is, MANOVA. Performance metrics ofANOVA is error or AUC. Performance metrics of MANOVA are true positive, falsepositive, true negative and false negative rates. We also perform the nonparametricversion of ANOVA which is called Friedman test. We apply Sign test when we comparemultiple classifiers over multiple datasets. We observe that using more than one per-formance metric includes their correlation in the statistical test and therefore producesmore accurate results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biçimsel metotlar koşut zamanlı sistemlerin tanımlanmasında ve doğrulanmasında yararlanılan matematiksel tekniklerdir. Biçimsel metotların sıkça kullanılan bir örneği de model denetlemedir. Model denetleme yönteminde hedef sistemin soyutlama ile oluşturulurmuş sonlu durumlu bir modeli üzerinde tüm durumların doğrulandığı kapsamlı bir inceleme yürütülür.Sistemlerin zamana bağlı davranışlarını inceleyen model denetleyiciler mevcuttur. Yakın zamanda iki yeni kavram, konumlar ve konum değiştirme, model denetlemede önem kazanmıştır. Konum ve konum değiştirme kavramlarını kapsayan çeşitli model denetleme yöntemleri üzerine algoritmalar önerilmişse de, bu tarz bir denetleme yapabilen çok az model denetleme uygulaması gerçeklenmiştir. Bu tezde koşut zamanlı sistemlerin zamansal ve uzaysal davranışlarını inceleyebilen yeni bir model denetleme metodolojisi önerilmektedir. Önerilen bu model denetleme metodolojisi ile sistemlerin uzaysal davranışları var olan model denetleme uygulamalarından daha kapsamlı bir şekilde incelenebilmektedir.Çevrel cebir ve çevrel mantık bu tez kapsamında modellerin ve sistem özelliklerinin ifade edilmesinde kullanılacak biçimsel dillerdir. Çevrel cebir pi-cebrinden türetilmiş bir işlev cebridir. Çevrel cebir ile koşut zamanlı sistemler, konumlar ve konumsal değişiklikler üzerinden modellenebilir. Çevrel mantık koşut zamanlı sistem modellerinin zamansal ve uzaysal özeliklerinin belirtilebildiği bir kipler mantığıdır. Çevrel mantık çevrel cebir üzerine bina edilmiştir. Önerilen model denetleme metodolojisi girdi olarak bir koşut zamanlı sistemin çevrel cebrin bir alt kümesi ile ifade edilmiş bir modelini ve çevrel mantığın bir alt kümesi ile belirtilmiş sistem özelliklerini alır. Model denetleyici çıktı olarak ya başarı mesajı döner ya da verilen sistem özelliklerinin sağlanmadığı durumları döner. Önerilen model denetleme metodolojisi çevrel cebir ve çevrel mantık kullanan ve hali hazırda gerçeklenmiş olan tek araçtır.Bu tezin kapsamında, gerçeklenmiş olan araç için performans sonuçlarının durum çalışmaları üzerinden gösterilmesi de bulunmaktadır. Çok etki alanlı ağlar için tanımlanmış güvenlik politikalarının güvenlik açıklıkları bulundurmadıkları ve belirli bir ağ yapılandırmasında tutarlı oldukları biçimsel yöntemlerle doğrulanmalıdır. Bu tezdeki durum çalışmalarında çevrel cebir ile modellenmiş çok etki alanlı ağlar, çevrel mantık ile belirtilmiş özelliklere karşı, önerilen model denetleyici ile doğrulanmaktadır.","Formal methods are mathematical techniques applied in specification and verification of concurrent interactive systems. Model checking is a widely used formal method for formal verification of systems. In model checking, an exhaustive search is applied on a finite state model of the target system.While there are model checkers to verify the only temporal behaviors of systems, two new notions of model checking analysis recently come into prominence, mobility and locations. Although there are various model checker proposals for modeling and verifying concurrent interactive systems with respect to mobility and locations, there are a few model checker tools able to perform such verifications. In this thesis, a new model checking methodology is proposed which is able to verify temporal and spatial properties of systems together. The proposed model checking methodology is able to perform more detailed verifications than existing tools.In this thesis, ambient logic and ambient calculus are used as formal languages to express models and the properties of the systems. Ambient calculus is a process calculus derived from pi-calculus. It is able to theorize about concurrent systems with respect to mobility and locations. Ambient logic is a modal logic able to express temporal and spatial properties of models. It is strictly based on ambient calculus. Proposed model checking methodology accepts models expressed with a fragment of ambient calculus and properties expressed with a fragment of ambient logic as inputs. It returns a success message or the states of the model which are violating properties. In the scope of this thesis, an implementation of proposed methodology is provided which is the only tool using both ambient calculus and ambient logic.In this thesis, performance of the proposed model checking methodology is shown over case studies. Security policies defined for multi-domain networks need to be formally checked against security breaches and ensured that they are consistent in a given network configuration. In case studies, a set of ambient calculus specifications modeling such networks are verified against ambient logic formulas with proposed model checking methodology."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez her yerde birden bulunan hesaplama ortamını geliştiren, radyo frekanslı tanımlamanın (RFID) güvenlik ve gizlilik konuları üzerinde durmaktadır. RFID teknolojisi birçok tipte nesneyi tanımlamada kullanılmaktadır. Varlık yönetimi, izleme, erişim kontrol ve otomatik ödeme RFID teknolojisinin kullanıldığı bazı temel uygulamalardır.Bu nedenle yakın gelecekte RFID teknolojisinin barkod teknolojisinin yerini alacaktır.Bununla beraber, RFID teknolojisini günlük kullanıma uygun hale getirmedeki en önemli mesele gizliliktir. Düşük maliyetli RFID etiketlerinin devre boyutu, güç tüketimi ve hafıza boyutu açışından kaynak sınırlamaları olduğu için, varolan kriptografik fonksiyonlara dayanarak gizli kimlik denetim protokolleri tasarlamak çok güçtür. Bu nedenle düşük maliyetli RFID etiketleri RFID uygulamalarında kullanmak için hafif kriptografiye dayanan yeni gizli kimlik denetim protokolleri gerekmektedir.Biz bu tezde, düşük maliyetli etiketler üzerinde odaklandık. İlk olarak, RFID sistemleri için yeni güçlü bir güvenlik modeli (ACAP) öneriyoruz ve yeni önerilmiş bir kimlik denetim protokolünün güvenliğini önerdiğimiz modele göre analiz ediyoruz. Önerilen protokolde, düşmanın en az bir iletişim akışını kaçırması gerektiği varsayılıyor ve bu varsayım altında protokolün ileri izlenebilirliğe karısı güvenli olduğunu iddia ediliyor. Biz önerilen protokolün bu varsayım altında güvenli olmadığını gösteriyoruz. RFID sistemleri için yeni bir kimlik denetim protokolü (ACA) öneriyoruz ve önerdiğimiz protokol ün güvenliğini kendi güvenlik modelimizi kullanarak analiz ediyoruz. Önerdiğimiz protokol gizlilik ve güvenlik tehditlerine karısı önceki protokollerden daha iyi bir koruma sağlıyor. Önerdiğimiz protokol sunucu taklit etme atağına karşı her hangi bir varsayım olmadan koruma sağlıyor ve ileri izlenebilirliğe karşı düşmanın en az bir iletişim akışını kaçırması gerektiği varsayımı altında koruma sağlıyor. Bununla beraber, önerdiğimiz protokolün performansını analiz ettik ve daha önceki çalışmalarla karşılaştırdık. Önerdiğimiz protokol sunucu ve etiket tarafında düşük hesaplama yüküne sahiptir.İkinci olarak, diğer bir kimlik denetim protokolünün SAPA (Storage Awareness Private Authentication) güvenliğini analiz ediyoruz ve SAPA'nın başarılı doğrulama oturumları arasında lokasyon ve bilgi gizliliği sağlamadığını ve SAPA'nın ileri izlenebilirliğe, servis reddi saldırısına ve sunucu taklit etme saldırısına dayanıklı olmadığını gösteriyoruz. RFID sistemleri için ağaç yapısına dayanan yeni bir kimlik denetim protokolü (ACAT) öneriyoruz. ACAT gizlilik ve güvenlik tehlikelerine karşı daha önceki protokollerden daha iyi koruma sağlıyor. ACAT bilgi gizliliği ve lokasyon gizliliği sağlıyor ve tekrar saldırılarına, servis reddi saldırılarına, ileri izlenebilirliğe (varsayım altında), geri izlenebilirliğe ve sunucu taklit etme saldırısına direnç gösterebiliyor. Diğer ağaç yapısına dayanan protokollerle kıyasladığımızda, etiket ve sunucu tarafında ACAT en az hesaplama ve iletişim yüküne sahiptir.","This thesis studies security and privacy issues of Radio Frequency Identification (RFID) technology that enhances ubiquitous computing environment. RFID technology is used to identify many types of objects. Some of the main applications are asset management, tracking, access control and automated payment. Therefore, in the near future, this technology will replace the barcode technology.However, privacy is one of main issues to adopt RFID technology in daily use. Due to resource constraints of low cost RFID tags in terms circuit size, power consumption and memory size, it is very restricted to design a private authentication protocol based on existing cryptographic functions. Therefore new private authentication protocols based on lightweight cryptography are required to use low cost RFID tags in RFIDapplications.In this thesis, we focus on low cost RFID tags. Our contributions are as follows. Firstly, we propose a new strong privacy model called ACAP for RFID systems and analyze the privacy of a former authentication protocol based on our privacy model. Former proposal assumes that the adversary should miss any reader-to-tag communication flows and claims that their protocol is secure against forward traceability only in such communication environment. We show that even under such an assumption, the former proposed protocol is not secure. We propose a new RFID authentication protocol called ACA. We analyze its security based on our privacy model. The proposed protocol provides better protection against privacy and security threats than those before. It is resistant to server impersonation attack without any assumption and secure against forward traceability, if the adversary misses any reader-to-tag communication flows. Furthermore, we analyze the performance of ACA. It has low computational load on both the tag and the server side.Secondly, we analyze the privacy and security of another former proposal SAPA (Storage Awareness Private Authentication) and discover that SAPA does not provide location and information privacy between successful authentication sessions and does not resist denial of service attacks, forward traceability, and server impersonation. We analyze the weaknesses of SAPA and propose a new tree based RFID authentication protocol called ACAT. ACAT provides better protection against privacy and security threats than those before. It provides tag information privacy and tag location privacy, and resists replay attacks, denial of service attacks, backward traceability, forward traceability (under an assumption), and server impersonation with an efficient key lookup. Furthermore, ACAT has the least computation and communication load on both the tag and the server side compared to other tree based protocols."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada, bilgisayarla kumanda edilebilen, alıcıları olan küçük boyutlu bir kara aracı inşası problemi ve bu aracın düzenli olmayan dış ortamlarda kendi başına dolaşması problemini araştırdık. Farklı uzaklık algılayıcı kurulumları denendiyse de daha çok kamera ile çalışılmaya odaklandık. Tek kameradan alınan resimlerden elde edilen ipuçları kullanılarak insan algısını taklit edecek algoritmaları temel aldık.Etraftaki engellere olan en düşük bağıl uzaklıkları tahmin etmek için kullanılan bir derinlik algılama yordamına önem verildi. İmgelerden çıkarılan değişik vasıfların önemine dair ayrıca bir çalışma yapıldı. Böylelikle, gerçek dünya deneylerinde kullanılacak algoritmanın işlem zamanı düşürülebilecekti ve deneyler yapılabilecekti. Daha az vasıflarla da imgeler içindeki uzaklıkların tahmin edilebileceğini gördük.Deneyler etrafta ağaç ve çalılıklar olan engebeli bir arazide yapıldı. Burada, robot, takip edeceği en iyi yönü ararken aynı zamanda fiziksel şartlarla da başa çıkmak durumundaydı. Deneyler ümit verici sonuçlar verdi. Araç, vasıf çıkarımı modelleri geliştirildikçe daha uzak mesafelere çarpmadan ulaşabiliyordu ve test alanının tamamını geçebiliyordu. Ancak aracın son aldığı karar, uzaklık tahmini ve yönelim gibi bir çok farklı parametreye bağlı olduğu için sistem bir bütün olarak düşünüldüğünde, hataları telafi etmek ve daha güvenli bir seyir için daha uygun modeller gerektiği çıkarımını yaptık.","In this study, we investigated the problem of constructing a small sized drive-by-wire ground vehicle with sensors and the problem of its autonomous navigation in unstructured outdoor environments. Although different sensor installations were tried on the vehicle, the focus was on the camera that would imitate the human perception using monocular cues in the acquired images.A high importance was given to a depth perception algorithm that is used to estimate the relative maximum distances of the obstacles around. A study on the importance of the features extracted from the images was also included so that the running time of the algoritm could be decreased, which would enable the system run in real world. We have seen that lesser number of features could well be used to estimate the depths in an image.The experiments were done on a rough terrain with trees and bushes around where the robot also had to cope with the physical conditions while trying to find the best direction to follow. The results were encouraging; the vehicle travelled longer distances; and even traversed the whole test area as the used methods got more developed, however, when the system is considered as a whole, we made an inference that more feasible models are required to compensate for erroneous estimations and, in the end, to make the navigation safer, since the final decision of the vehicle depends on many sequential parameters."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Televizyon (TV) kanallarına ait logolar televizyon yayınlarındaki anlam taşıyan yegane nesnelerdir. Bu logolardan yararlanlarak TV reklam tespiti ve ya izleyici oranlarının ölçümü gibi pek çok faydalı uygulama geliştirilebilir. Bu çalışmada otomatik bir TV logo tanılama sistemi geliştirilmiştir. Bu sistem iki kısımdan oluşmaktadır: TV logo tespiti ve TV logo sınıflandırması. TV logo tespiti kısmında, şu fikirden yola çıktık: `bir televizyon yayınında tüm içerik zamanla değişir, değişmeyen tek şey TV logolarıdır'. Videodaki değişmeyen bu sabit alanları (TV logolarını) bulabilmek için zamana göre ortalaması alınmış ayrıtlardan yararlanılmıştır. TV logo sınıflandırması kısmında ise sınıflandırıcı olarak Karar Destek Makinesi (SVM) kullanılmıştır. TV logolarını en iyi temsil edebilecek öznitelikleri belirleyebilmek için yaygın kullanılan bazı altuzay analiz yöntemlerinden Temel Bileşenler Analizi (PCA), Negatif Olmayan Matrislerde Çarpanlara Ayırma (NMF), Bağımsız Bileşenler Analizi (ICA) ve Ayrık Kosinüs Dönüşümü (DCT) yöntemleri karşılaştırılmıştır. Bu altuzayanaliz yöntemlerini uygulayabilmek için tüm logo imgeleri Izgara Öznitelikleri (GD) kullanılarak sabit boyutlu gösterime dönüştürülmüştür. Sınıflandırma deneyleri için 152 farklı kanaldan toplanmış 3040 imgeden oluşan bir logo veritabanı oluşturulmuştur. En iyi sonucu %99.21 ile ICA2 vermiştir. Logo tespit ve tanılama deneyleri için ise Türkiye'de en çok izlenen 12 TV kanalından kayıtlar yapılmış ve 240 kayıttan oluşan bir veritabanı oluşturulmuştur. Önerilen sistem ile logo tespiti için %99.17, logo tanılama için ise %96.03 gibi başarım oranlarına ulaşılmıştır. Yapılan deneyler sonucunda önerilen TV logo tanılama sisteminin yüksek başarım oranlarıyla çalıştığı ve izleyici oranlarını ölçme sürecinde kullanılabileceği gösterilmiştir.","Television (TV) logos are the only semantic objects that appear commonly in all TV broadcast videos. And they can be utilized in the development of many useful applications such as TV commercial detection, and audience measurement. In this study, we have developed an automatic TV logo identification system. The proposed TV logo identification system consists of two parts, namely, TV logo detection and TV logo classification.In the TV logo detection part, we utilized from the idea that `the broadcast video content is changing over time except the TV logos' and we used time averaged edges method to obtain static regions (TV logos) in broadcast videos. In the TV logo classification part, we have used Support Vector Machine (SVM) as classifier. We have compared some well known subspace analysis methods such as Principle Component Analysis (PCA), Non-negative Matrix Factorization (NMF), Independent Component Analysis (ICA), and Discrete Cosine Transform (DCT) to find best feature to describe TV logos. Before applying the subspace analysis methods, all logo images are converted into a fixed size representation by using Grid Descriptor (GD) method. For classification experiments, a TV logo DB of 3040 images is constructed from 152 different TV channels. The best classification performance is obtained by ICA2 with an accuracy rate of 99.21%.For the logo detection and identification experiments, we have collected 240 videos from the 12 most popular TV channels of Turkey. The proposed system achieves to 99.17% logo detection rate and 96.03% average accuracy rate for logo identification. Results of the experiments show that the proposed TV logo identification system works with high accuracy rates and can be utilized in an audience measurement process."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, gözetimli öğrenmede birden çok modelin, sınıflandırma başarısını artıracak ve karmaşıklığı denetim altında tutacak bir şekilde birleştirilmesi amaçlanmıştır. Bunun için iki yöntem önerilmiş ve bilinen tek ve çok gösterimli veri kümeleri üzerinde, standart sınıflandırıcılar kullanılarak yapılan benzetimlerle bu yöntemler sınanmıştır.Literatürde, birbirinden farklı sınıflandırıcılar üretmek için birçok yöntem önerilmiştir. Bunların arasında, (i) Farklı algoritmalar, (ii) Farklı üstparametreler, (iii) Farklı girdi altkümeleri, (iv) Farklı girdi gösterimleri ve (v) Öğrenme kümesinin farklı örneklemlerini sayabiliriz. Bu tezde, bu yöntemlerin sınıflandırıcılar arasındaki ilintiyi azaltmakta etkili olmadığını gösteriyoruz. Bunun yanında, ilinti ve hata arasındaki bağıntıyı ortaya koyarak, ilintinin üç değişik durumu için, sabit ve eğitilmiş birleştirme kurallarının hatalarının nasıl değiştiğini gösterdik. Bu durumlar: (i) Bağımsız sınıflandırıcılar, (ii) Eşilintili sınıflandırıcılar ve (iii) İlintili sınıflandırıcı gruplarıdır. Yapılan benzetimlerde, toplama kuralının ve eğitilmiş doğrusal birleştiricinin, ilintiye karşı en gürbüz davranışı gösterdiğini gözlemledik. Bu konuda yapılan önceki çalışmalarda sınıflandırıcıların bağımsız oldukları varsayılmıştır, ilintili olan durumdaki incelemeler bu çalışmaya özgündür.Taban sınıflandırıcılar arasındaki ilintiyi kaldırmak için iki algoritma öneriyoruz. Bunlar: (i) Başarıyı artırırken aynı zamanda maliyeti, yani zaman ve bellek karmaşıklığını da göz önünde tutan, Icon isimli, artırımlı bir birleşik sınıflandırıcı oluşturma algoritması ve (ii) Birleştirmeden önce ana bileşenler analizi ya da doğrusal ayırtaç analizi yardımıyla ardıl işlem yaparak ilintisiz üstsınıflandırıcılar üreten bir algoritmadır.Icon algoritması ilintili sınıflandırıcılar arasından altküme seçmektedir. Algoritmanın üç boyutu vardır: (i) Arama yönü (ileri, geri, kayan), (ii) Model değerlendirme ölçütü (başarı, çeşitlilik ve model karmaşıklığı) ve (iii) Birleştirme kuralı (sabit kurallar, eğitilmiş doğrusal birleştirici). Otuz sekiz veri kümesi üzerinde, on dört sınıflandırıcı kullanılarak yapılan benzetimlerde, model seçme ölçütü olarak başarının ve birleştirme kuralı olarak da toplama kuralının en iyi olduğu sonucuna varılmıştır. Diğer yaklaşımlar bu iki seçeneğe göre daha az yeğlenir sonuçlar vermektedir. Bilimsel yazında daha önce de altküme seçme çalışmaları yapılmıştır, ama bu tezdeki çalışma diğer çalışmalara göre, kapsam, veri kümesi ve sınıflandırıcı sayısı açısından daha geniştir. Bu yöntem kullanılarak, en iyi taban sınıflandırıcıdan ve tüm sınıflandırıcıları kullanmaktan daha başarılı sonuçlara ulaşılmış, en iyi altkümeden ise daha kötü olmayan fakat daha basit olan birleşik sınıflandırıcılar üretilmiştir. Çok gösterimli veri kümelerine uygulandığında, Icon'un otomatik olarak farklı gösterimlerle eğitilmiş ve birbirini tamamlayan sınıflandırıcılar seçtiğini gözlemledik.İlintili sınıflandırıcıların çıktılarını ilintisiz hale getirmek için temel bileşenler analizi kullanan Pca ve doğrusal ayırtaç analizi kullanan Lda algoritmaları ilintisiz üstsınıflandırıcılar oluşturmakta ve bu üstsınıflandırıcılar, doğrusal sınıflandırıcı kullanılarak birleştirilmektedirler. Az sayıda üstsınıflandırıcı, bu yöntemin başarılı olması için yeterli olmaktadır. Bu tezde yapılan çalışma, çok sayıda sınıfa genelleştirilebildiği, çok gösterimli veri kümelerine uygulanabildiği ve bilgi özütleyerek sonuçların yorumlanabilmesini sağladığı için yeni bir çalışmadır. Bu yöntemde, temel bileşenler analizi, doğrusal ayırtaç analizine göre daha başarılı olmuştur.Genel sonuç olarak, ilintiyi ortadan kaldırmak için kullanılan bu iki yöntemin karşılaştırılmasında, eğer amaç karmaşıklığı azaltmak ise, altküme seçmenin daha iyi olduğu, başarının daha önemli olduğu durumlar içinse öznitelik çıkaran üstsınıflandırıcıların kullanılmasının daha öne çıktığı görülmüştür.","In this thesis, the main purpose is to combine multiple models to increase accuracy, while at the same time keeping a check on complexity. Towards this aim, we propose two methods, and these methods are tested by simulations using well-known classification algorithms on standard uni- and multi-representation data sets.In the literature, methods have been proposed to create diverse classifiers. These methods change: (i) Algorithms used for training, (ii) Hyperparameters of the algorithms, (iii) Training set samples, (iv) Input feature subsets, and (v) Input representations. In this thesis, we show that these methods are not enough to decrease the correlations among base classifiers. Furthermore, we present the relation between error and correlation for fixed combination rules and a linear combiner, using three different cases. The cases are: (i) Independence, (ii) Equicorrelation, and (iii) Groups. We see that, the sum rule and the trained combiner show the most robust behavior to changes in correlation. Previous studies in the literature assume that the base classifiers are independent, the analysis in the presence of correlation, as presented in this thesis, is novel.To remove the correlation between classifiers, we propose two algorithms to construct ensembles of multiple classifiers: (i) An incremental algorithm, named {\sc Icon} which generates an ensemble of multiple models (representation/classifier pairs) to improve performance, taking into account both accuracy and the concomitant increase in cost, i.e., time and space complexity, and (ii) An algorithm which post-processes before fusing, using principal component analysis ({\sc Pca}) and linear discriminant analysis ({\sc Lda}) to form uncorrelated metaclassifiers from a set of correlated experts.{\sc Icon} chooses a subset among correlated base classifiers. The algorithm has three dimensions: (i) Search direction (forward, backward, floating), (ii) Model evaluation criterion (accuracy, diversity and complexity), and (iii) Combination rule (fixed rules or a trained combiner). Our simulations using fourteen classifiers on thirty eight data sets show that, accuracy is the best model selection criteria and sum rule is the best combination rule. Other approaches create less preferred results compared to these two. There has been studies of subset selection in the literature, but the work in this thesis has a larger number of classifiers and data sets and its scope is wider. Using this method, we create ensembles which are more accurate than the single best algorithm and using all algorithms; and which are not worse than the optimal subset using smaller number of base classifiers. When applied to multi-representation data sets, we see that {\sc Icon} automatically chooses classifiers which combine different representations and generates a set of complementary classifiers.{\sc Pca} which uses principal component analysis, and {\sc Lda} which uses linear discriminant analysis create uncorrelated metaclassifiers from correlated base classifiers and these metaclassifiers are combined using a linear classifier. This method is successful with a small number of components and has the same accuracy as combining all classifiers. The work in this thesis allows generalization to multiple classifiers, combines multiple representations, allows knowledge extraction, and is novel in these respects. In this method, principal component analysis is more successful than linear discriminant analysis.As the overall result, in comparing these two methods which get rid of correlation, we see that if the aim is to decrease complexity, then subset selection is better; if the aim is higher accuracy, we should prefer metaclassifiers which extract knowledge and has redundancy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ağ ömrü, Telsiz Algılayıcı Ağlar (TAA) gibi kısıtlı ve yenilenemez enerji kaynağına sahip düğümlerden oluşan ağlar için kullanılan yeni bir başarım ölçütüdür. Kullanıcılarının bir TAA'dan edindikleri toplam faydays işaret etmesi bakımından ağ ömrü dikkatle değerlendirilmesi gereken önemli bir göstergedir. Bu bağlamda ağ ömrü bir TAA kullanıcısının yaptığı toplam yatırımın ne derece geri döndüğünü de ifade etmektedir. Ancak uygulamaya bağımlı olduğu için TAA'ların ağ ömrünü belirlemek, gecikme gibi geleneksel ağ başarım ölçütleriyle karşılaştırdığımız zaman daha karmaşık olmaktadır. Uygulama bağımlılığı TAA alanında sıklıkla karşılaşılan ve araştırma problemlerine genelleştirilmiş çözümler bulmayı engelleyen bir etmendir ve ağ ömrü ölçümü probleminde de durum benzerdir.Bu çalışmada TAA'larda ağ ömrünün belirlenmesine uygulama bağımlılığı da katabilmek için bir çatı geliştirdik. Ağ ömrü ölçütünün ağ başarımını değerlendirmedeki önemi ve etkisini göstermek için ortaya koyduğumuz niceleme çatısını kullanarak video taşıyan ağ tiplerini de içerecek değişik uygulama senaryoları içeren deneyler gerçekleştirdik. Çalışmamızda uygulama seviyesindeki tanımlamaları dikkate almayan ağ ömrü ölçütlerinin TAA ağ ömrü nicelemesinde yetersiz kaldığını gösterdik.Önerdiğimiz metod, ATİZ (Ağırlıklı Toplam İşlevsel Zaman), iki farklı mekanizmayı içiçe kullanarak gerçekçi ve uygulamaya bağlı ağ ömrü nicelemesini gerçekleştiremektedir. İlk olarak, ATİZ bir fayda fonksiyonu aracılığıyla ağın kullanıcılarının kendi uygulama seviyesindeki gereksinimlerini sistematik olarak ifade etmelerine olanak vermektedir. Böylece ATİZ ağ ömrü nicelemesi probleminde içsel olarak bulunan, uygulama bağımlılığından kaynaklanan öznelliği, üzerinde matematiksel işlem yapılabilir hale getirerek bertaraf eder. Bahsi geçen fayda fonksiyonu ağdaki düğümlerin ortaklaşa ürettiği toplam yararı göstermektedir. İkinci olarak metodumuz, ağın yarattığı yararın kabul edilemez sınırların içinde olduğunu gösteren tek bir eşik tanımlayarak niceleme yapmak yerine değişen fayda seviyesini kullanıp ağ tarafından sunulan toplam işlevi zamanda ağırlıklı biçimde kaydetmek yoluyla daha yüksek çözünürlüklü ağ ömrü ölçümü yapmaktadır. Böylece sadece tek bir eşik değeri tanımlayan ağ ömrü ölçütlerinden farklı olarak ATİZ, ağın yararının bittiği noktaya kadar farklı yarar seviyelerinden geçerek gelen TAA'ların başarımlarını farklı rakamsal değerler ile ifade edebilmektedir.","Network lifetime is a novel performance metric that is used to evaluate networks comprised of nodes with irreplenishable energy sources. Wireless sensor networks (WSNs) are the primary examples of such networks. The network lifetime is a crucial performance metric since it indicates the amount of functionality obtained in return to the total investment including the sensor hardware, the deployment, and the administrative work. Unlike the legacy network performance metrics such as delay, throughput or jitter, the evaluation of network lifetime is not straightforward because of the application dependence involved. Application dependence is a recurring theme in the WSN domain that inhibits finding generalized solutions to the research problems, where the network lifetime quantification is no exception. In this work, we devise a framework for incorporating the application dependence into the lifetime measurement process of the wireless sensor networks, thereafter via extensive experiments, demonstrate the significance of the lifetime metric itself in the quantification process for a variety of application scenarios including both scalar and video based wireless sensor networks. We show that the lifetime metrics that ignore application dependence fail in solving the network lifetime quantification problem in WSNs. Our proposed framework, weighted cumulative operational time (WCOT), combines two distinct mechanisms for realistic and application context aware network lifetime evaluation. Firstly, by introducing the \emph{utility function} it enables the users of the network to inscribe their own application level requirements in a formal setting. This clarifies the inherent subjectivity due to the application dependence involved in the WSN network lifetime quantification problem by transforming it into a form that renders further computation possible. The utility function denotes the total cumulative utility (usefulness) offered by the collaboration of the sensor nodes. Secondly, instead of offering a single cut-off threshold value for defining the point after which the network is assumed to be nonfunctional, WCOT framework makes use of the gradual change in the utility of the network and record how the network evolves over time in terms of functionality offered by keeping the weighted sum of the operational time. Unlike lifetime metrics that focus on a single threshold value, WCOT is able to differentiate network performances that differ in how the network evolves till the utility drops to zero."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, duraklamasız, işaretlenmiş Türkçe videolarından otomatik ayrık işaret çıkarımı yapan bir yöntem geliştirdik. İşaretlenmiş Türkçe, Türk işaret dilindeki işaretlerin, Türkçe konuşma diline ait dilbilgisi kuralları dahilinde kullanılmasından oluşmuş görsel bir dildir ve el şekli ile el hareketlerinden oluşur. Duraklamasız işaret dilinde peş peşe yapılan işaretler birbirlerini etkileyebilir ve işaretlerin başında ve sonunda değişimler olabilir. Bu da ayrık işaret çıkarımını zorlaştırır. Bu çalışmada, el işaretleri bilgisini kullanarak Türk işaret dilinde sıklıkla kullanılan bazı işaretlerin ayrık çıkarımını yapmayı amaçladık. Kullandığımız yöntem iki adımdan oluşmaktadır: İlk olarak, el takibi modülü kullanılarak elde edilmiş el bölgelerine bölütleme uygulayıp sadece sağ veya sol eli içeren resimler elde ettik. Daha sonra el işaretlerini çeşitli yöntemler kullanarak betimledik. Bunlar şu şekilde sıralanabilir: 1) Ellerin merkez koordinatları ve bu koordinatların türevleri, 2) Her bir el için elips değişkenleri, 3) Ayrık kosinüs dönüşümü, 4) Yönlü Gradyan Histogramı, 5) Yerel Ikili Örüntü yöntemi, 6) Hu momentleri, ve 7) Işınsal Uzaklık fonksiyonu. Daha sonra işaret dizilerini çeşitli yöntemler kullanarak hizalayıp işaretlerin başlangıç ve bitiş noktalarını bulduk. Hizalama yöntemleri olarak dinamik zaman bükmesi (DTW), saklı Markov modeli (HMM) ve bağlaştırılmış HMM kullandık. Ayrıca sistemimizin başarımını arttırmak amacıyla bazı tümleştirme yöntemleri uyguladık. Sistemimizin başarımını işaretlenmiş Türkçe videolarından oluşan bir veri tabanı üzerinde gösterdik. Buna göre, DTW ile HMM algoritmaları birleştirildiğinde ve öznitelik olarak merkez koordinatları, bu koordinatların türevleri, ve elips değişkenleri kullanıldığında en yüksek başarımı elde ettik.","In this thesis, we attack the problem of extracting isolated signsfrom continuous signed speech videos. Signed speech is a languagethat uses the signs of sign language and the grammar of spoken language.It is a visual language and makes use of hand gestures, whichconsist of hand motion and hand shape. In continuous signedspeech, signs are expressed in succession, whichresults in coarticulation effects, making segmentation a challengingtask. In this work, we aim to segment some of the most common signsin Turkish Sign Language using hand gesture information. Thisprocess consists of two consecutive steps: First, we apply segmentationto hand regions obtained from a hand tracking module andobtain images containing only the left or the right hand. Then, werepresent hand gestures by a variety of features which can becategorized as follows: 1) Center of mass coordinates of each handand their first-order derivatives, 2) Ellipse parameters for eachhand, 3) Discrete CosineTransform, 4) Histogram of oriented gradients, 5) Local BinaryPatterns, 6) Hu Moments, and 7) Radial Distances. Then, we alignthe sequences with different methods and find the startand end positions for each sign. We use Dynamic Time Warping (DTW), HiddenMarkov Models (HMM), and coupled HMMs as differentalignment approaches. We also apply some fusion techniques toimprove the alignment performances. We experiment on a database fromTurkish signed speech videos and report the results. We see that thehighest accuracy is obtained by combining the DTW and HMM methods usingCenter of mass coordinates, their first-order derivatives, and Ellipsefeatures."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Eş zamanlı yer bulma ve haritalama (SLAM) problemi robot gezinmesi alanındaki en zor problemlerden biridir. Bu problem, ortam hakkında önceden bir bilgi verilmeden, bilinmeyen bir ortamın otonom olarak keşfedilmesini ve haritalanmasını içerir. Robot, ortamın haritasını çıkarmalı ve aynı zamanda kendi yerini bu haritaya göre tahmin etmelidir. Bu problemin dağıtık çoklu robotlar uzerine genişletilmesi de zorlukları ve vaatleri sebebiyle popüler bir konudur. Aynı ortamı yardımlaşarak gezen çoklu robotlar keşfetme süresini azaltabilir ve tahminin doğruluğunu artırabilir.Bu tez, görsel algılayıcıları olan ve aynı işaretçili haritada çoklu robotlar üzerinde en başarılı SLAM çözme yöntemlerinin uygulanmasını sunar. Literatüre iki katkı sağlanmıştır: EKF-SLAM yönteminin parametreleri denetlemeli veri ile Evrimsel Stratejiler yöntemi tarafından kalibre edilmiştir. Yeni bir belirsizlik yayılması ile harita birleştirme yöntemi Fast-SLAM yöntemi için sunulmuştur. Deneyler hem benzetim ortamında hem de gerçek ortamda denenmiş ve geliştirilen yöntemlerin ilerleme ve uygulanabilirliği test sonuçları ile gösterilmiştir.","The Simultaneous Localization and Mapping (SLAM) problem is one of the mostchallenging problems in robot navigation. The problem addresses autonomously ex-ploring and mapping an unknown environment without prior knowledge (of features).The robot should generate the map of the environment and estimate its pose with re-spect to the map. An extension of this problem to the distributed multi-robot platformis a popular research topic for its challenges and commitments. Multiple cooperativerobots exploring an area would decrease exploration time and increase the accuracy.This thesis introduces the application of two successful SLAM solution techniquesto the multi-robot domain using visual sensors and non-unique landmarks. There aretwo contributions to the literature: Evolutionary Strategies (ES) is used to calibratethe parameters of the Extended Kalman Filter-SLAM (EKF-SLAM) method with su-pervised data, and a novel map merging method with uncertainty propagation is in-troduced for the Fast-SLAM algorithm. The developed algorithms are tested in bothsimulated and real robot experiments and the improvements and applicability of thedeveloped methods are shown with the results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hedef tespit ve izleme uygulamalarında, telsiz muhabere yeteneğine sahip küçük algılayıcılar harekat sahasına çok yakın olarak yerleştirilebildikleri için doğru bilgi sağlarlar. Bu küçük algılayıcılar hedef tespit ve izleme hassasiyetlerini arttırmak için birbirleri ile ortak çalışma yeteneğine sahiptirler. Telsiz muhabere yeteneğine sahip küçük algılayıcılar için enerjilerini verimli olarak kullanabildikleri dağıtık bir hedef izleme algoritması geliştirilmiştir. Bu algoritma ile hedefi tespit eden algılayıcılar arasında en fazla bilgiye sahip ve mükerrer bilgi taşımayan algılayıcıların bu bilgilerini komşu algılayıcılar ile paylaşması ile hedef takip doğruluğundan çok fazla kaybetmeden algılayıcı ağın yaşam süresi uzatılmıştır. Dağıtık veri birleştirme mimarisi, algılayıcıların ortak çalışabilmeleri için gerekli altyapıyı sunar. Bu küçük algılayıcıların enerji tahditleri nedeni ile genel bir eğilim, bazı algılayıcıları geçici olarak pasif duruma getirmektir. Enerji tasarrufunu arttırmak amacı ile, karşılıklı en fazla bilgi içeriğine dayalı seçici bir algılayıcı etkinleştirme algoritmasına ek olarak, bilgi içeriği ile kontrol edilen sinyal gönderme gücü ayar düzeni geliştirilmiştir. Müşterek hedef izleme için geliştirilen güç ayar düzeni algoritmasının özü, hedef hakkında daha fazla bilgiye sahip olan algılayıcıların daha az bilgiye sahip olan algılayıcılara göre daha fazla çıkış gücü kullanarak bilgilerini etraflarındaki algılayıcılarla paylaşmaları esasına dayanır. Tek bir hedefin izlenmesi için yapılan çalışmalar birden fazla hedefin izlenmesi için geliştirilmiş ve dağıtık çoklu hedef izleme mimarisi önerilmiştir. önerilen mimariye ait performans testlerinde birden fazla hedefi tespit eden algılayıcıların sadece hakkında en fazla bilgiye sahip olduğu hedef bilgisini komşu algılayıcılarla paylaşmasının enerji tüketimi ve hedef izleme doğruluğu performansları için en doğru karar olduğu sonucuna ulaşılmıştır.Komşu algılayıcılar tarafından rapor edilen temas bilgilerinin, algılayıcıya ait iz listesinde mevcut temaslar ile ilişkilendirme probleminin çözümüne yönelik olarak bulanık mantık kullanan bir ağ iz ilişkilendirme algoritması önerilmiştir. önerilen algoritmada bulanık kurallar, temas ilişkilendirme kararı için kullanılan bulanık değişkenler arasında bir oylama mekanizması kullanılarak oluşturulmuştur. İz listesindeki temas ile komşu algılayıcı tarafından rapor edilen temas arasındaki Euclid mesafesi, olabilirlik ve Mahalanobis mesafesi ilişkilendirme kararını destekleyen bulanık değişkenler olarak kullanılmışlardır. önerilen algoritmanın, zikzaklı yolalan hedefler için temas ilişkilendirme performansını Euclid, olabilirlik ve Mahalanobis metrikleri kullanılarak yapılan ilişkilendirmelere göre arttırdığı, bunun sonucu olarak hedef takip doğruluğunu arttırdığı benzetim ile gösterilmiştir.","In this thesis we aim to design efficient algorithms for wireless ad hoc sensor networks that are supporting network centric warfare operations. These algorithms should conform to the hard end to end QoS requirements. They should be energy efficient. They should fuse and aggregate data to reduce the network traffic and obtain more accurate assessment of the environment. A particular challenge in the wireless sensor network setting is the need for distributed estimation algorithms which balance the limited energy resource at a node with the cost of communication and sensing. Distributed processing strategies that use a subset of sensor measurements directly mitigate the volume of inter-node communication thereby conserving power. The challenge is to decide in an intelligent manner which sensor measurements to use. In other words, to select a sensor that is likely to provide the greatest improvement to the estimation at the lowest cost.For target tracking applications, wireless sensor nodes provide accurateinformation since they can be deployed and operated near the phenomenon. Thesesensing devices have the opportunity of collaboration among themselves toimprove the target localization and tracking accuracies. An energy-efficientcollaborative target tracking paradigm is developed for wireless sensornetworks (WSNs). A mutual information-basedsensor selection (MISS) algorithm is adopted for participation in the fusionprocess. MISS allows the sensor nodes with the highest mutual information about the target state totransmit data so that the energy consumption is reduced while the desired target position estimationaccuracy is met. In addition, a novel approach to energy savings in WSNs isdevised in the information-controlled transmission power adjustment (ICTP), where nodes with more information use higher transmission powers than thosethat are less informative to share their target stateinformation with the neighboring nodes. Simulations demonstrate the performance gains offered by MISS and ICTP in terms of power consumption and target localization accuracy.A fully-distributed collaborative multi-target tracking framework thateliminates the need for a central data associator or a central coordinatingnode for wireless sensor networks is defined. Details of the distributed dataassociation architecture, which is more feasible than the ones relying on acoordinating entity, is described. It is shown that for target trackingapplications, the collaboration improves the target localization performance ofthe distributed data collecting devices. In order to reduce the communicationenergy exhausted for collaboration, the performance of the collaboration logicmanager is examined. Simulation results show that collaborating about a singletarget information is a rational decision. The problem of deciding which targetinformation to collaborate among the detected targets arises. A mutualinformation based metric is shown to be a good candidate for deciding on the targetwhich the sensor will collaborate about with the network.A fuzzy network association algorithm (FUNA) for associating the target report from the neighboring sensor node with a track in the track list is described. The rule base of FUNA is created by consulting to the result of a voting mechanism among the fuzzy variables to support the association decision. Euclid distance, direction difference, and speed difference between the track report from the neighboring sensor node and the track in the track list are the fuzzy variables that support FUNA. It is shown by simulation that FUNA reduces the number of false network associations for the meandering targets. Moreover, better target localization accuracies achieved by FUNA when compared to the Euclid, likelihood, and Mahalanobis distance based network association metrics."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sayısal elektronik, mini-elektro-mekanik sistemler ve kablosuz haberleşme teknolojilerindeki ilerlemeler neticesinde; algılayıcı, işlemci ve kablosuz haberleşme yeteneklerinin küçük boyutlardaki bir cihazda bütünleştirilmesi mümkün hale geldi. Bu tezde, kablosuz algılayıcı ağlarda hedef takibi meselesine odaklandık. İlk etapta, bulanık çıkarsama yöntemi kullanarak yeni bir yardımlaşmacı mantık üretmeye çalıştık. En çok bilgi ihtiva eden algılayıcının bilgisini yayması amacıyla daha iyi bir algılayıcıyardımlaşma ölçütü elde etmek için Öklid mesafesi ve karşılıklı bilgi miktarı ölçütlerini bulanık üyelik fonksiyonları olarak kullandık. İkinci hedefimiz, M/N-tabanlı yenibir ilklendirme mantığı kullanarak parazit yankının (saçıntı) olduğu ortamlarda, birhedef takip sisteminin hedef ilklendirme süreç başarımını iyileştirmektir. Genel M/Nilklendirme mantığında, geçit içindeki ardışık sezimler eş ağırlıkla değerlendirilirve ilklendirme sayacı bir artırılır. Ancak, eğer geçitteki yeni sezimlenen gözlemleröngörülen hedef konum merkezinden uzaksa, gözlemler gerçek bir hedef olmayabilir, ölçümün kaynağı parazit yankı olabilir. Bu nedenle, hedef ilklendirme kararı için M/N mantığı kullanırken gözlemin ilklendirme sayaç ağırlığını mesafe miktarına göre ayarlamalıyız. Bu amaçla, ilklendirme sayacı ağırlık değerini belirlemek için ceşitli ağırlıklandırma tasarımları planladık. Sonuç olarak, parazit yankının olduğu ortamlarda, M/N hedef ilklendirme mantığı için oval ağırlıklandırma tasarımı kullanmak;yanlış hedef ilklendirmelerini azaltıp, doğru hedef ilklendirmelerinin kabul edilebilir birseviyede idamesini sağlayarak umut verici sonuçlar vermektedir.","According to the advances in digital electronics, micro-electro-mechanical systems and wireless communication technologies, it is viable to integrate a device with sensing, computing and wireless communication capabilities within tiny dimensions. In this thesis, we focus on the target tracking issues on wireless sensor networks. First, we try to generate a new collaboration logic via a fuzzy inference system. We utilize Euclidean distance and mutual information metrics as the fuzzy membership functions to achieve a better sensor collaboration measure in order to lead most informative sensor node to broadcast its information. Our second aim is to improve the performance of the track initiation process of a target tracking system in cluttered environments via a new M/N-based track initiation logic. In generic M/N logic, the consecutive detections inside the gate are considered with identical weights and the initiation counter is increased by one. However, if the newly detected observations in the gate are away from the center of the predicted target position, the observations may not be a real target, the origin of the measurement may be the clutter. Thus, we should adjust the initiation counter weight of the observation according to the distance measure while utilizing M/N logic for the track initiation decision. For this purpose, we envisage different weighting schemes to determine the initiation counter weighting value. Consequently, elliptical weighting scheme for the M/N track initiation logic shows promising results for cluttered environments in terms of decreasing the false track initiations while sustaining an admissible level of true track initiations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılımda efor tahmini, yazılım mühendisliğindeki temel sorunlardan biri olagelmiştir ve dahaönceki calışmalarcoğunlukla modellerin tahmin kesinliğini arttırarak sonuçlardakiyüksek dalgalanmaları gidermeye odaklanmıştır. Bu modeller tümsel tahmin doğruluğunadayanan MRE (görece hata büyüklüğü) veya Pred(r) gibi değerlendirme kriterleri kullanılarakdeğerlendirilir.Uygulayıçılar ve araştırmacılar belli özellikteki yazılım efor tahmin modellerineihtiyaç duyarlar. Bu özellikler: 1) Modeli kurmak için kullanılan veriyi anlayabilmekve 2) kesin tahminler sunabilmek. Biz bu çalışmamızda açgözlü yığınlayçı gruplamaalgoritmasını (AYG) yazılımda efor tahmini alanına uyarlıyoruz ve modelimizi (AğaçTahmin ve Değerlendirme Bilgisi - ATDB) kurmak için onu benzerlik tabanlı tahminleyiciolarak kullanıyoruz. AYG tabanlı modelimizi, ATDB, kullanarak her bir testprojesi için bir benzerlik sayısı (k) sağlamayı ve tüm veri kümelerinde diğer k-tabanlıyöntemlerden daha düşük MRE değerleri elde etmeyi başardık.Durum Tabanlı Muhakeme (DTM) yöntemleriyle ilgili olarak özellik altkümesiseçme, ölçeklendirme, kullanılacak benzerlik ölçüsü ve kullanılacak benzerleri (uygunk değeri) seçme gibi pek çok sorun bulunmaktadir. Bizim çalışmamızdaki temelamacımız uygun k-değeri bulmak olduğundan, DTM yöntemleriyle ilgili diğer sorunlarbu çalışmamızda irdelenmeyecektir.ATDB ile veriyi daha iyi anlamak ve her test örneği için farklı sayıda benzerler seçmekmümkün olmuştur. ATDB, test projesi için alakasız benzerleri budayarak kullanılacakuygun sayıdaki benzerleri bulur. Bu yaklaşım tahminsel kesinlik bakımından tüm diğerk-tabanlı DTM yöntemlerinden 100% ve üzerinde daya iyi sonuçlar vermiştir.","Software effort estimation has been one of the major challenges in softwareengineering and previous research has mainly focused on addressing the large deviationproblem in estimations by improving prediction accuracies of models. These modelsare evaluated using measures such as MRE or pred(r), which all assess the models onthe basis of overall prediction accuracy.Practitioners and researchers require a software effort estimation model with thefollowing properties: 1)Understand the data that is used to build the model and 2)provide accurate estimations. In our study, we adapt greedy agglomerative clusteringalgorithm (GAC) to software effort estimation domain and use it as an analogy basedestimator to build our model: Tree Estimation and Assessment Knowledge (TEAK).By using GAC based model, TEAK, we are able to provide an analogy number (k)to be used for each individual test project and get lower MRE values than any otherk-based method in all datasets.There are multiple problems with case based reasoning (CBR) methods suchas feature subset selection, scaling, similarity measure and number analogies to use(suitable k value). As our intention in this research was to focus on the problem offinding the suitable k value, we do not address other CBR related problems and stickto the dynamic selection of a suitable k value for each single test instance.With TEAK it is possible to better understand the data on which effort estimationis to be done and use different number of analogies (k value) for each test instance.TEAK prunes irrelevant analogies in train set for a test project and thereby finds thenumber of analogies to be used during estimation. This approach has outperformed allother k-based CBR methods in terms of predictive accuracy up to more than 100%."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mürettebat zaman çizelgesi problemi iki alt probleme bölünür, uçuş dizisi bulma problemi ve mürettebat atama problemi. Literatürde uçuş dizisi bulma problemi üzerinde çok çalışma vardır ve bu çalışmanın da ana konusu budur. Bu çalışmada önceki metotlar incelenerek hibrid bir metod geliştirilmiştir.Bu çalışmada uçuş dizisi bulma probleminin matematiksel ifade ediliş şekli açıklandı. Temel olarak problem tamsayı programlama problemi şeklinde ifade edilir fakat problemdeki karmaşıklığı azaltmak için doğrusal programlama problemine çevriliyor. Doğrusal programlama problemlerini çözmek için kullanılan en iyi bilinen metot Sprint methodudur. Ayrıca önceki çalışmalarda adı dinamik uçuş dizisi üreten olan bir metot geliştirildi. Genellikle doğrusal programlama problemi çözüldükten sonra tamsayı değerleri bulmak için parçala ve sınırla veya art arda uçuşlara göre parçala yöntemi kullanılıyor. Ayrıca doğrusal programlama problemini çözdükten sonra tamsayı değerleri bulmak için kullanılan diğer bir metot da Carmen algorithmasıdır. Hibrid metotda doğrusal programlama problemini çözmek için Sprint metodu kullanıldı. Doğrusal programlama problemi çözüldükten sonra tamsayı değerleri bulmak için Carmen algorithması uygulandı. Deneyler gösterdiki Carmen algoritması çok hızlı fakat çok kötü sonuçlar veriyor. Bu nedenle yine Sprint metodu ile başlayan ve tamsayı değerler bulmak için art arda uçuşlara göre parçala yöntemini kullanan bir başka hibrid versiyonu uygulandı. En son kısımda Carmen algoritması ile art arda uçuşlara göre parçala yönteminin deneylerde çıkan sonuçlarının karşılşatırması verildi. Sonuç olarak ise hibrid metodunun kısa bir özeti açıklandı ve gelecekte yapılabilecek çalışmalar verildi.","Crew scheduling problem is divided into two sub problems, crew pairing and crew assignment problems. In literature, there are many studies on crew pairing problem and in this study also main subject is crew pairing problem. In this thesis, previous work on crew pairing problem is investigated and a hybrid method is developed by combining previous methods.In this study, the mathematical representation of the crew pairing problem is explained. Basically, the problem is represented as integer programming problem but to reduce the complexity it is relaxed to linear programming (LP) problem. Most well-known method for solving large size of LP is sprint method. Also in previous studies, another method which is called dynamic pairing generation is developed. Commonly for finding integer values after solving LP, branch and bound or branch on follow-on method is used. Also, Carmen algorithm is another method for getting integer values after finding LP solution. In hybrid method, for solving LP problem sprint method is used. For finding integer values, after solving LP problem Carmen algorithm is implemented. Experiments show that Carmen algorithm is very fast but it gives bad results. Therefore, another version of hybrid method is implemented which also starts with sprint method and uses branch on follow-on method to find integer solutions. In the last section, the comparison of the test results between Carmen algorithm and branch on follow-on method is given. As a conclusion a brief summary on hybrid method is explained and for future work is given."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tasarsız araç ağları için önerilen yönlendirme protokollerinin geçerliliği veperformansı çoğunlukla benzetimlerle değerlendirilir. Fakat, rasgele hareketliliğedayalı benzetimler araçların bireysel hareketlerini göz önüne almazlar. Bireysel araçhareketlerinin bir kısmını yansıtan gerçekçi bir hareket modeli tam ve doğru birdeğerlendirme için önemlidir. Bu tezde araçların temel davranışlarını göz önüne alangerçekçi bir hareket modelleme sistemi önerilmektedir. Hareket modelinin birprotokolün değerlendirmesini kayda değer derecede etkileyebileceğini göstermek için,önerilen model AODV ve OLSR yönlendirme protokolleri kullanılarak RandomWaypoint modeline karşı test edilmiştir. Benzetim sonuçları araç hareket modelininyönlendirme protokollerinin performansını etkilediğini göstermiş, hareket modelinintasarsız araç ağlarının başarım değerlendirmesindeki önemini vurgulamıştır.","The validity and performance of routing protocols for Vehicular Ad Hoc Networks (VANETs) are mostly evaluated by simulations. However, simulations based on random mobility fail to consider individual and specific behaviors of nodes. A realistic mobility model that is able to reflect some features of vehicle mobility is important for a more accurate evaluation. In this thesis, a realistic mobility modeling tool, Mobility for Vehicles (MOVE), which considers the basic mobility behaviors of vehicles, is proposed. The proposed model is tested against the Random Waypoint (RWP) model using Ad Hoc On Demand Distance Vector (AODV) and Optimized Link State Routing (OLSR) protocols to show that the mobility model can affect the evaluation of a protocol significantly. Simulation results show that vehicle mobility model effects the performance of routing protocols, emphasizing the importance of the mobility models in the evaluation of VANETs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son yıllarda elektronik ortamda bulunan elektronik kitap, dijital kütüphane ve e-posta mesajları gibi dökümanların miktarı hızla arttı. Bu nedenle, bu kaynakları düzenleme ve idare etme işi daha çok önem kazanmakla birlikte daha da zorlaştı. Metin sınıflandırma, elektronik ortamdaki bu dökümanların düzenlenmesi ve idaresi için geniş ölçüde kullanılmaktadır. Bununla birlikte, metin sınıflandırmada kullanılan veri çok boyutlu olduğu için öznitelik seçme işlemin daha verimli ve kusursuz yapılmasında çok önemlidir.Bu çalışmada, metin sınıflandırmadaki öznitelik seçme metriklerinin yerel ve genel politika kullanarak kapsamlı bir değerlendirmesini yapıyoruz. Yaptığımız deneyler için; boyutları, karmaşıklıkları ve çarpıklıkları farklılık gösteren yedi adet veri kümesi kullandık. Terim ağırlıklandırması için tf-idf metodu, sınıflandırıcı olarak da SVM (Destek Vektör Makinası) kullandık. Hemen hemen tüm veri kümeleri ve metriklerde, az sayıda anahtar sözcük için yerel politikanın, anahtar sözcük sayısı arttırıldığındaysa genel politikanın daha başarılı olduğunu gözlemledik.Mevcut öznitelik seçme metriklerinin değerlendirilmesine ek olarak, özellikle az sayıda anahtar sözcük kullanıldığında yüksek başarım sergileyen yeni metrikler tasarladık. Ayrıca, Uyarlamalı Anahtar Sözcük Seçimi (AKS) adını verdiğimiz bir anahtar sözcük seçme sistemi tasarladık. Bu yöntem, farklı sınıflar için farklı sayıda anahtar sözcük seçimine dayanıyor ve özellikle çarpık veri kümelerindeki başarımı farkedilir derecede geliştirdi.","In recent years, the amount of available documents in the electronic medium such as electronic books, digital libraries and email messages increased rapidly. Therefore, the task of organizing and manipulating these resources has gained more importance and has become more difficult. Automatic text categorization is widely used for organizing and manipulating these documents in the electronic medium. However, since the data in text categorization is very high-dimensional, feature selection is crucial to make the task more efficient and precise.In this study, we make an extensive evaluation of the feature selection metrics used in text categorization by using local and global policies. For the experiments, we use seven datasets which vary in size, complexity and skewness. We use SVM as the classifier and tf-idf weighting for term weighting. We observed that almost in all metrics and datasets, the local policy outperforms others when the number of keywords is low and global policy outperforms others as the number of keywords increases.In addition to the evaluation of the existing feature selection metrics, we propose new metrics which have shown high success rates especially with low number of keywords. Moreover, we propose a keyword selection framework called Adaptive Keyword Selection (AKS). It is based on selecting different number of keywords for different classes and it improved the performance significantly in skew datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Biz bu çalışmada ajan tabanlı dağıtık çizelgeleme sistemlerinin modellenmesi veanalizi için bir yazılım altyapısı ve matematiksel formülasyon sağladık. Nesne yönelimliajan tabanlı sistemlerin altyapısını tanımladık, ve dağıtık sistemlerde gözlenen problemleredeğindik. Ajan bazlı sistemleri derinlemesine incelemek için durum tabanlı modellemetekniğini kullandık.Karar veya kontrol değişkenlerinden oluşturduğumuz seti kontrol politikası olarakadlandırdık. Bu kontrol politikasını, karar süreci, tepki politikası ve karar süreci sırasındakiajan stabilitesinin kombinasyonundan oluşturduk. Değişik kontrol politikalarının sistemeetkilerini test etmek amacıyla bir deney ortamı hazırladık. Bu deney ortamında termintarihlerinin sıkılığı, işlerin gelme frekansı, işlem zamanının dağılımına gore problemleriklasifiye ve test ettik.Bu çalışma sonucunda kontrol politikaları doğru kurulmadıysa çözümmetodolojisinin tek başına iyi sonuçları garanti edemeyeceğini gösterdik. Aynı zamanda bukontrol politikalarının farklı problem tipleri için farklı performanslarla çalıştığını tespitettik. Karar prosesinin zaman alan bir politika olması durumunda karar zamanı içerenpolitikaların anlık cevap veren politikalara gore daha kötü sonuçlar verdiğini, hattatamamen rassal çözüm üreten anlık bir çözüm politikasının bile karar vermesi zaman alanama optimum çözüm üreten bir politikadan daha iyi sonuçlar verebildiğini gösterdik.","In this study we have introduced a mathematical foundation and a framework for themodeling and analysis of agent based distributed scheduling systems. We defined the basicstructure of an object oriented agent based system, and the issues in distributed systems. Inorder to explore the agent based structures deeply, a state based modeling approach is used.We combine a set of decision variables or control variables under the name of controlpolicy. The control policy is comprised of the decision process (DP), response policy (RP),and agent stability during the decision process. To test the impact of various controlpolicies to the performance of the system we set up an experiment with different problemsettings based on due date tightness, the frequency of job arrivals, and processing timedistribution.In this study we have been able to show that the solution procedure by itself does notguarantee a good overall performance in the system when the control policy is not set upcorrectly. Also we have been able to show the performance of these control policieschange from one problem setting environment to another. So it is not possible to say thatone magic solution procedure will be able to solve all the problem sets. It has been showedthat introducing the decision time to the decision process leads to significantly poorerresults compared to instantaneous policies, and even a responsive random dispatch policymay perform well better compared to a takes time control policy equipped with anoptimum dispatch algorithm."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Servis Odaklı Mimari (SOA) farklı is akısları tarafından olusturulabilen ve networküzerinden dagıtılabilir servislerin yaratılması ile olusturulmaktadır. SOA Mimarisiile olusturulması hedeflenen is akısları için ise bir çok dil bulunmaktadır. BPELyakın zamanda ortaya çıkan bir spesifikasyon olmakla birlikte web servis mimarilerive is akıslarını için kolay ve uygun bir dil özelligi tasımaktadır. Dizayn asamasındaBPEL proseslerinin dogrulanması için, BPEL ile yazılmıs proseslere yazılım dogrulamayöntemleri uygulanabilir. Bu çalısma ile BPEL proseslerinin PROMELA proseslerinedönüstürülmesi ve bu dönüstürülmüs PROMELA processlerinin SPIN aracınınyardımı ile dogrulanması gerçeklestirilmistir. Bu çalısmada assign, switch, sequence,empty, while, terminate, scope, flow, throw, invoke, reply, receive, pick, wait ve faulthandlerBPEL aktiviteleri baz alınarak bir PROMELA modeli olusturulmaktadır. Budönüsümü gerçeklestirmek için BPEL2PML diye bir tool implemente edilip, olusanPROMELA spesifikasyonları üzerinde dogrulama islemleri yapılabilabilmistir. BPELproseslerinin PROMELA modellerinin olusturulmasının ardından, SPIN ile dogrulamayapılarak, negatif örnekler, onaylama bildirileri (assertions) ve hiçbir zaman ulasılamayankod parçacıkları tespit edilebilmektedir.","Service Oriented Architecture(SOA) is based on creating services which can bedistributed on a network by different business flows. Business Process Execution Language(BPEL) is a recent specification language to express web service applicationsand business flows in an easier way in SOA implementations. In order to verify thecorrectness of BPEL processes during design, a number of software verification methodscan be applied to BPEL specified processes. In this paper, the translation ofBPEL process specifications into PROMELA specification language and verificationby model checking by SPIN tool are studied. By creating a model of any BPEL process,several verification steps can be applied during design time by the help of SPINtool. A subset of BPEL activities consisting of assign, switch, sequence, empty, while,terminate, scope, flow, throw, invoke, reply, receive, pick, wait, fault handlers and compensationhandlers are modeled to check and verify the processes specified by usingthese activities. With the tool created in this work, a given set of inputs consistingof BPEL source code(s), wsdl files(s) and BPEL descriptor file(s) are used to create aPROMELA model, then the model is verified by using the SPIN model checking toolfor counter claims, assertions and unreachable codes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hata kestirim teknikleri yazılım ürünlerindeki hatalı kod parçacıklarının tespit edilmesinde kullanılır. Yazılım geliştirme sürecinin test aşamasına geçilmeden önce hata kestirimi teknikleri uygulanması, yöneticilerin zaman ve iş gücü gibi kaynaklarınıkodun belirli bölümlerinin test edilmesi için ayırmasına yardımcı olarak kaynakların verimli ve etkili kullanılmasını sağlar. Hata kestirim araçları proje yöneticilerine, yazılım geliştirme sürecinin test kısmını ürün kalitesinden ödün vermeden planlamalarındayardımcı olur.Bu araştırmada yazılım hata kestirimini iki sını ? ı bir sını ? andırma problemi olarak ele aldık. Kestirim modelimizi oluşturmak için otomatik öğrenme teknikleri kullandık. Öğrenme temelli modellerin en uğraştırıcı bölümleri veri toplamaktır. Yazılım mühendisliğinde alan verileri ciddi bir problemdir. Şirketler ve araştırmacılar sıklıkla doğru seviyede veri toplama ile boğuşurlar: Örneğin modül / fonksiyon bazı ile dosya / sınıf bazı seviyeleri. Bu araştırmada doğru veri seviyesi probleminden yola çıktık.Sunduğumuz modeller yazılım ürününün kaynak koduyla ilgili hiyerarşi bilgisini kullanarak kaynak dosya (ya da sınıf) gibi daha üst parçacık seviyelerinde hata kestirimi yapmaktadır. Sunduğumuz modeli geçerli kılmak için NASA, SoftLab ve Eclipse veri setleriüzerinde deneyler gerçekleştirdik. Ayrıca sunduğumuz modelin net etkisini ortaya çıkarmak için kar-zarar analizi de gerçekleştirdik.","Defect prediction techniques are used to address defective sections of source code in software products. Applying a defect prediction technique before proceeding to testing phase of software development helps the managers to allocate their resourcesmore e ? ciently and most core e ? ectively such as time and e ? ort to test certain sections of the code. Defect predictors are useful tools to help project managers to plan test stage during the software development life cycle without compromising on the productquality.In this research we have taken software defect prediction as a two way classi ? cation problem. We have used machine learning techniques to construct our prediction model. One of the challenges in learning based models is the collection of data. In software engineering domain data collection is a major problem. Companies and researchers often struggle to ? nd out the right level of granularity in data collection: i.e. module / function level versus ? le / class level. In this research we have been motivated by the problem of right level of granularity. Our proposed models use the hierarchical structure information about the source code of the software product, in order to perform defect prediction for high level granularity such as source ? les (alsocalled classes).We have run experiments on NASA, SoftLab and Eclipse datasets to validate ourproposed model. Additionally we have also performed cost-bene ? t analysis to evaluatethe net e ? ect of using our proposed model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İnternet kullanımı arttıkça ve web teknolojileri geliştikçe, daha fazla insan İnternet üzerinden yazılım kullanmaya başladı. Web üzerinde yazılım kullanmanın makinadan bağımsız olması, kurulum gerektirmemesi ve kolay olması nedeniyle; web ve masaüstü uygulamaları arasındaki fark azaldı. Web teknolojilerinin kullanım alanı arttıkça, geliştirme çalışmaları hızlandı ve daha fazla insan web üzerinde yaratıcı, kolay kullanımı olan ve akıllı yazılımlar geliştirme üzerine çalışmaya başladı.Bu tez bahsi geçen web uygulamalarının altında yatan temel fikirleri(Web 2.0 ve Servis Odaklı Mimari) konu almıştır. Tezde teknolojiler araştırılmış, kullanıma hazır sistemler ve kütüphaneler incelenmiştir. Sonuç olarak, seçilen kütüphaneler ve sistemler kullanılarak, ilerideki geliştirmeleri kolaylaştıracak yeni bir sistem yaratılmıştır. Web 2.0, Servis Odaklı Mimari ve yeni sistemin faydalarını göstermek amacıyla; seçilen tüm kütüphaneleri bir araya getirip kullanan bir demo uygulaması geliştirilmiştir.","As Internet usage increases and web technologies evolve, more and more people start using software over the Internet. The gap between the web and desktop applications decreases due to the fact that the usage of the software is machine independent on the web; no setup is required and it?s easy. With the widening area of web technologies? usage, the development efforts and technologies advance and more people start to work on creating innovative, easy to use and smart software on the web.This thesis focuses on the most important the concepts that lie under these web applications (Web 2.0 and SOA). In the thesis, the technologies are researched, the ready to use frameworks and libraries are analyzed. As a result, a new framework is built with the chosen libraries for making future developments easier. In order to show the benefits of the Web 2.0 & SOA approach and framework?s capabilities, a demo application is developed that integrates and uses all the chosen libraries for this purpose."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sıkça kullanılan biyometrik yöntemlerden biri olan 3B yüz tanımanınbaşarımı, büyük ölçüde kayıtlamanın doğruluğuna bağlıdır. Buçalışmada kayıtlama yöntemlerini inceledik. Kayıtlama, yüzyüzeylerinin hizalanmasını sa?layarak karşılaştırma yapmayı mümkünkılar. Literatürde en iyi sonuçlar, bir test yüzünün tüm galeriyüzleriyle ayrı ayrı hizalanmasına dayanan birden-tüme kayıtlamayaklaşımıyla elde edilmektedir. Ancak bu yöntemin zaman karmaşıklığıçok yüksektir. Bu sorunu aşmak için, ortalama yüz modeline dayalıkayıtlama yöntemlerini inceledik. Ortalama yüz modeli oluşturmakiçin daha başarılı bir yöntem önerdik. Ortalama yüz modeli tabanlıkayıtlamayı geliştirmek için, yüzleri gruplayarak kategoriye aitortalama modeller ile kayıtlama yapmayı önerdik. şekil uzayındatopaklama sonucu oluşan gruplarla, morfoloji ve cinsiyet bilgisinedayanan grupları karşılaştırdık. Topaklama sonucu, morfoloji vecinsiyete dayalı grupla?manın da varolduğunu gördük. Ortalama yüzmodeline dayalı kayıtlama sayesinde, kayıtlama sonrasında derinlikdeğerlerinin eşit aralıklı örneklenmesi mümkün oldu. Bu yöntem, hemtanıma başarımında hem de karşılaştırma hızında artış sağladı. Yüzuzayında çeşitliliğe neden olan diğer bir etken olarak ifadeyiinceledik. Kayıtlama ve tanıma başarımlarında düşüşe neden olanifadenin etkisini azaltmak için, bölgesel modellerle kayıtlamayapmayı önerdik. Bu nedenle yüzü anlamlı bölgelere bölerek, her birbölge için ayrı bir ortalama bölge modeli elde ettik. Her bir bölgemodeliyle ayrı ayrı kayıtlama yaparak, bölgesel tanıma sonuçlarınıinceledik. İfade değişimlerinden daha az etkilenmesine rağmen, burunya da göz çevresi bölgesinin tek başına yeterli olmadığını ve tümbölgelerin kullanımının tanıma başarımını arttırdığını gördük. Bunedenle bölgesel kayıtlama sonuçlarını tümleştirme yöntemleriylebirleştirerek, tanıma performansını arttırdık.","Three dimensional (3D) face recognition is a frequently usedbiometric method and its performance is substantially dependent onthe accuracy of registration. In this work, we explore registrationtechniques. Registration aligns two faces and make a comparisonpossible between the two surfaces. In the literature, best resultshave been achieved by a one-to-all approach, where a test face isaligned to each of the gallery faces separately. Unfortunately, thecomputational cost of this approach is high. To overcome thecomputational bottleneck, we examine registration based on anAverage Face Model (AFM). We propose a better method for theconstruction of an AFM. To improve the registration, we propose togroup faces and register with category-specific AFMs. We compare thegroups formed by clustering in the face space with the groups basedon morphology and gender. We see that gender and morphology classesexist, when faces are categorized with the clustering approach. As aresult of registering via an AFM, it is possible to apply regularre-sampling on the depth values. With regular re-sampling,improvements in recognition performance and comparison time wereobtained. As another factor causing diversity in the face space, weexplore expression variations. To reduce the negative effect ofexpression in registration and recognition, we propose aregion-based registration method. We divide the facial surface intoseveral logical segments, and for each segment we create an AverageRegion Model (ARM). Registering via each ARM separately, we examineregional recognition performance. We see that even though someregions such as nose or eye area are less affected by expressionvariations, no single region is sufficient by itself and the use ofall regions is beneficial in recognition. We experiment with severalfusion techniques to combine results from individual regions andobtain performance increase."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım endüstrisinde bütçenin büyük bir bölümü proje uygulaması için kullanılmaktadır. Bu nedenle, her yazılım şirketi işgücünü etkin bir şekilde yönetmek zorundadır. Yazılım eforunu doğru şekilde tahmin etmek işgücü yönetimi için temel zorunluluktur.Araştırmacılar yazılım efor tahmininin öneminin farkına 1960'larda varmışlar ve şimdiye kadar aralarında öğrenme tabanlı olanların da bulunduğu birçok model önermişlerdir. Şirketler genellikle az sayıda tamamlanmış projeye ve bundan dolayı yeni projelerin eforunu tahmin etmek için kısıtlı miktarda efor bilgisine sahiptirler. Az miktarda bilgi kullanarak doğru tahminler yapmak zordur. Problem ve tahmin metodları karmaşıklaştıkça küçük veri kümeleriyle efor fonksiyonunu öğrenmek zorlaşır. Bu nedenle, efor tahmini için kullanılan tahmin edicinin performansını arttırmak önemlidir. Birçok araştırmacı güvenilir bir algoritma olarak sinir ağlarını yazılım efor tahmini araştırmalarında tek bir eleman olarak kullanmışlardır. Bu araştırmada, algoritmanın tahmin performansını geliştimeye odaklandık ve bu nedenle tek bir sinir ağı yerine sinir ağı topluluğu kullandık. Bunun yanında çağrışımlı belleği sinir ağı topluluğu ile bir araya getirerek son modeli oluşturduk. Ayrıca, özelliklerin bir kısmını seçmenin efor tahmin performansına etkisini analiz ettik. Bu amaçla, önemli bilginin büyük kısmını taşıyan özellikler bulunur. Ondan sonra ise önerilen modelde efor tahmini yapmak için sadece bu özellikler kullanılır.Önerilen model doğru tahminler sağlamaktadır. Bu nedenle yazılım firmaları bu modeli yazılım efor tahmininleri yapmak ve işgücünü etkili bir biçimde yönetmek için kullanabilir. Öte yandan, deneylerimizin sonuçları daha az özellik kullanmanın tahmin performansını arttırabileceğini gösterdi.","In software industry, most of the budget is used for project implementation. Therefore, each software company has to manage its workforce effectively. Estimating the software effort accurately is essential for workforce management.Researchers became aware of the importance of software effort estimation in 1960?s and so far they have proposed several models, some of which are learning oriented. Companies usually have a small number of completed projects and consequently limited amount of data for estimating the effort of new projects. It is hard to make accurate estimations with scarce data. As the problem and estimation methods become more complex, it becomes harder to learn effort function with small datasets. Therefore, it is important to improve the performance of the predictor for effort estimation. Many researchers have used neural networks as a single element to be a robust algorithm in software effort estimation research. In this research, we focused on improving the prediction performance of the algorithm and therefore, we used ensemble of neural networks rather than a single neural network. Furthermore, we combined associative memory with the ensemble to provide the final model. We also analyzed the effect of feature subset selection on effort estimation performance. For this purpose, the features that contain most of the important information are discovered. Thereafter, only these features are used for effort estimation on the proposed model.The proposed model provides accurate estimations. Therefore, software companies may use this model to estimate software effort and effectively manage their workforce. On the other hand, the results of our experiments showed that using fewer features may provide an improvement on the prediction performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada afetin az görüldüğü fakat algılayıcı ağın uzun bir süre çalışır ve müsait olması gerçeğinden yararlanılarak yeni bir şema tasarlanmıştır. Önerilen şema afet sezimi amaçlı kablosuz algılayıcı ve erişim düzeneği ağları için planlanmıştır. Ana amaçlarımız pil kullanımını azaltmak, ağ ömrünü arttırmak ve tekrar konuşlanma sayısını en aza indirmektir. Önerilen şema afetin afet alanındaki tüm düğümleri bozduğu ve göz görüşü yoksa iletişimi de engellediği durumlarda bile çalışabilmektedir. Şema erişim düzeneklerinin düzenli bir ızgara oluşturduğu ve algılayıcıların rastgele dağıtıldığı bir alanda çalışmaktadır. Şema herhangi bir afet yokken aylak dinlemeyi ve protokol ek yükünü azaltarak ağ ömrünü etkili bir şekilde azami mertebeye eriştirmeye, afet vurunca da düğümleri hızlı bir şekilde düzenlemeye çalışmaktadır. Afet sırasında operasyon uyarı evresi, gruplama evresi ve rota tespit etme evresini içerir. Gruplama mekanizması veri kümelemeye ve erişim düzeneklerinin ek yüklerinin azalmasına olanak sağlar. Ayrıca, rota tespit mekanizması yol üzerindeki düğümlerin görev döngüsü yapmasına izin verir ve onların darboğaz olmalarını engeller. Önerilen şema, iyi bilinen T-MAC algoritması ile ağ ömrü tabanında karşılaştırılmış ve daha iyi sonuçlar ürettiği gözlenmiştir.","In this work, a novel scheme is designed to exploit the fact that disasters occur rarely, but the sensor network should be up and available for a long time. The proposed scheme is devised for disaster recovery for wireless sensor and actuator networks. The main goal is to minimize battery usage, increase network lifetime, and minimize redeployment. The proposed model works even in the case that the disaster destroys all nodes within the disaster area and also blocks communication unless there is line of sight. The scheme works in an area where the actuators form a regular grid and the sensors are randomly deployed. The scheme tries to maximize network lifetime by reducing idle listening and protocol overhead while there is no disaster and rapidly organizes nodes when the disaster strikes. Operation under disaster includes an alarm phase, a grouping phase, and a routing phase. Grouping mechanism provides data aggregation and reduces the overhead of the actuators. Furthermore, routing mechanism allows nodes along the path to perform duty cycling and prevent them from becoming bottlenecks. The proposed scheme is compared with the well known T-MAC algorithm in terms of network lifetime and shown to produce better results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Finans piyasaları, analiz ve fiyat tahmini yapmak açısından zor biralandır. Tahmin yapılmasını zorlaştıran faktör, herhangi bir gündeki fiyatınortaya çıkmasında çok fazla etkinin olmasıdır. Tahmin ve analiz için şimdiyekadar pek çok istatistiki ve diğer yöntemler bu amaç için seferber edilmiştir -biz de bu yolda bir adım atmaya uğraştık.Bu bağlamda Gizli Markov Modelleri ve Kalman Filtreleri adlı iki kuvvetlimetotun, geçmiş senet verisini modelleyebilerek geleceğe dönük tahminyapabileceğini varsay\-dık, ve iki metodu birleştirerek KMM adlı üçüncü birmetodun performansına baktık. Fiyat tahmin sayılarıni üretirken Monte Carlometotu kullanarak uç noktalarda olan tahminleri ortalama içinde düzeltmeye veböylece daha iyi bir tahmine ulaşmaya çabaladık. Model eğitildikten sonra onuileriye dönük tahminlerde kullanmak için ise, GMM durumunda Viterbi algoritmasıile geçiş olasılıklarını rasgele sayı üreterek takip eden bir algoritma, KalmanFiltreleri durumunda ise en son gelinen zaman noktasından bir sonrakine geçişiçin bizim değiştirdiğimiz zaman güncelleme denklemleri, ve yine rasgele sayıüreten bir algoritma kullandık.Bu tezin bir diğer amacı tarif ettiğimiz metotların diğer klasik metotlarakıyasla nasıl başarı göstereceğini ortaya koymaktı. Bunun için Yapay SinirAğları, polinom regresyon ve en son pür rasgele sayı üreterek tahmin yapmayauğraşan üç diğer metotu test senaryolarımıza dahil ettik. Bu metotların arasındarasgele üretim en alt seviyede performans göstermesini beklenilen metot idi,diğer tüm metotlar farklı derecelerde bu metotu geçmeliydi, ki deneylersonucunda durumun böyle olduğunu gözlemledik.","Financial markets are challenging targets for analysis and prediction. The existenceof many factors that contribute to a nal price of security at time t, makes thetask of predicting a future price a very hard task indeed. In the past, many statisticaland non-statistical models have been utilized that attempted to perform this dauntingtask - the aim of this thesis is going to be trying to demonstrate Hidden Markov Modelsand Kalman Filter methods can be used for predicting a future price. We also deviseda mixture predictor using HMM and KF which we called KMM.For this purpose, we hypothized HMM, KF and KMM based models that aretrained on historical data can generate future data, thereby predicting this securities'price in the future. For data generation, we used Monte Carlo simulation to smoothover the irregular patterns. \Carrying the model forward in time"" is achieved by acombination of Viterbi algorithm and rolling the dice on hidden state transitions, inKF case, we follow the time transition equation.Another goal of this thesis was to determine how HMM, KF and KMM methodsstood in comparison to other conventional methods. We picked polynomial regression,Neural Networks (ANN) and plain \random guess"" as our comparison criteria. Randomguess was expected to be the lowest performer in our tests, every method mentionedshould have surpassed random guess results by wide margin. We were glad to see thatthis was indeed the case."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Elektronik ticaret sektöründeki en önemli bileşenlerden biri elektronik ürün kataloğudur. Daha yüksek müşteri memnuniyeti sağlamak için, ürün veya ürün gruplarının erişilebilirliği kolay ve hızlı olmalıdır. XML depolama yapıları konusunda, literatürde yapılan araştırmaların çoğu genel XML dökümanları üzerinedir. Bu çalışmada, metin tabanlı doğal olarak saklanan XML elektronik ürün katalogları için, kategorize edilmiş bir depolama yapısı önerilmektedir. Kategorileme yöntemi, XML tabanlı ürün kataloglarını verimli bir şekilde depolamamıza imkan tanımaktadır.Verinin depolanmasının yanında, filtrelenmesi de önemli bir işlem haline gelmiştir. Veri kümelerinin filtreleme yollarından birisi Skyline'dır. Skyline literatüründe, bir çok algoritma geliştirilmiştir. Fakat hala XML tabanlı bir veri kümesinin Skyline'ını doğrudan hesaplayan bir algoritma yoktur. İkinci katkımız olarak, sıkça sorulan Skyline sorgularının Skyline kümelerini tutan bir indeks oluşturulacaktır. Böylelikle indeks, o sorguların yinelenmesi durumunda herhangi bir Skyline algoritmasının çalıştırılmasını gereksiz kılacaktır.Test aşamasında, kendi kategorize edilmiş depolama yapımızla, XML tabalı ürün kataloglarının özel ihtiyaç ve özellikleri düşünülerek geliitirilmiş başka bir yaklaşımın performans karşılaştırmaları verilecektir. Ayrıca, değişik büyüklüklerdeki Skyline indekslerinin performans testleri sunulacaktır.","One of the most important components of e-commerce business is electronic product catalog. In order to provide higher customer satisfaction, the accessibility of products or product groups should be quick and easy. The research done in the literature on efficient storage structure for XML is mostly on generic XML documents. In this work, we propose a categorized storage structure for text-based natively stored XML electronic product catalogs. Categorization method allows us to store XML-based product catalogs in an efficient way.Beside the storage of data, filtering of data becomes a vital process. Skyline is one way of doing filtering on data sets. In the literature on Skyline, many algorithms have been developed, but still there exists no algorithm that finds the Skyline of an XML-based dataset directly. As our second contribution, we keep an index holding the Skyline sets of frequently asked Skyline queries. So, in case of repetition of that queries our index makes the execution of any Skyline algorithm unnecessary.We present the performance comparison of our categorized storage structure withanother approach for XML-based product catalog which considers their specific needs and properties. We also present the performance test of our Skyline index for various cardinalities."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hizmet tabanlı mimari daha etkili ve dinamik uygulamalara zemin sağlamaktadır. Hizmet tabanlı mimari bünyesinde anlamsal Web hizmetlerinin kullanımı, birlikte işlerliği ve esnekliği arttırmaktadır. Anlamsal Web hizmetlerinin kullanımıyla ilgili önemli noktalardan birisi de kullanılan hizmet eşleme yöntemidir. Anlamsal eşleme, önemli hizmet adaylarının bulunabilmesi için, anlamsal Web hizmetlerinin eşleştirilmesi ve kompozisyonu sırasında kullanılmaktadır. Bu adaylar arasından en iyileri seçilerek kompozisyon oluşturulabilir ya da bir çalışma hatası anında ilgili hizmetin yerine seçilen hizmet kullanılabilir.Bu araştırmada, önceden yapılan girdi-çıktı bazlı servis eşleme işlemsel süreci daha gelişmiş bir sürece dönüştürülmektedir. Yeni eşleştirme süreci, girdi-çıktı tanımlarına ek olaraktan SWRL diliyle yazılmış ön şart ve etki ifadelerini de desteklemektedir. Bu araştırmada, SWRL diliyle yazılmış OWL-S koşul ifadelerine eşleştirme puanı belirlemek için yeni bir yöntem sunulmaktadır. Önerilen eşleme metodu, kapsama tabanlı benzerlik, özellik tabanlı benzerlik, benzerlik uzaklığı notları ve WordNet tabanlı benzerlik yöntemlerini kullanmaktadır. Sunulan işlemsel süreç, isteğin ve sunulan hizmetlerin eşleşen özelliklerini bulup, eşleşen servisleri isteğe olan anlamsal benzerliklerine göre sıralamak için iki kümeli grafik bazlı yöntemlerden faydalanmaktadır.Geleneksel bilgi sağlayıcı değerlendirme yöntemleri kullanılarak geliştirilen işlem sürecinin, ön şart ve etki ifadelerini destekleyen, önceki girdi-çıktı bazlı işlem sürecinden daha iyi bir doğruluk değerinin olduğu gösterilmektedir.","Service oriented architectures provide more effective and dynamic applications. Using Semantic Web services in service oriented architectures improves interoperability and scalability. A very important aspect of using Semantic Web services is the matchmaking process. Semantic matchmaking is used during discovery and composition of Semantic Web services to find valuable service candidates. Among these candidates, best ones are chosen to build up the composition, or for substitution in the case of an execution failure.In this research we enhance Semantic Advanced Matchmaker (SAM) which is based on input and output matching. Our new matchmaking agent supports precondition and effect expressions written in SWRL during matchmaking in addition to input and output annotations. We present a novel approach for assigning matchmaking scores to condition expressions in OWL-S documents written in SWRL language. Proposed matchmaking method utilizes subsumption-based similarity, property-level similarity, similarity distance annotations and WordNet-based similarity. The algorithm uses bipartite graphs in order to find matching parameters of requests and advertisements and then ranks the advertisements according to their semantic similarity to the request.Using classical information retrieval evaluation techniques we show that our proposed agent, which is capable of precondition and effect matching, has significantly higher precision performance with respect to SAM on input and output matching."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada bilgi kazanç tabanlı özellik seçme metodu ile SOM (kendi kendini eğiten harita) kullanılarak olağan dışılık tespiti yapan bir network tabanlı girişim tespit sistemi düşünülmüştür. Özellik seçme ve olağandışılık tabanlı sistemin performansını ölçmek için KDD 99 (Uluslararası bilgi keşif ve veri madenciliği araç yarışması 1999) kullanılmıştır. Özellik seçme metodu, n özelliğin her bir kombinasyonunu tek bir özellikmiş gibi kabul etmekte ve bu yeni özelliklerin entropilerini hesaplayarak olağandışılık tespiti için uygun olup olmadıklarına karar vermektedir. Grup içerisindeki özelliklerin sayısı, yani n sayısı, arttıkça hem kombinasyonların sayısı hem de her bir yeni özelliğin entropisini hesaplamak için gerekli zaman artmakta ve bu durum verimsiz bir hale dönüşmektedir. Bu problemi halletmek için yine bilgi kazanç tabanlı bir nicemleme metodu düşünülmüştür. Temel özelliklerin nicemlenmesi, n sayısı arttığında kombinasyonlarla elde edilen yeni özelliklerin bilgi kazançlarının hesaplanmasını mümkün hale getirmektedir. Çalışmanın olağandışılık tespit kısmında her biri ayrı bir saldırı grubu için özelleşmiş çok sayıda SOM tasarlanmıştır. Her SOM için faydalı özellikler, özellik seçme metodu ile bulunmuş ve SOM'ların performansı ölçülmüştür.","In this work, an information gain based feature selection method and a network-based intrusion detection system utilizing anomaly detection using Self Organizing Maps (SOM) are proposed. KDD 99 (The International Knowledge Discovery and Data Mining Tools Competition 1999) is used for the feature selection and performance evaluation of the anomaly system. Feature selection method considers every combination of n feature groups as a unique feature and determines whether it is useful for the anomaly detection by calculating entropy of the each new feature. As the number of features in a group, namely n, goes up, both the number of the combinations and the time needed for calculating every new feature?s information gain increases, and it becomes computationally infeasible. To overcome this problem, a quantization method, which is also information gain based, is proposed. The quantization of the basic features makes possible of the calculations of the information gains of the new combinational features as the n increases. In the anomaly detection part of the work, multi number of SOMs, every one is specialized to detect an attack group, is proposed. The useful features for each SOM is determined according to proposed feature selection process, and the performance of the SOMs are calculated."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çalışması, Boğaziçi üniversitesi Bilgisayar Mühendisliği bölümünde verilen?Programcılığa Giriş? (kod: cmpe150) dersini destekleme amaçlı olarak geliştirilen?Giriş düzeyinde programcılık eğitimini desteklemek için web ortamı? çalışmasını anlatmaktadır.Bahsedilen ders, pek çok eğitim kurumunda yapısı ve boyutları sebebiyleöğrenciler için oldukça zorlayıcı bir ders olmuştur. Yaptığımız çalışmanın amacı dersinveriliş ortamı göz önünde bulundurularak öğretim kalitesini arttırmaktır. Bu çalışmadaöğrenci ve eğitim kadrosunun kullanımına açık şekilde program yazılabilecek ve eğitimmateryalleriyle zenginleştirilmiş bir web ortamı sunulmaktadır. Bu raporda tasarım,gerçekleştirim ve sistemin kullanımı anlatılmaktadır.Bu çalışma detaylı olarak bu sistemi neden ve nasıl geliştirdiğimize değinmektedir.Ayrıca iki dönemdir kullanmakta olduğumuz sistemin tecrübe ve dönütlerine de yer verilmiştir. 2. ünitede sistemi neden tasarladığımıza değindik. 3. ünitede çalışmamızlaalakalı alanlarda yapılan çalışmalardan bahsettik. 4. ünitede bu sistemin hangi özellikleriiçermesi gerektiğini anlattık. 5. ünitede sistemimizin içermesi gerektiği özelliklerigöz önünde bulunarak yaptığımız tasarımı sunduk. 6. ünitede tasarımımızı nasılsomut yazılıma dönüştürdüğümüzü anlattık. 7. ünitede sistemin öğrenci ve eğitimkadrosu gözünden nasıl kullanıldığını ekran görüntüleriyle tarif ettik. 8. ünitede sistemdenaldığımız dönütü aktardık. 9. ünitede bu sistemi kullandığımız iki sömestir'igöz önünde bulundurarak sistemimizi değerlendirdik. 10. ünitede sisteme gelecekteyapılabilecek olası eklentileri ve geliştirmeleri belirttik. Son olarak 11 ünitesinde songörüşlerimizi belirttik.","This thesis describes a Web based education support environment for supple-menting the teaching of ?Introduction to Programming? (code CMPE150) course atBoğaziçi University by the Computer Engineering Department. The course in questionhas always been a challenging one to teach due to its nature and the size of the stu-dent body. This work aims to provide a higher quality learning environment given theconstraints of where it is applied. To this end a system was designed, implemented,and used in the teaching of this course. This work reports on design, development anduse of this system.This thesis will describe in detail why and how we built the system as well as ouruse for two semesters. In Chapter 2 we explain our design motivations. In Chapter 3present work related to supplemental online teaching environments. In Chapter 4we describe the system requirements. In Chapter 5 we introduce the design of thesystem. In Chapter 6 we provide implementation decisions and details. In Chapter 7we explain the use of this system both from the student as well as sta ? perspective.In Chapter 8 we present consequences and bene ? ts of the feedback mechanisms thatwe implemented. In Chapter 9 we present our evaluation regarding the use during twosemesters. In Chapter 10 we outline future work. Finally, in Chapter 11 we completethe thesis with concluding remarks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"MR resimleme vasıtasıyla difuzyonun sınırlandırıldığı alanlarda, mesela insan beyninin içindeki sinir ağlarında, görselleştirilmesi alttaki mikro yapıyı anlamamızı sağlar ve onu daha detaylı incelememize izin verir. Ancak 3 boyutta tensör alanı görselleştirme bir çok meydan okumayı içinde barındırır.Bu calışmada, 3 boyutlu difuzyon tensör alanı görselleştirmek için interaktif bir uygulama sunulmuştur. Uygulama iki yaklaşım içermektedir. Birincisi, Tensör Boyama, komşu tensor çiftlerinin lokal bağlılık tanımlarına dayanmaktadır. Lokal bağlılık değerleri, eşik değerleri ile birlikte bir tensörün kendisine ulaşan boyayı komşu tensörlere ulaştırıp ulaştırmayacağını belirler. Tensör boyama birçok değişik bağlılık tanımını kullanır. Bu tanımların hepsi, difuzyon tensörünün, hareket eden parçacıkların uzaysal dağılımını açıklayan 3 boyutlu Gaussian PDF lerin ortak değişinti matrisi olarak yorumlanmasına dayanır. Ikinci yaklaşım tensör alanına uygun olarak beyazgürültü imgesinin düzenlenmesine dayanır. Bunun için akış görselleştirmede çok sık kullanılan Line Integral Convolution(LIC) tekniğinden faydalanılmıştır. LIC metodunda, lokal akış çizgilerinin hesaplanmasının ardından evrişim filtresi kullanılır.Bu çalışmada, önce difuzyon tensörünün görselleştirilmesinin gereklilikleri ele alındı ve ardından geliştirilen uygulama sunuldu. İki phantom difuzyon tensör alanı üzerinden elde edilen sonuçların ve değerlendirmelerinin sunumu ve yorumlama kısmı bunları takip etti.","Visualization of dffusion in restricted media, such as the fiber network in human brain, via MR imaging provides a better understanding of the underlying micro structure and allows us to study it in detail. However, 3D tensor field visualization presents several challenges.In this study, we present an interactive tool for visualizing 3D diffusion tensor fields. The tool is composed of two approaches. The first one, the Tensor Paint, is based on the definition of local connectivity between neighboring tensor pairs. The connectivity value together with a threshold determines whether a tensor passes the paint it has received to its neighbors or not. Tensor paint employs a number of different connectivity definitions. They are all based on the interpretation of the diffusion tensors as the covariance matrices of the 3D Gaussian PDFs representing the spatial distribution of moving particles. The second approach is based on the modulation of an input white noise texture by the tensor field. For this purpose, we have utilized the Line Integral Convolution (LIC) technique which is a widely used technique in flow visualization. In LIC, the application of a convolution filter follows local streamline computation.In the study, we first discuss the requirements for the visualization of diffusion tensor fields and then present our tool. Presentation of the results and evaluations obtained on two phantom diffusion tensor fields and a discussion follows this."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Borsa, henüz hisse fiyat davranışlarını tam olarak tahmin edebilecek herhangi bir yöntem bulunmadığından dolayı, araştırmacılar için her zaman çekici bir alan olmuştur. Hisse fiyat davranışlarının tahminini zorlaştıran yüksek belirsizlik ve volatilite nedeniyle, diğer tüm yatırım alanlarından çok daha fazla risk taşır. Yıllarca, geleneksel yöntemler geliştirilmiş ama bunlar, hisse fiyatlarının doğrusal olmayan ve karmaşık davranışlarını nedeniyle, kısmen başarılı ya da tamamen başarısız olmuşlardır. Yapay sinir ağları yaklaşımı, hisse fiyat davranışlarının tahmininde göreceli olarak yeni, faal ve umut veren bir alandır. Yapay sinir ağları, insan beyninin öğrenme ve karar verme işlemlerini taklit eden matematiksel modellerdir ve gürültülü veriye, karmaşık ve doğrusal olmayan problemlere kolay uyum sağlamaları nedeniyle, hisse fiyat davranışını tahmin etmeye uygundurlar.İstanbul Menkul Kıymetler Borsası, gelişmekte olan bir ekonomiye sahip olan Türkiye'deki tek hisse senedi piyasasıdır. Türkiye'deki piyasa durumları ve ekonomik dalgalanmalar, gelişmiş ülkelere göre hisse senedi piyasalarında daha çok belirsizliğe ve volatiliteye neden olmaktadır. Bu çalışmada amaç; bu belirsizlik ve volatiliteyi düşürmek için, hisse fiyatlarındaki değişimi modellemek, yapay sinir ağlarının finansal piyasalara uygulanmasındaki teori ve adımlarını incelemek ve günlük hisse fiyat yönü değişimlerini tahmin eden bir yazılım geliştirmektir ve aynı zamanda da, bu edinimleri hisse ticareti yapan bir sistem geliştirmekte kullanarak, yapay sinir ağlarının geleneksel tekniklere olan üstünlüğünü tartışmaktır.","The stock market has always been an attractive area for researchers since no method has been found yet to predict the stock price behavior precisely. It carries a higher risk than any other investment area, due to its high rate of uncertainty and volatility, thus making the stock price behavior difficult to forecast. For years, conventional methods have been developed but they have succeeded partially or have completely failed to deal with the nonlinear and complex behavior of stock prices. Artificial neural networks approach is a relatively new, active and promising field on the prediction of stock price behavior. Artificial neural networks (ANNs) are mathematical models simulating the learning and decision making processes of the human brain. Because of their nature of easy adaptation to noisy data, and solving complex and nonlinear problems, they fit into the area of stock price behavior prediction.The Istanbul Stock Exchange (ISE) is the only stock market in Turkey, which has an emerging economy. The market situations and economic fluctuations in Turkey create more uncertainty and volatility in the stock market when compared to emerged markets. This study tries to reduce the effect of this uncertainty and volatility by modeling the change in stock price direction of stocks, identifying the theory and steps involved in applying ANN in financial markets and developing a software package to be used for predicting directional daily stock price behavior. It also discusses the appropriate ways to use this process in developing trading systems, further discussing the superiority of ANN over traditional methodologies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir imge dizisinde bulunan yüz öznitelik noktalarının otomatik olarak takip edilmesi, ifade tanımayı da kapsayan birçok uygulamanın ilk adımıdır. İşaret dili özelinde bakarsak, ifadeler hem duygusal ifade hem de baş hareketi içerebilen ele ait olmayan işaretler olarak karşımıza çıkar. Bu çalışmada, Türk İşaret Dili'nde yaygın olarak kullanılan ifadeleri tanımayı amaçladık. Önerdiğimiz sistem iki aşamadan oluşmaktadır: İlkinde, imge dizisindeki her kare için, çok-yönlü (düz, sağa, sola, yukarı) Çok-çözünürlüklü Aktif Şekil Modelleri (ÇÇAŞM) ile yüzdeki nirengi noktaları otomatik olarak saptanır. Bulunan yönlerden şekli modele en iyi oturan ve önceki seçilen şekle en yakın olan yönün şekli seçilir. Eğer seçilen şeklin güvenirliği, eşik değerinin altında ise o kare boş bırakılır ve şekil başlangıç durumuna getirilir. Böylece takip edilen şeklin dağılması önlenir ve sistemin gürbüz çalışması sağlanır. Boş bırakılan kareler interpolasyon ile doldurulur ve hatalı sonuçları elemek için alpha-trim ortalama süzgeci kullanılır. İkinci aşamada takip edilen noktalar normalize edilir ve çok değişkenli Sürekli Saklı Markov Modelleri (SSMM) tabanlı sınıflandırıcıya girdi olarak verilir ve ifade tanınması yapılır. Bulunan sonuçları sınayabilmek için ele ait olmayan ifadelerden oluşan bir video veritabanı topladık. Hem takip hem tanıma kısımları için ÇÇAŞM yöntemini tek-yön/çok-yön ve genel/kişiye-özel çeşitlemeleri ile çalıştırıp sonuçları karşılaştırdık. Çok-yönlü kişiye-özel takipçi en başarılı sonuçları vermektedir ve sistemin gürbüz bir şekilde noktaları takip edebildiği gözlemlenmektedir. Sınıflandırma kısmı için önerilen SSMM sınıflandırıcısını değişik eğitim ve test kümelerinde denedik. Birbirinden farklı sınıflar için başarı çok yüksek gözükmektedir.","Extracting and tracking facial features in image sequences automatically is a required first step in many applications including expression classification. When sign language recognition is concerned, expressions imply non-manual gestures (head motion and facial expressions) used in that language. In this work, we aimed to classify the most common non-manual gestures in Turkish Sign Language (TSL). This process is done using two consecutive steps: First, automatic facial landmarking is performed based on Multi-resolution Active Shape Models (MRASMs) on faces. The landmarks are fitted in each frame using MRASMs for multiple views of faces, and the best fitted shape which is most similar to the shape found in the preceding frame is chosen. This way, temporal information is used for achieving consistency between consecutive frames. When the found shape is not trusted, deformation of the tracked shape is avoided by leaving that frame as empty and re-initializing the tracker. Afterwards, the empty frames are filled using interpolation, and alpha-trimmed mean filtering is performed on the landmark trajectories to eliminate the erroneous frames. Second, the tracked landmarks are normalized and expression classification is done based on multivariate Continuous Hidden Markov Models (CHMMs). We collected a video database of non-manual signs to experiment the proposed approach. Single view vs. multi-view and person specific vs. generic MRASM trackers are compared both for tracking and expression parts. Multi-view person-specific tracker seems to perform the best. It is shown that the system tracks the landmarks robustly. For expression classification part, proposed CHMM classifier is experimented on different training and test set selections and the results are reported. We see that the classification performances of distinct classes are very high."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüz dünyasında bilgi hem endüstri ve hem de akademik dünyanın gözünde en önemli değer konumundadır. Bilginin web tabanlı ortamlarda birikmesi ve farklı ancak birlikte hareket etme zorunluluğu olan uygulamaların entegrasyonu için artan talep, günümüz bilgi yönetim politikalarını servis tabanlı olmaya itmektedir. Web servislerinde sağlanan anlamsal ilerlemeler bu baş döndürücü değişim sürecinde yeni bir adım olmuş ve farklı uygulamaların entegrasyonunda ilerleme sağladığı gibi ölçeklenebilirlik konusundaki endişeleri azaltmayı da başarmıştır. Gelişen her teknoloji önümüze yeni bir açmaz sunarken, her yeni açmaz da yeni teknolojilerin gelişmesine yol açar. Anlamsal web servisleri genel kabül gördükçe en uygun ve istenilen web servisinin keşfi yeni bir zorluk olarak karşımıza çıkmaktadır.Web servislerinin keşfi farklı uygulamaların entegrasyonu sürecinde etkileşimin yapılacağı eşin bulunması açısından kilit bir adım olduğu gibi derlenme sürecindeki temel adımı oluşturması açısından da önem arz eder. Keşif ne kadar başarılı gerçekleştirilirse derlenme de o derece başarı ile neticelenecektir. Verilen gereksinimlere göre en uygun servisi bulmak doğru, verimli ve hassas bir skorlama mekanizması gerektirmektedir.Bu çalışmamızda anlamsal web servislerinin derecelendirilmesini konusunu ele aldık. Temel stratejimiz konseptler arası tekil ilişkileri baz alan ve farklı konseptler arası ilişkiyi işbu tekil ilişkiler yoluyla elde eden bir benzerlik kıstası yaratmak oldu. Bu yaklaşımı aynı problemi adresleyen diğer algoritmalarla karşılaştırmak için örnek bir servis kümesi üzerinde test ettik ve keşif sürecindeki ilerlemeleri gözlemledik.","Information is the most valuable asset of today?s world, both from the perspective of industry and academia. Accumulation of information on web based mediums with increasing demand of integration between different but necessarily collaborating parties drives today?s information management policies be service-driven. Semantic enhancements on web services take one more step ahead in this amazing evolution and improve integration between different applications besides removing concerns on scalability. Each emerging technology is a result of a trade-off and each trade-off yields new technologies to emerge. Once semantic web services become widely accepted, discovering the most appropriate and desired service becomes a challenging issue.Discovery is one of the key steps in the integration of applications, not only because it figures out who the companion in the interaction is but also it forms up the basis step for composition. Once discovery of web services can be successfully managed, composition of services will yield more successful results. To identify which service is the most appropriate for given user requirements, there has to be a valid, efficient and sensitive scoring mechanism to measure appropriateness.In this research, we focus on ranking of semantically enhanced web services. We base our strategy on individual relations between different concepts of ontology and identify the similarity degree with appropriate combination of those individual relations. We run our algorithm as well as other approaches addressing the same problem on a sample set of semantic web services and observe improvements on service discovery performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Genel anlamda iş dünyasındaki ve özel olarak insan kaynakları fonksiyonundaki gelişmelere paralel olarak İnsan Kaynakları Bilgi Sistemleri sürekli önem kazanmaktadırlar. İnsan Kaynakları Bilgi Sistemlerinin önemi öyle bir noktaya ulaştı ki, bu sistemler insan kaynakları fonksiyonunun daha düşük maliyetlerle daha yüksek hizmet sunma amacını gerçekleştirebilecek tek araç olarak görülüyorlar. Ancak, bu amaç sadece İnsan Kaynakları Bilgi Sistemlerinin başarılı bir şekilde uygulanmasının ardından gerçekleştirilebilir ve İnsan Kaynakları Bilgi Sistemlerinin uygulanması hiç de basit değildir. Bu çalışmada İnsan Kaynakları Bilgi Sistemleri uygulama projeleri sosyal ve teknik faktörler ile bu faktörlerin etkileşimleri de dikkate alınarak, kısaca sosyoteknik bir perspektif ile analiz edilmiştir. Literatür taraması ve nitel çalışmaların ardından araştırma gerçekleştirilmiştir. Çalışmanın sonuçlarına göre, literatürde bulunmuş olan kritik başarı faktörleri ve zorluklar Türkiye'deki İnsan Kaynakları Bilgi Sistemleri uygulama projeleri için de geçerlidir, ve bundan daha da önemlisi, sosyoteknik yaklaşım İnsan Kaynakları Bilgi Sistemleri uygulama projelerinin başarısı üzerinde olumlu bir etkiye sahiptir. Bu çalışma İnsan Kaynakları Bilgi Sistemleri uygulama projelerini yeni bir açıdan incelemekle kalmayıp, bununla beraber araştırmacılara ve insan kaynakları profesyonellerine İnsan Kaynakları Bilgi Sistemleri uygulama projelerinin anlaşılabilmesi için ışık tutmaktadır.","Human Resources Information Systems continuously gain importance parallel to the developments in the business world in general and Human Resources function specifically. The importance of Human Resources Information Systems has reached to such an extent that they are seen as the only enabler that can realize the aim of Human Resources function to cost less while delivering more. However, this can only be realized after successful implementation of the Human Resources Information Systems, which is not as straight-forward as the benefits of implementing. In this study, human resources information systems implementations are analyzed by taking into account both social and technical factors, and relationships of these two; which is summarized as the sociotechnical perspective. A field research in Turkey was conducted after studying the literature and making qualitative studies. The results of the field research revealed that challenges and critical success factors found in the literature are also valid for Human Resources Information Systems implementation projects in Turkey, and more importantly, sociotechnical approach has a positive effect on the success of human resources information systems implementation projects. This study not only handles human resources information systems implementations projects from a newer perspective, but also provides insight to researchers and also human resources professionals about having a deeper understanding of the implementations of Human Resources Information Systems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde insanlar kendi iş alanlarına yoğunlaşıp, kalan işleri dış kaynak kul-lanarak halletmeyi tercih etmektedirler. Bu durum teknoloji dünyasında iki önemlikavramın ortaya çıkmasını sağlamıştır. Bunlardan birincisi ""dış kaynaklı yazılımlar"",ikincisi ise ""dış kaynaklı veritabanları"" dır.Dış kaynaklı veritabanları birçok işi kolaylaştırmasına rağmen beraberinde bazısorunlar getirmistir. Veritabanının tipinden bağımsız olarak üçüncül kişilere verilenverilerin güvenle saklanması gerekliliği ortaya çıkmıştır. Bunun sağlanabilmesi içinveriler şifrelenmeli ancak üçüncül kişilere şifreleme anahtarı verilmemelidir. Şifrelemeanahtarının veritabanı servisini sağlayan üçüncül kişilere verilmemesi beraberinde birsorunu daha getirmektedir: Şifreli verilerin sorgulanması. Literatürde, şifrelenmiş ver-itabanlarının, şifreleme anahtarı servis sağlayıcı üçüncül kişilere verilemeden sorgula-ması ile ilgili çalışmalar bulunmaktadır. Bu çalışmalardan bazıları efektif iken bazılarıtepki zamanının düşük olması nedeniyle efektif değildir.Bu çalışma, şifrelenmiş XML dokümanlarının efektif ve güvenli olarak sorgulan-masını içermektedir. Önerilen çalışma şifrelenen XML dokümanının üçüncül kişilereşifreleme anahtarının verilmeden sorgulanmasını sağlamaktadır. Kullanılan indeksyapılarının daha güvenli olması için bazı yeni yapılar önerilmiştir. İkincil olarak buçalışmada servis sağlayıcı tarafında paralel sorgulama yapılmaktadır. XML dokümanlarıdeğişik işlemcilerde paralel olarak sorgulanmaktadır ve literatürde ilktir. Bu çalışmadaperformans karşılaştırmaları yapılmış, önerilen şemadaki şifrelenmiş dokümanları par-alel olarak işlemenin önemli derecede performans artırdığı görülmüştür.","Nowadays people prefer to concentrate on their own business and outsource therest of the work. This has brought two important concepts to information technologyworld. First one is the ""Software as a service"" and the second one is the ""Database asa service"".Using ""Database as a service"" concept made things easier but brought some issuesto consider. Independent of the database type (relational, XML or even °at text ¯le)the data kept in un-trusted third parties have to be secured in ""database as a service""concept. In order to overcome this security issue, the databases have to be encryptedand the key should not be disclosed to the service provider. Unrevealing the keyto database service provider brings another problem which is querying the encrypteddatabase. There are solutions in literature on querying encrypted databases withoutrevealing the key to service provider. Some of these solutions are e±cient while somesu®er from low response times.First contribution of this paper is proposing a schema which e±ciently and se-curely queries an encrypted XML document. Content of XML document is not revealedto server. Indexes are manipulated by adding bogus data in order to make the schemamore secure. Second contribution is parallel processing of query evaluation at serviceprovider side. Proposed model is a unique model in literature in terms of using parallelprocessing in encrypted XML documents. The response times of the proposed schemasare evaluated and it is shown that the proposed schema is an e±cient schema and par-allel processing signi¯cantly increases the performance in encrypted XML documents."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telsiz algılayıcı ağlar (TAA), belli bir hedef alanın akıllı ve uzaktan erişimli gözlemlenmesini sağladıklarından, birçok uygulama için gelecek vaadeden bir teknoloji alternatifi oluşturmaktadırlar. Çeşitli potansiyel uygulama alanlarından bazıları sağlıksal takip, olağanüstü durum gözlemleme, doğa gözlemleme, hassas tarım ve sızma sezme sistemleridir. Ayrıca, yeni algılayıcı türleri ve gelişmiş hesaplama, haberleşme ve güç kapasiteleri için yapılan donanım çalışmaları, yeni uygulama alanlarının ortaya çıkmasını sağlayacaktır.Algılayıcı düğümlerdeki genellikle değiştirilemeyen, limitli güç kaynakları nedeniyle TAA çalışmaları enerji-verimli ağ çalışması üzerine yoğunlaşmıştır. Bu enerji-verimli çalışma hedefi, ortam erişim kontrol (OEK) katmanı dahil her ağ katmanı için yeni çalışmaların yapılmasını gerektirmektedir. Bu tezde, TAA'lardaki OEK katmanı ile ilgili çeşitli başarım konuları incelenmiştir. İlk olarak, literatürde bulunan değişik OEK protokol yöntemlerini içeren karşılaştırmalı bir özet sunulmuştur. Protokollerin doğru başarım değerlendirmeleri için hedef TAA uygulamasının özelliklerini temsil edebilen gerçekçi bir paket trafik modeline ihtiyaç vardır. Bu ihtiyaç doğrultusunda, telsiz gözetim algılayıcı ağları için analitik bir paket trafik modeli önermekteyiz. Telsiz gözetim algılayıcı ağlarda, algılayıcı düğümler bir sızma sezdiklerinde toplayıcı düğümü haberdar etmekle görevlidirler. Kullanılan algılayıcı tiplerine uyarlanabilirlik özelliği sağlamak için olasılıksal ve parametrik bir sızma sezme modeli temel alınmıştır.Bu tezin bir diğer önemli katkısı da, OEK katmanı çekişmelerinin enerji ve gecikme kriterleri için eniyilenebilmesini sağlayacak çalışmalardır. Bu çalışmalar, belirtilen iki ayrı kriter için matematiksel formüllerin geliştirilmesi ve bu formüller ışığında çekişme penceresi boyutunun eniyilemesi ile başarılmıştır. Bu eniyilemelerin TAA'ların dağıtık yapısında kullanımını sağlayacak, en iyi sonuca yakın başarım değerleri sergilediğini gösterdiğimiz bir yöntem de bu tezde önerilmiştir.Bu çekişme eniyilemesi çalışmalarının genel ağ başarımına etkisini incelemek için de video algılayıcı ağları (VAA) üzerine çalışmalar yapılmıştır. VAA, düğümlerin kameralarla donatılmış olduğu ve uygulamanın istekleri doğrultusunda hedef bölgenin görüntülerini toplayıcı düğüme yollayan özel bir TAA türüdür. İlk olarak VAA'ların günümüz donanım teknolojilerinin özellikleri ile elde edebilecekleri ağ başarımı benzetim yoluyla çıkarılmıştır. Daha sonra, bu tezde önerilen çekişme eniyilemesi, bu VAA'lara uygulanmış ve akıllı çekişme penceresi boyutu tanımlamanın VAA'ların kapasitelerini nasıl arttırdığı gösterilmiştir.","Wireless sensor networks (WSNs) present a promising technology for many applications, providing an intelligent and remote observation of a destination. Among the various potential applications, there are health monitoring, disaster monitoring, habitat monitoring, precision agriculture, and surveillance systems. With the ongoing research both on new sensor types and on the hardware for improved computation, communication and power capacities, the emergence of novel application areas are expected.Due to the limited power sources of the sensor nodes which are generally irreplaceable, the WSN research is focused on the energy-efficient network operation. This energy concern requires new studies at each networking layer, including the medium access control (MAC) layer. In this thesis, we investigate a number of MAC layer performance issues for WSN by first presenting a comparative survey of different MAC protocol schemes proposed in the literature. For the correct performance evaluation of the protocols, one needs to utilize a realistic packet traffic model that reflects the specific features of the WSN application represented. We derive an analytical packet traffic model for Surveillance WSN where sensor nodes inform the sink for detected intrusion events. The sensor detection model used is probabilistic and parametric, which enables the adaptation of the packet traffic model to the sensor types deployed.One important contribution of this thesis is the optimization of the MAC layer contentions for minimization of the energy consumption or the delay incurred in contention slotted medium access protocols. This is achieved by by analyzing the energy consumption and the contention delay and, then, extracting the contention window size that optimizes the corresponding performance metric. For its practical implementation in the distributed environment of WSNs, a method is proposed which achieves near-optimal performance values.To investigate the effect of the contention optimization on the the overall network performance, video sensor networks (VSNs) are studied. VSNs are a special type of WSNs where the sensor nodes are equipped with cameras and send image or video of a target area based on the specifications of the application. First, the network performance of the VSNs are investigated via simulations for the currently available hardware technology. Then, by applying the contention optimization proposed in this thesis, we show how the capacity of VSNs can be improved with intelligent contention window size setting."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde yapılan çalışmanın temel amacı bebeklerdeki intrauterin büyüme kısıtlılığının hamileliğin erken safhalarında otomatik olarak tespit edilmesini sağlamaktır. Büyüme kısıtlılığın erken tespit edilmesinin zor olduğu kadar önemli olması araştırmacıları bu alana yöneltmiştir. Bu tez, acil servise gelen annelerin ultrasonlarından edinilen verilerin hızlı ve efektif bir şekilde sınıflandırılmaları sonucu intrauterin büyüme geriliği riskini düşürmektir. Günümüzde akıllı veri analizi sistemleri kullanımıyla anneye özgü, plasental ve cenine özgü verilerin edinilmesi doğrultusunda büyüme kısıtlılığınının olup olmadığı tespit edilerek gerçek zamanlı analiz ve teşhis imkanı sağlanmaktır. Bu çalışmada intrauterin büyüme kısıtlılığının önceden belirlenmesi için çeşitli makina öğrenmesi sitemleri kullanılmıştır. Önce, verinin boyutu manuel bir bir şekilde indirgenmiş ve sınıflandırma performansını artırdığı ispatlanan ölçeklendirme işlemi uygulanmıştır. Bu aşamadan sonra veriye onüç farklı sınıflandırma yöntemi uygulanarak sonuçlar karşılaştırılmıştır. Bu yöntemler temel olarak üç farklı grupta toplanabilirler. İlk grup Destek Vektör Makineleri (DVM), k-En Yakın Komşu (k- Nearest Negihbor ? k-NN) ve Lojistik Regresyon yöntemleri gibi tekil sınıflandırma yönetemleridir. İkinci grup yöntemler DVM ve k-NN sınıflandırma yöntemlerinde güven analizi yaparak düşük güvenli test verilerinin reddedilmesi sonucu daha yüksek sınıflandırma doğruluğu elde edilmesini amaçlamaktadır. Üçüncü grup deneyler ise ilk gruptaki üç sınflandırma yöntemlerinin değişik kombinasyonlarda birleşerek beraber veya sıralı bir şekilde sınıflandırma yapmalarına dayanmaktadır. Bu üç grup deneyler içinde sınıflandırma performansı sırasıyla en yüksek ikinci olmak üzere, üçüncü ve birinci sınıfladır. İkinci grup içinde ise DVM sınflandırması kullanan ve sınıflandırma güvenilirliği düşük vakaların reddedilmesi sonucu elde edilen sınıflandırma doğruluğu bütün testlerdeki en yüksek performası elde etmiştir.","The main objective of this study is to provide automatic recognition of IUGR in the early stages of pregnancy by using noninvasive method. The difficulty faced in interpretation of IUGR in the early stages forced researchers to study about automatic detection of growth restriction. We aim to make fast and effective classification of ultrasound readings that are collected from emergency deliveries. Using intelligent data analysis techniques, computer programs could easily interpret maternal, placental and fetal measurements, predict presence or absence of growth restriction and provide real-time analysis and diagnosis. In this study, several machine learning techniques have been applied to IUGR dataset for classification using PI (Pulsality Index), RI (Resistancy Index) of UA (Umblical Artery), MCA (Middle Cerebral Artery) and DV (Ductus Venosus), and AFI (Amniotic Fluid Index) measurements. These measurements are taken from ultrasound readings from the mothers at emergency room. After data acquisition and scaling processes of the data, we applied 13 different classification algorithms. These 13 classifiers that have been used in this study can be divided into three groups. First group consists of single classifiers such as Support Vector Machines, k-Nearest Neighbors and Logistic Regression. In the second group, we tried to reject low confident test instances to achieve higher classification accuracy with higher confidence. Third group uses hybrid classifiers in order to benefit from several classifiers. Among these groups, performance of second group outperformed the third and lowest performance obtained from the first group. Within second group, SVM classification with rejection of low confident test samples results are shown to outperform competing classification results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kredi riskinin yönetilmesi bankaların ana faaliyetlerinden biridir. Kredi risk dereceleri ise kredi risk yönetimi sürecinin ayrılmaz bir parçasıdır. Kredi derecelendirme sürecinde istatistiksel modeller ve kişisel tecrübelerden yararlanan sistemler kullanılabilmektedir. Ancak yüksek tutarlı kredilerin değerlendirildiği durumlarda, çok daha yüksek maliyetleri olmasına rağmen, kişisel tecrübelerden yararlanan sistemler istatistiksel modellere göre daha fazla tercih edilmektedir.Bir bankanın derecelendirme sürecinde farklı birimler görev almaktadır ve bu birimlerin performans değerlendirme kriterleri birbirinden tamamen farklı olduğundan, derecelendirme sürecinde anlaşmazlıklar ortaya çıkması kaçınılmazdır.Bu çalışma Türkiye'deki bir bankada kredi riskinin derecelendirilmesi sürecinde iki ayrı birimin değerlendirmeleri arasındaki farkları bir bilişim sistemi kullanarak göstermeyi amaçlamaktadır. Ek olarak, belirlenen risk derecesinin doğruluğu üzerinde ortak karar verme mekanizmasının etkisinin de görülmesi hedeflenmektedir. Kredi riskinin derecelendirilmesinde kullanılan bu sistem Analitik Hiyerarşi Süreci (AHS) adı verilen bir model üzerine kurulmuştur.","Credit risk management is one of the main activities of banks, and credit risk ratings are an essential part of the process. In the rating process statistical models and judgmental systems can be employed. At the evaluation of larger exposures, however, judgmental systems are preferred more than statistical models, although they are more costly.Different parties in a bank participate through the rating process and since performance assessment criteria of these parties are totally different from each other, disagreements in the rating process are inevitable.This thesis aims to show the differences between the judgments of two departments through the credit risk rating process in one of the banks in Turkey. Additionally the effect of group decision making on the accuracy of credit risk ratings is aimed at. The information system developed for credit risk rating is based on a descriptive and structured model called the Analytical Hierarchy Process (AHP)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Web için uygulama geliştirme bugün en önemli programcılık alanlarından birisini teşkil etmektedir. Web uygulamaları için daha iyi ve kolay programlama yolları sağlamak üzere şu anda sunulmuş ve kullanımda olan bir çok teknoloji mevcuttur. Bunlardan bir kısmı açık kaynak kodlu iken bazıları ise Microsoft ve IBM gibi büyük yazılım sağlayıcılar tarafından pazara sürülmektedir. SpringFramework bu pazarda açık kaynak kodlu bir alternatif olarak bulunmaktadır. Java tabanlı olan bu teknoloji, en iyi pratikler ve kabul edilmiş standartlar temelinde yazılım geliştirilmesi için sağlam bir alt yapı sunmak üzere tasarlanmıştır. Bu tez, düşük seviye görevleri kullanıcılarından saklayarak ve onları uygulamalarının gerçek amaçlarına odaklandırarak, SpringFramework üzerinde çalışan web uygulamaları geliştirme işini kolaylaştırmak üzere bir bilgisayar programı ortaya koymayı amaçlamaktadır. Kullanıcı dostu olma ve insan doğasına yakın olma temeline dayanan bu yazılım, otomatik kod ve sayfa üretimi, veritabanı ve uluslararası dil desteği ve kolay dosya yönetimi sağlamaktadır.","Web application development is one of the most important programming areas today. There are many technologies to provide a better and easier way of programming for web applications in the market. Some of them are open source and free whereas some of them are released by big software vendors such as Microsoft and IBM. The SpringFramework is an open source alternative in this area. It is a Java-based technology to provide a robust infrastructure to software development based on best practices and accepted standards. This thesis aims to provide a computer program to facilitate SpringFramework-based web application development by hiding low level tasks from the developer and trying to make it focus on the real purpose of his application. Based on user friendliness and being close to human nature this program provides automatic code and web page generation, database and internationalization support, easy file management."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım geliştirme endüstrisinde yüksek hata oranları geliştirme maliyetlerini ve hizmetleri yükseltmektedir, bu da müşteri memnuniyetsizliği ile sonuçlanmaktadır. Test süreci yazılım geliştirme safhalarından en kritik ve maliyetli olanıdır. Şirketler test için maliyetli araştırmalar yapmaktadır fakat hala yeterli bir seviyedeki test kapsamına ulaşamamışlardır. Bu sebepten dolayı yazılım mühendisleri ön test aşamasında hataları yakalamak için zeki modeller arayışındadır. Bu çalışmada biz önceki versiyon hataları, statik kod özellikleri ve çağrı grafiklerini kullanarak öğrenme temeline dayanan hata yakalama modeli kurmaya odakladık.Bu tezde motivasyonumuz, kodun mimari yapısını daha iyi anlayabilmek için statik kod özelliklerinin bilgisini arttırmaktır. Hata yakalama modeli için önerdiğimiz çatı, çağrı grafiklerine dayalı sıralama metodolojisidir. Bu araştırmada modül ilişkisinin ve yapısının kodun hata eğilimli olmasında önemli bir rol oynayıp oynamadığını araştırdık. Önerdiğimiz çatı modelinde modül ilişkilerini dikkate aldık ve çağrı grafiklerini kodu modülden modüle izlemek için kullandık. PageRank algoritmasını çağrı grafiklerine dayalı sıralama algoritmasını oluşturmak için kullandık. Çağrı grafiklerine dayalı sıralama algoritmasından ürettiğimiz değerleri statik kod özellikleriyle çarptık.Sonuçta oluşan yeni çerçeve statik kod özelliklerine dayanan tüm hata yakalama modellerinde kullanılabilir. Bu çerçeve ile yazılım geliştiriciler daha az test maliyetleriyle hata yakalayarak yazılımlarının kalitesini arttırabilirler.","In software development industry high defect rates increase the cost of development and maintenance, which ends in customer dissatisfaction. Testing is among the most critical and costly phases in software development. The companies make costly investments in testing; still they cannot reach an adequate level of test coverage. Due to this software engineers are in search for intelligent models, which would predict defects at pre-testing point. In this research we focus on building a learning-based defect prediction model based on pre-release defects, static code attributes and call graphs.In our research the motivation is to increase the information content of static code attributes through a better understanding of the architectural structure of the code. Our proposed framework for defect prediction model is a call graph based ranking methodology. We search through whether module interaction and structure play an important role in defect proneness of a given code. In our proposed framework module interaction is taken into consideration and call graphs are used to trace the code module by module. PageRank algorithm is utilized in constructing our call graph-based ranking algorithm. We adjust the values produced from call graph-based ranking algorithms with static code attributes.The resulting framework can be applied to any defect prediction model based on static code attributes. This framework will help software developers increase the quality of their products by catching defects with lower test costs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Şikayet yönetimi E-devlet alanında önemli bir uygulamadır. Vatandaşların şikayetlerinin toplanması, birleştirilmesi ve sıralanması etkili bir yönetim için gereklidir. Mevcut şikayet yönetim uygulamalarında, yapılan her şikayetin, hükümet tarafındaki yetkililerce, teker teker ele alınıp, incelenerek, hangi şikayetin daha önce işlenmesi gerektiğine karar vermesi beklenir. Fakat, bu zaman harcayıcı ve de dolayısıyla verimsiz bir yöntemdir.Bu durumla başa çıkabilmek için, bu çalışmada, şikayetlerin yönetilebileceği ontoloji tabanlı bir şikayet yönetim sistemi geliştirilmiştir. Vatandaşların şikayetlerinin ifade edilebilmesi için şikayetler üzerine bir ontoloji yaratılmıştır. Ek olarak, birtakım kriterlere göre, şikayetler arasında varolabilecek benzerliklerin belirlenerek bu şikayetlerin birleştirilmesi üzerine çalışılmıştır. Şikayetler üzerinde belirlenebilecek kısıtlarla, hükümet yetkililerinin hangi şikayetlerin diğerlerinden daha önemli ve öncelikli olduğu konusunda karar vermelerine olanak sağlanmıştır. Bu kısıtlar, vatandaş şikayetleri üzerinde, bir usavurucu yardımıyla uygulanmaktadır. Bu işlem, şikayetler arasındaki önceliklerin otomatik olarak belirlenmesine ve önem sırasına göre sıralanmasına izin vermektedir. Daha sonrasında ise, hükümet yetkilileri bu sıralanmış listeyi rahatlıkla işleme tabii tutabilecektir, zira ne zaman olursa olsun, daha öncelikli ve acil olan şikayetle ilgilendiklerini bileceklerdir.","Complaints management is an important application of E-government. Collecting, combining, and ranking citizens? complaints is necessary for effective management. Existing complaints management applications expect the government officials to processeach complaint one by one to decide which complaint should be dealt with first. However, this is time consuming and thus ineffective.In order to cope with this, we are developing an ontology-based complaints management system to manage complaints. We have developed a complaints ontology with which the complaints of the citizens can be expressed. Furthermore, we combine complaints that are similar based on some criterion. By specifying constraints on the complaints, the officials can specify which type of complaints are more important than others. We then apply these constraints on the citizens? complaints using a reasoner.This allows us to prioritize the complaints automatically and rank them based on importance. The government officials can then process the ranked list, knowing that they are dealing with the most urgent complaint at any given time."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Zamansal uyumluluk ilkesi, zamana bağlı bir sinyalden faydalı değişmezlikler öğrenmek amacıyla, sinyalin hızlı değişen bileşenlerini bir kenara bırakıp, yavaş değişen bileşenlerine ayırmayı ifade eder. Zamansal uyumluluk ilkesinin görsel uyaranlara uygulanması şimdiye dek daha çok erken görme aşamalarındaki degişmezlikleri, özellikle de birincil görsel korteksteki karmaşık hücrelerin değişmezlik özelliklerini, modellemeyi amaçlamıştır. Daha zor bir görev olan yüksek görme aşamalarındaki değişmezlikleri modellemeyi başarabilen, ve bu tür bir beceriyi şart koşan gerçekçi nesne veritabanlarında yüksek performansla nesne tanıyabilen, zamansal uyumluluk ilkesi tabanlı yapay ağlar literatürde nadir bulunmaktadır. Bu çalışma, zamansal uyumluluk fikrinin belli bir türü olan yavaş öznitelik analizinin değişmez nesne tanıma uygulamarında faydalı olabilecek yüksek aşama görsel temsiller olusturulmasında kullanılıp kullanılamayacağını araştırarak, önceki cümlede bahsi geçen eksikliğin giderilmesine katkıda bulunmayı amaçlamaktadır. Bugüne kadar bildiğimiz kadarıyla literatürde yavaş öznitelik analizinin basit, yapay uyaranların aksine gerçekçi nesne veritabanlarına uygulanması gerçekleştirilmemiştir. Bu amaçla, bu calışmada yavaş öznitelik analizinin kendisinin gerçekçi nesne veritabanlarındaki yüksek derece degişmezlikleri modellemeye uygun olup olmadığını araştırabilmek için herbiri `yavaş öznitelik analizi' yapan ünitelerden oluşan basit ileri-beslemeli ağ mimarileri kullanılmıştır. Bu modeller iki çeşit veritabanı üzerinde test edilmiştir: birincisi, düzlemsel pozisyon, düzlemsel rotasyon ve ölçek değişiklikleri uygulanan harf lerden oluşan veritabanları; ikincisi, bakış açısı değişmezliği öğreniminin test edilmesi için COIL-20 nesne veritabanı. Bu testlerden elde edilen sonuçlar, yavaş öznitelik analizinin çok basit denetimli sınıflandırma algoritmaları için bile bir ön-işleme adımı olarak kullanıldığında oldukça tatmin edici sınıflandırma performansları elde edilebileceğini göstermektedir. Yavaş öznitelik analizinin gerçekçi veritabanlarına rahatlıkla uygulanabilmesinin önündeki başlıca engellerin başarılı öğrenme için çok büyük öğrenme veri-kümeleri gerektirmesi, ve kullanılan modeller karmaşıklaştıkça (özellikle SFA-3 ve SFA-4 modelleri için) çok çabuk öğrenme veri-kümesine aşırı-uyum eğilimi göstermesi olduğu gözlenmiştir.","Temporal coherence principle is the idea of neglecting rapidly changing components of a temporal signal while keeping to the slowly varying ones, in order to extract useful invariances from the signal. We note that most of the applications of temporal coherence principle to visual stimuli aim at modeling invariances in early vision (mostly deriving invariance properties of complex cells in primary visual cortex). Temporal coherence implementing networks that can accomplish the more challenging task of modelling invariances in higher vision and perform reasonably well on real-world object data-sets requiring some such complex invariant recognition capability are scarcely found. In this work, we try to address this issue by investigating whether a specific variant of the idea of temporal coherence, i.e. slow feature analysis (SFA), can be used to build high-level visual representations that might be useful for invariant object recognition tasks. To date, we know of no network implementation of SFA that is put to challenge on a real-world data-set, rather than on some toy sets of simple, artificial stimuli. To this end, we use single SFA implementing nodes and very generic feed-forward network architectures to see whether SFA itself is capable of modeling high-level invariances in realistic object datasets. We test our models on two datasets that require some such capability for good recognition performance: firstly, on a dataset of letters undergoing translation, planar rotation and scale changes, and secondly on the COIL-20 dataset to see whether SFA can successfully learn view-point invariance. Our results suggest that SFA can yield satisfactory results on these datasets especially when used as a pre-processing step for even very simple supervised classification algorithms. The major limitations for the application of SFA to realistic object databases have been the requirement of large training sets for successful learning and the tendency to quickly overfit the training data as the SFA models become slightly more complex (especially for SFA-3 and SFA-4)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Web servislerinin artan popülaritesi ile birlikte, son yıllarda kamu ve iş alanlarındaki mevcut servislerin sayısı hızla artmaktadır. Servis sayısındaki bu artııs servis bulma problemini daha önemli ve zor bir hale getirmiştir. Servis bulmanın temel elemanı servis eşlemedir. Servis eşleme, servis sağlayıcılarının sundukları servisler arasından, servis tüketicisinin isteğini karşılamaya uygun olanlarının bulunup getirilmesi sürecidir. Mevcut standart servis bulma mekanizmaları günümüz kullanıcıların ihtiyaçlarını karşılamayacak basit servis eşleme metodları sumaktadırlar. Daha iyi servis eşleme metodları geliştirmek için yakın zamanda yapılan araştırmalar servislerin girdi-çıktı arayüzlerinin anlamsal modellerine ve bu modellerin servis eşlemesinde kullanımına dayanmaktadırlar. Ancak bu metodlar içsel süreç bilgilerinin yetersiz kullanımı nedeniyle düşük hassasiyet göstermektedirler.Bu tezde mevcut servis eşleme metodlarına kıyasla daha iyi hassasiyet elde etmek amacıyla iki yeni servis eşleme metodu önerilmiştir. Bu hedefe ulaşmak amacıyla, servislerin anlamsal olarak zenginleştirilmiş içsel süreç bilgilerinin kapsamlı olarak kullanımının gerektiği öne sürülmüştür. Buna bağlı olarak, önerilen metodlarda servis eşlemenin temel bilgi kaynağı olarak servislerin anlamsal kavramlarla işaretlenmiş içselsüreç modelleri kullanılmıştır. Önerilen ilk eşleme metodunda servis modelleme için sonlu durum makineleri, servis eşleme için çeşitli yapısal ve anlamsal ölçüm metodları kullanılmıştır. Önerilen ikinci eşleme metodunda ise servis modelleme için zamanmantığı, servis eşleme için model doğrulama teknikleri kullanılmıştır. Önerilen metodların gerçekleştirilmesi amacı ile bir servis eşleme taslağı önerilmiş ve durum incelemesi yolu ile önerilen metodlar değerlendirilmiştir.","With the increasing popularity of Web services, number of available services on public and business domains grows rapidly in the recent years. This growth in the number of services makes service discovery more important and challenging. The fundamentalelement of service discovery is service matchmaking. Service matchmaking is the process of retrieving suitable services given by service providers to satisfy service request of service consumers. The current standard service discovery mechanism providesonly primitive service matchmaking methods, which are not sufficient to fulfill the requirements of todays consumers. Recent research to develop better service matchmaking methods is based on the use of semantic models of input-output interfaces of services and their use in service matchmaking. However these methods suffer from low precision due to lack of use of internal process knowledge of services in matchmaking.In this thesis we propose two novel service matchmaking methods to achieve better precision than the state of the art service matchmaking methods. In order to achieve this goal, we claim that extensive use of semantically augmented internal process knowledge of service is necessary. Hence, in our proposed methods we use internal process models, which we markup with semantic concepts, as the core information source for service matchmaking. Our first matchmaking method uses finitestate machines for service modeling and several structural and a semantic similarity metric for matchmaking. Our second method uses temporal logic for modeling and model checking techniques for matchmaking. We propose a generic service matchmaking framework to realize our proposed approaches and conduct case studies to evaluate strong and weak points of our proposed matchmaking methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz algılayıcı ağlar (KAA) akıllı çevreler yaratılmasını sağlayan yeni bir ağ ailesidir. KAA'ların birçok kullanım alanı olmasına rağmen, askeri amaçlı olanları en ilginçleridir. Bu tezde, askeri gözetleme amaçlı zaman bölümlü çoklu erişim tabanlı yeni bir KAA (MILMON) önerilmiştir. MILMON geniş alanlarda makul bir sure dahilinde çalışmak üzere geliştirilmiştir. MILMON'un tasarım hedefleri enerji harcamasını azaltmak, gecikmeyi azaltmak, hata toleransını artırmaktır. Zaman bölümlü çoklu erişim tabanlı sistemlerin ana problemleri zaman senkronizasyonu ve zaman bölme dağıtımıdır. MILMON'u gerçekleyebilmek için, yeni bir zaman senkronizasyon mekanizması (SyncHRT), yeni bir zaman bölme dağıtım mekanizması (ft_DTSM) ve veri gösterge bölmesi mekanizması (DISM) önerilmiştir.Çıkış düğümünde bulunan uzun menzilli verici ile zaman senkronizasyonu, SyncHRT, enerji harcamasını en aza indirmek ve kesinliği artırabilmek amacı ile tasarlanmıştır. Uzun menzilli vericinin yolladığı sinyalleri birçok algılayıcı düğümün alabildiği kabul edilerek bu mekanizma geliştirilmiştir. Böylece çıkış düğümünün sinyalleri ile düğümler kendilerini doğrudan çıkış düğümüne senkronize edebilmektedir. Simülasyon modelleri SyncHRT'nin enerji harcamasını azaltırken kesinliği de arttırdığını göstermiştir. MILMON için önerilen bir başka mekanizma ise gecikmeye hassas, enerji verimli ve hata toleranslı dağıtık zaman bölümü dağıtım algoritmasıdır (ft_DTSM). Halen mevcut olan zaman bölümü dağıtma algoritmalarından çok daha az enerji harcar ve KAA'larda çok sık görülen yaklaşımlı veri trafiği esas alarak gecikmeyi de azaltır. ft_DTSM'in hata toleranslı yapısı, tek nokta hatalarına karşın ağın çalışabilmesine yardımcı olur. Askeri gözetleme sistemlerinin çoğunda olduğu gibi düşük veri yüklerine sahip sistemlerde, enerji harcamasını azaltan bir diğer mekanizma olarak veri gösterge bölmesi mekanizması (DISM) geliştirilmiştir.Analiz ve simülasyon sonuçları, sadece gecikme yada sadece enerji harcaması için MILMON'dan daha iyi performans gösteren KAA'lar olmasına karşın, MILMON'un enerji, gecikme ve hata toleransı konularında bir eniyileme gerçekleştirebildiğini göstermektedir.","Wireless sensor network (WSN) is a new network family that enables to create smart environments. Although WSN has many application areas, military applications of WSN are very interesting. In this thesis, a new TDMA based sensor network for military monitoring (MILMON) is proposed. MILMON is developed to operate in large areas for acceptable lifetime periods. Design considerations of MILMON are energy consumption, delay, and fault tolerance. The main problems of TDMA based systems are time synchronization and time slot distribution. In order to realize MILMON, a new time synchronization mechanism (SyncHRT), a new distributed time scheduling mechanism (ft_DTSM) and data indicator slot mechanism (DISM) are proposed. Time synchronization with high range transmitter, SyncHRT is designed to minimize energy consumption and maximize precision. It assumes the existence of high range transmitter, so that many of the nodes can receive the broadcast signal of the high range transmitter. In this way, sensor nodes can be synchronized to a central point. Simulation model shows that SyncHRT can reduce energy consumption and increase precision. Another mechanism proposed for MILMON is delay sensitive, energy efficient and fault tolerant distributed slot assignment algorithm (ft_DTSM). It uses much less energy than the existing slot assignment mechanisms and it reduces delay with the convergecast traffic assumption which is very common traffic type for WSNs. Its fault tolerant structure helps to survive against single point of sensor node failures. Another mechanism proposed for MILMON is data indicator slot mechanism (DISM) which reduces energy consumption especially on low traffic requirements, as in most of the military monitoring systems.Analysis and simulation show that although there are WSN systems that perform better than our system for only energy consumption or for only delay, MILMON realizes an optimization on energy, delay and fault tolerance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde kamera tabanlı işaret dili tanıma problemi üzerine çalışılmış ve üç alt problemde yoğunlaşılmıştır: (1) belirteçsiz el izleme, (2) çok kipli tümleştirme, (3) tanıma. Bu alt problemler için literatürde sunulan çalışmalara göre daha gelişmiş teknikler önerilmiş ve karşılaştırmalı analizler yapılmıştır. İşaret dilinde eller birbirini ya da yüzü kapatabilir. Bu tür durumlarda da gürbüz izleme yapabilecek bir izleme algoritmasına ihityaç vardır. Bu çalışmada çok sayıda nesnenin takibi sırasında temas ve kapatma durumlarında da gürbüz izleme yapabilen, birleşik parçacık süzgeci tabanlı bir yöntem önerdik. Yapılan testlerde önerilen yöntemin temas ve kapatmaya karşı gürbüz olduğu ve mevcut yöntemlere göre daha iyi çalıştığı gözlendi. İşaret dili, temelinde el hareketleri ve el şekline dayanan fakat bunların yanında yüz mimiklerinin, baş ve vücut hareketlerinin de kullanıldığı görsel bir dildir. Bu çalışmada işaretlerin bu çok kipli yapısını dikkate aldık ve ardışık tümleştirme yöntemi ile inanç tabanlı bir tanıma sistemi geliştirdik. Sonuçlar önerdiğimiz yöntemin literatürdeki diğer tümleştirme yöntemlerine göre daha başarılı olduğunu gösterdi. Bu çalışmada önerdiğimiz bir diğer yöntem ise, üretici ve ayırıcı modellerin birleştirilerek işaret tanıma amaçlı kullanılması üzerinedir. İşaret tanıma probleminde yoğunlukla kullanılan üretici modelleri, ayırıcı modellerin sınıflandırma gücü ile birleştirmek için Fisher çekirdeklerini kullandık ve çok sınıflı sınıflandırma yöntemi önerdik. Deneylerde bu yöntemin üretici ve ayırıcı modellerin güçlü yanlarını tek bir modelde toplayarak sınıflandırma başarısını arttırdığı görülmektedir. Bu çalışma kapsamında ayrıca, çalışmada önerilen yöntemleri ve fikirleri kullanan iki uygulama, işaret dili eğitmeni ve otomatik işaret dili sözlüğü, geliştirilmiştir.","This thesis addresses the problem of vision based sign language recognition and focuses on three main tasks to design improved techniques that increase the performance of sign language recognition systems. We first attack the markerless tracking problem during natural and unrestricted signing in less restricted environments. We propose a joint particle filter approach for tracking multiple identical objects, in our case the two hands and the face, which is robust to situations including fast movement, interactions and occlusions. Our experiments show that the proposed approach has a robust tracking performance during the challenging situations and is suitable for tracking long durations of signing with its ability of fast recovery. Second, we attack the problem of the recognition of signs that include both manual (hand gestures) and non-manual (head/body gestures) components. We investigated multi-modal fusion techniques to model the different temporal characteristics and propose a two-step sequential belief based fusion strategy. The evaluation of the proposed approach, in comparison to other state of the art fusion approaches, shows that our method models the two modalities better and achieves higher classification rates. Finally, we propose a strategy to combine generative and discriminative models to increase the sign classification accuracy. We apply the Fisher kernel method and propose a multi-class classification strategy for gesture and sign sequences. The results of the experiments show that the classification power of discriminative models and the modeling power of generative models are effectively combined with a suitable multi-class strategy. We also present two applications, a sign language tutor and an automatic sign dictionary, developed based on the ideas and methods presented in this thesis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Abonelere kişiye özel hizmetler sunmak GSM operatörleri için yeni bir ilgi alanı oluşturmaktadır. Özelleşmiş hizmetler sunmanın en etkili yolu konuma dayalı hizmetler sunmaktır. Müşterinin kullanması muhtemel yollardaki trafik sıkışıklığını haber veren uygulama, müşteriye yakın mağazalardaki indirimlerin haber verilmesi, bir müşterinin yakınlarında aradığı özelliklede başka bir kişinin varlığının bildirilmesi konuma dayalı kişisel hizmetlere örnek verilebilir. Fakat müşterilerin yerlerini takip etmek oldukça pahalı bir işlemdir.Buradaki amaç GSM operatörüne yapılan konum sorgulama sayısının azaltılmasıdır. Bu tezde hesaplı bir şekilde müşterilerin yerlerini takip edebilmek için çözüm sunulmaktadır. Sunulan çözüm müşterilerin gelecekteki konumlarını tahmit etmeye dayanmaktadır. Konum tahmini müşterilerin hareket alışkanlıklarını çıkartarak yapılmaktadır. Bu tezde iki çeşit hareket alışkanlığı kullanılmaktadır: yolculuk alışkanlığı ve belirli yerlerde uzun süre durma alışkanlığı. Her alışkanlık çeşidi için ayrı tahmin yöntemleri kullanılmaktadır: yol tahmini ve nokta tahmini.Sunulan çözüm, bir GSM operatörünün sağladığı gerçek konum bilgisi ve yapay olarak üretilen konum bilgisi kullanılarak test edilmiş ve sonuçlar istenilen başarının sağlandığını göstermiştir. Hata payı belirli bir seviyede kalmak kaydıyla konum sorgulama sıklığı önemli ölçüde azaltılmıştır.","Delivering personalized services to subscribers is a relatively new challengingarea for GSM content providers. One of the most effective ways to personalize mobileservices is to make use of the location of the mobile device and to provide locationbased services.Example location based services are receiving alerts about a traffic jam, notification of a sale on gas, issuing discount coupons to customers nearing a store andproviding information about playing movies in cinemas around. Applications can alsobe developed that will inform users about other users in close vicinity that have matchingprofiles, this type of application for example can be used for friend finding. Howevertracking users is a very expensive operation.The goal is to decrease the number of location queries sent to GSM operators whentracking users. A solution is presented to track users cost efficiently by predicting futurelocations of users. The algorithm proposed extracts movement patterns of subscribersand uses these patterns for location prediction. Two types of patterns, stationary andmovement, are mined from movement data and two types of predictions, point andpath, are used for predicting location.Real location data of many users provided by a GSM operator are used to evaluatethe algorithm. Simulations are also performed with artificially generated log data.Results demonstrated that the number of location queries is reduced signicantly whilekeeping error rate in an acceptable level."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, Türkiye'deki bankaların sistem geliştirme süreçlerindeki güncel durumunu, uluslararası kabul görmüş yazılım ve sistem geliştirme standartlarını kullanarak incelemeyi amaçlamaktadır. Çalışma öncelikle mevcut sistem geliştirme ve yazılım geliştirme standartlarını incelemekte, standartların detaylı incelenmesinden sonra süreçleri baz alan standartlar seçilerek bankaların süreçlerinde durum tesbiti yapmak için Çağlayan sistem geliştirme modeli aşamalarına gore sıralanmış bir süreç soru listesi oluşturulmaktadır. Soru listesinde yer alan her soru standartlarda yer alan süreç önerileri ve uyarılar baz alınarak oluşturulmuştur. Çalışmanın devamında oluşturulan sorular kullanılarak Türkiye'nin üç büyük bankası ile görüşmeler yapılmıştır. Görüşmelerden çıkan mevcut durumlar üç banka için standartlarda belirtilen ve beklenen durumlar ile birlikte değerlendirilerek üç bankanın süreç sorunları incelenmiş ve belirlenmiştir.","This thesis examines current system development processes of three major Turkish banks in terms of compliance to internationally accepted system development and software engineering standards. After a deep scan on system development and software engineering standards, related process-based standards are selected and used to form a question list covering whole system development process that is ordered like classical Waterfall life cycle model. Each question in the checklist is made up of guidance and suggestions from the international system development standards. Later on, questions are interviewed with information technology departments of three major banks in Turkey. Results have been aggregated by examining current process status of three banks together and problematic points have been identified using international system development standards."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezin konusu, nesnenin duruşu ve ışıklandırmanın değiştiği, önünü kapatan başka nesnelerin bulunduğu koşullarda, karmaşık bir sahnede insan başını izlemektir. Hareket tahmini ile birlikte nesnenin renk dağılımı ve doku özelliklerinin birleşimini kullanan genel bir izleme algoritması sunulmaktadır. Nesne kullanıcının başlangıçta seçtiği elips bir pencere ile tanımlanır. Renk dağılımı kroma bileşenlerine daha çok çözünürlüğün ayrıldığı bir YCrCb uzayında nesnenin renk histogramının hesaplanması ile elde edilir. Bilinen kesikli histogramın yanısıra yeni bir yöntem olarak Tekdüze Bulanık Renk Histogramı (UFCH) önerilmektedir. Nesne dokusu nesnenin kesikli kosinüs dönüşümünün (DCT) düşük frekans bileşenleri ve yerel ikili örüntüler (LBP) ile temsil edilir. İzleyiciyi kullanarak farklı özelliklerin ve birleşimlerinin verimleri denenmektedir. İzleme yordamı, örneklem kümesinin nesne penceresinin ötelenmesi ile elde edildiği Koşullu Yoğunluk Tahmini (Condensation) parçacık süzgeci ile sabit hızlı hareket tahminine dayanır. Histogramların karşılaştırılması Bhattacharyya katsayısına, DCTlerin karşılaştırılması ise farkların kareleri toplamına (SSD) dayanır. Benzerlik ölçütleri bağımsız olabilirlikler olarak birleştirilmektedir. Birleşik izleyici aynı nesnenin farklı özelliklerini izlediği için yalnızca renk dağılımı ya da sadece yapı bilgisini kullanan izleyicilerden daha gelişmiştir. Algoritma filmlere etkileşimli nesne bilgileri gömülmesi üzerinde denenmekte ve buna uygun hale getirilmektedir.","Tracking a human head in a complicated scene with changing object pose, illumination conditions, and many occluding objects, is the subject of this thesis. A general tracking algorithm is presented, which uses a combination of object color statistics and texture features with motion estimation. The object is defined by an ellipse window that is initially selected by the user. Color statistics are obtained by calculating object color histogram in the YCrCb space, with more resolution reserved for chroma components. In addition to the conventional discrete color histogram, a novel method, Uniform Fuzzy Color Histogram (UFCH) is proposed. The object texture is represented by lower frequency components of the object's discrete cosine transform (DCT), and local binary patterns (LBP). By using the tracker, performances of different features and their combinations are tested. The tracking procedure is based on constant velocity motion estimation by condensation particle filter, in which the sample set is obtained by the translation of the object window. Histogram comparison is based on Bhattacharyya coefficient, and DCT comparison is calculated by sum of squared differences (SSD). Similarity measures are joined by combining their independent likelihoods. As the combined tracker follows different features of the same object, it is an improvement over a tracker that makes use of only color statistics or texture information. The algorithm is tested and optimized on the specific application of embedding interactive object information to movies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Mobil teknolojiler günlük yaşamımızın birer parçası haline geldikçe, bilgiye erişmek için ihtiyaç duyulan akıllı gömülü sistemlere olan talep hızla artmaktadır. Bu tip sistemlerdeki zeka faktörü, içlerindeki yazılımda geliştirilmektedir. Dolayısıyla, yazılım mühendisliğinin güncel problemleri, gömülü sistemler için de geçerli hale gelmiştir.Gömülü sistem endüstrisinin, sert rekabet koşulları ve kısıtlı kar payı gibi kendine özgü problemleri bulunmaktadır. Endüstri, varolan süreçlerini iyileştirmek, ürünün kalitesini arttırmak ve maliyetini düşürmek için yaratıcı çözümler aramaktadır. Gömülü yazılım, son ürüne her geçen gün daha fazla hükmettiğinden, yazılım geliştirme döngüsündeki herhangi bir gelişme, endüstriye büyük faydalar sağlayacaktır.Yazılım geliştirmede en masraflı ve fazla zaman alan aşama test sürecidir. Uzmanlar, yazılımın kalitesini bozmadan, sınırlı zaman ve eforlarını verimli bir şekilde kullanabilmek için, yeni çözümlere ihtiyaç duyarlar. Bu çözümler, öğrenmeye dayalı tahmin modelleridir. Amaç, yazılımdaki hatalı parçaları tespit ederek test süreci için etkili ve hızlı yöntemler sunmaktır.Bu araştırmada, gömülü sistemlerin karakteristik özellikleri analiz edilerek, gömülü yazılımlara uygun bir hata tahmini modeli önerilmiştir. Hata tahmininde uygulanan en güncel makine öğrenme algoritması kullanılarak, aşamalı bir öğrenme mekanizması geliştirilmiş, böylece, modelin hata yakalama performansının arttırılması hedeflenmiştir.Hata tahmini araştırması üç açıdan ele alınarak, gömülü yazılımlar alanındaki uygulanabilirliği araştırılmıştır. Temel aşamalar a) modelin performasını iyileştirmek, b) veri toplama maliyetini azaltmak ve c) verinin içeriğini arttırmak şeklinde özetlenebilir.","As mobile technologies advance and become part of our everyday life, we need nomadic access to information through intelligent and interoperable devices. Hence there is an increasing demand for intelligent embedded systems. The intelligence comes from the software that runs on them, therefore, the current problems in software engineering also hold true for embedded systems domain.Embedded systems industry has its own unique challenges as well: tough competition and tight profit margins. The industry constantly seeks for creative solutions to improve existing processes, to increase the quality of the product, and to lower the costs. Since the embedded software increasingly dominates the end product, any improvement in software development lifecycle would bring tremendous benefit to the industry. The most costly and time consuming process area in software development is testing. Practitioners need oracles to help them decide how to allocate their limited time and effort effectively without affecting the quality of their embedded software. These oracles are basically learning-based predictive models that aim to provide effective and robust methodologies for testing phase by focusing on defect-prone parts of the software.In this research, we propose a software defect prediction model for embedded software by analyzing specific characteristics of embedded systems. We employ a cascading learning mechanism to increase the prediction performance of the model by using the state of the art machine learning algorithm for software defect prediction.We have examined the three pillars of defect prediction research and its practical challenges for embedded software domain: a) improving the prediction performance of the model, b) analysis of data collection effort and cost, and c) increasing the information content of data used in the model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar ağlarındaki büyüme ve günlük yaşamımızın bilgisayar tabanlı sistemlere bağımlılığının artması ile birlikte, bilgisayar sistemlerinin güvenli birşekilde çalışmasını sağlamak büyük önem kazandı. Bilgisayar ağlarını daha güvenli hale getirmek için, saldırı tespit sistemleri (IDS), ağdaki saldırıları saptamayı hedeflemektedirler. Bu çalışmanın amacı maksimum dağıntı yaklaşımını temel alan saldırı tespit sistemlerinin iyileştirilmesi ve geçici kuralların enformasyon teorisini ve istatistik sinyal işleme yöntemlerini kullanarak formüleştirilmesidir.Bu çalışmada hizmet engelleme saldırılarının (DoS) maksimum dağıntı ve hipotez test yöntemlerini kullanarak belirlenmesi amaçlanmaktadır. Önerilen yöntem eğitim ve saptama olarak iki safhadan oluşmaktadır. Eğitim kısmında, maksimum dağıntı yöntemi kullanılarak çeşitli saldırılar olması ve saldırı olmaması durumları için modeller kestirilmektedir. Saptama kısmında ise hipotez test yöntemi ile hangi modellin şuanki trafiğin özelliklerini daha büyük ihtimalle sağladığına karar verilmektedir. Önerilen yöntem hem normal ağ trafiğinin davranışına hem de bilinen saldırı tiplerinin davranışlarına odaklandığından, anomali saptama ve kötü kullanım saptama yöntemlerinin karışımı olarak düşünülebilir. Deneysel sonuçlar, önerilen yöntemin değişmeyen özelliklere sahip ve ağ trafiğinin çarpıcı bir şekilde değişimine sebep olan hizmet engelleme saldırılarının belirlenmesinde çok başarılı olduğunu göstermektedir. Fakat bu yöntem değişken özelliklere sahip ve kanıtları başlık bilgisinden farkedilebilir olmayan hizmet engelleme saldırılarının saptanmasında yetersiz kalmaktadır.","With the growth of computer networking and increased dependency of our every day life on the computer based systems, assuring reliable operation of computer systems has become very important. In order to render computer networks more secure, intrusion detection systems aim to recognise attacks. The objective of this work is to improve maximum entropy based intrusion detection methods and bring a formularization to ad hoc rules by using information theory and statistical signal processing.In this work, it is intended to identify denial-of-service attacks by using maximum entropy and hypothesis testing methods. Proposed method consists of two phases: training and detection. In the training part, models are estimated for various attack types and no attack case based on the maximum entropy principle. In the detection part, hypothesis testing technique is employed to decide which of these models most probably satisfies the characteristics of the current network traffic. The method proposed in this thesis can be considered as a hybrid form of anomaly detection and misuse detection methods, since it focuses on not only the characteristics of normal network activity but also the characteristics of the known attacks. According to the experimental results, proposed method is very succesfull in identifying the denial-of-service attacks which have invariable characteristics and cause a dramatic change in network traffic. However, our method is inadequate for detecting denial-of-service attacks, which have variable characteristics and whose evidences are not noticeable from header information."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"E-öğrenme sistemlerinin sadece başarı ve etkinliği değil değerlendirilmesi de karmaşık bir konudur. E-öğrenme uygulamalarının verimli olarak kullanılması için e-öğrenme sistemlerinin başarı ve etkinliğini ölçmek için güvenilir metotlar gereklidir. Bu tezin amacı başarı kriterlerinin belirlenerek e-öğrenme sistemlerinin başarı ve etkinliğinin ölçülmesini sağlayacak bir prototip sağlamaktır. Tezde kullanılan e-öğrenme sitemleri ve test araçları ticari olmayan, açık kaynak kodlu yazılımlar arasından seçilmiştir.Bir e-öğrenme sistemini başarılı bir şekilde değerlendirmek için sistemin değişik boyutları hesaba katılmalıdır, örneğin standartlar, kalite nitelikleri ve başka kriterler. Bu tez çalışmasında, e-öğrenme sistem yazılımlarını test etmek için bazı otomatik yazılım test araçları incelenmiş ve seçilenler kullanılmıştır. Açık kaynak kodlu Ilias, Dokeos, Docebo, Claroline ve Efront öğrenme yönetim sistemleri değerlendirilmek için seçilmiştir. E-öğrenme sistemleri değerlendirilirken yazılım testine odaklanılmış, tüm e-öğrenme süreci göz önüne alınmamıştır. Performans, işlevsellik, erişilebilirlik, güvenlik ve standart uyumluğu e-öğrenme sistemlerinin başarısı için gösterge olarak varsayılmıştır. İşlevsellik dışında diğer kriterler ticari olmayan test araçları ile değerlendirilmiştir. Sistemlerin işlevsellik testi için, işlevsellik karşılaştırma matrisi geliştirilmiştir. Matristeki her bir kritere 22 e-öğrenme uzmanının cevapladığı anket sonucuna göre ağırlık verilmiştir.Belirlenen kriterlere göre sistemlerin genel değerlendirmesi, testlerden alınan standart puanların ağırlıklı toplamları kullanılarak yapılmıştır. Kriterlerin ağırlıkları anketten alınan sonuçlar kullanılarak hesaplanmıştır. Hesaplamalar sonucunda öğrenme yönetim sistemlerinin sıralaması Docebo, Dokeos, Moodle, Claroline, Ilias ve Efront şeklinde oluşmuştur. Docebo ve Dokeos'un puanları birbirine çok yakındır.","E- learning system is a complex issue not only because of its success and effectiveness but also because of its evaluation. Reliable ways to measure the success and effectiveness of the e-learning system are required for e-learning applications to be used efficiently. The purpose of this thesis is to provide a prototype to evaluate e-learning systems? success and effectiveness by addressing the success criteria. E-learning systems and testing tools used in this thesis were especially selected from among non-commercial and open source software.In order for a successful e-learning system assessment, different dimensions of the system such as standards, quality attributes and several other criteria should be taken into consideration. In this thesis study, some automated software testing tools are examined and then selected to execute to test the e-learning systems? software. Open source Learning Management Systems were selected to evaluate, namely Moodle, Ilias, Dokeos, Docebo, Claroline and Efront. Assessment of e-learning systems success was focused on software testing, the whole e-learning process was not considered. It is assumed that performance, accessibility, security and standard compliance, and functionality comparisons of the systems can be indicators of the whole e-learning system success. Some non-commercial testing tools were used to evaluate e-learning systems according to the previously defined criteria except functionality. In order for the functionality testing of the systems, functionality comparison matrix was developed. Each criterion in the matrix weighted according to the survey results, which was answered by 22 e-learning specialists.Weighted sum of the standardized scores of tests were used to evaluate systems overall success according to the defined criteria. Weights were calculated according to the third part of survey. LMSs? scores according to these calculations were figured out in the order of Docebo, Dokeos, Moodle, Claroline, Ilias and Efront, whereas the scores of Dokeos and Docebo were very close to each other."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Proteinlerin iç dinamikleri simulasyon tekniklerinin yardımıyla, örneğin moleküler dinamikler (MD) simulasyonuyla analiz edilebilirler. Büyük boyutlu olan MD verisine sıklıkla uygulanan ana bileşenler analizi sonucunda proteinin işleviyle ilişkili oldukları bilinen esas modlar (ana bileşenler) elde edilir. Yakın zamandaki bir çalışmada, Alakent ve çalışma arkadaşları MD verisinden elde edilen esas modları zaman serileri modelleriyle incelemiş ve elde edilen parametreleri protein dalgalanmaları açısından yorumlamışlardır.Bu tezde, dihidrofolat redüktaz ve triozfosfat izomeraz enzimleri, MD verilerinden elde edilen ana bileşenlerine zaman serileri analizi uygulanarak incelenmiştir. Enzimlerin serbest (apo) ve ligand-bağlı halleri üzerinde gerçekleştirilen MD simulasyonlarının 3.2 ns uzunluğundaki ikişer bağımsız kısımları kullanılmıştır. İkişer bağımsız örnekten çıkarılan model parametrelerinin aynı hal için birbirlerine benzer çıkmaları analizin güvenilirliğini ve farklı konformasyonel altdurumların proteinin vibrasyonel frekans yoğunluğu üzerindeki etkisinin derecesini göstermiştir. DHFR, birbirlerinden bir hidrid iyonu farkı olan iki ayrı ligand ile incelenmiştir. NADPH ligandının DHFR proteinin beraber hareketlerine katılımı NADP+ ligandından yüksektir. NADPH bağlı DHFR proteinindeki beraber hareketlerin serbest haldekine benzediği, NADP+ bağlı haldeki beraber hareketlerin ise kaybolduğu gözlemlenmiştir. Hem DHFR hem de TIM proteinlerinin serbest hallerinin ligand bağlı hallerinden daha esnek oldukları görülmüştür. Her iki proteinde de ligand bağlanması düşük frekansları daha yüksek frekanslara doğru kaydırmıştır. NADP+ bağlı DHFR proteinin vibrasyonel frekanslarının NADPH bağlı halden daha düşük olduğu görülmüştür. Özetle, ligand bağlanmasının proteinlerin salınımlarının beraberliğini, vibrasyonel düşük frekans yoğunluğunu ve harmonik olmayan hareketlerini etkilediği; özellikle vibrasyonel frekansların katalitik döngü üzerinde önemi olabileceği sonuçlarına varılmıştır. Proteinlerin birbirleri ile bağlanma eğilimi incelenirken bu etkenlerin hepsi göz önüne alınmalıdır.","Internal dynamics of proteins can be analyzed by the help of simulation techniques, one of which is molecular dynamics (MD) simulation. Principal component analysis is commonly applied on large-sized MD simulation data to extract the functionally relevant essential modes (principal components). Recently, Alakent et al. analyzed the principal components from MD simulation data by time series models and interpreted the obtained parameters in terms of protein fluctuations.In this thesis, MD trajectories of two enzymes, dihydrofolate reductase (DHFR) and triosephosphate isomerase (TIM), are investigated by performing time series analysis on the principal components. Two independent MD trajectories of 3.2 ns duration are used for the free (apo) and ligand-bound (liganded) states of each enzyme. Model parameters extracted from two independent runs are similar for the same state of each enzyme, which indicates the reliability of the analysis, and shows the extent of the effect of different conformational substates on the protein vibrational frequency density. DHFR has been analyzed with two different ligands which differ from each other by only hydride ion. The contribution of NADPH to the collective motions of DHFR is higher compared to those of NADP+. It is also seen that the collective motions in NADPH bound DHFR are similar to the unliganded form, while the collective character of the motions in the NADP+ bound DHFR is lost. It is found that unliganded forms of both DHFR and TIM are more flexible than liganded form. For both TIM and DHFR, low frequencies shift to higher frequencies after the ligands bind. Vibrational frequencies of NADP+ bound DHFR are lower than those of NADPH bound DHFR. Briefly, it can be concluded that ligand binding affects the collectivity of fluctuations, vibrational low frequency density and anharmonic motions of proteins, and particulary vibrational frequencies of the proteins may have importance on the catalytic cycle. All these effects should be taken into consideration for examing binding affinities of proteins."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez şekil interpolasyonuna dayalı üç boyutlu parametrik bir insan bedeni modelleme gereci ortaya koymaktadır. İnsan bedeni modellemede günümüze kadar uygulanmış yöntemlerin bir sınıflandırması verilmektedir. Şekil interpolasyonunda yerel kontrolu sağlamak için, insan bedeni şekil tanımları antropometrik olarak bölümlenmiş-tir. Bölümler arası sınır bölgelerde pürüzsüz süreklilik, ağırlıklı bir interpolasyonla sağlanmıştır.Üç boyutlu model üzerinde bölümlerin imlenmesi için başka bir gereç geliştirilmiş- tir. Bu gereç her model için kanatlı kenar veri yapısı oluşturmaktadır. Bu yapı sayesinde nokta komşulukları bulunabilmektedir. Noktaların interpolasyon ağırlıkları da bu aşamada atanmaktadır. Sınır bölgelerde pürüzsüz sürekliliği sağlamak üzere, ağırlık atamaları için sönümlenen işlevler kullanılmaktadır.Sonuç modellerden görüntü sentezlemek için, octree'lerle hızlandırılmış ışın izleme yöntemi uygulanmaktadır. Örtüşme-önleme için kararsız desenli ileri örnekleme kullanılmaktadır. Uygulama olarak bir sanal giydirme gereci geliştirilmiştir. Bu gereç, üç boyutlu bir modelleme arayüzü ve giysilerin fotoğrafik görüntüleri ile bedenlerin sentezlenen görüntülerini kullanan bileşim altyapısıyla sanal bedenlerin giyinmiş görüntü- lerini oluşturan bir giydirme ortamı içermektedir.","This thesis presents a parameterized 3D human body modeling tool based on shape interpolation. In order to have local control on shape interpolation, human body shape descriptions are anthropometrically segmented. Smooth continuity at the boundaries of individual segments is achieved by weighted interpolation.A 3D editing tool has been developed for segmentation. This tool employs winged edge data structure. This structure allows fast access to vertex neighborhoods. The interpolation weights for vertices are assigned during segmentation. We use decaying functions to assign weights on boundary regions, enabling smooth continuity.Raytracing accelerated by octrees is used for synthesizing images of the resulting models. Anti-aliasing in these images is achieved by super-sampling with jittered patterns. The thesis also introduces a virtual dressing tool. This tool contains a 3D modeling interface and a dressing environment combined with a compositing subsystem, which creates dressed images of virtual replicas by utilizing layers of photographic images of garments and layers of synthesized images of body replicas."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Farklı dağılımlar üzerinden rassal değişken üretimi, stokastik benzetim için önkoşul oluşturmaktadır. Belirli programlama dilleri ve yazılımlar, standart dağılımlar için rassal değişken üretimini destekleyen fonksiyonlar barındırmaktadırlar. Yine de, standart olmayan dağılımlar ve yarı dağılımlardan rassal değişken üretebilmek için otomatik algoritmalara ihtiyaç duyulmaktadır. Bu araştırmada, Üçgensel Ahrens ve Polinomlu Yoğunluk Fonksiyonunun Ters Dönüşümü adında iki adet otomatik rassal değişken üretim yöntemi sunulmuştur. Bunların mevcut yöntemlerle yalınlık, hız ve diğer performans ölçütleri üzerinden kıyaslanabilirliği incelenmiştir. Algoritmaların temel içeriği açıklandıktan sonra, sözde kodları ayrıntılarla verilmiştir. Her iki algoritma da C programlama dili kullanılarak düzenli ve anlaşılabilir bir şekilde kodlanmıştır. Sayısal sonuçlar her iki algoritmanın da başarılı bir performans sergilediğini göstermektedir. Değişken reddetme yöntemi olan Üçgensel Ahrens daha küçük tablolar yardımıyla daha düşük reddetme katsayılarına ulaşmaktadır. Olasılık yoğunluk fonksiyonunu parçalar halinde polinomlara yaklaştıran Polinomlu Yoğunluk Fonksiyonunun Ters Dönüşümü ise daha karmaşık olmasına rağmen daha küçük tablolar yardımıyla göze çarpan yaklaşıklıklara ulaşmaktadır. Ayrıca, tek rassal değişken üretim zamanının daha hızlı olması Polinomlu Yoğunluk Fonksiyonunun Ters Dönüşümü'nü daha yüksek sayıda rassal değişken üretimi için seçkin kılmaktadır.","For stochastic simulation, the generation of random variates from different distributions is a prerequisite. In certain programming languages and software, there are already random variate generation functions of standard distributions. However, for generating random variates from non-standard distributions or quasi-densities, we need universal algorithms. In this research, we come up with two universal random variate generation methods, namely the Triangular Ahrens and the Polynomial Density Inversion. We try to see if they are competitive with existing methods with respect to simplicity, speed and other performance criteria. After explaining the basics of the algorithms, we define the pseudo-codes in detail. Both of the algorithms are coded in C in a comprehensible and elegant way. Numerical results indicate that both of the algorithms execute with a successful performance. The Triangular Ahrens, which is a rejection method, has a smaller rejection constant while it requires smaller tables. The Polynomial Density Inversion, which approximates the density with piecewise polynomials, is more complicated however we obtain outstanding approximations with smaller tables. It also has a faster marginal execution time which makes the Polynomial Density Inversion a preferable method for a large number of random variates."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Göç kavramı insanlık tarihi kadar eskidir. Sebepleri ve şekilleri yıllar içinde değişse de, sosyal bir davranış olarak göç ilk insandan bu yana süre gelmiştir. Göç hakkında farklı disiplinlerin farklı calışmaları ve teorileri vardır. Fakat göç konusu temelde sosyal bilimlerin konusudur ve insanoğlunun incelenmesi en zor davranışlarından biridir. Bu yüksek lisans tezinde yapılan çalışma göçü anlamaya ve sugarscape ortamında simule etmeye yönelik bir calışmadır. Göçü anlamak için, şimdiye kadar yapılmış calışmalar incelenmiş ve göçün başlamasını ve devam etmesini açıklayan teoriler bir araya getirilmiştir. Göçü sosyal açıdan inceleyen calışmalar haricinde, göçü modelleyen ve simule eden çeşitli calışmalar da incelenmiş ve kendi yaratacağımız modelde nelere dikkat etmemiz gerektiği belirlenmiştir. Bu çalışmalardan sonra göçü simule etmek için modeller oluşturulmuştur. Fakat oluşturduğumuz modellerde karşılaştığımız zorluklardan sonra bu kadar karışık bir insan davranışının kısa bir süre içinde modellemenin zorluğu anlaşılıp, toplam göç hareketinin bir safhasını oluşturan kolonileşme konusuna odaklanılmıştır. Birbirinden farklı yetenekte ve motivasyonda iki ırk yaratılıp bu ırkların yeni bir bölgenin kolonileşmesi sırasındaki hareketleri ve başarıları incelenmiştir. Ortamın ve ırkların özelliklerinin değişik değerleri için başarı oranlarındaki değişim incelenmiş ve çıkan sonuçların sebepleri açıklanmaya calışılmıştır.","Migration is as old as human history. The reasons and ways of migration are different from each other in different parts of history, but migration exits as a social behavior since the emergence of the first human. Although different disciplines have different types of studies on migration, migration is mainly a topic of social science and it is one of the difficult social behaviors of human to investigate. The work done in this M.S. thesis is the study of migration and migration simulation on sugarscape environment. To understand migration, studies done up to now have been investigated and theories related to the initiation and perpetuation of migration have been analyzed. We also studied models and simulations of migration to be aware of the problems we may face during creating our own model. After these studies some models have been created to simulate migration. After realizing the complex nature of the migration and modeling such a complex social behavior is very difficult in a short time, we thought that we can simulate some part of the whole migration picture. After that we have focused the subject of colonization. We have created two types of agents differ from each other in terms of their capabilities and motivations. The movement dynamics and success ratios of these agent types during colonization have been investigated by the help of simulations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, Bayer Filtresinden yüksek kalitede görüntü elde etmek ve kayıp renklerinhesaplanması işleminin performansını geliştirmek için ltrede bir piksel genişliğekadar düşen desenlerde eksik renk değerlerini hesaplayan bir algoritma sunulmaktadır.Algoritma öncelikle bir piksele kadar düşebilen ve eksik renk değerlerinin doğru hesaplanması zor olan bölgeleri tespit eder. Problemli ve eksik değerlerin hesaplanmasınınzor olduğu bölgelerde, özel bir ara değer hesaplama yöntemi seçilmiştir. Problemsizve kenarların az olduğu bölgelerde ise mevcut olan algoritmalar kullanılmaktadır. Bumetotla, eksik değerlerin hesaplanmasının zor olduğu, bölgelerde mevcut algoritmalarınhesaplama karmaşıklığı kabul edilebilir bir miktarda aşılarak %70'e varan bir görüntükalitesi artışı yakalanmıştır.Geliştirilen algoritmaçekirdek olarak VHDL dili kullanılarak gerçeklenmiştir. Algoritmanın Alan Programlamalı Kapı Dizileri (APKD) üzerinde işlevsel doğrulamasıyapılmıştır. Gerçekleme esnasında APKD olarak Virtex-II XC2V500 yongası kullanılmıştır. Geliştirilençekirdek 1000x1000 boyutlarındaki gerçek zamanlı videoişleme ve 1000n boyutlarındaki durağan görüntü işleme işlemlerini gerçekleştirebilir.Gerçeklenen sistem 25 MHz frekanstaçalışmaktadır ve saniyede 25 tane resim işleyebilir.Ulaşılan bu hız ise video işleme için yeterli imkanı sağlamaktadır.","The thesis introduces a low-cost algorithm for improving the demosaicking process in the texture areas such as one-pixel patterns. The algorithm first detects difficult texture regions. After the detection process is completed, the algorithm demosaicks the texture areas using special demosaicking operations whereas non-texture regions are restored using some of the existing demosaicking approaches. In this way, the quality of the texture areas in demosaicked images can be improved up to 70% while the computational complexity of the original demosaicking solution is increased only slightly.The new algorithm is implemented as a core by using VHDL (Very High Speed Integrated Circuit Hardware Description Language) language. The operational verification of the VHDL implementation is performed on FPGA (Field Programmable Gate Array). The Virtex-II XC2V500 device is selected in the implementation. The core is capable of processing 1000 x 1000 pixels real-time digital video and 1000xn pixels digital still images. The system operates at 25 MHz frequency and can process 25 images per second which is a sufficient speed for video processing."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Sensör teknolojilerindeki gelişmeler ve biyometrik özellikleri tanıma konusunda son yıllarda yapılan araştırmalar, üç boyutlu yüz tanımasistemlerinden beklentileri yükseltmektedir. Üç boyutlu yüz tanıma alanına olan bilimsel ilginin önemli bir nedeni yüz taramalarının kişileri rahatsız etmeden yapılabilmesidir. Bu durum, üç boyutlu yüz tanımayı, güvenlik ve insan-bilgisayar etkileşimi konularında kullanılabilir hale getirmektedir. Bu çalışmada, tam otomatik, parça tabanlı bir üç boyutlu yüz tanıma sistemi önerilmiştir. Önerilen sistem, tanıma konusunda poz düzeltme ve eğrilik tabanlı yüz bölütlemesine dayanmaktadır. Sistemin tanıma basamağında, yüz parçalarının kullanılması, yüz ifadelerindeki değişimlerde bile, sisteme gürbüzlük sağlamaktadır. Burun anatomik olarak yüzün en hareketsiz bölgesi olduğu için ifade değişimlerinden çoğunlukla etkilenmez. Bu sebeple, burun ucu bulma ve burun bölütü çıkarma konuları üzerinde yoğunlaşılmıştır. Ayrıca, burun ucu ve diğer nirengi noktaları poz düzeltmeye imkan vermektedir. Önerilen tanıma sisteminin poz düzeltme özelliği, sistemin poz değişimlerinde kullanılabilirliğini sağlamaktadır. Sonuçlarımız, doğal sınırlarından bölütlenmis burun bölgesinin, üç boyutlu yüz tanımada tek başına kullanımı ile, Boğaziçi Veri Tabanında, tanıma başarısı oranlarını düz yüz ifadeleri için yüzde 94.1'e kadar ve poz değişimleri için yüzde 79.41'e kadar arttırdığını göstermektedir.","The advances in sensor technologies and the several years of research in recognition of biometric modalities increased the expectations from 3D face recognition systems. An important reason of scientific interest on 3D face recognition is the ability ofacquisition of the facial data nonintrusively. This makes 3D face recognition applicable to real life tasks in terms of security and human computer interaction. In this study, a fully automatic part-based 3D face recognition system has been proposed. The proposed system is based on pose-correction and curvature-based facial segmentation for recognition tasks. Utilization of facial parts in the recognition step provides robustness to the system even in facial expression variations. Since the nose is anatomically the most stable part of the face, it is largely invariant under expressions For this reason, we have concentrated on locating the nose tip and segmenting the nose. Furthermore, the nose tip and other nose landmarks enable pose correction. Pose correction feature of the proposed recognition system, allows the identification of people under significant amount of pose variations. For the face recognition task, we try both one-to-all and Average Nose Model (ANM) based methodologies. Our results show that the utilization of anatomically-cropped nose region in 3D face recognition increases the rank-one recognition success rates up to 94.1 per centfor frontal facial expressions and 79.41 per cent for pose variations in the Bosphorus database."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde ürün gamı optimizasyonu, belli kategoriye ait ürünler içerisinde satış performansı en iyi olanları bulmaktan ziyade perakendecilerin ticari stratejilerini pazarda uygulamaları için kullanılan bir metod haline gelmiştir. Veri tabanlarına her gün kaydedilen milyonlarca veriyi düşündüğümüzde gün geçtikçe çoğalan veriden gerekli bilgiyi çıkarmak perakendeciler için daha zor hale gelmektedir. Bu problemin çözümüne yardımcı olmak için ürün gamı seçiminde veri madenciliği uygulamalarını kullanmayı ve yoğun veriden bilgi edinmeyi amaçlamaktayız.Şu da unutulmamalıdır ki perakendeciler en uygun ürün gamını seçerken sadece karmaşık algoritmalara güvenmemeli, iş mantığını da karar sisteminin içine yedirmelidir. Bu çalışmada biz bu konudaki önceki çalışmalardan PROFSET ve GENELLEŞTİRİLMİŞ PROFSET modellerine yeni geliştirmelerde bulunduk. Temel modeli sık alınan ürün kümesinin kar dağılım metodu, kategori başına sınırlamaları ve adetsel olarak bol satış yapan ürün kısıtlamalarında eklemeler ve düzeltmeler yaparak geliştirdik. Son olarak da yarattığımız modeli empirik olarak örnek bir perakende datası için test ettik. Tüm bunları yaparken perakende sektörü gerçekleri, tüketici ve müşteri algısını dikkatten kaçırmamaya özen gösterdik.","Assortment Optimization is not just selecting the best products according to the sales performance under a certain category, but also an execution method to apply retailers commercial strategy into market considering all strategies which retailer want to play. Regarding millions of data saved in databases and explosive growth of data leads to a situation in which it is increasingly difficult for retailers to understand the right information. To cope with this problem we are planning to use association algortihms to put in place data mining in product selection.It should also be considered that selecting best and suitable products for assortment of retailer need not only sophisticated algorithms to take decisions but also business perspective to embed into decision system. In this study, we approach the assortment selection problem, by improving the PROFSET model and GENERALIZED PROFSET model, which is based on a microeconomic framework. We improved the basic model by introducing additional method of profit allocation over frequent item sets, constraints about categories and sold quantities. Finally we empirically test our model with sample retailer data. While doing this we will also take into consideration the retail industry characteristics and consumer and customer perceptions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geniş bant radyo yayını erişimi, kablo ve xDSL gibi tel çekilen geniş banda bir alternatiftir. IEEE 802,16 standartı, Fiziksel katman ile Ortak erişim kontrolü katmanını tanımlar. Endüstride WiMAX (Mikrodalga erişimi için dünya çapında enteroperabilite) olarak bilinir.Tek noktadan çok noktaya şebekelerde kullanıcı istasyonun baz istasyonuna doğru veri aktarımı, kullanıcı istasyona uplink haritasını yollamak ile baz istasyonu tarafından belirlenir. Uplink haritası downlink bölümünde gönderilmekte ve büyüklüğü downlink bölümünde veri aktarımı kapasitesini etkilemektedir. Bu tezde, zamanlama servis tipi talep edilmeden tahsis hizmeti olan bağlantıların uzatılan bilgi üyesi yardımı ile gelecek periyodik sabit büyüklükteki bant genişliği tahsisleri gönderilerek uplink haritası nedeni ile oluşan ortak erişim kontrolü yükünü en aza indirmeyi sağlayan metodu geliştirdik.Önermiş olduğumuz çözümü OPNET 11,5 simülatöründe WiMAX modülünü kullanarak değerlendirdik. Simülasyon sonuçlarımız bizim önermiş olduğumuz çözümün zamanlama servis tipi talep edilmeden tahsis hizmeti olan bağlantıların kullanıcı istasyonlar tarafında kullanıldığı zamanlarda, verimliliği artırdığını göstermiştir.","Broadband Wireless Access (BWA) is an alternative to wired broadband like cable and xDSL. The IEEE 802,16 standard defines physical (PHY) and MAC layers of BWA systems. It has been called WiMAX (Worldwide Interoperability for Microwave Access) by industry.The uplink transmission of Subscriber Stations (SS) is determined by Base Station (BS) with sending Uplink Map (UL-MAP) in point to multipoint networks. The UL-MAP is sent in the downlink subframe and its size affects downlink data capacity. In this thesis, we introduce a new scheme to minimize MAC overhead due to UL-MAP size by using UL-MAP Extended Information Element (IE) to send future periodic fixed size grants for the connection whose scheduling service type is Unsolicited Grant Service (UGS).We evaluate our proposed scheme with simulations in OPNET 11.5 Modeler WiMAX module. Simulation results show that our proposed solution is superior to its conventional counterpart when there are high numbers of SSs with UGS connections in terms of cell throughput."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gömülü Sistemler calışma süreleri boyunca bir uygulamaya, değişiklik olmadanya da ufak değişiklerle atanan sistemlerdir. Bu sistemler, eğlence sektöründen kriptografiye, ev eşyalarınndan askeri ekipmana kadar geniş bir sektör yelpazesine hizmet vermektedir. İşlemcilerin uyarlanabilir komut setlerine sahip ve mimarilerinin yapılandırılabilir olması ile birlikte, gömülü sistemlerin atandıkları uygulamaya göre yapılandırıllabilme esnekliği sağlanmıştır. Yapılandırma, uygulamanın yetersiz olan bir kısmınıiyileştirmek için, işlemcide değişikliğe gidilmesi anlamına gelmektedir.Kullanıcının çeşitli düzeylerde müdahelesini gerektiren yarı otomasyon ya da tamotomasyon ile yapılandırma sağlayan araçlar, gömülü sistemler sektöründe yeni biraraştırma dalı ortaya çıkarmıştır.Bu tez, yapılandırılabilir komut ya da Tek Komut, Çoğul Veriyolu (TKÇV) stiliişlemci elemanlarını, gömülü sistemin ara gösterimini inceleyerek seçen bir araç sunmaktadır. Bulanık mantık uzman sistemi, bir oylama mekanizması olarak kullanılır.Bu tez, ön derleme ve son derleme safhalarının ortasında yer alarak, yapılandırmadason derleme safhasına destek olacak şekilde tasarlanmıştır.","Embedded Systems are dedicated to a task for their life time with no or slightmodications. These systems are necessary in a wide range of industrial areas fromentertainment industry to cryptography and from house appliances to army equipment.The emerging of processors with customizable instruction sets and customizable architecturesenabled the embedded processors to be tailored for the application they arededicated to. Tailoring stands for improving incompetent parts of an application bymodifying the processor.Development of design automation tools have been a new research era for embeddedprocessors. They enable customization either by partial automation which requireshuman assistance at varying levels or by full automation.In this thesis, an automation tool GAIA that selects custom instructions (CI)and Single Instruction Multiple Data (SIMD) style processing elements (PEs) has beendeveloped. The system achieves customization by examining the intermediate representation(IR) of an application. It is a fuzzy expert system that acts as a votingmechanism evaluating the attributes of the application components. The work of thisthesis contributes to the stage between the front-end and back-end compilation, withthe aim of assisting back-end compilation at customization process."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Veri madenciliği, iş zekası çözümlerinde çeşitli endüstri ve iş kollarını destekleyen ana teknoloji olarak kullanılmaya başlanıyor. Birçok veri madenciliği ürününün piyasada olmasına rağmen, standart protokollerin olmamasından dolayı bu ürünler uygulamalar ile entegre edilememektedir. Genel standartlara uymak, uygulama geliştirmeyi, bakımını ve uygulamalar arasındaki iletişimi kolaylaştırır. Ayrıca, bu standartlar veri madenciliği sürecinin daha kolay yapılabilmesine olanak verir. İleri seviye veri madenciliği standartlarından bir tanesi olan Java Data Mining (JDM) ile Java uygulamaları veri madenciliği motorları ile iletişim kurarak modellerin yaratılması, test edilmesi ve uygulanması işlemleri yapılabilir. JDM'in ilk versiyonu ile sınıflandırma, regresyon, öbekleme ve eşleştirme gibi temel veri madenciliği fonksiyonlarını yapılabilmektedir. Gelişmekte olan JDM 2.0 versiyonu ek gelişmiş bazı veri madenciliği fonksiyonları önermektedir; zaman serileri, özellik çıkarma ve metin madenciliği. Bu çalışmada JDM 2.0 standartlarını genişletmek üzere geliştirdiğimiz deneysel çerçeveyi sunmaktayız. Bu çerçevede, Bootstrap ile tahmin doğruluğunu belirleme, Bagging ve Boosting ile tahmin doğruluğunu artırma çalışmaları bulunmaktadır. Genişlettiğimiz JDM fonksiyonlarını iyi bilinen iris ve Sales History (SH) verisetleri üzerinde uyguladık.","Data mining is becoming a mainstream technology used in business intelligence solutions supporting various industries and lines of business. Although there are plenty of data mining products at the market, these products are difficult to integrate with user applications due to the lack of standardization protocols. Conforming to common standards facilitates development, implementation and maintenance of applications as well as communication among them. In addition, these standards enable data miners to develop data mining process easily. As being one of the well-established data mining standards, Java Data Mining (JDM) allows Java applications to communicate with data mining engines to build, test and apply mining models. First release of JDM supports the basic data mining functionalities; classification, regression, attribute importance, clustering, and association. Currently developing version (JDM 2.0) proposes the additional set of functionalities such as time series, feature extraction, text mining. In this study, we present the experimental framework developed to extend the JDM 2.0 by including ensembles methods such as boosting, bagging to improve the classification accuracy and bootstrap to assess accuracy. We have applied our extended JDM functionalities with two well known datasets that are iris dataset and Sales History (SH) dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dördüncü Nesil Ağlar, yüksek kalitede ve güvenli, tamamı IP tabanlı entegre bir sistem oluşturmak için sabit ve kablosuz ağ teknolojilerinin birlikte kullanılması olarak tanımlanabilir. Entegre sistem olan bu ağlarda, kendisinden önceki sistemlerdekine benzer uçtan uca servis kalitesini sağlamak zorlu bir konu olarak karşımıza çıkmaktadır.Bu tezde, uçtan uca servis kalitesi sağlayan, tamamı IP tabanlı yeni nesil kablosuz ağ mimarisi sunulmaktadır. `Frekans Değişimli Ortogonal Frekans Bölümlü Çoklama' tabanlı fiziksel katman üzerinde çalışan paket tabanlı `Ortam Erişim Kontrol' katmanı dizayn edilmiştir. önerilen `Ortam Erişim Kontrol' katmanında , IEEE 802.20 spesifikasyonuna Qualcomm tarafından teklif edilen yapı temel alınmıştır. Uçtan uca servis kalitesini sağlamak için, mimarinin omurgasında `Çoklu Protokol Etiket Anahtarmala' ve `Çoklu Protokol Etiket Anahtarmala'nın `DiffServ' desteği kullanılmıştır. IP katmanının servis kalite parametreleri, önerilen paket tabanlı radyo aryüzüne entegre edilerek, radyo arayüzünü de içeren uçtan uca servis kalitesi sağlanmıştır.Yeni `Ortam Erişim Kontrol' katmanını kullanan, `Kablosuz Erişim Yönlendiricisi' ve `Mobil Ekipman' olarak adlandırılan iki yeni ekipman tanıtılmıştır. `Kablosuz Erişim Yönlendiricisi', omurgaya `Çoklu Protokol Etiket Anahtarmala' mimarisinde bulunan standard `Etiket Köşe Yönlendiricisi' ile entegre edilmiştir. Mimari, `OPNET Modeler' similasyon araci ile `Mobil Ekipman'ların hissettikleri servis kalitesini analiz etmek için simüle edilmiştir.","Fourth Generation (4G) Networks can be defined as the convergence of wired and wireless network technologies and formation of all-IP based integrated system with premium quality and high security. As an integrated system, providing end-to-end Quality of Service (QoS) similar to legacy networks has been a challenging issue in such a network.In this thesis, an all-IP next generation wireless network architecture that supports end-to-end QoS is presented. A new packet based Medium Access Control (MAC) layer, which runs on top of Frequency Hopping Orthogonal Frequency Division Multiple Access (FH-OFDMA) based physical layer is designed and implemented. The proposed MAC layer is based on one of the promising proposals to IEEE 802.20 by Qualcomm. Multi Protocol Label Switching (MPLS) and DiffServ support of MPLS is utilized at the backbone of the architecture to provide end-to-end QoS. By integrating Internet Protocol (IP) Layer QoS parameters to proposed packet-based air interface, end-to-end QoS including the air interface is provided.Two new nodes, Wireless Access Router (WAR) and Mobile Node (MN), which implement the new MAC layer, are introduced. WAR is integrated to the backbone via standard Label Edge Router (LER) of MPLS architecture. The architecture is implemented with OPNET Modeler[3] simulation tool to analyze the QoS perception of MNs within the architecture."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde konuşma için, gürültülü kanallarda ses damgalama teknikleri kullanılarak oluşturulan yeni bir hata gizleme metodu sunulmuştur. Kısaca ECAW olarakanılacak olan hata gizleme yöntemi LSB(en önemsiz bit)-tabanlı bir ses damgalama tekniği kullanarak n. çerçeveye ait küme bilgisini, ses kodlaması öncesinde (n-1). çerçeveye gömmektedir. Transfer sonrasında hatalı ya da kayıp çerçeve, (n-1). çerçeveye gömülmüş olan küme bilgisi kullanılarak gizlenmektedir.ECAW'ın hata gizleme stratejisi, ses sinyalini, kanala göndermeden önce 5 ms lik çerçevelere böler ve k=32 değeri ile k-means kümeleme yöntemini çalıştırır. Her bir çerçeveye ait kümeleme bilgisi bir önceki çerçeveye gömülür. Bu, kanala 5 ms lik sabit bir gecikme tanıtır. Alıcı tarafta da, gelen ses sinyali 5 ms lik çerçevelere ayrılır ve k=32 değeri ile k-means kümeleme yöntemi tekrar çalıştırılır. Hata tespit etme yönteminin harici olarak sağlandığı farz edilmektedir ve eğer herhangi bir hata tespit edilirse, ECAW'ın hata gizleme stratejisi, hatalı bölümü, bölüme ait k-means kümesine ait merkezin karşılık gelen bölümü ile değiştirir.Deney sonuçları bazı kısıtlar ile birlikte önerilen yöntemin etkin olduğunu göstermiştir.","In this thesis, the author presents a novel error concealment method of speech for noisy channels using audio watermarking. The proposed error concealment algorithm abbreviated as ECAW is basically a LSB-based scheme and embeds the k-means clustering of (n)th frame into (n-1)st frame before audio encoding. After the transmission, the erroneous or lost parts of (n)th frame is concealed by the clustering information embedded into (n-1)st frame.Before sending speech signal into channel, ECAW's error concealment strategy divides speech signal into frames of 5 ms and executes k-means clustering with k=32. Clustering information of each frame is embedded into the previous frame. This introduces a constant delay of 5 ms to channel. Then, on the receiver side, received speech signal is broken into frames of 5 ms, too and k-means clustering with k=32 again is executed. It's assumed that error detection is provided externally and if any error is detected, ECAW's error concealment strategy replace the erroneous part with the corresponding part of the center of assigned k-means cluster.Experimental results prove the e±cacy of the proposed method in reducing dis-tortions despite some restrictions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Basit Tavsiye Modelinde (SRM), nüfus boyutuna göre hafıza boyutunun şöhret üzerindeki etkisi analiz edilmiştir. SRM'deki ajanlar tavsiyeler sonucunda yeni ajanlar öğrenir ve bildiği ajanları unutur. Tavsiye sırasında tavsiye yapacak ajan, tavsiyenin yapılacağı ajan, tavsiye edilecek ajan ve unutulacak ajan seçilir. SRM'de bu seçimler rasgele yapılır. SRM'de nüfus boyutu sabittir.Bu tezde, ajanları seçme metodu değiştirilerek Basit Tavsiye Modeli genişletiliyor. Ayrca, dinamik nüfus boyutu tanıtılıyor. Herbir genişleme simule ediliyor ve herbir genişlemenin etkisi simülasyon sonuçlarının SRM'nin sonuçlarıyla karşılaştırılarak analiz ediliyor.","In Simple Recommendation Model (SRM), the effect of memory size on fame with respect to the population size is analyzed. Agents of SRM may learn new agents and may forget some of the agents that they know as a result of recommendations. During recommendations, the agent who will make recommendation, the agent to whom recommendation is made, the agent that will be recommended and the agent that will be forgotten are selected. These selections are random in SRM. The population size is constant in SRM.In this thesis, SRM is extended by changing the selection method of agents. Also, dynamic population size is introduced. Each extension is simulated and the effect of each extension is analyzed by comparing the simulation results with the results of SRM."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım geliştirme firmaları projelerini başarılı bir şekilde, yani zamanında, bütçeyiaşmadan ve hatasız bitirmek için birçok zorlukla karşılaşmaktadırlar. Planlama vekaynakların paylaşımı bir yazılım şirketinin finansal performansını ve pazardakikonumunu doğrudan etkilemektedir. Asıl zorluk; proje yöneticilerinin, verilen bir projeiçin ne kadar süreyle ve maliyetle hangi seviyede yetenek gerekeceğine nasıl kararvereceğidir. Bu yüzden proje yöneticileri bu kararları vermeye yardımcı olacak akıllı yolgöstericilere giderek atan bir şekilde ihtiyaç duymaktadırlar. Bu yol göstericiler, işgücü vemaliyet tahmini için öğrenme tabanlı tahmin modelleri olarak tanımlanabilir. Bu tipmodeller, proje yöneticilerinin hatalı tahminlere bağlı olarak yanlış kararlar vermeleriniönlemektedir.Bu araştırmada, gömülü yazılım alanında maliyet tahmini için öğrenme tabanlıtahmin modelleri geliştirmeye odaklanıyoruz. Modelimiz, tahmin doğruluğu problemini,hem verinin kullanımı hem de model geliştirilmesi açılarından ele almaktadır. İlk olarak,verinin kullanımına odaklanıp, gömülü sistemlerde yazılım maliyeti tahmini için ne tür vene kadar veri kullanılması gerektiğini araştırıyoruz. İkinci olarak, model geliştirilmesiüzerine odaklanıp, gömülü yazılımlar için yeni bir maliyet tahmini modeli öneriyoruz.Sonuçlarımızın, maliyet modellerini eğitecek verinin seçimi ve eldeki kaynakların dahaetkin bir şekilde paylaşımı konularında proje yöneticilerine destek olacağına inanıyoruz.Yazında, gömülü yazılımların maliyet tahminiyle ilgili herhangi bir çalışmabulunmamaktadır. Biz, bu boşluğu gömülü sistemler alanında doldurmayı amaçlıyoruz.Buna ek olarak, yüksek doğruluk oranı elde eden yeni bir maliyet tahmini modelisunuyoruz. Deneylerimizde, sonuçlarımızın kullanılan modelden bağımsız olmasınısağlamak için, geniş çapta yapay öğrenme tekniklerinden faydalanıyoruz. Bir de,deneylerimizin değişik durumlarda da aynı sonuçları verdiğini göstermek ve dolayısıyla busonuçları genelleştirebilmek için üç farklı kaynaktan veri setleri kullanıyoruz.","Software development companies face many problems in order to complete theirprojects successfully: on time, within budget and with no defects. Scheduling and resourceallocation directly affect financial performance and market position of a softwarecompany. The challenge is how the project managers will decide what level of skill set,for how long and at what cost they will need for a given project. Therefore, practitionersincreasingly need intelligent oracles to help them make these decisions. These oracles canbe defined as the learning based prediction models for effort and cost estimation. Suchpredictive models prevent project managers to take wrong decisions due to inaccurateestimations.In this research, we focus on building learning based predictive models for costestimation in embedded systems domain. Our proposed model tackles the predictionaccuracy problem from both data usage and model development aspects. Firstly, we focuson data usage and investigate what kind of and how much training data should be used forsoftware cost estimation in embedded systems. Secondly, we focus on model developmentand propose a new cost estimation model for embedded software. We believe that ourresults would assist the software managers while selecting the data to train the cost modelsand allocating available resources more efficiently by using more accurate analysis.In literature, there has not been any study that focused on embedded software costestimation yet. We aim to fill in this gap for embedded systems domain. In addition, wepresent a new cost estimation model which achieves high accuracy rates. In our empiricalwork, we utilize a wide range of machine learning techniques in order to make our resultsbe independent from the techniques used. Also, we used datasets from three differentsources in order to be able to generalize our results under different set-ups."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, yazılım hata tahmini probleminin, yazılım karakteristiklerinin statik kod ölçütleriyle temsil edildiği ve hata tahmin modellerinin geçmiş hata kayıtlarından öğrenildiği veri madenciliği perspekti ? nden analizi yapılmıştır. Hata tahmin modelleri oluşturmak için uygulanan veri madenciliği metodlarının, statik kod ölçütlerindeki kısıtlı bilgi içeriğinden dolayı üst performans limitlerine ulaştığı gözlemlenmiştir. Bu sebeple, yeni ölçütler kullanmadan, verideki bilgi içeriğinin arttırılması hede ? enmiştir. Çünkü yeni ölçütlerin toplanması ya maliyetli olmaktadır ya da her durumda mümkün olmamaktadır. Veri madenciliği metodları bilgi içeriği açısından zengin veriler ile beslenmiştir. Bu amaçla 1) veri madenciliği metodlarının varsayımları, 2) birden çok şirketin proje verilerinin kullanılması, 3) yazılım modülleri arasındaki ilişkilerin modellenmesi analizleri gerçekleştirilmiştir. İlk analizde, naive Bayes metodunun ölçütlerin i) bağımsızlığı ve ii) eşit öneme sahip oldukları varsayımları ortadan kaldırılmıştır. Daha sonra yerel ve yabancı veriyle öğrenilen hata tahmin modelleri karşılaştırılmıştır. Son olarak, modül ilişkilerini modellemek için çağrı gra ? kleri analizi yapılmıştır. Kamuya açık endüstriyel veriler üzerinde yapılan analiz sonucunda: 1) naive Bayes varsayımlarının ortadan kaldırılmasının hata tahmini performansını arttırabildiği, 2) yabancı verilerle öğrenilen hata tahmini modellerinin hata yakalama kapasitelerinin -fazla yanlış alarm maliyetiyle- çok yüksek olduğu; ancak bu maliyetin önerilen süzme tekniğiyle ortadan kaldırılabildiği, 3) önerilen ilişki modeli ile yanlış alarmların azaltılabildiği gözlemlenmiştir. Yapılan analizler 1) yerel veri olmadığı durumlarda yabancı veriylehata tahmini yapabilmek, 2) yerel verilerle tahmin performansını arttırmak açısından yol gösterici ilkeler sağlamaktadır.","In this dissertation, we make an analysis of software defect prediction problem from a data mining perspective, where software characteristics are represented with static code features and defect predictors are learned from historical defect logs. We observe that straightforward applications of data mining methods for constructing defect predictors have reached a performance limit due to the limited information content in static code features. Therefore, we aim at increasing the information content in data without introducing new features, since collecting these may either be expensive or not possible in all contexts. We feed data mining methods with richer data in terms of information content. For this purpose, we propose the following methods: 1) relaxing the assumptions of data miners, 2) using project data from multiple companies, 3) modeling the interactions of software modules. For the first method, we use naive Bayes data miner and remove its i) independence and ii) equal importance of features assumptions. Then we compare the performance of defect predictors learned from local and remote data. Finally, we introduce call graph technique to model the interactions of modules. Our results on public industrial data show that: 1) relaxing the assumptions of naive Bayes may increase defect prediction performance significantly, 2) predictors learned from remote data have great capability of detecting defects at the cost of high false alarms, however this cost can be removed with the proposed filtering method 3) proposed way of modeling interactions may decrease the false alarm rates significantly. Our techniques provide guidelines for 1) employing defect prediction using remote information sources when local data are not available, 2) increasing prediction performances using local information sources."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, servis müşterisi etmenlerin servis ihtiyaçlarını en iyi şekilde karşılayacak servis sağlayıcıları seçmek için yardımlaştıkları bir e-ticaret ortamında, servis seçimi problemi incelenmiştir. Servis seçimi ile ilgili üç temel mesele bulunmaktadır: (i) müşterilerin servis sağlayıcılarla geçmiş ilişkilerinin betimlenmesi, (ii) servis sağlayıcılar ile ilgili yanıltıcı bilgilerin ayıklanması, (iii) müşterilerin gelişen servis ihtiyaçlarının ve bunların anlamsal ilişkilerinin yönetilmesi.Daha önceki yaklaşımlar müşterilerin servis sağlayıcılarla olan geçmiş ilişkilerini betimlerken sadece reytingleri kullanmaktadırlar. Reytingler belirli bir bağlamda verilirler. Ait oldukları bağlam reytingleri değerlendirmek için çok önemli olmasına karşın reytingler herhangi bir bağlamsal bilgiyi açıkça içermezler. Ayrıca, reytingler bir servis sağlayıcının verdiği servisin özelliklerini açıkça belirtmezler. Bir reyting bir müşterinin sadece belirli bir servis sağlayıcı ile ilgili sübjektif fikrini ifade eder. Reytingleri veren müşterilerin memnuniyet kriterleri ve beklentileri bilinemeyeceği için reytingleri yorumlamak neredeyse imkansızdır.Bu tezde, müşterilerin servis sağlayıcılarla olan geçmiş tecrübeleri, talep ettikleri ve aldıkları servisleri detaylı ve anlamsal olarak ifade edebilen bir ontoloji ile betimlenmektedir. Bir müşteri başka bir müşteri ile geçmiş tecrübelerini paylaşmaya karar verdiğinde, paylaşılan tecrübeleri alan müşteri, bu tecrübeleri kendi bağlam ve memnuniyet kriterlerine göre değerlendirebilmektedir. Reytinglerin yerine tecrübelerini paylaşarak, servis müşterileri servis sağlayıcıları daha doğru modelleyebilmekte ve böylece kendi ihtiyaçlarına en uygun servis sağlayıcıları daha iyi seçebilmektedirler.Bu tezde önerilen servis seçimi yaklaşımı, müşterilerin servis kavramlarını zamanla geliştirmelerine olanak sağlayacak kadar esnek, servis seçimi sırasında müşterilerin kendi memnuniyet kriterlerini ve bağlamlarını kullanmalarına olanak sağlayacak kadar bağlam farkı gözeten ve müşteri odaklı, ayrıca yanıltıcı ortamlarda bile başarılı servis seçimi yapabilecek kadar aldatmaya dayanıklıdır.","In this dissertation, we examine the problem of service selection in an e-commerce setting where consumer agents cooperate to identify providers that would satisfy their service needs the most. There are three major challenges related to service selection: (i) representing consumers' past dealings with providers, (ii) handling deceptive information and (iii) managing evolution of consumers' service needs and semantics.Previous approaches represent consumers' past dealings with providers only as ratings. Even though the context is crucial for interpreting the ratings correctly, ratings do not contain any contextual information explicitly. A rating merely represents subjective opinion of a consumer about a provider. Because, the satisfaction criteria and the expectations of the rater are unknown, it is almost impossible to make sense of a rating.In this dissertation, consumers? experiences with providers are represented with an ontology that can semantically capture the requested service and the received service in detail. When a consumer decides to share its experiences with a second consumer, the receiving consumer evaluates the experience using its own context and satisfaction criteria. By sharing experiences rather than ratings, the consumers can model providers more accurately and thus can select providers that are better suited for their needs.The proposed service selection approach in this dissertation is flexible enough to enable consumers to evolve their service semantics over time; context-aware and consumer-oriented to enable consumers to use their own satisfaction criteria and context during service selection; and robust to deception to lead satisfactory service selections even in highly deceptive environments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma Türkiye'deki lider beyaz eşya üreticilerinden birinin tedarikçi değerlendirme ve kota dağılım kararlarını iyileştirmeye yönetliktir. Karar verme sürecinin kalitesini ve hızını arttırmak üzere bir karar destek sistemi geliştirilmiştir. Mevcut satınalma sisteminde, karar verici tedarikçi adaylarını öznel olarak değerlendirmekte ve kota dağılımından önce her bir adayla sıkı pazarlık sürecine girmektedir. Önerilen sistemde, hem tedarikçileri nicel ve nitel kriterlere bağlı olarak değerlendirilen, hem de bir takım satınalma hedeflerini en iyi şekilde sağlayarak kota dağılımı yapan bir yazılım geliştirilmiştir.","This study focuses on the improvement of supplier evaluation and order allocation decisions for one of the leaders of the white-goods manufacturers in Turkey. A decision support system (DSS) is developed to increase the quality and speed of decision making. In the current purchasing system, the decision maker evaluates the supplier candidates informally and after tough negotiations quota diversification is established. In the proposed system, a tool is developed to evaluate the suppliers with qualitative and quantitative criteria and allocate annual quota so as to optimize a set of purchasing goals."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Belirsizlik, otonom robotlar için, duyargaların gerçek dünya gibi tüm ortam durumunu tam olarak yansıtamadığı hallerde başedilmesi gereken temel problemlerden biridir. Gerçekleştirilen eylemlerin sonuçlarının ne olacağı önceden bilinmese dahi etmenlerin mantıklı davranışlar içinde bulunmaları beklenmektedir. Bunun yanında ortamın aralıksız dağılımlı zaman yapısı problemi daha da zor hale getirmektedir.Markov Karar Yöntemleri bu tip ortamların modellenmesi için uygundur. Kısmen Gözlemlenebilir Markov Karar Süreçleri ise bütünüyle gözlemlenmesi mümkün olmayan ortamlar için tercih edilmektedir. Bu yöntemlerle ortamın modellenebilmesi için, gerçek dünyanın aralıksız dağılımlı yapısının aralıklı hale getirilmesi gerekmektedir.Bu çalışmanın amacı gerçek dünyayı modelleyerek, Kısmen Gözlemlenebilir Markov Karar Süreçlerine uygun öğrenme algoritmalarının gerçek robotlar üzerinde uygulanmasıdır.Deneyler Sony'nin dört bacaklı AIBO köpek robotları üzerinde, Webots simulasyon ortamı kullanılarak gerçekleştirilmiştir. İki farklı problem üzerinde algoritmalar uygulanmıştır: ``Topa Yaklaşma'' ve ``Gol Atma''. Robotların önceden verilen hedeflere ulaşmayı başardıkları ve gol skorlarında rastgele verilen kararlara nazaran daha başarılı oldukları gözlemlenmiştir. Sonuca ulaşırken gerçekleştirilen eylemlerin optimum olup olmadığı tartışılmış ve bunu etkileyen parametreler açıklanmıştır.","Uncertainty is a fundamental problem for autonomous agents in a partially observable real world, where the sensors are not able to give the complete state of the environment. Although the outcomes of actions are not predictable, the agents must behave rationally. Furthermore, continuous nature of the environment makes the problem more difficult to model.Markov Decision Process (MDP) is a way to model this kind of problems. Partially observable Markov decision process (POMDP) is an extension of MDP which can be used in environments which are not fully observable. In order to model the real world, the continuous states must be converted to discrete states.The aim of this work is to model the real world environment and implement ARKAQ learning algorithm which is suitable for Partially observable Markov decision problems (POMDPs).The experiments are realized with Sony AIBO four-legged robotic pets under Webots simulation environment. Two problems are studied: ``Ball Approaching'' and ``Scoring Goal''. The predefined targets are achieved by the robots and the results in goal scoring show that ARKAQ is clearly much more successful compared to random actions. The optimality of the results are discussed and the parameters that affect the optimality are explained."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezin amacı, mesru kullanıcıları biyometrik özelliklerine göre özdeslestiren ve gerçekleyen gerçek zamanlı kullanıcı arayüzleri gelistirmektir. Uygulamalarda yüz ve el geometrisi biyometrik belirleyici kimlikler olarak kullanılmıstır. Bu biyometrik belirleyicileri kullanan uygulamalar, tekli ve çoklu sekillerde gelistirilmistir.uygulama ve kod üreticileri özel görevler için tasarlanmıslardır. Bu çalısmada, kullanıcıların el ve yüz imgelerini gerçek zamanlı olarak toplamak, onları kaydetmek, gerçeklemek ve özdeslestirmek için altı tane Java uygulaması gelistirilmistir. Bütün uygulamalar ``sihirbaz uygulama'' olarak tasarlanmıs ve aynı senaryo üzerine oturtulmustur. Yüz tanımada, yüz imgelerinin özniteliklerini elde etmek için Gabor dalgacıkları kullanılmıstır. Kisi eslestirme Gabor tabanlı öznitelik vektörlerine göre yapılmıstır. El tanıma kısmında, el sekli tabanlı yaklasım uygulanmıstır. Bu yaklasımın önemli adımları el kesimleme, normallesme ve özniteliklerin çıkarımı olmustur. Uygulamaların basarımını sınamak için 40 kisiden veri toplanmıstır. Tanıma algoritmalarının basarımları, el, yüz ve çoklu sekiller için incelenmistir. Basarımın yanısıra, arayüzün kullanıslılığını artırmak için kullanıcı değerlendirmesi yapılmıstır. Hız, arayüz ve uygulamaların kullanılırlıklarını içeren bir anket sonucu, veri alınan kisilerden toplanmıstır. Kullanıcıların önerilerinden sonra arayüz tekrar gözden geçirilip düzeltilmistir.","The goal of this thesis is to develop user interfaces that identify and verify legitimate users in real-time due to their biometric characteristics. Face and hand geometry were the biometric identifiers that were used in the applications. Application programs using these biometric identifiers were developed in unimodal and multimodal cases. In this study, six Java applications were developed to capture users' hand and face images in real-time, to enrol, to verify and identify them. All of the applications were designed as wizard applications and were built upon the same scenario. In the face recognition, Gabor jets were used to extract feature values of the face images. Matching the person was done according to the Gabor based feature vectors. In the hand recognition task, hand shape-based approach was applied on the hands. Hand segmentation, normalization and feature extraction were the important steps of this approach. In order to test the performance of the applications, data were acquired from 40 people. Recognition performances of the algorithms were analyzed for face, hand and fusion of two modalities. Besides performance, user evaluation was carried out in order to improve the usability of the user interface. A questionnaire regarding the speed, user interface and usability of the applications were collected by the people whose data were acquired. The interface was revised after the recommendations of the users."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hesaplama; veri, hesaplama kapasitesi ve diğer kaynakların(özel araçlar) paylaşımıın sağlayan servisler topluluğu olarak tanımlanabilir. Bilgisayar ağlarındaki gelişme Grid'in ilerlelemesinde çok etkili olmuştur. Grid'in çalışması için en önemli işlemlerden biri, işler için kaynak seçimi, diğer adıyla eşleştirmedir. Eşleştirme, yapılacak işlerin boştaki kaynaklara atanması işidir. En önemli hedeflerden biri grid'in verimliliğini artırmaktır. Kaynakların birbirinden çok farklı olduğu göz önünde bulundurulduğunda bu zor bir işlemdir. Eşleştirme için en popüler yaklaşımlardan biri SEE-GRID, EGEE ve TR-GRID'in de kullandığı Condor'un eşleştirme algoritmasıdır. Araştırmamızın amacı bu algoritmayı geliştirerek eşleştirme için daha verimli algoritmalar tasarlamaktır. Bu çalışmada, eşleştirme için iki yeni algoritma öneriyoruz. Her iki algoritmada da yapılmaya çalışılan şey, işleri tek tek almak yerine, bir takım olarak almak ve mümkün olduğunca fazla işi boş kaynaklara atamaktır. Algoritmalarımızdan birisi, İlk Kıt Kaynaklar Eşleştirme (SRFM) algoritması, kıt kaynakları eşleştirmeye öncelik verir. Diğer algoritma is Lineer Programlama Tabanlı Eşleştirme (LBM) algoritması olarak adlandırılmıştır. Simulasyon sonuçlarına göre, önerdiğimiz bu algoritmaların, tamamlanan iş sayısını atrırarak daha iyi bir şekilde çalıştığı görülmüştür.","Grid computing can be expressed as a set of services for sharing data, computation capacity and other resources like special equipment. Improvements in networking enabled grid technology to progress quite fast. Resource selection for jobs submitted in a grid, also called matchmaking, is one of the most important tasks needed for operating a grid. Matchmaking is a process that tries to assign jobs to available resources. One important goal of matchmaking is to maximize grid throughput. This is a difficult goal to realize because of the existence of heterogeneous resources in a grid. A widely used approach is Condor?s matchmaking algorithm, which is used by SEE-GRID, EGEE and TR-Grid infrastructures. The goal of this study is to improve this algorithm to obtain better algorithms for the matchmaking process. We propose two new polynomial algorithms for matchmaking. The idea shared by both of our proposed heuristic algorithms is that our heuristics take the collection of jobs and try to match as many jobs to available resources. One of our heuristics, called Scarce Resource First Matchmaking (SRFM), assigns by first trying to match scarce resources. The other heuristic called Linear programming Based Matchmaking (LBM) solves relaxed version of the NP-hard integer program and assigns resources by using relaxed solution values. Our simulation results show that our collective matchmaking schemes work quite well by improving the number of completed jobs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"In open multiagent systems with autonomous and heterogeneous agents involved, achieving cooperation is necessary but di±cult. Since every agent has limited and dif- ferent capabilities, they need to exchange some of their tasks to get the maximum e±ciency. For this purpose, they need to ¯nd out whom they can trust and delegate their tasks to be done. An important issue in building trust is to model other agents based on the previous interactions with them and decide on future relations by review- ing this useful information. However, building accurate models of others and updating them with recent ¯ndings is di±cult since the agents do not always behave as expected regarding their autonomous behavior. This thesis studies trust in the context of a service selection problem where the agents try to ¯nd the best service provider. Two learning algorithms that can be used to model the agent's environment are considered. The learning algorithms vary in terms of the models that they generate as well as their update behavior based on interactions. The learning algorithms have been evaluated using the Agent Reputation and Trust (ART) Testbed simulation environment. This platform is chosen since it ¯ts the best to the experiments done in the thesis. The results of the simulations compare the two algorithms in terms of the accuracy of models, the e®ectiveness in ¯nding trustworthy agents as well as the e®ort needed to build accurate models. Further, the algorithms are compared in terms of their robustness when some agents cheat or respond erratically."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"WiMAX standardının Mesh çalısma modu sistem kapasitesini Internet ve intranet trafiği için iki bölgeye ayırmıstır. Standarda göre bu iki trafik türünden biri diğerinin kapasitesini hiçbir sekilde kullanamamaktadır. Bu durum iki bölümden birinde sıkısık- lık ve diğerinde bos kapasite olduğu durumlarda düsük sistem kullanımına yol aç- maktadır. Biz çalısmamızda IEEE 802.16'nin Mesh çalısma modu için katmanlar arası çalısan Kuyruk Durumundan Haberdar bir Yönlendirme metodu gelistirdik. Bu metodu iki farklı yaklasımla inceledik. Metodumuz, Internet trafik bölgesinde sıkısık- lık olduğu durumlarda Internet trafiğinin, intranet bölümünü de kullanmasına olanak sağlamaktadır. Çözümümüz standartta herhangi bir değisiklik gerektirmediğinden mevcut kullanıcı ve baz istasyonu cihazlarında kolaylıkla uygulanabilmektedir. Sim- ulasyon sonuçlarımız metodumuzun iki yaklasımınında, Internet trafiğinde sıkısıklık meydana geldiği durumlarda uçtan uca gecikmeyi ve düsen paket adedini azalttığını göstermektedir. Bunun yanısıra Internet trafiğinin, intranet trafiğine ayrılan bölgeyi kullanmis olduğu için metodumuz intranet trafiğinin uçtan uca gecikme değerlerini fazla olmamakta birlikte artırmaktadır.","The Mesh mode of the WiMAX standard divides the system resources into two regions, one for Internet other for intranet tra±c. According to the standard, one type of tra±c cannot use the other's reserved capacity in anyway. This results in reduced system utilization when there is congestion in one region while other is not congested. We develop a cross layer Queue Aware Routing (QAR) scheme for the Mesh mode of IEEE 802.16 with two approaches that utilize the capacity allocated to intranet tra±c Internet tra±c in case the latter su®ers from congestion. Our solution does not introduce any changes in the standard. Thus, it can be implemented without incurring any change to existing user and BS devices. Our simulation results show that both of our QAR schemes decrease the end-to-end delay and the number of dropped packets at the cost of a slight increase in the delay for the intranet tra±c."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Güzergah planlama problemleri bir gok alanda karşimiza çikmaktadir. Ornegin, robotik, montaj analizi, sanal prototip uretimi, ilaç tasanmi, üretim, ve bilgisayar animasyonlan bu alanlardan bazilandir. Guzergah planlama algoritmalan, başlangic konfigiirasyondan amaç konfigiirasyona siirekliligi olan bir sira liesaplasim saglamaktadir. Bir giizergahın planlamasi çeşitli sinirlamalan içermektedir, ornegin bulunan yol sayesinde robot hig bir engele çarpmamalidir. Tepkisel algoritma olarak kullamlan APF algorithmasinin geliştirilmiş modeli robot koordinasyonunda en başanli algoritmadir. Bu algoritma 250 robotun koordinasyonunu kolaylıkla saglarken, RRT Connect algoritmasi, sadece 40 robota kadar biiyiik masraflarla eşgudiim yapabilmektedir. Diger duşiinen algorithmalar RRT, PRM ve Lazy PRM algoritmasi ise sadece 20 robota kadar koordinasyon yapabilmektedir. Robot koordinasyonunda tepkisel algorithmalar daha basarili olurken, eger ortam bolgesel minimumlar igeriyorsa diisiinen algoritmalann kullamlmasi kagimlmazdir. Ozellikle dinamik ortamlarda miskin algoritmalann kullamlmasi kullamlan kaynak ve geçen zamam azaltmaktadir. Coklu robotlar igin giizergah planlarken merkezi olmayan yaklaşimlar veya kismi gruplamalar yapmak daha biiyiik başanmlar goster-mektedir. Merkezi yaklaşimlarda ihtiyag duyulan zaman ve kaynak iissel artarken, merkezi olmayan yaklaşimlarda dogrusal arttigi igin, ortamdaki idare edilen robot sayisi arttigi zaman merkezi olmayan yaklaşimlan kullanmak bir gereksinim haline gelmek-tedir. Robotlan kismi kiimelemek, ihtiyag duyulan kaynaklar yaklaşik dogrusal arttigi ve yakm robotlar merkezi anlamda idare edildigi igin en iyi sonuçlan vermektedirler.","Path planning problems arise in many different fields such as; robotics, assembly analysis, virtual prototyping, pharmaceutical drug design, manufacturing, and computer animation. Path planning algorithms aim to solve problems that involve computing a continuous sequence, a path, of configurations between an initial and goal configuration. Planning of a path involves some constraints, such as computing a collision-free path. We compared various path planning and navigation algorithms. As reactive algorithm, an improved version of Artificial Potential Field (APF) algorithm is used. In robot coordination this algorithm is the superior algorithm. It coordinates 250 robots easily. Whereas deliberative algorithms, such as Rapidly-exploring Random Tree Connect (RRT Connect) algorithm, can only coordinate 40 robots with high costs. The other deliberative algorithms, Rapidly-exploring Random Tree (RRT), Probabilistic Roadmap (PRM) and Lazy Probabilistic Roadmap (Lazy PRM), could not coordinate more than 20 robots within feasible resource and time limits in our tests. In robot coordination reactive algorithms are more successful, but, when the environment contains local minima, using a deliberative algorithm is inevitable. In path planning for multiple robots, decentralized approaches, or partially grouping of the robots show better performances. As the number of the controlled robots in the environment increases, using decentralized approaches becomes a requirement, because the amount of the required time and the resources increases exponentially in centralized approaches, but linearly in decentralized approaches. Partially grouping of the robots gives the best performance results, because the resource requirements increase nearly linear, and nearby robots are controlled in centralized manner."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma, gorüntü is¸leme yardımıyla mobil bir robotun ortamda bulunan en-gellere çarpmadan ilerlemesi, belirlenmiş olan hedefe dogru yol alması için gerekli rotanın çizilmesi ve gerekli kontrol komutlarını saglayan yazılımın Microsoft Visual C++ yardımıyla oluşturulması ile ilgilidir. Bu amaçla bir deney düzenegi tasarlanmış ve oluşturulmuştur. Bu calışmada ayrıca, yol planlama ile ilgili mevcut algoritmalar incelenmiş, ince-lenen bu algoritmalarla ilgili Matlab'te simulasyonlar yapılmıştır. Bu simulasyonların sonuçlarının karşılaştırılmasıyla, VisBug algoritmasının bu çalışmada kullanılmaya en elverişli yontem oldugu sonucuna varılmıştır. Son olarak, robotun kontrolü için gerekli komutlar Microsoft Visual C++ programında derlenmiş ve yine Visual C++ yardımıyla oluşturulmuş arayüze taşınmıştır.","This study investigates control of a mobile Lego robot moves towards to the speci¯ed target without hitting the obstacles with the help of image processing. An experimental set-up was designed and conducted for experiments. Additionally, most common path planning algorithms were examined and Matlab was used to make simulations of these algorithms in this study. In the light of com- parison of the simulation results, VisBug Algorithm was selected as the most suitable algorithm for our study. Finally, necessary control commands to control the Lego robot were written in Microsoft Visual C++ and, are implemented in a user interface."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Boyutu d olan noktalar kümesi üzerindeki Skyline işlemi verilen d boyut için hiç bir nokta tarafından domine edilmeyen noktaları içerir. Skyline sorgulamaları ve hesaplanması son zamanlarda veritabanı ile ilgilenen topluluklar tarafından büyük ilgi görmüştür. Skyline noktaları veritabanı sistemlerinde önem taşımaktadır. Bu noktalar çok kriterli karar verme sistemleri ve veri madenciliği sistemlerinde çok kullanışlıdır. Günümüzde Skyline hesaplamaları ile veri sorgulamaları yapan algoritmalar mevcuttur. Bunun yanında şifrelenmiş veri üzerinden sorgulama yapan algoritmalar da mevcuttur. Sunulan sistemde, Skyline hesaplanmaları güvenli bir yoldan yapılmıştır.Şifreleme süreci Skyline hesaplamaları ile entegre edilmiştir. Şifreleme için, sıralamayı koruyan şifreleme metodu olan ve böylece performansa katkısı bulunan OPES kullanılmıştır. Sunulan sistemde, sistemin güvenliği şema saklama prosedürü ile güçlendirilmiştir. Bu sistem ile Skyline hesaplamalarında güvenli bir yol ile dış kaynak kullanılabilir. Sunucuistemci mimarisi dış kaynak kullanımı için kullanılabilir. Özet olarak, bu sistem Skyline hesaplamalarını güvenli bir yolla yapmamızı sağlar.","The skyline of a set of d-dimensional points contains the points that are not dominated by any other point on these d-dimensions. Querying skyline points and its computation has recently received considerable attention in the database community. Skyline points are important in database systems. They are useful for multi-criteria decision making systems and data mining systems. There are several algorithms that query data by Skyline computation. Also, there are several algorithms that query requested data from encrypted data. In my proposed system, the Skyline computation is proposed in a secure way. I combine encryption process and skyline computation in a single system. For encryption, order preserving encryption, OPES is used, which helps in the performance. The security of the system is strengthened by the schema hiding procedure in the proposed system. By this system, the skyline computation can be outsourced in a secure way. The client-server architecture is used for outsourcing. In summary, this system proposes Skyline computation in a secure way."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Toplumsal etkileşim ve kişisel begeniler tüketim davranışlarımızı derinden etkiler. Bireyin davranışlarını yonlendiren pek çok etken olmakla beraber, en temel seviyede bu davranışları kişisel ve toplumsal iki bilesenin etkileşiminin bir sonucu olarak modelleyebiliriz. Kişisel bilesen bireyin begenilerini, toplumsal bilesen ise cevresiyle (arkadaşları, ailesi, toplumun geri kalanı) girdigi etkiles¸imin davranışlar üzerindeki etkisini temsil eder. Bu bilesenleri tanımlamak ve aralarındaki etkileşimin dogasını incelemek bilgisayar bilimleri, toplum bilim, bilişsel bilimler, ekonomi ve fizik gibi pek çok disiplinin katkıda bulundugu aktif bir araştırma alanı olmuştur.Hesaba dayalı modeller kurmak ve incelemek bu araştırmanın bir parçasıdır ve fizikçiler uzun zamandır bir etmenin iki alternatiften birisini secmesi gerektigi du-rumları yansıtan modelleri sunmakta ve incelemektedirler. Gerçek dünyada da uygu-lama alanı bulabilecek bu karar verme problemlerine iki alternatiften birisinin seçimi soz konusu oldugu için ikili karar verme problemleri adı verilmiştir. Referanduma sunulmuş bir konuda evet ya da hayır oyu kullanmak, bir urünü almaya ya da alma-maya karar vermek bu modeller kullanılarak incelenebilen durumlardır. Bununla beraber kultürel pazarlarda gozledigimiz bir durum etmenlerin kararlarının ikili karar verme problemi olarak ele alınamayacagını gostermektedir. Bu da kısıtlı bütçe ve benzeri sebeplerden dolayı etmenlerin pazardaki her urünü tek tek degil topluca ele almaları ve ürünlerin kendi aralarında rekabet ediyor olmalarıdır. Bir ürün hakkında verilen tüketim kararı diger ürünler hakkında verilen karardan bagımsız degildir.Bu tezde kultürel pazarlar için hesaba dayalı bir model sunuyoruz. Amacımız bu model yardımıyla makro seviyede gerçeklesen tüketim davranışlarını incelemektir. Kultürel pazardan kastımız tüketicileri temsil eden bir etmen kümesi ve ürünleri (or. kitaplar, filmler, müzik albümleri) temsil eden bir ürün kümesinden olusan bir sistemdir. Tüketiciler birbirleri arasında toplumsal etkileşim içindedirler ve bu etkileşim ile kişisel begeniler tüketmeye karar verecekleri ürünleri belirler.Sonuçlar, ürünlerin pazar paylarının tüketicilerin kişisel begenileri arasındaki benzerlige ve toplumsal etkileşimin şiddetine aşırı hassas oldugunu gostermektedir. Olusan pazar payları arasındaki adaletsizlik ve bir urünün başlangıçtaki çekiciligi ile sahip oldugu pazar payı arasındaki korrelasyon degisen toplumsal etkileşim şiddeti degerlerine gore ani iniş ve çıkişlar gostermektedir.Elde ettigimiz sonuçların belirli parametre degerlerine bagımlı olmadığını gostermek için simulasyonlarımızı degişik parametre degerleri (or. etmenler arası ilişkileri belirleyen topolojik yapılar, etmen sayısı, vb.) kullanarak tekrarladık. Sayısal sonuçların degerleri degismekle beraber modelimizin davranışlarının çok geniş bir parametre deger yelpazesinde niteliksel olarak degismeden tekrarlandıgını gordük.","Social interactions and personal tastes shape our consumption behaviorsof cultural products. The behavior of an individual is driven by many factors butat the simplest level we can model his behavior as the outcome of an interactionbetween a personal component, which represents his personal tastes, and a socialcomponent, which represents the e®ect of his peers, family, society and etc. onhis decisions. Identifying the social and personal components and studying theirinteraction at an emergent level is an active area of research which borrows methodsand techniques from various disciplines such as computer science, sociology, cognitivescience, economics, and physics.Constructing computational models and analyzing them is one part of theresearch and physicists have already come up with some models which help us to dealwith simple decision models where agents are required to pick one of two alternatives.This type of problems is called binary decision problems and can be applied to avariety of real world situations like voting for or against a legislation and buyingor not buying a product. However, in real cultural markets, where many productscompete with each other, the consumption decision is not a binary one because thepeople are limited in budget, time, etc. And the agents have to consider all optionsbefore they come to a decision. Therefore, it is not possible to view the decision ofconsuming a product or not as a simple binary decision because it is not independentof other products.viIn this thesis, we present a computational model of a cultural market and weaim to analyze the behavior of the consumer population as an emergent phenomena.We conceptualize a cultural market as a set of consumers and a set of cultural itemssuch as movies, songs, or books where the consumers make decisions to consumethe items or not. The consumers are in social interaction with each other and theymake decisions based on their personal opinions and social pressure together.Our results suggest that the ¯nal market shares of the cultural productsdramatically depend on the consumer heterogeneity and social interaction pressure.The inequality of the resulting market and the correlation between the initial attrac-tiveness and ¯nal market share of a product exhibits sudden increases and decreasesdepending on the values of social interaction pressure.We also extend our simulations to test the robustness of the observed phe-nomena with respect to the topology of the social interactions between agents andother model parameters. Our ¯ndings suggest that the relation between the result-ing market shares and the social interaction does not depend on the actual values ofthe parameters such as the number of agents or the properties of the topology butqualitatively same for a wide range of parameter settings."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde bir el sezim ve takip sistemi sunulmaktadır. Sezim işlemi renk temelli olup, takip renk ve doku bilgisinin kaynaştırılmasıyla gerçeklenmiştir. Üç farklı parametrik olmayan sını andırıcı; histogram, kernel ve voroni olasılık kestiricileri, altı farklı renk uzayında karşılaştırılmıştır. Ayrıca aydınlanmadan daha az etkilenen bir renk kaynaştırma sistemi sunulmuştur. El takibi için renk ve doku bilgileri birleştirilmiş ve dokuyu tanımlamak için aydınlanma farklılıklarından etkilenmeyen bir operatör kullanılmıştır. İki bilginin birleştirilmesiyle daha gürbüz bir el tanımlaması ve takibi elde edilmiştir. Edindiğimiz sonuçlar bu yaklaşımın el-yüz örtüşmesini çözebildiğini ve eli arka plandaki nesnelerden daha iyi ayırabildiğini ortaya koymuştur.","This thesis presents a hand detection and tracking system where hand is ini- tialized using the color clue and tracking is achieved with the integration of color and texture information. Three nonparametric skin classication schemes; histograms, kernel densities, voronoi tessellations are analyzed on six dierent colorspaces. The optimal fusion of color features is also investigated for illumination free skin classication. The texture and color cues are combined to track the hand through the course of action. Texture is dened by Local Binary Patterns (LBP), which is a coarse estimation of joint probability of neighboring pixel values. By combining the color with texture more robust representation of hand is attained and meanshift algorithm is used to locate the hand in this representation space. The results show that texture-color combination can deal with face-hand overlaps and confusions of hand with other skin colored regions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım, günlük yasantımızda hemen hemen her alanda kullanıldıgı için kritik bir rol oynar. Yazılım bu kadar önemli oldugu ve çok kullanıldıgı için, güvenilir bir yazılıma sahip olmak önemlidir. Bu nedenle, yazılım güvenilirligini ölçen ve kontrol eden yöntemleri kullanmak çok önemlidir. Güvenilirligi ölçmek için, literatürde çok sayıda yazılım güvenilirlik modeli önerilmistir. Çok sayıda yazılım güvenilirlik modeli olmasına ragmen, her türlü sartta kullanılabilecek ve evrensel olarak tavsiye edilecek bir model bulunmamaktadır. Bu nedenle, son zamanlarda ki çalısmalar; mevcut modeller arasından yazılım ortamını en iyi tanımlayan yazılım güvenilirlik modelini seçmek üzerine yogunlasmıstır. Bu tezde, gelisen yazılım güvenilirligi için bir model seçim algoritması öneriyoruz. Önerilen algoritmanın, yazılım güvenilirligini degerlendirecek olası kullanıcılar için kılavuz olması amaçlanmıstır. Önerilen algoritma herkese açık veriler ile test edilmis ve yazılım güvenilirlik model seçimi konusunda basarılı bulunmustur. Ayrıca, yazılım mühendisligi süreci, mevcut yazılım güvenilirlik modelleri ve mevcut yazılım güvenilirlik model seçim metodları üzerine detaylı bir literatür arastırması sunulmustur.","Software plays a critical role in our daily life since it is used in almost every area. Since the software is so important and used widely; it is important to have reliable software. Thus it is very important to use methods to measure and control the reliability of the software. To measure the reliability, a large number of software reliability models have been proposed in the literature. Despite that there exist a large number of software reliability models, there does not exist a model that can be used in all cases and universally recommended. For this reason, recent works have been focused on selecting the reliability growth model among the available models, which best describes the software environment. In this thesis, we propose an algorithm for software reliability growth model selection. The proposed algorithm is aimed to be a guideline for potential users who wants to evaluate software reliability. The proposed algorithm is tested with the publicly available data and performed satisfactory for reliability model selection. Moreover, a detailed literature survey on the software engineering process, existing software reliability models and software reliability model selection methods is presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tez ÖzetiMehmet Zeki Önal, ?Operasyonel Risk Yönetimi için BütünleştirilmişBilgiTeknolojileri Kontrol Listesi?Bu makale, bir organizasyonda özellikle bilgi sistemleri ve teknolojilerialtyapından kaynaklanan operasyonel riskleri yönetebilmek amacı bütünleşsı yla tirilmişşbir bilgi teknolojileri (BT) kontrol listesi geliştirmektedir. Çalı BT Yönetişma, imçerçevesi ve standartları n (bilgi kontrol modelleri) farklını seviyelerdeki operasyonelrisklere cevap vermeleri ve birleştirilmeleri gerektiğ sorununu vurgulamaktadı Risk,ini r.mları ş şBasel II bağ nda birı,operasyonel risk ve risk yönetimi tanı tartılmı lamıgereksinim analizi yapı şbilgi kontrol modelleri (BKM) arası bir farklı analizilmı, nda lıkgerçekleştirilmiş Basel II'de zarar olay tipleri olarak açıve klanan operasyonel riskkategorilerinin BKM'lerdeki kontrol hedeflerine eş tirilmesi ile operasyonel riskleşşnyönetimi (ORY) için bütünleştirilmiş kontrol listesi önerilmiş ÇalıBT tir. manıgeçerliliğve güvenilirliğ eş tirmeler üzerinde yapı şi i, leş lmıolan grup değerlendirmesinerı şdayandılmı r. Kontrol listesinin yönetimsel etkileri, kontrol listesinin denetimetışşı tıetkileri göz önünde bulundurularak tartılmı r.1","Thesis AbstractMehmet Zeki Önal, ?An Aggregated Information Technology Checklist for OperationalRisk Management?This paper develops an aggregated information technology (IT) checklist in orderto manage the operational risks in an organization, especially those caused by theinformation systems and technology infrastructure. The study addresses the issue of theIT Governance frameworks and standards (information control models) that respond todifferent levels of operational risks and need to be harmonized. The definition of risk,operational risk, and risk management are discussed, a requirement analysis regardingBasel II is conducted, a gap analysis between the information control models (ICMs) isperformed, and the aggregated IT checklist for operational risk management (ORM) isproposed by mapping the control objectives in ICMs to the operational risk categoriesdescribed in Basel II as loss event types. The validity and reliability of the study is basedon the focus group assessment of the mappings. The managerial impacts of the checklistare discussed, considering the audit implications of the checklist.1"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tez ÖzetiÇağla Özen Şeneler, ? nsan ve Bilgisayar Etkileşimi Analizi ve PrototiplendirmeÇalışmaları?Değişik teknolojilerin vasıtasıyla daha iyi kullanıcı arayüzleri geliştirmeye ilgigittikçe artmaktadır çünkü kullanıcı arayüzü yetenekleri bilgi teknolojilerini benimsemesürecine çok fazla katkı sağlamaktadır. Çalışmanın amacı, teknolojiyi benimsemesürecinin özelliklerini sınıflandırmak ve ürün tasarım özelliklerinin ve teknolojiyibenimseme sürecinin değişik taraflarının kullanıcının ürün tercihini ve ürünü kullanmakonusundaki niyetini nasıl etkilediğine hitap eden bir araştırma çatısı oluşturmaktır.Bu çalışma, teorik altyapıya, önceki deneysel çalışmalara, önceden tanımlanmışteknolojiyi benimseme modellerine ve kullanıcı memnuniyeti modellerinedayanmaktadır. Sunulan sınıflandırma ve çatı, bir dizi inceleme ile oluşturulmuştur:derinlemesine görüşmeler, beyin fırtınası oturumu ve uzman fokus grup. Sunulan çatıyıtest etmek için anket içeren deneysel bir çalışma tasarımlanmıştır.Bu çalışmanın sonuçları ürün tasarım özelliklerinin kullanıcı tercihleri üzerindekietkisini ve kullanıcının ürünü kullanma konusundaki niyetinin geçmişini öneçıkarmaktadır. Sonuçla, kullanıcının zihinsel sürecini uyaran, efektif, verimli ve akıllımakine etkileşimini arttıran, kullanıcının teknolojiyi kabullenmesine yardımcı olan veürün kullanımını destekleyen arayüzler yaratmak isteyen geliştiriciler için önemlidir.","Thesis AbstractÇağla Özen Şeneler, ?Human Computer Interaction Analysis and Prototyping Studies?There is an increased interest in developing better user interfaces by means ofdifferent technologies because capabilities of user interface add a lot to the informationtechnology (IT) adoption process. The purpose of the study is to develop a taxonomy forthe characteristics of technology adoption process and a research framework thataddresses how the product design features and various aspects of technology adoptionprocess influence user preference and intention towards using a product.This study is based on a theoretical background review, prior empirical studies,previously defined technology acceptance models, and user satisfaction models. Proposedtaxonomy and framework have been developed by series of observations: in-depthinterviews, a brainstorming session, and an expert focus group. In order to test theproposed framework, an experimental study including a questionnaire was designed.The study? results highlight the effects of product design features on userpreferences and antecedents of user intention about using the product. The results will beimportant to developers who want to create interfaces that stimulate mental processes ofusers, improve an effective, efficient, and intelligent machine interaction, facilitate useracceptance, and assist product utilization."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tez ÖzetiBanu Kargın, ?Mobil Servis Kullanımını Etkileyen Faktörler?Mobil teknolojiler popülerliğini gün geçtikçe artırıyor ve hayatımızın her alanınanüfuz ediyor. Katma Değerli Servislerin, tüketicilerin kullanım alışkanlıkları üzerindebüyük etkisi vardır ve bu servisler operatörler arasında ayrıştırıcı etken konumunagelmiştir. Bu da farklılaştırıcı hizmetler yaratılması için yeni fırsatların çıkmasınısağlamıştır. Daha iyi servisler, kullanıcıların ihtiyaçlarını anlayarak karşılanabilir. Buçalışmada amacımız, katma değerli servisleri, özellikle bilgi servislerini araştırarak mobilservislerin benimsenmesi sürecini aydınlatmaktır. Çalışmaya, literatür araştırmasıyapılarak başlandı. Daha sonra, röportaj, beyin fırtınası ve uzman odak grup nitelçalışmaları yapıldı. Bu çalışmalar sonrasında, deneysel çalışma yapıldı. Deneysel çalışmasırasında, birleşik (conjoint) analiz yapıldı. Bu analiz ile ürün seçim faktörleri araştırıldı.Servis maliyeti ve servis hızı önemli faktörler olarak ortaya çıktı. Bunlara ek olarakyapılan regresyon çalışması ile mobil servis kullanım niyetine yol açan faktörlerbulunmaya çalışıldı. Literatüre parallel olarak, servisi kullanma isteği ve fayda, niyetidoğrudan etkileyen faktörler olarak bulundu. Kişiselleştirme, mobil olma, kullanıcıdeneyimi ve servis içeriği de kullanma isteğini fayda üzerinden etkileyen faktörler olarakbelirlendi.","Thesis AbstractBanu Kargın, ?Factors Affecting the Adoption of Mobile Services?Mobile technologies are gaining more popularity and diffusing into every aspect ofour life. Value Added Services (VAS) has a huge impact on consumers? usage patternsand has become a significant differentiator across the operators. These led to newopportunities in innovation of differentiating services. Better services will be bestdeveloped by understanding the requirements of the users. In this study, our intention isto shed some light on the process of mobile service adoption by investigating value addedservices especially for informative services. The study started with background researchto identify factors determining the adoption of mobile services; then continued withqualitative studies; namely interviews, brainstorming sessions, and expert focus group.After these studies, an experimental study was conducted. During this experimentalstudy, a conjoint analysis had been conducted. During conjoint analysis, productpreference factors were explored. Service cost and service speed were seen as criticalfactors. In addition to these, according to results of regression analyses which are done tofind the determinants of mobile service intention, attitude and usefulness were found tobe significant factors parallel to literature. Personalization, mobility, user experience andcontent were identified as indirect determinants of attitude mediated through usefulness."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüz endüstriyel toplumlarında farklı etnik kökene sahip insanlar bir araya gelerek sosyal bir toplum oluştururlar. İnsanlar diğer şehirlerden ve hatta diğer ülkelerden gelerek birlikte yaşamaya başlarlar. Bu insanlar beraberinde kendi kültürlerini ve yaşam tercihlerini de getirirler. Birbirleriyle etkileşimleri sonucunda bazı kültürel değerler toplumun çoğu tarafından kabul edilirken bazıları da tamamıyla unutulurlar. Bu değerlerin toplumun çoğu tarafından kabul görmesinin yada tamamıyla unutulmasının ardında yatan bazı etkenlerin olması kaçınılmazdır ve bu basitçe toplulukların sayısal üstünlükleriyle açıklanamaz. Bunun yanında insanların diğer topluluk bireyleriyle ilişki kurma tercihleri gibi etkenlerin de incelenmesi gerekir. Bu yüksek lisans tezinde yapılan çalışma ilk kez 2006 yılında H. Bingöl tarafından önerilen Basit Tavsiye Modeli'ni geliştirmektedir. Yeni model iki noktada farklılık göstermektedir: Bunlar, bireyler arasındaki etkileşim alışverişi'nin kişilerin kültürel tercihleri üzerinden yapılması ve alıcı konumundaki bireyin seçilmesinin teklif eden bireyin tercihine göre yapılmasından ibarettir. Gerçek veri olarak 1998 yılında Wimmer tarafından yapılmış ve yerel İsviçre halkı ile göçmenler arasındaki ilişkileri inceleyen araştırma kullanılacaktır. Bizim modelimizde bireyler etnik kökenlerine göre gruplandırılacak ve ilk önce kendi kültürel tercihlerini taşıyacaklardır. Daha sonra birbirleriyle ve diğer gruplarla ilişkiye geçecek ve bir alış-veriş mekanizması ile kendi tercihlerini diğer bireylere kabul ettirmeye çalışacaklardır. Bu işlemin soncunda bazı kültürel tercihler tamamıyla ortadan kalkarken bazıları ise topluluğun çoğu tarafından bilinir hale geleceklerdir. Biz burada hangi toplulukların tercihlerinin kaybolduğu ve hangilerinin tercihlerinin toplumun çoğu tarafından bilinir hale geldiğini ve bunların arkasında yatan etkenleri bulmaya çalışacağız.","In Today?s modern Industrial cities we see that, many people having different cultures share the same settlement and form a typical social complex system. People come from other cities or even foreign countries and form an ethnically diverse population. Newcomers bring their daily habits and other cultural values such as clothing styles, meals, likes and dislikes. As a result of interacting with other people some cultural values change and completely forgotten while others become popular and known by the majority of people. There should be a mechanism helping some cultural values and choices being more popular and causing other people being assimulated by majorities and this mechanism may not be simple as because of their population sizes. Instead, there may be some other factors such as peoples? choice of interactions with other groups. The work done in this M.S. thesis extends the Simple Recommendation Model (SRM) that is firstly introduced by H. Bingöl in 2006. The new model diversifies in two points: That is, recommendations between agents will be made over their choices and selections of recommended agent will be made according to the recommender agent?s cpreference of interactions. The research made by Wimmer in 1998 about the native Swiss and immigrants? interactions among each other will be used for empirical data. In our model, agents will be grouped according to their national origin and initially will keep their own choices in their memories. Then, they will begin to interact with each other and with other groups. They will remember and forget the choices by an exchanging mechanism. As a result some choices will emerge to be known by the majority of people while some others will completely be forgotten. We will try to predict which group?s choices are likely to become popular and which group?s choices are likely to be forgotten and the reasons not mentioned."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"This work introduces a new human-computer interface(HCI) device for three dimensional (3D) visualized data. Although there are different approaches developed in the literature, 3D interfaces have not finished their development. The HCI we designed basically aims at taking an arbitrary cross-section (oblique slicing) from volumetric data. Additionally, the interface we called ?3D Stylus? has an extra option which enables the user to draw two dimensional curves. The 3D Stylus is a colorful, long and thin structure like a pen. The 3D Stylus is tracked by using image processing algorithms. 3D information about the interface is acquired with the help of stereo processing techniques applied to the images come from the stereo camera. The 3D Stylus is a flexible tool that can be used for different purposes in different applications. In the thesis, we firstly develop a oblique slicing application using 3D Stylus as normal vector of slicer held by the user. Then another application is developed for 2D drawing, and the 3D Stylus used as a chalk. At the end of the thesis, experiments are presented. Users are asked to use the 3D Stylus and mouse interfaces in our applications. Results about efficiency of the 3D Stylus are given, compared with mouse."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"GÖMÜLÜ SİSTEMLERDE HATA KESTİRİMİGömülü sistemlerin hayatımızın her alanına yayılması kısa sürede kaliteli gömülüyazılım üretilmesi için talebi arttırdı. Bu durumla başedebilmek ve geliştirme sürecini iyiyönetebilmek için yeni yaklaşımlara gerek duyulmaktadır. Yazılımda hata kestirimi, testaşamasının maliyetini düşürmek ve son ürünün kalitesini arttırmak için odaklanılmasıgereken alanlardan birisidir.Bu araştırmada özellikle gömülü yazılımlar için geliştirilmiş bir hata kestirimimodeli önerdik. Yazılım ölçütleri ve hataya meyillilik arasındaki karmaşık ilişkininmodellenebilmesi için makine öğrenimi teknikleri kullandık. Öne sürdüğümüz modelgömülü yazılımlarda hata kestirimi için uygun özellikleri olan üç makine öğrenimitekniğininin birleşiminden oluşmaktadır.Sonunda ortaya çıkan model, gömülü yazılım geliştirenlere yazılım geliştirmedöngüsünün gelecekteki yinelenmelerinin planlanmasında ve test kaynaklarının doğru birşekilde kullanılmasında yardımcı olacaktır. Böylece gömülü yazılım geliştiricileri hataayırım aşamalarının etkinliğini arttırarak ürünlerinin kalitesini arttırabileceklerdir.","DEFECT PREDICTION FOR EMBEDDED SOFTWAREAs ubiquitous computing becomes the reality of our lives, the demand for highquality embedded software in shortened intervals increases. In order to cope with thispressure, software developers need new approaches to manage the development cycle: tofinish on time, within budget and with no defects. Software defect prediction is one areathat has to be focused to lower the cost of testing as well as to improve the quality of theend product.This research proposes a defect prediction model specifically for embedded softwaresystems. We utilize machine learning techniques in order to identify the complexrelationship between software metrics and defect-proneness. Our proposed model involvesthree different machine learning techniques which have useful characteristics for defectprediction in embedded software. We combine the strengths of these machine learningtechniques in order to obtain a general model for defect prediction in embedded software.The resulting model may be used to assist the embedded software developers inplanning the future iterations of their development life-cycle and allocating their limitedtesting resources more effectively. This will help embedded software developers inincreasing the quality of their products by increasing the efficiency of defect removalstrategies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz algılayıcı ağlar, ilgilenilen bir alanın gözlenmesi amacıyla yerleştirilen çoksayıda algılayıcı düğümden oluşur. Algılayıcı düğümler pil ile çalışan cihazlar olduklarıiçin, çalışma süreleri kısıtlıdır. Çoktan-bire çok-hoplamalı iletim karakteristiğine sahipalgılayıcı bir ağda çıkış düğümüne daha yakın düğümler daha çok enerji tüketir. Böylelikle,çıkış düğümüne en yakın düğümler pillerini diğerlerine göre daha hızlı bitirirler. Bununyanında, bu düğümler öldüklerinde diğer düğümler çıkış düğümüne artık bağlanamayacağıiçin, ağ ömrü bu düğümlerin ömürleri ile sınırlıdır.Ağdaki dengesiz enerji tüketimi algılayıcıların farklı yoğunlukta yerleştirilmesi vefarklı pil kapasitesine sahip algılayıcılar kullanılarak telafi edilebilir. Bu tez, homojenolmayan topoloji dizaynlarının faydalarını incelemektedir. Tezin ilk bölümünde ağın farklıbölgelerinde farklı pil kapasiteleri kullanılması olasılığı incelenmektedir. Tezin ikincikısmında ise, kalabalık ağları ele alarak, ağın farklı bölgelerinde farklı yoğunlukta düğümkullanımının ağ ömrü üzerinde etkisi incelenmektedir.Bu tez homojen olmayan ağ topolojilerinin ağ enerji kaynaklarının toplamını etkinbir şekilde kullandığını göstermektedir. Bu etkililik, homojen olmayan ağ topolojilerikullanıldığında, aynı toplam maliyet ile çok daha uzun ağ ömrü sağlamaktadır.","Wireless sensor networks consist of a large number of sensor nodes deployed in aregion of interest for monitoring purposes. As sensor nodes are battery powered devices,their operation time is limited. In a multi-hop sensor network with many-to-onecommunication characteristics, the nearer a node is to the sink, the more energy itconsumes. Therefore, the nodes closest to the sink deplete their batteries faster than theothers. Moreover, the network lifetime is bounded by the lifetime of these nodes, sincewhen they fail, other nodes will no longer be connected to the sink.Unbalanced energy consumption in the network can be compensated by deployingsensors non-uniformly and using heterogeneous battery capacity sensors. This paperinvestigates the benefits of topologies which exploit nonuniformity and heterogeneity. Inthe first part of the thesis, we study the possibility of using different battery capacity nodesin different regions of the network. In the second part of the thesis, we consider densenetworks and study how the network lifetime is affected by using different densities indifferent regions of the network.The thesis shows that heterogeneous network topologies offer efficient usage of thetotal network energy resources. This efficiency results in significantly longer networklifetimes with the same total cost when variable capacity sensors or variable densities areused."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Benzer işler için bilinen en iyi klasik algoritmalardan üstel olarak daha verimli kuantum algoritmalarının kesfi, araştırmacıları kuantum hesaplamanın gorünürdeki üstunlugunün sebeplerini ve sınırlarını daha iyi anlamak için bir çok hesaplama modelinin klasik ve kuantum surumlerinin goreceli guçlerini karşılaştırmaya itmiştir. Bu sekildeki karşılaştırmalı analiz sonuçları ilginç gorünen modellerden biri sonlu durumlu makinelerdir. Bu çalışmada farklı kuantum sonlu makine türleri arasında en güçlü aile olan çift yonlü sonlu durumlu makinelere (2ksm) odaklanılmıştır. Kondacs ve Watrous herhangi bir verili pozitif hata sınırı e için Leq = {anbn| n > 0} dilini tanıyan 2ksm'nin inşası için buldukları yontemi kullanarak 2ksm'lerin klasik benzerlerinden daha güçlü oldugunu ispatlamis¸lardır. w girdi dizisi ol-mak üzere, bu yonteme gore insa edilen makineler O((\)) sayısında duruma sahiptir ve O((\)|w|) adım çalışırlar. Araştırmamızda, bu masraf fonksiyonlarının istenen hata sınırına baglılı?gını azaltmanın yolları incelenmektedir. Aynı dili tanıyan daha etkili yontemler sunulmaktadır. Yontemlerimizden birinin ürettigi sonlu makineler O(|w|) adımda dururlar (çalısma zamanı hata sınırına baglı degildir) ve verili herhangi bir c sabiti için O((\)i) sayıda duruma sahiptirler. Durum sayısı karmaşıklıgı J'a gore poli-logaritmik olan ve O(log(±)|w|) adımda duran sonlu makineler üreten başka yontemler de sunulmaktadır","The discovery of quantum algorithms which are exponentially more e- cient than the best known classical algorithms for similar tasks has spurred researchers to compare the relative powers of the classical and quantum versions of several computational models to better understand the causes and limitations of the apparent power of quantum computing. One model for which such comparative analyses have led to interesting results is that of nite automata. Among the various types of quantum nite automata, we concentrate on the strongest family, namely, two{way quantum nite automata (2qfa's). Kondacs and Watrous proved that 2qfa's are more powerful than their classical counterparts by describing a method for constructing 2qfa's that recognize the non{regular language Leq = fanbnj n > 0g for any given error bound > 0. Machines built according to this method have O(( 1 )2) states, and they halt after O(( 1 )jwj) steps, where w is the input string. In this thesis, we examine ways of reducing the dependence of these cost functions on the desired error bound. We present more ecient constructions to recognize the same language. One of our methods produces machines which halt in O(jwj) time (i.e. the running time does not depend on the error bound) and which have O(( 1 )2 c ) states for any given constant c > 1. Other methods, yielding machines whose state complexities are polylogarithmic in 1 , and which halt in O(log( 1 )jwj) time, are also presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vÖZETRH(+): ÇALIÂMA ANINDA YENÂDEN BETÂMLENEBÂLENDONANIMLAR ÜZERÂNDE YÜKSEK SEVÂYEDE SÂSTEMTASARIMI MODELÂYeniden betimlenebilen mimariler üzerinde gömülü sistem tasarm süreci, geliÂ³tir-me süresindeki giderleri azaltmak için ve çalÂ³ma annda kaynaklar verimli kullan-abilmek için akll çözümlere ihtiyaç duymaktadr. Fakat, varolan dillerin (C++/UML)uzants olan Â³u anki çözümler (SystemC/xtUML) bunun için yeterli deÂ§ildir. OluÂ³anverimsizliÂ§in sebepleri Â³unlardr: duyulan ayrntl operatör tanm gereksinimi, yüksekseviyelerde kullancy alt seviye tasarm problemleriyle karÂ³ karÂ³ya brakmak, karÂ³kdonanm soyutlama yöntemleri, yazlmn donanma atanmas srasnda kullancy yan-lÂ³ yönlendirme, yazlmn ara gösterimi üzerinde kullancnn kstlar girmesine izinvermeme, ve yüksek seviyeden alt seviyeye baÂ³arm eksikliÂ§i olan çkÂ³lar üretme. Bunedenlerden ötürü, varolan yöntemlerlerden verimli bir Â³ekilde yararlanmak için buyöntemler sadece tasarlandklar amaçlarla kullanlmaldrlar.Bu tez çalÂ³masnda, Â³unlar önermekteyiz: (1) RH(+); çalÂ³ma annda yenidenbetimlenebilen mimariler için sözü edilen verimsizlik problemlerini aÂ³an yeni markabir yüksek seviyede gömülü sistem tasarm modeli, (2) LRH(+); varolan dillerin biruzants olmayan yeni marka bir tasarm dili, (3) FRH(+); RH(+) gereksinimlerinikarÂ³layan çerçeve. ÇalÂ³mamzda, hedef mimari destek paketi geliÂ³tirmek, çeÂ³itli op-eratörler tanmlamak, kullanc etkiliÂ³imli grakler üretmek, yazlm proli çkarmak,kaynak yönetimi saÂ§lamak, ve çalÂ³ma an öykünüm için araçlar bulunmaktadr.","ivABSTRACTRH(+): THE MODEL FOR HIGH-LEVEL EMBEDDEDSYSTEM DESIGN ON RUN-TIME RECONFIGURABLEHARDWAREThe process of embedded system design on recongurable architectures needssmart solutions to reduce the cost of development life-cycle and to use resources ef-ciently at run-time. However, the current solutions (SystemC/xtUML), which areextended from the traditional languages (C++/UML), are insucient for that. In-eciency occurs due to: detailed operator denition requirement, forcing user to payattention low-level design problems at higher levels, complex hardware abstraction pro-cedures, misguiding user during mapping software to hardware, not permitting user todene constraints at the level having software intermediate representation, and out-puts lacking of performance from high levels to lower levels. Therefore, the traditionalmethods must only be used for what they are designed, in order to benet from themeciently.In this thesis, we propose: (1) RH(+); a brand new high level embedded systemdesign model for run-time recongurable architectures, solving the aforementioned in-eciency problems, (2) LRH(+); a brand new design language which is not extendedfrom any traditional languages, (3) FRH(+); the framework meeting RH(+) require-ments. In our work, we have the tools for developing board support package, deningmiscellaneous operators, generating graphs for user interactions, proling, resourcescheduling, nding possible paths with their execution delays, and run-time emulationof recongurable hardware."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"!""! # $%$% & !!"" $%! ' ( ! $%""( ()* !!","!"" #$ %!"" !""&#!""#"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde doğrusal tamsayı programlama (ILP) tabanlı, CHIPS adı verilenbir araç zinciri tarif edilmektedir. Temel bir işlemci ile adanmış birmantıksal devre arasındaki veri bandı genişliği verildiğinde, CHIPSözelleştirilmiş komutları bulur. Özelleştirilmiş durum yazmaçlarınıdestekleyen bir temel işlemci mimarisi üzerine kurulu bu yöntem,tasarımcıların isteğe bağlı olarak komutların işlenen girdi veçıktılarının sayılarını sınırlandırmalarına olanak verir. Bu tezde,en vaad edici alan, başarım ve kod büyüklüğü ödünleşimlerininbulunması için kapsamlı bir tasarım akışı anlatılmaktadır. Girdi/çıktısayısı ve yazmaç dosyası kapı sayısı üzerindeki sınırlandırmalar ilebirlikte if-dönüştürmesi ve döngü açılması gibi derleyici dönüşümlerideğerlendirilmektedir. Deneylerimizin önemli bir çoğunluğunda en yüksekbaşarımlı çözümlerin girdi/çıktı sınırlamaları kaldırıldığında bulunduğugözlemlenmiştir. Fakat, girdi/çıktı sınırlamaları sık kullanılan kodkısımlarının tanımlanmasını sağlamıştır. Şifreleme ve çoklu ortamalanlarını kapsayan on bir denektaşı testi üzerinde detaylı sonuçlarsunulmaktadır. Denektaşı testleri 1.7 ve 6.6 kat arasında hızlandırılmış,kod büyüklükleri yüzde altı ve yüzde 72 oranları arasında azaltılmış,en yüksek başarım için 12 ile 256 toplayıcı alanı arasında değişenmantıksal devre alanlarına ihtiyaç duyulmuştur. Yöntemimizin büyükproblemler üzerinde de etkili olduğu, 1000 kadar komuttan oluşan temelkod blokları içeren denektaşı testlerinin eniyi şekilde, çoğu zamansadece bir kaç saniye içinde çözülebildikleri gösterilmiştir.Aynı testlerüzerinde var olan en ileri yöntemlerin kabul edilebilir süreler içindeeniyi sonuçlara ulaşamadıkları görülmüştür. Çalışmamız diğer yöntemlertarafından bulunamayan çözüm örnekleri ile de desteklenmektedir.","In this thesis, we describe an integer linear programming (ILP) basedsystem called CHIPS for identifying custom instructions given the availabledata bandwidth and transfer latencies between the base processor and thecustom logic. Our approach, which involves a baseline machine supportingarchitecturally visible custom state registers, enables designersto optionally constrain the number of input and output operands forcustom instructions. We describe a comprehensive design flow toidentify the most promising area, performance, and code size trade-offs.We study the effect of the constraints on the number of input/outputoperands and on the number of register file ports. Additionally, we explorecompiler transformations such as if-conversion and loop unrolling. Ourexperiments show that, in most of the cases, the highest performingsolutions are identified when the input/output constraints areremoved. However, input/output constraints help our algorithmsidentify frequently used code segments, reducing the overallarea overhead. We provide detailed results for eleven benchmarks coveringcryptography and multimedia. We obtain speed-ups between 1.7 and6.6 times, code size reductions between six per cent and 72 per cent,and area costs that range between 12 adders and 256 adders for maximalspeed-up. We demonstrate that our ILP based solution scales well, andbenchmarks with very large basic blocks consisting of up to 1000instructions can be optimally solved, most of the time within a fewseconds. We show that the state of the art techniques fail to findthe optimal solutions on the same problem instances within reasonabletime limits. We provide examples of solutions identified by ouralgorithms that are not covered by the existing methods."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"AYIRTAÇ TOPLULUKLARI VE SINIFLANDIRICI B RLEŞT RMEKURALLARININ HATA ÇÖZÜMLEMESMurat SEMERCHer sınıflandırma algoritması veri hakkında farklı bir varsayımda bulunur ve farklıörüntüler üzerinde yanlış yapar; bu yüzden uygun bir kaynaşım ile genel doğrulukarttırılabilir.Birleştirme, genellikle sonsal olasılık olan sınıflandırıcı sonuç değerleri üzerindegerçekleştirilir. Sınıflandırıcı kaynaşım yöntemlerinin amacı doğruluk başarımınıarttırmak olsa da her zaman başarılı olacaklarının teminatı yoktur. Bu çalışmada bütünsınıflandırıcı sonuç değerlerini kullanmak yerine, onların altkümelerini kullanan yeni birbirleştirme tasarısı öneriyoruz. Ayırtaç seçmek ve birleştirmek için karar ağaçları veözellik seçme kullanan üç farklı yöntem deniyoruz. Karar ağaçlarının en iyi özellikaltkümesini seçmede daha başarılı olduğunu ve seçilen ayırtaç sonuçları eğitilmiş birdoğrusal model ile birleştirildiğinde doğruluk başarımını daha da arttırılabildiğinigörüyoruz.Sabit kuralların davranışlarını anlamaya çabalarken, hata fonksiyonunu yanlılık, değişintive gürültü bileşenlerine ayırma fikrini uyguluyoruz. Bu çalışmada yazındaki kare ve 0/1hata tanımlamalarının yanlılık, değişinti ve gürültü ayrıştırmalarını kısaca gözdengeçiriyor, bu bileşenlerin toplulukların hata davranışını, özellikle en küçük ve en büyükkuralları kullanıldığında, açıklamada yetersiz kaldığını gösteriyoruz. Bazı kaynaşımyöntemlerinin, veri kümesinin üstünde birbiçimli veya Gauss gürültü varsayımlarıaltında, ötekilerden daha iyi çalışmasının nedenlerini veriyoruz. Sabit kurallarındavranışını açıklamak için kesişim alanına dayanan bir ölçü öneriyoruz.","DISCRIMINANT ENSEMBLES AND ERROR ANALYSIS OF CLASSIFIER FUSIONRULESMurat SEMERCEach classification algorithm has its own underlying assumption and misclassifiesdifferent patterns and overall accuracy can be increased by a suitable fusion of multipleclassifiers.The combination is performed over the scores of classifiers, which are mostly posteriorprobabilities. Although the aim of classifier fusion is improved accuracy, there is noguarantee that this will be the case. In this study, we propose a new combination schemewhich uses a subset of the classifier scores instead of using all of them. We experimentwith three different methods for discriminant selection and combination, using decisiontrees and feature selection. We see that decision trees are better in choosing the bestsubset of features and accuracy is improved especially when the chosen discriminantoutputs are combined with a trained linear model.In trying to understand the behavior of the fixed rules, we apply the idea of decomposinga loss function into bias, variance and noise. This study gives a brief survey of the bias,variance and noise decompositions in the literature for squared and 0/1 loss. We showthat they are unable to explain the error behaviour of fusion rules, especially forminimum and maximum rules. We give the reasons why some fusion strategies workbetter than others under the assumptions of uniform or Gaussian noise. We proposeinstead a measure based on the area of intersection to explain the behavior of the fixedrules."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vÖZETVER KATARLARINDA B RL KTEL K KURALLARININ SAKLANMASIBu çalışma veri katarları için birliktelik kurallarının keşfi ile geleneksel veritabanlarıiçin birliktelik kurallarının saklanmasının birleştirilmesine yönelik bir çalışmadır. Temelolarak, veri katarında birliktelik kurallarının saklanmasını sağlayan bir sistem tanıtılacakve ilgili altyapı detaylı olarak geliştirilecektir.Bugüne kadar her iki alanla ilgili ve bazıları çok iyi sonuç veren birçok algoritmageliştirilmiş olmasına rağmen, veri katarları için birliktelik kurallarının saklanmasınayönelik bir çalışmayla karşılaşmadık. Bu çalışmada, bu iki ilginç araştırma alanlarınıbirleştiren yeni bir sistem tanıtılacaktır. Veri katarları için birliktelik kurallarınınsaklanması algoritmamızı sentetik veri üzerinde denemekteyiz. Aynı zamandaalgoritmamızı şablon tabanlı XML verisi için de çalıştırmaktayız. Performans testlermizgöstermiştir ki kurduğumuz sistem veri katarları için birliktelik kurallarını etkin bir şekildesaklamaktadır.","ivABSTRACTASSOCIATION RULE HIDING OVER DATA STREAMSThis study is about an endeavor towards combining association rule mining over datastreams and association rule hiding for traditional databases. Mainly, a system forassociation rule hiding over data streams will be introduced, and related background willbe developed in detail.Although there are many algorithms, some of which perform very well, developedfor both association rule mining over data streams and association rule hiding fortraditional databases so far, we have not meet a work on stream association rule hiding,namely a work which combines these two research areas. In this work, we introduce a newsystem in which we merge these two interesting research areas of association rule mining.We apply our stream association rule hiding algorithm on synthetic data. We also run ouralgorithm over a template guided XML data. Our performance tests show that proposedsystem hides association rules for data streams efficiently."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Geçtiğimiz on sene içerisinde internet ve mobil teknolojileri hayatımıza birçok yeni kavramı sokarken, öncesinde alternatifi olmayan birçok kolaylığı da beraberinde getirerek hayatımızın vazgeçilmez birer parçası olmuştur. ADSL ve kablosuz networklerin yaygınlaşması ve yakın bir gelecekte WiMAX ile şehir içi mobil internet ve üzerinde katmadeğerli servisler yine hayatımızda getireceği servislerle bir çığır açacaktır. Günümüzde e-ticaretin getirdiği bir çok kolaylık ve avantajlar birçok kişi tarafından benimsenmiş olsa da ödemelerin internet üzerinden kredi kartı ile yapılmasının ciddi güvenlik sorunlarına sebep olam ihtimali büyük çoğunluk e-ticareti hayatına sokmamayı tercih ediyor. Mobil ciharların bu kadar yaygınlaşması ve internet erişiminin de gün be gün daha kolay erişim imkanları, ödemelerinde cep telefonları üzerinden güvenli bir şekilde yapılmasını mümkün kılmaktadır. Bu projede, mobil platformlar üzerinden, direk kredi kartı veya para kullanmadan, ödemelerin yapılmasını sağlayan bir sistem gerçekleştirdik. Mevcut ödeme yöntemlerinden daha güvenli bir platform olarak mobil ödeme sistemini inşa etmek üzere çeşitli güvenlik algoritmaları ve yapıları kullanılmıştır.","Over the last decade, with the rapid development of internet and mobile technologies new concepts got into our lives. Several convenience which hasn?t been existed before became indispensable part of our lives. The widespread of ADSL and wireless Networks and with WiMAX technology, mobile internet and value added mobile services will usher a new era. Nowadays, although the convenience and advantages of e-trade is being used by so many people, the security risk of credit card transactions over internet keeps major community away from e-trade opportunities. Today?s mobile technology, spread of mobile devices and easier internet access alternatives, gives opportunity of mobile payment more secure and convenient. In this Project, we realized a payment system over mobile platforms without using credit card and cash. In this mobile payment system in order to maintain security, a group of algorithms and security blocks are used."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ESNEK KOD DENETİMİM. Erdal ŞekerciBilgisayar Mühendisliği, Yüksek Lisans Tezi, 2007Tez Danışmanı: Prof. Dr. H. Levent AkınAnahtar Kelimeler: Yazılım Kalitesi, Kod Analizi, Statik kaynak kod analizi, AyrıştırmaYazılım geliştirme sürecinde üzerinde durulan en önemli nokta, gereksinimlerikarşılayan ve doğru şekilde çalışan bir sistem üretmektir. Ancak, bir yazılımın doğruşekilde çalışması, onun kaynak kodunun kaliteli olduğunu ve düzgün yazıldığınıgöstermez. Kaynak kod içersinde fark edilmemiş hatalar veya gereksiz kodlar bulunabiliryada kaynak kod belirlenmiş kodlama standart ve kurallarına uymayabilir. Bu tip durumlarkaynak kodunun okunaksız bir hale gelmesine yol açar ve kaynak kodunu yazan kişidışındaki kişiler tarafından anlaşılmasını, geliştirilmesini ve analiz edilmesini oldukça zorhale getirir. Bu tez çalışmasına kaynaklık eden en önemli nokta da bu tip durumlarıengellemektir. Bu çalışmadaki fikir, verilen bir kaynak kodunu analiz etmek ve onukullanıcı tarafından tanımlanan esnek kontrol kurallarına ve kaynak kod standartlarına göredenetlemektir. Böylece, programlama derslerindeki projeler gibi çeşitli alanlarda verilenbir kaynak kodunu denetlemek ve kaynak kodunun tanımlanan kurallara göre kalitesinibelirlemek mümkün olacaktır.","FLEXIBLE CODE CHECKERM. Erdal ŞekerciComputer Engineering, M.S. Thesis, 2007Thesis Supervisor: Prof. Dr. H. Levent AkınKeywords: Software quality, Code checking, Static code analysis, ParsingIn software system development, the most important issue is to build a system thatsatisfies the requirements and works correctly. But even if a software system workscorrectly, this does not show that its source code is well-written. The source code maycontain unnecessary codes, may have undetected bugs, or may not conform to the requiredcoding standards or rules. This will make the code dirty and unreadable making it verydifficult for other people (except the writer) to understand, update or analyze the sourcecode. The motivation for this thesis underlies in this issue. The idea is to analyze a givensource code and check it according to user defined flexible checker rules and codingstandards (conventions). This could be useful in checking source codes in a variety of areassuch as student projects in programming courses and deciding how good the source codeswere written according to the defined rules of the checker."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KAYNAK KODUNU AKIŞ D YAGRAMINA ÇEV RMESelim DelioğluBilgisayar Mühendisliği, Yüksek Lisans Tezi, 2007Tez Danışmanı: Prof. Dr. H. Levent AkınAnahtar Kelimeler: Akış diyagramı, Dilbilgisi, Ayrıştırıcı, Kaynak kodu analizi, Kaynakkodu görselleştirmeGünümüzde insanlara algoritmalar için görsel olarak akış diyagramı düzenlemeimkanı veren çok çeşitli araçlar mevcuttur. Bu araçlarla istenilen programlama dilleri içinkaynak kodu veya kaynak kodu şablonları yaratılabilmektedir. Bundan daha zor bir görevde varolan kaynak kodlarını analiz edip bunu programlama dilinden bağımsız olarak ifadeedebilen bir şema yaratmaktır. Bu şema bilgisi ile akış diyagramı yaratılabilir veya var olankod yaratıcı araçlar da kullanılarak bir programlama dilinden diğerine tercüme yapabilenbir uygulama yapılabilir.","SOURCE CODE TO FLOWCHART CONVERTERSelim DelioğluComputer Engineering, M.S. Thesis, 2007Thesis Supervisor: Prof. Dr. H. Levent AkınKeywords: Flowchart, Grammar, Parser, Source code analysis, Source code visualizationThere are a wide variety of tools that enable people to visually design flow-charts foralgorithms to generate source code or code templates for desired programming languages.A challenge can be to analyze existing source code and generate a schema that describesthe algorithm independent of the underlying programming language. This schema can beused to generate a flowchart or one can further combine this with existing code generatorsto implement a translator that converts source code from a programming language toanother one."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZETTürkiye'deki Geleneksel Firmaların E-Ticaret Kurulumu SırasındakiStratejik Amaç ve Verimliliklerinin Analizi:Karşılaştırmalı ÇalışmaÖzlem SipahiPiyasalarda yaşanan rekabet ortamı, farklı büyüklükteki pek çok firmayı rekabetdışında kalmamak için yeni teknolojiler kullanmaya itmektedir. E-ticaret bu teknolojilerarasında en belirgin fayda sağlayanlardan biri olmakla birlikte, aynı zamanda firmalara pekçok seçenek sunarak kendileri için en uygun çözümü seçmelerine de yardımcı olabilmektedir.Bununla birlikte, teknolojideki yüksek hızda değişim göz önüne alındığında, firmalar yüksekdeğerde teknoloji yatırımlarında bulunmadan önce doğru ürüne yatırım yapabilmek için,yatırımın kendilerine dönüş oranının ne olacağını ve yapılacak yatırımların verimliliklerineetkilerini göz önünde bulundurmalıdır. Bu çalışmanın amacı, Türkiye'de yer alan farklısektörlerin e-ticaret uygulamalarına etki eden faktörlerin belirlenerek karşılaştırma yapılmasıve bu faktörlerin firmanın e-ticaret ile hedeflediği değerlere ulaşmasında yaratacağı etkininölçümlenmesidir. Çalışma kapsamında analiz yapılacak sektörler olarak ?Turizm, Finans veTekstil? belirlenmiş olup sektörler arasında yaşanan farklılığı belirleyebilmek amacıyla anketçalışması yapılmıştır. Hipotezler oluşturularak t testleri ve regresyon analizi yardımıyla e-ticaretin verimliliğe etkisinin ölçümlenmesi hedeflenmektedir.","ABSTRACTStrategic Aims and Effectiveness of Turkish Traditional CompaniesImplementing E-Commerce: A Comparative StudybyÖzlem SipahiIncrease of competition in the local markets urges the companies of various sizes toimplement new technologies in order not to be left behind the competition. E-commerce isone of the major types of these technologies, offering the companies a wide range ofopportunities, so that they can find the most appropriate solution for their needs. However, asthe technological solutions renew themselves with an amazing velocity, organizations have toconsider about the rate of returns on their investments. They should analyze the effects of newtechnologies on their organizational effectiveness before making an investment, so that theycan make the right selection. The aim of this study is to explore the factors affecting e-commerce in different sectors in Turkey, compare the sectors and measure the relations ofthese factors with the effectiveness of company objectives regarding e-commerce. In thescope of this research, Tourism, Finance and Textile sectors are selected as sample and asurvey has been conducted to define major differences between these sectors. Hypotheseshave been defined and tested using t tests and regression analysis in order to explore thefactors influencing effectiveness of e-commerce in organizations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Elektronik ortamda bulunan Web servislerinin sayısı arttıkça belirli bir isteğikarşılayacak uygun servisleri bulmak da önem kazanmaktadır. Bu probleme ilişkingünümüzdeki çözümler ve yaklaşımlar kısıtlı tanımlamalar kullandıkları için ve anlamsaltanımlamalardan tam anlamıyla faydalanmadıklarından yetersiz kalmaktadırlar. Servistanımlamaları arasındaki benzerlikleri bulmada kullanılan servis eşleme yöntemi etkin birWeb servis bulma işlemi için büyük önem taşımaktadır. Günümüze kadar olan çalışmalargöstermiştir ki anlamsal Web teknolojilerinin kullanımı servis eşleme yöntemininetkinliğini ve başarısını artırmaktadır.Bu araştırmada Web servisi bulma ve kompozisyonu konuları için çok önemli olanbir konuyu inceliyoruz: Web servis eşlemesi. Bu çalışmada OWL ve OWL-S gibi servislerive ontolojileri ifade etmede kullanılan güncel anlamsal Web teknolojilerini kullanıyoruz.Ayrıca, iki kümeli grafiklere dayanan etkin bir Web servis eşleme algoritmasınıtanıtıyoruz. Güncel çalışmaların çoğunda da görüldüğü üzere Web servislerindeparametrelerin anlamsal olarak eşlenmesi problemi olan parametre eşlemesi için iki kümeligrafiklere dayalı çözümler çok daha etkindir. Önerdiğimiz eşleme algoritması belirli biristeğe denk gelen aday Web servis kümesi içinden isteğe en benzer olan servislerisıralayarak çıktı olarak sunmaktadır. Ortaya koyduğumuz Web servis eşleyicisi anlamsalbenzerlik eşlemesi işlemi için şu teknikleri kullanmaktadır: Kapsama tabanlı benzerlik,özellik tabanlı benzerlik, benzerlik uzaklığı notları ve WordNet tabanlı benzerlik. Eldeettiğimiz sonuçlar gösteriyor ki ortaya koyduğumuz servis eşleyici anlamsal ilişkilerinortaya çıkarılmasında daha etkin olmakta ve detaylı bir eşleme yapılmasına imkanvermektedir.","As the number of available Web services increase finding appropriate Web servicesto fulfill a given request becomes an important task. Most of the current solutions andapproaches in Web service discovery are limited in the sense that they are strictly defined,and they do not use the full power of semantic and ontological representation. Servicematchmaking, which deals with similarity between service definitions, is highly importantfor an effective discovery. Studies have shown that use of semantic Web technologiesimproves the efficiency and accuracy of matchmaking process.In this research we focus on one of the most challenging tasks in service discoveryand composition: Service matchmaking. We make use of current semantic Webtechnologies like OWL and OWL-S to describe services and define ontologies. Weintroduce an efficient matchmaking algorithm based on bipartite graphs. We have seen thatbipartite matchmaking has advantages over other approaches in the literature for parameterpairing problem, which deals with finding the semantically matching parameters in aservice pair. Our proposed algorithm ranks the services in a candidate set according to theirsemantic similarity to a certain request. Our matchmaker performs the semantic similarityassignment implementing the following approaches: Subsumption-based similarity,property-level similarity, similarity distance annotations and WordNet-based similarity.Our results show that the proposed matchmaker enhances the captured semantic similarity,providing a fine-grained approach in semantic matchmaking."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yakın gelecekte, kablosuz ödeme sistemleri, üstün iş fırsatları oluşturmaya, tüketicilere mobil hizmetleri, elverişli ve esnek bir biçimde, istenilen yerde ve zamanda sağlamaya başlayacak, bu sistemlerin bankacılık sektöründe ve ödeme işlemlerinde önemi artacaktır. Cep telefonlarının, PDA'ların ve diğer mobil cihazların yayılımı düşünüldüğünde, mobil ödeme sistemleri hakkındaki bu öngörü desteklenmektedir. Ayrıca mobil ödeme sistemlerinin bir diğer yanı ise cep telefonlarının her tipte ödemeler için kullanılabilmesidir. Güvenli ve uygun maliyetli kablosuz ödeme çözümleri üretmenin, iş fırsatları yaratmasının yanında, mühendislere çözülmesi gereken yeni teknik konular getirmesi de bir diğer yönüdür. Bu yüzden, mobil ödemeleri destekleyen, güvenli ve kolay yönetilebilir kablosuz ödeme sistemleri üretmek popüler bir araştırma konusudur.Bu projede, stabil, güvenli ve sağlam bir mobil ödeme sistemi tasarlanmış ve geliştirilmiştir. Kural tabanlı, kullanıcı tarafından özelleştirilebilen dolandırıcılık tespit etme modülü, ek olarak sisteme dahil edilen yüksek güvenlik önlemleri, kullanıcı dostu, anlaşılması kolay arayüzü ile bu mimari gerçeklenebilir bir mobil ödeme yapısı sunmaktadır.","Mobile payment on wireless devices will provide excellent business opportunities in the coming years and offers consumers convenience and flexibility of mobile services anytime and at any place, and is playing an increasingly important role in payments and banking. This prediction is supported when considering the high rate of penetration of mobile devices, especially mobile phones, PDA?s and other. Also an additional aspect is that the mobile phone can be used as payment device for all types of payment situations. Creating secure and cost-effective wireless payment solutions to support mobile device users not only provides good business opportunities, but also brings new technical challenges and issues to engineers. So how to build secured, easily manageable, wireless payment systems to support mobile payment transactions becomes a hot research topic.In this project, a stable, secure and reliable mobile payment system is designed and implemented. With rule-based, user-customizable fraud detection system and additionally implemented high level security precautions; user friendly and intuitive interface, this architecture offers a feasible mobile payment framework."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz algılayıcı ağlar sınır bülgelerinde izinsiz sızmaları sezmek işin kul-g o clanılabilir. Algılayıcıların düzenli olarak yerleştirildiği ağlarda, güzetim kalitesi üncedenu s gg o oanaliz edilebilir. Eğer algılayıcılar sınır bülgesine rasgele dağıtılıyorsa, konuşlandırmag o g skalitesini belirlemek zordur ve uygun ülşuler kullanmak gerekir. Başlangışta konuşlandı-o cü s c srılacak algılayıcı sayısını belirlemek kritik bir tasarım kararıdır. Zaman işinde algılayıcı-clar üldükşe, konuşlandırma kalitesinin değişimini incelemek gerekir. Sebekenin ümrüo uc s gs ş ougüzetim kalitesine bağlı tanımlanmalıdır.o gBu tezde, kablosuz algılayıcı ağların güzetim kalitesini analiz etmek işin ülşutlerg o c o cüünerilmekte ve konuşlandırılacak algılayıcı sayısı ile arasındaki ilişki incelenmekte-o s sdir. En zayıf sızma yolu problemi tanımlanarak belli bir güzetim kalitesi işin gereklio calgılayıcı sayısını hesaplamak işin yüntemler ünerilmektedir. Eş-sezme şizgesi bir bülge-c o o s c odeki eşit sezme olasılıklarını güsterir ve uzerine boşaltma havzası kesimleme tekniğis o ü s guygulandığında ortaya şıkan şevre hatları olası sızma yollarını güsterir. Bu tezde,g c c ogüzetim kalitesini hesaplamak işin olası sızma yollarından oluşturulan şizgeyi kullanano c s cbir yordam ünerilmektedir. Güzetim kalitesi analitik olarak doğrulanmakta ve zamano o gişinde değişimi gerşekşi bir benzetim modeli ile analiz edilmektedir. Güzetim kalitesinec gs cc obağlı şebeke ümrü tanımları ünerilmektedir.gs ou o","Surveillance wireless sensor networks are deployed at border locations to detectunauthorized intrusions. For deterministic deployment of sensors, the quality of de-ployment can be determined suï¬ciently well by analysis in advance of deployment.However, when random deployment is required, determining the deployment qualitybecomes challenging. To assess the quality of sensor deployment, appropriate measuresmust be proposed. Determining the required number of sensors to be deployed initiallyis a critical decision. After deployment, temporal changes in the surveillance qualityas the sensors die in time must be analyzed. The network lifetime deï¬nition mustconsider the surveillance performance of the network.In this thesis, to analyze the surveillance performance of the network, we proposedeployment quality measures. We discuss the trade-oï¬ between the number of sen-sors and the deployment quality. We formulate the weakest breach path problem, andpropose a method to determine the required number of sensors to be deployed. Wepropose the utilization of the watershed segmentation on the iso-sensing graph thatreveals the equally sensed regions of the ï¬eld of interest in a surveillance application.The watershed segmentation algorithm is applied on the iso-sensing graph to identifythe possible breach paths. An algorithm is proposed to convert the watershed seg-mentation to an auxiliary graph which is then employed to determine the deploymentquality. The surveillance quality is veriï¬ed analytically. The temporal resilience of thesurveillance quality is analyzed with a realistic discrete event simulator, and networklifetime deï¬nitions based on the deployment quality measures are proposed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yüz tanıma biyometri araştırmalarına konu olmanın yanı sıra insan-bilgisayaru siletişimi bağlamında da şok araştırılmış, uzerinde şok şalışılmış bir problemdir. Bus g c s sü c cs sşalışmada amacımız uş boyutlu yüz tanıma tekniklerini değerlendirmek ve biyolojikcs üc u gtabanlı modeller yoluyla geliştirmektir. Bu amaşla üncelikle insanlarda yüz tanımanıns co unasıl olduğuna baktık. Varolan 3B yüz tanıma sistemlerini değerlendirdikten sonra,g u gbilişsel bilim bulguları ışığında bir yüz tanıma modeli ünerdik. Modelin ilk kısmıs sg u oolan otomatik kayıtlama, ve kayıtlama işin elzem saydığımız otomatik nirengi noktasıc gübulma problemlerine yoğunlaştık. Oncelikle üzniteliklerin üğrenmesini kolaylaştıracakg s o og sgüclü bir güzetimsiz üğrenme algoritması geliştirdik. Bu algoritma bize faktür ana-uş u o og s olizi yaklaşımıyla esnek veri modellemesi sağladı. Ardından yüzlerde tanımladığımızs g u gnirengi noktalarını otomatik olarak bulmak işin bu yaklaşımı kullandık. Sonra, bulunanc snirengi noktalarını yeni bir yapısal düzeltme algoritmasıyla düzelttik. Bu algoritmaylau ueksik ve hatalı imgelerde bile kayıtlama yapmak mümkün oldu. Otomatik nirengiuunoktası bulma metodumuzun başarısını deformasyonlu ve deformasyonsuz kayıtlamasmetodlarıyla ülştük, deformasyonsuz kayıtlamada daha yüksek başarı elde ettik. Li-oc u u steratürde sıkşa kullanılan ?düngülü en yakın nokta? algoritmasının en büyük sorunuu c o uu uukayıtlamanın yüksek maliyetli olmasıdır. Bunu aşmak işin ortalama yüz modeli kul-u s c ulanarak kayıtlama ünerdik. Ayrıca, ?diğer ırk efekti? uzerine yapılan araştırmalardano g ü syola şıkarak, yüzlerin gruplanarak paralel sınıï¬andırıcılarla değerlendirilmesinin başarı-c u g smı artırabileceği varsayımını denedik. Bir diğer yaklaşımda da şekil uzayında topak-g g s slama yaparak değişik gruplar elde ettik. Ortalama yüz modeli kullandığımız işin derin-gs u g clik değerlerinin eşit aralıklı ürnekleme ile düzenlenmesi de mümkün oldu. Bu yüntemg s o u uu ohem hız, hem de başarımı artırdı. Sonuş olarak tamamen otomatik ve başarılı bir 3Bs c syüz tanıma sistemi elde ettik.u","Face recognition has been an active area of study for both computer vision andimage processing communities, not only for biometrics but also for human-computerinteraction applications. The purpose of the present work is to evaluate the existing 3Dface recognition techniques and seek biologically motivated methods to improve them.We especially look at ï¬ndings in psychophysics and cognitive science for insights. Wepropose a biologically motivated computational model, and focus on the earlier stagesof the model, whose performance is critical for the later stages. Our emphasis is onautomatic localization of facial features. We ï¬rst propose a strong unsupervised learn-ing algorithm for ï¬exible and automatic training of Gaussian mixture models and useit in a novel feature-based algorithm for facial ï¬ducial point localization. We also pro-pose a novel structural correction algorithm to evaluate the quality of landmarking andto localize ï¬ducial points under adverse conditions. We test the eï¬ects of automaticlandmarking under rigid and non-rigid registration methods. For the rigid registrationapproach, we implement the iterative closest point method (ICP). The most importantdrawback of ICP is the computational cost of registering a test scan to each scan inthe gallery. By using an average face model in rigid registration, we show that thecomputation bottleneck can be eliminated. Following psychophysical arguments onthe ?other race eï¬ect?, we reason that organizing faces into diï¬erent gender and mor-phological groups will help us in designing more discriminative classiï¬ers. We test thisclaim by employing diï¬erent average face models for dense registration. We propose ashape-based clustering approach that assigns faces into groups with nondescript gen-der and race. Finally, we propose a regular re-sampling step that increases the speedand the accuracy signiï¬cantly. These components make up a full 3D face recognitionsystem."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde daha ünce teke günderim işin ünerilen şok katmanlı şizge yaklaşımınıo o co c c stüm-optik şok ï¬berli ağlarda şoğa günderim işin üneriyoruz. Bu yaklaşım daha genel,u c g cg o co sgerşekci ve esnek bir modelleme sağlamakta ve problemi nadir ışık bülme ve dalgaboyuc g s odünüştürme kısıtlarıyla bir matematiksel formülasyona (MILP) kavuşturmaktadır. Prob-o us u u slem CPLEX tarafından şozülüp ya verilen hassasiyette en iyi sonuş yada alt sınır kücukcü u u c uşüağlar ve gruplar işin elde edilebilir. Fakat büyük problemler ve dinamik şoğa günderimg c uu cg oihtiyaşları işin uş buluşsal metot ünerilir (LAMA, SLAM ve C-FWA). Cok sayıdac c üc s o şdeney LAMA ve SLAM'in en iyiye yakın ve rakibinden (M-ONLY) daha iyi olduğunugbütün metrikler işin güstermektedir. LAMA ve SLAM'in iyi şalışmasının sebebi rakip-uu c o csleri gibi rotalama ve ï¬ber-dalgaboyu atama safhalarını ayırmayıp birlikte eniyilemeyeşalışmasıdır. Bu sebeple ünemli tüm metrikler (kullanıcı ve grup tıkanma olasılıkları,cs o udalgaboyu ve ï¬ber dünüştürme, günderici sayısı) bu safhaların ayrılmasından negatifo us u obir şekilde etkilenmektedir. LAMA'nın ülşeklenebilir versiyonu olan SLAM LAMA'yas ocyakın bazen de ondan iyi sonuş verir ve herhangi bir büyüklükteki statik yada di-c uu unamik tüm-optik şoğa günderim problemlerini şüzer. Son olarak ünerilen yeni ï¬ber-u cg o co odalgaboyu atama stratejisi (C-FWA'deki Ex-Fit) First-Fit stratejisinden daha az ï¬berve dalgaboyu dünüştürme kaynaklarını harcamaktadır.o us u","We propose to use a layered graph approach, which has been previously proposedfor unicasting, to have a more general, realistic and ï¬exible model of an all-optical mul-tiï¬ber network for multicasting. This new presentation enables us to state the problemof all-optical multicasting with sparse light splitting and wavelength conversion restric-tions so that it is formulated as an original Mixed Integer Linear Programming (MILP).The MILP formulation is solved by CPLEX which ï¬nds the optimal solution within agiven precision and it also gives a lower bound by relaxing the integrality constraints.However, it is possible to solve MILP problems to optimality only for small networksand number of sessions, since the problem is NP-hard. Therefore, we also propose threediï¬erent heuristics (LAMA, SLAM and C-FWA) for larger problems and dynamic mul-ticasting requests. Extensive computational experiments demonstrate that LAMA andSLAM perform close to the optimal and better than their competitor (M-ONLY) forall metrics. However, LAMA and SLAM work better than their alternatives, since wejointly optimize routing and ï¬ber-wavelength assignment phases compared to the othercandidates which attack to the problem by decomposing two phases. Experiments showthat important metrics are adversely aï¬ected by the separation of routing and ï¬ber-wavelength assignment. SLAM, which is the scalable version of LAMA, performs closeor better to LAMA. Finally, we also propose a new ï¬ber-wavelength assignment strat-egy (Ex-Fit in C-FWA) which uses wavelength and ï¬ber conversion resources moreeï¬ectively than the First Fit."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu şalışma bir otonom robotlar takımının dayanışmalı konuşlandırılması işincs s s cyeni bir yüntem onerir. Bu calışma aynı zamanda gürü ltü lü , onceden tahmin edilemezo ü şs u u uu üve yeterli algılama yapılamayan diğer iş mekan gerşek-zamanlı robot calışmaları işingc c şs cde uygundur.Tekli kendini konuşlandırma sorununu her robot işin bulunduğu cevreye ait yerels c gşalgı ve hareket bilgisi kullanılarak cüzmek işin Ters Monte Carlo konuşlandırması(R-şo c sMCL) isimli yeni bir yüntem tasarlanmıştır. R-MCL, Markov konuşlandırması(ML)o s sve Monte Carlo konuşlandırması(MCL) uzerine kurulan melez bir yüntemdir.s ü o Buyüntemde ML tabanlı bülü m robotun olması gereken bülgeyi bulur ve MCL tabanlıo ou obülü m bu bülgeden ornekler seşerek geometrik konumu yüksek şüzü nü rlü kle bulur.ou o ü c u co u u uCoklu robot konuşlandırması sorununda robotlar kendi yerel tahminlerini ve diğerş s gtakım arkadaşlarından gelen paylaşılan bilgiyi kullanarak kendilerini konuşlandırır.s s sYerel bilgi ve inanşları uygun olarak birleştirebilmek, catışmaları onlemek ve takımc s şs üelemanları arasında dayanışmayı desteklemek işin R-MCL'e dayalı yeni bir dayanışmalıs c sşoklu robot konuşlandırma metodu sunulmuştur. Robotlar birbirlerini algıladıklarındac s sbu güzlemi yansıtan ızgara hücrelerini paylaşırlar. Yüntemin gerşek gü cü melezliğindeno u s o c uu ggelir. Gerşek-zamanlı uygulamalarda kesin olarak olşulemeyecek güzlemleri ızgara ta-c ü cü obanlı yaklaşımla, kendini konuşlandırma sorununu ise daha kesin sonuş veren ürnek ta-s s c obanlı yaklaşımla, benzer şalışmalardan daha az ornek kullanarak cüzer.Her iki yüntems cs ü şo ode benzetim robotları ve gerşek robotlar ile denenmiş ve sonuşlar yüntemlerin hızlı,c s c osağlam, kesin ve hesap, hafıza ve iletişim masraï¬arı aşısıdan ucuz olduğunu güstermiştir.g s c g o s","This work proposes a novel method for collaborative global localization of a teamof soccer playing autonomous robots. It is also applicable to other indoor real-timerobot applications in noisy, unpredictable environments, with insuï¬cient perception.A novel solution, Reverse Monte Carlo Localization (R-MCL) is designed to solvesingle self-localization problem using local perception and action about the surroundingenvironment for each robot. R-MCL is a hybrid method based on Markov Localization(ML) and Monte Carlo Localization (MCL) where the ML based part ï¬nds the regionwhere the robot should be and the MCL based part predicts the geometrical locationwith high precision by selecting samples in this region.In the multi-robot localization problem, robots use their own local position esti-mations, and the shared information from other team mates, to localize themselves. Tointegrate the local information and beliefs optimally, avoid conï¬icts and support collab-oration among team members, a novel collaborative multi-robot localization methodcalled Collaborative Reverse Monte Carlo Localization (CR-MCL), based on R-MCL,is presented. When robots detect each other, they share the grid cells representing thisobservation. The power of the method comes from its hybrid nature. It uses a gridbased approach to handle detections which can not be accurate in real-time applica-tions, and sample based approach in self-localization to improve its success, although ituses lower amount of samples compared to similar methods. Both methods are testedusing simulated robots and real robots and results show that they are fast, robust,accurate and cheap in terms of communication, memory and computational costs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Çoketmenli örgütler birbirleriyle iletişim halindeki etmenlerden oluşur. Belirli rollerive görevleri olan bu etmenlerin amacı örgütün hedeflerini etkin bir şekildegerçekleştirmektir. Örgütlerin biçimsel betimi, örgüt tasarımcısının var olan örgütleriincelemesini ve örgütlerde olası bir değişiklik hakkında fikir üretmesini sağlar. Örgütleridüzenli bir biçimde analiz etmek o örgütlerle ilgili oluşabilecek hataları erkenden teşhisetmeye yardımcı olur. Bu tez, örgütleri taahhütlere dayalı bir yaklaşımla temsil etmeye veoluşabilecek hataları ve çelişkileri ortaya çıkartıp çözmeye yarayacak metodlargeliştirmektedir. Buna ek olarak, tasarımcıların örgütleri kolay tasarlamasını ya da gerekendeğişiklikleri yapmasını sağlayan bir yazılım geliştirilmiştir. Bu yazılım bir örgütünişleyişinin tutarsızlıkları kontrol ederek oluşabilecek hataları işaret edebilir ve o hatalarındüzeltilmesini sağlayan öneriler sunabilir. Ayrıca, birden fazla örgütün bir arada çalışmasıiçin o örgütlerin benzer niteliklerini bir araya getirip, örgütlerle ilgili üst seviyeli birgörünümü kısmen otomatik bir şekilde ortaya çıkarabilir. Bu özellikler, iki örgütten oluşanbir vaka araştırmasıyla gösterilmiştir.","Multiagent organizations are composed of interacting agents. These agents areusually assigned with roles and have clearly defined tasks so that organizational goals areeffectively materialized. Formal specifications of multiagent organizations alloworganization designers to analyze existing organizations and reason about possible changesin the organizations. Systematic analysis of organizations can help identify potential errorsin the organization early on. In this thesis we study a commitment-based approach forspecifying organizations and then detecting and resolving inconsistencies and conflicts inthe specifications. Additionally, we have developed a software tool to help organizationdesigners with creation and manipulation of organizational specifications. The tool cancheck the workings of an organization for inconsistencies and signal the possibility or thecertainty of a conflict during execution and can provide a set of suggestions for resolvingconflicts. Furthermore, the tool can semi-automate the task of combining twoorganizational work-flows, by aggregating related properties of the organizations; and canpresent a higher level view of organizations. We illustrate these properties using a casestudy that deals with two organizations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Web servisleri günümüzde kullanılan en önemli dağıtık yazılım mimarisidir. Webservislerinin platformdan bağımsız olması ve kolay entegrasyonu, kendinden önce var olandağıtık yazılım mimarilerinde karşılaşılan sorunları çözmede etkili olmuştur. Sonuç olarak,web servisleri dağıtık mimarinin vazgeçilmez parçası olmuştur. Günümüzde, web servisleriile ilgili ana motivasyon, iş akışlarında kullanılmak üzere değişik web servislerini birleştirmeve entegrasyonunu sağlamaya yöneliktir. Bu konuda en etkili web servis entegrsayonuBusiness Process Execution Language (BPEL) dili ile sağlanabilir.Web servisleri, platformdan bağımsız ve kolay entegre olabilmelerine karşın,performans ve kullanılabilirlik açısından birçok problemlere sahiptirler. Bu konunun iki ananedeni vardır. Birinci neden, web servislerine erişmede istemci sunucu arasında olan networktrafiğidir. İkinci neden ise, web servisleri işlemlerinde XML bazlı protokollerin ve dillerinkullanılmasıdır. Bu yüzden, bu tezde, BPEL işlemlerinde kullanılan web servislerininperformans ve kullanılabilirlik sorunlarına çözüm bulmayı amaçladık. Bu çözüm için dekatkımız, proaktif önbellekleme kullanarak, ileride gereken web servis sonuçlarını önbellektetutmak olmuştur. Bu yüzden oluşturduğumuz Proaktif Önbellekleyici ve Hayali ProaktifÖnbellekleyici ve Programcı, ulaşım bilgileri bilinen web servislerine etkili önbelleklemesağlamayı amaçlamıştır. En önemli amaçlarımızdan biri de, önbelleklemeyi sağlarken istemcitarafında performans kaybına sebep olmamak idi. Bu sayede, web servislerinin yükünüazaltmaya çalıştık. Tezin sonunda yaptığımız deneysel testler, yaklaşımımızın etkisiniölçmeye yardımcı olmuştur.","Web services are one the most promising technologies in distributed computing.Platform independence and easy interoperability features of web services solved manyproblems faced with earlier distributed computing technologies. As a result, web services areessential for communication of objects in distributed world. Nowadays, the main motivationregarding to web services is composing them to accomplish business applications. There aremany web service composition languages in the literature. On those languages, BusinessProcess Execution Language (BPEL) is the most effective composition language to provideinteraction among web services.Despite platform independence and easier interoperability features, web services facemany performance and availability problems. There are two main reasons for this: The firstreason is the propagation delay between clients and server. The second reason is extensiveuse of XML in web service operations. Thus, in this study, we aimed to solve performanceand availability problems of web services that BPEL processes use in business applicationsby applying a caching mechanism. Our main contribution is to apply a proactive cachingmechnism to web services, so generated cache can be used for future operations. O u rProactive Caching Scheduler and Daemon Proactive Caching Scheduler performs caching ofweb services whose binding information is known. One of the most important aspects of ourstudy is to apply efficient caching without sacrificing overheads on client side. By this way,we aimed to decrease the load in web services since it is not necessary to invoke a webservice if its cache is not expired. Our research concludes with experimental tests taken fromreal life scenarios. The experiments help us to better understand the applicability andefficiency of our approach."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar agları günümüz insan yasamının önemli bir parçası olarak görülebilir. Çesitli kurulusların veri ve bilgileri özel ve genel aglar tarafından iletilmekte oldugundan bu agların güvenlik parametrelerine olan giderek artan özel bir ilgi olusmustur. Bu agların güvenligini artırmak için güvenlik duvarı ve saldırı tespit sistemleri gibi araçlar kullanılır. Saldırıların belirtilerini bulabilmek için bir bilgisayar sistemi veya agdaki olayları izlemek ve analiz etmek saldırı tespit sistemi olarak adlandırılır. Bu tezde maksimum entropi prensibini kullanan payload tabanlı bir saldırı tespit sistemi, Me-PAYL önerilmistir. Baslangıç noktası PAYL metodudur. Agdan izlenmis verileri kullanan maksimum entropi ve göreli entropyiye dayalı bir ag tabanlı tespit sistemi gelistirilmistir. Daha fazla verim almak için maksimum entropi yaklasımının avantajları PAYL modeli ile birlestirilmistir. Önerilen metot, Me-PAYL, bütün payloadlar içeren kullanılabilir en büyük veri kümesi olan, DARPA 1999 Intrusion Detection Evaluation (IDEVAL) veri kümesi ile test edilmistir. PAYL ve Me-PAYL metotlarının IDEVAL veri kümesi ile olan test sonuçlarını karsılastırdıgımızda, Me-PAYL metodunun çok daha verimli oldugu görülebilir.","Computer Networks can be considered as an important component of today?s human life. Since data and information of various organizations are transferred through private and public networks such as the global internet, special attention is being paid to the security parameters of these networks. In order to increase the security of these networks, tools such as firewalls and intrusion detection systems are used. The process of monitoring the events occurring in a computer system or network and analyzing them for sign of intrusions is known as Intrusion Detection System. In this thesis a payload based intrusion detection system using the maximum entropy principle, the Me-PAYL is proposed. The starting point is the PAYL method. A network anomaly detection technique that uses sniffed data of the network and based on maximum entropy and relative entropy methods is developed. Advantages of maximum entropy approach are combined with PAYL model to obtain more efficiency. The proposed method, Me-PAYL is tested with DARPA 1999 Intrusion Detection Evaluation (IDEVAL) Dataset, which is the largest dataset available with whole payloads. When comparing results of PAYL and Me-PAYL with tests on the IDEVAL dataset, it can be seen that the Me-PAYL method is much more efficient than the PAYL method."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Konuma dayalı servisler, mobil kullanıcılara bulundukları konuma bağlı olarak kişisel servisler sunmayı mümkün kılmaktadırlar ve dolayısıyla bu durum özellikle son yıllarda telsiz ağlarda konum belirleme üzerine çalışmaların artmasına neden olmuştur. Konum belirleme sayesinde acil durum servisleri, iz sürme, konuma dayalı bilgi ve reklam servisleri, konuma dayalı ücretlendirme gibi birçok servis mümkün hale gelmektedir. Bir mobil kullanıcının konumu birkaç baz istasyonunun kontrol kanallarından gelen sinyal gücü ölçümlerini kullanarak tahmin edilebilir. Sinyal gücü ölçümlerine dayalı bu yöntem literatürdeki sinyal geliş açısı yöntemi, sinyal alım zamanı yöntemi ve yardımlı küresel konumlama sistemi gibi yöntemler kadar hassas olmasa da, ağ yapısında ve mobil cihazlarda herhangi bir değişiklik ve buna bağlı olarak ek maliyet gerektirmemesinden dolayı yaygın olarak kullanılmaya devam edilmektedir. Radyo sinyallerinin yayılma karakteristiği ortamdan ortama farklılıklar gösterdiği için, konumu belirlenecek olan mobil cihazın içinde bulunduğu ortam koşulunun tahmini, sinyal gücüne dayalı konum belirleme yöntemlerine büyük yarar sağlayarak hassasiyeti arttıracaktır. Bu çalışmada, hücresel ağlar için ortam-bilinçli, sinyal gücü ölçümlerine dayalı yeni bir konum belirleme yöntemi sunulmaktadır. Önerilen metodun ana özelliği, örüntü tanıma vasıtasıyla kullanıcının içinde bulunduğu ortamı kırsal kesim, banliyö veya şehir içi olarak belirleyip bu bilgiyi kullanarak sinyal gücüne dayalı konum belirleme metodunun hassasiyetini arttırmaktır. Yöntemin başarımı farklı coğrafi koşullarda bir GSM ağından alınan gerçek ölçümler kullanılarak test edilmiş ve konumlama başarımının ortalama hata ve standard sapma gibi birçok yönden iyileştiği gözlemlenmiştir. Bunlara ek olarak, sunulan metod herhangi bir sinyal gücü tabanlı konum belirleme algoritmasına bir iyileştirme eklentisi olarak kolayca eklenebilir.","Location Based Services (LBS) enable personalized services to the mobile subscribers based on their current position and consequently it has received significant attention in both research and industry over the past few years. Mobile positioning plays a key role in providing LBS such as wireless emergency services, location tracking services and location-aware information and advertisement services. Using received signal strength (RSS) measurements from the control channels of several base stations, the location of a mobile unit can be estimated. Although the RSS method is not as precise as other localization methods in literature such as angle of arrival, time of arrival, and assisted global positioning system, it is easy to implement on any cellular network as it does not require any changes to existing phones and network structure. Since radio propagation characteristics vary in different environments, knowing the environment of the mobile user is essential for accurate RSS based location estimation. In this study, a novel mobile positioning algorithm for cellular networks based on the estimation of the radio propagation environment is presented. The key feature of the proposed method is its capability to estimate the environment of the mobile user as urban, suburban or rural using pattern recognition and to utilize this information for enhancing RSS based distance calculations. The proposed algorithm has been evaluated using field measurements collected from a GSM network in diverse geographic locations. Our approach turns out to be significantly beneficial, enhancing estimation accuracy, and thereby enabling high-performance mobile positioning in a practical and cost effective manner. Additionally, it is computationally light-weight and can be integrated onto any received signal strength based algorithm as an enhancement add-on."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez bir saglık kurumundaki tıbbi cihazların kontrolü, planlaması, tıbbi cihaz koruyucu bakım ve kalibrasyon islemlerinin yönetimi ve takvimlendirilmesi için gelistirilmis, çevrim içi çalısan bir tıbbi cihaz yönetimi sistemidir. Sistem hastane cihaz envanter yönetimi, tıbbi cihazlardan sorumlu personelin tanımlanması, tıbbi cihaz arıza ve bakım kayıtları, koruyucu bakım ve kalibrasyon yönetimi, tıbbi cihazlar ile ilgili analizler ve grafiksel gösterimlerden olusmaktadır. Sifre korumalı, kullanıcı dostu bir ag arayüzü ile sisteme kolay, evrensel ve güvenilir erisim saglanmıstır. Sistem bir is istasyonu üzerinde çalısmakta ve bir ag sayfası üzerinden çevrimiçi olarak kontrol edilmektedir. Sistem hazırlanmasında Microsoft SQL veritabanı ve .NET platformu kullanılmıstır. Sistemin tüm kodları C# programlama dili ile yazılmıstır. Anahtar Kelimeler: Tıbbi Cihaz Yönetimi, Koruyucu Bakım","In this thesis, a medical equipment management system is developed for online access to the medical assets in a healthcare facility to control, plan, schedule and manage the medical equipment preventive maintenance and calibration processes. The system consists of hospital equipment inventory management, personnel imformation in charge of medical equipment, equipment failure and maintenance record registration, preventive maintenance and calibration management, analysis and graphical representations. A password protected, user friendly web interface is provided for easy, universal and secure access to the system. The system is built over a workstation and controlled from an online web site. Microsoft SQL database and .NET platform is used for the preparation of the system. All codes of the system were written with C# programming language. Keywords: Medical Equipment Management, Preventive Maintenance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Nitel benzetimciler, dinamik sistemlerin olası davranışlarının analizi konusunda önemli araçlardır. Nitel benzetim yönteminin bazı kuramsal sınırları mevcuttur. Bir nitel benzetimci, kimi girdiler için ya yanlış tahminler vermekte ya da bazı olası davranışları göstermemektedir. Gösterilmiştir ki, mükemmel bir nitel benzetimci yapılamaz. Çünkü bazı yanlış tahminlerin yanlış olduğu ispatlanamamaktadır. Bu tez, yanlışlığı ispatlanabilen bütün yanlış tahminleri fark edip eleyebilen bir nitel benzetimcinin yapılabilirliğini sorgulamaktadır. Olumsuz bir sonuca ulaşılmıştır. Kimi makul özellikleri taşıyan herhangi bir nitel benzetimci için bu nitel benzetimci tarafından elenemeyen yanlışlığı ispatlanabilir bir yanlış tahmine neden olan ve sistematik bir şekilde elde edilebilen bir girdi mevcuttur. Bunun yanı sıra, gösterilmiştir ki yanlışlığının ispatlanması üstel zaman gerektiren yanlış tahminler de bulunmaktadır.","Qualitative simulators are important tools for analyzing the possible behaviors of a dynamical system. The technique of qualitative simulation has some theoretical limitations. For some input system models, a qualitative simulator either predicts spurious (impossible) behaviors or does not predict some possible behaviors. It has been shown that a ?perfect? qualitative simulator cannot be built, because there are some spurious behaviors which cannot be proven to be spurious. This thesis questions the possibility of building a qualitative simulator which can detect and eliminate all spurious behaviors which can be proven to be so. We find the answer to be negative. For each qualitative simulator which possesses some reasonable properties, there is an efficiently constructible, provably inconsistent input which cannot be rejected by the simulator in question. In addition, it is shown that there exist spurious behaviors which require exponential time to detect."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz iletişim ağlarında güvenliğin sağlanması, güvenlik sistemlerinin ens g u g g uzorlu problemlerinden biridir. Kablosuz ağların tümyayın doğası, onları yerel sabitg u gağlara nazaran gizli dinleme ve aktif saldırılara karşı daha korunmasız kılmaktadır.g sAyrıca, kablosuz ağlar üzellikle enerji ve bant genişliği olanakları bakımından sınırlıdırgo sgve bu durum kablosuz ağlarda güvenliği temin etmeyi güşleştirmektedir. Bu prob-g u g uc slemler, üzellikle uye sayısının şok fazla olduğu ve uyelerin sisteme giriş-şıkışlarının sıko ü c g ü sc sgerşekleştiği dinamik karakteristikteki kablosuz ağlarda büyümektedir.c sg g uuBiz bu tezde, yukarıda belirttiğimiz problemleri hedef alarak, her biri kablosuzgağlarda değindiğimiz sorunlara etkin şüzümler sağlayan yedi yeni şalışma üneriyoruz.g g g co u g cs oBu şalışmaların ana konusunu, uydu ağlarında ve askeri tasarız mobil ağlarda güvenliğincs g g u gsağlanması oluşturmaktadır. Biz, bu şalışmalarımızda kablosuz ağ güvenlik sistemler-g s cs guine uş temel noktada yenilik getirdik: Yapısal tasarım, bütünleşik anahtar yünetimüc uu s oteknikleri ve bildiğimiz kadarıyla daha ünce güvenli uydu şoklu yayın sistemleri veg o u caskeri tasarsız mobil ağlarda kullanılmamış yenilikşi kriptograï¬k yaklaşımlar. Sistem-g s c slerimizde yer alan karma anahtar yünetim teknikleriyle birleştirilmiş yapısal tasarımo s sprensipleri ?katmanların bağımsızlığı? prensibi uzerine kuruludur. Bu prensibe güre,g g ü okatmanlarından herhangi birinde gerşekleşen değişiklik, diğer katmanlara sirayet et-c s gs gmemelidir. Karma anahtar yünetim tekniklerimiz, mantıksal anahtar ağacı temellio gmerkezi anahtar yünetim teknikleri ile dağıtık anahtar yünetim tekniklerinin etkino g obir kombinasyonundan oluşmaktadır. Güvenlik mekanizmalarımızda kullanılan krip-s utograï¬k yüntemler ünerdiğimiz güvenlik mekanizmalarına uygun olarak seşilmiştir.o o g u c sËcsIlk şalışma olarak, yeni karma anahtar yünetim tekniklerimizi ve katmanlarınoË Ëbağımsızlığı prensibini ortaya atan Iki Katmanlı Pintsov-Vanstone Imzasını(TTPVSS)g güneriyoruz. Bu yaklaşımlar, uydu uzerindeki yeniden anahtarlama yükünü ünemlio s ü uuuo2ülşude azaltmakta ve geleneksel yüntemlere nazaran ünemli avantajlar sağlamaktadır.o cü o o gAyrıca, yenilik olarak TTPVSS, avantajlar sağlayan Eliptik Eğri Pintsov-Vanstoneg gËImza Semasını (ECPVSS) kullanmaktadır. Bu şalışmayı müteakiben, yeni bir Elliptikş cs uEğri Menezes-Qu-Vanstone (ECMQV) temelli uş katmanlı uydu güvenli şoklu yayıng üc u cmekanizması üneriyoruz. Bu güvenlik mekanizması, daha yüksek bir güvenlik ve iyi biro u u uperformans sağlamak amacıyla, GEO, MEO ve LEO uydularının kendilerine üzgü nite-g ouliklerinden faydalanmaktadır. ECMQV, diğer klasik kriptograï¬k yüntemlerden farklıg oolarak, temel kriptograï¬k amaşlara ulaşmakta ve aktif saldırılara karşı da güvenliğic s s u gtemin edebilmektedir. Diğer şalışmamız olan NAMEPS, signcryption temelli ve şokgcs ckatmanlı uydu şoklu yayın güvenlik protokolü, uyduların uzerindeki yükü daha dac u u ü uuazaltmak amacıyla, şok katmanlı bir mimariyi ve üzel karma anahtar yünetimi teknik-c o olerini bir arada kullanmaktadır. NAMEPS geleneksel kriptograï¬k yüntemlere güreo oünemli avantajlar sağlayan, şoklu alıcılı signcryption şemasını kullanmaktadır. Güvenlio g c s uuydu şoklu yayın sistemleri dışında, askeri mobil tasarsız ağlarda güvenliği sağlamakc s g u g guzere, HIMUTSIS (Signcryption tipi anahtar değişim şema temelli hiyerarşik şok kat-ü gs s scmanlı adaptif tasarsız ağ güvenlik protokolü)'i üneriyoruz. HIMUTSIS, askeri iletişimgu uo sağlarındaki tek noktaya bağımlılık problemini ve eşik değeri kriptograï¬ gereksinimig g s gazaltacak yeni bir şok katmanlı yapı ünermektedir. Ayrıca, yeni bir yaklaşım olarakc o sHIMUTSIS, yüksek performans ve güvenlik sağlayan şok seviyeli bir güvenlik sis-u u g c utemi ve signcryption temelli anahtar değişim protokollerini kullanmaktadır. Bu tezgsşalışmasında ağ güvenliği mekanizmalarına ek olarak, mevcut bazı kriptosistemlerincs gu giyileştirilmesi uzerinde de şalıştık. Bu bağlamda, orijinal Merkle kriptosistemi (MC)s ü cs gve onun bir varyantı uzerinde ünemli güvenlik avantajları bulunan Geliştirilmiş Merkleü o u s sKriptosistemini (IMC) üneriyoruz. Buna ek olarak, signcryption temelli yaklaşımlarlao sIMC algoritmasını birleştiren STAKE (Signcryption tipi kimlik onaylı anahtar oluştur-s sma) protokolü uzerinde de şalışmaktayız. Sonuş olarak, bu tez şalışmasında, bizleruü cs c cskablosuz ağlarda güvenlik ve kriptograï¬ konularında geleneksel yaklaşımlara nazarang u sünemli avantajlar sağlayan temel şalışmalarımızı bütünleşik bir şekilde sunuyoruz.o g cs uu s s","Providing security in wireless communication networks is one of the most chal-lenging problems in security systems. Broadcast nature of wireless networks makethem more vulnerable to eavesdropping and active attacks when compared to terres-trial ï¬xed networks. Also, wireless networks are resource limited especially for powerand bandwidth possibilities, which makes harder to provide security in these systems.These problems become much severe for wireless networks having very large numberof members and high member join-leave characteristic.In this thesis, in order to address aforementioned problems, we propose sevennovel studies each of them provides eï¬cient solutions for these problems in wirelessnetworks. We especially focus on providing security in satellite networks and militaryMobile Ad-hoc NETworks (MANET). We bring novelties to wireless network securitysystems in three main points: Structural design, integrated key management tech-niques and novel cryptographic approaches that have not been used in Secure SatelliteMulticast Systems (SSMS) and military MANETs. Our structural design principles,integrated with hybrid key management techniques, are based on ? independency oftiers ? principle. In this principle, modiï¬cation in a tier does not aï¬ect all other tiersin the network system. Our hybrid key management techniques combine centralizedlogical key tree based key management techniques and decentralized key managementtechniques in an eï¬cient manner. We speciï¬cally utilized appropriate cryptographicmethods to our security mechanisms.We propose Two-Tier Pintsov-Vanstone Signature Scheme (TTPVSS), which in-troduces our independency of tiers principle and a novel hybrid key management tech-nique. These approaches signiï¬cantly reduce rekeying workload of satellites and providemany advantages when compared to traditional methods. Also, as a novelty, TTPVSS2uses Elliptic Curve Pintsov-Vanstone Signature Scheme (ECPVSS), which provideshigh security and advantages. Then, we propose a new three-tier satellite multicastsecurity mechanism based on Elliptic Curve Menezes-Qu-Vanstone (ECMQV). Thissecurity mechanism additionally uses special properties of GEO, MEO and LEO satel-lites for better performance and security. ECMQV, diï¬erent from classical key ex-change and digital signature schemes, achieves major cryptographic goals and securityagainst active attacks. Our another study, NAMEPS, N-tier sAtellite Multicast sEcu-rity Protocol (Mechanism) based on Signcryption schemes uses N-tiered structure andEï¬cient Large Key management protocol (ELK) based hybrid key management tech-nique, which further reduces rekeying and cryptographic workload of satellites. As anovel approach, NAMEPS uses a multi-recipient signcryption scheme, which providescomputational and storage advantages. Apart from SSMS, we propose HIMUTSIS,HIerarchical MUlti-Tier adaptive ad-hoc network security protocol based on SIgncryp-tion type key exchange Schemes for military MANETs. In HIMUTSIS, we propose anovel multi-tier structure for military MANETs, which reduces threshold cryptogra-phy requirement and single point of failure problems. Also, as a novelty, HIMUTSISuses a multi-level security system and signcryption based key exchange protocols thatprovides high security and performance together. In addition to these, we also studiedon improving some existing cryptosystems. In this sense, we propose IMC (ImprovedMerkle Cryptosystem), which has signiï¬cant security advantages over both MC (MerkleCryptosystem) and VMC (Variant of Merkle Cryptosystem). Security of IMC is com-patible with today?s modern public key cryptosystems. Apart from these, we work onSTAKE (Signcryption Type Authentic Key Establishment), which integrates signcryp-tion based approaches with our IMC algorithm. As a result, in this thesis, we presentour major studies for wireless network security and cryptography in an integratedmanner providing many advantages when compared to the traditional approaches."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZETISINMA VE AÇMA-GERME HAREKETLER N N OKS JENMETABOL ZMASI ÜZER NDEK ETK LER N N YEN LENM Ş B RiYKÖS C HAZI TARAFINDAN ÖLÇÜMLENMESSon yıllarda büyük ilerleme kaydeden egzersiz fizyolojisinin temel ilkelerinden biriidmandan önce ısınma ve açma-germe egzersizleri yapılmasıdır. Bunun nedeni kandakioksijen metabolisması ile yakından ilgilidir. Isınma hareketleri, vücut ısısını arttırıp kandakipH miktarını düşürerek, enzim reaksiyonlarını harekete geçirir ve oksi-hemoglobininparçalanmasını hızlandırır. Açma-germe hareketleri ise, sarkomeri maksimal uzunluğunagetirerek ve ekstrasellüler matriksi (ağırlıklı olarak kolajen liflerini) hareket hattıyla aynıdoğrultuya dizer.Bu yüksek lisans tezi, ısınma ve açma-germe hareketlerinin oksijen metabolizmasıüzerindeki etkisini irdelemektedir. Ölçme işleminde kullanılan aygıt, NIROXCOPE 301 adlıbir iYKÖS cihazıdır. Niroxcope 2011'in gelişmiş sürümü olan Niroxcope 301, deoksi-hemoglobin (Hb) ve oksi-hemoglobin (HbO2) parametrelerinin zamana karşı değişmini lokalolarak ve kalibrasyon aşamasında belirlenmiş bir baz değere göre ölçer. Atardamar EngeliProtokolü, gastrocnemius üzerine uygulanarak egzersize hazırlanmış bir kası, hazırlanmamışhaliyle 3 parametreye göre karşılaştırır: Maksimal [Hb] seviyesi ANOVA (değişkenlerinanalizi) ile p = 4.71 e-5, %90 indisi ise p = 0.0054 sonucunu vermiştir. Geri dönüm süresi iseçift yönlü etkenler sebebiyle istikrarsız sonuçlar üretmiştir.Anahtar kelimeler: ısınma, açma-germe (esnetme) hareketleri, oksijen metabolizması,işlevsel Yakın-Kızılötesi Spektroskopi (iYKÖS), Niroxcope, iskemi1Boğaziçi Üniversitesi Biyofotonik Laboratuvarı tarafından geliştirilmiştir.","ABSTRACTQUANTIFICATION OF THE EFFECT OF WARM UP ANDSTRETCHING ON THE OXYGEN METABOLISM USING ANIMPROVED VERSION OF A fNIRS DEVICEIn the vastly improved field of exercise physiology, it is an imperative to exercise a awarm up and stretching routine before training. The reasoning is closely associated with theoxygen (O2) metabolism in the blood. Warm up provides the necessary means to activateenzymatic reactions to accelerate oxy-hemoglobin (HbO2) break up by increasing the bodytemperature and slightly decreasing the pH of blood. Stretching, meanwhile, acts as a regimeto educate the muscle by extending the sarcomere to its full length and lining up theextracellular matrix (predominantly, the collagen fibers) in the line of action.This M.Sc. thesis is involved with the analysis of the effect of warm up and stretchingon the O2 metabolism. The device used in the quantification process is a fNIRS equipment,named NIROXCOPE 301. Niroxcope 301, an improved version of Niroxcope 2011, locallymeasures the deoxy-hemoglobin (Hb) and oxy-hemoglobin (HbO2) change with respect totime and relative to a baseline determined at the calibration stage. The Arterial OcclusionProtocol was applied by using Niroxcope 301 in an effort to compare the gastrocnemius of thesubjects ready for exercise (i.e. with warm up and stretching) with the unpreparedgastrocnemius in terms of the pre-determined three parameters of post occlusion. Hbmax data,due to its great difference compared to that of the control groups resulted in p = 4.71 e-5 inANOVA analysis. 90% index provided the most sterile data as it is normalized by a maximalvalue. It resulted in p = 0.0054. trec was a more controversial data due to its dual nature (morerecuitment vs. better recovery of a single unit) and displayed a mixed pattern..Keywords: warm up, stretching, O2 metabolism, functional Near-Infrared Spectrscopy(fNIRS), Niroxcope, ischemia1Developed in the Biophotonics Lab, Boğaziçi University, Istanbul"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Güvenilir olmayan uzak sunuculardaki XML verilerin güvenilir olmayan kanallar-u udan güvenli bir şekilde sorgulanması azımsanmayacak oranda ilgi şekmektedir. Gizliu s cXML verilerinin, bilgilerin kütü kullanımından korunabilmesi işin şifrelenmesi gerek-ou csmektedir. Veriler şifrelendikten sonra sunucuya işeriğinin aşılmadan sorgulanmasıs cg cünemli bir araştırma alanı haline gelmektedir. Brinkman ve arkadaşları şifrelenmişo s s s süXML verileri zerinde basit yol sorguları işin bir yol ünermiştir. Onerileri yapısal sorgu-c o slar işin kullanılamamaktadır ve XML verisinin doğasındaki tekrar oranı dolayısıylac gşekincelere neden olmaktadır.cBu tezde XML dükümanları işin PRIX sistemini kullanan yeni bir güvenilir dışou c u skaynakta veri saklanması ve sorgulanması metodu üneriyoruz. Sınır sorgularının şifrelio sXML verisi uzerinde cevaplanabilmesi iin OPES kullanan yeni bir algoritma üneriyoruz.ü oü üOnerdiğimiz modeli PRIX kodlamasını baz alarak kodladık. Onerdiğimiz modeli dahag günceki bu alanda yapılan şalışmalar ile karşılaştırdık. Deneyler yol sorgularında büyüko cs ss uubir gelişme olduğunu güsterdi. Yine deneylerde yapısal sorgularda şok iyi zamanlamalars g o celde ettik. XML verilerinin şifrelenmesi işin gereken toplam süre ünemli oranda azaldı.s c uo","There has been a considerable interest for securely querying XML data storedon a remote untrusted database server over insecure channels. In order to protectconï¬dential XML data from malicious uses, XML data should be encrypted. OnceXML data has been encrypted, querying it without revealing its content to untrustedserver becomes a major research of area. Brinkman et al. introduced a way to searchfor simple path queries over encrypted XML data. Their proposal does not scale wellfor structural queries and has some drawbacks due to redundancy in XML format.In this thesis, we propose a new secure outsourcing scheme for XML documentswhich uses Prufer Indexes for Indexing XML (PRIX) system. OPES is an encryptiontechnique, which preserves natural order of data. We propose an algorithm to an-swer range queries over encrypted XML data using OPES. We have implemented ourscheme using PRIX as a basis. We compare our scheme with previous works in SecureData Outsourcing of XML documents. Experiments show a major improvement inpath queries, and very good query processing times for structural queries. Total timerequired to encrypt documents is also substantially reduced."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz Ustüne Bindirmeli Ağlar, mobil düğumlerin işinde yatay veyag ugü cdikey eldeğiştirmeler yaparak serbestşe dolaşabildiği şok katmanlı ağlardır.gs c s gc gBu sayede, mobil kullanıcının konumuna ve sahip olduğu yerel kablosuzgbağlantıya güre mümkün olan en iyi bağlanabilirlik sağlanmış olur. Sağladığıg o uu g g s g gyararların yanısıra, bu tipteki ağlar şeşitli problemleri de beraberinde ge-g cstirir. Bu problemler hem aynı kablosuz ağın hücreleri arasında gerşekleşeng u c syatay eldeğiştirmeler, hem de farklı katmanlardaki ağlar arasında gerşekleşengs g c sdikey eldeğiştirmeler yüzünden kaynaklanmaktadır. Bu yüzden, bir kablosuzgs uu uustüne bindirmeli ağ işin tüm bu problemlerin ustesinden gelebilecek etkiliüu gc u übir Hareket Yünetim Sistemi gerekmektedir.oBu tez şalışması, şu ana kadar kablosuz ustüne bindirmeli ağlar işincs s üu g cünerilen yatay ve dikey eldeğiştirme sistemlerini incelemekte ve bu sistemlerino gseksiklerini ortaya şıkarmaktadır. Daha sonra, incelenen sistemlerin eksiklikcve sakıncaları güz ününe alınarak kablosuz ustüne bindirmeli ağ yapısı işino ou üu g cyeni bir Hareket Yünetim Sistemi ünerilmektedir. Mobil kullanıcıların kablo-o osuz ustüne bindirmeli ağlar arasında serbestşe dolaşabilmesini sağlayan buüu g c s gyeni sistem hem yatay hem de dikey eldeğiştirme süreşlerini optimize et-gs ucmektedir. Yapılan simülasyon ve analitik şalışmalar ünerilen bu yeni hareketu cs oyünetim sisteminin enerji tüketimini, eldeğiştirme gecikmesini ve eldeğiştirmeo u gs gssırasında yapılan mesajlaşmayı azalttığını, gereksiz eldeğiştirmeleri ünlediğinis g gs o gve ağda dolaşan veri hacmini makul bir seviyede tuttuğunu güstermektedir.g s g oAyrıca, tüm bunları yaparken son kullanıcıların mobil cihazlarında ekstrauayarlar yapması da gerekmemekte ve eldeğiştirmeler son kullanıcının kesin-gstisiz iletişimini etkilememektedir.s1","Wireless Overlay Networks (WONs) are multi-layer networks in whichmobile nodes (MNs) move freely within cells of the same overlay or betweencells of diï¬erent overlays. Such a structure provides global access to MNsregardless of time and location. In spite of their advantages, WONs posemany challenges due to the simultaneous existence of horizontal handoversbetween cells of the same wireless network and vertical handovers betweendiï¬erent overlay networks. Thus, an eï¬cient mobility management systemneeds to be built for the WON architecture.This thesis includes a survey of present handover schemes proposed forWONs and points out their drawbacks. Then, by considering the drawbacksand incompleteness of the current schemes in literature, this thesis proposesa new mobility management scheme for WONs. The proposed scheme opti-mizes both horizontal and vertical handover processes. The simulation andanalytic work results show that the proposed system reduces power drain,handover latency and overhead due to extra messaging during handovers.Meanwhile, it eliminates the number of unnecessary handovers and keepsthroughput at a reasonable level. While dealing with all this, end users areisolated from making additional conï¬gurations on their mobile devices andhandovers are performed seamlessly.1"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vÖZETKUANTUM Ç FT YÖNLÜ SONLU DURUM MAK NELER N ND ZAYN VE S MULASYONUBu tezde, klasik sonlu durum makineleri (tek ve çift yönlü) ve kuantum çift yönlüsonlu durum makineleri ve bunlarla ilgili temel kuram ve ispatlar gözden geçirilmi tir.Ayrıca, kuantum çift yönlü sonlu durum makineleri için bir simülatörgeli tirilmi tir. Geli tirilen simülatör kullanılarak, {0n1n | n > 0} (tip 2) ve {0n1n2n | n > 0}(tip 1) gibi düzenli olmayan olan çe itli diller incelenmi tir.Bunların yanı sıra, kuantum sonlu durum makineleri için dil tanıma olasılı ınıarttıracak bir metot üzerinde çalı ılmı tır. Bu metot sayesinde, orijinal halde bir dilisınırlandırılmı hata ile tanıyamayan makineler, tanıyabilecek hale getirilebilmektedir. Bumetodu uygulayarak, literatürdeki bilinen bir makine üzerinde iyile tirmeler yapılmı tır.Ayrıca, çe itli di er makineler için de metodun uygulanması ve sonuçları incelenmi tir.","ivABSTRACTDESIGN AND SIMULATIONOFTWO-WAY QUANTUM FINITE AUTOMATAIn this thesis, we review classical finite state automata, (FSAs and TWAs) and 2-way quantum finite state automata (2QFAs). We examine fundamental theorems and theirproofs.We develop a software simulator of quantum finite state automata. We introducethe simulator and by the help of the simulator, we examine some non-regular languageslike {0n1n | n > 0} (type 2) and {0n1n2n | n > 0} (type 1).We also propose a new technique to enhance the language recognition probabilityof 2QFAs. This method may allow some languages to be recognized with bounded error, ifwe have an algorithm for the unbounded error version. A sample construction for such acase is inspected in detail. Using this technique, we enhance the complexity of a 2QFAwhich originally recognize string s with error probability of 1/2, beyond a well known2QFA in the literature for the same language."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Cok boyutlu OLAP küplerini verimli olarak saklayabilmek amacıyla, seyrek veş uyoğun yapıların getirilerinden faydalanan karma yüntemler geliştirilmiştir. Konu ileg o s silgili onceki şalışmalarda, ana kaygı seyrek ve yoğun kesimlerin ayrıştırılması olmuştur.ü cs g s sHer ne kadar ünceden ünerilen karma yüntemler verimli olsalar da, etkili bir ï¬zik-o o osel saklama yüntemi geliştirilerek daha fazla ilerleme sağlanabilir. Bu şalısmada, coko s g cboyutlu OLAP küplerini saklayabilmek işin, uzaklık - değer şiftlerini, şok boyutluu c gc cdizileri ve seyrek - yoğun ayrık saklama yüntemlerini, chunk seviyesinde tek bir ï¬zikselg oyapıda bir araya getiren, ï¬ziksel saklama yüntemi ünerilmiş ve veri erişim yüntemlerio o s s otanımlanmıştır. Karma yapımızda, aralık sorgularında disk sayfası erişimini azalt-s smak amacıyla, bir chunkın işindeki seyrek ve yoğun kesimler birbirlerine yakın kon-c gumlarda saklanmaktadır. Ayrıca, sıkıştırma oranını arttırmak işin, boyut değerleris c gsıralamasından bağımsız, yoğun alt-küp belirleme yüntemi geliştirilmiştir. Yüntemi-g g u o s s omizin verimliliğini güstermek amacıyla, deneyler yapılmış ve yakın bir şalışma ileg o s cskarşılaştırılmıştır.ss s","In previous studies about the subject, hybrid methods were developed to beneï¬tfrom the advantages of both sparse and dense structures for eï¬cient storage of multi-dimensional OLAP data. In these previous studies, main concern was to developeï¬cient sparse - dense region splitting algorithms. Although, previously proposedhybrid methods are eï¬cient, further improvement can be achieved by developing aneï¬ective physical storage method. In this study, we deï¬ned a chunk based physicalstorage structure to store multi-dimensional OLAP cubes that consolidates oï¬set-valuepairs, multi-dimensional array and sparse-dense split storage methods into a physicalstructure at chunk level and deï¬ned data access methods for this structure. At ourhybrid storage, sparse and dense regions of a chunk are stored at spatially close locationson the disk to lower the number of page accessed in range queries. Also, we developedan attribute value order independent dense sub-cube determination heuristic to increasecompression ratio. To illustrate the eï¬ciency of our method, we conducted experimentsand compared our results with a recent study."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çalışması taşınabilir elektrokardiyografi (EKG) aygıtlarıylaberaber kullanılacak dağıtık bir acil tanı sistemi için gerekliyazılımın tasarlanması ve geliştirilmesini içermektedir. Geliştirilen yazılım alınan sinyallerin işlenmesi için bir yardımcı DSPkütüphanesi, verilerin toplanması için bir merkezi veritabanı ve EKGkayıtlarının uzmanlar tarafından değerlendirilebilmesi için bir görüntülemearayüzünden oluşmaktadır. Sisteminbaşlıca amacı uzman hekimler (kardiyologlar) ile hastalar arasındakiuzaklığın en aza indirgenmesi ve bu sayede öncelikle akut miyokardinfarktüsü (AMİ) tanı süresinin olabildiğince kısaltılmasıdır. Böylecesemptomların başlangıcından tedaviye kadar geçen sürenin kısaltılmasıhedeflenmektedir. Bununla beraber, sistem başka kardiyolojik hastalıklarıntanısında da kullanılabileceği gibi, kalp hastalarının rutin gözetimiamacıyla da kullanılabilir.","This thesis aims for the design and implementation of a software systemfor distributed emergency diagnosis to be used inconjunction with ambulatory electrocardiography (ECG/EKG) devices.The software consists of a Digital Signal Processor (DSP) helper library for processing andconditioning the ECG signals, a database for central data storage,and an expert user interface for ECG data evaluation.The system primarily aims to reduce the gap between patients and experts(cardiologists) and allows for the rapid diagnosis of acutemyocardial infarction (AMI), commonly known as heart attack.This will consequently decrease the time span between the onset of symptomsand treatment. However, this system can also be used for the diagnosis ofother forms of cardiovascular diseases, as well as a means ofroutine monitoring of cardiac patients."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez, ucret tabanlı pazarlık yaklaşımlarına alternatif olarak, servis işeriği uzerineü s c güËcyapılan pazarlığın otomatikleştirilmesini temel alan bir yaklaşımı ünermektedir. Işerikg s s otabanlı pazarlıkta, ucretten ziyade servisin tanımı uzerine pazarlık yapılmaktadır. Tüke-ü ü uticinin ve ureticinin her ikisi de ilgilendikleri servis hakkındaki bir ontolojiyi paylaşmak-ü stadır. Paylaşılan ontoloji, anlamsal bilgilerinin güsterimini sağladığı gibi, belirlenmişs o g g sbir servisin ozelliklerini kapsar ve bunlar arasındaki ilişkileri muhafaza eder.ü sTekrarlayan etkileşimler sonunda, uretici tü keticinin ihtiyaşlarını doğru olaraks ü u c gügrenir ve tü keticinin daha şok beğeneceği tekliï¬er uretir. Tü keticinin tercihlerinioğ u c g g ü uoğügrenmek işin Versiyon Uzayı'nın genişletilmesi, karar ağaşlarının artımlı olarak kul-c s gclanımı ve ügrenmenin ceşitli anlamsal benzerlik ülşutleriyle birleştirilmesi gibi cesitlioğ şs o cü s şyaklaşımlar calışılmıştır. Bu tezin temel katkıları, ayıran kavramları ogrenebilme ka-s şs s üğbiliyeti ile Versiyon Uzayı'nın genişlemesi ve taksonomileri kullanan yeni bir anlamsalsbenzerlik olşutü dü r.ü cü u uPazarlık işin ünerilen yapı, artımlı ogrenme tekniklerinden ve ontolojilerin anlamlıco üğgüsterimlerinden onemli ï¬kirleri birleştirmektedir. Otomatikleşmiş pazarlık yapısınıno ü s ssteorisinine ek olarak, gerşekleştirilen sistemin detayları da verilmektedir. Ceşitli ügren-c s ş s oğme algoritmaları ve benzerlik olşutleri test edilmektedir. Test sonuşları servisler arasın-ü cü cdaki anlamsal yakınlığı güze almanın yapıcı bir etkisi olduğunu güstermektedir.go g o","This thesis proposes an approach for automating the content negotiation of ser-vices as an alternative to price-oriented negotiation approaches. In content-orientednegotiation, the description of services rather than their price are negotiated. Bothconsumers and producers share an ontology about the service of interest. The sharedontology contains the features for a given service and captures the relations betweenthem as well as providing the representation of semantics.Through repetitive interactions, the provider learns consumers? needs accuratelyand can make better targeted counter oï¬ers. In order to learn the consumer preferences,several approaches are explored such as the extension of Version Space, the use ofdecision trees in an incremental way and the combination of learning with a varietyof semantic similarity metrics. The main contributions of this thesis are the extensionof Version Space with the capability of learning the disjunctive concepts and a newsemantic similarity metric using the taxonomies.The proposed architecture for the negotiation combines important ideas fromincremental learning techniques with the expressive representation of ontologies. Inaddition to the theory of the automated negotiation architecture, the details of theimplemented system are given. A variety of learning algorithms and similarity metricsare tested. The test results show the constructive eï¬ect of considering the semanticcloseness among services."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Düşuk-Yer Yürüngesi (LEO) uydu sistemleri, evrensel gezgin ağların gelişimindeusü ou g svar olan karasal sabit ve telsiz ağların tamamlayıcısı olarak düşunülmektedirler şunküg usü u cü uDüşuk-Yer Yürüngesi uydu sistemleri Yer ile Eş zamanlı Yürünge (GEO) uydu sis-usü ou s outemlerine kıyasla düşuk yayılım gecikmesi, düşuk güş gereksinimleri gibi ünemli getis-usü usü uc orilere sahiptirler. Ancak, Düşuk-Yer Yürüngesi uyduları ile ilgili başlıca sorunlardanusü ou sbiri bu uyduların düşuk hızla fakat daha rasgele yünlere haraket eden karasal gezginusü oterminallere nispeten daha yüksek hızda hareket etmeleridir. Düşuk-Yer Yürüngesiu usü ouuydularının hızlı harekete etme üzellikleri gezgin kullanıcıların sıklıkla komşu uydularo sarasında eldeğiştirmesine sebep olmaktadır. Bundan dolayı, evrensel mobil iletişimigs sgeliştirme amacı ile yola şıkıldığında, Düşuk-Yer Yürüngesi uydu sistemlerinde mey-s c g usü oudana gelen uydular arası eldeğiştirmelerin yünetimini sağlayabilmek oldukşa uğraştırıcıgs o g c gsbir iş haline gelmiştir. Düşuk-Yer Yürüngesi uydularının yayınlarının etkili olduğus s usü ou gyeryüzü alanları arasında gerşekleşen eldeğiştirmelerin idaresi işin etkili ve eksiksizuu c s gs cmetodlar gerekmektedir. Bu konudaki temel endişe son kullanıcılara eldeğiştirmelerins gssebep olabileceği kesintilere karşı güvenilir bir servis sağlayabilmektir.g su gGünümüzde Düşuk-Yer Yürüngesi uyduları arasında gerşekleşen eldeğiştirmeleruu u usü ou c s gsesnasında karşılaşılan problemlerle başa şıkabilmek işin şeşitli şalışmalar mevcuttur.ss sc c cs csBu konuda yapılan şalışmalar, yeni hareket yünetim sistemlerinin tasarlanmasına vecs oeldeğiştirme sürecindeki karar verme aşamasının eldeğiştirmeleri hızlı ve doğru birgs u s gs gşekilde tetikleyecek yünde geliştirmeye odaklanmıştır.s o s s Bu tez şalışması yakın za-csmanda Düşuk-Yer Yürüngesi uyduları işin ünerilen eldeğiştirme yünetimi modellerininusü ou co gs obir araştırması niteliğini taşır. Bunlarla beraber, bu tez şalışması kapsamında incele-s g s csnen sistemlerin eksiklik ve sakıncaları güzününe alınarak, Düşuk-Yer Yürüngesi uyduoou usü ouiletişim ağları işin uydular arası iletişimin verimliliğini ve uydu konum değişim modelinis g c s g gskullanan iki yeni Eldeğiştirme Yünetim Sistemi ünerilmektedir.gs o o","Since Low Earth Orbit satellite constellations have important advantages overGeosynchronous Earth Orbit satellite systems such as low propagation delay, low powerrequirements, they are considered to be used to complement the existing terrestrialï¬xed and wireless networks in the evolving global mobile network. However, one ofthe major problems with LEO satellites is their higher speed relative to the terrestrialmobile terminals, which move at lower speeds but at more random directions. Thishigh mobility characteristic of LEO satellites causes mobile users to hand over betweenfootprints of adjacent satellites very frequently. Therefore, handover management inLEO satellite networks becomes a very challenging task for supporting global mobilecommunication. Eï¬cient and accurate methods are needed for LEO satellite handoversbetween the moving footprints. The main concern of researches done in this area isproviding a reliable service to the user that prevents a communication from beingdropped due to a handover.Currently, there are many studies dealing with the problems of handover man-agement in LEO satellite communication networks. Related work in this area focuseson the development of new mobility management architectures as well as improvingthe handover decision mechanisms to quickly and accurately trigger handovers. Thisthesis includes a survey of recent handover management protocols for LEO satellites.By taking into consideration the inconvenience and incompleteness of the current pro-posals in literature, this thesis proposes two new mobility management schemes forLEO satellite communication networks which use the eï¬ciency of inter-satellite linksbetween satellites and satellites? mobility pattern."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gömülü sistemlerin Alan Programlamalı Kapı Dizileri (APKD) içinde tasarlanmasıarttıkça, bu ortamlar için özel olarak tasarlanmış mikroişlemci ihtiyacı da artmaktadır.Mevcut seçeneklerden esnek olanı, ?yumuşak? Entelektüel Mülk mikroişlemci çekirdeği,yani mikroişlemcinin APKD'nin yeniden programlanılabilir mantık kapıları içerisindegerçekleştirilmiş olanıdır. Günümüzde ticari ve akademik yumuşak işlemciler yaygınolarak kullanılsa da, bunların çoğu eski ve halihazırdaki komut kümelerininsentezlenmesiyle oluşmuş, pahalı ve büyük APKD'lere sığan uygulamalardır. Yüksekbaşarımlı görüntü ve ortam işleme uygulamalarının gömülü sistemler piyasasına hakimolması ve günümüz işlemcilerinin TKÇV (tek-komut, çoğul-veri yolu) özelliğinibenimsemesi ile birlikte, yumuşak mikroişlemci çekirdekleri de dizi ve yöney işlemekabiliyetinden yararlanabilmelidirler.Bu tez, komut düzeyi paralelliği ile yapılandırılabilir yumuşak mikroişlemciçekirdeklerinin esneklik ve uyarlanabilirliğinden yararlanarak tasarlanmış SIxD'i sunuyor.Değişken veri alanı, özelleştirilebilir komut kümesi ve veri dizileri işleme kabiliyetiyleSIxD kırk bin dizilik APKD'lere sığabilen, veya veri dizileri işleme seçeneğiyle dahabüyük APKD'lerde daha yüksek performans gösterebilen yeni bir yumuşak çekirdekliişlemcidir.","The demand for FPGA-based processor cores increases as more embedded systemsare built on FPGA platforms. The flexible choice is the ?soft? processor IP core, aprocessor implemented in the reconfigurable logic of the FPGA. Commercial andacademic soft processors have been widely deployed, but most are synthesizedimplementations of legacy instruction sets that fill up large and costly FPGAs. With highperformance media processing applications dominating the embedded scene, and manymodern microprocessors adopting the SIMD technology, it is a fact that soft cores couldalso make use of array and vector processing functionality.This thesis presents the SIxD, a configurable CPU soft core designed to combinecomputer architecture basics to exploit instruction level parallelism with the flexibility andcustomizability advantages of soft cores realized on reconfigurable fabric. With run-timeconfiguration options such as variable data space, customizable instruction set, and arrayprocessing capabilities, the SIxD is a novel soft core that can be configured to fit in as lowas a forty thousand system gate FPGA, or offer higher performance array processing onbigger FPGAs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde web servislerinin araştırılması UDDI gibi merkezi kayıt merkezleriüzerinden sorgulama yolu ile yapılmaktadır. Fakat merkezi mimariler, ölçeklenebilirlik vetek nokta arıza konularında sorunlara sebep olmaktadır. Buna karşın, Napster ve Gnutellagibi eşler arası iletişim kuralları bilgi paylaşımı konusunda ölçeklenebilir ve sağlam bir altyapı sunmaktadır.Bu tezde, merkezi ve eş arası prokollerin avantajlarını beraber kullanabilmek içinsüper eş ağ protokolü önerilmektedir. Bunun yanında Web servisi arama istekleri ile ağdabüyük bir yük yaratmaktan kaçınmak ve ağ içinde dolaşmakta olan mesajların sayısını enaza indirmek için, super eşler arasında içeriği adreslenebilir ağ iletişim kuralı kullanılmasıönerilmektedir. çeriği adreslenebilir ağ prokolü ölçeklenebilir, hataya dayanıklı dağıtıkanahtarlı tablo yapısından oluşmaktadır. Önerilen mimari Sun Microsystems firmasıtarafından geliştirilmiş JXTA Çatısı üzerine yapılandırılmıştır.Önerilen mimaride, web servislerinin tanımlamaları anlamsal ontolojiler kullanılarakyapılmaktadır. Ontoloji tanımlamalarında anlamsal tanımlamalarda bir standart halinegelen OWL dili kullanılmıştır. Süper eşlerin dışında kalan kayıt merkezi eşleri webservislerine ait anlamsal tanımlamaların saklanacağı bir veritabanı görevi yaparken, süpereşler bu tanımlamaların dizinlerinin tutulduğu merkezi yapılar olarak görev almaktadır.Önerilen mimari, eş guruplarının web servislerinin sınıflandırdığı ve her grubun birsınıflandırmanın yönetimini aldığı kendi kendine kümelenebilen bir ağ yapısı sunmaktadır.","Web Service discovery is currently performed with centralized registries such asUDDI. But centralized architectures suffer from single-point of failure and scalability. Onthe other hand, peer-to-Peer (P2P) protocols like Napster, Gnutella can be used toimplement scalable and robust services for sharing information.In this thesis, we propose a super-peer network protocol to combine the efficiency ofa centralized protocols and P2P networks. For avoiding flooding the network with searchrequest and for minimizing the number of messages routed in the network, we representedContent-Addressable Network (CAN) structure, which provides a scalable, fault-tolerantdistributed hash table (DHT), for super-peers communication. We implemented ourproposed system over JXTA Framework.Web service definitions implemented semantically as OWL Ontology. The pure-peers are the registries for semantic web service definitions and super-peers stores indicesof these definitions. The proposed architecture offers self-maintaining and self-clusteringnetwork where the peer groups classify the web service definitions and each peer-groupbecomes the owner of a classification dynamically."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Statik optimizasyan problemlerinde optimizasyon süresince optimize edilen problemdeherhangi bir değişiklik olmadığı varsayılır. Bununla birlikte gerçek hayattaki birçokoptimizasyon problemi dinamiktir ve zaman içerisinde amaç fonksiyonu, karar değişkenleri yada ortamsal parametrelerinde değişikliklere maruz kalır. Dinamik optimizasyonproblemlerinde amaç statik bir optimal çözüm bulabilmekten ziyade, çözüm kümesi içerisindesürekli bir şekilde yer değiştiren optimal değeri olabildiğince iyi takib edebilmektir.Bu tezde önde gelen evrimsel dinamik optimizasyon tekniklerinin tam ve kapsamlı birkarşılaştırmasını sunuyoruz. 13 evrimsel optimizasyon algoritmasını ortak bir platform olanmoving peaks problemi üzerinde önemli problem parametrelerini değiştirerek inceleyipkarşılaştırdık. Bu algoritmalardan iki tanesi bu tez kapsamında geliştirilmiş, karmatekniklerdir. Yapılan karşılaştırma sonucunda, karma tekniklerin literatürdeki tekniklerdendaha iyi sonuç verdiği gözlenmiştir. Bununla birlikte bu çalışmada sinyal benzerliğini temelalan yeni bir performans ölçütü geliştirilmiş ve algoritmaların karşılaştırılmasındakullanılmıştır.Yapılan karşılaştırma çalısması moving peaks gibi sanal bir problemin yanı sırascheduling gibi gerçek bir problemide içermektedir. Dinamik scheduling problemini çözmeküzere dizayn edilmiş 5 evrimsel algoritmayıda inceledik. Algoritmalar stokastik ve deterministscheduling ortamlarında karşılastırıldı. Sonuçlar her ortamda iyi çalısan tek bir algorimanınolmadığını göstermektedir.","In stationary optimization problems, it is assumed that no changes occur with respect tothe problem solved during the course of computation. However many real-world optimizationproblems are non-stationary (dynamic) and subject to changes over time with respect to theobjective function, the decision variables or the environmental parameters. For dynamicoptimization problems the goal of an optimization algorithm is no longer to find a stationarysolution, but to continuously track the changing or moving optimum in the problem space.In this thesis, we present a complete and an extensive performance evaluation of leadingevolutionary optimization techniques in dynamic environments. We have examined andimplemented a set of 13 evolutionary optimization techniques on a common platform by usingthe moving peaks benchmark and by varying important problem parameters. Two newalgorithms which are the hybridization of the leading techniques in the literature have beenproposed in this thesis. Based on the experimental study, it was observed that the hybridmethods outperform the related work with respect to quality of solutions for variousparameters of the given benchmark problems. Additionally, a new comparison metric which isbased on signal similarity is proposed and used for performance evaluation of algorithms.The comparison study is based on both artificial problems including moving peaksproblems and some of the real-world problems such as scheduling. We have also implementedfive evolutionary algorithms which have been designed to solve dynamic job shop schedulingproblem. The algorithms are compared in both deterministic and stochastic schedulingenvironments. The results have shown that there is no algorithm that is best for allenvironmental conditions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dünya çapında ağ (World Wide Web) tüm gücünü anlamsal bilgi eklentileri yapıldığızaman ve otomatik işlemler gerçekleştirilebildiği zaman kazanacaktır. Bu amaçla webservislerinin kullanımı son yıllarda elektronik ticaret alanında oldukça önem kazanmıştır.Artan sayıdaki web servisleri, bu servisler arasında aranılan ve doğru web servisininbulunması problemini de beraberinde getirmektedir. Bu anlamda etkin bir web servis keşfi,anlamsal bilginin servislere eklenmesi ile mümkündür. Anlamsal web, web servislerininotomatik olarak keşfini, çağırılmasını, birleştirilmesini ve ilişkilendirilmesini sağlamaktadır.Anlamsal webin ilk adımını bu servislerin etkin bir şekilde keşfi oluşturmaktadır.Web servislerinin keşfi ve seçimi için sunulan yaklaşımların çoğu katı özelliklere sahipolması, anlamsal ve ontolojik yapının tüm gücünün kullanılmamasından dolayı kısıtlıimkanlara sahiptir. Bu tez çalışması, ilgili anlamlarda anlamsal web servisleri keşfi için genelbir çerçeve sunmaktadır. Kullanıcılar ve yazılım ajanları arama kriterlerini ve isteklerini XMLdokümanları olarak, belirlenen formatta genişletilebilir ve değiştirilebilir şekildetanımlayabilmelidirler. Sunulan mimarinin en temel bileşenlerinden biri olan, MS-serviseşleştirici olarak adlandırdığımız eşleştirici ajan, servis arama sorgusunu işler vedeğerlendirir. Servis eşleme etkin bir eşleme algoritması kullanılarak yapılmıştır. Eşleştiriciajan, servis talebinde bulunan insan, yazılımsal ajan veya yazılım bileşeni olabilen servisisteyicisine arama kriterleri ile en uygun şekilde eşleşen servisleri dereceli ve sıralı bir şekildedöner. Ontolojik kavramların anlamsal yakınlığının ve kullanıcının önceliklerinin servisisteyicisi tarafından tanımlanması ve bunun servis eşlenmesi sırasında kullanılmasıçalışmamızı diğer ilgili çalışmalardan ayıran temel özelliktir.","World wide web will gain its full power when semantic meta-data descriptions areadded and automatic processing of the web is realized. Web services gained importance in thee-commerce era in recent years. As the number of web services increase, discovering correctweb services for user needs becomes a problem. An effective discovery is only possible whenthere is semantic information. Semantic web enables automatic discovery, invocation,composition and mediation of web services by users, agents and programs. The first step insemantic web is the effective discovery of web services.Most of the current solutions and approaches on web service discovery and selection arelimited in the sense that they are strictly defined, and they do not use the full power ofsemantic and ontological representation. This research proposes a general ?semantic webservice discovery framework? in which: Users or software agents should able to set theselection criteria as XML documents, defined in preliminary format, in an extensible andmodifiable manner. A Matchmaking Agent (MS-Matchmaker), which is the main componentof the framework, processes the service discovery query. The matchmaking is done via anefficient matching algorithm. The matchmaker will return a rated and ordered set of suitableweb services to the service requestor who may be a human-user, software agent, componentor other. Semantic distance of ontology concepts are the main criteria of rating the webservices in parallel with user definitions, which is different from other approaches."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım oluşturma süreci yeni araçların ve tekniklerin yardımıyla gitgide daha insandanbağımsız bir hale gelmektedir. Bu alandaki araştırmaların önemli bir kısmı yazılım hatalarınınazaltılması, hataların tespiti ve tahmini üzerine odaklanmıştır. Yapay zeka tekniklerine ve verimadenciliğine dayalı hata tahmini bu alanda göreceli olarak yeni bir araştırma konususayılabilir. Bugün itibariyle, yazılım mühendisliği yazınında halen bir yazılım ürününün yeniversiyonlarına yönelik bir hata tahmin çözümü bütünüyle yer almamaktadır.Bu araştırmanın amacı, bir yazılımın yeni sürümlerindeki hata oranını eski sürümlerinegöre olan değişikliklerini baz alarak tahmin eden bir model ortaya koymaktır. Bu değişiklikleryazılımdaki bir yenilik, bir algoritma değişikliği ve hatta bir hata ayıklama değişikliği olabilir.Bu tür değişikliklerin türünü formal ve nesnel bir bakış açısıyla analiz ederek, ve bunayazılımın hacimsel değişikliğini de katarak, yeni versiyondaki hata oranını doğru bir şekildetahmin edebilmeyi amaçlıyoruz.Bu araştırmada önerilen modeli kullanarak, yazılım hayat döngüsündeki test sürecinikısaltabilmek ve harcanan eforu azaltabilmek mümkündür. Buna ek olarak, yeni bir yazılımsürümünün sağlamlığını saptamak bu model sayesinde olasıdır. Bu model, aynı zamanda biryazılım ürününe katılan yeniliklerin, hata ayıklama değişiklikleri gibi değişiklik türlerininhata oluşturma ihtimallerine olan katkısını ayrı ayrı anlamaya yardımcı olmaktadır.","Software lifecycle is becoming more human-independent with the help of newmethodologies and tools. Many of the research in this field focus on defect reduction, defectidentification and defect prediction. Defect prediction is a relatively new research area usingvarious methods from artificial intelligence to data mining. Currently, software engineeringliterature still does not have a complete defect prediction solution for new versions of asoftware product.In this research our aim is to propose a model for predicting the number of defects in anew version of a software product relative to the previous version by considering the changes.These changes might be introduced as a new feature or a change of algorithm or even as aform of a bug fix. Analyzing the types of changes in an objective and formal manner andconsidering the lines of code change, we aim to predict the new defects introduced into thenew version.Using such a proposed model will benefit to a more focused testing phase which willdecrease the overall effort and cost. Also, this method can help to determine the stability of asoftware version before publishing the product. The method also helps us to understand theindividual effect of a feature, bug fix or change in terms of probability of a new defectintroduction."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma karmaşık ağların incelenmesine yönelik bir çalışmadır. Temel olarak, birağdaki alttoplulukları yazılım ajanları kulanılarak bulmayı sağlayan yeni bir algoritmatanıtılacak, ilgili altyapı detaylı olarak verilecek ve çeşitli ağlar için algoritma performansıgözlenecektir.Öncelikle, karmaşık ağlarda temel kavramlar tanıtılacak ve yazılım ajanlarınınkullanımına ilişkin bilgiler verilecektir. Daha sonra, karmaşık ağlarda alttopluluk yapısınıortaya çıkaran mevcut algoritmalar tanıtılacaktır. Bir karmaşık ağda, kendi elemanlarıaralarında yoğun olarak bağlı olan, ancak diğer elemanlarla seyrek olarak bağlı olan altgruplar, alttopluluk olarak tanımlanır. Bugüne kadar, alttopluluk yapısını ortaya çıkarmakiçin çok çeşitli algoritmalar sunulmuştur, ancak bu algoritmaların da bir takım eksikliklerivardır. Örnek olarak, bu algoritmaların bir çoğu, doğru şekilde çalışabilmek için ağhakkında bazı ön bilgilere ihtiyaç duyar ki, bu gerçek hayatta çok uygulanabilir bir yoldeğildir. Ayrıca, zaman karmaşıklığı yüksek olan bazı algoritmalar ise sadece küçük ağlarauygulanabilmektedir. Geliştirdiğimiz algoritma, karmaşık ağlarda alttopluluk bulmak içinyeni bir yöntem önermekte ve bu sorunlara çözüm getirmektedir.Algoritmamız, ağ hakkında bilgi edinmek için yazılım ajanlarını, altopluluklara kararvermek içinse ağ modülerliğini (network modularity) temel almaktadır. Algoritmayı testederken, sonuçların doğruluğunu görebilmek için Zachary'nin Karate Kulübü ağı gibialttopluluk yapısı bilenen ağlarla, karmaşıklığını ve ölçeklenebilirliğini test etmek içinseReuters ağı gibi büyük ağlarla çalışıldı. Ayrıca, kendi oluşturduğumuz ve internetsitelerinin ziyaret edilme bilgilerinden oluşan internet ağı için de algoritmamızı test edildi.Bunun yaninda algoritma performansı, bilgisayar tarafından üretilen yapay ağlar için detest edildi. Sonuç olarak, algoritmanın kabul edilebilir zamanda, optimuma yakınalttoplulukları ortaya çıkardığını söyleyebiliriz.","The main purpose of this work is analyzing the complex networks. Mainly, a newcommunity detection algorithm based on using software agents will be introduced. Thetechnical background will be given in details and the performance of the algorithm fordifferent networks will be examined.First, the main concepts in complex networks and the information about usage of thesoftware agents will be introduced. Then, the current methods finding the communities incomplex networks will be presented. The community is defined to be the group of nodeswhich are densely connected within the group but rarely connected to the outside. Therehave been many algorithm proposed so far to detect the communities in complex networks.However, most of them have some weaknesses. For instance, some algorithms need someprior information about the network to find the communities such as number ofcommunities. There are also some algorithms with higher complexity values. Yet, thesealgorithms are not feasible or applicable to the real world complex networks. Ouralgorithm proposes a new algorithm to detect the communities in complex networks andaddresses these issues.An algorithm is developed that utilizes software agents for gathering informationabout the network and uses network modularity to decide on the community amongcandidates. To test the accuracy of the algorithm, the networks with known communitystructure like Zachary Karate Club network are used. The large networks such as web sitesnetwork that we created by observing a proxy server are also used to test the complexityand scalability of the algorithm. Besides, the performance with a computer generatednetwork is also presented. Finally, it can be said that the algorithm is able to reveal thenearly optimum communities with acceptable complexity."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hisse senedi getirilerinin tahmin edilmesi finans dünyasında özellikler Türkiye veBrezilya gibi gelişen ekonomilerde önemli bir kavramdır. Bu tez çalışmasında, yapay sinirağları kullanılarak hisse senedi piyasasının modellenmesi ve tahmin edilmesi yapılmıştır.Menkul Kıymetler Borsası ( MKB) Ulusal 100 ve Ulusal 30 endeksleri yerel market için,Brezilya ulusal endeksi uluslar arası piyasa için kullanılmıştır.Girdi uzayı statiksel kümeleme tekniği olan Expectation Maximization ile kümelerebölünmüştür. Yapay sinir ağı yapısı olan Mixture of Experts kullanılmış, her kümeye yerelbir eksper atanmıştır. Yerel uzmanlar kendi ilgi alanlarını öğrenirken, geçit eksperleri lokaleksperlerin çıktılarını işleyerek esas çıktıyı oluşturacak şekilde birleştirmişlerdir. Bununyanı sıra aynı teknik gelecek getirilerin hesaplanmasında kullanılmıştır.Finanssal zamana serilerinin modellenmesinde sadece geçmiş getiri değerlerikullanılmamıştır. Araştırılan piyasaların fazlaca değişebilir olmasını göz önündebulundurarak değişkenlik faktörü de modellere eklenmiştir. RiskMetricsâ¢ [30]kullanılarak hesaplanan değişkenlik mevcut veriyi daha iyi ifade edebilmek için dahiledilmiştir. Deneylerimizin sonuçları genel olarak kabul edilmiş ve hazırlanmış performansölçülerine göre değerlendirilmiştir.Deneylerimizden elde ettiğimiz bir diğer ilginç sonuç ise; değişik makro ekonomileresahip ülkelerin hisse senedi piyasalarının arasındaki ilişkidir. Bu ilişki şaşırtıcı değildirçünkü 1980-1990 yılları arasında Türkiye mali piyasaların serbestleşmesi süreci içindeönemli bir miktar düzenlemeleri Latin Amerika ülkelerinden almıştır, bunlarında başındaBrezilya gelmektedir.","Stock market?s return prediction is an important concept in emergent markets likeTurkey and Brazil. In this thesis, I used artificial neural networks architecture to model andpredict stock markets. Istanbul stock exchange indices National-100 and National-30 areused for domestic market, Brazilian stock exchange index, BVSP, is used as theinternational market.Input space is divided into clusters with statistical clustering technique ExpectationMaximization. ANN?s structure Mixture of Experts is used and local experts are assignedto each cluster. While local experts are learning their region of interest, in parallel, gatingexperts combine the outputs of them to model overall structure. Besides, future returns arepredicted based on patterns obtained from past trainings.In financial time series modeling using ANN, I used past returns in simulations.Since we know two investigated markets are highly volatile and chaotic, the volatilityfactor is added to the analysis as well. Volatility calculated from RiskMetricsâ¢ [30] is alsoincluded in the models to capture different dynamic features of the data. Results of oursimulations are evaluated by using previously defined and widely accepted performancemeasures.Another interesting result is gained during our simulations; two countries of differentmacroeconomic structures show similarities. Interaction between Turkish and Brazilianstock markets is not surprising; during the financial liberalization of the 1980-1990s,Turkey imported many constitutional laws from Latin American economies especiallyfrom Brazil."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gelecek Nesil Kablosuz Sistemlerin (GNKS) ayrışık yapısı sisteme kabul kon-strolünü şok karmaşıklaştırır. Sisteme kabul kontrolünde bağlantı kurma veya bağlantıu uc s s u g gel değiştirme isteği sırasında alt sistemlerin ulaşılabilirliğinin, kullanıcının tercihlerinin,gs g s gve bağlantı sınıfının hesaba katılması gereklidir. Bu tezde ilk ünce genel bir bağlantıg o gkabul kontrol algoritması veriyoruz. Aynı zamanda GNKS dahilinde sisteme kabulkontrol işin literatürdeki ilk analitik modeli üneriyoruz.c u oGNKS birden şok alt sistemden oluşur. Analitik modelimizde alt sistem sayısıc suzerine bir limit yoktur. Birden şok alt sistemin varlığından dolayı sistemin durum-ü c gları alışılmış türdeş kablosuz sistemlerin durumlarından daha karmaşıktır. GNKS ves su s sdurumlarını tanımladıktan sonra, GNKS işin modellemenin ve durum olasılıklarınınchesaplanmasının başlıca zorluklarına değiniyoruz.s gDurum olasılıklarını hesaplamak işin analitik bir şüzüm yaklaşımı sunuyoruz.c co u sDurum uzayı aşırı büyüse de durum olasılıklarını makul bir yolla hesaplamak işins uu cüakıllı bir şozüm üneriyoruz. Onerdiğimiz analitik şozüm de kabul edilir varsayımlaracü u o g cü udayanmaktadır.","The heterogeneous structure of Next Generation Wireless Systems (NGWS)makes admission control very complex. Accessibility of the subsystems at the timeof connection or handoï¬ request, availability of resources in the subsystems, user pref-erences, and connection class need to be considered in admission control. In this thesis,ï¬rst we give a general connection admission control algorithm. We also propose theï¬rst analytical model in the literature for admission control in NGWS.NGWS consists of many subsystems. Our analytical model has no limitation onthe number of subsystems in NGWS. Due to the existence of multiple subsystems,states of the system are more complex than the states in ordinary homogeneous wire-less systems. After deï¬ning NGWS and states, we point out the major challenges inmodeling for NGWS and evaluating state probabilities.For evaluating the state probabilities, we present an analytical solution approach.Since the state space explodes, we propose a neat solution to calculate the state prob-abilities in a reasonable way even as the state space grows. Our proposed solution isbased on reasonable assumptions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Dizi tip şifreleme algoritmaları güvenli sayısal haberleşme uygulamalarındakullanılan en yaygın şifreleme metotlarındandır. Bu tip şifreleme algoritmaların çoğunluğubasitliğinden, donanımdaki hızından ve iyi istatistiksel özelliklere sahip olduğundanDoğrusal Geri Beslemeli Kayan Saklaçları (LFSRs) tasarımlarında kullanmaktadır. Fakatbu randımanlı bileşenler güvenliği dikkate aldığımızda yeterli olmamaktadır. Tasarımcı,sistemi kriptanalize karsı daha güçlü yapmak için birçok doğrusal olmayan fonksiyonlar vemekanizmalar kullanmalıdır. Bir dizi tip şifreleyici yüksek periyoda, yüksek doğrusalkarmaşıklığa, iyi istatistiksel özelliklere ve cebirsel saldırılar, ilinti saldırıları, zaman belleködünleşimi saldırıları, böl ve fethet saldırıları gibi birçok başarılı güncel saldırıya karsıdayanıklı olmalıdır.Bu tezde yeni bir dizi tip şifreleyici tasarımı önerilmektedir. SAFE cebirsel ve ilintisaldırılarına karsı güçlü olması için tasarlandı. Tasarım evresinde hedef, iyi rasgeleliğe,yüksek periyoda ve doğrusal karmaşıklığa sahip ve saldırılara karsı dayanıklı bir dizi tipşifreleyici tasarlamaktı. Bu tezde yapılan yeniliklerde birisi, ilinti ve cebirsel saldırılarakarşı dayanıklılığı artırmak için doğrusal geri beslemeli kayan saklaçların yerine doğrusalolmayan geri beslemeli kayan saklaçların önerilmesidir. Buna ek olarak, başka bir yenilikise yeni bir seyreltme algoritmasının, EBSGvariant, şifreleyicinin güvenliğini artırmakamacıyla kullanılmasıdır. Ayrıca bu algoritmaların ürettikleri çıktı dizilerinin özellikleri vealgoritmaların bilinen bazı saldırılara karsı dirençleri çalışmada verilmektedir.Matematiksel açılımlar ve benzetim sonuçları ışığında şifreleyicinin istenen minimum çıktıözelliklerinin gereksinimleri yerine getirdiği ve bilinen bazı saldırı tiplerine karşı yüksekdirence sahip olduğu gösterilmektedir. Sonuç olarak, SAFE basit tasarımı sayesindedonanım ve yazılım uygulamaları için uygundur diyebiliriz.","Stream ciphers are one of the most important classes of encryption algorithms usedto ensure security in digital communication. The design of many stream ciphers is based onuse of Linear Feedback Shift Registers (LFSRs), due to their simplicity, speed ofimplementation in hardware and providing sequences with good statistical properties.However, this efficient component is not sufficient when we consider security. Thedesigner should use many nonlinear functions and mechanisms to make the system moreresistant against cryptanalysis. A stream cipher should have high period, high linearcomplexity, good statistical properties and be resistant against most recent successfulattacks such as algebraic attacks, correlation attacks, time/memory trade-off attacks, anddivide and conquer attacks.In this thesis, a new stream cipher design is proposed. SAFE is designed to beresistant against algebraic and correlation attacks. In the design phase, the objective was todesign a stream cipher with good randomness, high period and linear complexity andresistance against many attacks. The innovation in this thesis is the proposal of nonlinearfeedback shift registers instead of linear feedback shift registers to provide resistanceagainst correlation and algebraic attacks. In addition, another innovation is the use of a newirregular decimation algorithm, EBSGvariant, for increasing the security of the cipher.Keystream properties of the cipher and its resistance with respect to some well knowncryptographic attacks are investigated. From the mathematical expressions and simulationresults, it is shown that the cipher produces keystream sequences with satisfying basicsecurity requirements and provides high resistance against well known attack types.Finally, we can say that SAFE can be appropriate for both software and hardwareapplications due to its simple design."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tıbbi dökümanların elektronik ortamda özellikle XML tabanlı dökümanlar şeklindesaklanma oranının artması, bu amaçla kullanılan depolama aygıtlarının kayıt güvenirliliğinisağlamasını zorunlu kılmaktadır. Düzenleyici kurallar bu kayıtların `bir kez yaz çok kezoku' (WORM) depolama aygıtlarında saklanmasını öngörmektedir. Ayrıca, hassas bilgininkorunabilmesi ve güvenlik gereksinimlerinin karşılanabilmesi için WORM depolamaaygıtlarında saklanan dökümanlar şifrelenebilir. Bununla birlikte, kayıt sayısının fazlalığıbu kayıtlara hızlı bir şekilde ulaşabilmek için indeks kullanımını gerekli kılmaktadır.Fakat, kayıtlara indeks yoluyla ulaşılması bu kayıtların başkaları tarafından kolaylıkladeğiştirilmesi ve silinmesi için uygun bir ortam yaratmaktadır.Biz bu çalışmada, WORM depolama aygıtlarında şifreli şekilde saklanan XMLtabanlı tıbbi dökümanlar için yeni bir indeksleme yapısı ve şifreleme yöntemiönermekteyiz. Önerilen indeksleme metodu, WORM depolama aygıtlarında şifreli şekildesaklanan XML tabanlı tıbbi dökümanlar üzerinde izdüşüm, seçme ve birleştirme işlemleriyapabilen ve GHT veri yapısını kullanan bir indeksleme tekniğidir. Ayrıca, XML tabanlıtıbbi dökümanlar, geleneksel şifreleme yöntemlerini sıra korumalı şifreleme yöntemiyle(OPES) birleştiren yeni bir şifreleme algoritması kullanılarak saklanmaktadır. Literatürdeşu ana kadar sadece elektronik postalar, mali raporlar gibi sıradan dökümanlar içinindeksleme yöntemleri ile ilgili çalışmalar bulunmaktadır ve bu indeksleme yapıları sadecetemel kayıt ekleme ve kayıt arama algoritmalarını yapabilmektedir. Son olarak,önerdiğimiz sistemin performans açısından tatmin edici sonuçlar verdiğini kanıtladık.","Since the medical records are increasingly stored in electronic forms, especially inXML based documents, the storage devices for these records must preserve theirtrustworthiness. The regularity requirements rely on storing the critical data in Write-Once-Read-Many (WORM) storage devices to prevent them from easy modification. The XMLdocuments stored in the WORM storage may also be encrypted in order to protect thesensitive data, and satisfy the security requirements. Efficient access of the large volume ofrecords requires the use of direct access mechanisms such as indexes. Relying on indexesfor accessing records could, however, provide a means for effectively altering or deletingrecords, even those stored in WORM storage.In this study, we propose a novel indexing structure and an encryption schema forencrypted medical XML documents stored in WORM storage structures. The proposedindexing method expedites projection, selection and join operations on encrypted medicalXML records stored in WORM storages, and uses Generalized Hash Tree (GHT) datastructure. Also, medical XML documents are stored with a novel encryption schema whichcombines traditional encryption techniques with order preserving encryption schema(OPES). In the literature so far, there are only some studies on indexing techniques forsome ordinary documents such as electronic mail, financial statements, quality assurancedocuments which all stored in WORM structures, and these indexing structures onlymanage simple insert and search algorithms. Finally, we demonstrate that the proposedsystem gives satisfactory performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gerşek dünya, bu ortamdaki etmenler tarafından gürültülü algılayıcılar ya dac u u u uueksik algı nedeniyle kısmi olarak güzlemlenebilir. Belirsizlik altında üzerk stratejio ogeliştirmenin karşısında iki büyük engel vardır. Verilen bir gürev işin sürekli du-s s uu o c urum uzayının üzerk olarak bülgelere ayrılmasıve bu bülgeler uzerinde amaca yüneliko o o ü oügkarmaşık davranışların ortaya şıkarılması. Bu tezde isimleri ARKAQ-Oğrenme, KAFAQ-s s cügOğrenme ve KBVI olan ve şeşitli tekniklerin bir araya getirilmesinden oluşan uş yenics s ücügyaklaşım ünerilmektedir. ARKAQ-Oğrenme yapısında Kalman ï¬ltreleme üzelliği ek-so o güg üglenmiş, ART2-A ağı ve Q-Oğrenme metodları kullanılmıştır. KAFAQ-Oğrenme, Kalmans g sügï¬ltreleme ve Q-Oğrenme yüntemlerini kullanan bir sonlu durum makinasıdır. KBVIoise Monte Carlo metodlari kullanmakta ve sürekli durum ortamlarında Q-değerlerininu ghesaplanması işin yeni bir teknik ortaya koymaktadır.cBütün yordamlar gerşek zamanlıdır ve güreceli olarak düşuk yer ve zaman karma-uu c o us üşıklıkları vardır. Yordamlar iyi bilinen Kısmen Güzlemlenebilir Markov Karar Süreşs o ucproblemleri uzerinde uygulanmıştır. Burada sürekli dağılımlar kullanıldığı işin değerü s u g gc gfonksiyonunun güsterimi daha zorlaştırılmıştır. Yordamlar Markov olmayan güzlemlerio s s oiş inanş durumları ile ilişkilendirerek saklı durumları ortaya şıkarabilmiş ve iş inanşc c s c s c cdurum uzayı uzerinde yaklaşık olarak en iyi bir davranış politikası oluşturabilmişlerdir.ü s s s s","A real world environment is often partially observable for agents either becauseof noisy sensors or incomplete perception. Autonomous strategy planning under uncer-tainty has two major challenges. The ï¬rst one is autonomous segmentation of the statespace for a given task, and the second, emerging complex behaviors, that deal with eachstate segment. This thesis proposes three new approaches, namely ARKAQ-Learning,KAFAQ-Learning and KBVI, that handle both challenges by utilizing combinations ofvarious techniques. ARKAQ makes use of ART2-A Networks augmented with KalmanFilters and Q-Learning. KAFAQ is a ï¬nite state automaton using Kalman ï¬lters andQ-Learning. KBVI uses Monte Carlo methods and introduces a new technique tocalculate Q-values for continuous domains.All are online algorithms with relatively low space and time complexity. Thealgorithms were run for some well-known Partially Observable Markov Decision Processproblems, where the problem of representing the value function is more diï¬cult thanthe discrete case because inputs are continuous distributions. The algorithms couldreveal the hidden states, mapping non-Markovian observations to internal belief states,and also could construct an approximate optimal policy on the internal belief statespace."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"3B modellerin bilgisayar destekli tasarım, üretim, savunma, mimari, eğlence, vs. gibialanlarda kullanımının artmasıyla birlikte 3B nesne bilgilerinin gösterimi vegörselleştirilmesi gereksinimi giderek artmıştır. Birçok uygulamada, model bilgilerineiletişim ağları üzerinden erişilme zorunluluğu, verimli kodlama yöntemleri geliştirmeyi son20 yıllık dönemde ilgi çekici bir araştırma konusu yapmıştır. VRML (Virtual RealityModeling Language) ve MPEG-4 (Motion Pictures Experts Group-4) 3B nesne bilgilerininkodlanması ve görüntülenmesi için geliştirilmiş standartlara örnek verilebilir.3B nesne bilgilerini kodlamak farklı çerçevelerde ele alınabilir ve sınıflandırılabilir.Bu çalışmada bizi esas olarak ilgilendiren, geliştirilen kodlayıcının ilerleyici bir yapıyasahip olmasıdır. Kimi uygulamaların tek bir kodlanmış modelle çalışarak geri çatmayı bumodel üzerinde başarması yeterliyken, kimi uygulamalarda modelin ara aşamalarınıngörülmesi gerekebilir. Bu durumda ilerleyicilik, yani modelin kabadan iyiye doğru geriçatılması ve zaman ilerledikçe artan kesinlikte görselleştirilmesi gerekir.Bu çalışmada, çokgen ağ yapılarının sıkça kullanılan bir alt kümesi olan üçgen ağyapısındaki nesneleri ilerleyici biçimde kodlayan bir araç geliştiriliyor. Kodlama aracıKarni ve Gotsman'ın önerdiği yöntemle elde edilen spektral katsayıları daha öncesindeimge kodlama amacıyla kullanılmış olan ve küme bölüntüleme yaklaşımıyla çalışan birsıralama algoritması olan SPECK (Küme Bölüntüleyen Gömülü Blok Kodlayıcı) fikirlerinikullanarak bit-düzlemsel kodlamaktadır. Elde edilen bit katarı tamamen gömülü olupspektral yöntemden daha başarılı sonuçlar ürettiği gözlenmiştir.","The demand for visualizing 3D objects has been growing rapidly in recent years dueto the use of 3D models in several contexts and an increasing number of applications suchas computer aided design, manufacturing, defense, architecture, entertainment, etc.Accessing these models over networks is required in many cases and hence developingefficient encoding schemes has been an interesting research topic for a decade or two.VRML (Virtual Reality Modeling Language) and MPEG-4 (Motion Pictures ExpertsGroup-4) are two multimedia standards developed for coding and displaying polygonalmeshes.Coding 3D object data can take place in different domains and be classified indifferent ways. What primarily concerns us in this study is the progressive nature of thedeveloped scheme. That is, while some applications may do with one instance of anencoded model and reconstruction performed on this single instance, other applicationsmay require intermediate stages of a model that is reconstructed from coarse to fine intime. The latter case amounts to progressivity where a model can be viewed with higherand higher precision.In this work, we develop a progressive mesh geometry coder that operates on afrequently used family of polygonal meshes (i.e. triangle meshes). The tool operates onspectral coefficients obtained by the method of Karni and Gotsman and bit-plane codesthese coefficients using ideas borrowed from a set partitioning sorting algorithm calledSPECK (Set Partitioning Embedded Block Coder) formerly used for image codingpurposes. The output code is truly embedded and our method has shown to produce resultssuperior to those of the spectral method."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılımın servis olarak sunulması yaklaşımı, endüstriyel ve akademik çalışmalarınweb üzerinde entegrasyon alanında yoğunlaşması sonucunda gerçeklik kazanmıştır.Dağıtık bir altyapının gerçek potansiyeli, web servislerinin bir iş akışının parçaları olarakbelli bir amaca ulaşmak için birlikte çalışabilir hale gelmesiyle görülecektir. Rol oynayantüm tarafların beklenmeyen değişimler içinde olduğu böyle bir durumda, seçmeye dayalıbir derleme için kolay adapte olabilen, esnek sistemler gerekmektedir. Bu sistemler,ihtiyaçlara cevap verebilecek, bir bütünün parçaları gibi birleştirilmiş tek bir servisiderleme yeteneğine sahip akıllı sistemler olmalıdır.Web servisleri, tez kapsamında, daha çok bilgi servisleri olarak kullanılmaktadır. Buservisler ortam üzerinde bir değişiklik yapmadan, bilgi üreten servislerdir. Diğer türservisler ise ortam üzerinde değişiklik yaratan derleme sürecinin karmaşıklığını artırarakbelli bir anda ortam koşullarının kontrol edilebilmesini ve bir sonraki hareketinplanlanabilmesini zorlaştırmaktadır.Bu çalışmada, servislerin bulunmasına ve derlenmesine grafik tabanlı teorikaltyapıyla web servislerini birleştirerek rehberlik eden, etmen tabanlı bir sistemsunulmaktadır. Yaklaşımımızın test edilebilmesi için ağ teorisinden gelen tekniklerle webservislerini derlemeye yönelik planlar oluşturan, etmen tabanlı bir sistem geliştirilmiştir.Önerilen bu sistem, Anlamsal Web ve etmen etkileşimlerini gözönünde bulunduracakşekilde verimli web servisi derleme planları oluşturmaya yönelik bir prototip ilegerçeklenmiştir.","?Software as a service? approach has become a reality since efforts of both industryand research focused on service integration on the web. It would be possible to see the truepotential of such a distributed infrastructure when those services can be joined together asparts of a workflow in order to collectively achieve combined functionality. The collectivecomposition requires adaptive, dynamic systems where all parties are subject tounexpected changes. It also requires intelligent systems that are able to compose servicesas building blocks to generate a single service that meets requirements.Web Services, in our context, are mainly information services. These servicesproduce information rather than changing the world. The other type of services are calledworld altering services. These services change environmental view of the world. Suchservices introduce state complexity into composition process and make it harder todetermine next actions of composition process.In this research we present an agent based system that guides service discovery andservice composition by integrating graph theory into the Web Services domain. As themomentum around Web Services grows, there is an increasing need for effectivemechanisms of Web Services interaction. In order to test our approach we developed anagent based system that generates composition plans by using techniques inherited fromnetwork theory. The proposed system is applied on a prototype that depicts Semantic Webinnovations and agent interactions while targeting to generate effective Web Servicescomposition plans in an efficient manner."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayar-Aracılı İletişim Ortamında Farklı Görev Türlerinin İngilizce ÖğretmenliğiÜçüncü Sınıf Öğrencilerinin İletişim Stratejileri Kullanımı Üzerindeki EtkileriNur Eser AltunBu tez, bilgisayar-aracılı iletişim ortamındaki farklı görev türlerinin iletişimstratejilerinin kullanımı üzerindeki etkilerini ve ögrencilerin bilgisayarların iletişimve yazma amacı ile kullanılmasına karşı olan tuttumlarını araştırmayıamaçlamaktadır.İletişim stratejileri Dörnyei ve Scott'ın (1997) ve Smith'in (2003b)sınıflandırılmalarına dayanılarak ve üç farklı iletişimsel görev türü: (a) bulmaca, (b)karar-verme, ve (c) fikir-alışverişi kullanılarak incelenmistir.36 İngilizce öğretmenliği üçüncü sınıf öğrencisi Yahoo! Messengerkullanarak altı hafta boyunca çevrimiçi sohbet oturumlarına katılmıştır. Çevrimiçisohbet oturumlarından önce katılımcılara bilgisayarların kullanımına karşı olantutumlarını ölçmek için Warschauer'ın (1996b) anketi verilmistir. Bu anket aynızamanda katılımcılar hakkında demografik bilgi ve katılımcıların bilgisayarbilgileriyle ilgili bilgi toplamıştır. Katılımcılara aynı anket son çevrimiçi sohbetoturumundan sonra tekrar verilmistir. Veriler, tanımlayıcı istatistik, tek-yönlütekrarlanan ölçümlü varyans ve iki eş arasındaki farkın önemlilik testi yöntemleriyleincelenmiştir. Katılımcıların çevrimiçi sohbet oturumları hakkındaki deneyimleri vedüşünceleri ile ilgili nitel veriler Warshauer'in tutum anketini çaprazlama doğrulamaviiamacı ile oturumlar sonrası uygulanan ve Wang (1993)'ten uyarlanan oturumsonrası-anketi ile toplanmıştır.Çalışmanın sonucunda eşzamanlı bilgisayar-aracılı iletişim ortamındaöğrencilerin çok çeşitli iletişim stratejilerini kullandıkları ve görev türünün iletişimstratejilerinin kullanımının türünü ve sıklığını etkilediği bulunmuştur. Ayrıcaöğrencilerin bilgisayarların iletişim ve yazma amaçlı kullanımına karşı olumlututumlara sahip oldukları görülmüştür. Sonuç olarak, eşzamanlı bilgisayar-aracılıiletişim ortamının yazı-odaklı bir iletişim ortamı sağlayarak öğrencilerin iletişimstratejisi kullanımını teşvik ettiği ve hedef dilde anlaşmaya yönelik etkileşimeolanak kıldığı bulunmuştur.viii","Effects of Different Types of Tasks on Junior ELT Students?Use of Communication Strategies in Computer-Mediated CommunicationByNur Eser AltunThis thesis investigates the effects of different task types on the use ofcommunication strategies (CSs) in computer-mediated communication (CMC) andthe attitudes of students to using computers for communication and writing.The use of communication strategies in three different communicative tasktypes: (a) jigsaw (b) decision-making and (c) opinion-exchange were examined,based on and adapted from Dörnyei and Scott?s (1997) and Smith?s (2003b)taxonomies.36 junior ELT students participated in on-line chat sessions for six weeksusing Yahoo! Messenger. Before the chat sessions the participants were givenWarschauer?s (1996b) attitude questionnaire which also collected demographicinformation about participants and their computer familiarity. The participants weregiven the same questionnaire at the end of the last chat session. The data wasanalyzed using descriptive statistics, one-way repeated measures analysis of variance(ANOVA), one-sample and paired-sample t-tests procedures. Qualitative data aboutparticipants? experiences and feelings about the synchronous CMC to cross-validatethe findings of the attitude questionnaire was collected through a post-sessionquestionnaire which was adapted from Wang (1993).vThe results showed that students used a wide variety of communicationstrategies during synchronous CMC, and task type affected the frequency and type ofcommunication strategy used. It was also found that participants had positiveattitudes towards using computers for communication and writing. The studyprovided evidence that synchronous CMC medium gave learners the opportunity tointeract and negotiate meaning in the target language by providing them with a text-based communicative setting in which communication strategy use was promoted.vi"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez Türkiye'de özel bir hastanedeki hastane bilgi sistemi uygulama zorluklarınınpotansiyel kaynaklarını tetkik etmekte ve uygulama sırasındaki zorlukları önlemekiçin öneriler sa lamaktadır. Hasta bakımı vermenin artan maliyeti ve veri kalitesininve veriye ula manın geli tirme çalı malarında kar ıla ılan zorluklar sa lıkorganizasyonlarında bilgi sistemleri kullanımı için baskıyı artırmaktadır. Ancak,hastanelerin karma ık i akı larından dolayı, sa lıkta bilgi sistemleri kullanımıberaberinde bazı problemleri de getirdi. Bu çalı mada, potansiyel uygulamazorluklarını ortaya çıkarabilmek için, Hastane Bilgi Sistemi'nin henüz uygulamaa amasında olan Türkiye'deki özel bir hastanede bir ara tırma yapıldı. Veri toplamakiçin mülakat, gözlem ve anket teknikleri uygulandı. Veri, tanımlayıcı, faktör veANOVA analizleri kullanılarak analiz edildi. Bu analizlerin sonuçları; Hastane BilgiSistemi uygulama zorluklarının potansiyel kaynaklarının organizasyonel konular, sonkullanıcı profili, farklı sistemlerin entegre olması, farklı bölümlerin farklı i akı larıarasındaki tutarsızlıklar ve e itim konuları ile ilgili oldu unu gösterdi, di er taraftaise yazılım, donanım, planlama, destek, güvenlik ve hizmet sa layıcı ile ilgilikonularda ana bir problem yoktu. Literatür ara tırması ve bu çalı manın sonuçlarınınöncülü ünde, ba arılı, yeterli ve verimli bir Hastane Bilgi Sistemi uygulama fazınaula abilmek için son kullanıcı katılımı, i süreçlerinin yeniden yapılanması, donanımplanlama, bilgi sistemlerinin entegrasyonu ve destek bazında öneriler verildi.","This thesis looks for potential sources of implementation difficulties of hospitalinformation system in a private hospital in Turkey and provides recommendations toavoid these difficulties. Increasing cost of patient care delivery and the difficultiesfaced during the improvement studies of data quality and data access have increasedthe pressure for the use of information systems in healthcare organizations. However,due to complex workflows of hospitals, usage of information systems in healthcarebrought some problems along with it. In this study, in order to find out the possibleimplementation difficulties, a survey was conducted in a private hospital in Turkeywhich was just in the stage of implementing a hospital information system.Techniques of interview, observation and questionnaire were applied for datacollection. Data was analyzed by using descriptive, factor and ANOVA analyses.The results of these analyses showed that the potential sources of hospitalinformation system implementation difficulties were related to organizational issues,end user profile, integration of different systems, inconsistency among differentworkflows of different departments and training issues whereas there was no majorimplementation problem related to software, hardware, planning, support, securityand solution provider. Under the guidance of literature survey and the findings of thestudy, recommendations for achieving a successful, sufficient and efficient hospitalinformation system implementation phase are given in terms of end usercontribution, business process reengineering, hardware planning, integration ofinformation systems, training and support."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"PARALEL DÖRTYÜZLÜ ÖRGÜ İYİLEŞTİRMEMehmet BalmanBilgisayar Mühendisliği, Yüksek Lisans, 2006Tez Danışmanı: Doç. Dr. Can ÖzturanUyarlanmış Örgü İyileştirme, Parçalı Türevsel Denklemlerin çözümünde kullanılan anayöntemlerden biridir. Üç boyutlu sistemler daha karmaşık olduğundan, özellikle paralelortamlar için az sayıda arıtma/iyileştirme yöntemi mevcuttur. Buna rağmen iki boyutluyapılar için birçok algoritma önerilmiştir. Rivara'nın en uzun kenar bölme tekniğiincelenmiş, problemin paralel algoritma ile çözümü çalışılmış ve düzensiz dörtyüzlüörgüler için paralel yöntem sunulmuştur. Önerilen algoritma gerçek uygulamalar içinpratik ve büyük örgü yapıları için ölçeklenebilirdir. Dağıtık sistemler için kullanılabilir birveri yapısı anlatılmış ve işlemciler arası haberleşmeyi kullanan bir uygulama sunulmuştur.PTMR uygulaması örgü bilgisini işlemcilere dağıtıp kısa zamanda iyileştirme işleminiyapabilmektedir.","PARALLEL TETRAHEDRAL MESH REFINEMENTMehmet BalmanComputer Engineering, M.S. Thesis, 2006Thesis Supervisor: Assoc. Prof. Can ÖzturanKeywords: Adaptive Mesh Refinement, Tetrahedral Mesh, Longest-Edge Bisection,Parallel AlgorithmThe Adaptive Mesh Refinement is one of the main techniques used for the solutionof Partial Differential Equations. Since 3-dimensional structures are more complex, thereare few refinement methods especially for parallel environments. On the other hand, manyalgorithms have been proposed for 2-dimensional structures. We analyzed the Rivara'slongest-edge bisection algorithm, studied parallelization techniques for the problem, andpresented a parallel methodology for the refinement of non-uniform tetrahedral meshes.The proposed algorithm is practical for real-life applications and it is also scalable forlarge mesh structures. We describe a usable data structure for distributed environments andpresent a utility using the inter-process communication. The PTMR utility is capable ofdistributing the mesh data among processors and it can accomplish the refinement processwithin acceptable time limits."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma, Türkiye'deki en büyük sarfiyat ürünü imalatçılarından birindekitedarik zinciri performansını iyileştirmeye yöneliktir. Çalışmanın amacı, tedarikzinciri yöneticilerinin karar vermeleri için karar destek sistemi olarak çalışacak vekullanımı kolay bir denetim ortamı sağlayacak bir çözüm geliştirmektir. Mevcutsistemde, zincirin yukarısına doğru bir talep bilgisi akışı bulunmamakta ve imalatçıfirma imalat hızını kendisine son bir ayda verilen sipariş miktarlarına görebelirlemektedir. Diğer tarafta, dağıtıcıların verdiği toplam sipariş miktarının belirlibir kotanın üzerinde olması durumunda, dağıtıcılarına indirim uygulanmaktadır.?Aylık Kota? sisteminde, dağıtıcılar değerlendirme peryodu sonunda kotalarınaulaşmışlarsa, birim satınalma fiyatında indirim elde ederler. Mevcut tedarik zincirisistem performansını iyileştirmek üzere satış noktası verilerinin tedarik zinciriüyeleri arasında paylaşımı için bir bilişim sistemi önerilmektedir. Bir başkaiyileştirme stratejisi ise, ?Aylık kota? yerine, kotaların dağıtımcı her siparişverdiğinde kontrol edildiği ?Yuvarlama Dönem? yöntemini uygulamak olabilir.ARENA yazılımı kullanılarak üç simulasyon modeli geliştirilmiş, MS-Excel'iveritabanı olarak kullanan bir grafik kullanıcı arayüzü oluşturulmuş, ve tedarikzinciri yöneticileri için bir karar destek sistemine entegre edilmiştir. KDS ortamı,değişik performans ölçütleriyle üç modelin karşılaştırmak için kullanılmıştır.","This study focuses on the improvement of supply chain performance in one of thebiggest commodity product manufacturers in Turkey. The aim is to generate a toolthat runs as a Decision Support System (DSS) and provides an easy to use simulationenvironment for supply chain managers in decision-making. In the current supplychain system there is no demand information flow upwards in the chain and themanufacturer determines its manufacturing rate according to the orders faced in thelast thirty days. On the other hand, the manufacturer offers a volume discount optionif the orders placed by a distributor exceed a certain quota. In the ?Monthly Quota?system, the distributors gain a discount for their unit-purchasing price, if they reachtheir quota at the end of the evaluation period. As an improvement of the currentsupply chain system, an information system is proposed to share the Point of Saledata among the members of the supply chain. Another improvement strategy may beapplying the ?Rolling Horizon? instead of ?Monthly Quota? method where thequotas are checked every time a distributor places an order. Three simulation modelsare developed by using the software ARENA, a graphical user interface that usesMS-Excel as a database is generated and integrated into a DSS for the supply chainmanagers. The DSS environment is used to compare all three models with differentperformance measures."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ses kaynağı yeri belirlenmesinin telekonferans, konuşma tanıma, konuşmacı belirleme, otomotiv ortamında konuşma sinyali alma, yankılı ortamlarda ses yakalama,büyük odalarda ses kaydı ve işitme cihazı tasarlama gibi birçok uygulaması bulunmaktadır.Ses kaynağının yerini bulmanın bir yolu geliş yönü değerlerini kullanmaktır. Bu değer,mikrofon dizisinin orta noktası ve ses kaynağı arasındaki doğru ile mikrofon dizisinitaşıyan doğru arasındaki açıyı ifade etmektedir. Geliş yönü değerleri genellikle, ilk olarakiki farklı mikrofon tarafından algılanan sinyallerin geliş zaman gecikmesi değerlerinintahmin edilmesi, sonra da bu değerin diğerine dönüştürülmesi ile belirlenir. Geliş zamangecikmesi değeri ise çapraz-güç tayfı fazı katsayıları ile tahmin edilir.Bu tezde, üç boyutlu ortamlarda bulunan çok sayıdaki ses kaynağının yerlerini tespitedebilecek yeni bir yöntem önerilmiştir. İlk olarak, CSP katsayılarının eşzamanlı birbiçimde toplanması yöntemi ile DOA tahminleri bulunmuştur. Daha sonra bu tahminler,mikrofon dizisi tasarımına bağlı olarak çalışan ve bir tutarsızlık ölçüsünü esas alan yeni biryaklaşımla gruplandırılmıştır. Her bir ses kaynağı için DOA tahmini üçlüleri bulunduktansonra bunların yerleri üç koninin kesişim noktalarını bulmak için geliştirilen, tek değişkenebağlı bir fonksiyon üzerinde çalışan bir arama metodu yardımıyla bulunur.Ortamda birden fazla ses kaynağının bulunması bu probleme iki zorlukgetirmektedir. Birincisi, ses kaynakları arasındaki ilgileşimin geliş zamanı değerlerinintahmini sürecini saptırması, İkincisi ise, tüm kesişim noktaları arasından doğru kesişimleribulmak için çoklu mikrofon dizileri tarafından hesaplanan çoklu geliş yönü tahminlerininses kaynakları ile eşleştirilmesi zorunluluğudur. Bir başka önemli zorluk ise ortamın üçboyuta genellenmiş olmasıdır.viiDeneyler hem benzetim hem de gerçek akustik ortamda gerçekleştirilmiştir.Sonuçlar, algoritmanın karşılaştığı karmaşıklıklar, deneylerde kullanılabilen mikrofonsayısı ve bunları çeşitliliği göz önünde bulundurulduğunda oldukça umut vericidir.","Localization of sound sources has several applications like teleconferencing, speechrecognition, speaker identification, speech acquisition in an automobile environment,sound capture in reverberant enclosures, large room recording-conferencing, and hearingaid devices. One way of finding the location of a sound source is to utilize the direction ofarrival (DOA) values. This value indicates the angle between two lines, first of whichconnects the mid point of the microphone array and the sound source, and second of whichcarries the microphone array. DOA values are usually estimated by first estimating thetime delay of arrival (TDOA) value of the signals received from two microphones and thenconverting TDOA estimates to DOA estimates. TDOA value is estimated using the cross-power spectrum phase (CSP) coefficients.The existence of multiple sound sources in an environment brings two complicationsto this problem. First of all, the correlation between the sound sources distorts the TDOAestimation procedure. Second, multiple DOA estimates, which are calculated for multiplemicrophone arrays, have to be matched to the sound sources to find the correct intersectionpoints among multiple ones. Another major complication is the generalization of theenvironment to the three dimensional space.In this thesis, a new method is proposed, for localizing multiple sound sources inthree dimensional environments. The synchronous addition of CSP coefficients method isutilized for finding the undistorted DOA estimates. Then these estimates are clusteredusing a new design-specific, an inconsistency measure based clustering algorithm. Havingfound DOA estimate triples for each sound source, the location of sound sources aredetermined by finding the intersection point of three cones formed by three DOA values.This intersection is found by first finding a closed formula, which consists of a singlevvariable, for a locus of the intersection, which is a three dimensional path and then findingthe suitable point on this path.Experiments are done on simulation and real acoustical environments. The results arepromising considering the complexities that the algorithm faced, and the number of themicrophones that are available for the experiments, and the diversity of them."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Veri madenciliği, büyük veri tabanlarında yer alan verinin farklı açılardanincelenerek sakladığı gizli bilgilerin ortaya çıkarılması sürecidir. Müşterisegmentasyonu ve profillerin çıkarılması, şirketlerin değerli müşterilerininbelirlenmesi amacıyla kullanılan veri madenciliği uygulamalarıdır. Diğer müşteriguruplarından faklı ancak kendi içinde benzerlik gösteren değerli müşteriler gurubuelde etmek, şirketlerin kısıtlı kaynaklarını bu gurup için kullanmasına olanak sağlar.Bu çalışmanın amacı, veri madenciliği araçları ve uygulamalarını kullanarakhızlı tüketim sektöründe yer alan bir şirket için, müşteri ilişkileri yönetimiaktivitelerine temel olabilcek bir yapı geliştirmektir. Müşteri ana verisi ve satışişlemleri, müşteri ilşikileri yönetimi için kullanılabilcek anlamlı verileredönüştürülmektedir. Müşteri ve il segmentleri müşterilerin alışveriş davranışlarınagöre oluşturulmuştur. Segmentasyon modellemesi için hiyerarşik olmayan kümelemeyöntemleri kullanılmıştır. Müşteri ve il segmentlerinin profilleri kapsadıklarımüşterilerin özellikleri kullanılarak çıkarılmıştır.Müşteri ve il segmentasyonuna ait sonuçlar OLAP fonksiyonalitelerikullanılarak oluşturulşan yeni bir raporlama ortamı ile birleştirilmiştir. Tümanalizlerin sonucunda elde edilen anlamlı bilgi, şirketin değerli müşterilere ve değerliillere odaklanan efektif müşteri ilişkileri yönetimi aktiviteleri oluşturmasına ve sonuçolarak uzun dönemde karlılığını arttırmasına hizmet edecektir.",Data mining is a process of extracting hidden information from largedatabases by analyzing data from different perspectives. Segmentation and profilinganalyses are data mining applications used to detect valuable customers ofcompanies. Determining discrete valuable customer segments allows companies tofocus on these groups and reallocate their limited sources to serve them.The aim of this study is to propose a base for the customer relationshipmanagement activities by using data mining tools and applications for a FMCGcompany. Customer master data and sales transactions of customers are converted tomeaningful information that can be used for customer relationship managementactivities. Customer segments and city segments are constructed using the buyingbehavior data of customers as the input. Nonhierarchical clustering algorithm is usedto implement the segmentation analyses. Profiles of customer and city segments aredefined using the characteristics of customers included in these segments.Results of the customer and city segmentation analyses are combined bydeveloping a new reporting environment with OLAP functionalities. Meaningfulinformation obtained at the end of the analyses will help company to developeffective customer relationship management activities focusing on the valuablecustomers and valuable cities which will result in increasing the long termprofitability of the company.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Görsel dikkat iki aşamada gerçekleşir: Dikkat-öncesi (pre-attentive) aşama,görsel algı alanında hangi bölgelerin o andaki görev için önemli olduğunu ve dolayısıile dikkat edilmesi gerektiğini belirler. Daha sonraki dikkat (attentive) aşaması, oanda dikkat edilen bölgedeki öğeleri işler. Bu konuda yaygın olarak kabul gören ikigörüş vardır. Bunlardan ilki (aşağıdan-yukarı (bottom-up)) dikkat öncesi aşamanıngörüş alanının fisiksel özelliklerinden kaynaklandığını savunurken diğer görüş(yukarıdan-aşağı (top-down)), bakan kişinin amaç ve niyetinin bu konuda belirleyiciolduğunu savunur. Aşağıdan-yukarı fikrini desteklemek için, Theeuwes bir deneyyaparak eldeki görev ile ilgisiz bir tek öğenin (singleton) yoksayılamayacağınıgöstermiştir. Buna karşın Bacon ve Egeth (1994) eldeki görevin kullanılan stratejiyibelirlediğini öne sürmüştür. Bu çalışmada, Theeuwes'in lgisiz Tekil Öğe fikri ileBacon ve Egeth'in Özellik Arama hipotezini sınamak için üç deney yapılmıştır.Sonuçlar (i) görsel arama sürelerinin renk, yer, öğe sayısı ve şekli ile ilişkiliolduğunu (ii) aranan hedef şeklin olmadığı durumlarda, öğe başına harcanan sürenindaha az olduğunu, (iii) hedef öğenin olduğu durumda öğe başına arama zamanının,öğe sayısı ile ters orantılı olduğunu göstermiştir. Pekçok alternative açıklamaincelenmiştir.ACT-R/PM, bilişsel görevlerin bilgisayar ortamında modellenmesinisağlayan bilişsel mimarilerden biridir. Deney kurulumlarımızdan biri ACT-R/PMortamında modellenerek, ACT-R/PM'in deneyde kullanılan görevi modelleyipmodelleyemeyeceği sınanmıştır. Sonuçlar göstermektedir ki, mevcut parametreleriile ACT-R/PM bu görevi insanlardan daha yavaş yapmaktadır. Bunun yanında, ACT-R/PM öğe sayısı ile öğe başına arama zamanı arasındaki ters orantıyı damodellemekte başarısız olmuştur. Sonuçlar değerlendirilerek ACT-R/PM yapısınınbir eleştirisi sunulmuştur.","Visual Attention is deployed in two stages: The pre-attentive stagedetermines which areas of the visual field are relevant for the task and therefore needto be attended. The attentive stage processes the visual information available at theattended portion of the visual field. Two rival views suggest that the pre-attentivestage is controlled by physical properties of the visual field (bottom-up) or the goalsand intentions of the observer (top-down). In support of the bottom-up approach,Theeuwes conducted an experiment to show an irrelevant singleton cannot bemasked in a top-down fashion. However Bacon and Egeth (1994) suggested that thenature of the task dictates which method will be used. In this study, threeexperiments were conducted to test Theeuwes? Irrelevant Singleton hypothesis andBacon and Egeth?s Feature Search hypothesis. The results were not compatible witheither claim. The experiment results are further analyzed. Data indicate that, (i)search times depend on the color, location, set size and the form (ii) the time spentper item is larger when there is no target in the display; (iii) in the presence of atarget, the average search time per item is inversely proportional to the set size.Several possible explanations are discussed.ACT-R/PM is a cognitive architecture that allows a cognitive task to bemodeled in computer environment. One of our experiment setups was modeled inACT-R/PM to verify that ACT-R/PM can model our task. The results show that,when default parameters are used, ACT-R/PM is slower than human participants.Also, ACT-R models fail to show the inverse relation between average response timeper item and the set size. These results were evaluated and a criticism of currentACT-R/PM constructs was provided."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Örün madenciliği, veri madenciliği ve düzyazı madenciliği teknikleri kullanılarak yarıyapılanmış ya da hiç yapılanmamış örün dökümanları ve servislerinden otomatik olarak bilgiortaya çıkarmak ve elde etmektir. Örün madenciliği hakındaki bu çalışma iki bölümdenoluşmaktadır; örün yapı madenciliği ve örün içerik madenciliği. lk bölümde, en çok kabulgörmüş olan odaklanmış arama algoritmaları ile basit ağaç izleme algoritmaları, sayfa ilgililikderecelerine, anahtar kelime içermelerine ve isabet oranlarına göre karşılaştırılmışlardır. URLiçerikleri girdi olarak kullanıldıklarında tüm kriterler için en yüksek performans değerlerineulaşılmıştır. kinci bölümde, örün sayfaları üzerinden bir otomatik konu bulma metodolojisiönerilmiştir. Bir ara motorundan dönen HTML sayfalarındaki sadece liste maddelerininişlenmesiyle, kullanıcı tarafından belirlenmiş olan bir konu ile ilgili önemli başlıklarbulunabilir Bu metodoloji farklı parametreler-sayfa sayısı, farklı konular, kök bulmauygulaması, vb.- kullanılarak test edilmiştir. Bulunan aday kelimeler ilgililik puanlamalarınagöre sıralandıklarında kullanıcının belirlediği kelime ile yüksek doğruluk oranlarıgöstermişlerdir.","Web mining is defined as the process of using data mining techniques to automaticallydiscover and extract information from semi- or unstructured Web documents and services.This study on Web mining consists of two sections, covering Web structure mining and Webcontent mining. In the first section, most widely accepted focused crawling algorithms andsimple tree traversing algorithms are compared based on their page relevance, keywordpredicate satisfaction and hit ratio criteria. Using the URL tokens as an input resulted inhigher performances for all criteria. In the second part, an automatic topic findingmethodology through Web pages is proposed. Processing only list items on HTML pagesreturned from a search engine, it is expected to find related key concepts on a user-definedtopic. The methodology is experimented using different parameters, such as number of pages,different keywords, stemming implementations, etc. The candidate concepts ordered inrelevancy scores represent a high precision on user-defined topic."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzün hızla değişmekte olan rekabet ortamında, teknolojik alandakiilerlemelerin baskısı ve artan kurumsal ihtiyaçlara bağlı olarak, kurumlar içindekibilgi teknolojileri (BT) sürekli olarak geliştirilmektedir. BT yatırımlarından mümkünolan en yüksek geri dönüşün sağlanabilmesi için, bilgi teknolojilerinin kurum içiyayılım süreçleri dikkatli bir şekilde incelenmelidir. Bu çalışma, değişik bilgiteknolojilerinin kurumlar içindeki yayılımı ve bireyler tarafından özümsenmesineetki eden kurumsal, sosyal, bireysel ve teknolojik faktörleri ve bu teknolojilerinyayılım ve özümsenmesinin yönetimsel karar verme süreçlerinin etkinlik, verimliklikve üretkenliği ile ilişkisini araştırmayı amaçlamaktadır. Bu alandaki teorik altyapı veönceki saha çalışmaları detaylı bir şekilde incelenerek BT yayılımı bağlamındabütünleşik bir araştırma modeli oluşturulmuş ve bu model, değişik kurumlardaçalışan bireyler üzerinde yapılan bir anket çalışması aracılığıyla test edilmiştir.Bulgular, değişik bilgi teknolojilerinin kurum içi yayılım ve bireyler tarafındanözümsenme süreçleri üzerinde değişik faktörlerin etkili olduğunu göstermektedir.","In today?s rapidly changing competitive environment, Information Technology(IT) within an organization is continuously improved, driven by the external push oftechnological advances and internal pull of increasing organizational needs. In orderto achieve the greatest return on IT investment, the diffusion process of IT within theorganization should be examined carefully. This study aims to explore the effects oforganizational, social, individual and technological characteristics on the diffusionand infusion of different information technologies within organizations, and todiscover the relationship between the diffusion and infusion of these technologiesand the effectiveness, efficiency and productivity of managerial decision makingprocesses. Based on a thorough review of theoretical background and prior empiricalstudies in the area, an integrated research framework concerning IT diffusion contexthas been developed and tested via a survey applied on individuals from differentorganizations. Findings suggest that the antecedents of the diffusion and infusionpatterns vary for different types of information technologies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma çoklu-etmenli otonom robotların fabrika tarzı üretim birimlerindekullanımı ve alternatif uygulama detaylarını gözlemlemek amacı taşımaktadır.Çoklu-etmenli otonom robotların üretim tesislerinde kullanımı halen bu tesislerdemalzeme taşıma işlerinde kullanılan Otomatik Güdümlü Araç (OGA) sistemlerinin mevcutbazı darboğazlarını aşabilmeyi hedeflemektedir. Çoklu-etmenli otonom robotlar, robotikaraştırmaları alanında güncel bir araştırma konusudur.Çoklu-etmenli otonom robotlar, OGA sistemlerinden farklı olarak sabit bir hat, yahutsabit vericiler kullanılmadan kendi rotalarını çizerek yükleme ve boşalma noktalarıarasında daha liberal bir biçimde hareket edeceklerdir. Üretim ortamındaki hareketlilikOGA sistemlerinin sık sık yolunun kesilmesine yahut bu alanların başka işler içinkullanılamamasına yol açmaktadır. Sabit engellerin yahut dinamik engeller olan işçilerinrotayı kesecek biçimde yer değiştirmesi durumunda robotlar kaçınma manevraları yaparakyollarına devam edebilecekler yahut yeni bir rota saptayabileceklerdir. Bu durum dahaesnek bir üretim yapılanmasına da olanak sağlayabilecektir.Ortamı modelleyebilmek için üç boyutlu simülasyon programı Webots, hem grafikarayüzü hem de C, C++ ve Java programlamasına uygun birimleri ile, çeşitli üretim ortamıyerleşimleri, değişik robotik elemanların denenmesi ile robot mimarisi ve farklı yol bulmave görev atama stratejilerinin uygulanmasına uygun bir test ortamı oluşturmadakullanılacaktır. Yapılan çalışmalarda, robotlar ve üretim ortamı modellenmiş veprogramlanmıştır. Yapılan simülasyonların sonuçları değerlendirilerek önerilen sisteminesnek üretime tepkiselliği değerlendirilmiştir.Simülasyon programını çalıştırmak için gerekli dosya ve talimatlar tezin arka kapağıiçindeki ek CD'dedir. Ek CD'nin içeriği ve kullanımına ilişkin bilgi ise Read.Me metindosyasındadır.","In this study we aim to observe the usage of multi-agent autonomous robots inindustrial facilities and the related alternative application details of this usage.The purpose of the utilization of multi-agent autonomous robots in manufacturingplants is to pass over the bottlenecks existing in the usage of Automated Guided Vehicle(AGV) systems, which are being used in transportation of materials in such systems.Multi-agent autonomous robots are a current research issue in the field of robotics.Unlike AGV systems, determining their routes without using fixed transmitters,autonomous robots will be able to move liberally between loading and unloading points.Mobility in manufacturing environment very frequently causes the blockage of the route ofAGV systems or gives way to the impossibility of using such environment for otheractivities. In case of interruption of paths by fixed obstacles or dynamic obstaclesdescribed as workers, robots will be able to continue towards their targeted destinationeither by maneuvers of avoidance or by determining a new route. Consequently thissituation will provide a new facility for a more flexible manufacturing.For modeling the environment in our study, we have applied Webots, a 3-Dsimulation program that, both with its graphical interface and its C, C++ and Javaprogramming units, is used to create a test environment for the applications of units,various production environment layouts, robotic elements trials, robot architecture anddifferent path planning and task assignment strategies. In our studies, robots andproduction environment have been modeled and programmed. Conclusions of simulationshave all been evaluated to measure the proposed system?s responsiveness to flexiblemanufacturing.The files and instructions necessary to run the simulation program are available in theappendix CD which is attached inside the back cover of the thesis. Information related tothe content and usage of the appendix CD is in the Read.Me text file."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde sanal gerçeklik ve haptik uygulamalar için üçgenlerden olusan nesnelerin.sekizli-agaçlarla bölümlenmesine dayanan bir yap sunulmaktadr.Sekizli-agaçlarn verimli bir biçimde olusturulabilmesi için Minkowski toplamna.dayal bir yöntem gelistirilmistir. Minkowski toplamlarnn hesaplanmas düzlemlerin. .yerlerinin 3 boyutlu uzayda geometrik olarak dogrudan ötelenmesiyle saglanmaktadr.Yaknlk sorgularnn degerlendirilmesi için yaknlk sekizli-agac ad verilen yenibir veri yaps sunulmaktadr. Bu veri yaps araclgyla dsbükey bir nesnenin ge-.ometrik bilesenleri arasndan, belirli bir noktaya en yaknda olanlarnn izlenmesine.yönelik bir teknik gelistirilmis ve bu yöntem haptik bir uygulama için denenmistir.. . .hemele hümele ve de vd vd...",This thesis presents a framework based on spatial subdivision of triangular meshobjects with octrees for virtual reality and haptic applications.For ecient generation of octree representations a method based on Minkowskisums is developed. The calculation of Minkowski sums is achieved geometrically bydirect manipulation of planes in 3D-space.For the evaluation of proximity queries a new data structure called the proximityis introduced. A technique for tracking of geometric features of convex objectsoctreethat are in close proximity to a specic point of interest is developed and tested for anumber of applications including haptic interaction.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde bir takım üğrenme algoritmalarının şocukluk düneminde gürülen küşuk,og c o ou uc üyuvarlak, mavi hücreli tümürleri, gen proï¬llerine dayanarak, sınıï¬andırmau uo ve teşhisskoymadaki başarıları incelenmektedir. Tümür biyopsi materyali ve kültür hücrelerindens uo uu uoluşan numuneleri gen proï¬llerine dayanarak sınıï¬andırmadan ünce problemin boyutus okücultülmüştür. Boyut küşultme korelasyon tabanlı parametre seşimini takip edenuşü u us u uc ü ctemel bileşenler analizinden oluşan iki basamaklı bir işlem aracılığıyla gerşekleştirilmiştir.s s s g c s sNumuneleri sınıï¬andırmak uzere mantıksal model ağaşları ve de şok katmanlı yapayü gc csinir ağları eğitilmiştir. Her bir numune işin yapay sinir ağlarından ve mantıksal modelg g s c gağaşlarından elde edilen sınıf olasılıkları kullanılarak modelin yaptığı sınıï¬andırmayagc gparalel bir teşhis konulup konulmayacağını belirleyen bir kriter oluşturulmuştur.s g s s","The performance of certain machine learning algorithms in classiï¬cation anddiagnostic prediction of small round blue cell tumors (SRBCTs) of childhood is in-vestigated. Before classifying samples, including both tumor biopsy material and celllines, based on their gene expression proï¬les, dimensionality of the problem is reduced.Dimensionality reduction is achieved in a two-step procedure that includes correlation-based feature selection (CFS) followed by principal components analysis (PCA). Toclassify the samples into four distinct diagnostic categories, logistic model trees (LMT)and multilayer perceptrons (MLP) are trained. The posterior probabilities provided byLMT and MLP algorithms for each sample are then used to construct a measure, bymeans of which one might decide whether to classify a sample into one of the diagnosticcategories or to reject classifying."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, uş boyutlu (3B) bir yüz tanıma sistemi geliştirilmiştir. Onerilen tanıma sistemi 1) şakıştırma, 2) betimleme, 3) üznitelik şıkarma, ve 4) karar tümleştirme kısımlarından oluşmaktadır. Yaptığımız şalışmada bu kısımların herbiri incelenmiş, ve bu alt problemler işin yeni şüzümler sunulmuştur. Onerilen yüntemlerin her biri standart algoritmalar ile karşılaştırılmıştır. 3B yüzlerin karşılaştırılması ve benzerlik derecelerinin bulunması işin kayıtlama safhası ünemli bir yere sahiptir. Yaptığımız calışmada, yüzlerin ortalama bir yüz modeli kullanılarak şakıştırılması ünerilmiştir. Ortalama yüz modelinin kullanımı şakıştırma safhasının zamansal karmaşıklığını oldukşa azaltmaktadır. Hareketli bir yapıya sahip yüz yüzeylerinin şakıştırılması işin katı ve katı olmayan varsayımlara sahip iki farklı şakıştırma yüntemi ünerilmiştir. Yaptığımız tanıma ve doğrulama deneylerinde katı yüzey varsayımına dayalı Düngülü Yakın Nokta (DYN) yünteminin daha iyi sonuş verdiği gürülmüştür. Yüzlerin betimlenmesi işin nokta kümeleri, yüzey kıvrımları, ve derinlik imgeleri gibi şeşitli yüntemler denenmiştir.Her betimleme yüntemiyle uyumlu farklı üznitelik şıkarımları yapılmıştır.o o c sve FRGC yüz kütüphanerinde yapmış olduğumuz deneylerde, yüzey normallerinin veu uu s g ukıvrım doğrultularının daha iyi tanıma başarımına sahip oldukları güsterilmiştir. Tezdeg s o sayrıca, birden fazla tanıma algoritmasının kullanıldığı durumlarda, bu tanıyıcılarıngkarar seviyesinde birleştirilmesinin yararlı olduğu güsterilmiştir. Standart tümleştirmes go s u salgoritmalarına ek olarak, güvenilirliğe dayalı ve iki-seviyeli tümleştirme yüntemleriu g u s oügünerilmiştir. Oğrenme kümesinin az olduğu durumlarda güvenilirlik tabanlı yüntemin,o s u g u odiğer durumda ise iki-seviyeli tümleştirme yünteminin diğer yüntemlerden iyi tanımag u s o g obaşarımı güsterdiği güsterilmiştir. Tezde son olarak, yüzlerin yerel bülgelere ayrılaraks o go s u obetimlenmesi ile ilgili şalışmalar yapılmıştır. Yerel betimleme yüntemlerinin hem üznitelikcs s o oboyutlarında azalmayı sağladığı hem de yüz yüzeylerindeki yerel değişimlere karşı dahag g uu gs sdayanıklı olduğu ve büylece tanıma başarımını arttırdıkları güsterilmiştir.g o s o s","In this thesis, we attack the problem of identifying humans from their three di-mensional facial characteristics. For this purpose, a complete 3D face recognition sys-tem is developed. We divide the whole system into sub-processes. These sub-processescan be categorized as follows: 1) registration, 2) representation of faces, 3) extractionof discriminative features, and 4) fusion of matchers. For each module, we evaluate thestate-of-the art methods, and also propose novel ones. For the registration task, wepropose to use a generic face model which speeds up the correspondence establishmentprocess. We compare the beneï¬ts of rigid and non-rigid registration schemes using ageneric face model. In terms of face representation schemes, we implement a diverserange of approaches such as point clouds, curvature-based descriptors, and range im-ages. In relation to these, various feature extraction methods are used to determine thediscriminative facial features. We also propose to use local region-based representationschemes which may be advantageous in terms of both dimensionality reduction and fordetermining invariant regions under several facial variations. Finally, with the realiza-tion of diverse 3D face experts, we perform an in-depth analysis of decision-level fusionalgorithms. In addition to the evaluation of baseline fusion methods, we propose to usetwo novel fusion schemes where the ï¬rst one employs a conï¬dence-aided combinationapproach, and the second one implements a two-level serial integration method. Recog-nition simulations performed on the 3DRMA and the FRGC databases show that: 1)generic face template-based rigid registration of faces is better than the non-rigid vari-ant, 2) principal curvature directions and surface normals have better discriminativepower, 3) representing faces using local patch descriptors can both reduce the featuredimensionality and improve the identiï¬cation rate, and 4) conï¬dence-assisted fusionrules and serial two-stage fusion schemes have a potential to improve the accuracywhen compared to other decision-level fusion rules."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, Learn++ algoritması ile oluşturulmuş bir destek vektör makinesi (DVM)topluluğunun değişken (dinamik) bir ortamdaki sınıflandırma başarısı değerlendirilmiş vebu algoritmanın dinamik ortama uyum sağlayabilmesi için eski geçersiz bilgiyi unutmamekanizmasının kullanılması önerilmiştir.Birçok uygulamada, probleme ait veriler geniş bir zaman aralığında toplanır veverinin temelini oluşturan dağılım zaman içerisinde değişebilir. Bu da eski veri üzerindegerçeklenmiş olan modelin yeni veriler ile uyumsuz olmasına sebep olur ve bu durumdamodelin düzenli olarak güncellenmesi gerekmektedir. Dinamik bir ortamda önerilen birsınıflama modelinin başarılı olabilmesi için değişimin sınıflama modeli tarafından farkedilmesi ve modelin yeni ortama hızlı bir şekilde uyum sağlaması gerekir. Bu daoluşturulmuş olan modelin yeni örneklerle güncellenmesi ve eski geçersiz bilgininunutulmasıyla sağlanır.Learn++, sınıflayıcı topluluğu oluşturarak aşamalı öğrenmeyi sağlayan biralgoritmadır ve yeni bilgiye uyum sağlama, yeni bilgiyi öğrenme becerisine sahiptir.Dolayısıyla, geçersiz bilgileri unutmasını sağlayacak bir yöntem kullanılarak kolaycadinamik ortamlar için uyumlu hale dönüştürülebilir. Bu tezde Learn++ kullanılarakoluşturulmuş bir DVM topluluğunun dinamik ortamlara uyumlu hale getirilebilmesi içintopluluğu oluşturan sınıflayıcıların başarısını baz alan bir unutma yönteminin kullanılmasıöneriliyor. Tüm sınıflayıcılar içerisinde en başarılı K sınıflayıcı veya belli bir eşik değerüzerinde sınıflandırabilen sınıflayıcılar topluluk içerisinde tutularak bu sağlanmış oluyor.Sonuçlarımız gösteriyor ki, önerilen algoritma yavaş değişen ortamlarda, oluşturulanmodelin sınıflama başarısını artırmaktadır.","In this thesis, we evaluate the performance of support vector machines (SVM)ensemble, which is constructed by using Learn++ algorithm, on changing environment andpropose incorporating forgetting mechanism to adapt this algorithm to changingenvironment.In most of the real world applications, the data is collected over an extended periodof time and the distribution underlying the data is likely to change by time. These changesmake the model built on old data inconsistent with the new data, and regular updating ofthe model is necessary. For effective learning in a changing environment, the algorithmshould be able to detect context change and quickly adjust the hypothesis to the currentcontext. This can be achieved by revising the model by incorporating new examples andeliminating the effect of outdated concepts.Learn++ is an ensemble based incremental learning algorithm that is able to learnnew information. Therefore, it can be easily adapted to changing environments by using aforgetting mechanism to remove the redundant data from the ensemble. In this thesis, wepropose using a forgetting strategy that is based on the performance of the base classifiers.Only the best K classifiers or the classifiers whose classification performance exceeds athreshold value are kept in the ensemble.Our results indicate that incorporating forgetting mechanism improves theclassification performance of the proposed algorithm on a changing environment. Theproposed algorithm can effectively handle the gradual changes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezin konusu IEEE 802.15.4 standardı gibi düşuk data oranlı kablosuz kişiselus ü salan aËlarında güvenli bir grup anahtarı yünetimi şeması oluşturmaktır. letilen datanıng u o s shassas olduËu uygulamalarda, datanın güvenliËi kriptograï¬ teknikleri ile korunmalıdır.g u gGrup anahtarı bütün uyelere daËıtılır. Yeni uyeler dahil oldukşa veya eski uyeleruu ü g ü c üayrıldıkşa anahtar tekrar daËıtılır. Bu esnada güvenlik ve performans üzellikleri grupc g u oanahtarı yünetim algoritmalarıyla analiz edilir.oAlgoritma, uye olmayanların anahtarı elde etmesini veya tahmin etmesini en-ügelleyerek grup anahtarının güvenliËini saËlamalıdır. Algoritmanın performansı ise peku g gËşok faktüre dayanır. Ilk performans üzelliËi anahtarların hızla daËıtımını saËlayan algo-c o o g g gritma hızıdır. Kablosuz bileşenlerin işlem yapmalar güş harcamasına neden olur. Dahas s ucuzun pil ümrü ünemli olduËundan bu istenmeyen bir sonuştur. Standardın ihtiyaşlarınao uo g c cuygunluk ise başka bir performans faktürüdür.s ou uPerformans ve güvenlik üzelliklerine güre IEEE 802.15.4 aËları işin en iyi anahtaru o o g cyünetim algoritmasını bulmak uzere daha ünce ünerilmiş algoritmalar analiz edilipo ü o o ssonuşlar tartışılmıştır. Sonuşta var olan algoritmaların IEEE 802.15.4'ün ihtiyaşlarnac s s c u cuygun olmadıËı ortaya şıkmıştır. Bu nedenle üzellikle IEEE 802.15.4 standardı işing c s o curetilmiş bir grup anahtar yünetimi algoritması olan Hibrid Topoloji Grup Anatharü s oYünetimi Algoritması (HT-GKMA) ünerilmektedir.o o","This thesis concentrates on establishing a secure group key management schemein low data rate wireless personal area networks, namely IEEE 802.15.4 standard. Inapplications where the transmitted data in group communication is sensitive, security ofthe data should be provided using cryptographic techniques. Security and performanceaspects of group key management algorithms are analyzed while initially distributingthe group key to all members and redistributing the keys when a member joins orleaves the network.Security of a group key management means that the algorithm should not let thenon-group members to have or guess the group key, while performance of the algorithmdepends on many factors. First performance attribute is the speed of the algorithmfor fast distribution of keys in an eï¬cient way. Then, regarding that the wirelesscomponents? computations cause it to consume power, and this is an unwanted aï¬ect,less computational need is important. And ï¬nally, suitability to the standard?s needsis another key performance factor.In order to determine the most suitable key management scheme, which oï¬ersthe best security and performance to IEEE 802.15.4 networks, previously proposed keymanagement algorithms are analyzed and the results are discussed. This analysis showsthat the existing algorithms do not ï¬t IEEE 802.15.4?s needs, leading us to propose anew group key management algorithm especially designed for IEEE 802.15.4 networks,namely Hybrid Topology Group Key Management Algorithm (HT-GKMA)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Fiziksel bir dizgede değişkenlerin gelecekteki sayısal davranışı o dizge-gs sye ait adi diferansiyel denklem takımı tarafından belirlenir. Bu denklemtakımındaki sayısal büyüklüklerin kaldırılması ile elde edilen nitel diferansiyeluu udenklem sistemi ise adi denklem sisteminin yalnızca yapısını ifade eder. Birnitel denklem sistemi, dizgedeki değişkenlerin davranışlarının üngürülmesinings s o oudeğişkenlerin gelecekteki sayısal değerlerinin bulunmasından daha ünemligs g oolduğu durumlarda şok kullanışlıdır. Nitel denklem sistemleri aynı zamandag c snitel model olarak adlandırılır. Bir nitel modeldeki ilişkiler, değişkenlerdens gsbirisinin değerindeki bir değişimin dizgedeki diğer değişkenleri nasıl etkileye-g gs g gsceğini incelemek işin kullanılabilir. Diğer bir deyişle, nitel modeller diz-g c g sgenin bizce güzlemlenen davranışına neden olan arkaplandaki mekanizmanıno sanlaşılmasına yardımcı olurlar.sNitel modelleri sıfırdan yazmak kolay değildir ve alanında bilgi sahibi birguzman tarafından yapılması gerekir. Nitel modellerin güzlemlerden otomatikoolarak üğrenilmesi daha da zordur ve otomatik üğrenme alanındaki problem-og oglerden bir tanesidir. Tezde bu problemin şüzümüne yünelik olarak LYQUIDco u u oadı verilen bir algoritma ünerilmektedir. Algoritma güzlemlenmiş sayısalo o sürneklerin uzerine polinom eğriler oturtarak ürnekleri oluşturan gerşek fonksi-o ü g o s cyonlara yaklaşıklıklar bulmaktadır; değişkenler arasındaki nitel ilişkilerin bu-s gs slunmasında ise esas ürnekler yerine bu polinomlar kullanılır. LYQUID'inoyazındaki denektaşı problemleri uzerinde başarılı sonuşlar veren, hızlı ves ü s cgürültüye toleransı yüksek olan bir algoritma olduğu güsterilmiştir. Algo-uu u u go sritma, ürneklemenin nasıl yapıldığı ile ilgili kısıtlamaları kaldırmanın ütesindeo g odeğişkenlerin belli zaman aralıklarında ürneklenmediği durumlarda da başarılıgs o g solabilmektedir.1","The set of ordinary diï¬erential equations (ODE) of a physical system de-termines the precise numerical behavior that will be exhibited in the future.Abstracting an ODE into a qualitative diï¬erential equation (QDE) systemremoves all quantities from the equations and leaves only the structure of theequation system intact. However, a QDE is still very useful in anticipatingthe future when the qualitative behavior of the system is important ratherthan the exact numerical solution. Another name for a QDE is a qualitativemodel. Qualitative relationships make up a qualitative model and it is possi-ble to analyze how a change in one of the variables in the system aï¬ects theother variables using these relationships. In other words, qualitative modelshelp us understand the underlying mechanism which determines the behaviorthat we observe.Writing qualitative models from scratch is a diï¬cult problem which needsto be done by an intelligent expert with domain speciï¬c knowledge. Automat-ing the discovery of qualitative models from observations is a diï¬cult problemof machine learning. Various algorithms have been proposed for the solutionof this problem in the literature. This thesis presents a new algorithm calledLYQUID for the solution of the same problem. The algorithm uses polyno-mials ï¬tted on observed numerical data as approximations to the underlyingreal world functions; discovery of qualitative relationships is then performedover those polynomials rather than the original data samples. LYQUID isshown to be a fast and successful learning algorithm which performs verywell on benchmark models and tolerates high levels of noise. The algorithmnot only relaxes the restrictions over how the data are sampled but it is alsocapable of working with missing data.1"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada az zaman harcayan ve yüksek başarı oranları ortaya koyan spam e-posta filtreleme yöntemleri öneriyoruz. Yöntemler n-gram yaklaşımıyla birlikteönerdiğimiz ilk n-kelime tekniğini kullanmaktadırlar. Her ne kadar yöntemler Türkçe içindüşünülse de ngilizce e-posta mesajlarına da uygulanmıştır. Kaynak veriler her iki dil içinde derlenmiş ve testler farklı parametrelerle bu iki dil için gerçekleştirilmiştir. Türkçemesajlar için başarı oranı %95'in üzerindedir, ngilizce mesajlarda ise başarı %98'lereulaşmıştır. Daha da önemlisi, yöntemlerin harcadığı zamanın başarıdan ödün vermedenönemli miktarlarda azaltılmış olmasıdır.Aynı zamanda yukarıda önerilen yöntemleri temel alan birleşik algı katkısı (CPR)modelini ortaya koyduk. Bu model iki aşamalı olup temel başarı oranlarını %2 civarındaartırmıştır. Ek olarak Türkçe dilinin cümlelerdeki serbest kelime düzeni özelliğinin etkisiniçalışmamıza dahil ettik.","In the present thesis, we propose spam e-mail filtering methods having highaccuracies and low time complexities. The methods are based on the n-gram approach anda heuristics which is referred to as the first n-words heuristics. Though the main concern ofthe research is studying the applicability of these methods on Turkish e-mails, they werealso applied to English e-mails. A data set for both languages was compiled. Tests wereperformed with different parameters. Success rates above 95% for Turkish e-mails andaround 98% for English e-mails were obtained. In addition, it has been shown that the timecomplexities can be reduced significantly without sacrificing from success.We also propose a combined perception refinement (CPR) which improves baselinesuccess rates around 2%, where development set is used in the first step of the CPR to findout the parameters used in the second step. Free word order is another characteristic ofTurkish language; we will make an attempt to implement free word order aspect ofTurkish."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz iletişim alanında olduğu kadar konum bulma teknolojilerinde de yaşananhızlı gelişmeler sayesinde, hareketli nesneler kavramı gittikçe önem kazanmaktadır.Hareketli Nesne Veritabanı (Moving Object Databases - MOD) sistemleri, birçok alandagiderek artan bir ilgiye sahip olan konum tabanlı hizmetlerde yaygın olarak kullanılmayabaşlanmıştır. Literatürde, hareketli nesne veritabanı sistemlerine ilişkin en yakın komşuyubulma, karşıt en yakın komşuyu bulma, k - en yakın komşuyu bulma gibi birçok sorgulamaçeşidi mevcuttur. Bunlardan farklı olarak, bu tez çalışmasında, hareketli nesne veritabanısistemleri için bir sorgulama tipi olarak yeni bir operatör önerilmiş ve olası bir uygulamasıüzerinde durulmuştur. Önerilen atama operatörünün amacı, literatürde ağırlıklı iki parçalıeşleştirme olarak da bilinen atama problemini çözmektir. Özetle, amaç, iki nesne kümesiarasında maliyeti en aza indirecek olan kusursuz atamayı bulabilmektir. Örneğin, bir grupmüşterinin bir grup taksiye en az maliyetli olacak şekilde atanması gibi.Hareketli nesne veritabanı sistemi üzerinde çalışıyor olmamız dolayısıyla, problemeverimli bir çözüm üretebilmek için kullanıcı sorgularına gerçek zamana yakın şekildecevap verilmesi gerekmektedir. Ancak, en az maliyetli genel iki parçalı eşleştirmeprobleminin zaman karmaşıklığının O(N^3) olduğu bilinmektedir. Bu yüzden, problemeilişkin bilinen klasik çözüm yöntemlerinin hareketli nesne veritabanı sistemlerindekullanılması mantıksız olacaktır. Bu çalışmada, mantıklı bir zaman dilimi içerisinde yanıtverebilecek bir atama operatörü önerilmiştir. Ayrıca, hareketli nesne veritabanısistemlerindeki yoğun güncelleme yükünü karşılayabilecek bir Q+R ağaç indekslemeyapısından yararlanılmıştır. Son olarak, önerdiğimiz çözümün verimini artırabilecekperformans konuları üzerinde durularak uygulamamızın hareketli ortamdaki birkullanıcının isteklerini karşılayabilecek zaman karmaşıklığına sahip olduğunu gösterdik.","With the rapid development of wireless communications as well as positioningtechnologies, the concept of moving objects has become more and more important.Moving Objects Databases (MOD) are being used in a wide range of location basedservices that are of growing interest in many application areas. In the literature, severalqueries such as nearest neighbor, reverse nearest neighbor, k-nearest neighbor, proximityqueries etc. have been considered in moving object databases. Differently from these, inthis thesis, a novel operator is proposed as a query type for moving object databases, andalso a possible implementation is presented. The aim of the proposed assignment query isto solve the assignment problem, which is also known as weighted bipartite matching. Inshort, our objective is to find a perfect matching between two set of objects in a mannerthat minimizes the total cost. For instance, a set of people is to be assigned to a set of taxi-cabs with minimal total travel time.On the other hand, working with moving object databases, we have to give near real-time responses to user queries to provide an efficient solution for the problem.Unfortunately, the problem of finding a minimal-cost matching for a general bipartitegraph is known to have an O(N^3) time algorithm. Thus, we realized that classicalsolutions having a time complexity of O(N^3) become infeasible for this type of movingobject database application. In this thesis, we propose an assignment query that responds ina reasonable time period for MOD. Furthermore, we employ a Q+Rtree index structure tocope with the high update and querying overhead of MOD. At the end, we discussed theperformance issues to improve efficiency and showed that the time complexity of ourapplication meets the needs of users in mobile environment."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, gürültülü algısal veri durumunda parşa taşıma problemi ele alınmıştır.u u uu c s sBu senaryoda, iki boyutlu calışma ortamında hareket edebilen bir robot ve hareketşsyeteneËi olmayan parşalar vardır.g c Robot ve parşaların gerşek ile ülşulen konum-c c o cüüları arasındaki fark sarsıntılı harekete veya carpışmalara yol aşabilmektedir. Oncekiş s ccalışmadan farklı olarak, algısal verinin artık tam doËru olmadıËı kabul edilmektedir.şs g gDolayısıyla robotun durum bilgisine yüksek doËrusal olmayan yapısını dikkate alaraku gyaklaşıklaması gerekmektedir.s Bu parşacık süzgeşler kullanılmasıyla başarılmıştır.c uc s sParşacık süzgeşler doËrusal olmayan ve/veya Gauss olmayan ortamlarda Bayes süzgecinic uc g uyinelemeli olarak gerşekler. Parşaların modeli doËrusal olduËundan, yaklaşım Kalmanc c g g sËsüzegece şevrilir. Ilk olarak, robotun dinamik ve olşum modeli belirsizlikle birleştirilir.u c ü cü sSonra, parşacık süzgeş kullanılarak konumsal kestirimde iyileştirme yapılır. Robotunc uc shareketindeki iyileşmeler ve şarpışma sayısındaki azalma kapsamlı bilgisayar benze-s c stimleri ile doËrulanmıştır. Başarımın kuramsal deËerlendirmesi Cramer-Rao alt sınırıg s s gkullanılarak yapılmıştır. EDAR ile yapılan deneyler sistemin gerşek zaman başarımınas c sışık tutmuştur.s s","This thesis adresses the parts? moving problem under noisy sensory information.In this scenario, a 2D workspace contains an actuated robot and a set of unactuatedparts. The discrepancy between the robot?s and/or the parts? real and measured posi-tions may lead to jerky movements or even collisions in the parts? moving problem weare concerned with. In contrast to previous work, sensory data is no longer assumedto be perfect. Hence the robot needs to approximate state information, taking itshighly nonlinear nature into account. It accomplishes this using particle ï¬lters, whichimplement a recursive Bayesian ï¬lter in nonlinear and/or nongaussian environments.For the model of parts which turns out to be linear, the approach reduces to Kalmanï¬ltering. First the robot?s dynamic model and the measurement model are modiï¬ed toincorporate the inaccuracies in the sensory data; and then the particle ï¬lter is utilizedto get improved positional estimates. Enhancements in the robot?s movements andreduction in the number of collisions have been veriï¬ed through extensive computersimulations. An evaluation of its theoretical performance is presented based on theCramer-Rao lower bound. Finally, a series of experiments with EDAR provide insightinto real-time performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez şalışmasında, iki katmanlı bir uydu sisteminde, ağın o anki durumu dikkatecs galınarak yapılan yeni bir yünlendirme mekanizması tanıtılmaktadır. Uydu sistem-olerinde, sağlanan servislerin gereksinimlerine ve üzelliklerine güre değişik yürüngede uy-g o o gs oudular kullanılabilir. Yerdurağan uydu (GEO) sistemleri uştan uca 250-270 ms gecikmeg cdeğerlerinden dolayı VoIP (Internet Protokolü uzerinden ses aktarımı) servisleri işing uü celverişli değildir. Alşak yürünge uyduları (LEO) ve orta yürünge uydularından (MEO)s g c ou ouoluşan yerdurağan olmayan uydu (NGEO) sistemleri VoIP uygulamalarının gereksin-s gimlerini karşılayabilirler. Bununla birlikte, LEO ve MEO uydulardan oluşan iki kat-s smanlı bir sistem, tek katmanlı uydu sistemlerinden daha iyi başarım sonuşları vere-s cbilir. Ancak bu sistemlerin dinamik bir topolojiye sahip olmaları ve Dünya uzerindeu üdüzenli bir traï¬k dağılımının olmaması gibi sebeplerden dolayı, karasal paket tabanlıu gsistemlerde kullanılan yünlendirme protokollerinin kullanılması uygun değildir. ARPQo golarak adlandırılan ünerdiğimiz yünlendirme mekanizması, LEO ve MEO katmanlarıo g ouzerinde yük dağılımı yaparak, bazı ana noktalarda sıkışmanın ünlenmesini ve tümü u g s o uağ uzerindeki kanalların verimli bir şekilde kullanılmasını sağlar. Ayrıca, gecikme vegü s ggecikmedeki değişime duyarlı olan traï¬k (VoIP), uydularda kuyruklama gecikmesinigsazaltacak şekilde üncelikli olarak işlenir. Ceşitli benzetim şalışmaları ile, ünerdiğimizs o s şs cs o guyarlamalı yünlendirme mekanizmasının, uyarlamalı olmayan yünlendirme mekaniz-o omalarından daha iyi başarım değerlerine sahip olduğunu ve dolayısı ile VoIP uygula-s g gmaları işin elverişli olduğunu güsterdik.c s g o","In this thesis study, an adaptive routing policy utilizing the real-time network informa-tion of a two-layered satellite network is introduced. In a satellite network, dependingon the requirements and properties of services provided, various kinds of satellites fromdiï¬erent orbits can be employed. Geostationary Earth Orbit (GEO) systems are notsuitable for Voice over Internet Protocol (VoIP) applications due to long end-to-enddelay values about 250-270 ms. Non-Geostationary Earth Orbit (NGEO) systems con-sisting of Low Earth Orbit (LEO) and Medium Earth Orbit (MEO) satellites can satisfythe performance requirements of VoIP applications. Moreover, a two-layered system ofLEOs and MEOs can outperform single plane satellite networks. However, due to thedynamic topology of these networks and nonuniform traï¬c distribution over the Earth,terrestrial packet based routing algorithms cannot perform well. The proposed routingscheme dubbed as ?Adaptive Routing Protocol for Quality of Service? (ARPQ) pre-vents the congestion on some bottleneck links by distributing the traï¬c over the entirenetwork. Furthermore, link capacities can be eï¬ciently used. Additionally, delay andjitter sensitive voice traï¬c is processed in a prioritized way to prevent long queueingdelays. By a set of simulations, we showed that proposed mechanism performs betterthan nonadaptive routing mechanisms and therefore can enable VoIP applications oversatellite networks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, müzelerde tur rehberi olarak, gelen ziyaretçilere yön gösterebilen,onlarla konuşabilen, sergilenen eserler hakkında bilgi verebilen, otonom, hareketli,sosyal, bir robot için gerekli donanım ve yazılımın tasarımını yapmak ve yapılan butasarım doğrultusunda üç boyutlu benzetimi gerçekleştirmek amaçlanmıştır. Butasarım olabildiğince gerçekçi olmalı, robotun sahip olması gereken hareketmekanizması, algılıyıcıları, aküsü, motorları, vücut yapısı, kontrol mimarisi, robotunyapması gerekenler doğrultusunda, ortaya konmalıdır ve bunların uygunluğu testedilmelidir. Üretici firmaların yayınladığı bilgiler doğrultusunda tasarımı yapılanrobotun kontrolü için tepkisel robot mimarisi ve bulanık mantık kullanılmıştır. Dörtfarklı davranış, hedefe yönelme, engelden sakınma, insanla konuşma ve takipçileriyönlendirme davranışları tanımlanmış ve üç boyutlu modellenen ortamda testedilmiş, yapılan tasarımın ve geliştirilen kontrol programının yeterli olduğugösterilmiştir. Test ortamı için gerçek müze ortamı ve çoklu etmenlerinmodellenmeside yapılmıştır.","This thesis aims at building a realistic design of a fully autonomous socialmobile robot act as a tour guide to the visitors in museums and that can giveinformation about the museum and the exhibits. It should define all the parts robotneed such as locomotion mechanism, sensors, batteries, motors, body, controlalgorithms and methods required to accomplish its objective. Three dimensionalmodeling of the robot according to this design, building a virtual museum anddynamic agents, based on a real museum, in a simulation environment for furtherresearch and progress are also accomplished. Also, to verify the design, a fuzzycontroller based on a layered behavior-based approach, has developed to control therobot. The behaviors used by the robot include going to target point, avoidingobstacle, avoiding human in front of it by speaking and waiting the visitors behindwho are following him."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz iletişim ve elektronik teknolojilerindeki gelişmeler düşük masraflıkablosuz algılayıcı ağların yapımına imkan tanıdı. Algılayıcı ağların sağlık, askeri, ev vetarım, çevresel izleme gibi birçok uygulama alanı vardır. Algılayıcılar ucuz olmak zorundaolduklarından kısıtlı pil kaynakları vardır ve algılayıcı ağın çalışma ömrü büyük ölçüdeenerji tasarrufuna bağımlıdır. Uygun yönlendirme protokolleri tasarımlamak, enerjitasarrufu yapmanın etkin bir yoludur. Bu yüksek lisans tezinde, özellikle çok sayıdaalgılayıcı içeren ağlar için klasik yönlendirme protokollerine göre daha çok enerji tasarrufuyapıp ağ ömrünü uzatan yönlendirme protokolleri önerip detaylandıracağız.","Developments in wireless communications and electronics have made designinglow-cost sensor networks possible. The sensor networks have many application areas suchas health, military, home, agriculture, environmental. Because each sensor has to be low-cost, they have very limited battery and lifetime of the network depends heavily on savingenergy. One way of saving energy is designing appropriate routing protocols. In this thesis,we propose some new routing protocols that save more energy and increase the networklifetime comparing to the classical protocols especially in networks with a large number ofsensors."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu şalışmanın amacı Girdi-Cıktı Saklı Markov Modelleri kullanarak hem hareketcs şhem şekil değişimi işeren uş boyutlu el hareketlerini stereo gürüntüler uzerinden gerşeks gs c üc ou u ü cüzamanlı olarak tanıyacak bir etkileşimli arayüz geliştirmektir. Onerilen sistem kul-s u slanıcıların hem manipülatif hem haberleşmeye yünelik doğal el hareketleriyle PC uygu-u s o glamalarını kontrol etmelerini sağlayacak şekilde tasarlanmıştır. Bu iki tip el hareketig s ssistem tarafından gerşek zamanlı olarak ayırdedilebilmektedir. Uygulama, etkileşimlic shareket eğitimi ve kamera kalibrasyonu işin birer yazılım aracı da işerir. Eli ayırdetmekg c cişin kullanılan renkli eldivenler her renk olabilir, ve el ayırdetme problemini basitleşti-c srerek tanıma başarısını arttırırlar.süOnerilen sistemde elleri modellemek işin el şekli üzniteliği olarak Hu momentleric s o gve elin aşısı kullanıldı. Yeni bir yaklaşım olarak düzgelenmiş zaman bilgisinin Girdi-c s u sCıktı Saklı Markov Modellere girdi olarak verilmesinin bu modellerin saklı durumlarınınşsürekli bir yapı kazanması sağlandı ve bunun el şekli tanımadaki başarı oranını arttırdığıu g s s ggüsterildi. Ayrıca Girdi-Cıktı Saklı Markov Modelleri uzerine kurulu tanıma sistemlerio ş üişin tanımlı el şekillerini tanımsız hareketlerden ayıracak yeni bir uyarlanır eşik modelic s stasarlandı.üOnerilen sistem farklı hareketler işeren on şekilden oluşan ve aynı hareketleric s spaylaşan on cift el hareketinden oluşan iki ayrı el şekli veritabanı uzerinde test edil-s ş s s üvimiştir. Sistem ilk veritabanı uzerinde 2885 denemede 97.6%, ikinci veritabanında ises ü8675 denemede 94.1% tanıma başarı oranı güstermiştir. Bu oranlar uyarlanır eşiks o s smodeli ile sürekli bir girdi uzerinden tanıma yapıldığında ilk veritabanı işin 97.1%,u ü g cikinci veritabanı işinse 93.8% cıkmıştır.c ş s","This study focuses on the application of Input-Output Hidden Markov Models(IOHMM) to the recognition of 3D hand gestures that involve both hand motion andhand posture in a stereo vision-based approach. The proposed system is designed as areal time gestural interface that allows both communicative and manipulative gesturesto control target PC applications. The system allows training of new communicativegestures and automatically distinguishes these from manipulative gestures in continu-ous streams. Uniquely colored gloves with no preset colors are used as markers, whichincreases the recognition rate and simpliï¬es the hand localization problem. Cameracalibration and gesture training tools are provided with the system.The hand shape is modeled with Hu moments and the angle of the hand. Asa novel approach the inclusion of normalized time information as an input to theIOHMMs is proposed, which has the eï¬ect of a continuous state variable and is shownto handle temporal information better. Another novel method is proposed for gesturespotting in IOHMM-based frameworks, which distinguishes the meaningful gestures ina continuous input stream in real time using a threshold model with a single hiddenstate.The system is tested on two datasets that have 10 gestures with distinct trajecto-ries, and 20 gestures in 10 pairs that share the same trajectories. The proposed systemivis able to attain a recognition rate of 97.6% on the former dataset in 2885 trials, and arecognition rate of 94.1% on the latter dataset in 8675 trials. The gesture segmentationtest results for the same datasets with the inclusion of the proposed threshold modelare 97.1% for the former and 93.8% for the latter dataset."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu şalısma, Bridgestone ï¬rmasının urettiËi, motor ve kauşuk eyleyicilerdenc. ü g colusan bir robot kolunun denetimini işin, geri yayılım yapay sinir aËları,bulanık mantıkc g.ve genetik algoritmaları gibi esnek yüntemlerin, kullanımını kapsamaktadır.oRobot kolunun, uş islevcisinin şalısma alanı küşuk parşalara ayrılıp, her birc. c. uc ü cparşanın, yürüngeden baËımsız parametreleri, küşuk yapay sinir aËları kullanılarakc ou g uc ü güËrenilmistir. Bu kücuk yapay sinir aËlarının yapısı, robot kolunun Langrage - Eulerog uşü g.mekaniËine dayanmaktadır. Bu yapay sinir aËları arasında sürekliliËi saËlayabilmekg g u g gişin, uyelik fonksiyonu deËiskenleri, genetik algoritmalarla eniyilenmis basit bir bu-c ü g. .lanık mantık yüntemi kullanılmıstır. Yürünge izlemede, ünerilen yüntemin performansı,o ou o o.sadece yapay sinir aËlarından olusan denetleyicinin performansından daha iyi olduËug g.güsterilmistir.o .Bu şalısmanın asıl amacı, kücuk yapay sinir aËları( 3 düËum ve bir gizli katman-c. uşü g ug üdan olusan) ve minimum sayıda dilbilimsel deËiskenler ve kuralları olan bulanık mantıkg..ile, kauşuk eyleyiciler uzerinde, iyi bir şevrimdısı denetim sistemi gelistirmektir.DiËerc ü c g. .taraftan,daha iyi bir şevrimdısı denetiminin bulunması, gelecekte kullanılacak şevrimişic c c.denetiminde, daha kücuk üËrenme katsayısı kullanılabilmesini saËlayacaktır ve bu da,uş ü o g gıraksama ve kararsızlık ihtimalini azaltacaktır.","This study presents a combination of soft computing techniques, namely backpropagation neural network, fuzzy and genetic algorithms that are used to control theBridgestone Hybrid Robot Arm (BHRA).The workspace of the BHRA?s end eï¬ector is divided into small segments and thetrajectory independent parameters of all these segments are learned by training smallsize (only three nodes) neural networks for each segment. The structure of these neuralnetworks is based on the physical model, which is derived from the Language-Eulermechanics of the robot arm. To maintain continuity on the small neural networks, weuse a basic fuzzy algorithm whose fuzzy membership function parameters are optimizedby genetic algorithm (GA). The proposed technique?s performance was compared withonly-neural network controller and shown to be more accurate in trajectory control forrubbertuator robots.The main goal of this study is to maintain a better oï¬-line control on the rubber-tuators by using only small size (3 nodes and one hidden layer) neural networks and asimple fuzzy algorithm with minimal linguistic variables and minimal number of rules.On the other hand, ï¬nding a better oï¬-line control ensures that small learning rateswill be suï¬cient for future on-line training control, and choosing small learning rateswill decrease the prospect of divergence and the risk of instability in control."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım mühendisliğinde, asıl amaç limitli zaman planı ve bütçe ile istenilensonuçları veren projeler üretebilmektir. Bir projenin bütçesini etkileyen bir çok faktörvardır. Bunlardan en önemlisi bir proje üzerinde harcanan efordur ve bu efor proje üzerindeçalışan geliştirici, yönetici ve mimarları da kapsar. Eforu tahmin etmek ise önemlidir çünkübir projeye fazladan insan atamak gelir kaybına yol açacağı gibi gereğinden az insanıatamak ürünün bitirilmesinde gecikmeye yol açacaktır. Zaman planı ve bütçeyi dengelemekiçin, efor değerinin önceden belirlenmesi gerekir. Yazılım firmaları genelde gerekli eforutahmin etmek için uzman yargısını kullanırlar, ancak tatmin edici sonuçlar almaktanuzaktadırlar.Bu araştırmanın asıl amacı bütçe ve zaman planı aşımlarına bağlı problemlerinüzerinden gelmek için yazılım efor tahmininin bir analizini gerçekleştirmektir. Bizimsunduğumuz çözüm hem yazılım mühendisliğinde efor ve fiyat tahminine farklı bir bakışaçısı getirmekte hem de yazılım efor tahmini sürecini geliştirmeye çalışmakatdır. Eğeruygulayıcılar daha doğru efor tahminlerine sahip olurlarsa ilgili riskleri yönetebilirler ve burisklere bağlı ortaya çıkabilecek zararları önceden önleyebilirler.Biz, yazılım projelerinde daha iyi fiyat ve efor tahminleri için çok katmanlıperseptron, radyal taban fonksiyonları, karar ağaçları ve destek vektör makinaları gibimakina öğrenme yöntemlerini kullanarak bir model önerdik. Bu modele girdi olarakkullanılacak metric veriyi NASA, USC gibi üçüncü partilerden ve Türkiye' deki farklıyazılım firmalarından topladık.","In software engineering, the main aim is to develop projects that produce the desiredresults within limited schedule and budget. There are many factors that affect the budget ofa project. The most important factor that is affecting the budget of a project is effort whichincludes the developers, managers, and architects working on a project. Estimating effort iscrucial since hiring more people than actually needed leads to loss of income and likewisehiring less people than actually needed leads to delay in product delivery. To balanceschedule and budget, the effort needs to be correctly predetermined. In softwareengineering this problem is called as effort estimation problem. Software companiesusually use expert judgment to estimate the required effort, however, they are far fromgetting satisfactory results.The main objective of this research is making an analysis of software effortestimation to overcome problems related to budget and schedule overruns. Our proposedsolution not only brings another point of view into software engineering cost and effortestimation but it also tries to improve the software effort estimation process. If practitionershave more accurate estimations then they would be able to manage risks and prevent anylosses that may have occurred due to these risks.We have proposed a model that uses machine learning methods such as MultilayerPeceptrons, Radial Basis Functions, Decision Trees, Support Vector Machines andPrincipal Components Analysis for a better cost and effort estimation in softwaredevelopment projects. We have obtained the metric data that is used as an input to thesemethods from third parties such as National Aeronautics and Space Administration(NASA) and University of South California (USC) and various projects from softwaredevelopment organizations in Turkey."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Telsiz algılayıcı ağlar, veri aktarımı ve algılama gibi işlemleri işbirliği içinde gerçekleştirenküçük algılayıcı düğümlerinden oluşur. Algılayıcı ağlar, kolay konumlandırılmaları, kendikendine organize olabilmeleri, düşük maliyetleri ve geniş uygulama alanlarından dolayıyaygınlaşmaktadır. Bahsedilen geniş uygulama alanları, algılayıcı ağların tasarımı sırasındauygulamalara özel bir takım sorunları da beraberinde getirmektedir. Ancak literatürde var olançoğu çözüm, bir yandan düzlemsel alanlarda gerçekleşen mesafe tabanlı algılama ve iki boyutlubir haberleşme modelini temel alırken, bir yandan da normalde erişilmez arazilerde gerçekleşenrastgele konumlandırma senaryosunu temel almaktadırlar.Bu çalışma algılayıcı ağlarına gerçekçi bir modelleme ortamı dahil edilmesini içerir.Motivasyonumuz, algılayıcı ağların performans değerlendirmeleri sırasında, topografikdüzlemlerin etkilerinin hesaba katılmaması gibi gerçek dışı varsayımlardır. İşbirliği içindegerçekleşen bir hedef izleme uygulamasına üç boyutlu bir arazi modeli dahil edilmiştir. Algılayıcıağların yapay olarak yaratılmış arazilerdeki performans değerlendirmesinde üç metrik hesabakatılmıştır; hedef takibindeki ortalama hata, haberleşen algılayıcı çifti ve hedefi sezen algılayıcısayısı. Benzetimlerimiz, algılayıcı ağlarının konumlandırılma alanlarına yönelik gerçek dışıvarsayımlardan dolayı, kağıt üstündeki tasarımların ve performans öngörülerinin yanıltıcıolduğunu göstermiştir.","A wireless sensor network (WSN) is a self-organizing network, consisting of tiny wirelessnodes which carry out a sensing and transferring task in collaboration. WSNs are getting popularbecause of their ease of deployment, self-organizing capability, low cost and their wide range ofapplications. This wide spectrum of applications raises most of the time application specificresearch problems in WSN protocol stack and algorithm design. However, the performance of themost proposed models in literature, have been evaluated on planar surfaces, assuming a distancebased sensing and 2D freespace communication model, while assuming a random deploymentscheme which commonly takes place in 3D inaccessible terrains.In this thesis, we investigated the problem of incorporating a realistic modelingenvironment into sensor networks. Our motivation has been the non-realistic and contradictiveassumptions in WSN performance evaluations, where the formations of the topographic surfacethat would normally block the communication and sensing task are not taken into account. Weincorporated a 3D terrain model into the performance evaluation of a collaborative target trackingapplication. The evaluation is done on various artificially generated but realistic terrains, on theperformance metrics of mean error which is a measure of tracking accuracy, number ofcommunicating sensor pair and number of detecting sensors. Our simulations show that theperformance predictions could be misleading on the paper design, due to non-realisticassumptions with regards to the WSN deployment region."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Şimdiye dek önerilen kuantum programlama dillerinin hiç biri yeni bulunmuş olanadyabatik evrim yaklaşımına dayanmamaktadır. Adyabatik kuantum hesaplamanın anasorunun sıradan programcıların Hamiltonyen'lerin tasarımı hakkındaki içgörü eksikliğidir.Bu çalışmada fizik ve cebir hakkındaki gerekli ön bilgileri verdikten sonra adyabatikkuantum hesaplama konusunun esaslarını hem literatürde bilinen, hem de bizce geliştirilmişyeni örnekleri etraflıca tartışarak ortaya koyulmuştur. Bir adyabatik kuantum programlamaaltyapısının geliştirilmesi yönünde bir ilk adım olarak ana tasarım sorumlarını göstermek içindöngü ve dallanma gibi akış denetimi komutlarını adyabatik kuantum açısından incelenmiştir.","Although several quantum programming languages have already been proposed, none ofthese are based on the newly discovered adiabatic evolution approach. We acknowledge themain problem in adiabatic quantum computation to be the lack of insight that commonprogrammers have about the design of Hamiltonians.In the present work we provide necessary background in physics and algebra and thebasics of adiabatic quantum computation with comprehensive discussion of both examplesseen in literature and new ones. We examine some flow control constructs like loops andbranching from the adiabatic quantum perspective to illustrate the main design problems as afirst step towards the development of an adiabatic quantum programming infrastructure."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde yapılan çalışmanın temel amacı EKG işaretlerinin sınıflandırılması ilearitmik kardiyak hastalıkların otomatik olarak teşhisini sağlamaktır. EKG, kalptekielektriksel gerilimin bir sonucu olan grafik şeklinde bir işarettir ve kardiyologlar tarafındanteşhis amacıyla kullanılan en önemli veridir. EKG işaretlerinin yorumlanmasındakarşılaşılan güçlükler araştırmacıları kardiyak aritmi bozuklukların otomatik olarakbelirlenmesi konusunda çalışma yapmaya sevk etmiştir. Günümüzde akıllı veri analiziyöntemlerini kullanan bilgisayar programları karmaşık EKG işaretlerini kolaycayorumlayabilmekte, kardiyak aritmi varlığı konusunda öngörüde bulunabilmekte ve gerçekzamanlı analiz ve teşhis sağlamaktadır. Bu çalışmada, akıllı aritmi sınıflandırması içindiğer sınıflandırma yöntemlerine göre daha yeni bir yöntem olan Destek Vektör Makineleri(DVM) kullanılmaktadır. Deneylerde kullanılan veriler UCI Aritmi Veritabanı'ndan eldeedilmiş olup çok boyutlu EKG veri kümesinde boyut indirgeme için PCA ve ICAyöntemleri kullanılmıştır. DVM algoritmasının performansı model parametrelerine bağlıolduğundan parametre seçimi oldukça önemlidir. Yapılan çalışmada, parametre seçimi,boyut indirgeme ve eşik tabanlı bir reddetme yöntemi kullanılarak standart DVMsınıflandırıcısının performansı arttırılmıştır. Önerilen eşik tabanlı reddetme yöntemi ilebelirsizlik yönetimi sağlanırken sınıflandırmadaki yanlış alarmların da ortadan kaldırılmasıhedeflenmektedir. Karşılaştırma amacıyla k-NN ve karar ağaçları yöntemleri de EKG verikümesine uygulanmış ve deney sonuçlarına göre geliştirilmiş DVM yönteminin daha iyisonuç verdiği belirlenmiştir.","The main objective of this study is to provide automatic recognition of arrhythmiccardiac pathologies from the classification of ECG recordings. ECG is a graphical signalwhich is the result of electrical tension of heart and is the most important biosignal used bycardiologists for diagnostic purposes. The difficulty faced in interpretation of ECG signalsforced researchers to study about automatic detection of cardiac arrhythmia disorders.Using intelligent data analysis techniques, computer programs could easily interpretcomplex ECG signals, predict presence or absence of cardiac arrhythmia and provide real-time analysis and diagnosis. In this study Support Vector Machines (SVM) technique hasbeen applied to ECG dataset for intelligent arrhythmia classification. The dataset used inthis study have been obtained from UCI repository. PCA and ICA methods have been usedfor dimensionality reduction of high dimensional ECG data. Parameter selection is verycritical for SVM since its performance is greatly influenced by the model parameters. Theresults of the standard SVM classifier improved by parameter selection, dimensionreduction and a threshold based rejection method to avoid false predictions for ambiguouspatterns. The proposed threshold method provides uncertainty management and could beused for suppressing false alarms. As a comparison, k-Nearest Neighbor and Decision Treealgorithms have been tested on the arrhythmia dataset. According to experimental resultsimproved SVM results shown to outperform competing classification results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZETGEZGİN TASARSIZ AĞLARDA ÇOĞULORTAM UYGULAMALARIİÇİN SERVİS NİTELİĞİ DESTEKLİ ÇOĞULYAYINKaan BürBilgisayar Mühendisliği, Doktora Tezi, 2006Tez Danışmanı: Prof. Dr. Cem ErsoyAnahtar Sözcükler: Gezgin tasarsız ağlar, çoğulyayın, servis niteliği, telsiz iletişim.Bu çalışma, çoğulyayın etkinliğini her düğümün kendi komşuluk alanı içindeki ağkaynaklarının yeterliğini izleyerek sağlayan, tasarsız, servis niteliği destekli bir çoğulyayınyol atama yordamı (AQM-ad hoc quality of service multicast routing protocol) tanımlar.Kullanılabilir bantgenişliği süregelen oturumlara ayrılan ve komşular tarafından bildirilengereksinim düzeylerine göre belirlenir. Servis nitelik düzeyi oturum açılışında duyurulup,oturumun gerektirdiği nitelik düzeyinin izin verdiği sınırlara dek düzenli olarakgüncellenir. Düğümlerin, uygun servis niteliğinin sağlanamayacağı oturumlar için katılımisteğinde bulunmaları engellenir. Bir düğüm bir oturuma katılacağında, üç adımdan oluşanbir süreç gereken niteliklere en uygun yolu seçer. Çoğulortam uygulamalarının gerektirdiğigecikme sınırlarına uymak için, adayların oturum sunucusuna kadar izin verilen sıçramasayısı sınırlandırılır. Akışkan çoğulortamın doğasına uygun olarak, düğümler bantgenişliğigereksinimlerini yalnız kendileri için değil, verinin sürekli akacağı sanal bir tünel boyuncabelirler. Bir öncelik kuyruğu, veri paketlerinin iletim sırasını ait oldukları trafik sınıfınagore belirler. AQM, gürbüzlüğünü artırmak için, oluşturduğu çoğulyayın ağacını veri akışısırasında bir örgüye evirir. AQM'nin oturum üyelerine sağladığı tatmin düzeyi, önerilenyeni başarım ölçütleri ile de değerlendirilmiştir. Bilgisayarlı benzetim sonuçlarıgöstermiştir ki, servis niteliği yönetimindeki yenilikçi teknikleri ile AQM, gerek üyeler,gerekse oturumlar için çoğulyayın etkinliğini önemli ölçüde artırmaktadır.","ABSTRACTQUALITY-OF-SERVICE-AWARE MULTICAST ROUTING FORMULTIMEDIA APPLICATIONS IN MOBILE AD HOC NETWORKSKaan BürComputer Engineering, Ph.D. Thesis, 2006Thesis Supervisor: Prof. Dr. Cem ErsoyKeywords: Mobile ad hoc networks, multicast routing, quality of service, wirelesscommunications.This work defines the ad hoc quality of service (QoS) multicast routing protocol(AQM), which achieves multicast efficiency by tracking the availability of resources foreach node within its neighbourhood. Computation of free bandwidth is based onreservations made for ongoing sessions and the requirements reported by the neighbours.The QoS status is announced at session initiation and updated periodically to the extent ofQoS provision. Nodes are prevented from applying for membership if there is no QoS pathfor the session. When nodes wish to join a session with certain service requirements, athree-phase process ensures that the QoS information is updated and used to select themost appropriate routes. The allowed maximum hop count of the session is taken intoaccount in order to satisfy the delay requirements of the multimedia applications. To copewith the continuous nature of streaming multimedia, AQM nodes check the availability ofbandwidth within their neighbourhood not only for themselves but within a virtual tunnelof nodes. A priority queue determines the transmission order of data packets according totheir traffic classes to support even those applications with more stringent QoSrequirements. AQM evolves the initial multicast tree into a mesh during data flow toimprove robustness. New performance metrics are introduced to evaluate the efficiency ofAQM regarding the satisfaction level of session members. Simulation results show that, byapplying novel QoS management techniques, AQM significantly improves multicastefficiency for members as well as for sessions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"iüOZETüğ ËşË ËYAPAY OGRENME ICIN BIR UZMANLARü Ë şËKUMESINDEN SECIM YAPMAKarar birleştirme tek üğrenicili sistemlerin başarımını artırmak işin son yıllardas og s cyaygınlaşmıştır. Bir sınıï¬andırıcı kümesinin kullanımındaki temel düşunce, farklı sınıf-ss u usülandırıcılar tarafından yanlış sınıï¬andırılmış ürüntülerin aynı olmayabileceği ve birbirinis so u u gtamamlayan sınıï¬andırıcıların kararlarını uygun şekilde birleştirerek yanlış sınıï¬andırmas s shatasının azaltılabileceğidir.gSınıï¬andırıcı seşme ile kaynaşım farklıdır: Seşmede verilen bir girdi işin birc s c ckümedeki modellerin sadece bir veya birkaşı kullanılır, kaynaşımda ise girdi işin tümu c s c umodeller bir sonuş verir ve bu sonuşlar genel sonucu hesaplayabilmek işin ürneğinc c cogortalamaları alınarak birleştirilir. Bu şalışmada, yazındaki bazı sınıï¬andırıcı seşmes cs cmetodlarını karşılaştırmalı olarak inceliyoruz. Bir deneme verisi verildiğinde temelss gsınıï¬andırıcılar kümesinden en uygun alt kümeyi dinamik olarak seşebilen bütünleşiku u c uu ssistemler üneriyoruz. Bu sistemlerin seşme birimlerine odaklanarak, onları her sınıï¬andı-o crıcının uzmanlık alanlarını üğrenecek şekilde eğitiyoruz. Sınıï¬andırma aşamasında,og s g sverilen bir girdi işin seşme birimi en yetenekli sınıï¬andırıcıların hesaplanması ve kul-c clanılmasına olanak sağlar ve büylece sadece onların kararları hesaba alınır. Bu uzmanlıkg oüğrenimi probleminde, karar ağaşları, kural tabanlı algoritmalar ve yapay sinir ağlarıog gc ggibi değişik algoritmalar deniyoruz.gs40 veri kümesi ve 21 temel sınıï¬andırıcı uzerinde, uzmanlar kümesinin iyi eğitilmişu ü u g sbir seşme birimi kullanarak başarılı bir şekilde uzmanları seşebildiğini ve toplam başarıyıc s s c g sgeliştirdiğini gürüyoruz. Bu gelişme üzellikle hişbir temel sınıï¬andırıcının yüksek başarıs g ou so c u sgüsteremediği durumlarda anlamlı olmaktadır.o g","iABSTRACTSELECTING FROM AN ENSEMBLE OF EXPERTS FORMACHINE LEARNINGDecision combination has recently become popular to improve over single learnersystems. The fundamental idea behind an ensemble of classiï¬ers is that the patternswhich are misclassiï¬ed by diï¬erent classiï¬ers are not necessarily the same and thatby suitably combining the decisions of complementary classiï¬ers misclassiï¬cation errorcan be reduced.Classiï¬er selection is diï¬erent from fusion: In classiï¬er selection, for a giveninput, only one or a small number of the models in the ensemble are used whereasin fusion, given an input all models give an output which are then combined, forexample by averaging, to calculate the overall output. In this study, we review someclassiï¬er selection methods in the literature in a comparative manner. We proposesome composite systems which are capable of selecting the optimal subset of the baseclassiï¬ers from the ensemble dynamically when a test instance is given. We focus onthe selection units of these systems and their training so that they learn the areasof expertise of each classiï¬er. In the classiï¬cation phase, given a data instance, theselection unit allows the calculation and use of the most competent classiï¬ers so thatonly their decisions are taken into account. For this expertise learning task, we trydiï¬erent algorithms such as decision trees, rule based algorithms, and neural networks.On 40 datasets and 21 base learning algorithms, we see that by using a well trainedselection unit, an ensemble of experts is capable of selecting the experts successfullyand improve the overall accuracy. This improvement is signiï¬cant especially in caseswhen none of the base classiï¬ers have high accuracy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET gözetimli öğrenmede çapraz geçerleme ile model karmaşıklığının ayarlanması Bu tezde, model seçiminde çapraz geçerleme kullanımını gözden geçirerek gözetimli modellerden en iyisini bulan MultiTest metodunu önerdik. MultiTest algoritması, gözetimli öğrenme algoritmalarını beklenen hata üzerindeki ikili istatistiksel testlerin sonuçlarına ve algoritmanın karmaşıklığı gibi önceliklere göre sıralar. MultiTest meto dunu geçerlemek için ANOVA ve Newman-Keuls algoritmalarıyla karşılaştırdık. Bu algoritmalar metodların hata oranlarının aynı olup olmadığını kontrol eder. En iyi al goritmayı bulmak için kullanılabilseler bile, bu her zaman çalışmayabilir. Oysa, bizim önerdiğimiz metod her zaman en iyiyi bulabilir. MultiTest metodunu model karmaşıklığını eniyilemede kullanmaya çalıştık. Bunun için ya tüm olası modelleri MultiTest'le karşılaştırdık ve en iyi modeli seçtik ya da (model uzayı genişse) MultiTest'i kullanarak model uzayında etkili bir arama yaptık. Tüm modeller aranabildiğinde, MultiTest diğerlerinden anlamlı bir şekilde kötü ol mayan en basit modeli seçer. Tezde, ayrıca karar ağacı ve kural çıkarımı için karma, tüm değişkenli bir yapı önerdik. Bu yapı, modelin karmaşıklığını oraya ulaşan verinin karmaşıklığına uyduran, farklı yerlerde farklı modellerin olabildiği karma bir yapıdır. Önerdiğimiz Multi- Test'e dayalı, çok değişkenli yapıyı çok bilinen model seçme teknikleriyle standart veri kümeleri üzerinde karşılaştırdık.","IV ABSTRACT TUNING MODEL COMPLEXITY USING CROSS-VALIDATION FOR SUPERVISED LEARNING In this thesis, we review the use of cross-validation for model selection and pro pose the MultiTest method which solves the problem of choosing the best of multiple candidate supervised models. The MultiTest algorithm orders supervised learning algo rithms (for classification and regression) taking into account both the result of pairwise statistical tests on expected error, and our prior preferences such as complexity of the algorithm. In order to validate the MultiTest method, we compared it with Anova, Newman-Keuls algorithms which check whether multiple methods have the same ex pected error. Though Anova and Newman-Keuls results can be extended to find a ""best"" algorithm, this does not always work. On the other hand, our proposed method is always able to find an algorithm as the ""best"" one. By using MultiTest method, we try to solve the problem of optimizing model complexity. For doing this, either we compare all possible models using MultiTest and select the best model or if the model space is very large, we make an effective search on the model space via MultiTest. If all possible models can be searched, MultiTest-based model selection always selects the simplest model with expected error not significantly worse than any other model. We also propose a hybrid, omnivariate architecture, for decision tree induction and rule induction. This is a hybrid architecture that contains different models at different places matching the complexity of the model to the complexity of the data reaching that model. We compare our proposed MultiTest-based omnivariate architec ture with the well-known techniques for model selection on standard datasets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZETGENETIK ALGORITMA KULLANARAK KARMASIK AGLARDAALTTOPLULUK BULMA MODELI VE BU MODELIN GERÇEKAGLARDA UYGULANMASIBu çalisma karmasik aglarin incelenmesine yönelik bir çalismadir. Temel olarak,bir agdaki alttopluluklari genetik algoritma tabanli bir algoritma ile bulmayi saglayan biralgoritma tanitilacak ve ilgili altyapi detayli olarak gelistirilecektir.Öncelikle karmasik aglarda alttopluluk yapisini ortaya çikaran algoritmalartanitilacaktir. Bir karmasik agdaki alttopluluk yapisinda, alttopluluk üyeleri kendiaralarinda daha siki, diger alttopluluklardaki üyelerle ise zayif baglidir. Bugüne kadaralttopluluk yapisini ortaya çikaran ve bazilari çok iyi sonuçlar veren birçok algoritmaönerilmistir. Ancak bu algoritmalarin birçogu çalisma süresi bakimindan büyük aglardayetersiz kalmaktadir ki gerçek hayattaki birçok karmasik ag örnegi büyük karmasik agdir(ör: www agi, e-posta agi). Karmasik aglarda alttopluluk bulan yeni bir algoritmagelistirip, bu algoritmayi gerçek hayattaki Zachary'nin Karate Kulübü ve Enron e-postaagi gibi kompleks aglarda uygulamaktayiz. Zachary'nin Karate Kulübü agi bilinen birkarmasik ag örnegidir. Enron e-posta agini ise, verileri toplayarak ve bu verileri isleyerekolusturmus bulunmaktayiz.Ag modülerligini (network modularity) baz alan ve genetik algoritma kullanarakalttopluluklari belirleyen ve 100,000 üyeye sahip çok büyük karmasik aglarda çalisabilen,ölçeklenebilir bir algoritma sunmaktayiz. Algoritmamizi, dogrulugunu görmek içinalttopluluk yapisi bilinen aglarda ve ölçeklenebilirligini görmek için de Enron e-postaaginda çalistirdik. Algoritmamiz, makul bir süre içinde optimal alttopluluk yapilari ortayaçikarmakta ve çok büyük aglara ölçeklenebilmektedir.","ABSTRACTCOMMUNITY DETECTION MODEL USING GENETICALGORITHM IN COMPLEX NETWORKS AND ITS APPLICATIONIN REAL-LIFE NETWORKSThis work is an endeavor towards analyzing complex networks. Mainly, acommunity detection algorithm based on genetic algorithm will be introduced, anddetailed background will be developed.Firstly, we introduce community detection methods in complex networks. Acommunity in a complex network is a group of nodes that has more connectivity withinand less connectivity with other communities. There are many community detectionalgorithms proposed so far, some of which performs very well, however most of them arenot feasible in identifying communities in large complex networks, where many of thereal life examples of the complex networks are large complex networks (e.g. wwwnetwork, e- mail networks) due to time complexity of the algorithms. We introduce andapply a community detection algorithm on some real- life complex networks, likeZachary?s Karate Club and the Enron e- mail network. Zachary?s Karate Club network isa well-known network dataset. We collected data of Enron e-mail network and processedthat data to form the Enron e- mail network.We present a community detection algorithm that is based on the networkmodularity (Q) and is scalable to very large networks that has 100,000 nodes. We run ouralgorithm on known networks to assess the accuracy of our algorithm and then on Enrone-mail dataset as well to examine the scalability of our algorithm. Our algorithm givesoptimal community structure in very short time and is scalable to very large networks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET MOBİL KULLANICILAR İÇİN MOBİL AJAN TABANLI SERVİSLER: ""PEGASUS SİSTEMİ"" Mobil ajanlar, düşük işlem gücü, düşük bant genişliği ve ağ bağlantısı problemlerine sahip kullanıcılara zamanuyumsuz servisler sağlamak için ideal bir araçtır. Ne yazık ki varolan çoğu mobil ajan sistemini programlamak ve kullanmak uzmanlık ister. Bu çalışma, mobil ajanların XML dokümanları ile tamlandığı bir mobil ajan platformunu tarif etmektedir. Bu yolla daha esnek ve programlama dilinden bağımsız bir sistem tasarlanmış ve uygulanmıştır. Sistem, tecrübesiz kullanıcılara kolayca kullanılabilen hazır bileşenler sunmasının yanında, tecrübeli kullanıcılar için de kendi özel bileşenlerini hazırlamak ve sistemin işlevselliğini artırmak için olanaklar sunmaktadır.","IV ABSTRACT SERVICES FOR MOBILE CLIENTS VIA MOBILE AGENTS: ""PEGASUS SYSTEM"" Mobile agents are an ideal way to provide asynchronous services for users who have computing power, bandwidth and connection problems, but most of the available mobile agent systems are not trivial to program and deploy. This study proposes and implements a new mobile agent execution platform, where the mobile agent is defined as an XML document, with attached byte code for execution, to achieve flexibility and language independency. The system allows inexperienced users to create their mobile agents, using the already available objects residing at the server and experienced users to create their custom objects, and thus expand the functionality of the agent system."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET YAZILIM PROJELERİNDEKİ OLASI HATALARIN YAPAY SİNİR AĞLARI YÖNTEMLERİYLE BELİRLENMESİ Yazılım mühendisliği, esnek olmayan proje teslim tarihleri ve sınırlı bir bütçe ile gerçekleştirilebilecek zorlu bir iştir. Yazılım mühendisliğinin temel amacı müşteri isteklerine tam anlamıyla cevap verecek programlan zamanında üretmektir. Bu bağlamda, yazılım hatalarının en aza indirilmesi maliyet yönetiminin temelim oluşturur. Yazılım geliştirme süreci ilerledikçe, yazılımdaki hataların ve bunlardan doğacak problemlerin üstesinden gelmek zorlaşır. Böyle bir durumda ise, uzun test süreçleri kaçınılmaz hale gelir, geliştirme sürecinde istenmeyen durumlar oluşur ve proje programı ertelenmeye başlar. Bundan dolayı, yazılımın güvenirliliğini ve kalitesini korumak daha pahalıya mal olur. Bu tezde yapılan araştırmanın temel amacı, bu yazılım sorunlarının proje programı içinde üstesinden gelebilecek bir çalışma sunmaktır. Bu tip bir analiz ile daha verimli ve hataların önceden tahmin edilebildiği bir geliştirme yapılabilir. Projenin gelişme süreci içinde, yazılım hatalarının önceden ölçülebilmesi, bu tip sorunlara karşı gerekli önlemlerin alınmasına olanak sağlar. Bu araştırmayı başarmak için, 'makina öğrenmesi' ve 'yapay sinir ağları yöntemleri' kullanılmıştır. Boyut indirgeme için Temel Eleman Analizi; hata kusur tahmini için ise Karar Ağacı, Çok Katmanlı Percepton ve Radyal Kaynaklı Fonksiyonlar ele alınmıştır. Bu methodların kullanımında gerekli olan metric veriler Logo Business Solutions, Garanti Teknoloji ve Innova Bilişim Sistemleri adlı 3 firmanın gerçek hayattaki projelerinden elde edilmiştir.","IV ABSTRACT SOFTWARE DEFECT IDENTIFICATION USING NEURAL NETWORK TECHNIQUES Software engineering is a tedious job that involves people, tight deadlines and limited budgets. The goal of a software engineer is to develop a software program that produces the desired results of its customers on time and within budget. Delivering what customer wants also involves minimizing the defects in the programs. Defect minimization is the key ingredient in cost management. As the software project progresses, it becomes much more difficult and costly to overcome defect related problems. In such a case there needs to be a long test phase after the development is complete. Depending on the severity of the defects found in the test phase project schedules may be delayed or some fatal defects may end the software development all together. Therefore, it is important to establish quality measures early on in the project life cycle. The main objective of this research is making an analysis in order to overcome these software problems earlier in the project schedule. Such an analysis displays a disciplined process on software development with the aim of making software development more predictable and more efficient. If the software is measured early in its life-cycle, it will be possible to take necessary precautions before undesirable results come out. In order to accomplish this, we propose a model that uses machine learning and artificial neural network methods namely Principal Component Analysis for dimensionality reduction, and Decision Tree, MLP and Radial Basis Functions for defect prediction. The necessary code metric data are obtained from real-life projects of three different software companies in Turkey called Logo Business Solutions, Garanti Teknoloji and Innova Bilişim Sistemleri."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BAĞIMSIZ DÖRT DERECELİ HAREKET SERBESTLİĞİNE SAHİP KAUÇUK EYLEYİCİLERDEN OLUŞAN BİR ROBOT KOLU İÇİN PID VE BULANIK PH) DENETLEYİCİLERİNİN KARŞILAŞTIRILMASI Bu tezde, yüksek derecede doğrusal olmayan ve histerez özellik gösteren, bağımsız dört dereceli hareket serbestliğine sahip kauçuk eyleyicilerden oluşan bir robot kolu için iki farklı denetim algoritması tasarımı yapılmıştır. Deneysel amaçlı gerçekleştirilen denetleyiciler geleneksel denetim tekniği olarak kullanılan PID ile biraz daha gürbüz ve uyarlanır olan bulanık PED denetleyicidir. Bu denetleyicilerin kuramsal altyapıları da tartışılmıştır. Denetimin amacı değişik hızlarda üç farklı şablon yörüngede, uç-nokta konumunu izlemesidir. Gerçekleşen robot hareketinin, izlenen hedef yörüngeyi gecikme cevabını düşürerek ve kabul edilebilir konum hatasını sağlayarak izlemesi istenilmektedir. îyi şekilde ayarlanmış PID denetleyici ile bulanık PID denetleyici basanları karşılaştırılmıştır. Grafiksel ve nicel olarak karşılaştırmanın sonucunda, bulanık PID denetleyicisinin yörünge denetiminde histerez ve gecikme cevabına göre daha üstün olduğu görülmüştür.","IV ABSTRACT COMPARISON OF PID AND FUZZY PID CONTROL TECHNIQUES FOR A COMPLIANT RUBBERTUATOR-BASED 4-DEGREE OF FREEDOM ROBOT ARM In this thesis, two different control algorithms are designed for a compliant rubbertuator-based 4-degree of freedom robot arm, a highly non-linear pneumatic system with hysteresis. The controllers which are implemented for experimental purpose are a traditional control technique, PID, with a more robust and adaptive Fuzzy PID controller. The theoretical background of these controllers is also discussed. The control objective is end-effector tracking of three sets of trajectory patterns at various velocities. The actual robot motion is desired to follow the target trajectory with reduced delay response and an acceptable position error. The Fuzzy PUD controller performance is compared with the performance of a well tuned PID controller. Having compared performances graphically and quantitatively, it was observed that the Fuzzy PID controller is superior in dealing with the hysteresis and delay response for trajectory control."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET AJAN DESTEKLİ YENİ MOBIL WEB SERVİSLERİ ALTYAPISI Günümüzde masaüstü uygulamalarına her yerden erişim ihtiyacı gün geçtikçe artmaktadır. Bu bağlamda mobil cihazlar hayatımızın bir parçası haline gelmiştir. Bu cihazlar, çeşitli kablosuz teknolojiler kullanarak uzaktan bilgiye erişim dahil çok çeşitli özelliklere sahip olabilmektedir. Mobil cihazlar, Symbian, Palm, Windows Mobile gibi farklı platformlara sahip olabilmektedir. Sunulan fonksiyonlar benzer olsa da uygulama geliştirme ortamları platform bazında değişiklik gösterebilmektedir. Bu sebeple, kullanıcılar, kendi cihazlarındakinden farklı platformlarda koşan uygulamalara erişmek istediklerinde problemler yaşanabilmektedir. Bu noktada, web servisleri platformlar arası uyum problemlerine cevap oluşturabilir. Web servisleri, işletim sistemleri, programlama dilleri ve uygulama geliştirme yöntemlerinden bağımsızdır. Bir kere kurulduktan sonra, platform bağımsız olarak her türlü istemci tarafından kullanılabilmektedir. XML teknolojilerine dayanan Web servislerinde kullanılan protokoller işlem gücü ve ağ genişliği bakımından yüklü sayılabilir. Bu noktada soru, Web servislerinin işlem gücü ve ağ genişliği sınırlı olan mobil ortamda kullanımın verimli olup olmadığıdır. Bu araştırmada, web servisleri mobil ortamda işlem süreleri ve ağ yükü açısından incelenmiştir. Farklı mobil web servis mimarileri araştırılmış ve mobil ajanlara dayanan yeni bir altyapı önerilmiştir. Ayrıca geliştirilen iki test uygulamasının performansları işlem süresi ve ağ yükü açısından incelenmiştir.","ABSTRACT AGENT BASED NEW MOBILE WEB SERVICES FRAMEWORK In today's world there is an increasing need for ubiquitous access to desktop applications. Mobile devices have already been a part of our daily life. They provide for many different properties such as access to data in a nomadic fashion by using different wireless communication technologies. Mobile devices are running on many different platforms, such as Symbian, Palm, Windows Mobile and other proprietary platforms. Although the main functionalities are the same, the development environments vary for each platform. A problem of integration arises when users would like to access existing desktop applications, which are running on platforms different than mobile clients do, through their mobile devices. At this point, web services can be a right solution to solve integration issues. Web services are independent of the operating system, programming language and implementation methods. Once a service is deployed, it can be invoked from any client independent of its platform. Web services are based on XML technologies and the protocols used are heavy- weight in terms of processing power and network bandwidth. So, the question is that whether web services are appropriate for the mobile environment or not, especially when the processing power of the clients and network bandwidth is limited, or not. In this research, the performance of web services in terms of response time and network load is analyzed. Different mobile web services architectures are analyzed and a new framework based on mobile agents is proposed. Two test applications are developed and their performances are analyzed in terms of response time and network load."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET OASIS KULLANICI ADI GÖSTERGESİNE KULLANICI ADI - ŞİFRE DOĞRULAMASINI KOLAYLAŞTIRMAK İÇİN YAPILAN BİR EKLEME Günümüzde uygulamaların hatta kurumların haberleşme teknolojisi olarak web servisleri görülmektedir. Web servislerinde mesajlaşma Simple Object Access Protocol (SOAP) kullanılarak yapılmaktadır. SOAP basit ve genişletilebilir olmak üzere tasarlanmış fakat basit ve genişletilebilir olabilmesi için içine güvenlik gereksinimleri konulmamıştır. Organization for Advancement of Structured Information Standards (OASIS) tarafından SOAP'a güvenlik mekanizmaları eklemek için çeşitli SOAP eklemeleri önerilmiştir. Kullanıcı adı ve şifre doğrulaması için kullanılan SOAP güvenlik eki OASIS UsernameToken'dır. OASIS UsernameToken sadece temel kullanıcı adı ve şifre bilgisini taşıyabilir. Bu iki bilgi, bilinen kullanıcı adlan ve şifreler tek bir yerde saklandığında hızlı çalışmaktadır. Fakat bilinen kullanıcı adlan ve şifreler birden fazla yere dağıtılarak saklandığında eşleşen bir çift bulabilmek için tüm olası yerlerin taranması gerekir. Bu da web servisinin cevap verme süresini arttırır. Bu araştırmada, OASIS UsernameToken' a temel kullanıcı adı ve şifre bilgisi dışında bazı eklemeler yapılmasını öneriyoruz. Bu ek bilgiler, doğrulama modülleri tarafından kararlar alınırken kullanılabilir ve bu sayede doğrulama modülleri alınan kullanıcı adı şifre ikilisini sadece doğru yerdeki bilinen ikililerle karşılaştırırlar. Bu sayede web servisinin hızlı cevap vermesi sağlanır.","IV ABSTRACT AN EXTENSION TO OASIS USERNAMETOKEN FOR SIMPLIFYING USERNAME-PASSWORD AUTHENTICATION Web services are viewed as the current communication technology between applications and even enterprises. Web service messaging is performed through Simple Object Access Protocol(SOAP). SOAP has been designed to be simple and extensible. But for being simple and extensible, security issue has been omitted in SOAP. For adding security mechanisms to SOAP, some SOAP extensions have been published by Organization for Advancement of Structured Information Standards(OASIS). SOAP security extension for username-password authentication is OASIS UsernameToken. OASIS UsernameToken carries basic username password information. This basic information works fine when the known username - password pairs of a system are stored in a single location. But when the known username - password pairs are stored in multiple locations, each location must be searched to find a matching pair. Searching through each possible location increases response times of web services. In this research, we propose an extension to OASIS UsernameToken which contains additional information other than the basic username and password pair. This additional information can be used by authentication components of web services to make decisions and search for the received credentials at their exact place."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TEMEL İLİNTİ ATAĞININ GSM GÜVENLİK SİSTEMİNE OLAN KARŞILAŞTIRMALI DEĞERLENDİRİMİ GSM güvenliği A5 yordamının çeşitli türleri üzerine kuruludur. Bunlardan GSM sistemindeki ataklara karşı dirençli şifreleme yöntemi A5/1, zayıf olanı ise A5/2 yordamıdır.Bu çalışmada, A5/H adı verilen ve bu iki versiyonun hybrid (melez) birleşimi olan bir akım şifreleyicinin ataklara karşı çok daha dirençli olduğu gösterilmektedir. A5 yordamının kırılması için bugüne kadar bellek-zaman ödünleşimi (time-memory tradeoff), böl ve parçala (Divide and conquer) gibi yöntemler üzerinde çeşitli çalışmalar yapılmıştır. Bu atakların temel özelliği ise, atağın karmaşıklığının yazmaçların (shift registers) uzunluğuna üstel olarak bağlı olmasıdır. Temel ilinti atağı adı verilen yeni bir yöntem ise, atağın karmaşıklığını yazmaçların (shift register) uzunluğundan neredeyse tamamen bağımsız kılmakta ve 5-7 dakikalık bir GSM konuşma süresi ile A5'i kırabilmektedir.Bu çalışmadaki amaç,akım şifrelerine yönelik yapılan saldırılarda etkili bir yöntem olan temel ilinti atağını A5/1, A5/2 ve A5/H şifreleme sistemine uygulamak ve çeşitli kriterlere göre irdelemektir. Sonuç olarak temel ilinti atağının A5/1, A5/2 ve A5/H e karşı çok başarılı olduğu simülasyon sonuçlarıyla gösterilmiştir. Ayrıca, bu çalışmada temel ilinti atağına yeni bir yaklaşım da eklenmiştir. Bu yaklaşımla, atağın basan oranınının artırılabilineceği ispatlanmıştır.","IV ABSTRACT COMPARATIVE ASSESMENT OF BASIC CORRELATION ATTACK AGAINST GSM SECURITY SYSTEM GSM Security System is based on various versions of A5 algorithm. The one with strong encryption method is called A5/1; the weaker one is A5/2. Recent work, called A5/H, which is a hybrid combination of A5/1 and A5/2, shows that this stream cipher is much stronger to attacks. There has been many researches so far regarding methods such as time-memory trade-off, divide and conquer to break A5/1. The main feature of these attacks is that, the complexity of the attack is dependent exponentially to lengths of shift registers. However, a new method, called basic correlation attack, makes complexity of the attack almost independent of the lengths of shift registers and makes it possible to break A5 with a 5-7 minutes of GSM conversation. The main goal in this work is to implement basic correlation attack to GSM Security Algorithms A5/1, A5/2 and newly proposed A5/H and to investigate applicability of the attack regarding some criteria. Simulation results proved that basic correlation attack is quite successful to all of three stream ciphers, even A5/H. Moreover, a new approach has been integrated to basic correlation attack in this work. With this approach, it is proved by simulations that the success rate of the attack can be increased."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vüOZETü ËşË ËDORT BACAKLI ROBOT FUTBOLU ORTAMI ICIN YENIË ü ü ËVE DAYANIKLI BIR GOREV ATAMA YONTEMIËş Ë Ë ËGELISTIRILMESIUygun bir tasarım paradigması kullanıldığında, güreli olarak basit robotlardang ooluşan bir takım, karmaşık bir gürevi tek bir karmaşık robottan daha etkin bir şekildes s o s syerine getirebileceğinden şoklu-robot takımları giderek popülaritelerini arttırmaktalar.g c uCoklu-robot sistemlerinin tekil-robot sistemlerine güre ana avantajları sistemin hata-ş olara karşı dayanıklı olması ve paralel işlemeden ütürü yüksek performans sağlanmasıdır.s s ouu u gCoklu-robot sistemleri mayın temizlemeden gezegen keşiï¬erine, futbol oynamadan fe-ş slaket sonrası arama-kurtarma calışmalarına kadar pek cok uygulama alanına sahiptir.şs şRobot futbolu, sınırlı ve gürültülü algılayıcı bilgisi ve gürültülü eyleyiciler gibiu u uu u u uuï¬ziksel kısıtlara ve son derece dinamik değişen bir ortama sahip olduğundan, şoklu-gs g crobot uygulamalarını geliştirmek ve test etmek işin şok uygun bir ortamdır.s ccOyunu kazanma amacı bir dizi alt-amaca cevrilmeli, bu alt-amaşlara ulaşabilmekş c sişin gereken uygun eylemler seşilmeli ve oyun süresince iyileştirilmelidir. Uygun eylem-c c u sleri seşebilmek işin ortamin o anki durumunu değerlendirebiliyor olmamız, dolayısı ilec c gortam hakkında nitel bilgi sağlayabilen bazı olşutlerimiz olması gerekir.g ü cüBu şalışmada, ünce robotların ve topun sahadaki pozisyonlarından hesaplanancs obazı ülşutler tanımlayarak bu olşutler arasından bilgilendirici olduğu istatistiksel olarako cü ü cü gkanıtlanmış bir altkümeyi seşeceğiz. Sonra, seşilen ülşutlerin uzerine dayanıklı birs u cg c o cü ügürev paylaşımı yüntemi yerleştireceğiz. Gerek ülşut seşimi, gerek tasarlanan yüntemino s o s g o cü c osınanması konularındaki deneysel calışmalar detaylı olarak verilecektir.şs","ivABSTRACTDEVELOPING A NOVEL ROBUST MULTI-AGENT TASKALLOCATION ALGORITHM FOR FOUR-LEGGEDROBOT SOCCER DOMAINMulti-robot systems become more popular since a team of relatively simple robotsmay achieve a complex goal more eï¬ectively than a single complex robot if a properdesign paradigm is used. Two main advantages of multi-robot systems over singlerobot systems are their robustness and higher performance due to parallel execution.Multi-robot systems have a wide application area from mine sweeping to planetaryexploration and from soccer playing to search and rescue operations in disaster areas.Robot soccer is a good platform to test and develop multi-robot applicationsbecause it has some physical limitations such as limited and noisy sensorial informationand noisy actuators as in the real life and it also has a highly dynamic environment.The goal of winning the game should be decomposed into a sequence of sub-goals and proper sequences of actions for achieving the subgoals should be selected andreï¬ned through execution. In order to be able to select proper actions at a time, itshould be able to evaluate the current situation of the environment so we have to havesome metrics that gives quantitative information about the environment.In this work, we ï¬rst propose some metrics calculated from positions of robotsand ball on the ï¬eld and select a subset of these metrics that are statistically provedto be informative. Then, a task allocation algorithm is built on top of those metrics.Experimental study on both metric selection and evaluation of the designed algorithmare given."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GENİŞLETİLEBİLİR ETKİLEŞİMLİ WEB SERVİSLERİ Dağıtık uygulamalar ve dağıtık uygulama altyapıları gelişen bir araştırma sahası olarak özellikle Internet' in yayılması ile bir ivme kazanmıştır. Bu alandaki araştırmaların çoğu yeniden kullanılabilinir servis altyapıları oluşturmak üzerine yoğunlaşmaktadır. Son zamanlarda, bu altyapılara kullanıcılar ile etkileşim özellikleri sağlamak üzerine artan miktarda araştırmalar yapılmaktadır. Ancak hali hazırda bulunan etkileşimli servis altyapıları sunum katmanının kapsamlı uyarlamasına olanak sağlamamaktadır. Bu tezde araştırmanın amacı, etkileşimli dağıtık Web uygulamaları geliştirilmesi için, platform bağımsız, genişletilebilinir, etkileşimli Web servis altyapısının geliştirilmesidir. Araştırmamızda özellikle var olan etkileşimli servislerin, sunum ve servis katmanlarında yeniden kullanılabilirliğini sağlanmasına odaklanmaktayız. Genişletilebilirlik ve uyarlanabilirlik yeteneklerinin etkileşimli servislerin yeniden kullanılabilirliğini etkin bir şekilde arttırarak, katma değerli servis zincirlerinin geliştirilmesine olanak vereceğine inanmaktayız. Ayrıca istemci cihazlarından bağımsız bir servis çıktısı sunarak etkileşimli servislerin yeniden kullanılabilirliğini arttırmak ve etkileşimli uygulama geliştirilmesine etkinlik kazandırma konularına da odaklanmaktayız. Geliştirmiş olduğumuz kullanım örnekleri, sunulan model olan, Genişletilebilir Etkileşimli Web Servisleri (EIWS) altyapısının, kullanılan servisin sunum ve servis katmanlarında kapsamlı uyarlamasına olanak verdiğini göstermektedir. Kullanım örnekleri ayrıca EIWS altyapısının istemci cihazlardan bağımsız servis çıktıları üreterek herhangi bir istemci cihazla etkileşebildiğini göstermektedir. Bu özellikler etkileşimli servislerin gerektiğinde uyarlanarak, yeniden kullanımım sağlayan EIWS altyapısının, etkileşimli dağıtık Web uygulamalarının geliştirilmesine olanak sağlayabilecek bir altyapı olduğunu göstermektedir.","IV ABSTRACT EXTENSIBLE INTERACTIVE WEB SERVICES Distributed applications and their enabling architectures have been a developing research field and gained considerable momentum after the discovery of the Internet. Many of the research in this field focus on providing reusable service architectures to create applications using existing services. Recently there is increasing work to provide user interaction capabilities to these service architectures. However current interactive service architectures do not provide extensive capabilities to modify the presentation layer. In this research our aim is to design a platform neutral, extensible, interactive Web service framework that can be consumed in distributed interactive Web applications. We primarily focus on reuse of existing interactive services in both service and presentation layers. We believe that extensibility and customization capabilities on the interactive services will increase reusability of existing services and enable the development of value added services. We also focus on providing consumer device independent service outputs to increase the reusability of interactive services and increase efficiency of creating interactive Web applications. Use case implementations which are presented as part of this research demonstrate that our proposed model, Extensible Interactive Web Services (EIWS) framework, provides for extensive modification of service and presentation layers of consumed services. Use case implementations also demonstrate that EIWS framework provides for a platform neutral interactive service framework that can deliver interactive content to any consumer device. It is shown that EIWS provides for opportunity to reuse existing interactive services while modifying them as necessary. This makes EIWS a promising service framework for the efficient development of distributed interactive Web applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vÖZETSMS MESAJLARININ STAT ST KSEL DOĞAL D L ŞLEMEYÖNTEMLER KULLANILARAK ANLAMLANDIRILMASIGünümüzde mobil telefonların metin tipindeki mesajları kabul edipgönderebilmelerini sağlayan SMS (Kısa Mesaj Servisi) son kullanıcılar arasında oldukçayoğun bir biçimde kullanılmaktadır. SMS protokolünün 160 karakterlik limiti (Unicodekarakterler için bu limit mesaj başına 70 karaktere düşmektedir), HTML, XML gibiherhangi bir özel formatı olmadan sadece düz metinlerden kurulu olmasına rağmengünümüzde kısa mesaj servislerinin sayısı telekomünikasyon sektöründe her geçen günartış göstermektedir.Telekomünikasyon şirketlerinin spor, haber, hava durumu gibi çeşitli içerikhizmetlerinin sağlanmasında bu yönteme sıkça başvurdukları görülmektedir. Günümüzdebu çeşit kısa mesaj servisiyle verilen bir çok servis bulunmakta, bunların abonelik, iptal veservis içeriğinin türüne göre gereken bazı parametreleri yine SMS protokolü ile sonkullanıcılardan toplanmaktadır. Bu servislerin abonelik işlemlerinde kullanıcılardan dahaönceden belirlenmiş bir anahtar kelime yada kelimeler istenmekte buna göre sonkullanıcıların istekleri belirlenip arzu ettikleri hizmet kendilerine verilmektedir. Ancakkullanıcıların bir çoğu gönderdikleri mesajların karşıda bir insan tarafından okunduğunudüşünmekte ve çoğu zaman kendilerinden istenen örneğin önceden belirlenmiş ?ABONEHABER NTV? yerine ?ABONE HBR MTV? gibi mesajlar göndererek sadece gelenanahtar kelimeleri işlemeye göre programlanmış yazılımların hatalı yanıtlar vermesine yolaçmaktadırlar. Üst üste başarısız bir iki denemeden sonra, bu tür yanıtlarla devamlı hatamesajını yanıt olarak alan son kullanıcılar da servis almaktan vazgeçmekte, bu da ilgiliiçerik sağlayıcının hem gelir kaybetmesine neden olmakta hem de müşteri memnuniyetiniolumsuz yönde etkilemektedir.viBu tezde istatistiksel doğal dil işleme yöntemlerinin başında gelen N-Gramyöntemiyle bu probleme bir çözüm yöntemi getirilmeye çalışılarak, yeni bir SMS işlemimodülü geliştirilecek ve bu modülün son kullanıcıları olan gerçek bir abonelik sistemiüzerinde çalıştırılmasıyla, yöntem ve sonuçları tartışılacaktır.","ivABSTRACTIMPROVED HANDLING OF SMS MESSAGES WITH STATISTICALNATURAL LANGUAGE PROCESSING TECHNIQUESThe Short Messaging Service (SMS) is built on the ability of mobile telephones tosend and receive text messages. SMS based applications are increasing dramatically day byday in the telecommunications industry. The most common use of SMS is for notifyingmobile phone users that they have new voice or fax mail messages waiting. Whenever anew message is dispatched into the mailbox, an alert by SMS informs the user of this fact.The Short Message Service can also be used to deliver a wide range of information tomobile phone users from share prices, match scores, weather, flight information, newsheadlines, lottery results, jokes. In general, user interaction based SMS services requestsome predefined keywords from the users and respond to them after processing theirmessages.However, most users think that they are communicating not with a machine but withhumans, so they compose misspelled and/or machine specific messages containing morethan just the needed keywords. As a result, they receive error messages from the server andgenerally do not continue to use the software after trying two or three times by makingsame mistakes.In this thesis, I introduce a new Short Message Service (SMS) parsing model usingStatistical NLP Techniques, whose aim is to solve the existing SMS user subscriptionproblem of a real software company. To do this, the N-Gram statistical approach will beused."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V ÖZET CNC TAKIM TEZGAHLARI İÇİN GERÇEK ZAMANLI GÖMÜLÜ BİR KONTROLÖRÜN TASARIMI VE GERÇEKLENMESİ CNC takını tezgahları üretim endüstrisinde sıkça kullanılmaktadır. Büyük ölçekli üretim yapan firmalar tarafından kullanılan CNC makineleri genellikle üreticiye özgü bir kontrolör bulundurmaktadır. Ancak, küçük ve orta-ölçekli üreticiler maliyeti düşürmek amacıyla kontrolörsüz makineler de alabilmekte ve takım tezgahını bir PC'ye bağlayarak ve makine kontrolünü bir PC yazılımıyla yapabilmektedir. Yazılım temelli kontrolörler maliyet avantajı sağlamakla birlikte gerçek zamanlı üretim gereksinimlerini karşılamayabilirler. Modern işletim sistemleri işlemci zamanını birçok prosese bölüştürdüğünden gerçek zamanlı bir uygulama yüksek öncelik elde etmek için işletim sistemine müdahale etmek zorundadır. Bu durumda bile gerçek zamanlı görevlerin gecikmesi sebebiyle takım tezgahının hareketlerinde istenmeyen titreşimler ve sarsılmalar gözlenebilmektedir. Bu çalışmada gerçek-zaman performansını arttırmak amacıyla gerçek zamanlı, gömülü bir kontrolör önerilmektedir. Bu kontrolör, makine motorlarının hareketi için gerekli dijital sinyallerin üretilmesi gibi alt seviye fonksiyonları yerine getirmektedir. Gerçeklenen fonksiyonlar PC üzerinde çalışan bir yazılım tarafından çağrılmakta ve PC kontrolörle seri port üzerinden iletişim kurmaktadır. PC kullanıcı için bir arayüz sağladığı gibi makina komutlarını da saklamakta ve gerçek zamanlı olmayan işlemleri yapmaktadır. Böylece, kontrol görevlerinin hassas bir şekilde zamanlanmasını P C yerine gömülü kontrolör sağlamaktadır. Kontrolör makine motorlarının denetimine adandığından makinenin titreşimsiz ve sarsıntısız çalışması sağlanabilir.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF A REAL-TIME EMBEDDED MACHINE TOOL CONTROLLER CNC machine tools are widely used in the manufacturing industry. Machine tools used by large-scale manufacturers usually are equipped with a built-in, proprietary- controller. However, small and middle-scale machine shops may choose to purchase controllerless machines to decrease cost. In this case, the machine tool is commonly connected to a readily available PC and control tasks are accomplished by PC software. Software controllers present an advantage in terms of cost, however they may fail to meet real-time requirements. Modern operating systems support multiple running processes and time-sharing between these processes. Consequently, a real-time appli cation must modify OS kernel or system libraries to gain higher priority then other processes. Even so, machine tool users may observe jittered and jerky tool movements because time-critical control tasks are delayed. To enhance real-time performance, an embedded real-time controller is proposed. The embedded controller realizes low-level functions such as the generation of digital signals to stimulate machine motors. The functions implemented are invoked by a PC program through serial communication. PC acts as an interface and stores machine commands. Furthermore, it can carry out non-real-time jobs which require lengthy computation. Thus, the responsibility of accurate timing of control events is shifted to the embedded controller. As it is dedicated to interfacing motors, jitter-free operation of the machine can be ensured."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"1üOZETË şË ËDESTEK VEKTOR MAKINALARINDA MODEL SECIMIDestek Vektür Makinaları (DVM), temeli istatistiksel ügrenme teorisine dayanan,o oğgüclü ve sık kullanılan ügrenme algoritmalarıdır. DVM'ler eğitilirken, data, doğrusaluş u oğ g golmayan bir şekirdek fonksiyon kullanılarak yüksek boyutlu bir uzaya taşınır ve pozitifc u sve negatif ürnekleri ayıran büyükşe marjlı bir ustün yüzey bulunur. En iyi şekirdeko uuc üu u cfonksiyonu seşmek ve ıkıden fazla sınıï¬ı probleme genellemek, DVM'lerdeki temel prob-clemlerdir.Literatürde, en iyi şekirdek fonksiyon deneme yanılma ile seşilmektedir. Bizu c cen iyi şekireği şapraz-geşerlemeye dayalı model seşimi ile bulmayı üneriyoruz. Adayc gc c c osınıï¬andırıcılar değişik şekirdeklerle eğitilir ve 5 Ã 2 şapraz-geşerleme F testi kul-gs c g c cülanılarak en iyi model seşilerek melez modeller oluşturulur. Onerilen melez modelinc sperformansı, bire karşı hepsi ve ikili sınıï¬andırma yüntemlerini kullanan DVM'lerles okarşılaştırılmıştır. Karşılaştırmada doğruluk ve karmaşıklık (saklanan destek vektürle-ss s ss g s orinin sayısıyla orantılı) kriterleri kullanılmıştır.sËIki sınıf problemi işin tanımlanmış olan temel destek vektür makinasının ikidenc s ofazla sınıf problemi işin genişletilmesi gerekmektedir. Bunun işin, ünerdiğimiz melezc s co gmodelleri bire karşı hepsi, ikili sınıï¬andırma ve hata düzelten şıktı kodları (HDCK) kul-s u c şülanan yüntemler işinde kullandık. Onerdiğimiz melez modellerin HDKC ile kullanımı,o c g şşok sınıï¬ı problemlerde karmaşıklığı belirgin bir şekilde artırmadan başarılı sonuşlarc sg s s cverdi.","1ABSTRACTMODEL SELECTION FOR MULTI-CLASS SUPPORTVECTOR MACHINESSupport Vector Machines (SVMs) are widely used, powerful learning algorithmsbased on statistical learning theory. In SVM learning, the data are mapped to a highdimensional space via a non-linear kernel function and a maximal margin hyper-planeseparating the positive and negative instances is found in this new space. Choosing thebest kernel and generalization to multi-class cases are fundamental problems in SVMlearning.In literature, the best kernel function is chosen by using trial and error. Wepropose to use a cross-validation based model selection method to ï¬nd the optimalkernel. Candidate classiï¬ers, with diï¬erent kernels are trained and hybrid modelsare built by selecting the best model using the 5 Ã 2 cross-validation F test. Theperformance of the proposed hybrid model is compared to the performances of classicalSVMs in one vs. all (OVA) and pairwise classiï¬cation schemes in terms of accuracyand complexity (as measured by the number of support vectors stored).The basic two-class support vector machine needs to be extended to handle themulti-class problems and for this purpose, we incorporate our proposed hybrid modelsin one vs. all , pairwise and error-correcting output code (ECOC) schemes. We see thatthe proposed hybrid model together with ECOC ï¬nds accurate solutions for multi-classproblems without signiï¬cantly increasing complexity."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"nitel uslamlama ve benzetim, özellikle dinamik sistemlerin analizi, tasarımı ve tanısıiçin faydalı matematiksel araçlardır. Eksik, yani belirli bir girdi için yanlış tahmin üretenbenzeticilere, genellikle o davranışı elimine eden ilave süzgeçler eklenir. Kuipers tutarlılıközelliğini içeren, bir başka deyişle, çıktısında, girdiye uyan nicel bir denklemin sonucu olanhiçbir davranışı kaçırmayan bir benzetici (QSIM) sunmuştur. Girdi ve çıktı alfabesi ?saf?QSIM ile aynı olan tutarlı ve tam bir benzeticinin varolmadığı ispatlanmıştır.Bu tez, nitel benzetimin hesaplanabilirlik kuramına dayalı sınırları üzerine bir seri ilavesonuçlar içermektedir. lk olarak, herhangi bir sınırsız yazmaçlı makinenin modellemesi vebenzetimi için bir method ortaya koymakta ve bununla nitel benzetimin evrensel hesaplamagücüne sahip olduğunu tesis etmektedir. Evrensel hesaplama gücüne sahip olan hesaplamaaraçlarının meşhur kararlaştırılamaz Durma Problemi'nden indirgeme yardımıyla, girdi veçıktı da QSIM alfabesi kullanmak suretiyle, girdi ve çıktı alfabesinin pek çok ?daraltılmış?versiyonu için, tutarlı ve tam bir benzetici yapılamayacağını ispat etmektedir. Çalışma, içindesüreklilik kurallarına tamamı ile uyulduğu tek bir çalışma alanı içinde işleyen tutarlı ve tambir benzetici elde etmenin imkansız olduğunu kanıtlayan nihai bir ispatla sona ermektedir.Bu tezdeki sonuçlar QSIM girdi ve çıktı alfabesi kullanılarak ortaya konmuştur ve girdiçıktı alfabesi QSIM ile aynı olan tüm benzeticiler için geçerlidir. Sonuçlar, yanlış tahminlerinsebepleri ile ilgili daha derin ipuçları vermeleri açısından önemlidir ve daha daraltılmıştemsili alfabeler kullanarak tutarlı ve tam nitel benzeticiler yaratmaya çalışan araştırmacılarıyakınen ilgilendirmektedir.","Qualitative reasoning and simulation are useful mathematical tools, especially for theanalysis, design and diagnosis of dynamic systems. Simulators which are seen to beincomplete, that is, which produce spurious predictions for a particular input, are usuallyaugmented with additional filters eliminating that behaviour. Kuipers introduced asimulator (QSIM) which has the soundness property, that is, no trajectory which is thesolution of a concrete equation matching the input can be missing from the output. It hasbeen proven that there does not exist a sound and complete simulator whose input andoutput vocabularies are identical to those of the ?pure? QSIM.This thesis contains a series of further results about computability-theoreticlimitations of qualitative simulation. Firstly, it demonstrates a method for modeling andsimulating an arbitrary Unlimited Register Machine (URM) using QSIM, and therebyestablishes that qualitative simulation has universal computational power. By making useof reductions from the famous undecidable Halting Problem for computation toolspossessing universal computational power, it proves that it is impossible to build a soundand complete qualitative simulator using the QSIM representation for input and output forseveral ?weakened? versions of the representation. It finishes with an ultimate result thatachieving a sound and complete simulator, which operates only in a single operating regionin which continuity rules are fully obeyed, is impossible,.The results in this thesis are demonstrated using the QSIM representation for inputand output, and are valid for all qualitative simulators whose input and output vocabulariesare identical to that of QSIM. They are important in the sense that they provide deeperinsight to the causes of spurious predictions, and they are also interesting for researchersaiming to construct provably sound and complete simulators using weaker representations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZETOLASILIKSAL MUHAKEME (ARGÜMANLAMA) SİSTEMLERİNESNE-GEÇİŞSEL İLİŞKİ-GEREKTİRME MODELİVE VERİMLİ UYGULAMALARIBu çalışma karmaşık ağların incelenmesine yönelik yapılmış bir çabadır. Temel olarak,bir bağ analizi tabanlı seviyelendirme (BTS) algoritması tanıtılacak ve ilgili altyapıgeliştirilecektir.Öncelikle karmaşık ağların incelenmesi için grafik tabanlı Nesne-Geçişsel İlişki-Gerektirme (NGİG) modeli tanıtılacak ve kullanımı incelenecektir. Altyapıyı oluşturanmatematik model Olasılıksal Muhakeme Sistemleri (OMS) üzerinde yapılmış olup busistemler de matematik lojik ve olasılık teorisi üzerine kurulmuşlardır. NGİG modeli genel birçerçeve olup bir ağ yapısı içindeki nesnelerle (örn. ağ sayfaları, makaleler) bunları bağlayangeçişsel bir bağı (örn: ağ bağları (?link?ler)) incelemek için yapılmıştır. NGİG modellemesiniBTS problemi için uygulamaktayız. Bu işlem için yerleşmiş kanıtsal sebep üretmetekniklerini açık bir şekilde kullanmaktayız, ancak direk hesaplamalar NP-zor bir problemiçermektedir. Bu sebeple yaklaşık sonuç üreten NGİG Destek Yayılması olarakadlandırdığımız algoritma ailesini sunmaktayız. Bunlardan bir tanesini detaylı inceleyerek,sonlu sayıda iterasyon ile yaklaşık sonuçlar ürettiğini gösteriyoruz. Her iterasyon için yapılanişlemler ağ içindeki bağ sayısı ile lineer şekilde bağlantılıdır. Algoritmalarımızı CiteSeerbilimsel atıf ağına uyguladık. Bu ağ üzerinde seviyelendirme yapılarının karşılaştırmalısonuçlarını sunmaktayız. Çalışmamız baskınlığın küresel etkilerden yerel etkilere geçişinintemel bir BTS algoritması karakteristiği olduğunu ortaya çıkardı. Algoritmamız farklıparametreler ile kullanıldığında PageRank veya atıf sayımı ile yüksek korelasyonlu olabilensonuçlar üretmektedir.","ABSTRACTPROBABILISTIC ARGUMENTATION SYSTEMSENTITY-TRANSITIVE RELATION-IMPLICATION MODELAND DOCUMENT RANKING AS AN EFFICIENT APPLICATIONThis work is an endeavor towards analyzing complex networks. Mainly, a link analysisranking (LAR) algorithm will be introduced, and related background will be developed.Firstly, we introduce a graph based model we name Entity-Transitive Relation-Implication Model (ETRI) for analyzing complex networks. The underlying mathematicalmodel is built on Probabilistic Argumentation Systems (PAS), which are a combination of theuse of propositional logic and probability theory. The ETRI model is a generic framework,capable of dealing with entities (e.g. web pages) in a network linked by a transitive relation(e.g. hypertext links). We apply ETRI modeling to the LAR problem. This is desirablebecause it builds on established evidential reasoning techniques using clear semantics,however a direct application involves an NP-hard problem. Thus we present a family of novelalgorithms we call ETRI Support Propagation for approximations. We examine a member ofthese and show that it produces approximate results in finite iterations. Its iterations are linearin the number of edges of the network like PageRank. We run our algorithms on a snapshot ofthe CiteSeer citation network. We present a comparative study of different ranking schemes.Our studies reveal the transition of dominance from local to global influences as an importantcharacteristic of LAR algorithms. Our algorithms give results which can be highly correlatedwith citation count or PageRank when parameterized correspondingly."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET MAC VE RBAC MODELLERİ İLE XML DOKÜMANLARI İÇİN İNCE- YAPILI ERİŞİM KONTROL SİSTEMİ TASARIMI Günümüzde; XML, bilginin sunumu alanında betimleme dilleri arasında konuyla ilgili yapılan standartlaştırma çalışmalarından en ilgi çekenidir ve büyük bir hızla genel ağ üzerinde verinin gösterimi ve değişim standardı haline gelmektedir. Genel Internet ve tüzel Intranetler üzerinde dağınık verilerin büyük bir önem kazanması ile birlikte; XML dokümanlarında bulunan verilerin güvenliği literatürde önemli bir nokta haline gelmiştir. XML şifreleme ve dijital imzalama tekniklerinin yanında XML güvenliği alanında en çok çalışılan konulardan biri de XML dokümanları üzerinde erişim kontrol modeli tasarımıdır. XML dokümanları üzerinde erişim kontrolü çalışmaları ince-yapılı erişim kontrol modeli sistemi tasannu, erişim kontrol poliçeleri için etkili depolama mekanizmalarının tasarımı ve erişim kontrol poliçelerinin uygulanma stratejileri üzerine odaklanmıştır. Bu tez çalışmasında, bir XML dokümanının farklı bölgelerine erişmek isteyen çok büyük sayıda kullanıcılara sahip, bilgi akışının kritik ve güvenilirliğin esaslı olduğu bir ince-yapılı erişim kontrol sistemi tasarlanmıştır. Sistemde öznelerin, nesneler üzerinde erişim haklarını belirlemek üzere erişim kontrol listeleri yerine güvenlik etiketleme sistemi geliştirilmiştir. Bunun yanında XML dokümanının erişilebilirlik görünümünü oluşturmak için iki aşamalı bir budama sistemi oluşturulmuştur. Bu çalışmanın esas amacı, verinin güvenilirliğinin önemli olduğu sistemler için rol tabanlı erişim kontrolü ve zorunlu erişim kontrolü modellerinin avantajlarından yararlanarak ince-yapılı, esnek ve etkili bir erişim kontrol sistemi tasarlamaktır.","ABSTRACT DESIGN OF A FINE-GRAINED ACCESS CONTROL SYSTEM FOR XML DOCUMENTS WITH MAC AND RBAC MODELS Today, XML (extensible Markup Language) is currently the most relevant standardization effort in the area of document representation through markup languages and is rapidly becoming a standard for data representation and exchange over the Web. By gaining significant importance in distributed data over corporate Intranets and global Internet; the security of data in XML documents has become an important issue in the literature. Besides XML Encryption and Digital Signature techniques; one of the most studied areas in XML Security is to design an access control model over XML documents. The studies on access control over XML documents are focused on modeling a fine grained access control model, designing an effective storage mechanism for access control policies and enforcement strategies of access control policies. In this thesis study, a fine-grained access control system is designed where the information flow is critical and the confidentiality of the data is an essential issue like in military applications where there is huge number of users who needs to access the different portions of an XML document. Instead of using access control lists, a security labeling approach is developed to define the rules that a subject has a granted access to an object. Besides that it is designed a two-phase pruning system to achieve the accessibility view of the XML Document. The main goal of this thesis study is to design a fine-grained, flexible and effective access control system using the advantages of role-based access control and mandatory access control where the confidentiality of the data is critical."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET SEYAHAT ACENTELERİNİN E-İŞ'E UYARLANMASI İÇİN İŞ SÜREÇLERİNİN YENİDEN TASARLANMASI İnternet ve e-işe uyarlama, seyahat acenteleri için çağımızın en önemli konulandır. İnternetin coğrafi sınırlan kaldırmasına ve seyahat acentelerine iş yapma konusunda pek çok fırsat sağlamasına rağmen seyahat acentelerinin çoğu hala interneti kullanmamaktadır. Bu nedenle yakın bir gelecekte rekabet edebilirliklerini kaybedeceklerdir. Bu tez çalışmasında, seyahat acentelerinin e-iş ortamına uyarlanması için iş süreçlerinin yeniden tasarlanması amaçlanıldı. Seyahat acentelerinin şu anda var olan iş süreçlerini ve gereksinimlerini öğrenmek için röportajlar ve anketler yapıldı, iş süreçleri incelendi ve var olan raporlar, formlar ve prosedürler gözden geçirildi. Böylece görüldü ki Türkiye'deki seyahat acenteleri bir ölüm kalım savaşının içindeler ve acilen yeni bir tasarıma ihtiyaçları var. İş süreçlerini modellemek ve yeni modeli tasarlamak için yapısal teknikler kullanıldı. Süreçlerin içindeki tüm değer katmayan adımlar elendi, geri kalan adımlar basitleştirildi, basitleştirilmiş görevler, müşteri ihtiyaçlarının ve hizmet işlerinin dağıtımında düzgün bir akış sağlamak için bütünleştirildi ve sonunda otomatikleştirmeye hazırdı. Önerilen yeni model daha fazla esneklik ve rahatlık sağlamaktadır. Maliyetleri düşürmekte, seyahat acentelerinin şirket içi iletişimini ve rekabet edebilirliğini geliştirmektedir.","IV ABSTRACT BUSINESS PROCESS REDESIGN FOR THE ADOPTION OF TRAVEL AGENCIES TO E-BUSINESS The Internet and e-business adoption are the most important issues of this century for travel agencies. Although the Internet removes the geographical boundaries and provides travel agencies many opportunities to do business, many of the travel agencies still do not use the Internet, therefore, in the new future they may lose their competitiveness. The aim of this thesis is to redesign the business processes of travel agencies to help them adopt to e-business environment. In order to learn the current business processes (as-is system) and the requirements of travel agencies, interviews and questionnaires were conducted, business processes were observed and existing reports, forms and procedures were reviewed. It was seen that travel agencies in Turkey are in a life or death struggle and an immediate redesign is necessary. The structured techniques were used for modeling the business processes and designing the new model. All non-value adding steps in process were eliminated, the remaining steps were simplified, simplified tasks were integrated to affect a smooth flow in delivery of the customer requirements and service task, and finally it was ready to automate. The proposed new model provides greater flexibility and convenience. It reduces costs, improves communication and competitiveness of travel agencies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET ETMEN TABANLI İŞ AKIŞI ÇALIŞTIRMA DILI İLE BİRLEŞİK WEB SERVİSLERİ Web servisleri standartlara dayanan yeni bir dağıtık yazılım mimarisidir. Web servisleri, iş mantığının farklı ortamlar arasında güvenli gelişimine olanak sağlamak amacıyla servis bazlı mimariyi doğru olarak hayata geçirebilmeyi destekler. Günümüzde web servisi teknolojilerinin gelişim süreci devam etmektedir. Bu sürecin temel standartların gelişmesine rağmen tamamlanmamış olması, iş çevrelerinin halen Web servisi teknolojileri hakkında tartışmalarına yol açmakta ve web servislerinin asıl amacı olan iş verimliliğim arttırmanın önüne geçmektedir. Bu bağlamda, tezin hazırlanmasındaki başlıca hedef, web servislerinin derinlemesine anlaşılmasını sağlamak ve iş dünyasındaki potansiyel gücünü sebepleriyle ve kullanım şekilleriyle ortaya koymaktır. Tez çalışması web servisi teknolojileri ve bu teknolojileri üreten firmalar ile ilgili kapsamlı inceleme sonuçlan içermektedir. Özellikle çalışmanın büyük bir bölümü, teknoloji ilerledikçe ihtiyaç duyulan ve web servislerinin birleştirilmesini sağlamayı hedefleyen 'Birleşik Web Servisleri' alanına ayrılmıştır. Web servisleri alanı geliştikçe bu servislerin birbiriyle ilişkilerini sağlayacak mekanizmalara ihtiyaç doğmuştur. Bu ilişkilendirmeyi saylamayı amaçlayan oluşumlar içinde en umut vaat edeni BPEL'dir. Yine de iş dünyasının ve birleştirilmiş Web servislerinin gereksinimlerini karşılamak adına iyileştirmeler gerekmetedir. Bu bağlamda araştırmamızda BPEL dokümanlarının çalıştırılma performanslarını arttırmayı hedefleyen bir yapı kurmayı amaçladık. Bunu hedeflerken öncelikle BPEL içindeki flow yapı taşı üzerine yoğunlaştık. Temel amaç paralel çalıştırılması gereken aynı amaca hizmet eden fakat kullanıcının tercihlerine veya servis kalitesi parametrelerine uymayan işlerin kontrollü bir şekilde pasif hale getirilmesidir. Bunu sağlayacak olan bizim öne sürdüğümüz yapının en önemli parçası ajandır. Tezin sonunda önerdiğimiz yapının değerlendirilmesinine yardımcı olması adına bir örnek uygulama da bulunmaktadır.","ABSTRACT WEB SERVICES COMPOSITION WITH AGENT BASED BUSINESS PROCESS EXECUTION LANGUAGE Web services are new standards-based distributed computing architectures. They support for true Service Oriented Architecture (SOA). Web services are still a work in progress. Even for business people, most discussions of Web services focus on the technology of Web services, although core specifications like Extensible Markup Language (XML), Simple Object Access Protocol (SOAP), Web Services Description Language (WSDL), and Universal Description Discovery Integration (UDDI) are almost mature. From these thoughts in mind, the principal goal underlying this thesis will be to emphasize the potential of Web services solutions by studying Web services technology in- depth. Our research includes Web services composition which is one of the struggles of the Web Services Architecture. As the momentum around Web services grows, there is an increasing need for effective mechanisms of Web services interaction. Business Process Execution Language (BPEL) is a good candidate, which satisfies needs of the business to overwhelm this phenomenon. Although BPEL proves that it is the most promising business execution language in Web services area, there should be some improvements to fulfill all the requirements of composing Web services. We constructed an architecture to improve performance of business process executions when especially parallel execution is required in BPEL documents. Our architecture decides which paths to follow in execution according to user preferences or Quality of Service (QoS) parameters. If one can balance the user preferences with business executions in BPEL, he would not execute unnecessary and useless branches of parallel executions that may cause delaying the whole process. The controller agent is responsible for this balance. In other words, the agent decides appropriate execution flow based on user preferences and on historical data gathered from each execution of BPEL document. Our research concludes with a use case to explore the possibility of achieving the proposed architecture. The use case also helps us to better understand the performance changes caused by our approach when it is applied."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET VAVFRAME-HACIMSEL ANALIZ VE GORSELLEŞTIRME ÇATISI Literatürdeki tıbbi görselleştirme sistemlerinin paylaştıkları özellikler vardır. Bu sistemler modülerlik, kullanıcı tarafından genişletilebilme, işlevsel modüllerden bir ağ oluşturmak ve uygulama ağının çalışması ile etkileşmek için bir grafiksel kullanıcı arayüzü sağlamaktadırlar. VAVPrame var olan sistemlerin temel özelliklerine ek olarak, uygulamanın son kullanıcısı ile modül geliştiriciler arasında aracı rolü oynayan uygu lama tasarımcısı ismiyle yeni bir kullanıcı grubu ortaya koymaktadır. Son kullanıcı dan gelen özel bir uygulama isteği uygulama tasarımcısı tarafından değerlendirilir ve var olan modüllerin bir ağı olarak kurulur. Tasarımcı aynı zamanda son kullanıcıya sunulacak arayüz elemanlarının özelleştirilmesinden sorumludur. Bu yaklaşım hem özel uygulama geliştirme sürecini hızlandırmakta hem de anjiyografi ve kolonografi örneğinde olduğu gibi ilk bakışta farklı gözüken fakat teknik açıdan benzer operasy onlar arasında ileri derecede modüler paylaşım sağlanmaktadır. Bunun yanısıra son kullanıcı modüllerden ağ oluşturma işinin altında yatan karmaşadan arındırılmaktadır. Buradaki esas amaç hem geliştirme hem de özelleştirme etkinliğini artırmaktır. Bu tez aynı zamanda 3B veri ile etkileşim problemine VAVPrame çatısı altında çözüm aramaktadır. Fare ve klavye gibi alışılagelmiş arayüz araçlarına alternatif olarak sezgisel bir 3B kesit alıcı geliştirilmiştir. Yaklaşımın dayandığı temel 3B sanal kesit alıcı olarak kullanılan düzlemsel bir nesnenin çift kamera ile takip edilmesidir. Bu çözüm VAVPrame için bir modül haline getirilmiş ve diğer modüller ile birleştirilmiştir.","ABSTRACT VAVFRAME- VOLUMETRIC ANALYSIS AND VISUALIZATION FRAMEWORK Existing medical visualization systems share common features. They provide modularity, user extensibility, a graphical user interface to construct network öf compu tational modules and to interact with the execution of the application network. While providing all of the above, VAVPrame introduces a new user group called application designer which acts as an intermediary between the end-user of the application and the developers of the individual modules. A custom application request from the end- user is evaluated by the application designer and constructed as a network of existing modules. The designer is also responsible of the customization of the interface com ponents presented to the end-user. This approach speeds up the custom application development process as well as providing improved module sharing between seemingly different but technically similar applications, such as angiography and colonography. The end-user is also saved from the underlying complexities of constructing a network of modules. The goal is to increase efficiency in both development and customization. This thesis also addresses a common problem of interacting with 3D data within VAVPrame. An intuitive 3D sheer is developed and implemented as an alternative to conventional user interaction tools such as mouse and keyboard. The approach is based on stereo tracking a planar object used as a virtual 3D slicer."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,ÖZET KİLİT MONTAJ İŞLEMİNDE ENDÜSTRİYEL OTOMASYON TASARIMI VE GERÇEKLEŞTİRİLMESİ Günümüz üretim ve pazar koşullarında firmalar istikran sürdürebilmek için geniş ürün yelpazesi ve yüksek kalite gibi ölçütleri sağlamanın yanında maliyetlerini de en alt seviyeye çekmek zorundadırlar. Dengeli üretim hatları kurup üretim akışım mümkün olduğunca hızlandırmak maliyetler üzerinde büyük değişiklikler sağlayabilir. Bunun yollarından birisi ise günümüz teknolojisinden faydalanarak üretim hatlarına uygulanabilecek otomasyon alternatiflerini değerlendirip gerçekleştirmektir. Bu tezde Kayseri Organize Sanayi Bölgesinde kilit üretimi yapan HOKK Kilit firmasında bir ürünün montaj işleminde bir noktada oluşan darboğazı aşabilmek için tasarlanmış iki alternatif sistem önerisi üzerinde durulmuş ve bunların değerlendirilip karşılaştırılması sonucunda en uygun olan gerçekleştirilmiştir. Tez çalışması sırasında ilk olarak alternatif sistemlerin simülasyonu yapılarak bunların olası çıktıları elde edilmiştir. Simülasyon için ARENA programı kullanılmıştır. Alternatiflerin olası çıktılar üzerinden maliyet hesabı yapılarak çalışan sistem ile önerilen alternatifler karşılaştırılmıştır. Karşılaştırma sonucu alternatifler arasında tercih yapılmıştır. Servo motor kullanılan alternatiflerin kontrolü için mikroişlemci tabanlı bir elektronik kart tasarlanmıştır. Bu elektronik kart ile yine tez çalışması sırasında tasarlanan ara yüz arasındaki haberleşmede seri haberleşme mantığı kullanılmıştır.,"IV ABSTRACT DESIGN AND IMPLEMENTATION OF INDUSTRIAL AUTOMATION IN LOCK ASSEMBLY Firms should achieve some goals such as having wide variety of products and reaching high quality as well as reducing the costs to minimum levels in order to be well- armed against current production and market conditions. To set up balanced production lines and to increase the production speed may heavily change the costs. One of the ways of reaching this goal is to evaluate and implement the possible automation alternatives that can be applied to production lines by making use of the current technology. In this thesis, we worked on two alternative systems designed to overcome a bottleneck occurred in assembly process of a product produced by a firm, HOKK Kilit in Organized Industrial Region. Firstly, we acquired possible outcomes of the alternative systems by simulating them on PC. We used a computer software ARENA in the simulation process. After calculating the costs of the alternatives using the possible outcomes, we compared the existing system and the suggested system. Then, we chose one of the alternatives based on the results. We designed an electronic card based on a microprocessor to control the servo motor in chosen alternative. We used serial interface between this card and the user interface on the PC."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET iki eklemli doğrudan sürülebilir bir robot kolunun denetim algoritmalarının kıyaslamalı değerlendirilmesi Bu tezde, iki eklemli doğrudan sürülebilir SCARA tipindeki bir robot manipülatörü için farklı yörünge denetim algoritmaları uygulanmış ve takip performanslarına göre birbirleriyle karşılaştırılmışlardır. Doğrudan sürülebilir bir sistem olduğundan, yüksek hızlarda ortaya çıkan doğrusal olmayan etkenler doğrudan manipülatör denetimine yansıtılır. Bu da manipülatörü değişik yörünge izleme denetim algoritmalarım sınamak için daha faydalı bir sınama yatağı yapar. Bu çalışmada uygulanan denetimciler orantılı türev denetimi, hesaplanan tork denetimi, dolaysız, dolaylı, bileşik ve çok modelli uyarlamalı denetimciler, kayma tipli denetimci ve uyarlamalı kayma tipli denetimcilerdir. Tüm bu denetim algoritmaları önce C programlama dilinde yazılmış bir benzetim programında sınanıp daha sonra gerçek zamanda SCARA tipindeki robot kolu üzerinde uygulanmıştır. Uygulanan algoritmaların izleme başarılan birbirleriyle aslında yörünge izleme kesinliklerini sayısal olarak tanımlayan bazı anlamlı başarım ölçütlerine göre karşılaştırılmıştır. Bu denetimcilerin performansları değişik ağırlıkların etkisi altoda da karşılaştırılmıştır. Bütün deneysel ve benzetim sonuçlan ile bunların tartışmaları, uygulanan her bir kontrol algoritmasının üstünlükleri ile sakıncaları birlikte sunulmuş ve her bir uygulanan denetim algoritmasının ayrıntılı kuramsal temelleri de verilmiştir.","IV ABSTRACT COMPARATIVE EXPERIMENTS FOR THE CONTROL OF A TWO- LINK SCARA MANIPULATOR In this thesis, different control algorithms for the trajectory control of a two-link SCARA (Selective Compliance Assembly Robot Arm) type direct drive robotic manipulator are implemented and compared with each other according to their tracking performances. Being a direct drive system, the nonlinear effects arising from the dynamics of the manipulator under high velocities are directly reflected in the control of the manipulator. This makes the manipulator a more efficient test bed for testing the efficiency of the different tracking control schemes. The controllers that are implemented in this research are the PD controller, computed torque controller, direct, indirect, composite and multi-model based adaptive controllers, sliding-mode controller and adaptive sliding mode controller. All the control schemes are first tested through simulations which are written in the C programming language and then implemented under real time conditions on the SCARA type robot arm. The tracking performances of the implemented algorithms are compared with each other according to some meaningful performance indices which in fact define the tracking accuracies of the implemented control schemes numerically. The performances of the controllers are compared under different payloads as well. All the experimental and simulation results are presented along with the discussion of these results to demonstrate the advantages and drawbacks of each of the implemented control schemes and a brief theoretical background for each implemented scheme is also given."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET iki dereceli hareket serbestliğine sahip kauçuk eyleyicilerden oluşan bir robot kolu için robot denetim deney seti tasarımı Kauçuk eyleyici kullanan havalı sürücülü sistemlerin düşük sürtünme, büyük güç/ağırlık oranı gibi birçok özellikleri vardır. Kauçuk eyleyici tabanlı sistemlerin birçok üstünlüklerine rağmen doğrusal olmaması ve histerez özelliği göstermesinden dolayı hedef yörüngeyi izlemede tatmin edici bir başaran elde etmesi zor olmuştur. Bu çalışmada, robot kolunun denetimi geleneksel geri besleme denetleyicisinin (PID) geri yayılım yapay sinir ağlan ters modeli birleşimi ile yapılmıştır. Geri besleme sistemin kararlılığını sağlamak ve dış bozucu girişi bastırmak için kullanılırken ileri besleme, hedef izlemeyi iyileştirmek için kullanılmıştır. İleri beslemeli yapay sinir ağlarının yapısı robot kolunun Lagrange mekaniğine dayanır. Önerilen denetim sistemi iyi şekilde ayarlanmış PID denetleyicisi ile farklı yörüngelerde, farklı hızlarda karşılaştırılmıştır. Deneylerin sonuçları, önerilen sistemin başarımının iyi ayarlanmış PID denetleyicisine göre daha iyi olduğunu göstermiştir.","IV ABSTRACT DESIGN OF A ROBOT CONTROL EXPERIMENT SETUP FOR A 2-DEGREE OF FREEDOM RUBBERTUATOR ROBOT Pneumatic drive systems using Rubbertuators have many features such as low friction, large power/weight ratio. In spite of many advantages of the Rubbertuator-based systems, it has been difficult to obtain the satisfactory tracking performance for reference trajectory because of nonlinearity and hysteresis involved with Rubbertuator systems. In this study, the robot arm is controlled with the combination of traditional feedback controller (i.e. PID) and backpropagation neural network inverse model. Feedback is used for stabilizing the system and for suppressing disturbances while the feedforward control is used for improving the reference tracking. The structure of the feedforward neural network is based on Lagrangian mechanics of the robot arm. The proposed control system is compared with a well-tuned PID controller for different trajectories with different velocities. The results of the experiments have shown that the performance under the control of the proposed system was better compared to a well-tuned PID controller."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TERS SARKAÇ DENETİMİ: YUKARI KALDIRMA VE DENGEDE TUTMA İÇİN ÇEŞİTLİ STRATEJİLERİN KIYASLANMASI Bu tezde, doğrusal olmayan bir elektro-mekanik sistem olan ve açık çevrimde kararsız özellik gösteren, ters sarkacın yukarı kaldırılması için iki farklı denetim tasarımı dengede tutulması için üç farklı denetim tasarımı yapılmıştır. Deneysel amaçlı gerçekleştirilen denetleyiciler, yukarı kaldırma için bulanık mantık kullanan bir sezgisel denetleyici ve bir enerji denetleyicidir. Yukarıda dengede tutmak için durum değişkeni geri besleme denetleyicisi ve en uygun denetleme tekniği olan LQR denetleyici ve iyi bilinen geleneksel denetim tekniği olarak kullanılan PID denetleyici uygulanmıştır. Denetimin amacı sarkacı başlangıçtaki aşağı sarkık pozisyonundan yukarıya kaldırmak ve burada dengede tutarken dayanak yörüngede, konumunu izlemesidir. Önerilen tekniklerden üç farklı karışım seçilmiş ve başarımları incelenmiştir. Karşılaştırdığımız zaman görülmüştür ki, her denetleyicisi farklı durumlarda belli üstünlüklere ve faydalara sahiptir.","IV ABSTRACT CONTROL OF INVERTED PENDULUM: COMPARISON OF VARIOUS STRATEGIES FOR SWING UP AND BALANCING In this thesis, two different control schemes are designed for swinging up and three different schemes for balancing of an inverted pendulum, a non-linear electro mechanical system with open loop unstablity. The controllers which are implemented for experimental purpose are a heuristic control technique using fuzzy logic and an energy control technique for swinging up. In order to balance the pendulum in the upright equilibrium, state feedback control, LQR control which is an optimal control technique and well known traditional control technique PID control are implemented. The control objective is swinging up the pendulum from its initial downward equilibrium to the upward and then balance at this state while it is tracking of desired trajectory. Three different combinations of proposed control schemes are chosen and their performances are compared with each other. Having compared all combinations, it is observed that every controller has advantages and merits for different cases."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"AnahtarÂ Kelimeler:Â UygulamaÂ üretme,Â YazılımÂ geliştirme,Â NesneyeÂ dayalıÂ yazılım,Â EsnekÂ üretim sistemleri,Â  KesikliÂ olayÂ benzetimiÂ MevcutÂ  uygulamaÂ  veÂ  kodÂ  üreticileriÂ  özelÂ  görevlerÂ  içinÂ  tasarlanmışlardır.Â  YazılımÂ geliştirmeÂ  süreçlerininÂ  bazıÂ  adımlarındaÂ  kullanılırlarÂ  veÂ  birÂ  yazılımınÂ  bütünününÂ geliştirilmesiÂ  içinÂ  yeterliÂ  değillerdir.Â  BUILD.NETÂ  nesneÂ  tabanlıÂ  yazılımlarÂ  içinÂ  yeniÂ  birÂ çizgeselÂ uygulamaÂ üretmeÂ çerçevesiÂ ortayaÂ koymaktadır.Â DiyalogÂ formlarıÂ veÂ akışÂ şemalarıÂ kullanarakÂ  kaynakÂ  kodunuÂ  programlaraÂ  dilineÂ  bağlıÂ  olmadanÂ  temsilÂ  edebilmektedir.Â  BuÂ yollaÂ  programlamaÂ  diliÂ  bilmeyenlerdeÂ  nesneÂ  tabanlıÂ  yazılımlarÂ  geliştirebilmektedir.Â GeliştirilenÂ çerçeveÂ  bahsedilenÂ çizgeselÂ gösterimiÂ dörtÂ farklıÂ programlamaÂ dilindeÂ kaynakÂ kodunaÂ çevirebilmektedir.Â OluşturulanÂ kaynakÂ koduÂ başkaÂ  birÂ derleyiciÂ  veyaÂ  yorumlayıcıÂ kullanılmadanÂ uygulamayaÂ çevrilebilir.Â ÖnerilenÂ yglamaÂ üretmeÂ çerçevesiÂ karmaşıkÂ  birÂ  yazılımÂ geliştirmeÂ projesindeÂ testÂ edilmiştir.Â  BILD.NETÂ  kllanılarakÂ  esnekÂ  imalatÂ  sistemleriÂ  içinÂ  nesneÂ  tabanlıÂ  veÂ  kesikÂ zamanlıÂ  birÂ  benzetimÂ  paketiÂ  geliştirilmiştir.Â  BÂ  sahaÂ  çalısmasıÂ  geliştirilenÂ  çerçeveninÂ gerçekÂ hayattaÂ yglanabilirliğiniÂ göstermiştir.","Keywords:Â  ApplicationÂ  generation,Â  SoftwareÂ  development,Â  ObjectÂ  orientedÂ  software,Â FlexibleÂ manfactringÂ systems,Â DiscereteÂ eventÂ simlationÂ ExistingÂ  applicationÂ  andÂ  codeÂ  generatorsÂ  areÂ  designedÂ  forÂ  domainÂ­specificÂ  tasks.Â TheyÂ  areÂ  sedÂ  inÂ  theÂ  intermediateÂ  stepsÂ  ofÂ  softwareÂ  developmentÂ  processÂ  andÂ  areÂ  notÂ intendedÂ  toÂ  developÂ  fllÂ  scaleÂ  applications.Â  BILD.NETÂ  introdcesÂ  aÂ  newÂ  graphicalÂ applicationÂ generationÂ frameworkÂ forÂ objectÂ­orientedÂ softwareÂ implementation.Â ItÂ tilizesÂ aÂ langageÂ­netralÂ  representationÂ  ofÂ  sorceÂ  codeÂ  throghÂ  dialogÂ  formsÂ  andÂ  flowÂ  diagrams.Â ThisÂ  representationÂ  methodÂ  allowsÂ  nonÂ­programmersÂ  toÂ  developÂ  objectÂ­orientedÂ  softwareÂ easily.Â TheÂ designedÂ frameworkÂ canÂ convertÂ thisÂ graphicalÂ representationÂ intoÂ sorceÂ codeÂ inÂ  forÂ  differentÂ  programmingÂ  langages.Â  GeneratedÂ  sorceÂ  codeÂ  canÂ  beÂ  compiledÂ  intoÂ exectableÂ directlyÂ withotÂ singÂ anyÂ externalÂ compilerÂ orÂ interpreter.Â ProposedÂ  applicationÂ  generationÂ  frameworkÂ  isÂ  testedÂ  onÂ  aÂ  complexÂ  softwareÂ developmentÂ  project.Â  AnÂ  objectÂ­orientedÂ  discreteÂ­eventÂ  simlationÂ  packageÂ  forÂ  flexibleÂ manfactringÂ systems,Â FMS.NET,Â isÂ implementedÂ byÂ singÂ BILD.NET.Â ThisÂ fieldÂ stdyÂ showsÂ thatÂ thisÂ frameworkÂ canÂ easilyÂ beÂ tilizedÂ onÂ realÂ lifeÂ scenarios."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÇEVRİTLERDEN ÜÇ-BOYUTLU ÇOK ÇÖZÜNÜRLÜKLÜ ARAZİ MODELİ YARATILMASI Çevrit haritalan günümüzde halen arazi yükseklik bilgileri için en önemli veri kaynağı olma özelliğini sürdürmektedir. Bir çok bilimsel ve teknik sistemde, daha iyi algılama, otomatik işleme ve analiz yapılabilmesi için nesnenin üç boyutlu modeline ihtiyaç duyulmaktadır. Örnekleme noktalarından otomatik olarak eğrilerin oluşturulması ve orta eksen dönüşümleri alanında yapılan çalışmalar çevritler arasındaki konumsal ilişkilerin daha iyi yorumlanabilmesine olanak sağladı. Bu teknikler sayesinde yaratılan arazi modellerindeki vadi, sırt ve doruk noktalarda oluşabilen ""düz üçgen"" problemi ortadan kaldınlabildi. Bu tezin amacı, çevrit teknikleri üzerine yapılmış yeni çalışmalar ışığında, çevrit tabanlı üç boyutlu (3B) arazi model yaratılması için çevrit tabanlı bir yaklaşım geliştirmektir. Bu tezde iki alternatif metod denenmiştir. İlk olarak, her bir çevrit basitleştirilmekte, ve sonrasında bu basitleştirilmiş çevritlerden 3B ağ yaratımı gerçekleştirilmektedir. İkinci yaklaşım olarak, daha az sayıdaki çevritten 3B ağ yaratımı gerçekleştirilmiştir. Çalışmamızda ilk metodun daha iyi çalıştığı gösterilmekte ve bu yaklaşımla elde edilen sonuçlar aşamalı ağ yöntemi gibi geleneksel 3B sadeleştirme metodlanyla karşılaştınlmıştır.","IV ABSTRACT MULTIRESOLUTION 3D TERRAIN GENERATION USING CONTOURS Contour maps are still the most widely available data source for terrain elevation information. In many scientific and technical systems, three dimensional object views are required to better understand the structure or to facilitate its automatic manipulation and analysis. Lately, studies on the automatic reconstruction of the curves from sample points and the medial axis transforms have greatly helped to realize spatial relationships between contours. These techniques help us to remove ""flat triangles"" that exists on the ridges, valleys and summits of the terrain. The aim of this thesis is to build a contour-based approach for multi resolution 3D terrain generation based on these recent advances in contour techniques. In this thesis, we try two alternatives. First, we simplify individual contours and then build 3D meshes from these simplified contours. In the second approach, we try to use fewer contour lines to build meshes. We show that the prior alternative performs better and compare this approach with conventional 3D simplification methods such as progressive meshes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vüOZETS-LOC VE MY ENVIRONMENT: OTONOM ROBOTLARËşË ËË Ë Ë ËICIN YENI BIR LOKALIZASYON SISTEMILokalizasyon problemi, başlangış konumunun bilinmediği durumlarda cevredens c g şalgınan bilgileri kullanarak bir robotun cevresine güre konumunu belirlemesidir. Kısaca,ş o?Neredeyim?? sorusunu yanıtlamaktır. Lokalizasyon, birşok yüntemin literatüre dahilc o uedildiği aktif bir calışma alanıdır.g şsRobotların gerşek hayattaki gibi sınırlı ve gürültülü algısal bilgilere sahip ol-c u u uumalarından ve cevrelerinin oldukşa hareketli olmasından dolayı, robot futbolu lokali-ş czasyon tekniklerinin geliştirilmesi ve denenmesi işin iyi bir ortamdır.s cBu şalışmada, yeni bir lokalizasyon tekniği ve algılama modülüyle algılama modü-cs g uu ulünün şıkışını kullanan oteki modüller arasında bulunacak yeni bir modül oluşturulmuş,uu c s ü u u s sbunların ikisi birlikte yeni bir lokalizasyon sistemi olarak ünerilmiştir.o süOnerilen yeni modül, My Environment, algısal verileri depolar ve ï¬ltrelenmiş,u sdaha sağlıklı veriler sağlar. Yeni lokalizasyon tekniği olan S-Loc ise her algısal veri işing g g csadece bir ürneğin kullanıldığı ürnek tabanlı bir lokalizasyon tekniğidir.og go gBu sistem, RoboCup 2005 - Sony Dürt-Ayaklılar Ligi'nin Teknik Yarışmalaro skategorisini kazanan Cerberus'05 bünyesinde gerşekleştirilmiştir. Bu başarı, deney-u c s s ssel şalışmalarla birlikte onerilen şüzümün uygulama alanı işin yüksek bir performansacs ü co u u c usahip olduğunu güstermektedir.g o","ivABSTRACTS-LOC AND MY ENVIRONMENT: A NEWLOCALIZATION SYSTEM FOR AUTONOMOUS ROBOTSThe localization problem is the detection of the pose of a robot relative to theenvironment using the information about the environment sensed by the robot whenthe starting position is unknown. In short, it is answering the question ?Where amI??. Localization is an active ï¬eld of study where many approaches are introduced intothe literature.Robot soccer is a good platform to develop and test localization techniques sincethe robots have limited and noisy sensorial information as in the real life and theenvironment is also highly dynamic.In this work, a new module that will stand between the perception module andthe other modules that uses its output and a new localization technique are introduced,and they are together proposed as a new localization system.The proposed new module is My Environment, which stores the perceptional dataand provides a ï¬ltered and more robust data, and the new localization technique isS-Loc, which is a sample based localization technique where only one sample is usedfor each perception data.This system is implemented in Cerberus?05, which won the Technical Challengesin the RoboCup 2005 - Sony Four-Legged League. This success, together with theexperimental study, has shown that the proposed solution has a high performance forthe application domain."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZETBİR ARMATÖR FİRMA İÇİN BULANIK MANTIK KARAR VERMEYÖNTEMİ İLE YAZILIM SEÇİMİBu çalışma temel olarak EMES Denizcilik ve Nakliyat A.Ş.'nin operasyonlarınıyönetmek için kullanacağı yazılımın, bilgi talep dökümanı (RFI), iş senaryoları ve tanıtımdeğerlendirilmeleri ile seçiminin yapılması üzerine odaklanmaktadır.Arkas Holding bünyesindeki şirketlerden birisi olan EMES Denizcilik ve Nakliyat A.Ş.acenteleri ve merkez ofisi arasındaki işlerin ilerleyişindeki manuel çalışma, e-posta ağırlıklıiletişim, işlemlerdeki bilgi eksikleri yüzünden takip, kontrol, onaylama ve raporlamazorlukları ve gecikmeleri yaşanmaktadır. Firmanın ihtiyaçlarına en uygun yazılımın doğru birdeğerlendirme ile seçilmesi gerekmiştir. Bu konu firmanın büyümesi ve rekabeti açısındankritik bir konu olmuştur. Temel operasyonlar ve aktiviteler firmanın ilgili departman müdürve sorumlularından elde edinilmiştir. Toplanan bilgiler şirketlerin standart yazılımpaketlerinin değerlendirilmesi için genelleştirilmiş bilgi talep dökümanına çevrilmiştir.Paketlerin operasyonel uygunluğunun detaylı tesbiti için yüksek öneme sahip beş adetsürecin anlatıldığı beş farklı senaryo oluşturulmuştur. Ayrıca satıcı firmaların tanıtımlarınındeğerlendirilebilmesi için sorular oluşturulmuştur. Satıcı firmaların bulanık mantıkyöntemiyle değerlendirilmesinde RFI skorları, geliştirme süreleri ve satınalma maliyetlerikullanılmıştır.Son olarak firmanın operasyonlarına ve ihtiyaçlarına en uygun ürünü gösteren birdeğerlendirme tablosu ve bulanık mantık sonuçları hazırlanmıştır.Anahtar Kelimeler: Bilgi Sistemi Satınalması, Yazılım Seçimi, Metne Dayalı Senaryo,Bilgi Talep Formu (RFI), Bulanık Mantık","ABSTRACTSOFTWARE SELECTION FOR A LINER SHIPPING COMPANYUSING FUZZY LOGIC DECISION MAKINGThis thesis mainly focuses on selection of software for managing operations of EMESShipping and Transportation Company by the evaluations of scripted scenarios, requests forinformation (RFI), and demonstrations from software companies.EMES Shipping and Transportation Company, which is a member of Arkas HoldingGroup experiences difficulties and delays in reviewing, approving, controlling and reportingoperations between Head Quarter and Agencies due to processes that were overburdened withmanual tasks, e-mail based workflow, and lack of process information. It is a necessity toselect software from the market by evaluating them in the terms of company requirements.This process is a critical issue for future growth and competitiveness of EMES.Key operations and activities of the company are obtained from department managersand staff. Gathered information is converted to a generalized request for information for theevaluation of the companies and their standard software packages. Five major scriptedscenarios are prepared to understand how the software packages handle the operations ofsoftware packages. A demo evaluation document prepared for scripted scenarios to evaluatedemonstrations.A fuzzy approach is designed to evaluate companies with RFI scores, developmenttime, and purchase cost variables. Finally an evaluation table and fuzzy based comparisonresults are prepared to show most fitting product to company operations and requirements.Keywords: IS Procurement, Software Selection, Request for Information (RFI), ScriptedScenario, Fuzzy Logic"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"1üOZETËË ËGIZLI ALTGRUP ALGORITMALARININËGENELLEMELERIGelecekte bir bitlik bilginin bir atomla güsterilmesi süz konusu olacaktır. Buo odurumda, klasik mekanik atomik seviyede incelenen bu modeli aşıklamada yetersizckalacaktır. Bunun yerine, kuantum mekaniği kullanılmak zorunda kalınacaktır. Kuan-gtum biti, 0 ve 1'in süperpozisyonları şeklinde var olmaktadır. Bu süperpozisyonlarınu s uyaratılabilmesi ve uzerlerinde paralel hesaplama yapılabilmesi klasik hesaplamadanüdaha hızlı şozümlere izin vermektedir. Kuantum hesaplaması, bu ï¬ziksel üzelliklerdencü u oyararlanılarak bilişim problemlerinin nasıl daha verimli şekilde şozülebileceğini in-s s cü u gceleyen araştırma alanıdır.sBu tezde, bazı kuantum algorithmalarının genelleştirilmesi problemi incelenmiştir,s sbüylece bu algoritmalar tanım kümesinin eleman sayısının ikinin ussü olmak zorunda ol-o u üumadığı durumlarda şalışacaklardır . Bu algoritmaları analiz ederken, eleman sayılarınıng csikinin ussü olması gerekmeyen bazı vektür kümelerinin eşit olasılıklı süperpozisyonların-üu ou s uın mükemmel uretilmesinin mümkün olduğu varsayımında bulunulmuştur. Ballhysa'nınu ü uu g süngürdüğu model ürnek kabul edilmiş, Chi, Kim ve Lee'nin Deutsch-Jozsa algoritmasıo o ug ü o sgenellemesi olarak hazırladıkları algoritmalar ile Simon'ın algoritmasına uyarlanmıştır.s","1ABSTRACTGENERALIZATIONS OF HIDDEN SUBGROUPALGORITHMSIn the future, it can be possible to store bit information in atoms. In thatcase, classical mechanics will not be enough to explain the atomic level model. Insteadquantum mechanics will have to be used. A quantum bit exists as a superpositionof 0 and 1. Creating superpositions and making parallel computation on them willallow faster solutions than classical computation. The ï¬eld of quantum computationexamines the possibility of using these physical properties for solving computationalproperties more eï¬ciently.In this thesis, we consider the problem of generalizing some quantum algorithmsso that they will work on input domains whose cardinality is not necessarily powersof two. When analyzing the algorithms we assume that generating superpositions ofarbitrary subsets of basis states whose cardinalities are not necessarily powers of twoperfectly is possible. We have taken Ballhysa?s model as a template and have extendedit to Chi, Kim and Lee?s generalization of the Deutsch-Jozsa algorithm and to Simon?salgorithm."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"RASTSAL KUANTUM GEZİNTİLERİNİN BENZETİMİNİNENİYİLENMESİUĞUR KÜÇÜKBilgisayar bilimleri alanında üstel ifadelerle ölçülen bir başarım artışı, pratikteçözülebilir sayılan problemler kümesinin tanımını genişletebilecek kadar önemli bir başarıdır.Kuantum bilgisayarlarına duyulan ilginin arkasında bazı kuantum algoritmalarının klasikeşdeğerleri karşısında üstel ifadelerle ölçülecek düzeyde hız kazanımları sağlamalarıyatmaktadır. Bu çalışmada, bu algoritmaların en yenisi, rastsal kuantum gezintilerine dayalıolanı ele alınacak. Rastsal kuantum gezintileri yoluyla üstel algoritmik hız kazanımları eldeetmenin metodları detaylı biçimde incelenecek. Bu inceleme, kuantum bilgisayarlarının temelkavramlarının, kuantum benzetim tekniklerinin ve rastsal kuantum gezintisi fikrinin tartışıldığıtanıtıcı bölümlerden sonra yer alacak. Ayrıca rastsal kuantum gezintilerinin kuramsaluygulamasına dair yeni bir eniyileme tekniği de tanıtılacak. Bu teknik benzetim algoritmasınındöngüsel adımlarında küçük süreler için benzetimlenen bileşen Hamilton operatörlerinin sırasıüzerinde yapılacak oynamalara dayanmaktadır. Yaklaşımımız doğrusal kombinasyonlarkuralının bir grup Hamilton operatörünün benzetiminde kullanıldığı durumlar içingenelleştirilebilir.","OPTIMIZATION OF QUANTUM RANDOM WALK SIMULATIONSUĞUR KÜÇÜKIn computer science, an exponential performance gain is considered an importantachievement that can extend the set of practically computable problems. Behind the interest inquantum computation, there is the fact that several quantum algorithms have been shown toprovide exponential speedup against their classical counterparts. Of these, the most recent one,the one based on quantum random walks, is discussed in this work. The methods used indemonstrating the exponential algorithmic speedup by quantum random walks are analyzed indetail. This analysis comes after introductory parts where basic quantum computationconcepts, quantum simulation techniques and quantum random walk ideas are discussed. Anew optimization technique on the implementation of quantum random walks is alsointroduced. This technique is based on the idea of manipulating the order in which theconstituent Hamiltonians are simulated for small durations in the iterative step of thesimulation algorithm. Our approach can be generalized to optimize any quantum simulation inwhich the linear combination rule is used to simulate a collection of constituent Hamiltonians."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET.. TASARSIZ AĞLAR İÇİN YENİ BİR GRUP ANAHTAR YÖNETİMİ YAPISI GELİŞTİRİLMESİ Tasarsız ağlar önceden hazırlanmış bir altyapı olmadan kendi kendine haberleşebilen bir grup mobil cihazın oluşturduğu haberleşme ağlarıdır. Grup haberleşmesi, dağıtık ve katıhmsal uygulamaları içine alan, çok sayıda gönderici ve alıcının bulunduğu bir iletişim yöntemidir. Tasarsız ağlar grup haberleşme uygulamaları için ucuz ve kul lanımı kolay bir uygulama platformu oluşturur. Ancak böyle uygulamaları güvenli hale getirmek güçtür. Güvenliği sağlamaktaki temel zorluk kriptografik anahtarların yönetimidir. Bu tezin konusu tasarsız ağlarda grup anahtar yönetimi problemidir. Bu çalışma tasarsız ağlar için geliştirdiğimiz yeni, çok katmanlı ve katıhmsal bir grup anahtar yönetimi yöntemini içerir. Sunduğumuz yöntem çok katmanlı altgrup yapısına dayanmaktadır. Çözümümüzün ana fikri her katmanda bir önceki katmanda elde edilen bir anahtarı kullanarak anahtar paylaşımı protokolleri koşturmaktır. Amaç grup anahtarını grubun her üyesinin katılımıyla üretmektir. Sunulan yöntem çevrim sayısı, üssel işlem sayısı ve toplam mesaj boyu kıstaslarında tek katmanlı katıhmsal grup anahtarı paylaşımı yöntemlerine göre daha verimli çalışmaktadır.","IV ABSTRACT DEVELOPMENT OF A NEW GROUP KEY MANAGEMENT SCHEME FOR MOBILE AD HOC NETWORKS A mobile ad hoc network is self-organizing network which consists of a collection of mobile nodes that do not have a pre-established infrastructure to provide connectiv ity. Group communication is a many-to-many communication paradigm, which applies to distributed and collaborative applications. Mobile ad hoc networks constitute a cost effective and easy-to-use platform for group communication applications. How ever, securing such applications is a challenging task because of the nature of mobile ad hoc networks and group communication protocols. Key management is the core problem in providing security. This thesis addresses the problem of cryptographic key management for group communication in mobile ad hoc networks. We developed a new hierarchical and contributory group key management scheme which works efficient in mobile ad hoc networks. Our solution proposes a multilevel subgroup structure. The main idea of our hierarchical group key management scheme is to use contributory protocols at each level of the subgroup hierarchy, using a key produced at one level as the input for upper level key agreements. The aim is to generate a group- wide secret key, using contributions from each member. The proposed scheme decreases number of rounds, number of exponentiations and total message size for key agreement with respect to a totally flat key agreement scheme."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V ÖZET telsiz kanallarda imgeler için damgalama kullanarak hata giderimi Bu çalışmada, hataya açık telsiz bir kanaldan iletimi sırasında, yüksek oranda paket kayıbı sonucu bozuluma uğrayan bir imgeye uygulanabilecek yeni bir hata gideri mi algoritması önerilmektedir. Sınırlı kaynaklara sahip ağlarda çalışan gerçek zamanlı uygulamalarda ek gecikmelere uğratılmamak ve bant genişliğini dikkatli kullanmak büyük önem taşır. Hata giderim teknikleri bu bozulumları onarmak için basit bir yapı sağlamaktadır. Ne yazık ki, şu anda var olan hata giderim tekniklerinin çoğu eğer paket kayıpları belli bir eşik değerin altında ise ve/veya düzgün dağılıma sahipse çalışmaktadır. Veri saklama yöntemlerini kullanmak bu kısıtları aşmak için olası bir yaklaşımdır. Bu nedenle, makroblok tabanlı en-uygun-komşu-eşlemesi bilgisini orijinal imgeye ayrık dalgacık dönüşümünü kullanarak gömen ve böylece uzamsal artıklıktan faydalanan bir hata giderim tekniğini araştırdık. Bu tekniğin çeşitli telsiz kanallardaki başarımmı benzetim kullanarak değerlendirdik. Önerilen hata giderim tekniğinin, ori jinal imgenin algısal kalitesinde bir miktar kayıp pahasına, özellikle yüksek hata içeren kanallarda başarılı olabildiğini gösterdik. Dolayısıyla, yöntemimizin geri-uyumlu bir şekilde, kablosuz ağlardaki bu sorunlarla savaşım için gerçeklenmesini öneriyoruz.","IV ABSTRACT ERROR CONCEALMENT FOR IMAGES OVER WIRELESS NETWORKS USING WATERMARKING In this thesis, we propose a new error concealment method for covering up the high packet losses of an original image after its transmission through an error-prone wireless channel. Error-concealment techniques provide a simple framework to compen sate these distortions without incurring additional delays and wasting bandwidth which is crucial for real-time applications over networks with limited resources. Unfortunately, most of the existing error-concealment techniques work only if the packet losses are smaller than a threshold and/or they are uniformly distributed. Utilizing data hiding techniques is a potential approach to overcome this restriction. We investigated an er ror concealment technique utilizing discrete wavelet transform (DWT) for embedding macroblock-based best-neighborhood-matching (BNM) information into the original image in order to utilize spatial redundancy. We call this method Best- Neighborhood- Matching Based Wavelet Domain Error Concealment Technique (BNMWEC). We eval uated the performance of this technique with various wireless channel models by using simulations. We propose to implement it for wireless networks to combat degradation of image quality in a backward compatible scheme. We show that the proposed error concealment technique is a promising one, especially for the erroneous channels causing a wider range of packet losses, at the expense of some degradation in the perceptual quality of the original image."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TÜRKİYE İÇİN FİNANSAL KRİZ TAHMİNİ YAPAN BİR VERİ MADENCİLİĞİ MODELİ Türkiye'de oluşabilecek bir fînansal krizi önceden tahmin etmek üzere bir veri madenciliği modeli öne sürülmektedir. Bu amaca yönelik olarak, 1997'de ortaya çıkan Asya fînansal krizinin göstergesi olduğu düşünülen yedi oran, bu veri madenciliği modelinde girebilecek aday oranlar olarak alınmıştır. Türkiye'de oluşabilecek bir fînansal krizi tahmin etmeye uygun oranlan seçmek için t-test kullanılmıştır. Ocak 1998 ile Ekim 2000 zaman aralığım kapsayan veri kullanılarak, t-testini geçen oranlar standartlaştırılmıştır. Fisher' in Doğrusal Ayrıştırma Analizi kullanılarak her oranın katsayısı belirlenmiştir. Daha sonra da erken uyan sinyalinin verileceği seviyeyi belirleyen eşik değeri hesaplanmıştır. Öğrenme verisinin ortalama değerlerini, standart sapmalarını, modelin katsayılarım ve eşik değerini kullanarak, Türkiye Ekonomik Stabilite Endeksi (TESE) olarak adlandırdığımız, Nisan 1992 ile Eylül 2004 zaman aralığım kapsayan bir zaman serisi oluşturulmuştur. Eğer TESE erken uyan sinyali verirse, bu 10 ay sonra bir fînansal krizin ortaya çıkabileceği anlamına gelir. Ancak modelde bulunan değişkenlerin 3 ay geç açılanmasından dolayı TESE fînansal krizi ancak yedi ay önceden tahmin etmektedir.","IV ABSTRACT A DATA MINING MODEL FOR PREDICTING A FINANCIAL CRISIS IN TURKEY A data mining model is proposed to forecast a financial crisis in Turkey. For this purpose, seven ratios that have been thought of as the indicators of the 1997 Asian financial crisis are taken as the candidate ratios that would be included in the data mining model. Student's t-test is used in order to select the appropriate ratios for the prediction of a financial crisis in Turkey. The ratios that pass t-test are standardized by using only the training data, which includes the time period between January 1998 and October 2000, inclusively. By means of Fisher's linear discriminant analysis, the coefficient of each ratio is determined. Then, a cut-off value that gives the level of the early warning signal is calculated. Using the means and the standard deviations of the training data, the coefficients of the model and the cut-off value, a time series called Turkish Economic Stability Index (TESI) is constituted for the time period between April 1992 and September 2004, inclusively. If TESI gives an alarm signal, it means that a financial crisis may occur ten months later. However, TESI predicts a financial crisis seven months in advance because of the three-month lag time of the included variables."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TÜRKÇE İÇİN KORPUS TABANLI BIRLEŞTIRMELI KONUŞMA SENTEZLEME SİSTEMİ Konuşma sentezi yazılı metnin makine tarafından üretilmiş sentetik konuşmaya çevrilmesi işlemidir. Birleştirmeli konuşma sentezleme sistemleri sentezlemeyi daha önceden kaydedilmiş ses parçalarını birleştirerek yapar. Korpus tabanlı metotlar (parça seçme) birleştirilecek ses parçalarım seçmek için geniş bir ses parçası veritabanı kul lanırlar. Bu tez kulağa doğal insan sesi gibi gelen, anlaşılabilir korpus tabanlı bir leştirmeli bir konuşma sentezleme sistemi geliştirmek için harcadığımız emeğin bir sonucudur. Tasarlanan sistem metin normalizasyonu, metin analizi ve isteğe bağlı kul lanılan nakledilen vurgu ön birimlerini içerir. Parça seçme algoritması veritabanmdaki parçaların oluşturduğu ağda Viterbi algoritması ile en iyi patikanın bulunmasına daya nır. Arka uç harmonik kodlama ses modeli ve üst üste getirip ekleme yöntemini kul lanarak ses dalga formunu oluşturur. Bu çalışmada farklı parça büyüklükleri, örneğin heceler, fonemler ve yarım fonemler denenmiştir. Konuşma korpusu tasarımı ve kayıt metinlerinin seçilmesinde kullanılan metotlar açıklanmıştır. Sesi modellemek ve ses dal gası oluşturmak için harmonik kodlama yöntemine dayanan bir ses modeli geliştirilmiş tir. Harmonik kodlama, ses veritabanmı 3 kat sıkıştırmayı sağlamıştır. Parça seçmede spektral süreksizlik ve vurgusal uyumsuzluk objektif maliyet ölçekleri kullanan Viterbi algoritması yazılmıştır. Türkçe fonem seti oluşturulmuştur. Türkçe için metinden foneme çevrim üzerinde çalışılmış ve de kök kelimelerin okunuşlarını içeren bir sözlük hazırlanmıştır. Basit bir metin normalizasyon modülü yazılmıştır. Parça seçmede vur gunun önemini araştırmak için nakledilen vurgu kullanan ve vurgu modeli kullanmayan sistemler karşılaştırılmıştır. Sentetik konuşma kalitesini değerlendirmek için öznel din leme testleri yapılmıştır. Sonuç olarak MOS benzeri bir derecelendirmede 4.2 puan alan bir Türkçe konuşma sentezleme sistemi geliştirilmiştir.","IV ABSTRACT A CORPUS-BASED CONCATENATIVE SPEECH SYNTHESIS SYSTEM FOR TURKISH Speech synthesis (text-to-speech) is the process of converting the written text into machine generated synthetic speech. Concatenative speech synthesis systems ren der speech by concatenating pre-recorded speech units. Corpus-based methods (unit selection) use a large inventory to select the units and concatenate. This thesis is part of an effort to design and develop an intelligible and natural sounding corpus-based concatenative speech synthesis system for Turkish. The implemented system contains a relatively simple front-end comprised of text analysis, phonetic analysis, and optional use of transplanted prosody. The unit selection algorithm is based on commonly used Viterbi decoding algorithm of the best path in the network of the units. The back-end is the speech waveform generation based on the harmonic coding of speech and overlap- and-add mechanism. In this work, the different unit sizes such as syllables, phones and half-phones have been experimented with. Speech corpus design and recording script preparation methods have been explained. A speech model based on harmonic coding of speech has been developed for speech representation and waveform generation. The harmonic coding has enabled us to compress the unit inventory size by a factor of three. A Viterbi decoding algorithm using spectral discontinuity cost and prosodic mismatch objective cost measures has been implemented. A Turkish phoneme set has been de signed. Text-to-phoneme conversion for Turkish has been worked on, and a root words pronunciation lexicon has been constructed. A simple text normalization module has been implemented. The importance of prosody in unit selection has been studied by using transplanted prosody vs no synthetic prosody modeling in unit selection. Sub jective tests have been carried out for evaluating the synthesized speech quality. The final Turkish speech synthesis system got 4.2 MOS like score in the listening tests."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ORUNTU TANIMA İÇİN DOĞRUSAL OLMAYAN BOYUT İNDİRGEME METODLARI Boyut indirgemenin amacı verideki önemli bilgileri tutarken, verinin daha az boyutlu ve daha basit gösterimini bulmaktır. İlgili öğeleri çıkarmak ve ilgisiz olanları süzmek için yüksek boyutlu verilere boyut indirgeme uygulamak gereklidir. Bunun sonucunda daha basit modeller ve veri hakkında yararlı bilgiler elde edilir. Bu tezde boyut indirgeme için gözetimsiz, doğrusal olmayan metotları çeşitli stan dart değerlendirme veri kümelerinde deneyerek ele alıyor ve karşılaştırıyoruz. Ayrıca daha önce karşılaşılmamış veri noktaları sorununu çözmek üzere eşleme fonksiyonlarının öğrenimini öneriyoruz. Bu çahşmada, veri dağılımının doğasında bulunan ölçü birimlerinin kullamlmasınm Öklid mesafesinden daha iyi modellemeye olanak sağladığım ve yüksek boyutlu veri modellerinin doğruluklarını arttırdığını gözlemledik.","IV ' ABSTRACT NONLINEAR DIMENSIONALITY REDUCTION METHODS FOR PATTERN RECOGNITION The aim of dimensionality reduction is to find a lower dimensional, simpler representation while keeping the important information in the data. It is essential to employ dimensionality reduction for high dimensional data in order to extract relevant features and filter the non-relevant ones. This allows obtaining simpler models and useful knowledge from the data. In this thesis, we discuss and compare several unsupervised nonlinear methods for dimensionality reduction, namely, Isomap, Locally Linear Embedding (LLE), Curvilin ear Component Analysis (CCA), Curvilinear Distance Analysis (CD A) and Stochastic Neighbor Embedding (SNE), by testing their accuracies on standard benchmark data sets. We propose a modification (SNE-Iso Hybrid), and introduce the implicit learning of mapping functions in order to solve the problem of mapping previously unseen data points. We observe that using the metrics inherent in the data distribution allows better modelling than using the Euclidean distance and increases the model accuracies for nonlinear data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TELSİZ DUYARGA AĞLARINDA BİRDEN FAZLA MERKEZ YERLEŞTİRME PROBLEMİ VE ENERJİ VERİMLİLİĞİ Kablosuz algılayıcı aygıtlarının ömürleri açısından, enerji en önemli kaynaktır. Bu yüzden, ağın ömrünü en üst düzeye çıkarabilmek için, enerjinin kullanımı en iyi şekilde yönetilmelidir. Enerji tasarrufu için, çıkış gücünün ayarlanabildiği verici devrelerini kullanmanın yanı sıra, çok zıplamalı konuşma hatları kullanılmalıdır. Bununla birlikte, çok fazla sayıda algılayıcıdan oluşan büyük ölçekli algılayıcı ağlarında, veri toplamak için birden fazla merkez kurulmalıdır. Bu sayede, hem ağ daha kolay yönetilebilecek, hem de her bir algılayıcının enerji harcaması azaltılmış olacaktır. Bu tezde, birden fazla merkez düğümün algılayıcı ağı alanına yerleştirilmesi ile ilgili problemleri ortaya çıkardık. Birden fazla merkezli algılayıcı ağlan için yeni ifadeler ve tanımlar içeren bir çerçeve oluşturduk. Daha sonra, çok hoplamalı konuşma hatlarının kullanılmasının enerji harcamasındaki etkisini inceleyerek, alternatif rotalardaki kazançları analitik tekniklerle karşılaştırdık. Bu sırada, çok hoplamalı konuşma hatlarının kullanılmasının her zaman enerji kazancını sağlamadığını gösterdik. Bunun yanı sıra, her hoplamada harcanan fazla enerjinin göz ardı edilmesi ve çıkış gücünün ayarlanabildiği verici devrelerinin öneminin gereğinden fazla önemsenmesi durumunda büyük enerji kayıplarının oluştuğunu gösterdik. Analitik sonuçlan, değişik senaryolar üzerinde çalıştırdığımız benzetim yöntemleriyle karşılaştırdık. Daha sonra, büyük ölçekli algılayıcı ağlarındaki birden fazla merkez yerleştirme sorunların inceledik. Ağ üzerindeki enerji harcamaların hesaplayabilmek için matematiksel bir formülasyon önerdik. Daha sonra, tasarım kriterlerine göre değişebilecek farklı sorunları listeledik. Son olarak, algılayıcı ağı için verilecek en az çalışma süresi kısıtını sağlayacak en az sayıda merkezin ağa yerleştirilmesi sorunu incelendi. Çözüm önerisi benzetim yöntemleriyle sınandı.","IV ABSTRACT MULTIPLE SINK LOCATION PROBLEM AND ENERGY EFFICIENCY IN LARGE SCALE WIRELESS SENSOR NETWORKS Energy is the most critical resource in the life of a wireless sensor node. Therefore, its usage must be optimized to maximize the network life. Besides using power adjustable transmitter circuitry, usage of multi-hop communication links should be considered to save energy. Moreover, in large-scale networks with a large number of sensor nodes, multiple sink nodes should be deployed, not only to increase the manageability of the network, but also to reduce the energy dissipation at each node. In this thesis, we introduce problems that are related with locating multiple sink nodes in the sensor network area. We give a framework consisting of new formulations and definitions for the multiple sink sensor networks. Then, we investigate the use of multi-hop communication links and compare the amount of energy gain upon alternative routes using analytical techniques. We show that employing multi-hop links does not always result in energy gain, and try to quantify situations when it is advantageous. We also show that neglecting the overhead energy and overemphasizing the importance of power adjustable transmitter circuitry could result in considerable energy loss. The analytical results are validated using simulations on different scenarios. Then, we focus on the multiple sink location problems in large-scale wireless sensor networks. We propose a mathematical formulation for sensor networks to calculate the energy dissipation throughout the network. Then we state different problems depending on the design criteria. Finally, we consider locating sink nodes to the sensor environment, where we are given a time constraint that states the minimum required operation time. We use simulation techniques to test our solution."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GÜVENLİK AGI İLE GÜÇLENDİRİLMİŞ 802.11 TELSİZ YEREL ALAN AĞI İÇİN POLİTİKA TANIMLAMA DİLİ Geniş alan ağlarında her yönetimsel alan bir grup güvenlik politikasına sahip tir. Yönetimsel alanlar birbirlerinden izole olmadığı için, sözkonusu güvenlik poli tikalarının entegrasyonu dikkate alınmalıdır. Dizüstü ve avuçiçi bilgisayarlar gibi mo- bil aygıtların varlığı, sözkonusu problemi daha karışık hale getirmektedir. Bu yüzden, farklı yönetimsel alanların güvenlik politikalarını oluşturan güvenlik politikası ele manlarının arasındaki uyuşmazlıktan kaynaklanan güvenlik açıklarının meydana gelme si kaçınılmazdır. Sözkonusu güvenlik açıklarının saptanması için formal bir politika tanımlama diline ihtiyaç vardır. Şu anda güvenlik politikalarını tanımlamakta kul lanılan konuşma dili ile karşılaştırıldığında, formal dilin avantajı Isabelle gibi teo rem ispatlama amaçlı yazılımların desteği ile güvenlik politikalarının doğrulanmasının mümkün olmasıdır. Bu tezde güvenlik ağı ile güçlendirilmiş 802.11 telsiz alan ağları için politika tammlama dili elde etmek amacı ile varolan Mobaati formal modeline ek lemeler yapılmıştır. Sözkonusu eklemeler, Mobadti modeline ait devingenlik ve haber leşme aksiyomlarına; sistem bilgisine, mimari operasyonlara ve dosya erişim operasyon larına ilişkin aksiyomların ilave edilmesi ile gerçekleştirilmiştir. Ortaya çıkan politika tanımlama dilinde örnek doğrulamalar, Mobadtı modeli için geçtirilmiş olan MaRK teorem ispatlama yazılımını, yazılım içinde gerekli uyarlamalar yapılmış hah ile kulla narak yapılmıştır.","IV ABSTRACT A POLICY SPECIFICATION LANGUAGE FOR AN 802.11 WLAN WITH ENHANCED SECURITY NETWORK In wide area networks, each administrative domain owns a set of security poli cies. Integration of these security policies should be considered, since administrative domains are not isolated from each other. The existence of mobile devices such as lap tops, PDAs and mobile agents makes the problem more complicated. Thus, existence of security flaws arising from inconsistencies among the elements of security policies of different administrative domains is inevitable. In order to detect such security flaws a formal policy specification language is needed. The advantage of a formal language compared to the natural language, is that it makes the verification of security poli cies via automated theorem proving tools, such as Isabelle, possible. In this thesis, we extend the existing network-aware formal model Moba(ni to obtain a formal policy specification language for 802.11 wireless LANs with enhanced security network. Ex tensions are made by adding axioms for system information, architectural operations and file access operations to existing mobility and communication axioms of Mobacıtı. In order to perform sample verifications using the axioms we formed, a proof assistant for Mobadti called MaRK is used with the necessary adaptations made."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET 3B YÜZEY ÇAKIŞTIRMA TABANLI ŞEKİL BİLGİSİNDEN 3B YÜZ TANIMA Yüz tanıma teknikleri son yıllarda büyük gelişmeler göstermiştir. Her ne kadar iki boyutlu imge tabanlı yüz tanıma algoritmalarında önemli ilerlemeler kaydedildiyse de, ışıklandırma, poz ve ifade farklılıklarından doğan sorunlar hala çözülebilmiş durumda değildir. Bu tür sorunları çözmenin diğer bir yaklaşımı ise şekil bilgisinin mevcut olduğu üç boyutlu yüz bilgisinden yararlanmak olabilir. Bu çalışmada üç boyutlu yüz tanıma algoritmalarında kullanılmak amacıyla insan yüzü şekil bilgisini ifade eden iki algoritma önerilmiştir. Bu algoritmaların ilkinde yüzler örtük polinomlar ve değişmezleri ile temsil edilip tanıma işlemi bu polinomlardan çıkarılan öznitelikler ile yapılmaktadır. Nokta Kümesi Farkı olarak adlandırılan ikinci yaklaşım ise çehresel yüzeylerin çakıştırılması ve yoğun nokta eşleştirmesine dayalıdır. Bu algoritmaların tanıma performansları diğer şekil tanımlayıcılarmmkilerle karşı- laştırılmıştır. Deneylerimiz, çakıştırma tabanlı yaklaşımın 30 kişilik gürültüsüz bir ver- itabanmda yüzde 98.9, 106 kişilik gürültülü bir veritabanında ise yüzde 93 oranında tanıma başarımı gösterdiğini ve ön işleme ve öznitelik çıkarma işlemlerinin diğer algorit malardan daha hızlı olduğunu göstermiştir. Ayrıca çakıştırma algoritmasının çıktıları Nokta Dağılım Modelleri gibi istatistiksel şekil değişikliği analizlerinde kullanılmaya hazırdır. Ayrıca, bir öznitelik seçme işlemi yüzün hangi bölgelerinin tanımada önemli olduğu-nu incelemek için uygulanmış ve sonuçlar ağız bölgelerinin tanımada pek etkin olmadığını, yüzün üst bölgesinin ise önemli bir rol üstlendiğini ortaya koymuştur.","IV ABSTRACT 3D FACE RECOGNITION FROM SHAPE INFORMATION BASED ON 3D SURFACE REGISTRATION Face recognition techniques have shown a great improvement in the last decades. Although important advances have been realized on image based 2D face recognition algorithms, there still remains some challenges to deal with like illumination, pose and expression variations. A convenient way to deal with these problems would be to utilize 3D information where the shape information of faces is directly available. In this work, we propose two different methods to represent shape information of human faces to be used in a three dimensional face recognition system. The first one describes the faces with implicit polynomials and their invariants. The second approach, called the Point Set Distance method, is based on the registration of facial surfaces and establishment of point-to-point dense correspondence. The recognition performances of the algorithms are compared with other shape descriptors and our results show that the surface description method based on reg istration produces yields classification results as good as 98.9 per cent on noise- free database consisting of 30 people and 93 per cent on a noisy database of 106 people. The preprocessing and feature extraction steps are performed faster than the existing methods and the outputs of the registration process are ready to be used for statistical purposes such as Point Distribution Models or other shape variation analysis. A feature selection method is also implemented to investigate the importance of different facial regions in the human 3D face recognition process. Results have shown that the upper part of the faces plays a crucial role."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DOĞRULU STEINER AĞAÇ PROBLEMİ İÇİN SERİ VE PARALEL ALGORİTMALAR Doğrulu Steiner ağaç problemi çok büyük ölçekli entegre devre tasarımı (VLSI) ve ağ yapılarında pek çok önemli uygulaması olan NP-complete bir problemdir. Bu tez çalışması doğrulu Steiner ağaç problemini inceler ve bu problemi çözmek için hem seri hem de paralel dallan ve kes algoritmaları önerir. Bu tezde, problemi kısa zamanda çözmemizi sağlayan cutsec ve birbiriyle çakışan güçlü kısıtlamalar adında iki yeni doğrusal programlama kısıtlaması gösterdik. Ayrıca, bir heterojen hesaplama ortamı içinde büyük problem örneklerinin çözümü için paralel mesaj geçişi algoritması sunduk. Hem paralel hem de seri algoritmalar nesne tabanlı yöntembilim kullanılarak C++ programlama diliyle yazılmış bir program içinde bütünleştirilmiştir. Sunulan algoritmaların deneysel sonuçlarına SteinLib kütüphanesi içinden alınmış TSP ve ES1000FST örnekleri üzerinde testler yaparak baktık. Sunulan algoritmaların doğrulu en küçük Steiner ağaç (RSMT) probleminin kesin sonucunu elde etmeleri için gerekli ortalama çalışma zamanının diğer rakip algoritmalardan daha iyi olduğunu gördük. Hazırladığımız programın, değişiklikleri ve geliştirmeleri kolaylaştıran arabirimi sayesinde geliştirilebilecek diğer algoritmalar için bir taban oluşturduğunu söyleyebiliriz.","IV ABSTRACT SEQUENTIAL AND PARALLEL ALGORITHMS FOR THE RECTILINEAR STEINER TREE PROBLEM The rectilinear Steiner tree problem is an NP-complete problem with many important applications in networks and very large scale integration (VLSI) design. This thesis examines the rectilinear Steiner tree problem and proposes sequential and parallel branch and cut algorithms to solve it. In this thesis, we present two new LP constraints, cutsec constraints and strong incompatibility constraints that allow us to greatly reduce the time to solve the prob lem. We also present a message passing parallel algorithm to solve large problem instances in an heterogenous computing environment. Both sequential and parallel algorithms are unified in a program that is written in C++ programming language by using object oriented methodology. We look at the experimental results of the presented algorithms by performing benchmark tests on TSP and ES1000FST instances from the SteinLib library. Average running time of the algorithms to solve the rectilinear Steiner minimal tree (RSMT) problem to optimality are better than that of other competing algorithms. We can also say that our program can be a base for other new developing algo rithms due to its interface that facilitates improvements and modifications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET PERA: LOKASYON BAZLI MULTIMEDYA SERVİSLERİ ÇATISI Bilgisayar teknolojisinin gelişmesiyle birlikte kullanıcılara sunulabilecek servislerde büyük bir artış oldu. Bilgisayarlar artık cebe sığacak kadar küçüklüler ve veri alışverişi için kablo kullanma zorunluluğu ortadan kalktı. Bu sayede insanlar artık istedikleri zaman istedikleri yerden bilgiye ulaşabilir oldular. Bu çalışmada, konum tabanlı, çokluortam servislerinin sunulabilmesi için bir sistem tasarlandı ve geliştirildi. Geliştirilen bu sistem sayesinde kullanıcılar, kablosuz ağ bağlantısı olan herhangi bir yerde diğer kullanıcılar ile sesli ve görüntülü olarak konuşabilecek, mesaj laşabilecek ve konumlarına bağlı olarak hizmet alabilecekler. Kullanıcıların konumları sistem içerisindeki bir modül taralından hesaplanarak diğer modüllerin kullanımına sunulmaktadır. Bu sayede konuma bağlı bilgiler kullanıcı istediğinde veya başka bir kaynak tarafından tetikîendiğinde kullanıcıya ulaştırılabilir. Ayrıca bu system sayesinde kullanıcılar diğer kullanıcıların konumlarını görebilir veya hareketlerini izleyebilirler. Bu çalışmanın bir diğer amacı da yeni servislerin sistem devredeyken eklenebilmesini sağlayan bir yapı sunmaktır. Sistemde kullanıcıya sunulabilecek servislerde herhangi bir kısıtlama bulunmamaktadır. Bu sayede operatörler istedikleri zaman yeni servis tanımlayabilir veya varolan servisler üzerinde değişiklik yapabilirler. Ük bölümde genel olarak sistemin genel yapısı tanıtılmıştır. İkinci bölümde varolan çözümler sunulmuştur. Üçüncü bölüm tasarımın ana hedeflerini, dördüncü bölüm ise sistemin mimari tasarımını ayrıntıları ile anlatmaktadır. Beşinci bölümde sistem üzerinde yapılan testler ve bunların sonuçlan verilmektedir. Son kısımda ise genel olarak alman sonuçlar sunulmakta ve sistemin gelecekte geliştirilebilecek yönleri tartışılmaktadır.","IV ABSTRACT PERA; LOCATION BASED MULTIMEDIA SERVICES FRAMEWORK With the improvements in computer industry, computers became smaller and more powerful. Pocket size computers and wireless network technology have opened a new area of services that can be offered to the users. Now, people are able to get information anywhere, anytime. In this study, a framework for delivering location based, multimedia services is proposed, designed and developed. With this new framework, in any place where there is wireless network access, users can make voice and video calls, use instant messaging and presence and benefit from location-based services. A module inside the framework determines locations of the users and this information is made available to other modules. Using this user location information, location-based services can be offered to the user on request or on time and location triggers. With this system, users can also see the location of their friends and track their assets. Another objective of this study is to provide a framework for the operators to develop new services while the system is up. There does not exist any limit on the number of services that can be developed. Using this framework, operators can define new services, and modify available ones whenever they wanted. In the first section, a general introduction of the system is given. In the second section, current solutions of the defined problems are presented. Third section defines main objectives of the system, and in the fourth section architectural details of the system are explained. In section five, performance tests and results are given. At the end of the document, general results of this study are presented, and future work on the system is discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BLUETOOTH SİSTEMİNİN KİMLİK DOĞRULAMASINA YÖNELİK AKTARMA SALDIRILARI VE ÇÖZÜMLER Bluetooth, kişisel alan kablosuz iletişiminde yaygınlaşmakta olan bir teknolojidir. Bluetooth bağlantı seviyesinde kimlik doğrulama ve şifreleme mekanizmaları sağlar. Fakat Bluetooth'un güvenlik sistemi bazı saldın tiplerine karşı savunmasızdır. Bu tez çalışmasında Bluetooth'un kimlik doğrulama protokolüne yönelik aktarma saldırılarını tanımlayacağız. Bu saldırıların amacı kimlik taklit etmektir. Saldırgan, kimliğinin doğruluğunu hedef cihazlara kanıtladıktan sonra bu cihazlar üzerindeki kısıtlı servislere erişebilir. Saldırganın bu saldırıları gerçekleştirebilmek için her iki hedef cihaz tarafından bilinen gizli bir bilgiyi tahmin etmesine veya ele geçirmesine gerek yoktur. Yapması gereken tek şey kimlik doğrulama protokolü çalışırken hedef cihazların birisinden aldığı bilgiyi diğerine aktarmaktır. Eğer hedef cihazlar birbirini duymuyorlarsa, Bluetooth'un kimlik doğrulama protokolü böyle bir aktarıma imkan tanır. Bu tür bir kurgu gerçek bir ortamda oldukça muhtemeldir. Hedef cihazlar gezici davranışlarından dolayı uzak yerlerde olabilirler veya saldırgan, hedef cihazların birbirlerini dinlemelerini engelleyebilir. Bu çalışmada, aktarma saldırılarını birkaç senaryo için analiz ettik ve her biri için çözümler önerdik. Bu çözümler Bluetooth kimlik doğrulama protokolünün güvenliğini geliştirmekte fakat varolan yapının üzerine önemli bir yük getirmemektedir. Ayrıca Bluetooth'un bağlantı kurma prosedürünü ve güvenlik protokollerini benzetimleyen bir Bluetooth simülatörü geliştirdik. Aktarma ataklarının olabilirliğinden emin olmak için bu simülatörü kullanarak saldırıların simülasyonunu yaptık. Bu simülasyon sonuçlan, mevcut Bluetooth protokol tanımlamalanmn aktarma ataklanna karşı savunma mekanizmalanmn olmadığım göstermektedir. Son olarak, aktarma saldınlan senaryolan üzerinde bazı deneyler yaptık ve deneysel zaman sonuçlannı analiz ettik. Aktarma saldınlannm bağlantı kurma süreci sırasında önemli bir kısmi gecikme yarattığı gözlendi. Bu kısmi gecikmeler akıllı bir yöntem ile aktarma saldmlannı tespit etmek için kullanılabilir. Çalışmamızda aktarma saldınlanna karşı böyle bir savunma mekanizması da önerdik.","IV ABSTRACT RELAY ATTACKS ON BLUETOOTH AUTHENTICATION AND SOLUTIONS Bluetooth is an emerging technology for personal area wireless communication. It provides authentication and encryption mechanisms on the link level. However, the security of Bluetooth is vulnerable to some types of attacks. In this thesis, we describe relay attacks on Bluetooth authentication protocol. The aim of these attacks is impersonation; having authenticated to the victims, an attacker can access to restricted services on the victim devices. The attacker does not need to guess or obtain a common secret known to both victims in order to set up these attacks. He merely relays the information received from one victim to the other during the authentication protocol run. Bluetooth authentication protocol allows such a relay if the victims do not hear each other. Such a setting is highly probable in a real environment. The victims may be in distant locations due to their mobile behavior or the attacker may prevent them to listen to each other. We analyzed the relay attacks for several scenarios and proposed solutions for each case. These solutions improve the security of the core authentication protocol of Bluetooth, but do not impose a significant burden on top of the existing authentication scheme. Moreover, we developed a Bluetooth simulator that implements Bluetooth connection establishment procedure and security protocols. By using this simulator, we simulated relay attacks to make sure about their feasibility. The results of these simulations show that current Bluetooth specifications do not have defensive mechanisms for relay attacks. Finally we set up some experiments on relay attack scenarios and analyzed empirical timing results. It has been observed that relay attacks create a significant partial delay during the connection establishment process that might be used in an intelligent way to detect relay attacks. In our study, we also offered such a protection mechanism against relay attacks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TCP MEKANİZMALARINDA SIKIŞIKLIK DENETİMİ VE AKTİF KUYRUK YÖNETİM MEKANİZMALARI Günümüzde İnternet, büyümeğe ve uygulama çeşitliliği olarak gelişmeğe devam ettikçe, sıkışıklık denetim mekanizmalarının oynadığı rol, bu farklı uygulamaların bek lentilerini karşılamak için gitgide daha önem kazandı. TCP (İletim Denetimi Protokolü), uç düğümler arasında çalışan ve ancak ağ aşırı derecede yüklendikten sonra tepkin, kendi sıkışıklık denetim mekanizmasına sahip ol masına rağmen, IETF (İnternet Mühendisliği Çalışma Kolu) bu mekanizmalara ilave olarak, sıkışıklık olmadan paketleri düşürerek, kaynaklara yeni başlayan sıkışıklığı önceden tepkin davranarak haber verecek ve yönlendiricilerde yürütülecek aktif kuyruk yönetim mekanizmalarını uygulamaya koymayı düşünmektedir. Bu çahşmada, iki farklı AQM (Aktif Kuyruk Yönetimi) mekanizması ve bunların parametrelerinin seçimi konusunun ana hatları önerilmiştir. İki mekanizma da bu lanık kontrol kuramına dayanmaktadır. İlk önerilen uyarlanır olmayan bulanık denet leyici, son senelerde önerilen pek çok AQM mekanizmalarından daha iyi performans göstermektedir. FMRLC (Bulanık Modele Dayanan Öğrenen Denetleyici) önerilen ik inci mekanizma olup, ağdaki farklı durumlara uyum göstermekte ve ilkine göre daha iyi sonuçlar almaktadır. Benzetim senaryoları sadece FTP (Dosya Aktarım Protokolü) bağlantılarından, kablosuz olanlara kadar değişmektedir. Karşılaştırma için incele nen performans ölçütleri, anlık kuyruk boyu, darboğaz bağının kullanımı, düşürülen paketler, bağlantıların sayısı ve adalettir.","IV ABSTRACT TCP CONGESTION CONTROL AND ACTIVE QUEUE MANAGEMENT MECHANISMS As the Internet continues to expand in size and diversity, congestion control mechanisms start to represent a more and more important role in meeting the expec tations of different applications. Although TCP (Transmission Control Protocol) has its own end-to-end conges tion control mechanisms, which act only in a reactive manner, in that congestion con trol is done after the network is overloaded, IETF (Internet Engineering Task Force) is thinking to deploy additional active queue management mechanisms executed by routers, which can be proactive and drop packets before congestion occurs and thus notify the sources of the incipient congestion. In this study, two different AQM (Active Queue Management) mechanisms and guidelines for their parameter selection are proposed. Both mechanisms are based on fuzzy control theory. The first one is a direct fuzzy controller that performs better than most of the AQM mechanisms proposed in the last few years. The second mechanism is a FMRLC (Fuzzy Model Reference Learning Controller), which adapts to different conditions in the network and shows even better results than the direct one. The sim ulation scenarios vary from FTP (File Transfer Protocol) connections only to wireless cases and performance metrics investigated for the comparison are the instantaneous queue length, bottleneck link utilization, dropped packets, number of connections and fairness."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yerleşim planlama hareketli ağlarda çok önemli bir problemdir. Genelde, kayıt ve arama maliyetleri gezgin bir kullanıcının şu anki konumunun takip edilmesi ile bağlantılıdır. Tüm ağı tek bir yerleşim alanı olarak kabul etmek arama maliyetini maksimize ederken ağda tek bir yerleşim alam bulunduğundan kayıt olma maliyeti sıfır olacaktır. Öte yandan, ağdaki her hücrenin bir yerleşim alanı olarak kabul edilmesi her yerleşim alanında sadece bir hücre bulunacağından arama maliyetini sıfırlarken kayıt maliyeti maksimize olacaktır. Tüm ağı yerleşim ağlarına bölmek ve her baz istasyonunu bu yerleşim ağlarına atamak toplam kayıt ve arama maliyetini minimize edebilir. Bu çalışmada, optimal ağ yapısını bularak gezgin bir kullanıcıyı takip etmenin maliyetini optimize etmek için üç evrimsel yöntem ve bu yöntemlerin birbirleri ile kıyaslanmaları sunuldu. Verilen bir ağı optimal yerleşim alanlarına ayırmak için Genetik Algoritmalar, Çoklu-Hedefli Genetik Algoritmalar ve Memetic Algoritmalar kullanıldı. Optimal ağ yapısını bulmak NP-Complete olduğu bilinen bir problemdir. Evrimsel algoritmalar normal arama algoritmalarının yetersiz kaldığı problemler için uygundur. Bu çalışma üç algoritmanın gerçekleştirilmesi ile ilgili detaylı bilgi vermesinin yanında bu algoritmaların sözkonusu problem üzerindeki performanslarının kıyaslamasını da sunar.","Location management is a very important problem in mobile networks. In general, registration and paging costs are associated with tracking the current location of a mobile user. Considering the whole network as a single location area (LA) maximizes the paging cost and minimizes the registration cost. On the other hand considering each cell as a separate LA maximizes the registration cost and minimizes the paging cost. Partitioning the whole network into location areas and assigning base stations to these location areas can minimize the total cost of registration and paging. In this work, three evolutionary methods for optimizing the tracking cost of a mobile user by finding an optimal network structure are given and their results are compared. Genetic Algorithms, Multi-Objective Genetic Algorithms and Memetic Algorithms are used to partition a given network into optimal location areas. Finding optimal network structure is known to be NP-Complete. Evolutionary algorithms are suitable for optimizations when normal search algorithms are inefficient. This work gives detailed explanation of implementation details for each algorithm and a comparative study about the performances of algorithms on this particular problem is given."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET MODEL TABANLI UÇ BOYUTLU EL ŞEKLİ TANIMA Bu çalışmada model tabanlı el şekli tanıma problemi ele alınmıştır. Model tabanlı el şekli tanıma sistemleri, el imgeleri ile bunlara karşılık bir el modelinin benzerliğini arttırmayı hedeflerler. Burada silindir ve küre gibi çok temel şekillerle oluşturulmuş oldukça basit bir geometrik model kullanılmıştır. Kullandığımız benzerlik ölçütü üç boyutlu modelin izdüşümü ile kameralardan alman imgelerdeki el yüzeyinin örtüşme miktarıdır. Genetik algoritma ve Downhill-Simplex algoritması kullanılarak model imge örtüşmesi optimize edilmektedir. El şekli tanımada en önemli problemlerden biri parmakların üst üste gelerek görüşü engellemesidir. Bu sorunu çözmek amacıyla, arama alanım daraltmak ve lokal çözümleri önlemek için parmakların biomekanik ve kinematik kısıtlarından yararlandık. Bu problemi gidermek için daha etkili bir yöntem birden fazla kamera kullanarak de rinlik bilgisinin yokluğundan doğan belirsizliklerin giderilmesidir. Bu çalışmada iki ka meralı bir sistem verilmiş olsa da önerilen yöntem istenilen sayıda kamera kullanımına izin vermektedir.","IV ABSTRACT MODEL BASED THREE DIMENSIONAL HAND POSTURE RECOGNITION FOR HAND TRACKING This study focuses on model based hand posture recognition, which is the acqui sition of the static hand pose information. Here, we have applied geometric modeling with a simple 3D hand model constructed with basic geometric shapes. Our similarity measure is the non-overlapping area of silhouette of the model and the images acquired from the camera. This measure is optimized so as to estimate the best matches using two search methods, the Genetic Algorithm and the Downhill Simplex Method. In order to resolve the occlusion problem, the biomechanical constraints of finger motion are integrated to the search algorithm. This helps reduce the search space and eliminate convergence to local minima to some extent. A more significant remedy to attack ambiguities is the use of multiple camera systems. The proposed system uses two cameras and is scalable to any desired number of viewpoints. Our results reveal that even with a very simple model, 3D hand pose reconstruc tion can be achieved in occluded poses. The proposed system promises better results with more detailed and accurate hand models. Our experiments also demonstrate that GA-DS hybrid algorithm outperforms GA in the constrained multidimensional global optimization of hand model parameters."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DEPREM SONRASI ARAMA KURTARMA İÇİN GELİŞTİRİLEN YENİLİKÇİ BİR AYGITIN SİSTEM KONTROL VE YÖN BULMA YAZILIMLARININ TASARIMI VE GERÇEKLEMESİ Deprem sonrası arama kurtarma için geliştirilen geleneksel aygıtlar, ses ve hareket gibi canlılık işaretlerini algılamaya çalışmak yoluyla göçük altındaki insan bedenlerini aramaktadırlar. Bu yaklaşım, arama aygıtlarının karmaşık ve pahalı olmasına neden olmaktadır. Yine de yeterli başarım sağlanamamaktadır. Kişilerin küçük RF vericiler taşımaları durumunda, göçük altındaki bedenlerin aranması problemi, homojen olmayan ortamda vericilerin yönünü bulma problemine indirgenecektir. Bu, arama aygıtlarının karmaşıklığını ve maliyetini azaltacağı gibi performanslarını da arttıracaktır. Bu görüşün geçerliliğini ispatlamak amacıyla, TÜBİTAK Marmara Araştırma Merkezi Bilişim Teknolojileri Araştırma Enstitüsü'nde bu tür bir verici ve ilgili arama aygıtının prototipleri geliştirilmiş ve testler tatmin edici sonuçlar vermiştir. Bu çalışma, adı geçen arama aygıtının sistem kontrol ve yön bulma yazılımlarının tasarım ve gerçekleştirme çalışmalarını kapsamaktadır.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF THE SYSTEM CONTROL AND DIRECTION FINDING SOFTWARE FOR AN INNOVATIVE EARTHQUAKE SEARCH AND RESCUE DEVICE Conventional earthquake search and rescue devices search human bodies under ruins, trying to detect signs for a living body such as sound and movement. This conventional approach requires complex and expensive search devices. Still, their performance is not sufficient. If people would carry small RF transceivers, the victim location problem would be reduced into a transmitter direction-finding problem in inhomogeneous medium. This would highly decrease the complexity and cost of search devices and increase their performance. In the Information Technologies Research Institute of TÜBİTAK Marmara Research Center the prototypes of such a transceiver and the corresponding search device are developed to prove the above statement and tests have shown satisfactory results. This study includes the design and implementation of the system control and the direction finding software of the search device."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÜNİVERSİTELERE YÖNELİK BÎR EĞİTİM YÖNETİM SİSTEMİ İyi bir e-eğitim alt yapısının kurulması, üniversitelerde derslerin internet tabanlı teknolojilerle daha etkin bir biçimde desteklenmesini sağlayabilir. Bu türden bir altyapı ihtiyacını, bir Eğitim Yönetim Sistemi karşılayabilir. Eğitim Yönetim Sistemi eğitsel içeriğin dağıtımı, öğrenci ilerlemesinin takibi ve raporlanması, öğrenci ve eğitim kaynakları arasındaki etkileşimin yönetimi için tasarlanmış bir yazılımdır. Günümüzde bir birinden farklı niteliklere sahip değişik Eğitim Yönetim Sistemleri vardır. Bu tez çalışmasında özellikle üniversitelerdeki eğitim ortamlarını destekleyebilecek nitelikte bir Eğitim Yönetim Sistemi geliştirilmiştir. Bu sistem kendi içinde öğrenci, assistan, öğretim görevlilerinin, derslerin yanısıra bölüm, program gibi birimlerin yönetimini ve bunların birbirleriyle ilişkilendirilmesini mümkün kılmaktadır. Sistem, önemli bir uluslararası e- eğitim standartı olan SCORM standartına uygun hazırlanmış eğitsel içerikleri desteklemektedir. Sistem, dersler bazında ödev verme ve toplama, sınav yapma, öğrencileri değerlendirme olanağı sunmaktadır. Sistemde asenkron eğitim benimsenmiştir. Sistem kullanıcılar arasındaki işbirliği ve iletişimi destekleyecek asenkron bir mesaj laşma aracı da sunmaktadır.","IV ABSTRACT A LEARNING MANAGEMENT SYSTEM FOR UNIVESITIES Building a good e-learning infrastructure can serve the purpose of supporting courses at universities more effectively with Internet based technologies. The requirement for this kind of infrastructure can be fulfilled with a Learning Management System (LMS) which is the software designed to deliver learning content, track and report learner progress and manage the interaction between learners and learning resources. Today there is a variety of Learning Management Systems with different features. In the thesis, a Learning Management System that can support the education at universities is designed and implemented. The system enables the management of students, assistants, lecturers, programs, and departments within itself and enables to relate them to each other. The system supports learning content compliant with SCORM standard which is one of the important international e-learning standards. The system allows giving and collecting assignments, conduct exams, and grade students. The system implements asynchronous learning. Moreover, the system offers a messaging tool to support collaboration and communication between users."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET hisse senetleri içtn tarihsel benzetim Finans mühendisliğinde hisse senedi, opsiyon gibi çeşitli yatırım araçlarının modellerinde geometrik Brown türü yürüyüş (geometric Brownian motion) sıklıkla kullanılır. Böyle bir model herhangi bir zaman aralığında fiyatların logaritmik farklarının normal dağılım göstermesinin ve geçmiş fiyat hareketlerinden bağımsız olmasının varsayılmalannı gerektirir. İncelenen zaman aralığı küçüldükçe bu iki varsayımın doğruluğuna dair ciddi kuşkular duyulmaktadır. Literatürde günlük logaritmik fiyat getirüerinin normal dağılmadığım öneren birçok çalışma bulunmaktadır. Fiyat değişimlerinin geçmiş fiyat hareketlerinden bağımsızlığına da birçokları kuşkuyla bakmaktadır. Bu tezde istanbul Menkul Kıymetler Borsası'nda (IMKB) işlem gören bazı senetleri inceledik. Uyguladığımız testler normal dağılım ve geçmiş fiyat hareketlerinden bağımsız olma varsayımlanmn doğru olmadığım öneren kanıtlar sunmuştur. Günlük logaritmik fiyat hareketlerini incelediğimizde, literatürde sıkça bahsedildiği gibi, merkezde ve uçlarda normal dağılıma göre daha yüksek yoğunlukta dağılım gözlenmiştir. Tarihsel benzetim uygulayarak, normal dağılım varsayımından bağımsız modeller geliştirdik. Bu tarihsel benzetim modellerini Markov modelleriyle birleştirerek yeni modeller elde ettik. Böylelikle eUediğimiz Markov modelleri geçmiş fiyat harekelerine olan bağımlılığı da modellememize olanak sağladı. Geliştirdiğimiz bu modellerden aldığımız sonuçlan geometrik Brown türü yürüyüş ile karşılaştırdığımızda, sonuçlar, geliştirdiğimiz modellerin çok kısa dönemde daha iyi performans gösterebileceğini önermektedir. Bu modellerden elde edilen opsiyon fiyatları Black-Scholes opsiyon fiyatlarıyla da karşılaştınlmıştır","IV ABSTRACT BEYOND GEOMETRIC BROWNIAN MOTION IN STOCK PRICES Geometric Brownian motion is widely used in financial engineering to model the price changes of numerous commodities including stock prices and derivatives such as options. This model requires the price returns for any time interval to be log-normal and independent of previous price movements. However there is considerable concern if these assumptions are valid as the time scale gets smaller. Evidence against log-normality of the daily price returns in different markets are readily available in the literature. There is considerable skepticism on random walk, independence of the future price changes to past price movements as well. In this thesis we considered some securities of Istanbul Stock Exchange (IMKB). Our tests presented evidence against the normality and the random walk assumptions. Furthermore in our examination of the logarithmic daily returns of the securities we observed the higher concentration in the center and in the tails in agreement with results in the literature obtained in different stock markets. We constructed models that include historical simulation, hence relaxing the normality assumption and models that utilizes a combination of historical simulation and Markov models, the latter enables us to simulate dependencies on past price movements. The comparison of the forecast results obtained with the expected value of geometric Brownian motion suggests that these models may outperform the latter in extremely short term. Furthermore the option prices obtained from these models are compared with the Black-Scholes option prices."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hazırlanan projenin amacı, CMPE 150 kodlu ""Bilgiişleme Giriş"" isimli ders içeriği için, bir uzaktan eğitim sistemi kurulmasıdır. Aslında, diğer bölüm derslerini de elektronik ortama aktarmak amacıyla bir model yaratılmıştır. Dersin tüm içeriği baştan oluşturulmuştur. Yedi tane konu belirlenmiş ve ders bu konular üzerine hazırlanmıştır. Konuların seçiminde amaç, yeni bilgisayar mühendisi adaylarına, bilgisayar mühendisliği ile ilgili temel kavramların anlatılmasıdır. Ders içeriğinin elektronik ortama aktarılması, gelişmiş web teknolojileri kullanılarak gerçekleştirilmiştir. Dünya üzerinde Internet'in yaygınlığı düşünüldüğünde, hazırlanan ders içeriğinin sunumunda, World Wide Web'in araç olarak kullanılması uygundur. Eğitim için hazırlanan içeriği, etkileşimli görüntüler katarak zenginleştirmek, içeriği takip eden kişinin dikkatini arttırmaktadır. Etkileşimli görüntüler ile desteklenmiş elektronik içerik, daha anlaşılır ve dikkat çekici bir hal almaktadır. Etkileşimli görüntülerin hazırlanmasında Macromedia Flash kullanılmıştır. İçeriğin, farklı üreticiler tarafından geliştirilmiş olan Öğrenim Yönetim Sistemleri ile uyumlu çalışabilmesi, daha fazla kişiye ulaşması ve tekrar kullanılabilir olması açısından önemlidir. Farklı üreticiler tarafından hazırlanan Öğrenim Yönetim Sistemleri ile çalışabilmesini sağlamak amacıyla, hazırlanan içerik Sharable Content Object Reference Model (SCORM) ile uyumlu hale getirilmiştir.","The purpose of the thesis is to construct a distance learning system for the educational content of the CMPE 150 course named ""Introduction to Computing"". Actually, a framework has been developed to transport other departmental courses to the electronic media. The whole content is constructed from the beginning. Seven subjects are chosen for delivery, which are about the basic concepts in computer engineering. The aim is to give these basics to the new computer engineer candidates. The electronic content is prepared using advanced web technologies. As the Internet is widespread used in the World, WWW is the best method for the delivery of the electronic content. The content should be supported with visual material to attract the attention of the audience. The content, supported with interactive animations, will be more understandable and more striking. Macromedia Flash is used to construct the interactive animations for the course content. The content should also be compatible with Learning Management Systems developed by different vendors to reach more people and implement reusability. To make the content compatible with LMS software developed by different vendors, the electronic content is organized as Sharable Content Object Reference Model (SCORM) compliant."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GERÇEK-ZAMANLI İLETİŞİM İÇİN GECİKME-KISITLAMALI ÇEVRİMİÇİ ÇOKLU- YAYIN YOL- ATAMA BİLİŞSEL YÖNTEMLERİ Gerçek-zamanlı iletişim önem kazanmakta. Çoklu kullanıcılı gerçek-zamanlı iletişim uygulamaları yaygınlaşırken, çoklu-yaym yol-atama daha popüler olmaktadır. Çoklu-yaym yol-atama literatürü oldukça geniş olmasına rağmen, çevrimiçi çoklu-yaym yol-atama göreceli olarak fazla çalışılmamış bir alandır. Çevrimiçi çoklu-yaym otu rumlarında çoklu-yaym grup üyeleri oturuma sıklıkla girer ve çıkar. Gerçek-zamanlı iletişim söz konusu olduğunda, çevrimiçi çoklu-yaym yol-atama daha zor olmaktadır. Gerçek-zamanlı iletişim uçtan-uca gecikme gibi ilave kısıtlamaları çoklu-yaym yol- atama üzerine empoze eder. Gerçek-zamanlı iletişimin katı gecikme kısıtlamaları çoklu- yaym ağaçlarının yenilenmesi için gösterilecek hesapsal çabayı sınırlar. Bu çalışmanın motivasyonu gerçek-zamanlı iletişimde oturum boyunca gecikme- kısıtlamalı çoklu-yaym ağaçlarının çevrimiçi hesaplamalarında, hız için eniyilikten be lirgin bir şekilde ödün vermeksizin kullanılabilecek hızlı ve etkili çevrimiçi çoklu-yaym yol-atama buluşsal yöntemleri geliştirmektir. Bu amaç için çoklu-yaym yol-atama altyapısında kullanılabilecek hızh ve etkili gecikme-kısıtlamah tekli-yaym yol-atama yöntemleri ayrıca gereklidir. Bu tezde, iki çevrimiçi çoklu-yaym yol-atama bilişsel yöntemi ve bir tekli-yaym yol-atama bilişsel yöntemi önerilmiştir. Önerilen bilişsel yöntemlerin başarımı lit eratürdeki çevrimiçi ve çevrimdışı bilişsel yöntemler kullanılarak değerlendirilmiştir. Benzetimlerin de işaret ettiği üzere, önerilen bilişsel yöntemler başarım ile hesapsal çaba arasındaki en iyi dengeyi sunmaktadır.","IV ABSTRACT DELAY-CONSTRAINED ONLINE MULTICAST ROUTING HEURISTICS FOR REAL-TIME COMMUNICATION Real-time communications is becoming essential. As applications of real-time communications with multiple participants become widespread, multicast routing is becoming more popular. Although there is a vast amount of literature on multicast routing, online multicast routing is a relatively unexplored area. In online multicast ses sions, multicast group members join and leave the multicast session frequently. When real-time communications is concerned, online multicast routing becomes tougher. Real-time communications imposes its additional constraints, such as end-to-end de lay, to multicast routing. Rigid delay constraints of real-time communications restrict computational effort for online update of multicast trees. The motivation of this work is to develop fast and efficient online multicast routing heuristics that can be used in real-time communications for online computation of delay-constrained multicast trees throughout a multicast session without significantly sacrificing optimality for speed. For this purpose, fast and efficient delay-constrained least-cost path heuristics are also required to be used as an underlying unicast routing heuristic in multicast routing. In this thesis, two online multicast routing heuristics and one unicast routing heuristic is proposed. Performance of proposed heuristics is evaluated using online and offline multicast routing heuristics from literature. Simulations indicate that our heuristics offer the best balance among performance and computational effort."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET SESSION INITIATION PROTOKOLÜ ÜZERİNDE SERVİS MİMARİLERİ Session Initiation Protocol (SIP), HTTP ve SMTP protokollerine benzerliği sebebiyle IP üzeri ses dünyasında hemen kabul görmüş ve kullanılmaya başlanmıştır. Bu protokol temelde iletişim kurmak isteyen herhangi iki yada dafa fazla varlığın oturumunu başlatmak, değiştirmek yada sonlandırmak için kullanılır. Bu protokol kullamlarak çok sayıda iletişim servisi geliştirilmiştir. Bu servisler için pek çok yazılım dili tanımlanmıştır. Bu diller farklı iletişim servislerini kolaylıkla gerçeklemek için kullanılır. SIP protokolü servisleri çok çeşitli olup, servis çeşitliliği arama bekletme, kısa kodlu arama, arama sınırlandırma, arama transferi gibi yaygın ve bilinen iletişim servislerinden web'den arama, anlık mesaj laşma, lokasyona göre ulaşım, şahsın sistemde olup olmama bilgisine göre arama ve mesajlaşma gibi yeni tip Internet servislerine kadar geniş bir yelpazeyi kapsamaktadır. Bu servisler için değişik servis teknolojileri ve basit yazılım dilleri geliştirilmiştir. Bunlardan bazıları SIP CGI, SIP Servlets, JAIN SIP, CPL, SCML, CCXML olarak sıralanabilir. Çağrı işleme Dili (CPL) çok sayıda servisi desteklemekle birlikte, üçüncü taraf çağrı denetimi servislerini sağlamak için gerekli mekanizmaları içermez. Bu eksiklik CPL dilinde yapılan geliştirme ve de yeniliklerle giderilmiştir. Bu çalışma ile arama başlatma yeteneği kazandırılan CPL, web'den arama, varlık (presence) bilgisine göre arama yapma gibi servisleri tanımlayabilecek şekilde geliştirilmiştir. Yine benzer şekilde, bütünleşmiş ağlar üzerinde genel ve açık servis yaratabilme ve çalıştırabilme kapasitesi olan JAIN mimarisinde CPL desteğinin olmaması bu mimarinin eksikliğidir. Diğer bir yandan, yine bu çalışma ile gerekli arayüzleri tanımlayarak CPL modülünün JAIN SUP mimarisine kazandırılması hedeflenmiştir. Geliştirilen JAIN SIP CPL mimarisi çeşitli SIP servislerinin gerçeklenmesine olanak sağlamaktadır. JAIN SIP CPL servis mimarisi SIP bileşenleri üzerinde daha kapsamlı bir arama kontrol mekanizması oluşturur.","IV ABSTRACT SERVICE ARCHITECTURES OVER SESSION INITIATION PROTOCOL Session Initiation Protocol (SIP) has gained wide acceptance in the Voice over IP community since its introduction, due to its resemblance to HTTP and SMTP. It has been mainly used for initiating, modifying, and terminating of sessions between communicating entities. Many communication services are built upon it, and different programming languages have been defined and used to ease implementation of these services. Range of services include traditional telephony, i.e. abbreviated dialing, call forwarding, call logging, call transfer and new services like click-to-dial, presence, messaging, and third party call control. Service technologies and scripting languages exist to provide these vast range of services: SIP Common Gateway Interface (SIP CGI), SIP Servlets, Java API's for Integrated Networks (JAIN SIP), Call Processing Language (CPL), Service Creation Markup Language (SCML) and Call Control Markup Language (CCXML). Although CPL supports many services, it lacks the mechanisms to provide third party call control services. This work presents third party call control extensions to CPL. Extensions fulfill the requirement to initiate calls, thus extend capabilities of CPL to cover third party call control services like wake-up, click-to-dial, automatic call based presence services. Similarly, JAIN Architecture have capability to be an open service deployment framework over the Integrated Networks, nonetheless it does not have support for CPL. This work has another focus to develop a CPL adapter module to JAIN SIP by providing necessary interfaces. An architecture deploying the JAIN SIP CPL module has mechanisms to afford these vast services by bridging CPL with JAIN. JAIN SIP CPL service frameworks will posses a fine-grained control over SIP messaging components: SIP proxies, and SIP Back-to-Back-User-Agents (B2BUAs)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KISMI IZLENIMLI MARKOV KARAR YÖNTEMLERİNE SİNİRSEL-BULANIK BİR YAKLAŞIM Yapay Zeka alanında, belirsizlik altında rasyonel davranabilmek, en zor ve en önemli problemlerden biridir. Belirsiz durumlar, olasılık içeren ortamlar ve mekanik problemler ana sorunları meydana getirir. Günümüzde, belirsiz ortamları bir perfor mans kriteri ile beraber modelleyen Kısmi Izlenimli Markov Karar Yöntemleri (POMDP), bu probleme tatmin edici tek modeli getirmektedir. Bu yüzden, POMDP modeller ine çözümler bulabilmek yapay zeka alanındaki en ümit vaad edici konulardan biri haline gelmiştir. Olası çözümler, robot yönlendirme, hata saptama ve karar verme gibi sayısız alanlara da uygulanabilirler. Ne yazık ki, POMDP'lerin konvansiyonel tekniklerle çözülmeleri, çok ufak problemler için bile. çok zordur. POMDP'ler için en uygun çözümleri bulma yöntemlerinin hepsi NP-Zor olarak bilinmektedir. Konvansiy onel teknikler olarak genelde numaralandırma algoritmaları kullanılmaktadır, ancak genellemeden uzak olmaları sebebiyle, bunların üstel zaman ve yer karmaşıklıklarına sahip olacakları kesindir. Ayrıca, üretecekleri çözümlerin kontrol edilebilmelerinin zor olması bir yana anlaşılabilmeleri bile mümkün olmayabilir. Bu tez, sinirsel ağ yapılarının, bulanık mantık karar verme ve Q-Öğrenme mekaniz malarının bir kombinasyonunu kullanarak, POMDP olarak modellenmiş problemlere hızlı, dayanıklı ve kolay anlaşılabilir çözümler elde edebilmek için alışılmışın dışında bir sinirsel-bulanık teknik sunmaktadır.","IV ABSTRACT A NEURO-FUZZY APPROACH TO PARTIALLY OBSERVABLE MARKOV DECISION PROBLEMS In the field of Artificial Intelligence, behaving rationally under uncertainty is one of the hardest and most important problems. Uncertain cases, probabilistic environ ments and mechanical problems are the main obstacles. Today, Partially Observable Markov Decision Processes (POMDPs) which model uncertain environments with per formance criteria, deliver the only satisfactory solution for these problems. So, finding solutions to POMDP models is one of the most promising issues in the field. Possible solutions apply to numerous areas including robot navigation, fault detection, decision making, etc. Unfortunately, POMDPs are also very hard to solve by conventional tech niques even for very small problems. Finding optimal solutions to POMDP problems is known to be NP-hard. Mostly enumeration algorithms are used as the conventional approach, but lacking generalization, these are guaranteed to have exponential time and space complexities. Moreover, their solutions are not much understandable if not intractable. This dissertation presents a novel neuro-fuzzy approach to obtain fast, robust and easily interpreted solutions to POMDPs by utilizing a combination of several learning techniques including neural networks, fuzzy decision-making and Q-Learning."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET XML BİLGİYE DAYALI ÇOK UYGULAMALI AKILLI KARTLAR İÇİN VERİ YAPILARI Akıllı kart, kredi kartı boyutlarında, işlem yapabilme yeteneğine ve belleğe sahip entegre devre taşıyan, plastik karttır. Akıllı kartlar günümüzde bazı uygulamarda kullanılmaktadır. Gelecekte yaygınlaşması ve farklı amaçlar için kullanılması beklenmektedir. Akıllı kartlar veri ve uygulama (program) tutabilir. Birden fazla uygulama aynı karta yüklenebilmektedir. Çok uygulamalı akıllı kart birden fazla amaç için kullanılabilir; çünkü birden fazla uygulama aynı kartta tutulur. XML, metinsel bilgiyi belli bir hiyerarşide tutmak için tasarlanmış, kendi kendini tanımlayan bir dildir. XML kendi kendini tanımlayan ve ortamdan bağımsız doğası sebebiyle; veri gösterimi, veri depolaması ve veri iletişiminde kullanılmaktadır. Bu sebeble biz bu projede XML veri formatım sağlık ve trafik uygulamalarının bilgilerinin depolamasında ve gösteriminde kullanmayı tercih ediyoruz. Bu projede, çok uygulamalı akıllı kart, XML ve XML agent teknolojilerini birleştirmekteyiz. Amacımız sağlık ve trafik uygulamalarını tutan, hızlı ve verimli, XML bilgiye dayalı çok uygulamalı akıllı kart tasarlamak ve teklif etmiş olduğumuz veri yapılarının, sorguları hızlı ve verimli bir şekilde çalıştırmasını sağlamaktır. XML agent teknoloji bizim teklif etmiş olduğumuz veri yapılarını kullanarak XML bilgiyi işleyip akıllı kartın dosya sistemine aktarmak için kullanılır. XML agent aynı zamanda kartın sorgulanması sonucunda oluşan bilgiyi XML formatına çevirmek için de kullanılır. Biz teklif ettiğimiz her bir veri yapısını gerçekleştirdik ve her birinin ne kadar hızlı ve verimli olduğunu göstermek için performans değerlendirmesi yaptık. İlginç sonuçlar ve teklif edilen veri yapılarıyla ilgili detaylı bilgiler de bu projede sunuldu.","IV ABSTRACT STORAGE STRUCTURES FOR XML BASED MULTI APPLICATION SMART CARD Smart card is a credit card sized plastic card embedded with an integrated circuit chip, which provides processing capability and memory storage. Smart cards have been used for some applications today. Smart cards are expected to spread and be used for different purposes in the future. Smart cards can store data and applications. Several applications can be loaded on to the same card. Multi-application smart card is used for more than one purpose as multiple applications are held on the same card. XML (Extensible Mark-up Language) is a self-defining language, designed to store textual data in a hierarchical structure. Because of this self-describing and platform independent nature, XML is accepted and used for data representation, storage and exchange. Thus, we prefer XML as data format for storage and representation of the data of health and traffic applications for this project. In this project, we combine multi-application smart card, XML, and XML agent technologies. Our objectives are to design efficient XML based multi-application smart card that holds health and traffic applications, and enable the proposed storage structures to process selection, projection, and join queries efficiently. XML agent technology is used for the purpose of parsing and mapping XML data to the relational files on the smart card file system using our proposed storage structures. It is also used for converting the data of the query result extracted from smart card into XML format. We implement each storage structure we proposed, and show effectiveness of each storage structure making performance evaluations. Interesting results and insights of our proposed structures are also presented in this project."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DEUTSCH-JOZSA ALGORİTMASININ BİR GENELLEMESİ VE BİR KUANTUM PROGRAMLAMA ALTYAPISININ GELİŞTİRİLMESİ Bilgisayar bileşenlerinin boyutlarındaki küçülme eğilimi şimdiki hızıyla devam ederse 20 yıl içinde bir bitlik bilginin birkaç atomla gösterilebilmesi sözkonusu olacaktır. Bu ölçekte klasik fiziğin alışılmış kuralları geçerliliğini yitirir. Kuantum mekaniğinin kuralları, bir kuantum bitinin aynı anda sıfır ve bir değerlerinin bir süperpozisyonunda olmasına izin vermektedir. Kuantum sistemlerinin bundan kaynaklanan koşutluk özellikleri, klasik modelin elverdiğinden daha hızlı hesaplamayı mümkün kılmaktadır. Kuantum hesaplama, bu fiziksel özelliklerden yararlanılarak bilişim problemlerinin nasıl daha verimli şekilde çözülebileceğini inceleyen araştırma alanıdır. Bu tezde, eleman sayılarının ikinin üssü olması gerekmeyen baz vektörü kümelerinin eşit olasılıklı süperpozisyonlannm üretilmesi problemi incelenmiştir. Bu iş için geliştirilmiş iki algoritma karmaşıklık ve hassasiyet açılarından karşılaştırılmış ve Grover döngüsü tabanlı olan bir seçeneğin, Deutsch-Jozsa probleminin amacın karakutu fonksiyonunun verilmiş bir altkümesinin sabit mi yoksa dengeli mi olduğuna karar vermek olduğu bir genellemesi için tek taraflı hata özelliğine sahip bir algoritma hazırlanmasına elverdiği gösterilmiştir. İkinci bir katkı olarak, klasik bir tersinemez programı kuantum bilgisayarlarında çalıştırılabilecek hale çevirebilen bir kuantum programlama altyapısı geliştirilmiştir. Sistemin görsel bileşeni verilen programa karşılık gelen kuantum devresini istenirse ""kontrollü değil"" kapısı gibi düşük düzeyde kapıları, istenirse de programlama dili işlemlerine karşılık gelen daha yüksek düzeyde kapılan temel alarak çizebilmektedir.","IV ABSTRACT A GENERALIZATION OF DEUTSCH-JOZSA ALGORITHM AND THE DEVELOPMENT OF A QUANTUM PROGRAMMING INFRASTRUCTURE If miniaturization trends in computer technology continue for the next 20 years, it has been estimated that by that time only one atom will be needed to store one bit of information. At such scales, our classical intuitions no longer work, and the laws of quantum mechanics allow a quantum bit to exist in a superposition of its logical values. The superposition and ensuing parallelism properties of quantum systems allow for faster computation than offered by the classical computing paradigm. The field of quantum computation examines the possibility of using these physical properties for solving computational properties more efficiently. In this thesis, we consider the problem of generating superpositions of arbitrary subsets of basis states whose cardinalities are not necessarily powers of two. Two alternative algorithms for this problem are examined with respect to complexity and precision, and a variant based on the Grover iteration is shown to yield an algorithm with one-sided error for a generalization of the Deutsch-Jozsa problem, where the task is to decide whether a specified subset of the oracle function is constant or balanced. We also propose a quantum programming infrastructure which translates a classical irreversible program into the domain of quantum algorithms. A visual component of the system outputs the corresponding quantum circuit in terms of either low level gates such as CNOT, or higher level gates corresponding to programming language level operations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET hareketli internet protokolü kullanan bilgisayar ağlarının bilgi güvenliğinin dinamik paket filtreleme güvenlik duvarı kullanılarak incelenmesi Çeşitli hareketli bilgisayar cihazlarının kullanımının artması ile, şirketlerde, üniversitelerde, okullarda ve diğer benzeri kurumlarda hareketli bilgisayarların kullanımı yaygınlaşırken, bu artış farklı hareketli bilgisayar ağlan uygulamalarının kullanımı ihtiyacını doğurdu. Bu tez, hareketli özel bilgisayar ağlarının bilgi güvenliğinin; Netfilter güvenlik duvarı, hareketli internet protokolüne (Mobile IP) ilave uygulamalar, internet protokolü içinde internet protokolü (IPIP Tunneling) ve ortak, açık politika servis (COPS) protokolü kullanılarak arttırılması amacıyla yapılmıştır. Bu çalışma, hareketli Internet protokolü kullanan bilgisayarların, herkese açık rnternet'ten güvenlik duvarlarıyla korunan farklı özel bilgisayar ağlarında operasyonlarını sürdürmesini sağlamaktadır. Genel bazı güvenlik uygulamalarıyla karşılaştırıldığı zaman, bu çalışma hareketli bilgisayarların kendi bilgisayar ağlarıyla yabancı bilgisayar ağlan arasında gezinmesi sırasında oluşan transmisyon kontrol protokolü (TCP) bağlantılarının analizini gerçekleştirmektedir. Transmisyon kontrol protokolü oturumlarının devamlılığının sağlanabilmesi için Internet protokolü içinde Internet protokolü paketleri filtrelenmesi yapılmaktadır. Bu metod ile, hareketli bilgisayarların farklı bilgisayar ağlarında transmisyon kontrol protokolü bağlantılan kopmadan gezinebilmesi sağlanmıştır.","IV ABSTRACT SECURITY CONSIDERATIONS IN MOBILE IP NETWORKS USING STATEFUL PACKET FILTERING FIREWALLS As the usage of various mobile devices increases, companies, universities, schools and other organizations are put into the mobile working environment and this motivates the different needs for Mobile IP implementations in addition to the basic IP scheme. This thesis presents a new approach for improving network security of private networks in Mobile IP environments by using Netfilter Firewall with a new extension to Mobile IP Protocol, IPIP Tunneling and COPS (Common Open Policy Service) protocol. This work permits mobile nodes using Mobile IP to operate in private address networks which are separated from the public Internet by firewalls. To the contrary of the common security implementations between home and private networks such as IPSec or SOCKS, this study relies on the analyses of TCP connection states (by stateful firewalls) of mobile nodes while mobile devices are roaming between home and foreign networks with filtering of IPIP tunneled packets in the middle of a TCP session. A new method is implemented to keep the TCP connections without being broken and maintaining their states throughout the migration between different subnets."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BAĞIMSIZ PARÇA ANALİZİNİN KONUŞMACI TANIMA SİSTEMLERİ İÇİN ÖN İŞLEMCİ OLARAK KULLANILMASI Günümüz konuşmacı tanıma sistemleri, genellikle labaratuvar koşullarında kaydedilmiş yüksek kalitede ses örnekleri girdi olarak kullanıldığında, yüksek performans göstermektedir. Fakat gerçek koşullar altında, çevreden gelen gürültü, müzik ve diğer konuşmalar gibi etkenler, performansı büyük oranda düşürmekte ve ciddi bir problem oluşturmaktadır. Konuşmacı tanıma sistemlerinin performansım arttırmak için ses örneğinin kalitesini, sisteme girilmeden önce konuşmacıya ait kısımlarını, orjinal ses karışımından ayırarak arttırmak çok önemlidir. Bu tezde yapılan çalışma, bağımsız parça analizinin (BPA) konuşmacı tanıma sistemleri için ön işlemci olarak kullanılarak, ses karışımlarını kaynak sinyallerine ayırmak ve gerçek koşullar altmda ""kokteyl parti problemi"" ni kaynak konuşma sinyalini, otomatik konuşmacı onaylama sistemi ile kullanarak çözmek için yapılan deneylerin sonuçlarını anlatmaktadır. Deneylerde YOHO veritabanı [15] kullanılmıştır. Önerilen metodun verimliliğini göstermek için konuşma, gürültü ve müzik ile karıştırılmış ses örneklerinden elde edilen performanslar gösterilmiştir. Ayrıca, değişik BPA metodlannm performansım karşılaştırmak için birkaç BPA algoritması kullanılmıştır. Yapılan deneylerin bir sonucu olarak; EGLD-ICA ve Fast-ICA gibi BPA algoritmalarının, ses kanşımlanm kaynak sinyallere ayırmak ve böylece tanıma işleminin performansım arttırmak için, konuşmacı tanıma sistemlerinde ön işlemci olarak kullanılabilecekleri başarıyla gösterilmiştir.","IV ABSTRACT INDEPENDENT COMPONENT ANALYSIS AS A FRONT-END FOR SPEAKER RECOGNITION Current speaker recognition (SR) systems show high performance when high- quality speech samples, usually recorded in laboratory conditions, are used as input. However in real world experiments, interfering sounds in the environment (noise, music, other speakers etc.) degrades the performance and presents a serious challenge. To improve the performance of SR systems, it is important to improve the quality of speech input before being introduced into a SR system by separating those portions of speech that belong to testing speaker from the original sound mixture. The work in this thesis reports the results of experiments on using independent component analysis (ICA) as a front-end processing for SR to decompose sound mixtures into source signals and interfacing source speech signal with automatic speaker authentication system to overcome the ""cocktail party problem"" in real-world environments. In experiments, YOHO database [15] is used. The performances with interfering speaker, noise, and music are obtained to show the effectiveness of the proposed method. Also several ICA algorithms are used to compare the performances of different ICA methods. As a result of experiments, it has been successfully shown that ICA algorithms, like the EGLD-ICA and Fast-ICA, can be used as a front-end for speaker recognition systems to separate sound mixtures into source signals therefore increase the performance of the recognition task."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET VEKTÖR UZAYINDA SIRADÜZENSEL AĞAÇ YAPISI İLE DÜZENLENMİŞ METİN VERİ TABANLARININ ÇOKLU YOLLAR ÜZERİNDEN SORGULANMASI Günümüzde gelişmiş bilgi tarama teknolojileri, kolay ve hızlı olmasından dolayı vektör uzay kavramı üzerine kurulmuştur. Genellikle metin tipi veri tabanları doküman başlıklarının indekslenmesiyle oluşturulan vektör uzaylarında oldukça büyük ve seyrek matrisler olarak tanımlanır. Bu matris uzayında istenilen ya da buna yakın bir konudaki dokümanların araştırılması (sorgulanması) büyük zaman alır ve araştırma sonucuna ulaşılabilmesi için oldukça çok sayıda hesaplama yapılması gerekir. Literatürde yapılan çalışmalarda büyük boyutlu metin veri tabanlarına boyut indirgenmesi uygulandıktan sonra bu yeni boyutlarda tanımlanan her bir dokümanın tek tek taranmasıyla sonuca varılan yöntemler tanımlanmıştır. Bu çalışmada ise boyut indirgemesi göz ardı edilerek, sıradüzensel ağaç yapısı ile istenilen dokümanların aynı gruplara toplanması ve araştırmanın bu alt gruplardaki daha az sayıdaki benzer dokümanlardan oluşturulan ortalama merkez vektörler üzerinden çoklu yollar kullanılarak yapılması önerilmiş ve bu yöntem literatürde sıkça kullanılan Gizli Anlambilimsel Dizinleme Yöntemi ile karşılaştırılmıştır. Böylece tüm veri tabanına bakılması yerine çok daha az sayıdaki dokümana bakıldığından daha az sayıda hesaplama yapılarak sorgulama sonucuna kısa zamanda ulaşılması sağlanacaktır. Gruplamaların sıradüzensel bir ağaç yapısıyla yapılması, böylece sorgulamanın ağaç içerisinde özyineli olarak belirlenecek olan grubun içindeki alt gruplara yönlendirilmesiyle aramanın küçük gruplarda yapılması önerilmiştir. Bu sıradüzensel ağaç yapısı ile farklı boyutlarda düzenlenmiş olan IEEE metin veri tabanlarının Sabit ve Uyarlanabilir Çoklu Yollar üzerinden sorgulanması ve hesap karmaşıklığı, başarım ödünleşmeleri incelenmekte ve karşılaştırılmaktadır.","IV ABSTRACT MULTIPATH QUERYING OF HIERARCHICALLY TREE STRUCTURED DOCUMENT DATABASES IN VECTOR SPACES Recently developed information retrieval technologies are based on the concept of a vector space due to the fact that it is speedy and simple to deal with zeros and ones. Generally, text databases are huge matrices defined in the vector spaces that are specially formed by indexing the titles of documents. Searching through these databases to find documents related to our desired subject takes a long time and lots of calculations have to be done. In the literature, methods are used with dimension reduction by means of SVD or PCS, then defining the documents in new dimensions and then searching all of the documents in the reduced dimensions one by one to find the relevant documents about a desired subject. In addition to say that the dimension reduction also accelerates to search documents in hierarchical tree representation because of less calculation while dealing with reduced dimension matrices. In this study, we do not use a reduction of dimension but also compare the results with other Information Retrieval Methods like LSI or Cosine Similarity Algorithm. Making the grouping as a hierarchical tree structure is proposed, so that it can be possible to direct the search to smaller groups in each step. Static M-Path Algorithm and Adaptive M-Path Algorithm search are proposed in IEEE. Transaction in Information Theory databases with three different dimensions which are 544 x 301, 1218 x 801 and 1600 x 1228. By these methods the searching complexity is reduced and the number of calculation gets smaller. Another finding is the fact that a result to a search is related to the query vector. Generally, the more keywords that a search vector contains, the larger is the probability of finding a good result (a closer document to the query vector) but the nice or worst hierarchical tree design can lead to better or worst results of our searching."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KABLOSUZ ALGILAYICI AĞLARINDA UÇTAN UCA GÜVENLİ OLAY İLETİMİ Bu tezde, duyarga ağları için yeni bir grup uçtan uca güvenli olay iletimi yöntemi sunulmaktadır. Duyarga ağlarrındaki amaç meydana gelen olayları sezmek olduğundan, sunulan bu yöntemlerde, güvenli veri paketi iletimi yerine güvenli olay iletimi göz önünde tutulmaktadır. Güvenli olay iletimi bir çok uygulama için oldukça kritiktir. Bundan dolayı, olayları güvenli bir şekilde iletme gereksinimi bizi yeni bir grup uçtan uca güvenli olay iletimi yöntemi sunmaya yönlendirdi. Bu yöntemler alındı esasına dayanan ve alındı esasına dayanmayan olmak üzere iki geniş sınıf altında toplanabilir. Bizim bu tezde sunduğumuz yöntemler alındı esasına dayanan yöntemlerdir. En son olarak, önerilen yöntemlerin başarımı farklı uygulamaları için benzetim kullanılarak değerlendirilmiştir.","IV ABSTRACT END-TO-END RELIABLE EVENT TRANSFER IN WIRELESS SENSOR NETWORKS In this thesis, a new group of end-to-end reliable event transfer schemes is in troduced for sensor networks. In the proposed schemes, reliable event delivery is con sidered rather than reliable delivery of data packets, since the ultimate goal is the detection of events in sensor networks. Reliable event transfer is critical in many sensor network applications. Therefore, the need for transferring the events in a reliable manner coerced us to introduce a new group of end-to-end event transfer schemes categorized into two broad classes, as acknowledgement based and non-acknowledgement based. Our schemes introduced in this thesis are in acknowledgement based class. Finally, the performance of the proposed schemes is evaluated for various application areas by simulation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET OPTİK yoguşma anahtarlamali ağlarda öğrenmeye DAYALI DALGABOYU ATAMASI Gelecek nesil optik ağ teknolojilerinden olarak öne sürülen Optik yoğuşma anahtarlamali (OBS) ağlarda, her tüm optik ağda olduğu gibi performansı etkileyen en önemli kriterlerden birisi dalgaboyu dönüşüm özelliğinin olup olmamasıdır. OBS ağlar üzerinde yapılan çalışmalardan çoğunda bu özelliğin var olduğu varsayılmıştır. Ancak bu varsayım dalgaboyu çevirim teknolojilerinin henüz olgunlaşmamış ve pahalı olmasından dolayı çok pratik ve gerçekçi değildir. Bu yüzden dalgaboyu dönüşüm özelliği olmayan yönlendiricilerin bulunduğu OBS ağlarda verimli dalgaboyu atanması üzerinde çalışmalar yapmak gerekmektedir. Daha uzun süredir ve yaygın olarak üzerinde çalışılan dalgaboyu yönlendirmeli (wavelength routed) ağlar için bir takım metotlar geliştirilmiştir, ancak bu metotlar OBS ağlar için elverişli değildir. Bu çalışmamızda OBS ağlarda öğrenmeye dayalı bir dalgaboyu atama tekniği geliştirdik ve bu metodumuza çağrı üstünlüğüyle sökme (preemption) ve OBS ağlara mahsus bir özellik olan paketlerin yoğuşmalar halinde toplanması gibi bir takım özellikleri kullanarak birtakım ilaveler yaptık. Bu ilaveler ile öne sürdüğümüz metotların performansa katkılarını çeşitli simülasyonlar yaparak gösterdik.","IV ABSTRACT LEARNING-BASED WAVELENGTH ASSIGNMENT IN OPTICAL BURST SWITCHING NETWORKS As in any WDM network, the wavelength conversion capability of routers has a major effect on the performance of OBS networks. However, wavelength conversion is an immature and expensive technology and still remains as a topic of further study. Therefore assuming full wavelength convertibility is not a practical assumption. It is important to focus on avoiding burst drops in OBS networks with wavelength conversion incapable nodes, and efficient wavelength assignment is an important issue for this purpose. Wavelength assignment techniques proposed for Wavelength-Routed Networks are generally not suitable for OBS Networks and some distributed assignment techniques are needed to be devised. In this paper, we proposed a learning based wavelength assignment technique, namely LWA. We make some extensions to this technique via employing a preemption mechanism and using some features of OBS like burst aggregation, and show that the proposed techniques are suitable in order to reduce the burst drop probability, as well as supporting QoS and reducing the end-to-end delay."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET «. işitme engelliler için konuşma ve metinden üç boyutlu yüz sentezleme Bu tezin amacı, dudak okuma vasıtasıyla işitme engellilere yardımcı olmak için, herhangi bir insanın konuşmasından görsel konuşma oluşturan bir sistem geliştirmektir. Bu çalışmada, MPEG-4 yüz animasyonunu oynatmak için yüz noktalarını sentezleyen bir sistem gerçekleştirilmiştir. Gerçekçi ve doğal konuşma animasyonu oluşturabilmek amacıyla, bir konuşmacıdan alman işitsel ve görsel veriler ile eğitilen, koddefteri tabanlı bir teknik kullanılmıştır. Eğitim sadece bir konuşmacı ile gerçekleştirildiğinden, bu teknik konuşmacı-bağımlıdır ve farklı konuşmacılar tarafından kullanıldığında perfor mans önemli ölçüde düşebilir. Sistemin konuşmacı-bağımsız performansım iyileştirmek için, tek-konuşmacılı koddefterinin az sayida konuşmacıdan alman ses verileri kul lanılarak genişletilmesiyle, yeni bir koddefteri oluşturulmuştur. Sistemin eğitimi için, fonetik olarak dengeli Türkçe metinler kullanılarak, işitsel-görsel ve sadece-işitsel veri tabanları hazırlanmıştır. Senkronize işitsel ve görsel verileri toplamak için, bir üç boyutlu yüz hareketi yakalama sistemi geliştirilmiştir. Bu sistem, konuşmacıların üç boyutlu yüz noktalarını izleyip oluşturmak için bir stereo kamera ve yuvarlak etiketler den yararlanır, ve videoyu işlemek için bir kişisel bilgisayara ihtiyaç duyar. Sistemin sentezleme performansı çeşitli testler yapılarak ölçülmüştür. Sistem, harhangi bir Türk konuşmacının sesinden, görsel konuşma için yüzleri canlandnabilmektedir.","IV ABSTRACT SPEECH AND TEXT DRIVEN 3D FACE SYNTHESIS FOR THE HEARING IMPAIRED The goal of this thesis is to develop a system that generates visual speech from an input speech of any speaker, in order to aid hearing impaired by means of lip reading. In this study, an initial system that synthesizes face points to drive an MPEG-4 facial animation engine was implemented. To produce realistic and natural speech animation, a codebook based technique, which is trained by audio and visual data from a speaker, was employed. Since training is performed with only one speaker, this technique is speaker-dependent and the performance can be degraded considerably when used by different speakers. To improve the speaker-independent performance of the system, a new codebook was created by extending the single-speaker codebook with auido data from a small number of speakers. For the training of the system, audio-visual and audio-only speech databases were collected using a phonetically balanced Turkish speech corpus. To capture the synchronized audio-visual data, a 3D facial motion capture system was developed. This data capture system employs a stereo camera and circular stickers to track and reconstruct 3D face points of the speakers, and requires a single PC to stream and process video. The synthesis performance of the system was evaluated by performing objective tests. The system is capable of animating faces for the visual speech from an input speech of any Turkish speaker."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET MOBIL SİSTEM YÖNETİMİ MIDP, CLDC ile birlikte, java platformu için; kullanıcı arayüzü, uygulama modeli, ağ, ve hücresel telefon gibi mobil cihazlar için güçlü depolama özelliklerini tanımlayarak, tam bir J2ME uygulama ortamı hazırlayarak, kullanışlı uygulamalar yazmak ve geliştirmek için kullanılan bir uygulama programlama arayüzleri kümesini tanımlar. Bu çalışmada varsayılan sistem J2ME WTK 1.0.4. 'de geliştirildi ve çalıştırıldı. Amaç, Mobil Sistem Yönetimi olarak isimlendirilen genel amaçlı bir istemci-sunucu uygulaması tasarlamaktır. Mobil Sistem Yönetimi'nin yönetsel parametreleri bilgi sistemlerinin detaylı monitör edilmesine ve üzerinde yer alan fonksiyonların tam olarak kontrol edilmesine izin verir. Sistem yönetimi uygulama sistemlerinin durumunu ve Unix işletim sisteminin fonksiyonlarını monitor etme, ve bunların gerçek zamanla etkileşimlerini analiz etme imkanını verir. Bu çalışma için tasarlanan sistemin organizasyonunda temel olarak iki ana yaklaşım varsayıldı: Biri bir Unix makinayı mobil bir cihazla kontrol etmek, diğeri ise güvenlik düşüncesi ile verinin iletilmesi sırasında veri kaybını ve saldırgan girişimler ya da bilgi kaybı gibi saldırılan önleyerek veriyi korumak. Mobil cihaz olarak Java destekli mobil bir telefon kullanıldı, bilgi güvenliği için şifre tabanlı bir şifreleme/deşifreleme algoritması kullanıldı. İstemci tarafında kullanıcı, şifre, ve İP bilgisini kullanarak bir Unix sisteme bağlanma yolu ile data toplanır. Performans verisi bir grafik ara yüzü ile elde edilir ve yorumlanır, işletim sistemi işlemlerini görüntüleme, ve sistem uygulamalarım yönetme gibi pekçok sistem yönetimine yönelik işlemler çalıştırılabilir. Sunucu tarafında iki temel yapı vardır: Bir webserver, ve bir veritabam. Veritabanı kullanıcı, şifre, IP, hostname gibi sistem bilgilerini tutmak için gereklidir. Bu proje ile yeni özellikler ekleyerek kolaylıkla geliştirilebilecek genel bir Mobil Sistem Yönetimi çalışması elde edildi.","IV ABSTRACT MOBILE SYSTEM ADMINISTRATION The Mobile Information Device Profile (MIDP) defines a set of Application Programming Interfaces (APIs) for the Java platform together with the Connected Limited Device Configuration (CLDC), used for writing and developing useful applications providing a complete Java 2 Mobile Edition (J2ME) application environment defining issues such as user interface, the application model, networking, and persistence storage for mobile devices like cellular phones. The system proposed in this work was developed and executed on the J2ME Wireless Toolkit 1.0.4. Aim is to design a general client-server application named as ""Mobile System Administration"" (MSA). MSA's administrative parameters permit detailed monitoring of the information system and complete control over its functions. Administration is capable to monitor both state of application servers and components of Unix operating system and analyze their interaction in real-time. Basically two main approaches supposed to organize the system designed for this work: One is to control a Unix server from a mobile device, and the other is to keep data, by preventing data loss and attacks like hacker attempts or information loss during transmission of the data for security considerations. A Java-enabled mobile phone is used as mobile device; a password-based encryption/decryption algorithm is used for security. On the client side, some data is collected by connecting to a Unix server using user, password, and IP information. Performance data is obtained and interpreted by a graphical interface, many administrative tasks can be run such as displaying operating system processes, and managing server applications. On the server side, there are two main buildings: a web server, and a database. Database is needed for storing system information like user, password, IP, and hostname. A general Mobile System Administration tool was obtained with this thesis work which may be developed easily by adding new features."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV ÖZET YAPAY SINIR AĞLARININ HİSSE SENETLERİ PİYASASI İŞLEMLERİNDE KAZANÇ ENBÜYÜKLEME AMACIYLA TEKNİK ANALİZ GÖSTERGESİ YAKLAŞIKLAŞTIRICISI OLARAK KULLANIMI Doğrusal olmayan/kaotik zaman serilerinin (hisse senedi fiyatlarının) tahmin edilebilir olup olmadığı hala çözülmemiş bir sorudur. Yapay Sinir Ağlarının öğrenme yetenekleri hisse senedi fiyatlarını tahmin etmek için kullanılmıştır ancak basan sınırlıdır. Geleneksel yaklaşım, gerçek ve tahmin edilen değerler arasındaki farkın karesini enküçükleme benzeri kriterler kullanarak, bir yapay sinir ağı modeline hisse senedi fiyat geçmişini öğretmektir. Diğer taraftan, Teknik Analiz Göstergeleri, tahmin etmeye çalışmadan, zamanında al/sat sinyalleri üreterek hisse senedi fiyatlarından kar elde etmeyi başarırlar. Bu çalışmada, ilk adımda, giriş ve saklı nöron sayısı bakımından yapısal değişiklik gösteren yapay sinir ağı, önceden eniyilenmiş ""Williams' %R"" (WR) diye adlandırılan teknik analiz sinyalini öğrenmek için eğitilmişlerdir. WR parametrelerinin en çok kar üretimi için ön eniyilemesi, en çok kullanılan teknik analiz ve çizenek yazılımı olan MetaStock tarafından yapılmıştır. Fakat, WR tarafından üretilen kar, sabit bir formül tarafından sınırlandırılmıştır. Bir sonraki adımda, yapay sinir ağlarının global fonksiyon yaklaşıklaştırıcı olabilme yeteneklerinden yararlanarak, ağın parametreleri (ağırlıklar ve yanlılıklar) rastgele arama yöntemiyle, ilk adımda elde edilen parametre uzayı etrafında, bu ağ ile benzeştirilen WR tarafından üretilmiş al/sat sinyallerine göre karı enbüyüklemek amacıyla eniyilenmiştir. Eniyilenen ağ, örtük bir kar üretim fonksiyonu gibi davrandığından ve bu fonksiyonel formu WR'daki gibi sınırlandırılmış olmadığından daha iyi al/sat kararlan elde edilmiştir. Hesaplamalarda İMKB-100 Endeksi'nin günlük kapanış değerleri kullanılmış ve yalnızca ""açığa satış"" olmadığı durumlarda değerlendirilmiştir. Sonuç olarak, ilk eniyilenmiş WR sinyalinin 56.8 birim kan, simulasyonlann birinde 73.3 birim karla geçilmiştir. Bu önerilen yöntemin potansiyelini ispatlamaktadır.","Ill ABSTRACT TRADE-PROFIT MAXIMIZATION IN STOCK MARKETS WITH NEURAL NETWORKS AS TECHNICAL-ANALYSIS-INDICATOR APPROXIMATORS Whether nonlinear/chaotic financial time series (stock prices) are predictable or not is still an unsolved question. Learning abilities of neural networks (NN) are used to forecast stock prices; however with limited success. The traditional approach is to train a NN model to stock-price history using a criterion such as minimizing the squared error between predictions and actual values. Technical Analysis Indicators (TAI), on the other end, without any attempt to forecast, manage to extract profits from stock prices by providing timely buy/sell signals. In this work, in the first step, feedforward NNs, differing in structure in terms of number of input and hidden neurons, are trained to learn the pre- optimized TAI signal called the ""Williams' %R"" (WR). The pre-optimization of the WR parameters for maximum profit generation is done with the most widely used TA and charting software MetaStock. However, the profit generated by the WR is limited by its fixed formula. In the next step, by capitalizing on the global function approximation abilities of NNs, the parameters (weights and biases) of the NN are optimized via a random search, around the parameter space obtained in the first step, with the objective of maximizing the profit according to the buy/sell signals generated by this ""NN-simulated WR"". Since the optimized NN acts as an implicit profit-generating function, and since this functional form is not restricted as in the case of WR, better trading decisions are obtained. In the computations daily closing values of the ISE100 (Istanbul Stock Exchange 100 Index) are used and only the long positions are considered (no short-selling). As a result, the 56.8 unit profit of the original optimized WR signal is surpassed by a 73.3 unit profit in one of the simulations; proving the potential of the proposed method."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüzde otomatik kimlik tanıma sistemleri bilgisayar tabanlı uygulamaların vazgeçilmez bir parçasını teşkil etmektedir. Bu amaçla üretilen şifre ve anahtar gibi çözümler düşük maliyetleri ve kolay uygulanabilirlikleri ile oldukça yaygın kullanılmaktadır, ancak bu çözümler unutulma, kaybedilme ya da yetkisiz kişilerin eline geçebilme riski taşımaktadırlar, bu nedenle kişiye özel fiziksel karakteristiklerin belirlenmesi ve kullanılmasına dayalı biometrik çözümler üzerinde durulmaktadır. Biometrik çözümler iris taranmasından, parmak izi incelenmesine, DNA analizinden, imza ve yazı kontrolüne kadar oldukça geniş bir yelpazeye yayılmaktadır. Ses, bir mikrofon veya telefon aracılığı ile kolaylıkla sayısal veriye çevrilebilmesi nedeni ile oldukça popüler bir biometriktir. Bu çalışmada konuşan kişinin söylediği kelimelerden bağımsız olarak kimliğini tesbit etmeyi hedefleyen bir sistem sunulmaktadır. Sesin kişiye özel karakteristiklerinin belirlenmesinde Mel-Frekans Kepstrum sabitleri, bu karakteristiklerin modellenmesinde Linde-Buzo-Gray vektör niceliklendirmesi, iki modelin benzerliğinin değerlendirilmesinde Euclidean mesafesi kullanılmıştır. Ses örneklerinin anlamlı karakteristiklerinin karşılaştırılması, ve benzer olanlarının eşleştirilmesi önemli ölçüde dönüşümler ve karşılaştırmalar gerektirmektedir, bu nedenle oldukça fazla hafıza kullanımı ve disk erişimi söz konusudur. Tek bir bilgisayar üzerinde oluşan bu yük, paralel çalışan bir bilgisayar kümesine dağıtılarak daha hızlı sonuç üreten bir sistem oluşturulmuştur. 100 modelin 16 işlemci ile parallelizme dayalı eşleştirilmesi aynı methodu kullanan seri uygulamaya göre 13.8 kat hızlanma sağlamıştır.","Automatic user identification is an indispensable part of today's computer based applications. Passwords and keys are common solutions due to their ease of implementation and low cost, but these solutions also contain the risk of being forgotten, stolen, or being used by unauthorized users, therefore security professionals are working on biometric solutions that are based on human specific characteristics. Biometric solutions include a great range from iris-scan to finger-scan, from DNA analysis to signature and keystroke scan. Voice is a popular biometric as it can be easily collected and digitalized by a microphone set or by a phone. In this study a text-independent speaker identification system is presented. Mel- Frequency Cepstrum Coefficients are used in feature extraction, Linde-Buzo-Gray vector quantization is used in modeling these features, and measuring the similarity of models is achieved by using Euclidean distance metric. Comparing meaningful characteristics of voice samples requires a significant amount of transformations and calculations; therefore speaker recognition process results with large amount of memory usage and disk access. To share this load to a cluster system instead of using a serial machine, a parallel text- independent speaker identification system is implemented, and clear performance improvements are observed. Our parallel speaker recognition system achieves a speed up about 13.8 compared with its serial implementation in the case of using 16 processing elements to identify a corpus of 100 speakers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V ÖZET CEP TELEFONLARINDA SESİN DURAKSIZ AKTARIMI Bu tezin amacı Nokia 7650 cep telefonu üzerinde sesi duraksız aktarma uygula ması yazmak ve bu uygulamanın performansını GPRS altyapısı üzerinde test etmektir. Durakız aktarım protokolü olarak RTP protokolü; ses kodlama tekniği olarak da PCM, PCMU, ve AMR belirlenmiştir. Nokia 7650 cihazı üzerinde Symbian 6.1 işletim sistemi koşmaktadır ve Series 60 platformu bu işletim sistemi üzerinde uygulama geliştirmek için kullanılır. Series 60 platformu iki programlama dili sağlar: Java, Symbian C++. Bu dillerden hiçbiri RTP desteği vermez. Daha da kötüsü, Java'da RTP geliştirmek için gerekli olan UDP desteği de yoktur. Bu yüzden sesi duraksız aktarma uygula masında Symbian C++ dili kullanılmıştır. Symbian C++ kullanılarak RTP ve RTCP protokolleri geliştirilmiştir. Bunların üzerine de sesi duraksız aktaran uygulama yazılmıştır. Bu uyguluma bir sunucu yazılımına ihtiyaç duyar. Bu yüzden Windows üzerinde koşan, Visual C++ kullanılarak mikrofondan sesi alıp yazmış olduğumuz RTP ve RTCP protokollerini kullanarak sesi stream eden sunucu yazılmıştır. Tekli dağıtım yapan bu uygulama, çoklu dağıtıma çevrilerek ses konferansları için aday bir sunucu haline getirilebilir.","IV ABSTRACT AUDIO STREAMING ON MOBILE PHONES The objective of this thesis is to implement an audio streaming client on Nokia 7650 mobile phone and evaluate the performance of it on GPRS network. As streaming protocol, RTP; as audio encoding technique PCM, PCMU, and AMR are determined to be utilized. Nokia 7650 runs Symbian 6.1 OS and Series 60 Platform enables the developers create applications on Symbian OS. This platform provides two programming lan guages, Java and Symbian C++. Neither of the programming options provides RTP functionality. Worse, Java option lacks the UDP protocol essential for RTP implementation. Thus, C++ option is used in the audio streaming client development. Utilizing Symbian C++, RTP and RTCP protocols are implemented. Upon these protocols, audio streaming client is implemented. The client application needs a streaming server for its operation. Utilizing Visual C++ a multithreaded audio streaming server is implemented which runs on Windows XP. It captures sound through the microphone and streams it using the RTP and RTCP protocols which are also implemented by us. This server, although currently implemented as unicast, may be a candidate audio conference server if modified to work as multicast."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET J2ME ÜZERİNDE MIDP 2.0'IN YENİ ÖZELLİKLER İLE M-TİCARET SİSTEMİ Günümüzde ağ bağlantısına sahip olan cep telefonu ve PDA gibi cihazlar kullanıcıların her türlü bilgiye herhangi bir zaman ve mekanda ulaşmalarına olanak sağlamaktadır. Bu tür cihazlar için bir sonraki adım ise elektronik ticaretin internet ortamında sağladığı başarıyı mobil dünyaya taşımaktır. Ancak bu cihazların kısıtlı kaynaklara sahip olması bir masaüstü bilgisayarın sahip olduğu tüm güvenlik özelliklerini içermelerine engel olmaktadır. Bu çalışmada, J2ME'nin MIDP 2.0 platformunun getirdiği yeni güvenlik değerlerinin üzerinde bir mobil ticaret iskeleti tasarlanmıştır. MIDP 2.0, elektronik ticaretin parasal değer taşıyan uygulamalarda sıkça kullandığı HTTPS protokolünü kablosuz cihazların kullanımına sundu. Bu platformun istemcilere bilginin sunucudan itme yöntemi iletilmesini ve istemcinin otomatik olarak başlamasını sağladı. Bu özellik istemcinin de sunucuya periyodik olarak istekte bulunmasını engelledi. Diğer yandan, MIDP platformu tanımlama bilgisi gibi oturum takibi mekanizmalarını desteklememektedir. Oturum takibi ve oturum süresinin dolması gibi işlemler uygulama seviyesinde kontrol edilmiştir. MIDP, istemci doğrulama işlemlerini içermediği için GSM şirketinin RADIUS sunucusu istemcinin İP adresinden MSISDN numarasına geçişi sağlamada kullanılmıştır. Sunucudan XML formatında gönderilen mesajları bellek nesnelerine çevirmek için de istemci XML ayrıştırıcı kullanmaktadır. Borsa işlemlerinin sunucuya iletildiği bir uygulama da tasarlanan yapının kanıtı olarak bu teze eklenmiştir.","IV ABSTRACT AN M-COMMERCE FRAMEWORK ON J2ME WITH NEW FEATURES OF MIDP 2.0 Today, small devices with network connection like Personal Data Assistants (PDAs) and cell phones, let users to reach any kind of information from anywhere and anytime. The next step for these devices is to carry the success of e-commerce in internet environment to the mobile world. However, the limited resources of these devices prevent them to include all the security features of a desktop machine. In this study, an m-commerce framework is designed on top of the new security enhancements of the MIDP 2.0 platform of J2ME. MIDP 2.0 specification introduced HTTPS protocol for wireless devices, which is the secure way of communication used commonly in many monetary transactions of e-commerce applications. The push registry feature of this platform enabled the client devices of the design to be launched automatically with incoming network connection. With this feature, the client is prevented from pooling the server for the results of its orders periodically. On the other hand, the MIDP does not support session tracking mechanisms like URL re-writing or cookies. The session tracking and session timeout is handled in the application layer. Since the client authentication is not implemented in MIDP, the RADIUS server of a GSM Company is used to make a mapping from the IP address of the client to its MSISDN. The messages send from server to clients are coded in XML format and clients included a parser to translate these messages into memory objects. A proof of concept implementation that sends stock exchange operations to the server is also added in this thesis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET *. ÖZERK ROBOTLAR İÇİN GERÇEK ZAMANLI PLANLAMA SİSTEMİ DİZAYNI VE GELİŞTİRİLMESİ Bu çalışmada gerçek zamanlı özerk robotlar için bir sistem dizaynı önerilmektedir. Kompleks problemleri çözebilecek gerçek zamanlı özerk planlama sistemleri geliştirmek gerçekleştirilmesi zor bir görevdir. Bunu gerçekleştirmek için planlama sisteminin dizaynı gerçek zamanda çalışabilecek ve tatmin edici sonuçlar döndürebilecek hale çevirilmelidir. Bu tezde, robot futbolu karşılaşmaları için bir futbol takımı geliştirmek hedef lenmiştir. Robot futbolu ortamı çok ajanlı olup, hem ekip çalışması, hemde ekiplerin karşılıklı çekişmesini gerektirir. Planlayıcı olarak klasik ortam bağımsız planlama sis temleri kullanmamızın amacı bu sistemlerin avantajlarından yararlanmak istememiz- dir. Birinci avantajı modülerliktir. Geliştirilen sistemi bir yada daha çok ortam bağımsız planlayıcıyla kullanmak mümkündür. Bilinen ve iyi kodlanmış planlayıcıları kullanarak performans artışı sağlamamamız bu sistemin ikinci avantajıdır. Bir diğer avantajı da, sistemin planları depolayıp sonraki oyunlarda kullanabilmesidir. Planlama sistemi Java programlama dilinde ve FastForward planlayıcısıyla oluş turulmuştur. TeamBots simulasyon ortamında dört farklı takıma karşı denenmiştir. Sonuçlar göstermiştir ki, yeterli sayıda oyundan sonra, oluşturulan ve en çok kullanılan 1000 planı reaktif planlama modülünde depolayarak, Planlama Sistemi yüzde 95 oranla planları hemen döndürebiliyor ve bu sayede sistemimiz gerçek zamanlı planlama sistemi gibi davranıyor. Diğer sonuçlara göre, bir maçta ortalama olarak 165 ve maksimum 300 farklı plan kullanıldı. Yeni yaratılan plan sayısı her çalıştırışta düştü ve 300 maçtan sonra hemen hemen hiç yeni plan yaratılmamaya başladı.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF A REAL TIME PLANNING SYSTEM FOR AUTONOMOUS ROBOTS This work proposes a system design for real time planning for autonomous robots. Implementing a real time autonomous planning agent, which can solve complex prob lems, is a hard to achieve task where the planning system design must be adapted to process in real time domain and should be able to return satisfactory results. In this thesis, we aimed to develop a soccer team for robot-soccer competitions. The robotic soccer environment is multiagent and both cooperative and competitive goals are available. We use domain independent planners in order to benefit from their advantages. The first advantage is modularity. It is possible to use the generated system with one or more domain independent planners. The second advantage is the performance improvements obtained with the use of well known and good implemented planners. And another important advantage is the planning system stores the generated plans and can use them in future games. The planner system is implemented in Java and uses the FastForward planner. The implementation was tested in the TeamBots environment against four different teams. The results show that after sufficient number of runs if we store the top re quested 1000 plans in the reactive planning module, the Planning Engine returns plans immediately 95 percent of the time which enables our system to behave as a real time planning system. Other statistics show that on the average the number of different plans used in a game is 165 and a maximum 300 plans are used. There is no clear distribution between plan request counts. The number of new generated plans drops in each run and after 300 matches it almost approached 0."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"HİSSE SENEDİ DEĞİŞEBİLİRLİĞİNİNYAPAY SİNİR AĞLARI İLE TAHMİN EDİLMESİMustafa Serdar YümlüBilgisayar Mühendisliği, Yüksek Lisans Tezi, 2004Tez Danışmanı: Prof. Dr. Fikret S. GürgenTez Danışmanı: Doç. Dr. Nesrin OkayHisse senetleri piyasası, kapitalist ülkelerin ekonomilerinde çok önemli bir roloynamaktadır. Milyonlarca insan hergün daha fazla kar elde edebilmek için alış/satışyapmaktadırlar. Bu noktada piyasanın geleceğini bilebilmek daha fazla önem kazanıyor.Borsada gelecek tahmini, olası kayıpların tahmin edilmesidir. Bu olasılık, ilgili piyasakatılımcısı için gelecek risk profilini oluşturur. Önemli olan bu riskin tahmini,ölçülebilirliği ve matematik normlarıyla ifade edilebilmesidir. Bu bağlamda zaman serisiiçindeki varyans ölçülür ve tahminler bunun üzerine gerçekleştirilir. Finans zaman serileri,direkt olarak ölçülemeyen şartlı varyans (volatilite) olarak bilinen zamana bağlı varyanssergiler.Biz bu çalışmada, yapay sinir ağları kullanarak volatilite modellemesi ve bumodellerle gelecek tahminleri üzerine odaklandık. Özellikle, yapay sinir ağlarının hissegetirilerinin risk tahminlerinde kullanımını araştırıyoruz. Geleneksel yöntemlerin aksine,volatilite içerisinde zamana bağımlı ilişkiyi yapay sinir ağları ile modelliyoruz.Karışık Uzmanlar içerisindeki böl ve yönet tekniği ile once uzayı gruplara ayırdık veher gruba bir yerel uzman atadık. Yerel uzmanlara kendi ilgi alanlarını öğreterek ve buyerel uzmanların çıktılarını kapı uzmanı aracılığıyla birleştirerek zaman içindeki ilişkiyimodelleyebildik ve bu tekniği İstanbul Menkul Kıymetler Borsası (İMKB) Ulusal 100endeksinin gelecek tahmininde kullandık. Ayrıca girdi ve çıktı uzayı arasındaki ilişkiyiTekerrür Eden Yapay Sinir Ağları' nın çoklu geribesleme mekanizması ile modelledik.Geleneksel ve sinirsel yöntemleri birleştirerek yeni modeller ortaya koyduk ve bütün bumodeller tanımlanmış kriterler ile test edilip karşılaştırıldılar. Sonuç olarak, KarışıkUzmanlar ve Tekerrür Eden Yapay Sinir Ağları' nın İMKB Ulusal 100 endeksinin günlükzaman serileri modellemesinde geleceği parlak volatilite modelleri olduğuna karar verdik.","FORECASTING STOCK MARKET VOLATILITYUSING ARTIFICIAL NEURAL NETWORKSMustafa Serdar YümlüComputer Engineering, M.S. Thesis, 2004Thesis Supervisor: Prof. Fikret S. GürgenThesis Co-Supervisor: Assoc. Prof. Nesrin OkayStock markets play a very significant role in the economy of capitalist countries.Millions of people trade everyday in order to have more and more profit. At this point,being able to know the future of the market gets more importance. Future prediction in astock market is the prediction of the probability of the future losses. This probability formsthe future risk profile for the interested market participant. The important thing is theestimation, measurement and the definition of the risk in mathematical norms. In thiscontext, the variance in the time series is measured and the predictions are based over thisvariance. Financial time series exhibit time dependent heteroskedastic variance known asthe conditional variance (volatility) that is not a directly observable feature.In this thesis study, we focus on the volatility modeling using artificial neuralnetworks (ANNs) and future predictions with these volatility models. Specifically, we areinvestigating the use of ANNs in risk estimation of asset returns. On the contrary totraditional methods, we have used ANNs to model the relationship, the dependence in timein volatility.We have divided the space into clusters with the help of the Mixture of Experts(MoE)?s divide and conquer technique and we have assigned local experts to each cluster.Having localized experts learn their region of interest and having combined the outputs ofthese local experts via a gating expert we have been able to model the relationship in timeand we have used this technique for the future prediction of Istanbul Stock Exchange (ISE)National-100 index. Also we modeled the relation between the input and output space bythe help of the hybrid recurrent neural networks (RNN)?s multiple feedback mechanism.As a result, we have determined that MoE and hybrid RNN are very promising in modelingthe volatility of ISE National-100 index."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kaynak tahsis problemi, bilişim şebekelerinin etkin olarak çözülememiş prob lemlerinden biridir. Bu problemin modellenmesi doğrultusunda bilişim şebekeleri için yeni bir birleşimsel müzayede tabanlı kaynak tahsis (BMTKT) yaklaşımı önerilmiştir. Bu ekonomi tabanlı model müşterilere ayrım yapmaksızın, istedikleri kaynak tiplerine birleşimsel teklif vermelerine imkan vererek, bilişim şebeklerine ait kaynakların etkili ve ekonomik açıdan verimli tahsisine olanak sağlamaktadır. Bu modeli çözmek için öncelikle BMTKT problemi tanımlanmış ve problem tamsayı programlama metodu kullanılarak formüle edilmiştir. Bu problem NP-hard sınıfına ait bir problem olduğun dan dolayı optimum çözümü bulmak çok fazla zaman alabileceğinden, birim fiyat kri teri tabanlı iki yaklaşık sonuç algoritması önerilmiştir. BMTKT modeli için, içinde suni test üreticisi, optimum çözücüsü, bir üst sınır hesaplayıcısı ve üç adet yaklaşık sonuç çözücüsü bulunduran bir yazılım paketi hazırlanmıştır. Elimizde bu modele ait gerçek hayat verileri olmadığından, algoritmaların performansları test üreticisi tarafından oluşturulan kapsamlı testler ile sınanmıştır. Önerilmiş olan iki polinom zamanlı yaklaşık sonuç algoritması optimum sonuçlara göre yüzde 97,3 ve yüzde 99,2'lik ortalama sonuç larla ümit verici performans değerleri vermiştir.","Resource co-allocation problem is one of the challenging problems in grids. In order to model this problem, a new combinatorial auction based resource co-allocation (CABRC) approach is proposed. This economy based model provides efficient allo cation of resources in a grid environment by allowing bidders to submit bids on the combinations of different resource types. In order to solve the model, CABRC problem is defined and formulated using integer programming. It is proved that CABRC prob lem is NP-hard and since optimum solutions may take tremendous amount of time to be found,- two new greedy heuristics based on price per unit criteria are proposed. A software package that consists of an artificial test case generator, an optimum solver, an upper bound estimator and three greedy heuristic solvers for CABRC problem is coded. Since there is no real world data for testing the solvers, performance of algo rithms are compared using a comprehensive test suite which is produced by the test case generator. Proposed two polynomial time heuristic solvers produce promising re sults of 97.3 per cent and 99.2 per cent average performance relative to the optimum solution respectively."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET akustik dizilerle hacimsel görüntülemede sanal eleman yöntemi Sanal eleman yöntemi 3-boyutlu ultrasonik görüntüleme sistemleri için, özellikle de taşınabilir sistemlerde gelecek vaad eden bir alternatiftir. 2-boyutlu dönüştürücü dizileri kullanarak 3-boyutlu görüntüleme ancak modern ultrason sistemlerindeki ön-uç donanım karmaşıklığı azaltılarak mümkün olabilir. Geleneksel tam evreli dizi (TED) yöntemi her elemana ait işaretleri ayrı ayrı işleyebilmek için paralel ön-uç elektronik do nanıma ihtiyaç duyar. Bu kullanılmakta olan 1-boyutlu dizilerle 2-boyutlu görüntüleme sistemleri için uygun olsa da TED yöntemi aşırı artan kanal sayısı ve düşük çerçeve hızı bakımından 3-boyutlu görüntülemeye uygun değildir. Bu çalışmada ön-uç donanım karmaşıklığını azaltacak bir yöntem araştırılmıştır. Tüm dönüştürücülerden gelen işaretlerin aslında akustik eksen üzerinde bulunan tek bir sanal kaynaktan geldiği varsayılmıştır. Bunun için gönderim kanallarına uygun elek tronik gecikmeler uygulanır. Bu yöntem ile her çerçeve için tek bir işaret gönderip-alma yeterli olmaktadır. Çerçeve hızındaki bu büyük gelişim gönder-al dizi çiftlerinin zaman içinde çoklanmasma ve böylece görece daha küçük dizilerle daha yüksek çözünürlüğe olanak sağlar. Buna ek olarak, dizilerin halka biçiminde tanımlanması gönderiş kanalı karmaşıklığı-nı azaltır. Bu çalışmada matematiksel modellerle destekelenen kapsamlı bir altyapı sunuldu. Daha sonra sanal eleman yöntemini geleneksel TED yöntemi ile karşılaştırdık. Karşılaştırma-ları yaparken özel olarak hazırladığımız bilgisayar pro gramlarından faydalanıldı. Ayrıca odaksızlama etkilerini azaltmak için pencereleme modelleri ve değişik halka modelleri de sunuldu.","IV ABSTRACT VOLUMETRIC ACOUSTIC ARRAY IMAGING USING VIRTUAL TRANSMIT ELEMENTS Virtual element method is a promising way to achieve 3D ultrasound systems especially possible implementation for portable systems with reduced active channel requirement. 3D ultrasound imaging systems using 2D transducer arrays is only possi ble if the front-end hardware complexity of modern ultrsound systems can be reduced. Conventional full phased array (FPA) imaging requires parallel front-end electronic hardware to process the signals from each element independently. While currently feasible for commercial 2D ultrasound imaging using ID transducer arrays, FPA imag ing does not scale well to 3D imaging due to the overwhelming number of transducer elements and due to unacceptable frame rates. This study aims to explore an alternative way to reduce the front-end hardware complexity. Signals from all array elements are assumed to originate from a virtual element located along the acoustic axis. This abstraction is achieved by applying coherent electronic delays to trasnmit channels. By this method it is possible to con struct a frame at one firing event. This drastic improvement in frame rate allows us to time-multiplex transmit/receive array couples, thus achieving higher resolution with relatively smaller apertures. Also definition of ring arrays reduces the transmit channel count. We presented an extensive background for acoustic imaging providing mathematical models. Virtual Element Method is then compared to conventional FPA method. Comparison realized by simulations by means of custom computer programs. Apodization to compensate for defocusing artifacts and different ring array models are presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DİNAMİK ROTA PROBLEMİNE DEĞİŞEN ESNEKLİK SEVİYELERİNDE BULANIK MANTIK YAKLAŞIMI Son yıllarda değişen pazar koşullarına hızlı uyum sağlama esnek imalat sistemleri açısından varlıklarını sürdürmeleri için bir gereklik halini almıştır. Değişken ürün taleplerine hızlı uyum sağlamak esnek imalat sisteminin esneklik özelliğini ile yakından ilgilidir. Bununla birlikte esnek imalat sistemlerinin karmaşık yapılarından dolayı, istenilen performans ile ihtiyaç duyulan esneklik seviyesi arasındaki ilişki henüz netlik kazanmamıştır. Bulanık mantık doğası gereği çok karmaşık problemlerin çözümünde kuvvetli bir araçtır. Değişen koşullara uyumlu çözümler için kesin ve sayısal bilgiye ihtiyaç duymamaktadır. Bu tez rota problemine bulanık mantık yaklaşımını rota esnekliği için iş taslağını göz dikkate alarak pratik bir hesaplama yöntemi ile birlikte sunmaktadır. Deneysel sonuçlar bulanık mantık yaklaşımının değişen sistem şekillerinde geleneksel rota çözüm kurallarından daha iyi sonuç verdiği göstermektedir. Ayrıca bu tez daha önce yapılmış, istenilen sistem performansı ve buna bağlı rota esneklik seviyesi arasında ilişkiyi açıklayan çalışmaların sonuçları doğrulanmıştır.","IV ABSTRACT A FUZZY LOGIC APPROACH TO DYNAMIC ROUTING PROBLEM UNDER VARYING LEVELS OF ROUTING FLEXIBILTY Cost effective and rapid response to changing production needs and requirements has become a critical issue for the design and operation of manufacturing systems. Quick adaptation to variable markets has strong relation with how flexible a manufacturing system is. However the necessary flexibility level for the required system performance is not clarified yet because of high complexity of systems. Due to its very nature fuzzy logic is a powerful approach for solving problems in high complexity. This thesis introduces a fuzzy logic approach to dynamic routing problem where routing flexibility incorporates not only the possibility of performing an operation on alternative machines but also the possibility of producing the same work piece by alternative sequences of operations, namely the so-called operation and processing flexibilities. Extensive simulation experiments in a hypothetical FMS environment show that the proposed fuzzy approach outperforms several conventional heuristics in variable system configurations. Also, a new index for measuring routing flexibility both in operation and processing flexibility cases is introduced. The relation between routing flexibility level and system performance is examined under several cases to reveal important characteristic behaviour."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BELGE SINIFLANDIRMA İÇİN GÖZETİMLİ VE GÖZETİMSİZ ÖĞRENME ALGORİTMALARI Bilgisayar ve elektronik teknolojilerinin gelişmesi, İnternet ve Web'in yaygınlaş masıyla elektronik belgelerin miktarı her geçen gün artmaktadır. Bu elektronik veri- tabanlarmda ilgili verilere daha hızlı, kolay, ve doğru bir şekilde erişebilmek için bel gelerin otomatik olarak sınıflandırılması önem kazanmıştır. Otomatik sınıflandırma için temelde iki yapay öğrenme yaklaşımı vardır: gözetimli öğrenme ve gözetimsiz öğrenme. Gözetimli öğrenmede, önceden sınıfların bilinmesi ve bu sınıflara ait belgelerden oluşan bir öğrenme kümesi gerekir. Gözetimsiz öğrenmede ise sınıfların önceden bilinmesine ve herhangi bir aşamada insan yardımına ihtiyaç yoktur. Bu çalışmada otomatik belge sınıflandırma için gözetimli ve gözetimsiz temel yöntemleri ele alıyoruz. Bu temel yöntemlerin beş standart veritabanı üzerindeki başarımlarım farklı kıstaslara dayanarak inceüyor, gözetimli ve gözetimsiz öğrenme yaklaşımlarını birbiriyle kıyaslıyoruz. Bu çalışma sonucunda gözetimsiz yöntemler içinde fc-means ve bisecting A;-means'in belge öbeklenmesi için daha elverişli olduğunu gördük. Gözetimli yöntemler arasında en iyi başarımı destek vektör makinaları elde ediyor. Gözetimsiz yöntemler olmalarına rağmen A;-means ve bisecting fc-means göze timli bir yöntem olan naive Bayes'den daha kaliteli öbekler oluşturuyor. Gözetimsiz yöntemlerin oluşturduğu öbeklerin toplam benzerliği gözetimli yöntemlerininkinden genellikle daha yüksek. Bu sonuç öğrenme kümesinde hatalı bazı belgelerin olmasından kaynaklanıyor olabilir. Bu nedenle sınıfların belirlenmesi ve öğrenme kümesinin oluştu rulması aşamasında gözetimsiz yöntemlerden faydalanılmasını öneriyoruz.","IV ABSTRACT SUPERVISED AND UNSUPERVISED MACHINE LEARNING TECHNIQUES FOR TEXT DOCUMENT CATEGORIZATION Automatic organization of documents has become an important research issue since the explosion of digital and online text information. There are mainly two ma chine learning approaches to enhance this task: supervised approach, where pre-defined category labels are assigned to documents based on the likelihood suggested by a train ing set of labelled documents; and unsupervised approach, where there is no need for human intervention or labelled documents at any point in the whole process. In this study we compare and evaluate the performance of the leading supervised and unsupervised techniques for document organization by using different standard performance measures and five standard document corpora. We conclude that among the unsupervised techniques we have evaluated, &-means and bisecting &-means perform the best in terms of time complexity and the quality of the clusters produced. On the other hand, among the supervised techniques support vector machines achieve the highest performance while naive Bayes performs the worst. Finally, we compare the supervised and the unsupervised techniques in terms of the quality of the clusters they produce. In contrast to our expectations, we observe that although &-means and bisecting fc-means are unsupervised they produce clusters of higher quality than the naive Bayes supervised technique. Furthermore, the overall similarities of the clustering solutions obtained by the unsupervised techniques are higher than the supervised ones. We discuss that the reason may be due to the outliers in the training set and we propose to use unsupervised techniques to enhance the task of pre-defining the categories and labelling the documents in the training set."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ağdaki belgelerdeki büyük artış ve İnternet'in yaygın kullanımı nedeniyle, bilgiye erişim günümüzün bilgisayar dünyasında önemli bir uygulama haline gelmiştir. Ancak, klasik ""kelime torbası"" yaklaşımı, kullanıcı beklentilerim artık yeterince karşılayamamaktadır. Bu bağlamda, doğal dil işleme (DDİ) tekniklerinin kullanımı akla gelmektedir. Bu tezde, doğal dil işleme tekniklerinin Türkçe'de bilgiye erişim etkinliğini geliştirip geliştiremeyeceği sorununu ele almaktayız. TURNA adında, dilbilime dayalı bir bilgiye erişim sistemi gerçekleştirdik. Sistem, doküman ve bilgi isteklerini işlemede doğal dil işlemenin üç değişik düzeyindeki bilgileri kullanmaktadır: biçimbilim, sözdizim ve kavramsal sözlük düzeyleri. Bu doğal dil işleme tekniklerinin değişik birleşimleri Türkçe belgeler ve bilgi isteklerinden oluşan bir küme üzerinde sınanmıştır. Sonuçlar, kesinlik ve geriçağırım açısından ele alınmıştır. Doğal dil işleme tekniklerinin, özellikle gövdeleme ve sözdizimsel tamlayan-tamlanan ikililerinin kullanımımn, Türkçe bilgiye erişim etkinliğini geliştirebildiği ortaya çıkarılmıştır.","Information retrieval (IR) has become an important application in today's computer world because of the great increase in the amount of web-based documents and the widespread use of the Internet. However, the classical ""bag of words"" approach no longer meets user expectations adequately. In this context, the use of natural language processing (NLP) techniques comes into mind. In this thesis, we investigate the question of whether NLP techniques can improve the effectiveness of information retrieval in Turkish. We implemented a linguistically motivated information retrieval system, called TURNA (TUrkish information Retrieval engine based on Natural language Analysis). The system uses knowledge of three different levels of natural language processing in document and query processing: morphological, syntactical and lexico-semantical levels. Different combinations of these NLP techniques are tested on a set of Turkish documents and queries. The results are evaluated in terms of precision and recall. It is shown that natural language processing techniques, especially stemming and the use of syntactical head-modifier pairs, can improve information retrieval effectiveness in Turkish."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÇOKLU-ETMEN TAKIM DAVRANIŞLARININ PEKİŞTİRMELİ ÖĞRENİLMESİ Pekiştirmeli öğrenme (RL), etmenlerin tecrübe ile öğrendikleri genel problem çözümü için bir çerçevedir. Çoklu etmen davranışlarını incelemek için popülerliği ve karmaşıklığı sebebiyle robot futbolu seçildi. Bu çalışmada, bir robot futbol takımını eğitmek için üç değişik yol izlendi. Birinci yaklaşım RL'i bir takımın tamamını eğitmek için doğrudan kullanmıştır. Bu deneyler için pekiştirmeli öğrenme yöntemi olarak Q(A), fonksiyon yakınsama için Beyincik Örnekli Boğum Yöneticisi (CMAC) ve etmenlerin hareketlerini yerine getirmek içinse motor şemaları kullanıldı. Eğitim evresinde iki takım farklı ödül şemaları ve farklı rakipler kullanılarak eğitildi. Her iki takımda elle geliştirilmiş orta seviyeli takımları yenmeyi başardı. İkinci yaklaşım ödülleri şekillendirerek kaleci rolü oluşturmayı hedeflemiştir. Bu takım bütün bir takım olrak eğitilen üç takım arasındaki en iyi takımdır. Bu çalışmada etmenlerin takım davranışlarını ölçmek amacıyla istatistiksel bir yöntem geliştirilmiş etmen saldırganlığı, takım saldırganlığı, takım türdeşliği ve takım yoğunluğu isimli ölçekler tanımlandı. Eğitim sonrasında takımlar bu ölçeklere göre birbirleriyle karşılaştırılmıştır. Üçücü yaklaşımda, RL edil gen etmenlerin kullandıkları karar alma yönteminin yerini almıştır. Market yönteminin rol ilişkilendirme mekanizması RL ile karşılaştırılmış RL'in gelişme gösterdiği kaydedilmiştir. Bu üç yaklaşım içerisinde, edilgen etmenlerin öğrendiği üçüncü yaklaşım en umut verici olandır çünkü tasarımcılara etken oyuncular için kendi kabul edilmiş stratejilerini uygu lama fırsatı verip bunun yanında çoklu-etmen alanındaki daha karmaşık bir problem olan rol ilişkilendirme problemini etken oyuncuların politikalarını öğrenmeye gerek duy madan çözer.","IV ABSTRACT REINFORCEMENT LEARNING OF MULTI- AGENT TEAM BEHAVIOR Reinforcement Learning (RL) is a framework for general problem solving where an agent can learn through experience. The soccer game is selected as the problem domain s a way of experimenting multi-agent team behaviors because of its popularity and complexity. In this study, three different ways of training a robotic soccer team is experimented. The first approach uses RL directly to train a complete team. For these experiments, the learner implements Q(A) Learning as the RL algorithm, Cerebellar Model Articulation Controller (CMAC) as the function approximation method and motor schemas as the locomotion unit. Both teams are trained using different reward schemas and opponent teams through learning phase. As a result, both teams are able to learn strategies to defeat moderate level hand-coded teams. The second approach uses reward shaping to generate roles especially a goalie. This team is the best among the three teams trained as a whole. A statistical method is introduced to evaluate team behaviors by defining metrics for an agent's offensiveness, team's offensiveness and team's homogeneity. The resulting teams are compared to each other by using novel metrics defined in this study. In the third approach, RL replaces a decision algorithm used by passive players. Market algorithm's role assignment mechanism is compared with the RL version where RL shows improvements. Among the three approaches, the third approach, passive player learning, is the most promising one because its design enables the designers to implement their own accepted strategies for active players and solves a more complex task namely role assignment in multi-agent domain without trying to relearn the active player's strategy."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET YAPAY SİNİR AĞLARININ DEĞİŞİK TEKNİKLERİ KULLANILARAK GELİŞTİRİLMİŞ BİR YAPAY YAŞAM UYGULAMASI Yapay yaşam doğal olarak var olan yaşam yerine insan eliyle yaratılmış yaşam anlamına gelir. Yapay yaşam pek çok bilim dalının birlikte çalışması ve yaşam benzeri işlemler ve simülasyonlann kullanılmasıyla yaşamı modellemeye, doğal yaşamdan çıkarılmış tekniklerle çeşitli problemleri çözen uygulamalar geliştirmeye hatta yaşamı oluşturmaya çalışır. Bu tez çalışmasında gerçek yaşam benzeri yaşam biçimleri oluşturmaya çalışan bir bilgisayar programının taslağı, yürütülmesi ve sonuçları sunuldu. Bir yapay yaşam dünyası ve bu dünyayı oluşturan yapılar ve bu yapılar arasındaki etkileşimler tasarlandı. Bu yapay dünya içerisinde yaşayan yaşam formlarının fizyolojileri, metabolizmaları, duyu mekanizmaları ve davranış biçimleri tanımlandı. Yaşam formlarının kontrol mekanizması olarak yapay sinir ağları kullanıldı. Farklı yapay sinir ağı mimarileri, ve bu mimariler için farklı evrim teknikleri tasarlandı, test edildi ve karşılaştırıldı. Yapay sinir ağlarının yazılım ortamında temsil edilebilmesi için değişik yapılar ve bu yapılar üzerinde çalışan evrimsel operatörler tasarlandı ve test edildi.","IV ABSTRACT AN ARTIFICIAL LIFE IMPLEMENTATION USING DIFFERENT TECHNIQUES OF ARTIFICIAL NEURAL NETWORKS Artificial life means life created artificially by human rather than by nature. It tries to achieve several goals like modeling or even creating life and developing applications for finding solutions to real world problems using methods taken from life. The work reported in this thesis is the design, implementation and results of a software infrastructure that tries to create artificial life forms, which resembles the real life forms. An artificial life world and the constituents of this artificial world and the interactions between them were designed. The physiology, metabolism, sensory mechanisms and behaviors of the agents that live in this world were defined. For the controlling structure of the agents artificial neural networks were used. Different artificial neural network architectures and evolution techniques were designed, tested and compared in this study. Different strategies for encoding artificial neural networks were designed and tested and for these encoding strategies different evolutionary operators were defined."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BİR İSPANYOLCA TÜRKÇE OTOMATİK ÇEVİRİ SİSTEMİ YAKLAŞIMI Bu tez çalışmasında, aradil tabanlı, çift yönlü bir İspanyolca Türkçe otomatik çeviri sistemi anlatılmaktadır. Bu çahşmada,Türkçe ve İspanyolca biçimbirim ve sözdizim kuralları ele alınmıştır. İspanyolca çok çeşitli biçimbirimsel fiil çekim kombinasyonları incelendi, 53 çeşit kuralsız İspanyolca fiil çekimim karşılamak için sonlu durumlu makine tasarlandı. Ayrıca, İspanyolca ve Türkçe cümlelerin çözümlenmesi ve üretilmesi için anlambilimsel gösterim modelleri geliştirildi. Farklı anlamsal belirsizlik türlerim çözümlemek maksatlı birkaç farklı yöntem geliştirildi. Bu çalışma sırasında geliştirilen ana uygulama, Türkçe veya İspanyolca dilinde girilen kaynak dosyalan okuyup, buradaki cümleleri (eğer mümkünse) hedef dilde çıkarır. Etkileşim modunda çalışacak başka uygulamalar da geliştirilebilir; böylece hatalı girilen kaynak cümlelerin kısmi çevrimi mümkün olup, kullanıcıya doğru çeviriyi bulması konusunda yol gösterilebilinir.","IV ABSTRACT AN APPROACH FOR MACHINE TRANSLATION BETWEEN TURKISH AND SPANISH In the present thesis, an interlingua based bidirectional machine translation system between Turkish and Spanish has been discussed. In this study, Turkish and Spanish morphology and syntax rules are examined. Spanish verb conjugation with a great variety of morphological combinations are investigated, a finite state automata is designed to cover 53 different types of irregular Spanish verbs. Additionally, semantic representation models are built for both parsing and generation of Spanish and Turkish sentences. Several methods are developed to resolve different ambiguity types. The main application developed for this study reads the input files in the source language either in Turkish or Spanish, and outputs the translation (if possible) of the sentence in target language. Other programs can be implemented to translate in interactive mode, so that with incorrect input sentences partial transfers can be possible to guide the user to figure out the correct translation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GENETİK ALGORİTMALARIN TERS PROTEİN KATLANMASI PROBLEMİNE UYGULANMASI Proteinlerin üç boyutlu şekillerinin bulunması, biyoinformatik alanında şu an en önemli sorudur. Onunla beraber diğer bir problem ise ters protein katlanması prob lemidir yani, şekli bilinen bir protein için ona uygun dizilerin bulunması. Üç boyutlu şekil sayısının, dizi sayısından daha az olduğu bilgisi temel alınırsa bu problemin çözümü daha kolaydır. Bu problemi çözmek için bir genetik yordam hazırladık. Yor dam uygun yapılar bulmak için serbest enerji seviyesini azaltmaya çalışmakta, bunun için olasılık olarak birbirlerine yakın olan amino asitleri bir araya getirmektedir. Yordamın etkinliği değişik şekillerde test edildi. İlk olarak sonuçlar veri ta banındaki diziler ile karşılaştırılarak benzer olanlar bulundu. Daha sonra ise dizi hede flenen katlanma modeline giydirilerek, şeklin gerçek anlamda hedefle uygun olup ol madığına bakıldı. Bu durum, sadece hedefle giydirme diğer seçeneklere göre daha az enerji seviyesinde olunca olası olan bir durum olduğu için, karşılaştırma şansı ortaya çıktı. Verilen bir sekile yüksek oranlarda uygun sonuçlar elde edebildik.","IV ABSTRACT APPLYING GENETIC ALGORITHMS TO INVERSE PROTEIN FOLDING PROBLEM Finding the three dimensional structure of protein is currently the most impor tant question in bioinformatics area. Together with it is the inverse folding problem; given the structure of the protein, find the sequences that are compliant with it. Given the fact that there are far less number of structures than sequences, this problem is more plausible to solve. We have implemented a genetic algorithm (GA) to solve this problem. The algorithm tries to minimize the free energy by trying to find highly probable residuals together in probability terms in order to form suitable structure. The efficiency of the algorithm is tested by different ways. First the results are compared to sequences in databases to find similar sequences. Then the sequence is threaded to target fold to find whether it is in fact compatible with the target or not. Since this is possible when the threading gives minimum energy state for the target and other folds are not in close states, a comparison is possible. We can find highly plausible sequences for a given structure."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET WISPOT SUNUCULARININ TASARIMI VE UYGULAMASI Mobil teknolojideki gelişmeler, insanların, istedikleri bilgiye her an ve her yerde, hareket halinde iken bile ulaşabilmelerini sağladı. Teknoloji aynı zamanda kişilerin bilgiye ulaşmalarmdaki eğilimi ""bilgi için araştır"" dan ""bilgi seni bulsun"" yönüne doğru değiştirdi. Birinci yöntem bilginin istemci uygulamalarına sunucular tarafından istek-cevap protokolleri kullanılarak ulaştırıldığı çekme-tabanlı yaklaşıma, ikinci yöntem de bilgi akışının sunucu tarafından başlatıldığı itme-tabanlı yaklaşıma karşılık gelmektedir. Bu çalışmada, itme-tabanlı ve çekme-tabanlı yaklaşımlann beraber kullanıldığı, WISPOT ismiyle, bir kablosuz bilgi dağıtım sistemi tasarladık. WISPOT sistemi küçük kapsama alanlarındaki, sisteme kayıtlı ve hareketli kullanıcılara, hiçbir kullanıcı müdahelesi olmadan, popüler bilgi servisleri dağıtır. Kullanıcılar, uygun donanım ve yazılım desteği olan dizüstü veya el bilgisayarları ile, bir WISPOT sunucusunun yakınından geçerken, abone oldukları bilgi servislerinin en son sürümleri mobil cihazlarına otomatik bir şekilde indirilir. Servisleri yalnızca sisteme kayıtlı istemcilere dağıtmak istediğimiz için, güvenli bir doğrulama mekanizması tasarladık. Bilgi dağıtma mekanizmasında, sistemin, bilgi servislerinin popülerliği ile başa çıkmaktaki ölçeklenirliğini iyileştirmek için, indisleme ile bMeştirilmiş çoğa dağıtımı kullandık. Bilgi dağıtma mekanizmasının güvenilirliğini bilgi dönmedolabı, ileri hata düzeltme ve otomatik tekrar istek tekniklerini beraber kullanarak sağladık. Güvenlik mekanizması ile sistemin istemcilerine dağıtılan büginin gizliliğini sağladık. Güvenlik ve güvenilirlik mekanizmalarını mobil uçbirimlerin kısıtlı güç kapasitelerini göz önünde bulundurarak tasarladık. WISPOT da kullanıcı ile etkileşimi en az seviyede tutmak için, yayınlama/abonelik tekniği ile bir kullanıcı belgileme mekanizması tasarladık. Ek olarak, WISPOT sisteminin prototipini uyguladık, mekanizmaların işlevselliğini sınadık ve çeşitli başarım değerlendirme deneyleri gerçekleştirdik.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF WISPOT SERVERS The advances in mobile technology enabled people to access information on demand at any time and place even while they are on the move. The technology also changed the trends in reaching the infonnation for a person from ""search for the information"" to ""let the information find you"". The former view corresponds to pull-based approaches, where data is brought from servers to client applications using request-response protocols, and the latter view corresponds to push-based approach where data flow is initiated from the server side. in this study, we designed a wireless information delivery system, namely WISPOT, which uses both the push-based and the pull-based approaches together. WISPOT system delivers popular information services to registered mobile users in a small coverage area, without any user intervention. As users with notebook or handheld computers equipped with appropriate hardware and software pass by a WISPOT server, the most recent version of the subscribed information services will be automatically downloaded to their mobile devices. We designed a secure authentication mechanism, since we aim to deliver services only to the registered clients of the system. In the data delivery mechanism, we employed multicasting combined with indexing to improve the scalability of the system in coping with the popularity of the information services. We achieved the reliability of data delivery mechanism by using data carousel, forward error correction and automatic retransmission request techniques together. We provide the privacy of data delivered to the clients of the system with the security mechanism. We designed the security and reliability mechanisms with the consideration of the limited power capacity of mobile terminals. To keep the user interaction minimal in WISPOT, we designed a user profiling mechanism using a publish/subscribe technique. Additionally, we implemented a prototype of the WISPOT system, tested the functionality of mechanisms and performed several performance evaluation experiments on the prototype."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET PROSTAT KANSERİ OLMA OLASILIĞI OLAN BİYOPSİ ÖNCESİ HASTALARDA YANLIŞ TANIYI AZALTMAK İÇİN VERİ MADENCİLİĞİ UYGULAMASI 50 yaş ve üstündeki erkeklerde prostat kanseri teşhisi için üç adet veri maden ciliği yöntemi kullanılmıştır. Bunlar: Karar Ağacı, Yapay Sinir Ağları ve K-En Yakın Komşu Algoritmasıdır. Bu erkekler, biyopsi öncesi ""koyu gri tanı alanı"" na girmekte dir. Biz koyu gri alanı Rektal Muayene sonucu normal olmak ve toplam PSA değeri 4 ile 20 ng/ml arasında bulunmak şeklinde tanımladık. Tıbbi çevrelerce çok iyi bili nen ""gri alan"" tanımının yukarıdaki tanımdan tek farkı, PSA değerinin 4 ile 10 ng/ml arasında olmasıdır. Biz tek bir kanserli hastayı bile kaçırmadan koyu gri alandaki gerek siz biyopsi alanını daraltmak istiyoruz. Finansal Risk Yönetimi kuramında da olduğu gibi, hata maliyeti çok yüksek olan özel bir sınıflandırma problemiyle karşı karşıyayız. Bu çalışmada 139 hasta yer almıştır. Veri madenciliği algoritmalarında kullandığımız girdi değişkenleri hastanın yaşı, serbest PSA, PSA yoğunluğu, serbest PSA'mn toplam PSA'ya oranı ve PCA teşhisinde ilk kez kullanılan bir değişken olan total PSA'mn kısa dönemdeki (10 gün) değişkenlik katsayısı scvtPSA'dır. Önce, bu değişkenleri kul lanarak bir karar ağacı oluşturduk. Karar ağacı eğitim veri setiyle eğitildikten sonra ve eğitim veri setiyle denendiğinde bir tek kanserli hastaya bile yanlış tam koymadı ve yüzde 68.8 yanlış alarm oranı verdi. Test veri setiyle denendiğinde ise yanlış alarm oram yüzde 55.6'ya düştü ve bir tek kanserli hastaya bile yanlış tanı konulmadı. (Bunun dışında, Karar Ağacı gri alanda denendiğinde literatürdeki gri alan sonuçlarına benzer sonuçlar verdi). K-En Yakın Komşu Algoritması ve Karar Ağacının doğrusal bileşkesi de tatmin edici sonuçlar verdi. Ayrıca, scvtPSA'nm Prostat Kanseri teşhisinde koyu gri alan için etkin bir değişken olduğu sonucuna varıldı.","IV ABSTRACT USING DATA MINING TO REDUCE FALSE POSITIVES FOR PRE-BIOPSY PATIENTS WITH MODERATE CHANCE OF HAVING PROSTATE CANCER Three data mining tools, namely a Decision Tree, an Artificial Neural Network and the Kth Nearest Neighbor Algorithm, are employed to detect prostate cancer among men above the age of 50. These men belong to what we call the pre-biopsy diagnostic ""dark gray zone"". We define the dark gray zone as having a normal Digital Rectal Examination result and a total Prostate-Specific Antigen level between 4 and 20 ng/ml. The dark gray zone is a superset of the well-known ""gray zone"" whose definition is identical to that of the former with the only exception that the PSA level falls between 4 and 10 ng/ml. We want to reduce the unnecessary biopsies in the dark gray zone while not missing a single cancer patient. Because the cost of making an error of type one is very high, we have a special kind of a classification problem, which is also seen in Financial Risk Management Theory. 139 patients were included in the study. As input variables to our data mining tools, we use age of patient, free PSA, PSA density, the ratio of free to total PSA, and the short term (10-day) coefficient of variance of total PSA, namely scvtPSA, a novel variable used for the first time in prediction of prostate cancer. First, we develop a decision tree model using these variables. The decision tree trained with the training data gives a false positive rate of 68.8 per cent when tested on the training data when we fix the sensitivity at 100 per cent. For the test data, its false positive rate value decreases to 55.6 per cent while the sensitivity is successfully maintained at 100 per cent. (Our Decision Tree gives results comparable to those in the existing literature for patients in the gray zone as well.) A linear combination of Kth Nearest Neighbor Algorithm and Decision Tree results is also satisfactory. We also conclude scvtPSA is significant in predicting prostate cancer in the dark gray zone."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BENZETIMLENMIŞ ÖZERK ARAMA KURTARMA EKİBİ TASARIM VE GELİŞTİRMESİ Afetlerden sonra arama kurtarma çalışmaları yürütmek çoklu-etmenlerin kullanıldığı çok sayıda alandan biridir. Bu çalışmada, afet sonrası arama kurtarma çalışmalarında yer alacak; hiyerarşi, işbirliği ve öğrenme özelliklerine sahip bir çoklu-etmen sistemi yazılımı geliştirilmiştir. Sistem, etmenler arası iletişimdeki kısıtların etmenlerin işleyişi üzerindeki olumsuz etkilerini en aza indirecek şekilde tasarlanmıştır. Etmenler, yönetici etmenler ve arama-kurtarmadan sorumlu etmenler olarak iki katmanlı bir hiyerarşi oluşturmaktadır. Üst katmandaki etmenlerin görevi iyi bir ortam modeli oluşturup alt katmandaki etmenleri hedeflere atamaktır. Arama kurtarma işlemlerinden sorumlu etmenler, kendi davranışlarının sonuçlarından hangi davranışın hangi durumda uygun olduğunu öğrenirler. Ayrıca, yönetici etmenlerin bildirdiği hedefler ve kendi karar verdikleri hedefler arasında tercih yapmayı öğrenirler. Yönetici etmenler ise, arama kurtarma etmenlerinin geribildirimlerinden hangi atama yönteminin hangi durumda etkili olduğunu öğrenirler. Öğrenme metodu olarak takviyeli öğrenme kullanılmıştır. Çoklu-etmen sistemi araştırmacı ve açgözlü olmak üzere iki ayrı şekilde çalıştırlabilir.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF A SIMULATED AUTONOMOUS RESCUE TEAM Multi-agent systems are devised for several different areas. Carrying out rescue activities after a disaster is one such area. In this work, a software multi-agent system that involves hierarchy, cooperation, and learning is implemented for carrying out rescue operations in a disaster environment. The system is designed so that the constraints, such as those for communication, affect the operation of the agents minimally. A two-level hierarchy of agents is formed where the agents higher in the hierarchy are responsible for obtaining a better world model and commanding the agents in the lower level. The platoon agents learn from the result of their actions as well as learning which action source, i.e. the dispatcher or the environment, is a better choice at a given state. The dispatchers learn from the feedback of their platoons on whether their assignments were useful. Reinforcement learning is used as the learning method of the agents. The system can be run both in explorer mode and in greedy mode."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET IEEE 802.11 TELSİZ AG ALTYAPISI KULLANARAK KONUM İZLEME VE KONUM TABANLI HİZMETLER Bir insanın ya da bir nesnenin konumunun izlenmesi ilkel çağlardan beri insanlığın sorunlarından biri olmuştur. Son zamanlarda, konum izleme alanında ünlü GPS sistemi ve değişik kurum ve kuruluşların geliştirdiği Bat ve Airld dahil olmak üzere birçok çalışma ve proje yürütülmüştür. Kapsama alanları ve sonuçlarının doğrulukları ne olursa olsun bütün bu sistemler kurulum için özel donanıma ihtiyaç duymaktadırlar. Bu çalışmadaki amacımız benzer bir işlevi yerine getirecek donanımdan bağımsız ve kolay kurulabilecek bir sistem geliştirmekti. Bu amaçlar doğrultusunda WLAN Tracker (Telsiz Ağ İzcisi) sistemi geliştirildi. WLAN Tracker sistemi telsiz ağ içerisinde ölçülen sinyal güçlerine dayalı olarak izleme işini yapmakta ve tamamiyle yazılımsal parçalardan oluşmaktadır. Bunlara ek olarak, WLAN Tracker çok katlı binalar gibi üç boyutlu ortamlarda da çalışabilmesi için geliştirildi. Geliştirilen sisteme ayrıca kullanıcılarına basit yazı tabanlı hizmetler sunabilecek bir konum tabanlı hizmet sistemi eklendi. Çalışmaların son aşamasında sistemimizin performansım yaptığı tahminlerin doğruluğuna göre değerlendirdik ve benzer sistemlerle karşılaştırdık.","IV ABSTRACT LOCATION TRACKING AND LOCATION BASED SERVICES USING IEEE 802.11 WLAN INFRASTRUCTURE Location tracking of someone or something has always been a problem of mankind from the ancient times. In the recent decades, there have been many studies about location tracking including the Global Positioning System (GPS), Active Badge, Bat, and Airld systems from different companies and institutions. Whatever the coverage and accuracy of these systems are, they all depend on customized hardware for implementation. Our aim was to develop a system that will not be hardware dependent and easy to deploy. For these purposes, WLAN Tracker is developed. It is a pure software solution based on the signal strength measurement in Wireless Location Area Networks (WLANs) for the solution of mentioned complexities. In addition to this, WLAN Tracker is improved to be able to operate in multi-dimensioned environments such as a multi-story building. Moreover, a simple location based service scheme is added to WLAN Tracker in order to provide text based services to its clients. Then, we investigate the performance of our system by comparing its estimations with real values and by comparing it with other similar systems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DAĞILIM TAHMİNİ ALGORİTMALARI KULLANARAK EN UYGUN YAPAY SİNİR AĞI YAPISININ BULUNMASI Bir yapay sinir ağırım mimarisinin, genelleme performansının ve işleyiş hızının belirlenmesinde çok büyük önemi vardır. Bu yüzden her uygulamaya özgü, eğitim verisini öğrenerek deneme verisi üzerinde genelleme yapabilen en az karmaşık yapının bulunması gerekir. Bununla beraber böyle bir yapının bulunması zordur. Biz bu motivasyonla kendi çalışmamızda, yapay sinir ağı mimarisi uzayı için bir çeşit arama yöntemi geliştirdik. Önce ağ yapılarını kesikli değerlerden oluşan kromo zomlar olarak temsil etmeyi sağlayan bir çeşit direk kodlama mekanizması oluşturduk. Arama mekanizması olarak, genetik algoritmalardan esinlendik fakat genetik operatör olarak, aramaya yön vermek amacıyla, bir çeşit dağılım tahmini algoritması olan Bayesian optimizasyon algoritmasını kullandık. Bayesian optimizasyon algoritmasında kromo zomlar Bayesian ağları kullanılarak temsil edilir. Optimizasyon yöntemimizin başarılı olduğunu, PROBENİ ölçüm setinden aldığımız her biri üç veri setinden oluşan iki sınıflandırma problemi ve iki regresyon problemi üzerinde deneyerek gösterdik. Üzerinde çalıştığımız çoğu veri seti için, optimizasyon yöntemimizin ortaya çıkardığı ağ yapılarının performansı, deneme yanılma yöntemleriyle ya da geleneksel genetik algoritmalar kullanılarak bulunmuş ağların performansına göre daha iyi düzeyde bulundu.","IV ABSTRACT NEURAL NETWORK TOPOLOGY OPTIMIZATION USING ESTIMATION OF DISTRIBUTION ALGORITHMS The topology of an ANN has a significant impact on its generalization perfor mance and speed of operation. For this reason, an optimal network topology, the smallest complexity which still allows the network to learn the training data and to generalize over the test data, should be found specific to each application. However, it is difficult to find an optimal topology. With this motivation, in our work, we developed a way of searching in the space of ANN architectures. First, we devised a kind of direct encoding mechanism for representing network topologies as chromosomes. As the search mechanism, we inspired from genetic algorithms but we used Bayesian optimization algorithm (BOA), a kind of estimation of distribution algorithm for guiding the progression, as the genetic operator. In BOA, Bayesian networks are used for representation of chromosomes. The success of our optimization tool was tested on two classification problems and two regression problems, with three data sets in each, from PROBEN1 benchmarking suite. The generalization performances of the obtained networks by our optimization tool are mostly better than the hand designed ones and the ones obtained by using traditional genetic algorithms for most of the data sets used for benchmarking."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TÜRKÇE İÇİN GELİŞTİRİLMİŞ DİYALOG ETMENİ ALTYAPISI TASARIMI VE GERÇEKLENMESİ Yapay zekanın bir alt alanı olan Doğal Dil İşleme'nin (DDİ) amacı bilgisayarların doğal dilleri, bu dilleri anadili olarak konuşan insanlarla karşdaşlırüabilir basan seviyelerinde kullanabilnıesidir. Bu tezde anlatılan çalışma, ileride üzerinde farklı uygulamalara yönelik diyalog etoenlerinin geliştirilebileceği bir Türkçe diyalog etmeni altyapısının kurulmasıdır. Diyalog etmeni temelde iki ana kısımdan oluşur: Doğal dil işleme altyapısı ve diyalog işleme politikası. Doğal dil işleme altyapısı Boğaziçi Üniversitesi'nde greçeklenmiş Türkçe Okur Yazar (TOY) doğal dil işleme altyapısının geUştirilmiş bir sürümü olup biçimbirim, sözdizim ve arılambilim kısımlarından oluşur. Diyalog etmeni altyapısına girilen bir cümle ilk olarak cümle işleme bölümünde biçimbirimsel ve sözdizimsel çözümlemeden geçer. Bu işlemin ardından diyalog işleme politikası cümlenin anlambilimsel gösteriminin oluşturulması ve de diyalogun yürütülmesi işlevlerini yerine getirir. Diyalog işleme politikası aynı zamanda cümle işleme birimi ile veri tabam arasında aracı görevi görür. Cümle oluşturma kısmı diyalog işleme politikasından gelen anlambilimsel gösterimin doğal dil cümlesine dönü^ştürülmesinden sorumludur. İkinci ana kısım diyalog işleme politikasıdır. Bu politika çerçevesinde kullamcınm girdiği cümleler işlenir ve bunlara karşılık gelen yanıt ya da sorular hazırlanır. Başka bir deyişle sistemin diyalog içerisindeki davranış tarzı tamamen diyalog işleme politikası ile belirlenir. Buradaki önemli husus diyalog işleme politikasının kullanıcı üe konuşurken doğal dil işleme altyapısının her türlü özelliğinden faydalanmasıdır. Üç ömek diyalog politikası gerçeMeştirilmiştir.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF AN IMPROVED CONVERSATIONAL AGENT INFRASTRUCTURE FOR TURKISH Natural Language Processing (NLP) is a subfield of artificial intelligence (AI) whose ultimate aim is to enable computers to use natural languages with performance levels comparable to those of native humans. The work reported in this thesis is the design and implementation of a Turkish conversational agent infrastructure that can be of use in development of agents customized for various man-machine communication applications. Our conversational agent architecture consists of two basic parts: The sentence processing mechanism and the conversation policy. The natural language processing infrastructure is an improved version of the Türkçe Okur Yazar (TOY) NLP infrastructure developed in Boğaziçi University and consists of modules for morphology, syntax and semantics. An input sentence entered to the conversational agent infrastructure is first processed by the sentence processing module, which is responsible for morphological and syntactic parsing. After completing the sentence processing, the conversation policy module handles the respective procedures concerning the semantics if the sentence and the management of the conversation. It also plays an intermediate layer role between sentence processing and the knowledge base. The sentence generation module is responsible for converting the logical formula coming from the conversation policy module into a natural language sentence. The second part is the conversation policy. According to this policy, the statements entered by the user are processes and the respective answers or questions are generated. In other words, the behavior of the system in a particular dialogue is determined by the dialogue processing algorithm. The dialogue processing algorithm sits on top of the sentence processing infrastructure and uses it to communicate with the user. Three sample conversation policies were implemented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÇOK ÇÖZÜNÜRLÜKLÜ İMGE PİRAMİDİ KULLANAN SİNİR AĞI TABANLI YÜZ SEZİMİ Bir imgedeki insan yüzünün varlığını ve konumunu bulmayı amaçlayan yüz sezimi, otomatikleştirilmiş yüz imgesi analizinin ilk önemli adımıdır. Yüz seziminin biyometrik kimlik tespiti, içerik tabanlı imge bulup getirme, video kodlama, video konferans, güvenlik, akıllı insan-bilgisayar arayüzleri alanlarında çeşitli uygulamaları vardır. Bu çalışmada, siyah beyaz imgelerde dikey cepheden yüz sezimi ele alındı. Sistemimiz örneklerden öğrenme tabanlıdır. Sistemin eğitim evresi, uygun yüz ve yüz olmayan örneklerin oluşturulmasını ve sinir ağlarının geri besleme yöntemiyle eğitilmesini içerir. Sistemin test evresi bir imge piramidinin pencere tarama yöntemi ile sinir ağı kullanılarak test edilmesini ve imge piramidinin farklı boyutlarından gelen sezim sonuçlarının hiyerarşik gruplama kullanılarak birleştirilmesini içerir. Eğitim verisi üzerinde boyut indirgeme uygulanmıştır. Ağlardan bir tanesi indirgenmiş girdi uzayında eğitilmiştir. İki değişik sonuç birleştirme yaklaşımı geliştirilmiştir. îlk yaklaşımda imge piramidinin değişik boyutlarındaki sezim sonuçları özgün boyuta taşınıp gruplandmlmıştır. İkinci yaklaşımda sezim sonuçlan önce imge piramidinin değişik boyutlarında gruplandmlmış, bu grupların ortalama değerleri özgün boyuta taşınıp yeniden gruplandırılrmştır. Test veri kümeleri üzerindeki ayrıntılı sonuçlara göre özgün girdi uzayında eğitilen ağm indirgenmiş girdi uzayında eğitilene göre, ilk birleştirme yaklaşımının da ikinciye göre daha başarılı olduğu görülmüştür.","IV ABSTRACT NEURAL NETWORK BASED FACE DETECTION USING A MULTI RESOLUTION IMAGE PYRAMID Face detection, which aims to detect the presence and the position of a human face in an image, is the first important step in automated facial image analysis. Face detection has several applications in areas such as biometric identification, content-based image retrieval, video coding, video conferencing, security and intelligent human-computer interfaces. In this work, upright frontal face detection in gray scale images is studied. Our system is based on learning from examples. Training phase of the system includes the construction of appropriate face and nonface samples and the training of neural networks using a bootstrap method. Testing phase of the system includes the testing of an image pyramid with the neural networks using a window scanning technique and the merging of the detection results from different scales of the image pyramid using hierarchical clustering. Dimensionality reduction is applied on training data. One of the networks is trained with the reduced input space. Two merging approaches are developed. In the first approach, detection results of different scales are carried to the original size and then they are clustered. In the second approach, detection results are pre-clustered in different scales then the mean value clusters are carried to the original size and they are again clustered. Overall test results on the test datasets show that the neural network trained with original input space performs better than the one trained with reduced input space. Also the first merging approach performs better than the second merging approach."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÇOK HOPLAMALI TASARSIZ KABLOSUZ AĞLARDA GÜÇ KONTROLÜ KULLANARAK SERVİS KALİTESİNİN SAĞLANMASI Günümüzde çok sayıda kişi hücresel telefon, avuçiçi ve dizüstü bilgisayarları gibi taşınabilir cihazlardan ayrı ayrı faydalanmaktadır. Bu cihazların birbirleriyle etkileşim içinde, hareketli olarak, kullanılması söz konusu olduğunda; istediğimiz anda ve istediğimiz yerde herhangi bir merkezi altyapıya ihtiyaç duymadan iletişim kurabilme olanağına sahip olacağız. Bu iletişimi sağlayan sistem ise Çok Hoplamalı Tasarsız Kablosuz Ağlardır. Çok Hoplamalı Tasarsız Kablosuz Ağlarda bütün üniteler serbestçe dolaşmakta olup, sabit bir altyapıya ihtiyaç duymamaktadırlar. Haberleşme ortamının paylaşılmakta ve iletişim ağlarının dinamik bir topolojik yapıda olması nedeniyle, Çok Hoplamalı Tasarsız Kablosuz Ağlarla servis kalitesini bağdaştırmak pek kolay bir iş değildir. Günümüze kadar, servis kalitesine destek konusunda, servis kalitesi yönlendirme protokolü ve ortam erişim kontrolü gibi elemanların üzerine ayrı ayrı eğilmek suretiyle çok sayıda metod geliştirilmiştir. Ancak, hiçbirinden kesin sonuç alınamamıştır. Hareketli Tasarsız Kablosuz Ağların servis kalitesi konusunda desteğin artırılması için yukarıda değinilen elemanların hep birlikte çalışması gerekmektedir. Tezimizde bu durumu sağlayacak olan bir servis kalitesi yönlendirme protokolü önerdik. Bu protokolü, topolojik değişkenler ile ağ kaynaklarını izleyen MAC katmanı ile birleştirdik. MAC katmanı bir taraftan kaynak yararlılığının artırılması için iletim gücünü kontrol ederken, diğer taraftan yönlendirme protokolüne gerekli bilgi kaynağını sağlamaktadır. Servis kalitesinin artırılması ile ilgili olarak önerdiğimiz çözümü değerlendirmek için benzetimler yaptık. Bu benzetim sonucunda, elemanların birlikte etkileşim içinde çalışmasının, servis kalitesi desteğiyle ilgili daha iyi bir başarım elde edilmesini sağladığı görülmüştür.","IV ABSTRACT QoS SUPPORT IN MULTIHOP AD HOC NETWORKS USING POWER CONTROL Today, many people use numerous portable devices, such as mobile phones, PDAs and laptops. When these mobile devices are used interactively, we can establish communication anytime and anywhere without the aid of a central infrastructure. This system is called multihop ad hoc wireless network (MANET). In a MANET, all nodes move freely and do not require any fixed communication infrastructure. Because of the shared communication media and the dynamic topology of the network, incorporating QoS into MANETs is not an easy task. Several methods have been developed addressing particular aspects of QoS support, focusing on QoS routing, medium access control. However, none of them results in a complete solution. A complete solution for QoS support in MANETs can be achieved by cooperating those focused components. In this thesis, we propose a QoS routing protocol. We tightly couple the routing protocol with underlying MAC layer to monitor topological changes and available network resources. MAC layer controls transmission power to increase overall resource utilization and supplies available resource information to routing protocol. We use simulations to evaluate the performance of the proposed solution. They show that interaction of these components results in better performance in QoS support."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ŞİFRELEME GERÇEKLEŞTİRMELERİNİN GEZGİN İNTERNET ARACI SİSTEMLERİNİ NASIL ETKİLEDİĞİ Bu yüksek lisans çalışmasında, gezgin İnternet aracı sistemleri ve gezgin İnternet aracı sistemlerinde verilerin korunması için kullanılan şifreleme gerçekleştirmeleri üzerinde çalıştık. Gezgin İnternet aracısı, çoktürel ağlar üzerinde verilen görevleri yerine getirmek üzere kendi kontrolünde bir makineden diğer makineye gidebilen programdır. Gezgin İnternet aracılarının uygulamalı birçok avantajı olmasına rağmen gezgin İnternet aracılarının kötücül gezgin İnternet aracı sunucularından ve gezgin İnternet sunucularının kötücül gezgin İnternet aracılarından korunması gibi önemli dezavantajları vardır. Bu çalışmanın uygulamalı kısmının amacı şifreleme sistemlerinin gezgin İnternet aracı sistemlerini nasıl etkilediğinin incelenmesidir. Bir Kullanımlık Anahtar Üretmeli Sistem ve Diffie-Hellman Anahtar Değiştokuş Sistemi gerçekleştirilmi ve bu sistemler elde edilen veri büyüklüğü, ziyaret edilen istemci sayısı, şifreleme anahtar boyu ve algoritması gibi farklı değişkenler kullanılarak test edilmiştir. Çalışmanın sonuç kısmında, gezgin İnternet aracılarının ihtiyaçlarına göre uygun şifreleme sisteminin seçilebilmesi için test sonuçları hakkında yorumlar yapılmıştır.","IV ABSTRACT HOW CRYPTOGRAPHIC IMPLEMENTATIONS AFFECT MOBILE AGENT SYSTEMS In this Master Thesis Project we studied on mobile agent systems and cryptographic implementations used in these mobile agent systems for data protection. Also this thesis examines how cryptographic implementations affect mobile agent systems. A mobile agent is a program that can move from machine to machine under its own control in order to achieve some tasks over a heterogeneous network. Although mobile agents have many practical advantages, they have significant drawbacks such that protecting mobile agents from malicious mobile agent servers and protecting mobile agent servers from malicious mobile agents. The practical part of this work aims to examine how cryptographic systems affect the mobile agent systems. One-time Key Generation System and Diffie-Hellman Key Exchange System are implemented and tested using different variables such that retrieved data size, visited number of clients, encryption key sizes and algorithms. At the conclusion part of the study, we commented on the test results to be able to choose a cryptographic system according to the mobile agent requirements.ÖZET ŞİFRELEME GERÇEKLEŞTİRMELERİNİN GEZGİN İNTERNET ARACI SİSTEMLERİNİ NASIL ETKİLEDİ?İ Bu yüksek lisans çalışmasında, gezgin İnternet aracı sistemleri ve gezgin İnternet aracı sistemlerinde verilerin korunması için kullanılan şifreleme gerçekleştirmeleri üzerinde çalıştık. Gezgin İnternet aracısı, çoktürel ağlar üzerinde verilen görevleri yerine getirmek üzere kendi kontrolünde bir makineden diğer makineye gidebilen programdır. Gezgin İnternet aracılarının uygulamalı birçok avantajı olmasına rağmen gezgin İnternet aracılarının kötücül gezgin İnternet aracı sunucularından ve gezgin İnternet sunucularının kötücül gezgin İnternet aracılarından korunması gibi önemli dezavantajları vardır. Bu çalışmanın uygulamalı kısmının amacı şifreleme sistemlerinin gezgin İnternet aracı sistemlerini nasıl etkilediğinin incelenmesidir. Bir Kullanımlık Anahtar Üretmeli Sistem ve Diffie-Hellman Anahtar Değiştokuş Sistemi gerçekleştirilmi ve bu sistemler elde edilen veri büyüklüğü, ziyaret edilen istemci sayısı, şifreleme anahtar boyu ve algoritması gibi farklı değişkenler kullanılarak test edilmiştir. Çalışmanın sonuç kısmında, gezgin İnternet aracılarının ihtiyaçlarına göre uygun şifreleme sisteminin seçilebilmesi için test sonuçları hakkında yorumlar yapılmıştır.VI TABLE OF CONTENTS ACKNOWLEDGEMENTSiii ABSTRACTiv ÖZETv TABLE OF CONTENTSvi LIST OF FIGURESix LIST OF ABBREVIATIONSxi 1. INTRODUCTION1 1.1. MASIF1 1.2. IBM's Aglets Software Development Kit2 1.3. About This Thesis3 2. MOBILE AGENTS4 2.1. Characteristics of Mobile Agents4 2.1.1. Mobility5 2.1.2. Autonomy5 2.2. Evolution of Mobile Agents5 2.2.1. Remote Procedure Calls (RPC)5 2.2.2. Remote Evaluation (REV)5 2.2.3. Mobile Agents6 2.3. Mobile Agent Systems7 2.4. Applications of Mobile Agents9 2.4.1. E-commerce9 2.4.2. Search Engines and Content-Based Image Indexing and Retrieval...9 2.4.3. Personal Assistance10 2.4.4. Electronic Mail...10 2.4.5. Parallel Processing for Distributed Systems10 2.5. Benefits of Mobile Agents11 2.5.1. Reduce Network Load11 2.5.2. Overcome Network Latency11 2.5.3. Execute Asynchronously and Autonomously11 2.5.4. Heterogeneous12vıı 2.5.5. Robust and Fault Tolerant12 2.5.6. Adapt Dynamically12 2.6. Drawback of Mobile Agents12 IBM AGLET MODEL13 3.1. Basic Elements13 3.2. Aglet Life-Cycle14 3.3. Benefits of Agent Characteristics of Java15 3.3.1. Platform Independence15 3.3.2. Secure Execution15 3.3.3. Dynamic Class Loading15 3.3.4. Multithread Programming16 3.3.5. Object Serialization16 3.4. Drawback of Agent Characteristics of Java16 3.4.1. Inadequate Support for Resource Control16 3.4.2. No Protection of References17 SECURITY ISSUES18 4.1. Protecting Mobile Agents from Malicious Host18 4.2. Protecting Hosts From Malicious Mobile Agents18 4.3. Protecting Mobile Agents from Other Agents19 4.4. A Security System for Data Protection of Mobile Agents19 4.4.1. Key Generation Module21 4.4.2. Algorithm of the System22 4.4.3. Rlk, R2k Random Numbers22 4.4.4. Generation of DES Key Seed22 4.4.5. Agent Execution and Retrieving Data23 4.4.6. Encryption of Rlk, R2k and DSA (DES (data))24 4.4.7. Creating New Coupler for the Next Server26 4.4.8. Decryption of the Cipher26 4.5. Step by Step Implementation of the Encryption System27 4.5. 1. Generating Initial Coupler CO, RSA, DSA Key Pairs and Sending the Aglet to the Next Server27 4.5.2. Receiving Aglet and Generating Rl, R2 Random Numbers27 4.5.3. Generating DES Key28vııı 4.5.4. Encrypting the Plaintext and Signing28 4.5.5. Combining the Rl, R2 and DSA(DES(data)) and Encrypting Using RSA29 4.5.6. Receiving Aglet and Decrypting RSA Cipher text30 4.5.7. Decrypting the DES Cipher Text31 4.6. An Alternative Security Model Using Diffie-Hellman Key Exchange3 1 4.6.1. Diffie-Hellman Key Exchange31 4.6.2. Security Model with Diffie-Hellman33 5. EXPERIMENTAL RESULTS35 5.1. Test Environment35 5.2. Experiments with Different Encryption Algorithms35 6. CONCLUSION48 6.1. Number of Clients48 6.2. Size of the Retrieved Data49 6.3. Encryption Algorithms and Key Sizes49 REFERENCES50IX LIST OF FIGURES Figure 1.1. Tahiti Aglet server2 Figure 2.1. General representation of agent systems4 Figure 2.2. Evolution of mobile agents6 Figure 3.1. Relationship between Aglet and Proxy13 Figure 3.2. Aglet life-cycle model14 Figure 3.3. Object serialization in Java16 Figure 4.1. Overview of security system20 Figure 4.2. Key generation module21 Figure 4.3. DES key generation23 Figure 4.4. Generating coupler and key pairs27 Figure 4.5. Generating Rl and R2 random numbers27 Figure 4.6. Generating DES key28 Figure 4.7. Encrypting the plaintext and signing29 Figure 4.8. Encryption with RSA30 Figure 4.9. Decryption of RSA30X Figure 4.10. Decryption of DES31 Figure 4.11. Diffie-Hellman key exchange33 Figure 4.12. Security model using Diffie-Hellman key exchange33 Figure 5.1. Encryption vs. number of clients (500 Kbytes, 512 Bits)37 Figure 5.2. Encryption vs. number of clients (750 Kbytes, 512 Bits)39 Figure 5.3. Encryption vs. number of clients (1000 Kbytes, 512 Bits)40 Figure 5.4. Encryption vs. number of clients (500 Kbytes, 768 Bits)42 Figure 5.5. Encryption vs. number of clients (750 Kbytes, 768 Bits)44 Figure 5.6. Encryption vs. number of clients (1000 Kbytes, 768 Bits)45 Figure 5.7. Ratio of encryption algorithms for encryption systems (512 Bits)46 Figure 5.8. Ratio of encryption algorithms for encryption systems (768 Bits)47XI LIST OF TABLES Table 2.1. Agent mobility support8 Table 5.1. Aglet execution times for 500 Kbytes data size and 512 Bits key size for RSA (msec.)36 Table 5.2. Aglet execution times for 500 Kbytes data size and 512 Bits key size for Elgamal (msec.)36 Table 5.3. Aglet execution times for 500 Kbytes data size and 5 12 Bits key size for Diffie-Hellman (msec.)37 Table 5.4. Aglet execution times for 750 Kbytes data size and 512 Bits key size for RSA (msec.)38 Table 5.5. Aglet execution times for 750 Kbytes data size and 512 Bits key size for Elgamal (msec.)38 Table 5.6. Aglet execution times for 750 Kbytes data size and 512 Bits key size for Diffie-Hellman (msec.)38 Table 5.7. Aglet execution times for 1000 Kbytes data size and 512 Bits key size for RSA (msec.)39 Table 5.8. Aglet execution times for 1000 Kbytes data size and 512 Bits key size for Elgamal (msec.)40Xll Table 5.9. Aglet execution times for 1000 Kbytes data size and 512 Bits key size for Diffie-Hellman (msec.)40 Table 5.10. Aglet execution times for 500 Kbytes data size and 768 Bits key size for RSA (msec.)41 Table 5.11. Aglet execution times for 500 Kbytes data size and 768 Bits key size for Elgamal (msec.)41 Table 5.12. Aglet execution times for 500 Kbytes data size and 768 Bits key size for Diffie-Hellman (msec.)42 Table 5.13. Aglet execution times for 750 Kbytes data size and 768 Bits key size for RSA (msec.)43 Table 5.14. Aglet execution times for 750 Kbytes data size and 768 Bits key size for Elgamal (msec.)43 Table 5.15. Aglet execution times for 750 Kbytes data size and 768 Bits key size for Diffie-Hellman (msec.)43 Table 5.16. Aglet execution times for 1000 Kbytes data size and 768 Bits key size for RSA (msec.)44 Table 5.17. Aglet execution times for 1000 Kbytes data size and 768 Bits key size for Elgamal (msec.)45Xlll Table 5.18. Aglet execution times for 1000 Kbytes data size and 768 Bits key size for Diffie-Hellman (msec.)45XIV LIST OF ABBREVIATIONS API ASDK CBR CPU DES DSA GSM IBM MASIF M.I.T. OKGS OMG PDA RAM REV RPC RSA SHA TCP URL WWW Application Programming Interface Aglets Software Development Kit Content Based Retrieval Central Process Unit Data Encryption Standard Digital Signature Algorithm Global System for Mobile communication International Business Machines Mobile Agent System Interoperability Facility Massachusetts Institute of Technology One-Time Key Generation System Object Management Group Personal Digital Assistant Random Access Memory Remove Evaluation Remote Procedure Call Rivest, Shamir and Adleman Algorithm Secure Hash Algorithm Transmission Control Protocol Uniform Resource Locator World Wide Web1. INTRODUCTION Over the last few years, Internet and local networks are becoming overloaded and busy. So that developers are searching for new software technologies other than client server, applets and servlets to overcome these problems. Mobile agent is an alternative to solve these problems. Mobile agent is a program that can halt itself, ship itself to another computer on the network, and continue execution at the new computer. The key feature of this kind of software agent is that both its code and state are mobile. There are some organizations that determine the standards for mobile agent systems. Object Management Group (OMG) and Foundation for Intelligent and Physical Agents (FIPA) represent almost 1000 members. Mobile Agent System Interoperability Facility (MASIF) is another foundation, which is supported by OMG. 1.1. MASIF Although mobile agents are new technologies, there are some various kinds. These systems differ widely in architecture and implementation, so some aspects of mobile agents should be standardized. MASIF [1] is a collection of definitions and interfaces that provides an interoperable interface for mobile agent systems. There are some aspects that MASIF standardize and doesn't standardize. Aspects that MASIF doesn't standardize:. Language interoperability Local agent operations such as agent interpretation, serialization/deserialization, and execution.Aspects that MASİF standardize:. Agent Management: Standard operations such as creating an agent, suspending it, resuming, and terminating should be done in a standard way for different types of agent systems.. Agent Transfer: Agent applications can freely move among agent systems of different types.. Agent and Agent System Names: Agent and agent system names allow agent systems and agents to identify each other.. Agent System Type and Location Syntax: The agent transfer cannot happen unless the agent system type can support the agent. The location syntax is standardized so that the agent systems can locate each other. 1.2. IBM's Aglets Software Development Kit The Aglets Software Development Kit (ASDK) is an implementation of Aglet API, which can be downloaded from IBM Tokyo Research Laboratory's Web site [2]. The Aglet API is a set of Java classes and interfaces that allows creating mobile Java agents. Figure 1. 1 represents the Tahiti Aglet server. Si^ft& ik}%mWk&&;'^fa*t^ -.- '- C i hr ?.WX. iej m Aglet Mobility View Options Tools Help >< Create AsrVfJ^b Retract e3tamples.simp]e.DisplayAglet : Mori Jim 16 22:46:47 EEST 2003 Hello, world! I amexamp] e3amp]es.http.WebServerAgkt : Mon Jun 16 22:45:55 EEST 2003 examp]es.hel]o.He]bAglet : Mon Jun 16 22:45:52 EEST 2003 Create : examples.simp]e.DisplayAglet fromatp://ism:4434/ Figure 1.1. Tahiti Aglet server1.3. About This Thesis In this part we will describe the order of how our work is organized. First of all we mention about theoretical information about mobile agents. Then it follows with the security issues of mobile agents and practical implementations. Next parts summarize the experimental results and conclusions. This thesis consists of following chapters:. Chapter 2, """"Mobile Agents"", is about theoretical information about mobile agents.. Chapter 3, ""IBM Aglet Model"", gives information about ASDK.. Chapter 4, ""Security Issues"", is about the security concern with the mobile agents and implementation of cryptographic systems for data protection.. Chapter 5, ""Experimental Results"", includes results obtained from tests using ASDK according to some variables.. Chapter 6, ""Conclusion"", summarizes conclusions of this study according to test results.2. MOBILE AGENTS Mobile agents are software programs that can migrate from one node to another autonomously and can collect, filter and process the information. They can suspend their own executions, transfer themselves to another agent server and resume their execution. Mobile Agent MIGRATION Agent Server A ?*"" Mobile Agent Agent Server B Authentication and decryption of code, data and state of mobile agent Figure 2.1. General representation of agent systems Mobile agents include the code, the data and the state of running application during their itinerary. They need agent servers to execute. Agent servers' role in the agent environment is to load mobile agents' code and to provide communication between the nodes. 2.1. Characteristics of Mobile Agents Although there is no exact set of characteristics that define an agent, there are two main characteristics that an agent must have:2.1.1. Mobility Mobility is the primary characteristic of mobile agents. By using mobile characteristic, mobile agents can migrate from one node to another where data is physically stored. When mobile agent travels to the host and access the data locally, it prevents the transfer of large amount of information from one host to another. 2.1.2. Autonomy Another essential characteristic of mobile agents is autonomy. A mobile agent is able to travel and execute without direct need of human intervention or guidance. Also, the agent maintains control over its own actions and state. Mobile agents can collect, filter, process the information and return back to the home server so the user can perform other applications in the same time. 2.2. Evolution of Mobile Agents 2.2.1. Remote Procedure Calls (RPC) In the RPC model, there are two processes: client process and server process. Client process sends a message including procedure parameters and wait for the results. After receiving them, client process resume execution. On the server side, server process waits for a message and when a message is arrived, it executes a procedure using the parameters. Server process returns the procedure results to the client and waits for the next message [3,4]. 2.2.2. Remote Evaluation (REV) Remote evaluation is an extension to the RPC model. It allows the client to send a request to the server in the form of a program. The server executes this program locally and returns the results to the client. This is synchronous a interaction that the client is blocked until the remote computation finishes and returns the results [5].2.2.3. Mobile Agents Mobile agent comprises the code, the data and the context that it can migrate from one server to another. Unlike REV, mobile agents doesn't have to return any results to the client or home server. Also mobile agents have much more autonomy that remote procedure calls. Figure 2.2 illustrates the differences between RPC, REV and mobile agents. Figure 2.2. Evolution of mobile agents #?,tf£lN2.3. Mobile Agent Systems Telescript [6], developed by General Magic, includes an object-oriented, type-safe language for agent programming. Telescript servers are called as places. Telescript has significant support for security, including an access control mechanism similar to capabilities [7]. Each agent and place has an associated authority. A place can query an incoming agent's authority and deny its entry or restrict its access rights. Each agent has a permit, which specifies its access rights and resource consumption quotas. Agents that exceed their quotas or attempt unauthorized operations are terminated by system. Because Telescript is not successful commercially, General Magic reimplements Telescript with Java classes and named as Odyssey. Tacoma is developed by the University of Tromso, and Cornell University. Agents are written in Tel language [8]. Tacoma generally focuses on operating system support for agents. The Tacoma system is based on Unix and Transmission Control Protocol (TCP). Tacoma agents can carry scripts written in C, Tcl/Tk, Perl, Pyhton and Scheme. Agent Tel is developed by Dartmouth College and allows Tel scripts to migrate between servers [9]. It focus on five research areas: o Performance. o Support for multiple languages. o Cryptographic authentication and restricted execution environments to protect a machine from malicious agents, o Economic-based models to limit agent's resource consumption, o Networking sensing, navigation and planning to determine the best path through the network according to its task. Agent Tel has two main components: o A server that runs on each computer. o An execution environment for each supported language.Azlet is a Java-based system developed by IBM. Agents (called Aglets), migrate between agent servers (called Tahiti), located on different network hosts. Aglets will be mentioned in detail later. Concordia [10] developed by Mitsubishi Electric, supports mobile agents written in Java. Like most Java-based systems, it provides agent mobility using Java's serialization and class loading mechanisms. A Concordia system is made up of Java VM, a server and a set of agents. In this system agent state is protected during transition. Servers can protect their resources using access control list based on user identities. Each agent is associated with a particular user and carries user's password, which is hashed. This system can only be used in closed networks because passwords should be stored in global file for verifying. Voyager is a Java-based agent system, which is developed by ObjectSpace [11]. In this system a global unique identifier is assigned to an agent and a symbolic name during the creation of agent. Agents migrate to other servers by moveTo command. Following table summarizes the agent system naming and agent migration: Table 2.1. Agent mobility support2.4. Applications of Mobile Agents 2.4.1. E-commerce E-commerce is an up growing industry such that only in United Stated online sales grew 52% over last year to $78 billion (Forrester Research) so different technologies are thought to be used in e-commerce. Mobile agents are one of these technologies that they can perform transactions between business-to-business, business-to-consumer and consumer-to-consumer. Mobile agents reduce the amount of human interaction in order to buy and sell goods. Kasbah System, developed in M.I.T., is a good example of how mobile are used in e- eommerce. Users who would like to buy or sell item create the agent and dispatch it to agent marketplace. This agent finds other buying/selling agents and negotiates with them on behalf of the user. If they agreed according to the constraints that are defined by the user, they return back and inform the users. Lastly they arrange the payment and delivery of the item. Another example is Zeus agents, which is developed in Hewlett Packard Laboratories by using British Telecommunication's Zeus Toolkit, which is written in Java [12]. 2.4.2. Search Engines and Content-Based Image Indexing and Retrieval In the content-based retrieval (CBR) searching technique, search engines are queried according to a sample media type and similar media types are returned back. [13] In this technique, search engine generates a list of URLs pointing to a similar images and a thumbnail for each image. In the WWW indexing is used as centralized. Because of centralized indexing, bottlenecks are occurred when attempting to locate information. To cope with these bottlenecks the index needs to be decentralized in the same manner. Mobile agents can be used for performing distributed indexing [13, 14].10 2.4.3. Personal Assistance Mobile agents can be used for personal assistance such that scheduling a meeting. An interesting study was performed in [15] on this subject. An organizer will organize a videoconference with the participants who are in different domain but have the same electronic agenda server domain. A mobile agent is dispatched by organizer and visits all participants. Mobile agent negotiates the potential rescheduling with the each participant's personal agent on his behalf. Mobile agent only returns the possible schedules. 2.4.4. Electronic Mail Today a widely used communication tool is e-mail but if slow dialup connection is used, opening large attachments or spam mail is becoming a problem. Also mobile users that use low capability devices such as mobile phones or PDAs might not be able to read the attachments because the format is simply not supported by the device. S. Karnouskos and A. Vasilaskos proposed a new flexible, secure and intelligent mobile e-mail system [16]. In this e-mail platform, system will contain context information for each user. This context information includes user's location and devices with capabilities. This context information could be updated by mobile agents. Also mobile agents could be used to retrieve user's location, i.e. querying GSM phones. When a PDA user receives an email, which includes an attachment with video and sound, video may be send to mobile phone of the same user and sound is send to PDA if PDA doesn't support video format. 2.4.5. Parallel Processing for Distributed Systems Another area that mobile agents can be used is distributed computing. When a calculation requires so much computing, it could divided into discrete units and each can be assigned to mobile agents than mobile agent would be dispatched to the host with the smallest workload and return back with the results. This technique is successfully tested on prime number calculation by Penny Noy and Michael Schroeder [17].11 Some of the other applications of mobile agents are:. Weather Forecast [ 1 8]. Distributed Intrusion Detection [ 1 9]. Telemedicine [20] 2.5. Benefits of Mobile Agents Various reasons to use mobile agents [21]: 2.5.1. Reduce Network Load When very large amounts of data are stored at the remote hosts, these data should be processed locally instead downloaded over the network. Mobile agents allow transporting the program to the data to process locally rather than transporting the data to the program. Generally this reduces network load. 2.5.2. Overcome Network Latency In the real-time systems, the most important point is to respond to change in real time. Controlling such systems through a large network, significant network latencies occur. To overcome this network latency, mobile agents are alternative solution because mobile agents can be dispatched from a central controller to act locally and execute the controller's directions. 2.5.3. Execute Asynchronously and Autonomously It is not economic to maintain a continuous network connection for mobile devices such as PDAs, cellular phones and mobile devices because they have expensive network conditions. At this point mobile agents are useful because they do not require a continuous network condition. Use could dispatch a mobile agent into the network and disconnect the12 connection. When user reconnects, mobile agent returns back with completing its tasks. This is also very useful for laptops because it provides power consumption. 2.5.4. Heterogeneous Mobile agents are computer independent and depended only execution environment. This is an important benefit because networks may consist different types of computers and different types of software. 2.5.5. Robust and Fault Tolerant Mobile agents can react effectively to undesired changes to the environment. For example if a network host is to be shutdown the mobile agent can detect this and dispatch itself to another host. 2.5.6. Adapt Dynamically Mobile agents can clone themselves to maintain optimal configuration for solving a problem. 2.6. Drawback of Mobile Agents Although mobile agents have many advantages, they have a major drawback such that security threads. As mentioned before mobile agents could be used in many applications but all these applications feel need for security mechanism. For example if a mobile agent were used for e-commerce, maybe it would carry credit card number and personal information. All these critical information should be protected against malicious servers or third parties. Also malicious agents could be exist in the network so agent servers should protect their stored data or prevent their CPU usage from agents.13 3. IBM AGLET MODEL As it is briefly described at the previous section, Aglet is a Java-based system developed by IBM [22]. Agents (called Aglets), migrate between agent servers (called Tahiti), located on different network hosts. 3.1. Basic Elements IBM Aglet agent system is formed by 3 basic elements:. Aglet: An Aglet is a mobile Java object that visits Aglet-enabled hosts in a computer network. It is autonomous because it runs in its own thread of execution after arriving at a host.. Proxy: A Proxy is a representative of an Aglet. It serves as a shield that protects the Aglet from direct access to its public methods. Figure 3.1 illustrates the relationship between Aglet and Proxy.. Context: A context is an Aglet's workspace. Context provides maintaining and managing running Aglets in a uniform execution environment where the host system is secured against malicious Aglets.. Identifier: An identifier is bound to each Aglet. This identifier is unique throughout the lifecycle of the Aglet. Clients Figure 3.1. Relationship between Aglet and Proxy14 3.2. Aglet Life-Cycle There are basically only two ways to bring an Aglet to life: one is creation; another is cloning from an existing Aglet. Figure 3.2. represents the life-cycle of an Aglet [23]. Dispose Clone Aglet L_ Dispatch Retract Create Deactivate Class File Active Disk Storage Figure 3.2. Aglet life-cycle model Creation: The creation of an Aglet takes place in a context. An identifier is assigned to new Aglet and initialized. The Aglet starts executing after successfully initialized. Cloning: Cloning of an Aglet is copying the original Aglet. The only difference is the assigned identifier. Dispatching: Dispatching an Aglet from one context to another will remove it from its current context and insert it into the destination context, where it restarts execution. Retracting: The retraction of an Aglet will remove it from its current context and insert it into the context from which retraction is requested. Activation and Deactivation: The deactivation of an Aglet is the ability to temporarily halt its execution and store its state in the secondary storage. Activation of an Aglet will restore it in the same context. Disposal: The disposal of an Aglet will halt its current execution and remove it from its current context.15 3.3. Benefits of Agent Characteristics of Java 3.3.1. Platform Independence Java is designed to be able to operate in heterogeneous environments. Java compiler generates byte code to make the Java applications to run on any computer where Java runtime system is present. Java byte code different from the non-portable native code. The Java language is not platform dependent such as primitive data types are not dependent on the underlying processor or operating system. Also libraries are platform independent. 3.3.2. Secure Execution As Java is also been known Internet language, it provides security mechanisms for the secure design. These are the security concepts of Java:. Does not allow illegal type casting or ant pointer arithmetic.. Programs do not have access to private data in objects. If byte code is changed, Java runtime environment ensures that the code will not violate the rules of Java.. Java has a security manager to check operations such that file access and network connections. 3.3.3. Dynamic Class Loading Dynamic class loading mechanism allows the Java virtual machine to load and define classes at runtime. This provides a protective name space for each agent, so each agent can execute safely.16 3.3.4. Multithread Programming An agent can execute independently of other agents being in the same place. Java allows each agent to execute in its own process, which is also called thread of execution. 3.3.5. Object Serialization Object serialization is briefly described by N. Karnik in his Ph. D. Thesis [24]. Java provides object serialization functions, which allow us to convert an object instance into a machine independent array of bytes. This byte array can be transmitted over a network to another host and de-serialized there where converted back to a Java object. This is illustrated in Figure 3.3. This is the most important property for agent's mobility. Figure 3.3. Object serialization in Java 3.4. Drawback of Agent Characteristics of Java Although Java language system is suitable for mobile agents, it has some disadvantages that some of them can be handled by work around solutions, but some of them couldn't be handled. 3.4.1. Inadequate Support for Resource Control Java language is not adequate to provide resource control. An agent can start looping and waste processor cycle and start consuming the CPU and memory resources. In the terminology of security, this is called denial of service. Using this inadequateness, one type of attack is an agent group penetrated into a server and takes over all its resources and17 makes it impossible to operate. Unfortunately Java couldn't provide limiting the CPU and memory resources allocated by an object. 3.4.2. No Protection of References A Java object's methods are available to any other object that has a reference to it. This access is very important for agent. There is no way that the agent can directly monitor and control which other agents are accessing its methods. In the Aglets, this problem is solved by using a Proxy object between the caller and the callee to control access.18 4. SECURITY ISSUES As described before mobile agent technology introduces many potential advantages that result from its mobility and autonomy features such as reducing network load, being robust and fault tolerant. Despite of its advantages, mobile agent technology raises several security problems. Nowadays, security problems recognized as a major problem to put mobile agent technologies in practical use. The security problems can be categorized as follows: 4.1. Protecting Mobile Agents from Malicious Host Although mobile agents can act autonomously, it is obvious that they require mobile agent servers to execute. At this point integrity and confidentiality is major concern for mobile agents because a mobile agent server could modify, remove or add mobile agent code or data. So it is important that server shouldn't able to tamper with an agent or its information. Following criterias should be ensured [25, 26]:. Sensitive information never passes through an untrusted machine in an unencrypted form.. The information should be meaningless without cooperation with a trusted site.. Theft of the information should not be catastrophic and could be detected by an audit. 4.2. Protecting Hosts From Malicious Mobile Agents As mobile agents execute on mobile agent servers, malicious mobile agents may pretend to be a virus or worm and could give damage to servers. When a mobile migrates to a server, it uses the server's CPU and data stores to execute. So following precautions should be taken at the server side [27]:19. Server should authenticate the agent.. Resource limits should include access rights for reading a certain file and CPU usage. 4.3. Protecting Mobile Agents from Other Agents During mobile agents execute on the mobile agents environment, they could execute at the same machines and meet. So agent should not permit the other agents to steel or modify the agent's resources. This problem can be viewed as like a protecting the machine. 4.4. A Security System for Data Protection of Mobile Agents As described before during the trip of the mobile agent, confidentiality and integrity of agent data should be obtained. For instance if a mobile agent is used in e-commerce application to buy or sell books, it will travel from one host to another, find the cheapest book and buy it. In this application to buy this book, it should carry the credit card number or personal information. This information should be kept secret and confidentiality and integrity should be provided. A one-time key generation system is proposed by Jong-Youl Park for the confidentiality and integrity of agent data [28]. The main idea is a sequence of interrelated encryption keys to encrypt the agent data. Important point of the system is one-way hash function, which is used to generate the encryption keys and make the system one way. Figure 4.1 illustrates the general view of the system.20 Agent Server ASk Agent Structure on Agent Server ASk.i Agent Code Encrypted Data DESfc,(dataM) Encrypted random number ASo-pub (Rlk-i) R2k- Coupler Ck.; Sep I Agent Structure on Agent Server ASk Code Check * ? Agent Run i t Step 3 RU Step 2 >. Hash (1) Encryption DES key R2k Step 4 > Hash (2) Kev Generation Module Agent Code Encrypted Data DESk.,(jiatok.i) D£Sk (data*) ASo.pUb (Rlk-b k-l- ) I- AS"".pub(Rlk,R2k...) > Coupler Ck Figure 4.1. Overview of security system As illustrated in Figure 4.1, at the first step agent server ASk-i generates a coupler and sends it to the next agent server ASk. If ASk-i is home server, coupler Co is random 160-bit value generated by ASn. Secondly, after receiving Ck-i, server ASk generates own DES key in the key generation module, which is based on one-way hash function. Combination of Ck-i and random number Rlk is used as an input for the first hash function and output of the first hash function is used as a DES key seed to encrypt data retrieved from server ASk. At the third step server ASk encrypts data using the previously generated DES key, which is the output of the first hash function. At the last step, to establish inter-relationship between servers, server ASk generates a new coupler using the combination of output of the first hash function and random number R2k as an input of the second hash function. Also random numbers Rlk and R2k are encrypted using the home server's public key and send to home server to be able to decrypt the ciphers. When the next server receives the coupler, it also generates own DES key and encrypt the data.21 4.4.1. Key Generation Module A one-time agent key, which is used to encrypt the data, is based on this one-way property, and it provides an inter-relationship between two consecutive agent keys. Figure 4.2 briefly shows how to make the inter-relationship; Rlk and R2k are 320 bits random numbers generated by the current host and they are encrypted with ASo-pub, the public key of the home server. ASk.! ASk coupler Ck-1 & Ck-i ® & Hash Function (> Hash Function Code Agent ASk ck -- »< c, coupler Agent Datak DesKey DESk(Datak) run Code Code Figure 4.2. Key generation module22 4.4.2. Algorithm of the System A server, ASk, receives a coupler Ck-i from the previous server, ASk-i, and generates random numbers Rlk and R2k that are secret information of ASk. If ASk-i is the home server (ASo), it creates a mobile agent and the initial coupler Co, and then dispatches it to the next agent server ASi. Otherwise agent server ASk generates its key seed Sk using Ck-i, Rlk and SHA-1, and also generates a new DES key based on Sk. then ASk generates Ck, a new coupler for the next agent server, and sends it to the next agent server ASk+i with the agent data. 4.4.3. Rlk, R2k Random Numbers Rlk and R2k are provided by the current host, and they are encrypted with ASo-pub, the public key of the home server. An agent key is created using not only Rlk but also the coupler Ck-i. So only the home server, ASo, can have Rlk, R2k, and Ck-i for each host, and reconstruct every agent key. In order to generate a one-time agent key, two random numbers Rlk and R2k are generated and they are 320 bits. These are used to scramble a coupler and to satisfy the secure condition of the one-way function from the birthday attack. Secure condition of a one-way hash function imposes restrictions on size of input and output data; size of an output must be more than 128-bits and that of input is double of the output size. For the reason of secure condition, Rlk and R2k, which are inputs of SHA-1, is decided on double size (320-bit) of the output (160-bit). They are encrypted using ASo-pub, the public key of the home agent server. Therefore only the home ASo can decrypt them. 4.4.4. Generation of DES Key Seed As it is seen in Figure 4.3 Sk is the DES key seed, which is used for DES key generation. It is the digest of the hash function SHA-1 where its input is the combination of Ck and Rlk- Combination is refers to XOR operation between Ck-i and Rlk. Before the XOR operation Ck-i should be concatenated with the same value because Ck-i is a 160-bit value and Rlk is 320-bit value. Equation is as follows:23 S^SHA-ÜC^-.C^Rl,) (4.1) To make these two variables at the same size concatenation is necessary. After DES key seed is generated, data retrieved from current server is encrypted with the DES key, which is generated using DES key seed. Figure 4.3 illustrates the generation of DES key from the DES key seed: 159 11 ? T> 6T, t M QS ? Qrt 177 ? 1?R Sk3 Sk3 Sk3 W DES key Figure 4.3. DES key generation 4.4.5. Agent Execution and Retrieving Data Data is the result of the agent execution and is encrypted with the agent key, which generated previously. datak = agent data retrieved from server ASk (4.2.)24 4.4.6. Encryption of Rlk, R2k and DSA (DES (data)) Rlk, R2k, and DSAk(DES(data)) are encrypted by current server with ASo-pub. Agent data, i.e. ASo-pub(Rlk, R2k, DSAk(DES(data))), might be modified or be deleted by another agent server. However, when the agent returns to the home server ASo, the deletion or modification is detected due to the inter-relationship among Sk's. In addition, digital signature is inserted to encrypted data to verify the data. In the implementation part RSA is used for the encryption. Encryption = AS^^ (Rlk, R2k, DSAk (DES(data))) (4.3) As a public key cryptography algorithm RSA or ELGAMAL could be used. The RSA algorithm is a cryptosystem for both encryption and authentication developed in 1977 by Ron Rivest, Adi Shamir and Leonard Adleman. Following steps represents the RSA key generation, encryption and decryption phases [29]: Key generation:. Select p, q where p and q both prime numbers,. Calculate n = pxq. Calculate 0(n) = (p-l)(q-l). Select integer e where gcd(0(n),e) = 1 ; l : [ 27 -89 -50 83 1 123 27 67 31 51 75 -91 36 110 -64 -49 60 54 69 -82 I XXXXXXXXXKXXXKXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXHXX Generating RSA key pairRSA Key pair generatedGenerating DSA key pair - DSA Key pair generated... ""ixxx Addr: atp: //ism =4435 place: Figure 4.4. Generating coupler and key pairs 4.5.2. Receiving Aglet and Generating Rl, R2 Random Numbers After home server dispatches the Aglet, client server receives it and generates random numbers Rl and R2. XXXXXXXXXXXXXXXXXXXXXMXXXMWXXXXXXXXXXXXXXXXXXKKXXXMXXXXXXXXMMXI* I fiM HT THE 1. SERUER*3E3gXXXXMXXXXXXXXXXXXXXMXXXXXXXX«-X-«XXXXXXXXMXXXX-KXXXXX'»fr»H6XXXXXXX Generating Random Numbers Ril, R21 fill : C 37 121 -11 87 -6 -120 -88 76 89 58 15 77 17 -186 -116 72 -11 -44 -102 19 -95 49 6 91 40 -29 37 44 -128 35 -108 24 121 42 -95 68 -55 118 -54 69 ] R21 : 1-123 -25 81 76 117 75 -55 84 122 -22 -42 95 -20 -100 -63 70 -90 124 -21 -114 -54 120 -55 -63 -42 -45 3 1 -24 -70 -30 56 107 -11 -28 0 -66 118 76 -53 3 XXXXXXMXXXXXXXXXXXXXXXXXXMMXXXXXXXXXXXXXXMXXXMMXXXXXXXMMXXMMXXK- Figure 4.5. Generating Rl and R2 random numbers28 4.5.3. Generating DES Key Client server generates DES key using random number Rl and received coupler CO to encrypt the plain text. *** DES KE¥ GENERATION *** MaKMMXKKaaMKXlilOIKXKXXXtBHWHt-M-X-H /////// / Rİİ /- /////// MHOR>! HASH FUNCTI0N !> * DES KEY * ft*««*3frM-»*BfrJM«£ I /////// \ / G0 //////// Generating DES KeyDes Key Seed : [ 107 68 77 56 94 -38 -46 27 ] DES Key is GeneratedDES Key : T 21-123 -95İ492 74 -89 107JW»BH»etXXXXXXXKX«!e!XXXXaMKKMXXXXWaXXXX«XXXKX?HiXXXXl(X»BaXXXXi»Ht Figure 4.6. Generating DES key 4.5.4. Encrypting the Plaintext and Signing Data, retrieved at the client server, is encrypted using the previously generated DES key and ciphertext is signed.29 !!!!?!!!!!!!!!!!!****!!??*!! DATA : ismail ENCODED DATA : : [ 105 İİ5 109 97 105 108] Encrypt ing Data with DESData is EncryptedENCRYPTED DATA : [ 126 93 111 112 29 -45 8 1841 ^X«KXXKKKXXXXXXXMMXWHHH] *** «SHt *X-X- MXXXXXXXXXKXKKKKXXHM-MKKXXKXKXK Signing The Encrypted DataDSA.Lenght = 46 Encrypted Data Signed52 35 97 -43 36 42 64 -122 60 18 -100 -81 2 20 126 79 -26 70 10 65 -72 70 53 3 -35 65 ] iHHBHWtXXXXXXXXXWHHHWHBHHH(XXXXXXli*iHHCXXKXXXKXXXXXX4HHt«XXKXXXKWt Figure 4.7. Rncrypting the plainte* 4.5.5. Combining the Rl, R2 and DSA(DES(data)) and Encrypting Using RSA Random numbers Rl, R2 and signed DES data are encrypted using RSA public key, so only home server can decrypt it using its private key. After Encryption is completed Aglet is dispatched to home server.30 Encrypting Combined Data Using RSA Public Key... Encyrption is CompletedIHlMKKKKKXXKKIIKKKXIIKieKKKKlHBHHHHlKXXKKKKllKKKXKICmilBHt^iBHHi *** CIPHERTEXT = RSft CR11, R21, DSA EDES I> ~~~ K4H* KKK KXKKKK-«»MKKKKKKKKKKWWXKKKMMMMKKKKKKKM-K»K-K-K-M-»MKKKKKMKKMW 18 -127 8 -29 93 -99 83 3 »X»XXX»XMeHH«HH(XXXXXXXX«»XXX»^HHtX«(X«XXX»HHHWWWWtW(X*lHHHBHH(» kkkkk flddr: atp://isn/ place: Figure 4.8. Encryption with RSA 4.5.6. Receiving Aglet and Decrypting RSA Cipher text When home server receives the Aglet first of all it decrypts the RSA cipher text using its private and obtain random numbers Rl, R2 and Signed DES data. Because home server has signed DES data, it verifies whether it is changed or not. «-W-W-M-M X X X M X M M M X X M M X X X X X-3g^»E-*<-X--«-M-M-M M K M-X M M M-X M M M M^M^H^M-M X X M XHM-X X X X X-X-M-M-3* DECRYPTED TEXT : MMMXMXMM-M-XMM'MXM'MOCKKMMXMXX «KMM X »frX- X-X-X-X XXXXXXXXXXXXXXXXXXXXXXMXXXXXXXXXXXXXXXXXMXXXXXXM «-X-X- Uerifying Signature ----_- SIGNATURE UERIFIEB= TRUE ^XXX-XXXXXXXXXXXXXXXXXXXXX-X-XXXXXXXXXXXXXM^CXXXXMXXXXXXMXX-^CX-XX-X-3-&*t- Figure 4.9. Decryption of RSA31 4.5.7. Decrypting the DES Cipher Text When home server decrypts RSA cipher text and obtains Rl, due to the fact that it has also knows the CO value, it can easily generates the DES key and decrypts the DES cipher text. ll)llCXXXXXXXXK»IIIHHHmKX>XK»XKXXX»»XllKI(lHHll(XXXXKIHBHHHHHHBeHlKKKX)t ENCODED PLAIN TEXT RECEIUED FROM SERUER 1 : [ 105 115 109 97 105 108] XmtKKXXXMXXXXXKKXXlCXXXXXXllXXXXKXXKXXXXlBlXXXXXXXKKKMXKXiHtXMWXXX PLAIN TEXT RECEIUED FROM SERUER 1 : ismail Figure 4.10. Decryption of DES 4.6. An Alternative Security Model Using Diffie-Hellman Key Exchange Although previously described security system provides data protection during the itinerary, it has some disadvantages:. The security system completely depends on the initial coupler Co. If this value is replaced or disrupted, all of the system will collapse down. Another security system is proposed in this thesis, which is based on the Diffie- Hellman key exchange. 4.6.1. Diffie-Hellman Key Exchange Diffie-Hellman key exchange is proposed by Whitfield Diffie and Martin E. Hellman [31]. The purpose of the algorithm is to enable two users to exchange a secret key securely than can be used for encryption. Diffie-Hellman allows two A and B to agree on a shared key through public messages:32. Alice and Bob publicly agree on: o p: large (5 12-bit) prime number o g: smaller number, not prime, g mod p. Both k values are same. kA = TBS"" mod/? = \gSB modp) A mod/? (4.6) kB = T/B mod p = (gSA mod pfB mod p (4.7) If the following Chinese Remainder Theorem is applied to above equations, it can be proved that kA = ks. Chinese Remainder Theorem: (x mod pY mod/? = x7 mod/? (4.8) So; kA=kB=gSBS""modp (4.9) Figure 4.1 1. Illustrates the Diffie-Hellman key exchange:33 Generate Random Sa Calculate Ta = gSA mod p Calculate k = (TB)SAmodp Generate Random Sb Calculate Tb = gSs mod p Calculate k - (Tb)^ mod p Figure 4. 1 1. Diffie-Hellman key exchange 4.6.2. Security Model with Diffie-Hellman This security model is based on Diffie-Hellman key exchange. The main idea of this model is encrypting the data using one key, which is obtained with Diffie-Hellman key exchange. Figure 4.12. Illustrates this security model. Agent Code Public T]x Public T2x Public Tn.lx Public Tn Code Check * ? Agent Run DES key 1 "" Encryption Diffie Hellman Key Exchange ^. Agent Code *. DES(dataO *' Public Tiv Public T2x Public Tn.i, Public T"". Figure 4.12. Security model using Diffie-Hellman key exchange34 Let's explain the system step by step: Home server generates public Tjx values for each agent server in the network using the public values p and g. When agent server receives the agent, it generates a secret value using Diffie- Hellman key exchange algorithm. Agent server uses this secret key as a DES key seed, generates DES key and encrypt the retrieved data. Generates public Tiy value, which will be used by home server to generate secret key. Replace this Tiy value with the Tix value and send the agent to the next server. When home server receives all Tny values it generates secret keys and DES keys so it is able to decrypt all encrypted data.35 5. EXPERIMENTAL RESULTS In this section our aim is to examine how encryption system affects our agent system and the performance of different types of encryption algorithms in the agent system. For this examination we performed our tests according to following variables:.. Different data sizes which is retrieved from agent servers. Different encryption algorithms. Different key sizes for encryption. Different number of agent servers. 5.1. Test Environment In this project we have constituted a local area network using 3 computers:. PHI 500 MHz. 192 Mb. RAM. Celeron 466 MHz. 256 Mb. RAM. Celeron 433 MHz. 160 Mb. RAM These 3 computers have connected with 100Mbps. ethernet card over a hub. 5.2. Experiments with Different Encryption Algorithms In this section we present our results obtained for different encryption algorithms. As it is previously described in the one-time key generation system, for equation 4.3, RSA and ElGamal algorithms are used for public key encryption and Diffie-Hellman key exchange model is compared. Table 5.1, Table 5.2 and Table 5.3 present the encryption, data retrieving and agent journey times for the following parameters:36. Data size: 500 Kbytes. Encryption key size: 512 Bits Figure 5.1 represents the percentage of encryption period for the encryption algorithms according the same parameters. Table 5.1. Aglet execution times for 500 Kbytes data size and 512 Bits key size for RSA (msec) Table 5.2. Aglet execution times for 500 Kbytes data size and 512 Bits key size for ElGamal (msec)37 Table 5.3. Aglet execution times for 500 Kbytes data size and 512 Bits key size for Diffie-Hellman (msec) ""?if l\v3A\ ElGamal -*- Diffie-Hellman 3 5 7 Number Of Clients Figure 5.1. Encryption vs. number of clients (500 Kbytes, 512 Bits) Table 5.4, Table 5.5 and Table 5.6 present the encryption, data retrieving and agent journey times for the following parameters: Data size: 750 Kbytes Encryption key size: 512 Bits Figure 5.2 represents the percentage of encryption period for the encryption algorithms according the same parameters.38 Table 5.4. Aglet execution times for 750 Kbytes data size and 5 12 Bits key size for RSA (msec) Table 5.5. Aglet execution times for 750 Kbytes data size and 5 12 Bits key size for ElGamal (msec) Table 5.6. Aglet execution times for 750 Kbytes data size and 512 Bits key size for Diffie-Hellman (msec)39 RSA EIGamal. Diffie-Hellman 13 5 7 Number Of Clients Figure 5.2. Encryption vs. number of clients (750 Kbytes, 512 Bits) Table 5.7, Table 5.8 and Table 5.9 present the encryption, data retrieving and agent journey times for the following parameters:. Data size: 1000 Kbytes. Encryption key size: 512 Bits Figure 5.3 represents the percentage of encryption period for the encryption algorithms according the same parameters. Table 5.7. Aglet execution times for 1000 Kbytes data size and 5 12 Bits key size for RSA (msec)40 Table 5.8. Aglet execution times for 1000 Kbytes data size and 512 Bits key size for ElGamal (msec) Table 5.9. Aglet execution times for 1000 Kbytes data size and 512 Bits key size for Diffie-Hellman (msec) 13 5 7 Number Of Clients RSA ElGamal. Diffie-Hellman Figure 5.3. Encryption vs. number of clients (1000 Kbytes, 512 Bits)41 We performed the same tests increasing the key sizes from 512 bits to 768 bits for all three algorithms RSA, ElGamal and Diffie-Hellman. Table 5.10, Table 5.11 and Table 5.12 present the encryption, data retrieving and agent journey times for the following parameters:. Data size: 500 Kbytes. Encryption key size: 768 Bits Figure 5.4 represents the percentage of encryption period for the encryption algorithms according the same parameters. Table 5.10. Aglet execution times for 500 Kbytes data size and 768 Bits key size for RSA (msec) Table 5.1 1. Aglet execution times for 500 Kbytes data size and 768 Bits key size for ElGamal (msec)42 Table 5.12. Aglet execution times for 500 Kbytes data size and 768 Bits key size for Diffie-Hellman (msec) EIGamal -k- Diffie-Hellman 3 5 Number Of Clients Figure 5.4. Encryption vs. number of clients (500 Kbytes, 768 Bits) Table 5.13 Table 5.14 and Table 5.15 present the encryption, data retrieving and agent journey times for the following parameters:. Data size: 750 Kbytes. Encryption key size: 768 Bits Figure 5.5 represents the percentage of encryption period for the encryption algorithms according the same parameters.43 Table 5.13. Aglet execution times for 750 Kbytes data size and 768 Bits key size for RSA (msec) Table 5.14. Aglet execution times for 750 Kbytes data size and 768 Bits key size for ElGamal (msec) Table 5.15. Aglet execution times for 750 Kbytes data size and 768 Bits key size for Diffie-Hellman (msec)44 Figure 5.5. Encryption vs. number of clients (750 Kbytes, 768 Bits) Table 5.16 Table 5.17 and Table 5.18 present the encryption, data retrieving and agent journey times for the following parameters:. Data size: 1000 Kbytes. Encryption key size: 768 Bits Figure 5.6 represents the percentage of encryption period for the encryption algorithms according the same parameters. Table 5.16. Aglet execution times for 1000 Kbytes data size and 768 Bits key size for RSA (msec)45 Table 5.17. Aglet execution times for 1000 Kbytes data size and 768 Bits key size for ElGamal (msec) Table 5.18. Aglet execution times for 1000 Kbytes data size and 768 Bits key size for Diffie-Hellman (msec) 3 5 Number Of Clients RSA ElGamal. Diffie-Hellman Figure 5.6. Encryption vs. number of clients (1000 Kbytes, 768 Bits)46 We also observed the ratio of encryption algorithms for OKGS and Diffie-Hellman key generation system. Figure 5.7 represents these ratios. For example the first bar in Figure 5.7 represents DES, DSA and RSA ratios in the OKGS system when RSA is used for public encryption for 512 bits key size and 500 Kbytes retrieved data. Similarly second bar represent the ratios in OKGS but ElGamal instead of RSA is used for public key cryptography. Third bar represents the DES and Diffie-Hellman key exchange ratios for Diffie-Hellman key exchange system. Like Figure 5.7, Figure 5.8 also represents the ratios in the OKGS and Diffie- Hellman key exchange system for 768 bits key sizes. 500 KBits 750 KBits 1000 KBits 100% 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% B Diffie-Hellman Key Exchange j D ElGamal ORSA QDSA HDES RSA/ElGamal/Diffie RSA/ElGamal/Diffie RSA/ElGamal/Diffie Hellman Hellman Hellman Figure 5.7. Ratio of encryption algorithms for encryption systems (512 Bits) m>' §p^ an» &»w47 100%-fT 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 500 KBits 750 KBits 1000 KBits ^ UDiffie-HelIman Key Exchange DEIGamal ORSA DDSA ' EDES RSA/ElGamal/Diffie Hellman RSA/ElGamal/Diffie Hellman RSA/ElGamal/Diffie Hellman Figure 5.8. Ratio of encryption algorithms for encryption systems (768 Bits)48 6. CONCLUSION In this thesis, we have integrated OKGS and Diffie-Hellman Key Exchange System to IBM Aglets and performed tests to compare these systems how they affect the agent system. As we performed our tests for different parameters, now we will conclude according to these variables. 6.1. Number of Clients In the experimental results section, from Figure 5.1 to Figure 5.6 represent that what ratio does the different encryption systems occur in the whole agent system. The whole agent system is formed with encryption system, Aglet's journey (serilization + class loading + travelling) and data retrieving. As a result when the number of clients that Aglet visits increase, the encryption ratio decreases because when tables from Table 5.1. to Table 5.16. are investigated, it can be concluded that while the increment rate of encryption time interval approximately equals to increment rate of the number of clients, increment rate of the journey time is more than increment rate of the number of clients. This is because of the fact that the agent carries the data retrieved from the previous servers. For example from Table 5.1., when the number of clients is increased from 1 to 7, the encryption time interval increases approximately 7 times, on the other hand journey time interval increases 1 1 times.49 6.2. Size of the Retrieved Data Again in the exprimental results from Figure 5.1 to Figure 5.6, it can be concluded that when the retrieved data size increases, encryption time interval increases. Because when tables from Table 5.1. to Table 5.16. are investigated, it can be concluded that while the increment rate of encryption time interval approximately equals to increment rate of the retrieved data size, increment rate of the journey time interval is less than increment rate of the retrieved data size. This is because of the fact that the time formed with serilization, class loading and data carrying. When only data carrying increases, increment rate of the journey time becomes less than increment rate of the retrieved data size. For example from tables Table 5.1 and Table 5.2, when retrieved data size is increased from 500 Kbytes to 750 Kbytes for 5 clients encryption time interval increases 1.5 times, on the other hand journey time interval increases 1.1 times. 6.3. Encryption Algorithms and Key Sizes Each figure from Figure 5.1 to Figure 5.6 represents how the encryption systems affect the general agent system when different encryption algorithms are used with different key sizes. From the figures it is clear that OKGS with ElGamal algorithm has the biggest ratio when it is compared aganist OKGS with RSA and Diffie-Hellman key exchange system and OKGS with RSA has greater ratio than the Diffie-Hellman key exchange system. On the other hand key size changes should be taken on care while making compration between systems with different encryption algorithms. Figure 5.7. and Figure 5.8. represents the ratio of encryption and key exchange algorithms in the whole encryption system. When these 2 figures investigated, it can be concluded that RSA key generation and encryption has the least ratio in the whole encryption system, ElGamal is the second and Diffie-Hellman has the greatest ratio. As a result of this statement, when key size is increased, the ratio of the Diffie-Hellman Key System is increased more than OKGS.50 REFERENCES 1. Milojicic, D., M. Breugst, I. Busse, J. Campbell, S. Covaci, B. Friedman, K. Kosaka, D. Lange, K. Ono, M. Oshima, C. Tham, S. Virdhagriswaran and J. White, ""MASIF, The OMG Mobile Agent System Interoperability Facility"", Second International Workshop on Mobile Agents 98 (MA'98), Stuttgart-Germany, 9 September- 11 September, 1998. 2. ASDK, Aglets Software Development Kit, IBM, http://www.trl.ibm.co.jp/Aglets/ 3. Andrew, D. B. and B. J. Nelson, ""Implementing Remote Procedure Calls"", ACM Transactions on Computer Systems, Vol. 2, No. 1, pp. 39-54, February 1984. 4. Srinivasan, R., Remote Procedure Call Protocol Specification Version 2, RFC 1831, August 1995. 5. Hartson, H.R., J.C. Castillo, J. Kelso, J. Kamler and W.C. Neale, ""Remote Evaluation: The Network as an Extension of the Usability Laboratory"", Proceedings of CHI'96 Human Factors in Computing Systems, pp. 228-235, 1996. 6. White, J. E., Mobile Agents, Technical Report, General Magic, October 1995. 7. Tardo, J. and L. Valente, ""Mobile Agent Security and Telescript"", Proceedings IEEE Computer Conference 96, Los Alamitos-California, 1996. 8. Jahansen, D., R. V. Renesse and F. B. Schneider, An Introduction to TACOMA Distributed System: Version 1.0, University of Tromso, Technical Report 95-23, 1995. 9. Gray, R. S., ""Agent Tel: A Flexible and Secure Mobile-Agent System"", Proceedings Fourth Annual Tcl/Tk Workshop, 1996.51 10. Kobrick, R., ""Concordia"", Communication of the ACM, Vol. 42, No. 3, pp. 96-97, March 1999. 11. ObjectSpace Inc., ObjectSpace Voyager Core Package Technical Overview, Technical Report, July 1997. 12. Fonseca, S., An Agent-Based Electronic Commerce Marketplace, Ph. D. Thesis, University of California, 2000. 13. Roth, V., ""Content-based image indexing and retrieval with mobile agents"", Proceedings First International Symposium on Agent Systems and Applications, and Third International Symposium on Mobile Agents (ASA/MA '99), pp. 260-261, CA, USA, 1999. 14. Grey, D. J., P. Dunne and R. I. Ferguson, ""A Mobile Agent Architecture for Searching the WWW"", Proceedings Workshop on Agents in Industry, 4th International Conference of Autonomous Agents, Barcelona, June 3rd 2000. 15. Glitho R., E. Olougouna and S. Pierre, ""Mobile Agents and Their Use for Information Retrieval: A Brief Overview and an Elaborate Case Study"", IEEE Network Magazine, Vol. 16, No. 1, pp. 34-41, January/February 2002. 16. Karnouskos, S. and A. Vasilikos, ""Active Electronic E-mail"", Proceedings of the ACM 2002 Symposium on Applied Computing, Madrid-Spain, 2002. 17.Noy, P. and M. Schroeder, ""Mobile Agents for Distributed Processing"", Agents Workshop on Infrastructure for Multi-Agents Systems 2000, pp.263-265, 2000. 18. Johansen, D., ""Mobile Agent Applicability"", Proceedings of the Mobile Agents 1998, Springer- Verlag LNCS series, Stuttgart, 9-11 September, 1998.52 19. Farmer, W. M., J. D. Guttman and V. Swarp, ""Security for Mobile Agents: Issues and Requirements"", Proceedings of 4th European Symposium on Research in Computer Security, pp. 1 18-130, September 1996. 20. Smith, K. D. and R. B. Paranjape, ""Mobile Web Agents for Telemedicine"", 1st International Workshop on Mobile Agents for Telecommunication Applications, Ottawa-Canada, October 6-8, 1999, pp. 405-417, 1999. 21. Lange, D. B., M. Oshima, ""Mobile Agents with Java: The Aglet API"", World Wide Web Journal, Vol. 1, No. 3, pp. 1 1 1-121, 1998. 22. Lange, D. B., M. Oshima, Programming and Deploying Java Mobile Agents with Aglets, Addison- Wesley, Massachusetts, 1998. 23. Karjoth, G., D. Lange and M. Oshima, ""A Security Model For Aglets"", IEEE Internet Computing, Vol. 1, No. 4, pp. 68-77, July- August 1997. 24. Karnik, N., Security in Mobile Agents Systems, Ph.D. Thesis, University of Minnesota, 1998. 25. Gray, R., S. D. Kotz, G. Cybenko and D. Rus, ""D'Agents: Security in a Multiple- Language, Mobile Agent System"", Mobile Agents and Security, Lecture Notes in Computer Science, Springer- Verlag, 1998. 26. Koon, S., Protecting Mobile Agents Against Malicious Hosts, M. S. Thesis, The Chinese University of Hong Kong, 2000. 27. Sameh, A. and D. Fakhry, ""Security in Mobile Agent System"", Proceedings of the 2002 Symposium on Applications and Internet, Nara- Japan, Jaunary 28-01 February 2002, p.4, 2002.53 28. Park, J. Y., D. I. Lee, H. H. Lee and J. G. Park, ""One-Time Key Generation System for Agent Data Protection"", IEICE Transaction on Information and Systems, Vol. E85-D, No. 3, March 2002. 29. Stallings, W., Cryptography and Network Security, Prentice Hall, New Jersey, 1999. 30. ElGamal, T., ""A public key cryptosystem and a signature scheme based on discrete logarithms"", IEEE Transactions on Information Theory, 1985. 31. Diffie, W. and M. E. Hellman, ""New Directions in Cryptography"", IEEE Transactions on Information Theory, pp. 644-654, November 1976."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GEZGİN İNTERNET ARACISI TABANLI DAMGALAMA PROTOKOLÜ Bu yüksek lisans çalışması, gezgin İnternet aracısı tabanlı damgalama protokolü üzerinedir. Kopyalamayı caydırma uygulamalarında, içerik sahibi ağ üzerinden dağıtılacak olan her kopyanın içine ayrı ayrı damga koyar. Eğer izinsiz kopya bulunursa, kopyanın kaynağı içindeki damga sayesinde bulunur. Böylece alıcıların kendi kopyalarını izinsiz olarak çoğaltıp dağıtmaları engellenir. Geleneksel damgalama yöntemlerinde, içerik sahibinin her zaman dürüst olduğu kabul edilir. Fakat bu yaklaşım, alıcıyla, alıcının satın aldığı belirli kopyanın ilişkilendirilmesi ve piyasada bulunan her yasadışı kopyadan alıcının sorumlu tutulması problemine sebep olur. Damgalama yöntemlerinin etkinliği damga arama yöntemlerine bağlıdır. Düz bir yaklaşımla içerisinde damga aranacak olan tüm belgeler indirilir. Bu yaklaşım ağ trafiğinin ve yerel hesaplama yükünün artmasına sebep olur. Biz bu tezde, yukarıda bahsedilen problemleri gezgin İnternet aracısı sistemleri kullanarak çözmeye odaklandık. Sistemimizi diğer önerilen sistemlerle karşılaştırıp sonuçlan verdik.","IV ABSTRACT MOBILE AGENT-BASED WATERMARKING PROTOCOL This Master Thesis Project studies a watermarking protocol based on the mobile agent systems. Digital watermarks have been proposed for variety of purposes such as copy protection, copyright protection, copy deterrence, ownership verification, content authentication, broadcast monitoring. In copy deterrence applications, content owner embeds a distinct watermark in each copy of the data that is distributed over a network. If the unauthorized copy of the data is found, then the origin of it can be determined by recovering the watermark corresponds to each buyer. This discourages the buyers from duplicating and distributing the watermarked copy sold to him. In traditional watermarking schemes used in the copy deterrence applications, there is an assumption that the content owner is trustworthy. However, this approach causes the problem of binding together the buyer and the specific copy he bought and therefore holding him responsible for any illegal copies of the same watermarked copy found in the market. The effectiveness of the watermarking schemes relies on the watermark detection process. A straightforward approach is to download all digital documents to be detected. This causes a problem that increases the network traffic and enforces a heavy burden to local computation. In this thesis, we focused on solving these problems using mobile agent systems. We compared our protocol with other proposed protocols and gave results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DEĞİŞMEZ MANIFOLD YÖNTEMİ KULLANILARAK KAOS KONTROLÜ Bu tezin amacı, bazı kaotik sistemlerin kontrolünü, sistem dinamiğini bilmeksizin OGY Yöntemi ve Değişmez Manifold Yöntemi ile simüle etmektir. Sistem verilerinden yerel doğrusal modeli elde etmek için, iki farklı teknik kullanılmıştır: Geleneksel OGY yönteminde kullanılan en küçük kareler yöntemi ve eğitilmiş sinir ağından analitik modelin çıkarılması. Hedefin kararlı hale getirilmesi, incelenen kaotik sistemler üzerinde başarıyla gerçekleştirilmiştir.","IV ABSTRACT CHAOS CONTROL USING INVARIANT MANIFOLD METHOD The aim of the thesis is to simulate the control on several chaotic systems with the OGY Method and Invariant Manifold Method without a priori knowledge about the system dynamics. For obtaining the local linear model from system data, two different techniques have been employed: conventional least squares fitting as used in the conventional OGY Method and the extraction of analytic model from a trained neural network. Stabilization of the target has been achieved for the considered chaotic systems successfully."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET WEB SERVİS ORKESTRASYON STANDARTLARI Web servisleri internet standartlarını temel alan, farklı ortamlardaki uygulamaların ortak çalışmasını sağlamak üzere tasarlanmış olan yeni bir dağıtık yazılım mimarisidir. Günümüzde web servis teknolojilerinin gelişim süreci devam etmektedir. Temel standartlar ile ilgili çalışmalar tamamlanmış olmakla birlikte, karmaşık iş gereksinimlerini karşılayacak spesifik standartların hazırlığı henüz sonlanmamıştır. Bu tezin hazırlanmasındaki başlıca hedef, web servis teknolojilerinin rolünü, standartlarını ve eksikliklerini inceleyerek, web servislerin dağıtık yazılım çözümü olma potansiyelini ortaya koymaktır. Tez çalışması web servis teknolojileri ile ilgili kapsamlı inceleme sonuçları içermektedir. Özellikle ""Web Servis Orkestrasyon"" alanında sayısız standart yayınlandığından, çalışmanın büyük bir bölümü bu konuyla ilgili olarak hazırlanan BPEL4WS, WSCI ve BPML gibi dilleri araştırmak ve karşılaştırmalı sonuçlar üretmek için ayrılmıştır. Web servis teknolojilerine geçiş için genel bir plan mevcut olmadığından, örnek bir fınans web servisi hazırlanarak finans servisleri açısından Web servis uygulama geliştirme olanakları araştırılmıştır.","IV ABSTRACT WEB SERVICE ORCHESTRATION STANDARDS Web services are a standards-based, loosely coupled new distributed computing architecture designed and specified to foster cross-platform program-to-program communications. Currently the Web services landscape is in an evolving state with core specifications almost mature, whereas more specific standards for complex business requirements have not been finalized. The principal goal underlying this thesis is to highlight the potential of Web service solutions as an enabling distributed computing technology by studying the role, standards and deficiencies of Web service technologies. The thesis study includes a state-of-the-art study on Web services technology and its radical changes on application innovation and development. Due to competing vendor specifications in the field of ""Web Service Orchestration"", a major part of the study is devoted to taking different viewpoints on existing business process languages such as BPEL4WS, WSCI and BPML so as to produce an extensive comparative study. As a general scheme for Web service adoption does not exist, the work is concluded with a financial Web service use case to investigate the feasibility of the Web services paradigm for application development in the financial services industry."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TÜKETİCİ FİNANSMANI SEKTÖRÜNDE MÜŞTERİ ELDE ETME VE SADAKATİ MODELLEMESİ Gelişmiş kuruluşların bir çoğu yılllardan beri müşterilerinden çok miktarda veri toplamaktadırlar. Veri tabanlarında Bilgi Keşfi olarak da bilinen Veri Madenciği'nin amacı, iş yaşamında kuruluşun geleceğine yön verecek proaktif ve bilgiye dayalı kararlar alınmasını sağlamaktır. Bunu gerçekleştirmek için veri madenciliği araçları, sözkonusu büyük hacimdeki veri içerisinde var olan fakat önceden keşfedilmemiş ilginç/değerli örüntüler, ilişkiler ve/veya modeller ortaya çıkarmaktadırlar. Bu tezin amacı, veri madenciliği araçları ve teknikleri kullanarak, türk tüketici finansmanı sektöründe müşteri değerinin ölçümlenmesi ve arttırılmasına, ve müşteri ilişkileri yönetimine yönelik bilgi tabanlı bir sistem geliştirilmesidir. Yöneticiler ve pazarlamacılar gibi karar vericilerin faydalanabilmesi için, ham veri içindeki mevcut kayıtların yararlı bilgilere dönüştürülecektir. Müşterilerin daha iyi anlaşılmasıyla, değerli müşterilere odaklanılmasıyla ve olumlu cevap verebilecek müşterilere pazarlama kampanyalarının düzenlenmesiyle, firma, yüksek yatırım geri dönüşünün yanında müşterileri ile daha iyi ve tutarlı ilişkiler kuracaktır. Kullanılacak yöntemler; segmentasyon, karar ağaçlan, regresyon, ilişkilendirme ve istatiksel analize dayalı veri madenciliği teknikleridir. Uygulanan metodoloji ve veri madenciliği uygulaması arkasında çalışan algoritmalar ayrıntılı olarak sunulmuştur. Firma için gerçekleştirilen müşteri segmentasyonu ve profillerin çıkarılması, sınıflandırma ve alış-veriş bağıntı kurallarının çıkartılması tezin üçüncü bölümünde yer almaktadır.","IV ABSTRACT CUSTOMER ACQUISITION AND RETENTION MODELING IN CONSUMER FINANCE SECTOR Most of the established companies have accumulated masses of data from their customers for decades. The goal of Data Mining, also known as Knowledge Discovery in Databases (KDD), is to find interesting patterns and/or models that exist in databases but are hidden among the volumes of data, allowing business to make proactive, knowledge- driven decisions. The aim of this study is to propose a new data-driven approach to evaluate and improve customer value, and relationship management at the consumer finance sector in Turkey using data mining tools and techniques. The customer records will be transformed into valuable information from which the decision-makers, such as marketers and administration, can benefit. By better understanding the customers, by focusing on ""valuable"" customers and design marketing campaigns to people who are likely to respond, the company will not only achieve superior returns on its resource investment, but it will build better relationships with its customers. Data mining techniques employing algorithms based on decision trees, logistic regression, association rules and basic statistical analyses are performed in this study for a consumer finance company. The methodology and all the algorithms that are employed are illustrated in detail. The core of this study is portrayed in Chapter 3. It contains the key issues in modeling efforts how data mining techniques are applied. More specifically, it includes the modeling and analysis related to customer segmentation and profiling, classification and association mining for the company under study."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DİNAMİK ZAMAN EGILTIMI TABANLI ARİTMİ SINIFLANDIRMA SİSTEMİ DİZAYN VE UYGULAMASI Bu tezde aritmi analizi için kullanılacak bir sistem gerçeklenmiştir. Bu amaçla bir görselleştirme ve test arabirimi hazırlanmıştır. Ayrıca dinamik zaman eğiltimi (DTW) temelli bir analiz algoritması önerilerek bu sistem üzerinde gerçeklenmiştir. Önerilen algoritmanın amacı, elektrokardiografik işaretlerin aritmi analizinde kullanılacak, hızlı ve sağlam bir sınıflama yöntemi bulmaktır. Hastaların EKG işaretleri zaman içerisinde değişiklikler göstermektedir. Bir çok aritmi analiz sisteminde, bu değişiklikleri tespit etmek amacıyla, referans şablonlar dinamik olarak oluşturulmak zorunda kalınmıştır. DTW yönteminin kullanılması halinde ise bu zorunluluk ortadan kalkmıştır. Dolayısı ile programların karmaşıklığı azalmıştır. Sonuç olarak, hastadan bağımsız olarak çalışabilecek kullanışlı bir analiz sistemi mümkün kılınmıştır.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF A DYNAMIC TIME WARPING BASED ARRHYTHMIA CLASSIFICATION SYSTEM In this thesis we have developed and implemented an arrhythmia analysis system. For this purpose we have developed a visualization and test interface. And we have proposed an algorithm based on dynamic time warping (DTW) and programmed this algorithm in the system. The aim of the algorithm is to provide fast and robust arrhythmia classification of electrocardiagraphic (ECG) signal. Morphologic characteristics of a patient can vary greatly from time to time. In order to increase the robustness, many arrhythmia analysis systems try to define new templates dynamically. Since such variances can be handled automatically in DTW algorithms, dynamic template handling is not a necessity anymore. As a result, using this method, patient independent and simple analysis systems can be made possible."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TÜRKÇE MORFOLOJİK ÇÖZÜMLEME, YAPAY SINIR AĞLARI VE BAYES FİLTRELEME TABANLI UYARLAMALI SPAM-ÖNLER FİLTRELEMESİ Bu çalışmada, Yapay Sinir Ağları ve Bayes Filtresi uygulamalarını temel alarak Türkçe spam mesajlarını filtreleyen bir algoritma ortaya koyuyoruz. Sonuçta, Microsoft Outlook ile bağlantılı çalışabilen bir spam-önler filtresi ortaya çıktığı için, ürün son kul lanıcıya yöneliktir ve bundan dolayı kullanıcıya özeldir; program kullanıcının spam ve normal mesajlarını öğrenerek kendini her kullanıcı için uyumlu hale getirir. Algorit mamızın iki temel kısmı var: birinci kısım Türkçe kelimelerin morfolojisini incelerken ikinci kısım morfolojik incelemeden gelen kelime köklerini kullanarak spam mesajları filtreler. Öğrenme algoritmalarının girdi vektörleri iki şekilde belirlenir: ikili model ve olasılık modeli. Bu çalışmada, Yapay Sinir Ağlarının iki yapısı kullanılmıştır: tek katmanlı ve çok katmanlı algılayıcı birimleri. Bayes Filtresi de üç değişik yaklaşımla gerçekleştirilmiştir: ikili model, olasılık modeli ve ileri olasılık modeli. Bu çalışma için 750 (410 spam, 340 normal) mesaj kullanılmıştır. Filtrelemede yüzde 90'dan yüksek başarı oranı elde edilmiştir.","IV ABSTRACT ADAPTIVE ANTI-SPAM FILTERING BASED ON TURKISH MORPHOLOGICAL ANALYSIS, ARTIFICIAL NEURAL NETWORKS AND BAYES FILTERING We propose an anti-spam filtering algorithm that is used for Turkish language based on Artificial Neural Networks and Bayes Filter. The final product is an anti-spam filtering program which works compatible with Microsoft Outlook so it is user-specific, thus adapts itself with the characteristics of incoming e-mails. The algorithm has two parts: the first part deals with morphology of Turkish words. The second part classifies the e-mails by using the roots of words extracted by the morphology part. The input vectors to the learning algorithms are chosen with two models: binary model and probabilistic model. Two structures of ANN are employed in this study: single layer perceptron and multi layer perceptron. Bayes Filter is also implemented with three different approaches: binary Model, Probabilistic Model, Advance Probabilistic Model. Spam detection performance of the proposed system is improved by including non-Turkish words. A total of 750 mails (410 spam and 340 normal) are used in the experiments. A success rate over 90 per cent is achieved."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET gezgin tasarsiz ağlarda hizmetlere erişim için çapraz katmanlı bir ağ protokolü Gezgin tasarsiz ağlar, önceden planlanmış bir telsiz ağ altyapısının kapsama alanında olmaya gerek bırakmaksızın, telsiz iletişim yapma yeteneği olan hareketli bil gisayarların birbirleri ile geçici süreli bilgi değişimi yapmalarına olanak verir. Bu ağ yapısının kırılgan ortamı, basit ve uygulamalardan haberdar iletişim yaklaşımlarının, karmaşık ve genel amaçlı protokol yığınlarına tercih edilmesini gerektirmektedir. Bu yaklaşımlar, uygulamaların sundukları hizmetleri duyurmalarına, ağ üzerindeki diğer hizmetleri keşvetmelerine, bağlanmalarına ve kullanmalarına olanak sağlamalıdır. Bu tezde etkileşimsiz isimli hizmetlere devingen erişim ile ilgilenilmiş, hizmet keşfi ve yönlendirme sağlamayı amaçlayan basit bir çapraz katmanlı protokol tasarlanmıştır. Önerilen protokoldeki algoritmalar, doğrulama ve başarım ölçümü amacıyla GloMoSim telsiz ağ benzetim yazılımına eklenerek gerçeklenmiştir. Gerçeklenen bu benzetim yazılımı kullanılarak, temsili uygulamalar ve bu uygulamalardan türetilmiş senaryolar oluşturulmuştur. Yapılan bu deneylerden edinilen sonuçlar, etkileşimsiz isimli hizmet lere devingen erişim için hizmetlerden haberdar bir basit protokol yığını kullanımının mümkün olduğunu göstermiştir. Ayrıca ağ katmanı seviyesinde, hizmetlerden haberdar olmanın getirileri vurgulanmıştır. Tezin içeriğinde gerekli hazırlık bilgileri, önerilen iletişim altyapısı, tasarlanan düzenekler, benzetim yazılımı ayrıntıları, deneyler ve sonuçlar bulunmaktadır.","IV ABSTRACT A CROSS LAYER PROTOCOL FOR SERVICE ACCESS IN MOBILE AD HOC NETWORKS Mobile Ad Hoc Networks (MANET) are composed of moving wireless commu nication capable computers usually deployed for the purpose of temporal information exchange in cases where coverage of infrastructured networks is not available. Consid ering the fragile environment of MANET, simple and application aware communication approaches must be preferred in favor of complex and general purpose cascaded stack of protocols. These approaches must serve the applications need for access to ser vices available on other hosts, addressing the announcement, discovery, binding and utilization of those services. In this thesis, dynamic access to named non-interactive services in ad hoc net works is studied and a simple cross layer protocol is designed for service discovery and routing. The algorithms of the proposed protocol are implemented in a wireless network simulation software, GloMoSim, for the purpose of algorithm verification and performance evaluation. Some representative applications and scenarios designed out of these applications using the simulation software extensions for the new protocol are also implemented. The results from these experiments have shown that a service aware slim protocol stack implementation is possible for non-interactive service access in mo bile ad hoc networks. The advantages of having service awareness in the network layer are also emphasized. Content of the thesis includes the necessary motivation and background for MANET, proposed communication infrastructure, designed mechanisms, simulation implementation details, experiment and results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET 3G VE 802.11 AĞLARINDA AAA TEMELLİ SAYDAM KİMLİK TANIMA SİSTEMİ Üçüncü Nesil gezgin telekomünikasyon sistemleri, çoklu ortam hizmetlerine, gezgin iletişim ve İnternet alanlarında kaydedilen ilerlemelerin aktarılmasını olanaklı kılar. Öte yandan, kablosuz yerel alan ağlan kolaylıkla uygulanabilir, kurulum masrafları düşüktür ve diğer kablosuz teknolojiler ile karşılaştırıldığında daha yüksek hızda hizmet verirler. İnternette erişim bağımsızlığı elde edilebilmesi ve kablolu ile kablosuz uçbirimler arasmda ara işlemlerin sorunsuz gerçekleştirilebilmesi bakımından güvenlik konusu büyük önem taşır. Ara işlemlerin gerçekleştirilmesinde izlenebilecek bir yaklaşım, 802.11 WLAN ve 3G ağları arasında ara işlemlerin güvenli yapılabilmesini sağlamak olabilir. Her iki sistem, kendi etki alanlarında kendilerine özgü kimlik denetim mekanizmalarına sahip olmalarına karşın, iki etki alam arasında saydam kimlik denetimini mümkün kılan tek bir mekanizmadan söz edilemez. Bu tez çalışmasında, 3G ve 802.11 ağları arasmda AAA tabanlı bir kimlik denetim sistemi oluşturulmuştur. Bu çalışmada önerilen kimlik denetim mekanizması, 3G ve 802.11 ağlan arasmda, sözkonusu iki tekonolojide mevcut olan denetim mekanizmalarım kullanmak suretiyle saydam kimlik denetimini gerçekleştirmenin yam sıra 3G ve 802.11 ağlan arasında oturum anahtan ve kriptolama algoritmasının dağıtılması için de bir yöntem sunmaktadır","IV ABSTRACT AAA BASED SOLUTION FOR THE AUTHENTICATION INTEROPERABILITY OF 3G AND 802.11 NETWORKS Third Generation mobile telecommunications systems enable multimedia services combining the growth in mobile communications with the growth of the Internet. On the other hand, Wireless Local Area Networks (WLAN) are easy to implement, cheaper to construct and provides high speed services compared with other wireless technologies. In order to achieve access independence and to maintain a smooth interoperation with wireline and wireless terminals across the Internet, security is an important issue that must be handled. One step to achieve interoperability is to provide secure interoperability between the 802.1 1 WLAN and 3G networks. Although both systems have authentication mechanisms in their own domain, there is not a single mechanism that provides seamless authentication between two domains. In this thesis, an Authentication-Authorization- Accounting (AAA) based authentication mechanism is presented between 3G networks and 802.1 1 networks. The proposed solution for the authentication interoperability problem between 3G and 802.11 networks provides seamless authentication between two domains using the existing authentication mechanisms in each domain and provides a way for distributing session key and encryption algorithm between 3G and 802.1 1 networks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET SOZCUK ANLAMLARI İÇİN GELİŞTİRİLMİŞ GÖSTERİMLER KULLANAN BİR TÜRKÇE DİYALOG ETMENİ Yapay zekanın bir araştırma dalı olan Doğal Dil İşleme'nin (DDİ) amacı bilgisayarların insanlar gibi doğal dilleri kullanabilmesini ve öğrenmesini sağlamaktır. Bu tezde anlatılan çalışma, sözcük anlamları için geliştirilmiş gösterimler kullanan bir Türkçe diyalog etmeninin kurulması ve uygunlanmasıdır. Diyalog etmeni Boğaziçi Üniversitesi 'nde geliştirilmiş TOY doğal dil işleme altyapısının üzerine inşa edilmiştir. Temelde iki ana işlem yapabilir: Cümleden bilgi edinme ve diyalog işleme. Cümlenin işlenmesi biçimbilimsel, sözdizimsel ve anlambilimsel aşamalardan geçerek gerçekleştirilir. Cümle biçimbilimsel ve sözdizimsel çözümlemeden geçtikten sonra anlamsal gösterimi elde edilir. Bu gösterimden çıkartılan bilgi bilgi tabanında tutulur. Kullanıcı evet/hayır soruları yardımıyla bilgi tabanındaki bu bilgileri sorgulayabilir. Diyalog etmeni girilen cümlede yer alan ve bilmediği kelime ya da kelimeleri öğrenebilme yeteneğine sahiptir. Etmen kelimenin biçimbilimsel özelliklerinin yanısıra kelimenin ne anlama geldiğini bilgi tabanındaki kavramlar bağlamında kullanıcıdan öğrenir ve bu bilgiyi işlemleri sırasında kullanır. Diyalog etmeni kendinden önceki etmenlerden farklı olarak insanlarda olduğu gibi dış dünya hakkında genel bir bilgi dağarcığına sahiptir Bu dağarcık anlambilimsel bir ağ ile etmene eklenmiş olup yeni eklemelere ve değişikliklere açık bir yapıdadır. Bu anlambilimsel ağ gönderim çözümünde ve yükümlülük kipi içeren soruların cevaplanmasında kullanılmıştır.","IV ABSTRACT IMPROVED TREATMENT OF WORD MEANING IN A TURKISH CONVERSATIONAL AGENT Natural Language Processing (NLP) is a research area of artificial intelligence whose aim is to make computers use natural languages like human beings. The work reported in this thesis is the design and implementation of a Turkish conversational agent whose treatment of word meaning is strengthened and improved with respect to other agents. Our conversational agent is based on the TOY NLP infrastructure developed in Boğaziçi University. The agent can perform two basic operations: acquiring knowledge from a sentence or answering user queries. The processing of a sentence goes through the morphological, syntactic and semantic levels. If a sentence is morphologically and syntactically checked, its internal semantic representation is derived. If the agent acquires knowledge from this representation, it is stored in its knowledge base. The user can query the agent's knowledge base by asking yes/no questions. The conversational agent has the capability of learning words that it does not recognize in the input sentence. Beside the word's morphological features, the agent learns what this word means in the context of other concepts in its knowledge base from the user and uses this information in the operations. The conversational agent has some commonsense knowledge about the external world similar to human beings, unlike its predecessors. This knowledge is represented with a semantic network whose design is open to additions and modifications. This network is used for anaphora resolution and improved handling of questions requiring treatment of deontic modalities."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TAVLAMA BENZETİMİ YÖNTEMİ VARYANTLARIYLA OLUŞTURULMUŞ KARAR AĞAÇLARININ PROSTAT KANSER TANISINA UYGULANMASI Gelişmiş birçok ülkede erkeklerde en çok görülen kanserlerden birisi prostat kanseridir. Bizim asıl hedefimiz, Benzetimli Tavlama yöntemi kullanarak, hiç bir kanser hastasını kaçırmazken, kanser olmayan hastaların gereksiz yere biyopsiye gitmesini en gelleyecek karar ağaçlan oluşturmaktır, ikinci hedefimiz ise kanser olmayan hastalara doğru tanı koymaktır (BPH ya da Kronik Prostatis şeklinde). Biyopsi, enfeksyona ne den olan, rahatsız edici ve pahalı bir işlemdir. Veriler 119 erkek hasta kullanılarak oluşturulmuştur. Bu hastalar 50 yaş ve üstü, PSA değerleri 4 ng / mi ila 20 ng / mi arasında olan ve normal parmakla kontrol sonuçlarına sahip olanlardır. Bu araştırma, Selmin Danış'm yüksek lisans tezinin bir sonraki aşamasıdır. Karar ağaçlarından birini C4.5 algoritmasının Java üzerinde yazılmış J48 uygulaması ile oluşturduk. Diğer karar ağaçlarını Benzetimli Tavlama ynteminin 2 varyasyonunu kullanarak, Hiç Red dedilen Adimi Olmayan Tavlama Benzetimi ve Genelleştirilmiş Tavlama Benzetimi, uygulayarak oluşturduk. Bu üç ağaçta, C4.5 uygulamasının karar ağacı oluştururken işe yaramayan değişkenleri kullanmadığı bilinerek ve aynı değişkenlerle başlayarak oluşturulmuştur. Bütün ağaçlar aynı çalışma kümesi ve bu küme ile kesişmeyen test kümesi ile oluşturulmuştur. Öğrenme kümesi toplam kümenin rastgele seçilmiş %70'idir. ikinci ve üçüncü ağaçların yapılandırılmasında raslantısallık olduğu için, öğrenme kümesi üzerinde çalışılarak, herbir algoritma için oluşturulan beşer ağaçtan en iyileri seçilmiştir. Seçilen ağaçlar daha sonra test kümesi üzerinde uygulanmıştır. Öğrenme sonucunda oluşturulan ağaçlar birbirleri ile karşılaştırılmıştır. Gerçek pozitiflik oranı, yanlış pozi tiflik oranı ve başarı oranı herbir ağaç için belirtilmiştir. Bundan başka, her oran için %90 düzeyinde güvenilirlik aralıkları sunulmuştur. ;","IV ABSTRACT AN APPLICATION OF DECISION TREES CONSTRUCTED WITH SIMULATED ANNEALING VARIANTS TO PROSTATE CANCER DETECTION In most industrialized countries, prostate cancer (PCA) is the most common malignancy among men. Our major goal is to design a decision tree using Simulated Annealing, with which we will not to miss any of the PCA patients, while reducing the number of patients without PCA to have unnecessary biopsies. Our secondary goal is to determine the correct diagnosis for non-cancer patients who have either BPH or Chronic Prostatis. Data from 119 male patients were used. Their ages were 50 or over, Prostate Specific Antigen values were in the region between 4 ng/ml and 20 ng/ml, and they had normal Digital Rectal Examination results. This research is the next step after Selmin Danis's M.S. thesis. We construct a decision tree based on a Java implementation of the C4.5 algorithm called J48. We then constructed two more decision trees, this time using two different variants of the Simulated Annealing algorithm, namely ""SA Without Rejected Moves"" and ""Generalized SA"". All three trees had the same attributes to work on, although that did not mean all three would eventually use the same set of attributes since C4.5 allows the decision tree not to use a given attribute if it does not help the decision making. All three trees used the same training group and the same disjoint testing group. The training group has randomly selected 70% of the patients. Since there is randomness involved in the second and third trees, only the best performing one out of the five trees were chosen at the end of the training stage for both SA implementations. Then, these two trees were tested using the testing data. Finally, we compared the testing results of these three decision trees. We provide the true positive rate, false positive rate and the success rate for all three trees. Moreover, we give confidence intervals for these rates at the level of 90% confidence."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET STATİK GÖREV ZAMANLAMA ALGORİTMALARININ KARŞILAŞTIRMALI OLARAK İRDELENMESİ Bu çalışmada, günümüze kadar yapılmış olan görev zamanlama algoritmalarının karşılaştırması yapılmakta ve varolan bu algoritmalardan bazılarını ağırlıklı olarak kullanan yeni bir algoritma önerilmektedir. Paralel programların belli bir grup işlemci üzerine dağıtılmasına yönelik çalışmalar uzun süredir yapılmaktadır. Görev zamanlama probleminin NP-tam olduğu bilinmektedir. Dolayısıyla problemin çözümüne yönelik çeşitli bilimsel yayınlarda buluşsal algoritmalar önerilmiştir. Bu çalışmalarda, ağırlıklı olarak algoritmaların bireysel olarak ne kadar iyi oldukları gösterilmeye çalışılmıştır. Günümüze kadar görev zamanlama algoritmaları karşılaştırmalı olarak sunan çok fazla çalışma yapılmamıştır. Bu çalışmada, 12 görev zamanlama algoritması ortak bir zeminde uygulanıp, karşılaştınlmaktadır. Görev zamanlama algoritmaları karşılaştırılırken, oluşturdukları çizelge süreleri belirleyici kriter olarak kullanılmaktadır. Görev zamanlama buluşsal algoritmaları oluşturdukları çizelge süresinin kısalığına veya optimum çizelge süresini bulmalarına bağlı olarak değerlendirilmektedir. Varolan algoritmalar üzerinde değişiklikler yaparak ve farklı yapıda test çizge kümelerini girdi olarak kullanarak, yapılan değişikliklerin etkileri belirlenmektedir. Bu şekilde hangi buluşsal algoritmaların en etkili olduğu belirlenmektedir. Bu özellikler doğrultusunda, varolan algoritmalardan bazılarım kullanan yeni bir görev zamanlama algoritması önerilmektedir. Varolan ve yeni geliştirilen görev zamanlama algoritmalarının oluşturdukları çizelge süreleri karşılaştırmalı olarak sunulmaktadır.","IV ABSTRACT A COMPARATIVE STUDY OF STATIC TASK SCHEDULING ALGORITHMS In this thesis a comparative study of existing task scheduling algorithms is made and a new algorithm is proposed which is a weighted combination of some existing task scheduling algorithms. The problem of scheduling parallel programs on a set of processors has been studied for a long time. It is known that task scheduling problem is NP-complete. Therefore, heuristic algorithms have been presented in different research work. In those research works, the presented task scheduling algorithms were individually reported to be efficient. The relative effectiveness of those algorithms is not widely emphasized. In this thesis, 12 different algorithms have been implemented and their scheduling results are presented and compared. While comparing the task scheduling algorithms, schedule lengths they have generated are used as the main comparison criteria. Making modifications on existing task scheduling algorithms and applying a group of task sets as an input to these task scheduling algorithms, we can test for the effect of these modifications. In this manner, a new algorithm that is a weighted combination of some existing task scheduling algorithms is generated. The schedule lengths generated by the existing and newly developed task scheduling algorithms are presented and compared."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET WISPOT İSTEMCİSİNİN TASARIMI VE UYGULAMASI Hareketli istemcilere veri yayımı problemi, kaynakçada geniş olarak çalışılan bir konudur. Hareketli uçbirimler, kablosuz haberleşme donanımına sahip el bilgisayarları veya dizüstü bilgisayarlar gibi pille çalışan, düşük maliyetli ve taşınabilir bilgisayarlardır. İstemcilerin sınırlı güç kapasiteleri, kablosuz ortama uygun çalışan güvenilirlik ve güvenlik mekanizmalarmın kullamlması ve veri yayımı sistemlerinin asimetrik doğası, kablosuz veri yayımı mimarisinde göz önünde bulundurulması gereken en önemli noktalardır. Bu çalışmada, WISPOT olarak adlandırdığımız, sınırlı kapsama alanında kayıtlı hareketli istemcilere popüler veri servisleri veren, bir istemci-sunucu bilgi dağıtım sistemi tasarladık. Böyle bir servisi sağlayabilmek için, itine ve çekme tabanlı mekanizmaların kullanıldığı ölçeklenebilir bir veri dağıtımı mekanizması tasarlanmıştır. Sistemde herhangi bir servis almadan önce kullanıcılara uygulanması gereken bir kullanıcı doğrulama mekanizması kullanılmıştır. Sunucuya istemcilerin taleplerini bildirmek ve böylece sunucu tararında kullanıcı profillerini oluşturmak için bir yayınlama/abonelik mekanizması uygulanmıştır. Kullanıcılar herhangi bir güncelleme olduğunda kullanıcı profilleri yardımıyla bir sunucunun kapsama alanından geçerken hiçbir kullanıcı etkileşimi olmaksızın bilgi servislerini kaydedebilirler. WISPOT tasarımında güvenli doğrulama, istek ve veri alımı mekanizmaları sağlayabilmek için, güvenlik mekanizmaları tamtılmıştrr. İstemcinin kapsama alanında kalma süresi tamamlanamayan veri aktarımına yol açacak kadar az olabilir. Bu gibi aktarımların tamamlanması işiyle sistem baza hata düzeltme mekanizmalarının kullanarak ilgilenmektedir. Bütün sistem tasarımı istemcilerin sınırlı gücü göz önünde bulundurularak yapılmışlar. Bunun yam sıra WISPOT istemcisinin bir prototipi hazırlanmış ve işlevselliği test edilmiştir. Prototip üzerinde çeşitli başaran değerlendirme deneyleri yapılmıştır.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF WISPOT CLIENT The problem of data dissemination to mobile clients is a broadly studied subject in literature. The mobile terminals have emerged as battery-operated, low-cost and portable computers such as handheld computers or laptop computers equipped with wireless communication peripherals. The major issues that have to be considered in wireless data dissemination architectures are the limited power capacity of the clients, employment reliability and security mechanisms suitable for wireless medium and the asymmetric nature of data dissemination systems. In this work, we designed an information delivery, client-server system, namely WISPOT, which gives popular data services in a limited coverage area to registered mobile clients. To provide such a service, a scalable data delivery mechanism is designed which employs both pull and push based mechanisms. A user authentication mechanism is employed in the system, which has to be performed prior to reception of any services. A publish/subscribe mechanism is implemented to inform the server about the requests of the clients and hence to form the user profiles of the clients on server side. Users receive information services in case of any updates with no human interaction with the help of their user profiles as they pass through the wireless coverage area of a server. To achieve secure authentication, request and data reception mechanisms security mechanisms are introduced in WISPOT design. The residence time of a client in the coverage area may be very short which may lead to an incomplete data transfer. The completion of such transfers is dealt by the system using some error correction mechanisms. The overall system design is constructed considering the limited power of the clients. In addition, a prototype of the WISPOT client is implemented and tested for its functionality. Several performance evaluation experiments are performed on the prototype."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"""Standart Saat"" yöntemi, bir modelin farklı parametreli değişkelerinin benzetiminin gerçekleştirilmesinde kullanılır. Bu tezde ilk olarak, yöntemin çoktürel UNIX ağı ortamı üzerinde gerçekleştirilmesiyle ""Standart Saat"" tabanlı dağıtık benzetim aracı geliştirilmiştir. Bu çalışmanın amacı, dağıtık benzetim uygulamasının ölçeklenebilirliğini ve yük dengelemesinin etkisini araştırmaktır. İki farklı sezgisel yük dengeleme tekniği önerilmiştir: (1) her değişkenin maliyet tahminine dayalı statik yük dengelemesi ile (2) benzetim sürecinde başarılarına dayalı olarak değişkeleri iş istasyonları arasında geçiren dinamik yük dengelemesi. Başarım kuyruk ağı örnekleri kullanılarak incelenmiştir. Yedi makineye kadar yapılan gerçek zamanlı deneylerden elde edilen sayısal sonuçlarla hızlanma ile gerçekleştirilme ve yük dengeleme verimliliği incelenmiştir. İş istasyonu sayısı arttıkça doğrusala yakın hızlanma elde edilmiştir. Ayrıca yük dengelenmesi ile rassal dağıtıma göre yüzde 8 'e kadar değişen iyileştirme sağlanmıştır. Çalışmanın ikinci aşamasında, benzetim aracına örün tabanlı bir grafik ara birimi eklenerek kolay kullanımlı ve pratik bir deney yürütme platformu oluşturulmuştur. Böylece, tüm sistem güçlü bir sunucu üzerinde çalışan benzetim aracı ile bu araçla iletişim kuran örün tabanlı bir arayüzden oluşmaktadır. Kullanıcı arayüzü kuyruk ağları için model geliştirme, istenilen deneyleri benzetim aracım kullanarak gerçekleme ve basit çıktı analizi yapmayı platform bağımsız olarak gerçekleştirmeyi sağlar. Son aşamada geliştirilen benzetim ortamına deneysel tasarım yöntemi ve yanıt yüzeyi yöntemi eklenerek örün tabanlı bir benzetim eniyileme aracı prototipi oluşturulmuştur. Bu araç, daha az ancak etkili deneylerin seçilerek yapılmasını ve kısa sürede en iyi sonuçlarının bulunduğu alana ulaşılmasını sağlamıştır. Bu benzetim eniyileme yaklaşımın uygulanabilirliği ve sistemin özellikleri iki düğümlü bir Jackson ağı ve bir imalat sistemi örnekleri üzerinde gösterilmiştir.","Standard Clock approach is used to simulate a number of parametric variants of a single system. In this thesis, a simulation engine based on the distributed implementation of the Standard Clock approach on networks of heterogeneous UNIX workstations is developed. The objective is to examine the scalability of the implementation and study the effect of load balancing. Two different heuristic load balancing techniques are proposed: (1) a static load balancing that is based on estimated cost of each variant and (2) a dynamic load balancing that migrates variants between workstations, based on their estimated performance during the simulation process. Simple queueing models are used to study the performance. Numerical results obtained from real-time simulations on a network of up to 7 workstations are used to investigate the speedup and the efficiency of both the implementation and the load balancing techniques. As more workstations are added to the simulation environment, a sublinear speedup is obtained. In addition, the load balanced distribution has produced an improvement up to 8 per cent compared to random distribution. Secondly, a web based user interface is integrated to this engine to provide an easy to use and practical experimentation platform. The complete system mainly consists of a web based graphical user interface that communicates with a powerful server that runs the engine. The user interface allows creating simulation models of queueing network, performing simulation experiments using the simulation engine, and performing simple output analysis in a platform independent manner. Finally, a prototype for a web based simulation optimization tool is developed by extending the system with the power of experimental design methodology and response surface method. Hence, this tool provides a way of planning which variants to simulate in order to quickly reach the neighbor of the optimal solution. The applicability of this simulation optimization approach and the features of the interface are illustrated using a two-node Jackson network and a manufacturing system as examples."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V ÖZET EGIM UZAYINA İZDÜŞÜMLE GERÇEKÇİ RESİM SENTEZLEME Gerçekçi resim sentezleme, bilgisayar grafiğindeki temel problemlerden biri olagel miştir. Gerçekçi ışık simülasyonları yapmamıza yardımcı olan global ışıklandırma al goritmalarının bu amaca ulaşmaktaki yeri önemlidir. ""Bu tezde, global ışıklandırmanın hesaplanması için izdüşüm bazlı bir yöntem öneriyoruz, izdüşüm metodumuz olan eğim uzayına izdüşüm yöntemi, sahneyi oluşturan bütün üçgenlerin ışıklandırmayı hesapla mak istediğimiz noktada merkezlendirilmiş bir yarıküreye tepesinden teğet düzleme izdüşümlerini alıp örnekliyor. Öncelikle izdüşüm yöntemini detaylı anlatıyor sonra bu yöntemle kullanılmak üzere dört örnekleme yöntemi öneriyoruz. İlk örnekleme yönte mimiz olan geodezik kubbe yöntemi, bir geodezik kubbenin noktalarının izdüşümlerini örnekleme noktaları olarak kullanıyor. Kullandığımız özel geodezik kubbe, izdüşümü alındığında düzenli bir dizilim oluşturuyor, böylelikle izdüşümler verimli örneklenebili yor, ikinci metodumuz olan alternatif örnekleme metodu bir ızgaranın kesişim noktala rını kullanıyor. Rastgele örnekleme bir diğer metodumuz ve son metodumuz olan aralık sınırlı rastgele örnekleme, rastgele nokta seçiminde asgari mesafe kuralı uyguluyor. Örnekleme yöntemlerinin performanslarını ve kalitelerini karşılaştırmak için yaptı ğımız resim sentezleme deneylerimize göre; performans ve kalite beraber düşünül düğünde, geodezik kubbe örnekleme yönteminin sonuçları diğerlerinden üstün. Eğim uzayına izdüşüm yöntemi global ışıklandırma problemine genel bir çözüm sunuyor. Daha önceki yöntemlerle aynı prensiplere dayandığı için onlarda kullanılan hızlandırma ve geliştirme yöntemleri de uygulanabilmekte. Yöntemin karmaşıklığının doğrusal olmasına karşın, temel işlemi hızlı bir işlem olan basit perspektif izdüşüm.","IV ABSTRACT PHOTO-REALISTIC RENDERING USING GRADIENT SPACE PROJECTION Photo-realistic rendering has always been a challenge in computer graphics. Global illumination algorithms, which helps us in making realistic lighting simulations, have a key role to achieve this goal. In this thesis we present a projection-based method for calculating global illumination. The projection method is Gradient Space Projection (GSP), which projects each polygon in the scene on a plane tangent to the hemisphere centered on the point of interest. We first discuss GSP in detail, then propose four sampling methods for using this projection. The first sampling method is geodesic dome sampling, which uses the nodes of a projected geodesic dome as the sampling points. We use a special kind of geodesic dome that forms a regular pattern when projected onto the gradient space, so that the projections are efficiently sampled. The second method is alternative sampling method, which uses the intersection points of a grid as the sampling points. The other method is random sampling and the last sampling method is distance constrained random sampling, which applies a minimum distance rule to the random sampling point generation. We present the test renderings for comparing both the performance and the qual ity of the sampling methods. Our results show that the geodesic dome sampling is superior when both performance and quality are considered. The GSP method is a general solution to the global illumination problem. It is based on the same principles as the previous methods, so their acceleration and enhancement methods are also applicable to GSP. Even though the complexity of GSP is linear, its basic operation is a simple perspective projection which is fast."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET D AGITTK ARAMA MİMARİSİ Internet hızlı bir şekilde büyüyor ve bilgi arayan kullanıcıların bir ağ arama motoru kullanması zorunluluk haline geldi. En yaygın kullanımı olan Google arama motoru üç milyardan fazla sayfa kapsadığım iddia ediyor. Ağ büyüdükçe, büyük hesaplama ihtiyaçları, sayfa dizMerinin güncellenmesinde gecikmeler ve ağ gezicileri için bant genişliği ihtiyaçları ile karşılaşıyoruz. Bu tezde, arama motorları için dağıtık arama mimarisi (DSA) ile yeni bir bilgi getirme yöntemi sunuyoruz. Merkezi örümcek veya ajan mimarisi yerine dizinleme modüllerimiz yerel ağ sunucuları üzerinde çalışıyorlar, ağ sayfalarını çekiyor, dokümanlarla ilişkili anahtar sözcükleri ağ sunucusu tarafında parçalayıp puanlıyor ve o sitenin sayfalarının özet bilgilerini oluşturuyorlar. Daha sonra, özel bir modüller arası protokol ile bu özet bilgiyi sunucu modüllerine gönderiyorlar. Dağıtık yaklaşımımızm indirgenmiş bant genişliği kullanımı, ölçeklenebilirlik ve daha hızlı sayfa dizini güncellemeleri konularında bir takım avantajlar getireceğine inanıyoruz.","IV ABSTRACT DISTRIBUTED SEARCH ARCHITECTURE The Internet is growing quite rapidly and using a web search engine has become a must for users seeking information. The most widely used search engine Google claims that they have a coverage of more than three billion pages. As the web size grows, huge computational requirements, latencies for updates of page indexes and bandwidth needs for crawlers are introduced. In this thesis, we represent a new way of information retrieval for search engines by the use of distributed search architecture (DSA). Instead of using centralized spider or agent architecture, our indexer modules work on the local web servers where they traverse the web pages, parse and score the keywords related to these documents and build up the meta data for the pages of that web site. Later, with a specified module to module protocol they send meta data to the DSA server modules. We believe that our distributed approach offers several advantages such as minimized bandwidth usage, scalability and faster page index updates."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET HAREKETLİ ROBOTLAR İÇİN HIZLI KONTROLÖR TASARIMI Hareketli bir robotun belli bir amaca ulaşabilmesi için algılama, modelleme ve hareket etme gibi birçok zor görevi aynı anda ve çok küçük bir zaman diliminde gerçekleştirmesi gerekmektedir. Bir robotun kabiliyetleri algılıyıcıları ve hareket bir imleri ile sınırlandırılmış olduğu için, kontrol sisteminin bu kaynakları en iyi şekilde kullanması da çok önemlidir. Bu araştırmada, amacımız hareketli robot çalışmaları için uygun bir araştırma sahası olan robot-futbolu yarışmalarına katılabilecek bir kontrol sistemi hazırlamaktı. Robot-futbolu dünyasını modellemenin kolaylığının yanısıra, karmaşık hedefler ve çeşitli kurallar bu model içerisinde çok rahat tanımlanabilmektedir. Bu araştırma sırasında bu hedefleri ve kuralları potansiyel alanlar olarak tasarladık. Bu sayede potansiyel alan planlama methodunun en önemli iki avantajından faydalanma imkanı bulduk. İlk olarak, potansiyel alanlarla çok değişik dünya modellerini çok düşük bellek ve zaman karmaşıklığı ile modellemeyi başardık, ikinci olarak, potansiyel alan planlama metho dunun modülerliğinden faydalandık. Kontrolör sisteminin içindeki her bir modülü, diğerlerinden bağımsız olarak şekillendirilebilecek biçimde tasarladık. Bu araştırmada, hedefimiz en iyi şekillendirimiş kontrolör modüllerini bulabilmek olduğu için, genetik algoritmalardan faydalandık. Bu algoritmalarda uygunluk fonksiyonlarını hesaplamak için robot-futbol takımlarının aralarında yaptıkları maçlarm sonuçlarını kullandık. Testlerimizin sonuçlarında, potansiyel alanlara planlama methodunun yüksek hareketlilikteki sistemlerde başarılı olduğunu gördük ve genetik algoritmalarla kon trolörümüzün değişik görevler için başarıyla programlanabileceği sonucuna vardık.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF FAST CONTROLLERS FOR MOBILE ROBOTS In order to achieve a goal, a mobile robot controller should handle several chal lenging tasks like processing sensor information, modeling the world and acting. First of all a good controller should be fast enough to do all those task simultaneously in a small period of time. Since the capabilities of a robot are restricted by its sensors and actuators, the controller also should be able to exploit those resources. In this research, our aim is to create a robot team for robot-soccer competitions. Robot-soccer is a very suitable research area for mobile robots. The robot-soccer world is relatively easy to model. Complex goals and various constraints can be defined precisely on this world. In our controller we implemented all goals and constraints using potential fields. This allows us to benefit from two main advantages of potential field planners. The first one is, the planner can model any world using generic field functions with quite low time and space complexity. The second advantage is the modularity of the planner. Each module of the planner can be configured separately to increase performance of the overall system. We used genetic algorithms as our training algorithm because the problem is a complex search task for the best configuration. As the fitness function, we used the results of the matches between robot-soccer teams. From the results of our tests, we are able to conclude that the potential field planner is quite successful for highly dynamic tasks like robot-soccer."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET MELEZ BİR BİYOMETRİK SİSTEM: EL VE YUZ ONAYLAMANIN BİRLEŞTİRİLMESİ İnsanların biyometrik yöntemlerden yararlanılarak tanınması günümüzün bilgi toplumlarında gittikçe daha fazla önem kazanmakta ve biyometrik sistemlerin artan bir şekilde kullanılmasına yol açmaktadır. Şimdiye kadar, parmak izi, yüz, ses, el geometrisi, iris gibi birçok biyometrik özellik kapsamlı bir şekilde araştırılmış ve çeşitli uygulamalarda basan ile kullanılmıştır. Ancak tek bir biyometrik özellik kullanan biyometrik sistemlerin bir takım sınırları vardır ve istenen başarımı sağlayabilmek için birden fazla biyometrik özelliğin birleştirilmesi gerekebilir. Çoklu biyometrik sistemler daha güvenilir ve dayanıklıdırlar ve daha yüksek başarıma sahiptirler. Bu çalışmada, kullanıcılardan gördükleri yüksek kabul oranı ve kolay kurulum- ları nedeni ile biyometrik özellikler olarak el ve yüz kullanılmıştır. Üç ayrı uzman kullanılarak bir kullanıcı onaylama sistemi hasırlanmış ve bu üç uzmanın başarımları karşılaştırılmıştır. Birinci uzman el geometrisi ve parmakların örtük çokterimli mod ellerini kullanmaktadır, ikinci uzman yüzün özyüzler metodu ile gösterimine, üçüncü uzman ise Gömülü Saklı Markov Modelleri ile temsil edilmesine dayanmaktadır. Bu uzmanların çıktılarını birleştirmek için Toplam Kuralı, Bayes yaklaşımı, Lojistik Re- gresyon, Doğrusal Ayırtaç Analizi ve Yapay Sinir Ağları kullanılmış ve farklı yöntemlerin başaranları 25 kişilik bir veritabanı kullanılarak karşılaştırılmıştır. Sonuçlar uzman çıktılarının birleştirilmesinin her durumda daha iyi sonuç verdiğini göstermiştir.","IV ABSTRACT A HYBRID BIOMETRIC SYSTEM: COMBINING HAND AND FACE VERIFICATION Person identification using biometric methods is getting more and more im portant in today's information society; resulting in increased utilization of biometric systems. Up to now, many biometric properties like fingerprint, face, voice, hand ge ometry, iris have been extensively studied and used in several applications successfully. However, biometric systems using a single biometric characteristic have some limita tions and we may need to combine multiple biometrics for the desired performance. Multi-modal biometric systems are more reliable, have larger tolerance and provide better performance. In this work, we chose hand and face as our biometric characteristics, because of their high user acceptance and easy setup. We implemented a user verification system using three distinct experts, and compared their individual performances. The first expert is based on hand geometry and implicit polynomial fit of the fingers, second one is based on Eigenface coding of faces and the third one relies on Embedded Hidden Markov Models. We used Sum Rule, Bayesian approach, Logistic Regression, Fisher's Linear Discriminant and Neural Networks for combining these scores, and compared their performances on a 25-person multi-modal database. The results showed that combining expert outputs always results in increased system performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,Günümüzde Internet dev bir boyuta erişti. Bunun sonucu olarak belli bir kritere uyan dokümanları bulmak daha da zorlaştı. Bu problemi çözmek için tarama motorları ortaya çıktı. Bu araçlar çok iyi programlanmış olmalarına rağmen kullanıcıların bütün ihtiyaçlarım karşılayamazlar. Programımız bu ihtiyaçların bir kısmını insanlara kişisel masa üstü tarama motoru sağlayarak karşılamayı amaçlamaktadır. Oluşturduğumuz program içerik tabanlı resim ve yazı taramaları yapabilir. Kullanıcılar HTTP standartlarına uyan herhangi bir hedef siteyi araştırabilir ve dizinleyebilirler. Dizinleri veri tabanına kaydetmek için ODBC ve SQL kullandık. Bunun sonucu olarak kullanıcılar araştırma motorumuzun yeteneklerini çok iyi bilinen bu veri tabam ara yüzünü kullanan programlar yazarak geliştirebilirler. Programın günümüzün PClerinde çalışması için bazı mühendislik kararlan vermek zorunda kaldık. Bu dokümanda oluşturduğumuz programın bölümleri ve aldığımız bazı kararların nedenleri açıklanmaktadır.,"Internet today has reached an enormous size. Consequently finding documents meeting certain criteria has become harder. To solve this problem search engines have emerged. Though these engines are very well programmed, they can not meet all the needs of users. Our software tries to meet some of these needs by providing a personal desktop search engine. The software we have produced is capable of making both content based image and text searches. Users can search and index any target site that confirms to HTTP standards. We have used ODBC and SQL to store indexes to a database. As a result of this, users can extend the capabilities of our search engine by writing software using this well-known database interface. In order to make our software work on today's PC's we have made some engineering decisions. This document explains the parts of the program we have produced and the reasons of some of the decisions we have made."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET WEB ARAMA MOTORLARI İÇİN BAĞLANTI TEMELLİ BİR SIRALAMA ALGORİTMASININ PARALEL GERÇEKLENMESİ Bağlantı temelli sıralama, Web sayfalarının, yardımlı metin linkleri ile kendi ara larında oluşturdukları bağlantı yapısına göre sıralandırılmasına dayanan bir tekniktir. Bu tekniğin popüler uygulamalarından biri arama motorlarıdır. Şu anda en iyi arama motoru olarak gösterilen Google, başarısının büyük bir bölümünü yine bağlantı temelli sıralamaya dayanan ve esas olarak Web sayfalarının popülerliğini hesaplayan PageRank isimli bir algoritmaya borçludur. Web'in şu andaki boyutu göz önüne alınacak olursa, güçlü bir bilgisayar üzerinde her bir Web sayfasının popülerliğini (ya da PageRank'ini) hesaplamak saatler veya günler sürebilir. Biz bu tezde PageRank algoritmasını MPI kullanarak dağıtık hafızalı paralel bil gisayarlar için tasarlayıp kodladık. Bunu yapmaktaki amacımız, hızla artan Web say faları için PageRank hesaplamalarını hızlı ve ölçeklenebilir şekilde gerçekleştirmek ve böylece PageRank'in yöntem olarak izin verdiği kişisel aramayı merkezi bir arama mo toru servisi olarak mümkün kılmaktır. PageRank şu anda bir abone kitlesine kişisel arama servisi vermek için kullanılmamaktadır. Yaptiğımız deneylerde, geliştirdiğimiz kodun iki Linux PC öbeği üzerindeki performansını ve ölçeklenebilirliğini gözledik. Çalışmamızın sonuçlarından da görüleceği gibi, gerçeklememiz uygun bir alt yapı ile kişisel arama servisi sağlamak amacıyla kullanılabilir.","IV ABSTRACT A PARALLEL IMPLEMENTATION OF A LINK-BASED RANKING ALGORITHM FOR WEB SEARCH ENGINES Link-based ranking for Web pages is a technique that orders Web pages based on their linkage information. A popular application for link-based ranking is search engine technology. Google, which is currently considered the best search engine, owes much of its success to its PageRank method, which is a link-based algorithm to approximate the global popularity of Web pages. Considering the current size of the Web, calculation of the popularity of each web page (which is also called PageRank) can take many hours or days on a powerful computer. In this thesis, we designed and implemented the PageRank algorithm for dis tributed memory parallel computers using MPI. Our aim is to make PageRank calcu lations for the growing number of Web pages in a fast and scalable way. Thus, it will be possible to provide central personalized search service that is a feature of PageRank method. PageRank is not currently used to provide personalized search service to a group of subscribers. We performed experiments on two Linux PC clusters to evalu ate the performance and scalability of our implementation. As can be seen from our results, our implementation can be used to give personalized search service with an appropriate infrastructure. v >"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KÖK KEPSTRAL KATSAYILARININ TELEFON HATLARI ÜZERİNDE KONUŞMACI TANIMA PERFORMANSINA ETKİSİ Bu tezde, telefon kanalları üzerinden gürbüz konuşmacı tanıma sistemleri için değişik özellik vektörlerinin deneysel değerlendirmesi yapılmakta ve kök kepstral katsayılarının gürültülü ortamlardaki konuşmacı tanıma sistemlerinde özellik vektör seti olarak kullanımı önerilmektedir. Amaç tüm işlem ve sınıflandırma adımları değişmeden sadece kullanılan özellik vektörünü değiştirerek, vektör setleri arasında kontrollü bir karşılaştırma yapabilmektir. Değerlendirilen özellik vektör setleri; mel-frekansı kepstral katsayıları (MFCC), geniş-bant mel-frekansı kepstral katsayıları, kök kepstral katsayıları (RCC), ve geniş-bant kök kepstral katsayıları (WRCC)'dir. Veritabanı olarak TUBİTAK- UEKAE (Ulusal Elektronik ve Kriptoloji Araştırma Enstitüsü) tarafından telefon hatları üzerinden toplanan Türkçe ses veritabanı olan TURTEL kullanılmıştır. Konuşmacılar 32 elemanlı gauss karışım modelleri (GMM) ile modellenmiştir. Modeller oluşturulurken 93 konuşmacı (56 bay, 37 bayan) tarafından söylenen ortalama 30 sn uzunluğunda ses kayıtları kullanılmıştır. Test için ise, 2-3 sn uzunluğunda kaydedilmiş cümleler kullanılmaktadır. Ayrıca, gerçek ortamlarda karşılaşılabilecek toplamsal gürültüyü simüle edebilmek için test verilerine 20dB, 15dB, ve lOdB SNR seviyelerinde araba gürültüsü ilave edilmiştir. Deneyler hem temiz hem de gürültülü telefon konuşmaları ile yapılmıştır. Sonuçta; temiz veriler kullanıldığında MFCC ve WMFCC özellik vektör setlerinin her ikisi ile de yüzde 95.6 gibi gayet iyi bir tanıma oram elde edilmiştir. Fakat, verilere gürültü eklendiğinde performansları önemli ölçüde düşmüştür. Diğer taraftan, temiz veriler kullanıldığında RCC ve WRCC özellik vektörleriyle ulaşılan konuşmacı tanıma oranları sırasıyla yüzde 93.5 ve yüzde 94.6 olmuştur. Bu oranlar MFCC ve WMFCC katsayılarıyla elde edilen oranlardan iyi olamasa da, gürültülü veriler ile yapılan deneylerde RCC ve WRCC vektörleri kullanılarak çok daha iyi sonuçlar alınmıştır. Değişik gürültü oranları ile elde edilen sonuçlar ayrıntılı olarak raporda sunulmuştur.","IV ABSTRACT EFFECTS OF ROOT CEPTRAL COEFFICIENTS ON SPEAKER RECOGNITION PERFORMANCE OVER TELEPHONE CHANNELS In this thesis, we experimentally evaluated four different types of feature vectors for their noise robustness and proposed RCC coefficients for feature parameters of a speaker recognition system especially in noisy environments. We believe that this is the first time RCC parameters have been used for speaker recognition and this work will be a reference for a further study. The experiments were made using the TURTEL database, a Turkish telephone- speech database collected by TUBITAK-UEKAE (National Research Institute of Electronics and Cryptology) over telephone channels. The goal is to keep all processing and classification steps constant and to vary only the features parameters to allow a controlled comparison. The evaluated feature vector sets are Mel Frequency Cepstral Coefficients (MFCC), Wide-band Mel Frequency Cepstral Coefficients (WMFCC), Root Cepstral Coefficients (RCC), and Wide-band Root Cepstral Coefficients (WRCC). Speakers were modeled using 32-component GMMs (Gaussian Mixture Model). The training data were approximately 30 seconds speech spoken by 93 speakers (56 male, 37 female). After modeling, the system was tested for each speaker with 2-3 seconds recorded sentences. To simulate environmental additive noise, the test data was also degraded with 20dB, 15dB, and lOdB SNR car noise. Then the tests were repeated with the degraded telephone-speech. It has been observed that MFCC and WMFCC feature sets both performed the same recognition accuracy of 95.6 per cent with clean data. In spite of good recognition rates with clean speech, the performances of MFCC and WMFCC sharply decreased with car noise-degraded recordings. On the other hand, with RCC and WRCC feature parameters we achieved 93.5 per cent and 94.6 per cent recognition rates respectively using clean speech. Although these rates are lower than that of MFCC and WMFCC, the results for RCC and WRCC were much better with noisy telephone data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V ÖZET ZEMIN TEMİZLEME ROBOTU İÇİN KURAL TABANLI YÖNGÜDÜM YÖNTEMİ Bu tez çalışmasında, zemin temizleme robotuna algılayıcı tabanlı bir yöngüdüm yöntemi sunulmaktadır. Bu yöngüdüm yöntemi, kural tabanlı kontrol ve ızgara modelleme tekniğini kullanmaktadır. Temizleme robotunun, etrafı kapalı bir alan içerisinde tüm gezilebilinir alanları gezmesi ve her gezdiği noktadan en az sayıda geçmesi bu çalışmanın temelini oluşturmuştur. Bu gereksinimleri karşılayabilmek için iki farklı süpürme stili incelenmiş ve gerçeklenmiştir. Aynı zamanda, temizleme robotu önerilen yöngüdüm yöntemini kullanarak gezindiği çevrede oluşabilecek değişikliklere uyum sağlamaktadır. Bu yöntemin denemeleri, bir benzetim yazılımı üzerinde gerçeklenmiştir. Benzetim sonuçları, bu tezde verilmiş ve yorumlanmıştır. Bu geliştirilen yöntem, piyasaya sürülecek bir zemin temizleme robotunun ilk örneklerinde kullanılacaktır.","IV ABSTRACT RULE-BASED CONTROL FOR AN AUTONOMOUS VACUUM CLEANER This study presents a sensor-based control method for sweep navigation of an autonomous vacuum cleaner. This method is built by using a heuristic rule-based control and grid-model techniques. The proposed method includes two different sweep strategies: spiral and plow sweep for unknown indoor environments. Both strategies allow the vacuum cleaner cover all free space within the closed environments. Additionally, these strategies minimize the number of times the vacuum cleaner cleans the same free space. This navigation method adapts itself to changes in the environment. A robot simulator program has been developed to test this proposed method in a variety of randomly generated environments. Simulation results are illustrated and compared. This method will be realized on a real robot vacuum cleaner prototype, which will then appear as a commercial product in the marketplace."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BİR UYGULAMA ALANINDA TÜRKÇE METNİN ANLAMBİLİMSEL GÖSTERİMİ Anlambilim, doğal dil işleme biliminin 3 katmanından en önemli ve en zor olanıdır. Anlambilim, en üst katmam oluşturur ve diğer katmanlardan faydalanır. Anlambilim seviyesinde, doğal dillerdeki cümleler anlamsal formüllere çevirilir, ve bu formüller, çeviri, insan-makine diyalogu gibi çeşitli uygulamalarda kullanılır. Bu tez çalışmasında Türkçe cümlelerin anlamsal gösterimlerinin çıkarılması yönünde çeşitli metotlar geliştirildi. Öncelikle, başlangıç aşamasında Türkçe'nin küçük bir kümesi seçildi: 'yemek tarifleri'. Yemek tariflerindeki cümleler, sözdizim ve anlambilim seviyelerindeki kurallar ve formüllerde kolaylık sağlayacak bazı karakteristik özellikler gösterirler. Bir takım kolaylıklara rağmen bu cümleler bir takım kompleks isim tamlamaları ve zarf tümleçleri içerirler. Özellikle farklı zarf tümleçleri anlamsal formül çıkarırken önemli problem oluşturmaktadırlar. Bu çalışma sırasında geliştirilen ana uygulama, girilen dosyalardaki yemek tariflerini okuyup, buradaki cümlelerin anlamsal formüllerini çıkarır. Bu formüller başka uygulamalar tarafından kullanılarak Türkçe cümlelerin diğer dillere çevrimi sağlanabilir.","IV ABSTRACT FORMING SEMANTICS OF TURKISH TEXTS IN AN APPLICATION AREA Semantics is the hardest and most important part of NLP's three level structure: Morphology, Syntax, Semantics. It is the top level and other level's outputs are used. In the semantics level, the sentences of natural languages are translated into semantic formulas; which can further be used for applications like machine translation and human-machine conversation. In this study, several methods are developed to derive semantic representations of Turkish sentences. Firstly, to start with a small subset of Turkish is chosen: the recipes. The sentences in the recipes have some characteristics that make syntactic rules and semantic formulas simpler. Despite this simplicity those sentences contain several complex noun and adverbial phrases. Especially different adverb types cause problems in semantic representation. The main application developed for this study reads the recipe files, and outputs the semantic representations (or inter-lingua formulas) of the sentences. Other programs can be implemented to translate some of these sentences into English, to check the validity of the semantic outputs of the main application."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET İNTERNET PROTOKOLÜ SURUM 4'ÜN DEVİNGENLİK DESTEĞİNİN BAŞARIM DEĞERLENDİRİMİ Bu yüksek lisans çalışması, İnternet Protokol ü Sürüm 4'ün devingenlik desteğinin - Gezgin İPs4- başarım değerlendirimi ve İnternet Protokol'ü Sürüm 6'nın devingenlik desteği -Gezgin İPs6- ile karşılaştırılması üzerinedir. Gezgin İnternet Protokolü (Gezgin İP), uçbirim devingenliğini İP altağları arasında sağlamak amacı ile Internet Engineering Task Force tarafından önerilen standart çözümdür ve uçbirimlere İP ağlarına bağlanma noktalarım değiştirmelerine izin vermek amacı ile tasarlanmıştır. Gezgin İP, ağ katmanında çalışır ve İP paketlerinin yönlendirilmesini etkiler; devingenliği farklı ortamlarda (Yerel Alan Ağlan, Kablosuz Yerel Alan Ağlan, çevirmeli bağlantılar, kablosuz kanallar gibi.) kolaylıkla mümkün kılabilir. Gezgin İP devingenlik problemini kendi yerel ağındaki sabit İP adresi ile yeni bir ağa girdiğinde aldığı geçici İP adresi (misafir adresi) arasındaki ilişkiyi yöneterek çözer. Taşıma ve Uygulama katmanları ise yeni bir ağa girilmesine rağmen kendi yerel ağlarındaki sabit İP adresini kullanırlar ve böylece devingenlikten bağımsız tutulurlar. Bu çalışmanın değerlendirim kısmında, İPs4'ün devingenlik desteğinin davranışını görmek amacıyla ns-2 benzetim aracı kullanılarak yapılan benzetimlerden yararlanılmıştır. Kullanılan benzetim aracı ns-2, oldukça yaygın kullanılan bir araçtır ve kendisine birçok akademik ve bilimsel çalışmada gönderimler yapılmıştır. Çalışmanın sonunda, iki devingenlik protokolü Gezgin İPs4 ve Gezgin İPs6 arasında yapılan karşılaştırmanın sonuçlan bulunmaktadır.","IV ABSTRACT PERFORMANCE EVALUATION OF MOBILITY SUPPORT IN INTERNET PROTOCOL VERSION 4 This Master Thesis Project studies a performance evaluation of Mobility Support in Internet Protocol Version 4 -Mobile IPv4, for short- [1] and makes a comparison with Mobility Support in Internet Protocol Version 6 -Mobile IPv6, for short- [2]. Mobile Internet Protocol (IP) is the Internet Engineering Task Force (IETF) proposed standard solution for handling terminal mobility among IP subnets and was designed to allow a host to change its point of attachment transparently to an IP network. Mobile IP works at the network layer (layer 3), influencing the routing of datagrams, and can easily handle mobility among different media (Local Area Networks (LAN), Wireless LAN (WLAN), dial-up links, wireless channels, etc.). Mobile IP solves the mobility problem by managing the correlation between a changing IP address (care-of address) and the static home address. The transport and application layers keep using the home address, allowing them to remain ignorant of any mobility taking place. The practical evaluation of this work aims that making a set of simulations using ns-2 simulator to see behavior of the mobility support of the IPv4. This simulation tool is one of the most-common network simulators and has been referenced for a lot of RFCs and papers. At the end of the study, results of the comparison of two mobility protocols; Mobile IPv4 and Mobile IPv6 are briefly given."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GENETİK AĞLARIN ÖZNITELIKLİ ÇIZGE EŞLEME KULLANILARAK ÇÖZÜMLEMESİ Bioinformatik, fazla miktardaki biyolojik verilerin işlenmesi ve sonuçlara ulaşılabilmesi için örüntü algılama ve veri madenciliği alanlarının istatiksel ve hesaplanabilir yöntemlerini kullanır. Bu tezde yapılan çalışma, genler arasındaki etkileşimleri bir çizge ile modellemek ve de bu çizgelerin farklı canlılar arasında ne derece uyumlu olduğunu incelemektir. İki çizge arasındaki eşlemeden sonra açıkta kalan düğüm ve bağlantıların henüz keşfedilmemiş bağlantıların, genlerin ya da proteinlerin varlığına işaret edeceği düşüncesinden hareketle, gen ürünlerinin işlevlerini tanımlamak hedeflenmiştir. Bu tezde gen ağlarının özellikleri incelenip uygun bir çizge eşleme algoritması geliştirilmiş ve gerçeklenmiştir. Ağ, gen ve proteinler için hazırlanmış ikili etkileşim tablolarından modellenmiştir. Diğer bir çok karmaşık ağlar gibi, genetik ağların da ölçeklenemez özellikler gösterdiği saptanmıştır. Ölçeklenemez ağların ayırt edici özelliklerinden yararlanarak arama uzayını sınırlayan bir çizge esleme aracı geliştirilmiştir. Esleme ölçütleri ve değerlendirme için kullanılan buluşsal yöntemler eslemeye çalıştığımız ağların kendilerine özgü bağlanırlık dağılımından, kümeleşmiş yapısından, düğümler arası ortalama uzaklığın kısa olmasından ve az sayıda bağlantıya sahip olmasından faydalanır. Çizge esleme uygulaması girdi olarak etkileşim listelerini alır ve çizgeleri oluşturur. Çıktı olarak eşleştirilmiş düğümler listesi üretilir. Eslemenin uyuşmayan bölümleri de bildirilir. Geliştirilen yardımcı uygulamalar ölçeklenemezliği test eden program ile nükleotid dizisi hizalamayı sağlayan araçtır.","IV ABSTRACT ANALYSIS OF GENETIC NETWORKS USING ATTRIBUTED GRAPH MATCHING Bioinformatics adopts statistical and computational methods from the pattern recognition and data mining disciplines to process the immense biological data and derive conclusions. The work done in this thesis is modeling the interaction of genes as a graph and examining how compatible these graphs are among different organisms. The motivation was that the missing nodes and links of the mapping between the graphs indicate the existence of unidentified genes, proteins or interactions, which might lead to the assignment of functions to the gene products. In this thesis, the properties of genetic networks are explored and a suitable graph matching algorithm is developed and implemented. The network is modeled from the pairwise interaction tables for genes or proteins. Like many other complex networks, these networks are shown to exhibit scale-free characteristics. A search-based graph matching tool is developed which exploits the distinguishing properties of scale-free networks when limiting the search space. The matching criteria and evaluation heuristics are based on the characteristic connectivity distribution, cliquish structure, short diameter and sparseness of the networks at hand. The graph matching application takes the list of interactions as input and constructs the graphs. The list of matching nodes is produced as output. The missing parts of the mapping are also reported. The auxiliary applications developed are a tester for scale-free behavior and a nucleotide sequence alignment tool."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET XML İÇİN PATH INDEX SEÇİMİ XML (extensible Markup Language) teknolojisi, yarı yapısal doküman temsili ve veri alışverişinde standart haline gelmiştir. XML dokümanları veri saklama ve sorgulama için çok yaygın bir şekilde kullanılmaktadır. XML dokümanlarına erişimde indexleme performansı arttırır. Bu yüzden XML için indexleme konusunda çok derin araştırmalar yapılmış ve bir çok index tipi önerilmiştir. XML dokümanları graf yapısıyla ifade edilebilirler ve grafın üzerindeki yollar için de path index en uygun index yapılarından birisidir. Path index XML dokümanları için çok önemli ve çok yaygın bir index tipidir. Hard disk yeri limiti nedeniyle graf üzerindeki her yol için path index tutamayiz. Bu yüzden elimizdeki hard disk kısırına uygun ve veriye erişim maliyetini en düşük seviyeye indirecek şekilde olası path index kümesinin en uygun alt kümesini seçmek zorundayız. Hard disk kısıtı hesaba katıldığında kullanılacak indexleri sadece bir sorguyu düşünerek belirlemek yanlış olacaktır. Bu yüzden hard disk kısıtı sınırlarında maliyeti en düşük seviyeye getirecek index alt kümesini tüm sorguları hesaba katarak bulacak genel bir optimizasyon algoritmasına ihtiyaç duyulmaktadir. Bu probleme path index seçimi problemi denmektedir ve bu problem NP zorluğunda bir problemdir. Bu tez çalışmasında logaritmik zamanda, kullanıcının belirleyeceği bir hata payıyla, bu problem için yaklaşık optimal sonuç bulan bir metod sunacağız.","ABSTRACT PATH INDEX SELECTION FOR XML XML (extensible Markup Language) has become a standard for semi-structured document representation and data exchange. There is a large amount of XML documents being used for data storage and retrieval. In accessing XML documents indexing increases the p erformance. T hus i ndexing X ML d ocuments h ave b een e xtensively r esearched a nd various index types have been proposed. The elements of an XML document can be represented by a graph and path indexes are created on the paths of the graph. Path index is an important and commonly used index type for XML documents. It has been used in important projects. Because of the secondary storage space constraint, we cannot create a path index for every path. Thus we need to select a subset of the possible set of the indexes which will fit into the allocated secondary space and which will minimize the cost of processing access operations on the XML document. Because of the storage space constraint, it may not be possible to select locally the subset of indexes, which will minimize the cost of processing. That's why there is a need for a global optimization algorithm, which will specify the indexes that will minimize the cost within the storage space constraint. This problem is called the path index selection problem. It is a NP hard problem. In this dissertation, we will present a method which gives an approximately optimal solution within a user specified error bound in a logarithmic time order."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DOKUNMALI ARAYUZ KULLANARAK BİR ROBOTUN UZAKTAN KUMANDA EDİLMESİ Bu tez dokunmak arayuz yardımı ile bir robot kolunun İP temelli bir ağ üzerinden uzaktan kumanda edilmesi amacına yönelik deneysel bir çalışmadır. Bu anlamda amaç, Java programlama dilinde dokunmak arayüz kullanarak bir robot kolunun uzaktan kumandası için uygulama geliştirmektir. Bilgi teknoloj ilerilerim ve nesnel programlama konularım daha iyi anlama ve bu konulardaki tecrübe kazanma isteği bu çalışma için gerekli motivasyonu sağlayan etkenlerin başında gelmektedir. Yapılan çalışma uygulamaya yönelik bir mühendislik çalışmasıdır. Yapılan çalışmada robot kolu olarak Quick Shot firması tarafından oyuncak olarak üretilen SVI-2000 robot kolu kullanıldı. Robot kolunun sürücü devresi H-bridge yöntemi ve yeni teknoloji ürünü devre elemanları kullanılarak yeniden tasarlandı. Geleneksel oyun çibuğu yapısal bir değişiklik ile dokunmak arayüz olarak kullanıldı. Robot kolu için sürücü programlan, kullanıcı arayüzleri ve haberleşme sürücüleri geliştirildi. Java programlama dili ile geliştirilen yazılımın tasarım aşamasında nesnel ve geleneksel tasarım teknikleri etkin olarak kullanıldı.","IV ABSTRACT TELEOPERATION OF A ROBOT ARM USING HAPTIC INTERFACE This thesis is concerned with an experimental design and application of robot arm control over an IP based Internet network using haptic interface. Towards this end, the objective is to create a Java code for teleoperation of the haptic interface based robotic system. The motivation for this project stems from the desire to gain experience and greater depth of understanding in Object Oriented software design and information technology using latest technologies. The work done is an application oriented, engineering project. The Robotic system consists of S VI-2000 robot arm originally produced as a toy by Quick Shot Company. The hardware driver of the robot arm has been redesigned using H- bridge technique and new technological equipment. The conventional joystick has been modified and used as the haptic interface. The software drivers for the robot arm, the graphical user interface (GUI) and the communication driver have been developed. The whole software design employed design patterns and object oriented design techniques using Java Programming Language."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET VEKTÖR UZAYINDA DOKÜMANLARIN SERADÜZENSEL OLARAK GRUPLANDIRILMASIYLA METİN VERİ TABANLARINDA SORGULAMA Metin tipi veri tabanları doküman başlıklarının indekslenmesiyle oluşturulan vektör uzaylarında oldukça büyük ve seyrek matrisler olarak tanımlanır. Bu matris uzayında istenilen ya da buna yakın bir konudaki dokümanların araştırılması (sorgulanması) büyük zaman alır ve araştırma sonucuna ulaşılabilmesi için oldukça çok sayıda hesaplama yapılması gerekir. Literatürde yapılan çalışmalarda büyük boyutlu metin veri tabanlarına boyut indirgenmesi uygulandıktan sonra bu yeni boyutlarda tanımlanan her bir dokümanın tek tek taranmasıyla sonuca varılan yöntemler tanımlanmıştır. Bu çalışmada ise boyut indirgenmesi yapıldıktan sonra istenilen dokümanların tek bir büyük bir matris içerisindeki tüm dokümanlara bakılarak aranması yerine veri tabanındaki dokümanların önce gamlandırılarak benzer konudaki dokümanların aynı gruplara toplanması ve araştırmanın bu alt gruplardaki daha az sayıdaki benzer dokümanlara bakılarak yapılması önerilmiştir. Böylece tüm veri tabanına bakılması yerine çok daha az sayıdaki dokümana bakıldığından daha az sayıda hesaplama yapılarak sorgulama sonucuna kısa zamanda varılacaktır. Gruplamaların sıradüzensel bir ağaç yapısıyla yapılması, böylece sorgulamanın ağaç içerisinde özyineli olarak belirlenecek olan grubun içindeki alt gruplara yönlendirilmesiyle aramanın küçük gruplarda yapılması önerilmiştir. Tasarlanan dört değişik tipte sıradüzensel ağaç yapısı üç ayrı veri tabam üzerinde denenmiştir. Sonuç olarak yapılan sorgulamalara bulunan dokümanların büyük bir bölümü sorgulama vektörüne en yakın ilk üç dokümandan biri çıkmış ve az bir kısmı ise başarısız olmuştur. Bu yöntemle araştırmalardaki hesaplama sayısı azaltılmıştır. Varılan sonuçlardan bir diğeri de yapılan araştırmanın sonucunun aynı zamanda kullanılan sorgulama vektörüyle de ilgili olduğudur. Sorgulama vektöründe ne kadar çok kelime bulunursa sonuçta bulunacak dokümanın sorgulama vektörüne yakın bir doküman olma olasılığı o oranda yüksek olacaktır.","IV ABSTRACT TEXT DOCUMENT QUERYING VIA HIERARCHICAL CLUSTERING OF DOCUMENTS IN VECTOR SPACES Text databases are big sparse matrices defined in the vector spaces that are formed via indexing the titles of documents. Searching through these databases for finding documents about a desired subject takes a long time and lots of calculations have to be done to get the result. In the literature, the proposed methods for searching these databases contain applying dimension reduction to the databases, then defining the documents in these new dimensions and then searching all of the documents in the reduced dimensions one by one to find the relevant documents about a desired subject. In this study, after applying dimension reduction, grouping the similar documents together and then searching through these small groups containing small amount of documents instead of searching the whole collection one by one are proposed. Thus fewer similar documents in groups will be searched and a result can be found in a short period by doing less calculations. Making the grouping as a hierarchical tree structure is proposed, so that it can be possible to direct the search to smaller groups in each step. Four different tree structures are proposed on three different example text databases are tested. Most of the results to the queryings are one of three closest vectors to the query vector and a few results are unsuccessful. By this method the searching complexity is reduced. Another finding is the fact that a result to a search is related to the search or query vector. The more keywords contain a search vector, the larger is the probability of finding a good result (a closer document to the query vector). a.W&FE?^T P&w ı.. ;.j^v,'^,"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KAOTİK BİR SİSTEMİN YAPAY SİNİR AĞLARI VASITASI İLE LOKAL ANALİTİK MODELİNİN ÇIKARILMASI Son yıllarda yapay sinir ağları özellikle yaklaşık hesap ve modelleme konularında rağbet görmektedirler. Ancak bu yapay sinir ağları, üzerlerinde farklı hesaplamalar yapmaya veya geliştirmeye müsait bir analitik modeli doğrudan sunmamakta, bu durum ise çoğu kez önemli bir dezavantaj olarak görülmektedir. Bu tez kapsamında, yapay sinir ağlarının yapılarına ve parametrelerine ait bilgileri kullanarak, bir yapay sinir ağının analitik modelinin çıkarılması hedeflenmektedir. Bu amaçla kaotik sistemler ve onların denetimi seçilmiştir. Yöntemin uygulama aşamaları şöyledir: seçilen kaotik sistem, merkezcil tabanlı fonksiyonlar kullanan bir yapay sinir ağının eğitilmesi sureti ile modellenmekte, bu yapay sinir ağından analitik model çıkarılmakta ve son olarak da çıkarılan modele dayanarak denetim uygulanmaktadır. Simulasyon sonuçlan, yöntemin oldukça başarılı olduğunu göstermektedir. Bu nedenle, uygun bir yapay sinir ağı yapısı seçildiği takdirde, yapay sinir ağlarının, üzerinde farklı matematiksel işlemler yapmaya açık analitik modellerinin çıkarılabileceği ve bu modeller kullanılarak tatmin edici sonuçlara ulaşmanın mümkün olduğu söylenebilir.","IV ABSTRACT EXTRACTION OF LOCAL ANALYTICAL MODEL OF A CHAOTIC SYSTEM VIA NEURAL NETWORKS For the last few decades, artificial neural networks have become popular for approximation and modelling purposes. However these neural networks do not directly provide an analytical model accessible for calculations, which is usually seen as their major drawback. By using the knowledge of the architecture and parameters of neural networks, it is aimed to extract an analytical model from neural networks in this thesis. Chaotic systems and their control is chosen for this purpose: the chaotic system is modelled by training a radial basis function neural network, then the analytical model is extracted from that neural network, and finally OGY control is applied on the basis of the extracted model. The method has turned out to be quite successful according to the simulation results. Therefore it is fair to conclude that the use of neural networks as an intermediate modelling tool, with the analytical model giving satisfactory results and being accessible for further calculations, is possible, ifa suitable architecture is chosen."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET REGRESYON İÇİN KURAL VE İSTİSNALARIN ÖĞRENİLMESİ: REX ALGORİTMASI İnsan zihni birçok kavramı genel bir kural ve birkaç istisna olarak şekillendirir. Kural basit olup çoğu durumda geçerliyken, istisnalar kuralın basitliğini ve kullanışlılığını bozmadan sıradışı örneklerin de öğrenilebilmesini sağlar. REx algoritması başarılı ve anlaşılabilir bir öğrenme modeli oluşturmak için aynı prensibi yapay öğrenmeye uygular. Daha önce sınıflandırma için incelenmiş ve başarıya ulaşmış olan REx bu tezde regresyon problemlerine, yani çıktısı sürekli problemlere uyarlanmaktadır. Daha basit başka bir algoritmayı temel kural olarak kullanarak öğrenme verilerinden bir dizi istisna belirlenir, ve istisnaları yerel uzmanlar olarak ekleyerek kural bozulmadan genişletilir. Tezde hem işbirlikçi hem de karışım birleştirme senaryoları incelenmekte, ve yoğun istisna gruplarını bulmaya dayanan bir ek anlatılmaktadır. Aynı zamanda, bazı örnekleri vurgulamak yönünden REx ile ilintili olduklarından, regresyon amaçlı Bagging, AdaBoost çeşitleri ve Destek Vektörü Makinalan da detaylı olarak incelen mektedir. Tüm algoritmaları karşılaştıran tartışmalar çeşitli veri kümeleri üzerinde yapılan benzetimlerden gelen deneysel değerlerle desteklenmektedir. Alınan sonuçlara göre, REx'in karışım türü tutarlı öğrenmeyi zorlaştıran bazı yapısal sorunlar içerirken, işbirlikçi hali özellikle basit kurallar kullanıldığında tatmin edici başarıya sahiptir.","IV ABSTRACT LEARNING RULES AND EXCEPTIONS FOR REGRESSION: THE REX ALGORITHM The human mind models many concepts as a general rule and a few specific ex ceptions. The rule is simple and covers most cases, and the exceptions allow learning obscure examples while still keeping the rule simple and useful. The algorithm REx (iJules and inceptions) applies the same paradigm to machine learning to produce an accurate and interpretable learning model. Previously explored for classification with success, REx is adapted in this thesis to regression problems. Using another simpler algorithm as a base rule, it determines a set of exceptions in the training data, and augments the rule by nondestructively incorporating the exceptions as local experts. Both collaborative and mixture combination schemes are explored, with a possible improvement through finding clusters of exceptions. Also included are detailed exam inations of Bagging, AdaBoost variants and Support Vector Machines for regression, because of their relation to REx in emphasizing some examples more than others. Sim ulations on several datasets provide empirical support for the discussion comparing all algorithms. The results indicate that while the mixture version of REx suffers from certain structural drawbacks that hinder consistent learning, the collaborative version achieves satisfactory performance, especially with simple rules."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ROBOTIK EĞİTİMİ İÇİN BİR SİMULASYON YAZILIMI GELİŞTİRİLMESİ Bu çalışmada, silindirik tip robot manipulator direkt kinematik, ters kinematik, dinamik ve PID tipi hesaplanmış tork kontrol benzetim yazılımı eğitimsel amaç için geliştirildi. Tüm bu denklemler MATLAB programında simüle edildi. Eğitimsel amacın gerçekleştirilebilmesi için görsel canlandırmalar MATLAB benzetimlerine eklendi. PID hesaplanmış tork denetimcisi için Matlab-Simulink kullanıldı. Sonuç olarak, silindirik tip manipulator için bütünleşik bir analiz paketi geliştirilmiş oldu. Görsel canlandırmalar dolayısı ile bu yazılım giriş seviyesinde lisans veya yüksek lisans derslerinde eğitim amaçlı olarak kullanılabilir. Yazılımdaki esnek yapı, farklı giriş değişken bilgilerinin etkilerinin kullanıcılar tarafından gözlemlenmesine izin verecektir. Kullanıcılar simulink geribeslemeli denetimcinin PID değerleri ile oynayabilecek ve değişik girdilerin etkilerini görebileceklerdir.","IV ABSTRACT DEVELOPMENT OF A SIMULATION SOFTWARE FOR ROBOTICS EDUCATION In this study, the simulation software of direct kinematics, inverse kinematics, dynamics and PID type computed torque control of a cylindrical type robot manipulator is developed for educational purpose. All the equations are simulated in MATLAB software. In order to satisfy educational purpose, visual animations have been added to Matlab simulations. For PID computed torque controller Matlab-Simulink is used. As a result, a complete analysis package is developed for a cylindrical type manipulator. Because of the visual animations, this software can be used as an educational tool in an introductory Robotics course in undergraduate or graduate level. Flexible structure in the software will allow the users to observe the effects of different variable input data. Users can also play with controller PID values on simulink feedback controller, and see the effects of different inputs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KURALLAR VE İSTİSNALARIN ÖĞRENİLMESİ İÇİN BİRDEN ÇOK SINIFLANDIRICININ BİRLEŞTİRİLMESİ Bu tez Kıtral-ve-îstisnalar (İngilizce kısaltması REx) isimli bir grup çoğul öğrenme algoritmasının geliştirilmesini içerir. Farklı algoritmalar içerikleri ve öğrenme farklılıkları nedeni ile aynı problem için farklı sınıflandırıcılar oluşturmaktadır. Böylece birden çok sınırlandırıcıyı bir araya getirermek başarıyı arttıracaktır. REx metodlan da birden çok sınırlandırıcıyı kullanmaktadır ve öğrenilecek olan kavramın bir kaç kural ve bunlara uymayan istisnalar ile ifade edilebileceğini öngörmektedir. REx metodları üçe ayrılır; Ardışık, İşbirlikçi ve Karışım çoğul-sınıflandırıcı. Ardışık REx çok-seviyeli bir sınırlandırıcı algoritmasıdır. Bu metod, verilen eğitim kümesi üzerinde bir kural oluşturduktan sonra gerekirse diğer kuralları birbirini takip edecek şekilde oluşturur. Bu kurallarla belli bir güven çerçevesinde öğrenilemeyen örnekler istisna olarak ayrılırlar, işbirlikçi ve Karışım REx metodlan ise tek-seviyelidir. Ardışık REx metoddan farklı olarak tek bir kural ve onun istisnalarından oluşurlar. İşbirlikçi REx metodunda kural tüm uzayda geçerliyken, Karışım REx metodu istisnalara uyguladığı gibi kurala da bir geçerlilik alam koyar. Bu üç metod kabul görmüş çoğul-sınıflandırıcılar ve kendisini oluşturan sınıflandırıcılar ile kıyaslanmıştır. Ayrıca bu metodlar UCI'a ait on veri kümesinde test edilmiş ve sonuçlar bahsi geçen diğer metodlarla kıyaslanmıştır. Yapılan testlerin sonuçlan göstermiştir ki REx metodlan oldukça başarılı sınıflandırma sonuçlan elde etmiş ve bu sonuçlara ulaşırken Adaboost ve Bagging gibi popüler çoğul-sınıflandırıcı metodlarından daha az maliyetle ulaşmıştır.","IV ABSTRACT COMBINING MULTIPLE MACHINE LEARNING ALGORITHMS TO LEARN RULES AND EXCEPTIONS This thesis is concerned with development of a group of learning methods, namely REx (Rule-and-Exceptions), which are ensemble methods (composed of multiple learners). Depending on its inductive bias, each algorithm converges to a different classifier and makes errors accordingly. So, they complement each other and an ensemble scheme can outperform its base classifiers. Therefore, combining statistically less correlated base classifiers helps even more. REx algorithms also use this combination principle. These methods use a priori assumption that a concept to be learned can be defined in terms of a few simple rules and exceptions. There are three types of REx; Cascading, Collaborative and Mixture REx. Cascading REx is a multistage ensemble, focusing not only on accuracy but also cost. It tries to fit a few rules to the training set in a cascaded order. After learning a few rules at different stages, samples failing at all confidence tests are extracted as exceptions. Collaborative and Mixture REx methods are single-stage ensembles. These methods consist of single rule and its exceptions. In Collaborative REx, the rule is valid for the whole input space, whereas, Mixture REx defines an expertise area not only for exceptions but also for the rule. The REx algorithms are analyzed and compared with well-known ensembles, Adaboost and Bagging, and base classifiers. Empirical studies on ten UCI data sets show that REx algorithms get highly accurate results at low costs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DEĞİŞKEN SIĞALI KOMPRESÖRLÜ BUZDOLABININ ÇALIŞMA ORANININ UYARLAMR BULANIK DENETİMİ Yiyeceklerin uzun süreli saklanması yada kısa süreli korunması amaçlı kullanılan buzdolabı sistemleri, içeride bulunan ısıl enerjinin dışarıya atılmasını sağlayan bir mekanizmayla donatılmıştır. Bu mekanizmanın en önemli öğesi kompresörlerdir. Sabit sığalı bir kompresör ile yeni bir soğutma sistemi tasarımlandığında seçilen kompresörün gücü, en kötü çalışma koşullarında gerekli en küçük soğutma gücünü sağlamak amaçlı seçilir. Bu nedenle en kötü çalışma koşullan için seçilen soğutma sığası, normal çalışma koşullarında çok yüksek kalır. Bunun sonucu olarak düşük bir oranda çalışan kompresör verimsiz bölgede çalışır. Fakat değişken sığalı bir kompresör kullanılarak sistemin gerek duyduğu sığaya göre kompresör sığası ayarlanabilir ve kompresör en verimli bölgede çalıştırılabilir. Klasik kontrol yöntemlerini kullanarak doğrusal olmayan buzdolabını kontrol etmek zordur, çünkü sistem parametreleri içerilen ısıl süreçlerden dolayı zamana bağlı olarak değişmektedir. Bu tür sistemlerde uzman bilgisi ve gevşek tanımlanmış bazı sistem karakteristiklerini içeren bulanık mantık denetleyicileri kullanılabilir. Bu tez çalışmasında, değişken sığalı kompresörlü klasik bir buzdolabının bulanık mantık denetim yöntemi ile verimli ve de enerji tasarrufu sağlayacak şekilde denetlenmesi amaçlanmıştır.","IV ABSTRACT ADAPTIVE FUZZY RUN-TIME CONTROL OF A REFRIGERATOR WITH VARIABLE CAPACITY COMPRESSOR Refrigeration systems, which are designed to store and preserve food, are equipped with a mechanism that takes thermal energy out from the internal ambient and keeps the low temperature inside the refrigerator within defined limits. The most important component of these systems is the compressor. When designing a new refrigeration system using Fixed Capacity Compressors (FCC) the compressor size is selected to achieve cooling capacity based on the maximum demand at the highest ambient temperature the refrigerator can work at. The consequence is that the compressor delivers high cooling capacity, selected to overcome the worst condition, and needs to be cycled on and off, when normal conditions are achieved. The results are duty cycles with ""on times"" typically from 30 to 50% and consequent low compressor efficiency during the running period. However, by using Variable Capacity Compressors (VCC), the cooling capacity can be adjusted according to appliance demand. To control the refrigeration system by using classical control methods is difficult since its system parameters are time varying due to involved thermal processes. Fuzzy controllers, which contain expert knowledge and some vaguely defined system characteristics, can be used in such systems. In this thesis study the aim is to achieve an efficient refrigeration control of a conventional refrigerator with a Variable Capacity Compressors (VCC) by using a fuzzy controller to reduce overall energy consumption meeting all temperature requirements."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KESİKLİ OLAY BENZETİMİ YÖNTEMİ KULLANILARAK GEZGİN AJAN PERFORMANS ANALİZİ Gezgin-ajanlar üzerine kurulu yazılım geliştirme henüz çocukluk aşamasında ve gezgin-ajan sistemleri üzerindeki araştırma, henüz ihtiyacı karşılayacak düzeyde değil. Gezgin-ajan sistemlerinin performansı, kullanılabilirlikleri açısından kritik bir öneme sahip. Tezimizde, kesikli olay benzetimi yöntemi kullanarak, genel tipte gezgin-ajan sistemleri için bir performans ölçüm yöntemi oluşturduk. Üç değişik durum için kesikli olay benzetimi modelleri sunuyoruz: tek-atlamalı ajanlar, çok-atlamalı ajanlar ve randevu ajanlarları. Gezgin ajan performansı üzerine araştırmalar genellikle tek-atlamalı ajanlar üzerine iken, tezimiz çok-atlamalı ve randevu ajanları durumlarını da kapsamaktadır. Bu üç model olabilecek hemen hemen tüm ajan yer değiştirme senaryolarım kapsamaktadır. Ayrıca, modellerimizi bir kesikli olay benzetimi yazılımı kullanarak somutladık ve değişik senaryolar, ajan büyüklükleri ve değişik ajan geliş sıklıkları için toplam servis süresi ve zamansal kullanışlılık değişkenlerini inceledik. Son olarak da elde ettiğimizi sonuçlan, diğer makalelerdeki bazı sonuçlar ile karşılaştırdık. Sonuç olarak, büyük ajanların kötü kullanışlılığa neden olduğunu ve geliş sıklığının fazla olmasının da servis süresini olumsuz yönde etkilediğini gördük.","IV ABSTRACT PERFORMANCE ANALYSIS OF MOBILE AGENTS USING DISCRETE EVENT SIMULATION Mobile-agent based application development is still in its infancy state and research on mobile agent based systems is not sufficient to meet the needs. Mobile-agent performance is a critical issue for mobile-agent based systems and their feasibility. We have utilized discrete-event simulation technique to build a performance evaluation scheme for generic mobile-agent systems. We introduced discrete event models for three different cases: single-hop agents, multi-hop agents and rendez-vous agents. Research on mobile- agent performance generally focuses on single-hop case; in addition to that, our thesis covers multi-hop and agent rendez-vous cases. These three models generalize almost all of the possible agent migration scenarios. We have also implemented our models in a discrete event simulator and evaluated total service time and useful time utilization, for scenarios with different agent sizes and arrival rates. We have finally compared our results with available data from other papers. We saw that bigger agents leads to poor utilization, and heavier arrival rates would adversely affect service times."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Konum alanı (Location Area) planlaması, çağrı (paging) ve kayıt (registration) sinyali maliyetlerinde etkili olduğu için hücresel telsiz ağ planlamasında önemli bir role sahiptir. Bir konum alanı için en üst servis alanı büyüklüğü bir Hareketli Servisleri Anahtarlama Merkezi (Mobile Services Switching Center) 'nin servis alanıdır. Bu uç durumda kayıt sinyali gerekmemekte, fakat çağrı maliyeti en üst düzeye ulaşmaktadır. Diğer tarafta ise eğer her hücre bir konum alanı olarak tanımlanırsa, çağrı maliyeti en düşük değerde olmakla beraber kayıt sinyali en yüksek seviyesine ulaşmaktadır. Servis alanını bir veya daha fazla konum alanına bölerek toplam maliyeti ola bilecek en düşük seviyeye indirmek, bu iki uç durum arasında bulunmaktadır. Bu çalışmada konum alanı planlaması için en uygun yöntemi bulmaya çalıştık. Bu amaç dahilinde, gerçek hayatta kullanılan bir hücresel telsiz ağın bilgilerini, gerçekçi bir prob lem tanımı yapmak için kullandık. Bu çalışmamızda Tavlama Benzetimi (Simulated Annealing) temeline dayanan bir çözüm yöntemi sunmaktayız. Akabinde, bu yöntemin kalitesini ve uygunluğunu araştırmak için bu yöntemden elde ettiğimiz sonuçlarını diğer bazı yöntemlerin sonuçları ile karşılaştırdık. Bu yöntemler; Rastgele Oluşturma (Ran dom Generation), Açgözlü Yaklaşım (Greedy Search) ve bir Buluşsal Yöntem (Heuristic Algorithm) 'den oluşmaktadır.","Location area (LA) planning plays an important role in cellular networks because of the trade-off caused by paging and registration signalling. The upper boundary for the size of an LA is the service area of a Mobile services Switching Center (MSC). In that extreme case, the cost of paging is at its maximum but no registration is needed. On the other hand, if each cell is an LA, the paging cost is minimal but the cost of registration is the largest. Between these extremes lie one or more partitions of the MSC service area that minimize the total cost of paging and registration. In this study, we try to find an optimum way of determining ""Location Areas"". For that purpose, we use the available network information to formulate a realistic optimization problem. We propose an algorithm based on simulated annealing (SA) for the solution of this problem. Then, we investigate the quality of the SA based technique by comparing its results with greedy search, random generation methods and a heuristic algorithm."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ALÇAK YÖRÜNGE UYDU AĞLARINDA YOL ATAMA İÇİN EN AZ AKIŞ EN ÇOK ARTIK KAPASİTE METODU Yeni uydu sistemleri operatörleri 21. yüzyılda dünya nüfusunun ortalama yüzde elliden fazlasının banliyölerde yaşayacağı varsayımından yola çıkarak uydu üzerinden televizyon yayım yerine haberleşme hizmeti vermek üzerine yoğunlaşmaktadırlar. Bilindiği üzere karasal kablolarla bağlı kablolu veya kablosuz ağların kurulum ve işletim maliyetleri, hizmetin insanların şehir dışında yaşadıkları yerlere kadar iletilmesi durumunda uydu sistemlerinden daha fazla olarak ortaya çıkmakta ve karlılık azalmaktadır. Bu hizmetlerin insanların iletişimi ile birlikte sağlık, eğitim, kriz yönetimi, çevre izlenmesi, elektronik ticaret ve Internet erişimi gibi hizmetleri de kapsaması düşünülmektedir. Uydu sistemleri, karasal kablo tabanlı haberleşme sistemlerinin varolduğu yerlerde yedek sistem olarak kullanılması düşünülmektedir, çünkü bu sistemler doğal afetlerden (deprem, sel, vb.) etkilenmezler ve küresel bir hizmeti vermeye devam ederler. Bununla birlikte, bu sistemlerin bir doğal afet anında bölgede kolaylıkla kurulacak lokal istasyonlar aracılığı ile kablosuz haberleşme cihazlarım arımda tüm dünya ile iletişim kurabilecek bir altyapı sağlaması planlanmaktadır. Bu tezde, uydu ağlan araştırılmıştır. Uydu tipleri, önemleri, avantaj lan detaylı olarak açıklanmıştır. Uydu yönlendirme algoritmalan verilmiş ve yeni bir algoritma tasarlanmıştır. Bu algoritma bir Yönlendirme Kümesi (RS) içinde çalışan ve Enaz Akış Ençok Kalan Kapasite (MFMR) prensibine dayalı olarak çalışmaktadır. RS üzerinde MFMR herhangi bir kısayol bulma algoritmasından daha hızlı çalışmakta ve aday yollar arasında bağlantılarda en az yükü yaratacak yolları seçmektedir. Bu çalışmada, yönlendirme yöntemi modellenmiş ve bir simülasyon yazılımı üzerinde geliştirilerek basanını türlü senaryolar altında incelenmiştir.","IV ABSTRACT A MINIMUM FLOW MAXIMUM RESIDUAL METHOD FOR ROUTING IN LEO SATELLITE NETWORKS The satellite networks have been widely used for TV broadcasting for many years. However, the operators of new satellite systems give more importance to communication satellite networks than TV broadcasting systems since they believe that an average of 50 per cent of the world population will be living in rural areas in the 21st century. Land based wireless or wired networks will cost much more than any satellite network because the setup and operational costs in wired networks will be high compared to the expected revenue for such areas where people live far away from each other. Moreover, this population will need services that could be given on satellite networks such as health care, crisis management, environmental monitoring, electronic commerce and Internet access. The satellite networks are regarded as a backup communication system where land based communication networks exist, because the satellite systems do not suffer from natural disasters (earthquake, flood, etc.) and continue giving service globally. Moreover, in natural disaster cases, people think of using portable land based wireless network equipment and satellite systems together in order to setup the network as quick as possible and make the local system communicate with the rest of the world. All of these needs will increase the communication satellite network usage and the satellite system operators will prefer these networks as being more profitable compared to TV broadcasting systems. In this thesis, the satellite networks are studied. The type of satellite systems, their importance, advantages are given in detail. The satellite routing schemes are given and a new routing algorithm is introduced. The new routing algorithm, the Minimum Flow Maximum Residual (MFMR) method runs on Routing Set (RS) concept. Along with the RS, the MFMR runs faster than any shortest path algorithm and finds the minimum flow path out of candidate paths in order to minimize the maximum flow over the links. In this work, the routing scheme is modeled and implemented in a simulation tool and the performance is evaluated on various scenarios."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET YAPAY SINIR AĞLARININ ÇOK KATMANLI ALGILAYICILAR İÇİN ARTIMLI OLUŞTURULMASI Çok katmanlı algılayıcıların yapılarının belirlenmesi problemi ve standart geri yayılım algoritmasının sorunları bu konudaki çalışmaları bu yapıyı öğrenme sırasında belirleyebilen algoritmalar üstünde yoğunlaştırdı. Bu çalışmada, çok katmanlı algılayıcıların yapılarını otomatik olarak belirleyen iki algoritma öneriyoruz: Birinci algoritma, CAST, saklı üniteleri birer birer ekleyerek tek saklı katmandan oluşan bir yapı oluşturur. İki yapıyı karşılaştırırken istatistiksel testleri kullanır, ikinci algoritma, MOST, birden fazla saklı katmanı olan ya da hiç saklı katmanı olmayan yapılar oluşturabilir. Üniteleri birer birer eklemek yerine, bir ya da daha fazla ünite çıkarmayı, eklemeyi ya da yeni bir saklı katman eklemeyi dener ve istatistiksel testleri kullanarak bir seçim yapar. MOST algoritması ünite ekleme ve çıkarmaya hem de birden fazla saklı katmana izin veren tek algoritmadır. Önerilen algoritmaların kullanılan standart veri kümeleri üzerindeki sonuçları ümit verici ve optimal çözüme yakındır.","IV ABSTRACT INCREMENTAL NEURAL NETWORK CONSTRUCTION ALGORITHMS FOR TRAINING MULTILAYER PERCEPTRONS The problem of determining the architecture of a multilayer perceptron together with the disadvantages of the standard backpropagation algorithm, directed the re search towards algorithms that determine not only the weights but also the structure of the network necessary for learning the data. In this work we propose two algorithms: the Constructive Algorithm using Sta tistical Tests (CAST), and Constructive Algorithm with Multiple Operators using Sta tistical Tests (MOST). The first one constructs a single hidden layer network by adding hidden nodes one by one. The algorithm checks the difference between the errors of the current and candidate networks and decides whether to select the candidate network or not by using a statistical test for comparing the accuracies of the two networks. The networks that are constructed by MOST can have more than one hidden layer. The algorithm uses node removal, addition and layer addition and determines the number of nodes in layers by heuristics. To our knowledge, MOST is the only algorithm that constructs a multilayer perceptron with multiple hidden layers with multiple units per layer. The results of the algorithms are promising and near optimal."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"OGY yöntemi, kaotik sistemlerin kontrolü için basit, ancak güçlü bir yaklaşım sunmakta ve enerji tüketen kaotik sistemlerin orijinalde kararsız olan denge modlarını, sistem denklemlerini bilmeksizin kararlı hale getirebilmektedir. Ancak, bu yöntemin en tipik dezavantajı, rastgele bir başlangıç noktasından başlandığında, sistemin kararlı hale getirilecek denge modu civarına oldukça uzun sürede yaklaşabilmesi ve sadece denge modu civarında kullanılabilen denetleyicinin oldukça geç devreye girmesidir. Bu dezavantajı azaltma çalışmaları, literatürde hedefe yöneltme olarak adlandırılmaktadır. Genişletilmiş Denetim Bölgeleri yöntemi, deneysel verilerden elde edilen yerel modelleri kullanarak, sistem denklemlerinin bilinmediği durumlarda da çalışabilen bir hedefe yöneltme yaklaşımıdır. Bu yöntem, denetim parametrelerine küçük değişimler uygulayarak, sistemin hedef civarına bir kaç adımda yönlendirilebildiği çıkış bölgelerim belirleyip modelleme düşüncesine dayanmaktadır. Bugüne kadar, bu çıkış bölgelerindeki sistem dinamiğinin modellenmesi, yapay sinir ağlan yardımıyla gerçekleştirilmiştir. Bu çalışmada, Genişletilmiş Denetim Bölgeleri yönteminin kümelendirilmiş versiyonunun sinir ağlan yerine, basit analitik modellerle gerçekleştirilmesini sağlayan iki farklı strateji geliştirilmiştir. Farklı metotlarla toplanan verilerden elde edilen alt-kümeler, analitik olarak bir hiper-elipsoid olarak modellenmekte; ardından bu modeller kullanılarak, denetleme parametresinde küçük ayrıksı oynamalarla sistem hedefe yöneltilmektedir. Tek denetim parametreli çeşitli kaotik sistemler üzerinde yapılan benzetim sonuçlan, önerilen yöntemin Kümelendirilmiş Genişletilmiş Denetim Bölgeleri yönteminden daha az bellek ve işlem süresi ile ancak daha düşük hızla hedefe yöneltmeyi gerçekleştirebildiğim, göstermiştir.","The OGY method provides a simple but powerful approach of controlling chaotic dynamics. This method can stabilise inherently unstable equilibrium modes of dissipative chaotic systems under the lack of knowledge about the system equations. However, it has the typical drawback of a long waiting time until the system starting from random initial conditions enters the close neighbourhood of the equilibrium mode to be stabilised, where the controller can be activated. The reduction of this drawback is known under the name of targeting. The Extended Control Regions method is a targeting approach, which can operate under the lack of knowledge about the system equations by employing local models of the system dynamics extracted from empirical data. The method is based on the idea of identifying and modelling those regions of the phase space, starting from which the system can be steered to a close neighbourhood of the target within a few steps applying small perturbations in the control parameters. So far, the modelling of the system dynamics within these phase space regions have been realised using artificial neural networks. In this study, two different strategies are developed in order to realise the clustered version of the Extended Control Regions method on basis of simple analytical models rather than neural networks. Each cluster obtained from the gathered data is analytically described as a hyper-ellipsoid. Subsequently, the analytical models of the clusters are used for targeting purposes by applying small discrete variations in the control parameter. Simulation results on several chaotic systems with single control parameter show that the proposed method can achieve targeting using less memory and computation time than the Clustered Extended Control Regions method on cost of a slower targeting performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KAOTIK SİSTEMLERİN KARARLI HALE GETİRİLMESİ VE HEDEFE YÖNELTİLMESİ İÇİN İŞLEMSEL OLARAK ZEKİ TEKNİKLER Kaos, ilk koşullara ve küçük pertürbasyonlara duyarlı bağımlılık, uzun dönemdeki kestirilemezlik ve garip çeker gibi ilginç özellikleri olan, doğrusal olmayan bir davranış biçimidir. Kaotik davranış, ekonomiden elektroniğe kadar geniş bir yelpazede karşımıza çıkabilir. Kaos, kontrol mühendisliği açısından istenmeyen bir davranış biçimi olmasına rağmen, yerel kararlılaştırma teknikleri kaosun hassas bağımlılık özelliğinden yararlanarak küçük bir kontrol enerjisiyle kabul edilebilir bir performans elde etme imkanı sağlar. Fakat, incelenen sisteme bağlı olarak, sistem stabilizasyon tekniklerinin uygulanabileceği yerel bölgeye gelinceye kadar geçen zaman uzayabilir. Bu durum, hedeflemeyi, yani sistemin herhangi bir noktadan alınıp küçük pertürbasyonlarla hedef bölgesine mümkün olan en kısa zamanda götürülmesi işim, gerekli kılar. Bu çalışma esas olarak sistem denklemlerinin önceden bilinmediği ve denetim parametrelerinin yalnızca küçük bir aralıkta değiştirilebileceği varsayımları altında hedefe yöneltme türündeki bir denetim problemi üzerinde yoğunlaşmıştır. Bu amaçla, hedefe bir kaç adımda ulaşılabilen çıkış bölgelerindeki sistem davranışını modelleme fikrine dayanan, işlemsel olarak zeki bir yöntem önerilmiştir. Yöntem ayrıca kaotik sistemlerin fraktal doğasından kaynaklanan saçılmış verilerle eğitilen denetleyicinin üreteceği yanlış çıktıları ortadan kaldırmak için, bir kümelendirme algoritmasıyla daha da geliştirilmiştir. Önerilen yöntemlerin başarımı pek çok düşük ve yüksek boyutlu sistem üzerinde denenmiştir. Simülasyon sonuçlan, önerilen yöntemlerin, rastgele bir başlangıç noktalan kümesi için, ortalama erişim süresini önemli ölçüde düşürebildiğini göstermiştir.","IV ABSTRACT COMPUTATIONALLY INTELLIGENT TECHNIQUES FOR STABILISATION AND TARGETING OF CHAOTIC SYSTEMS Chaos is a type of non-linear behaviour that has several peculiar properties namely sensitive dependence on initial conditions and small perturbations, long-term unpredictability, and strange attractors. Chaotic behaviour can be observed in a wide spectrum of areas ranging from economics to electronics. Although chaos is an undesired type of behaviour from the control-engineering point of view, local stabilisation techniques suggest achievement of an acceptable performance by exploiting the sensitive dependence property with small control expenditure. However, depending on the system under consideration one can suffer from long waiting time until the system visits the local region, where stabilisation techniques can be applied. This leads to the necessity of targeting, which is the task of steering the system towards the local region in the shortest possible time by applying small perturbations. This work focuses mainly on the targeting type of control problem under the assumptions that a priori knowledge of the system model is not available and that the control parameters of the system can be changed within only a relatively small range. For that purpose, a computationally intelligent technique is proposed, which relies on the idea of modelling the behaviour of the chaotic system in the appropriate regions, starting from which the target can be reached within a few steps. Furthermore, the technique has been improved using a clustering algorithm in order to eliminate misleading outputs of the controller trained with scattered data stemming from the fractal nature of chaotic systems. The success of the proposed techniques has been experimented on several low and high-dimensional chaotic systems. Simulation results have revealed that the proposed techniques can significantly reduce the average reaching time for a random ensemble of initial conditions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GSM VE DIGER HÜCRESEL AĞLAR İÇİN GRAFİKSEL BİR AG PLANLAMA ARACI Kablosuz haberleşme endüstrisi son on yılda çok büyük bir gelişme gösterdi. Radyo tayfı çok fazla doldu. İyi bir ağ tasannu artık incelikten çok gereklilik haline geldi. Bu, çalışabilir ve düşük masraflı kablosuz sistemler için bir ön şart oldu. Frekans planlama hücresel ağ tasarımında anahtar noktadır, ve mevcut frekanslar hücrelere her hücrenin kapasite gereksinimleri karşılanacak şekilde atanmalıdır. Bu zor bir iştir; çünkü mevcut frekans sayısı limitlidir ve frekanslar atama sırasında tekrar kullanılmalıdır, ki bu da tekrar kullanılan frekanslar arasındaki karışım nedeniyle haberleşme hatlarında kalite kaybına sebep olur. Bu çalışmada kullanıcının kablolama altyapısıyla beraber, kablosuz hücresel bir ağ yaratabileceği, hem el ile, hem de bir algoritmaya göre otomatik olarak frekans ataması yapabileceği, yapılan atamanın sonuçlarını inceleyebileceği ve yaratılan kablolama altyapısını görebileceği grafiksel bir ağ planlama aracı geliştirmeye çalıştık. Ayrıca, grafik desteklemeyen diğer programların tasarım sonuçlarım alıp grafiksel olarak gösterebilmek için programa XML temelli bir arayüz ekledik. Böylece program, tasarım probleminin sunumundan çok problemin kendisi üzerinde yoğunlaşmış tasarım programlan için grafiksel bir sunum aracı olarak da kullanılabilir.","IV ABSTRACT A GRAPHICAL NETWORK PLANNING TOOL FOR GSM AND OTHER CELLULAR NETWORKS The wireless telecommunications industry has undergone explosive growth in the last decade. Radio spectrum has become severely congested. Good network design is no longer a nicety, but rather a necessity. It is a prerequisite for workable, cost-effective wireless systems. Frequency planning is a key point in cellular network design, and available frequencies should be assigned to cells in a manner that the capacity requirement of each cell is met. This is rather a hard task because the number of available frequencies is limited, and frequencies should be reused in different cells, which leads to loss of quality of communication links due to interference between the reused frequencies. In this thesis, we tried to come up with a graphical network planning tool, by which the user will be able to create a wireless cellular network, together with the wired structure, make frequency assignment both manually and automatically using a specific algorithm, examine the results of the assignment performed and view the wired structure created. Additionally, we added an XML based interface to the tool so that the tool can import design results of other programs that do not support graphics, in order to display the results graphically. Thus, the tool can also be used as a graphical presentation program for other design tools that concentrate on the design problem itself rather than its presentation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET HAREKETLİ UYGULAMALAR VE HİZMETLERİN BAŞARIM ANALİZİ İÇİN TEST ORTAMI Bu tezde, Hareketli Uygulamalar ve Hizmetler Test Ortamı (HUHTO) geliştirilmiş ve uygulama hizmetlerinin çıktıları ölçülmüştür. Test ortamı geliştirme konusu oldukça geniş bir konu olduğu için ön şart olarak günümüz hareketli ağ protokollerinin oldukça iyi bilinmesi gerekmektedir. Bu protokolleri detaylı çalıştıktan sonra, gerekli yazılımların kurulumu gerekmektedir. Edinilen tecrübe aktarildigi için, ileride HUHTO üzerinde çalışacak araştırmacılar zaman yitirmeyeceklerdir. Bu test ortamı geliştirilirken, akılda bundan sonra geleceklere yol gösterici ve zaman kazandırıcı bir ortam bırakma düşüncesi vardı. Bu nedenle, bu tezde kullanılan protokoller ve IEEE 802.11 ağ alt yapısı hakkında kapsamli bilgi verilmiştir. Hareketli servislere ek olarak, sürekli video ve müzik yayını yapan yazılımlar kurulmuş ve bu servislerin başarım ölçümleri yapılmıştır. Ölçümler sırasında kodlama hızı, eş zamanlı kullanıcı sayısı ve ağ yapısı etmen seviyeleri kullanılmıştır. Test sonuçlan bir çok etmen seviyesi sonuçlarının, 2k etmensel ve iki-etmen tüm etmensel tasarımıyla elde edilmiştir. Bu tezde çıkan sonuçların matematiksel yorumlan verilmiştir. Bu yorumlar çoğunlukla tüm sistemin basarımını etkileyen değişkenlerin etkilerini kapsamaktadır. HUHTO üzerinde kurulan video ve müzik yayım uygulamaları bu değişkenlerin etkilerini ölçmekte kullanılmıştır.","IV ABSTRACT A TESTBED FOR THE PERFORMANCE EVALUATION OF MOBILE APPLICATIONS AND SERVICES In this thesis, Mobile Application Services Testbed (MAST) is deployed to evaluate the performance of mobile multimedia services. Testbed development covers a wide range of topics. Establishing the testbed requires the knowledge of the current mobility and multimedia protocols like RTP, RTSP, SIP, and MobilelP. After getting accustomed with the protocols, required entities are configured. Finally, an environment is created in which other researchers and developers can test their applications. This testbed is deployed while keeping in mind that this thesis will be a guide to the followers and will help them to improve the MAST. Because of this, special attention is paid to give thorough information to the readers about the IEEE 802.11 architecture, mobility and multimedia protocols that will run on MAST. In addition to the mobility services, we have configured streaming entities on MAST. We have deployed both video and music streaming servers. Next, we have evaluated the performance of the streaming servers under different levels of factors like; number of simultaneous users, encoding rate and network architecture. We have done many tests by changing the levels of the encoding rate, number of simultaneous users and network architecture factors. We have done 2k factorial and two- factor full factorial experiment designs. Finally, we found the effects of each factor in the streaming architecture."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET PARALEL MAKİNA TOPLAM ARTI GECİKME PROBLEMİNE GENETİK ALGORİTMA YAKLAŞIMI Bu tezin konusu olan çalışmada Genetik Algoritmaların (GA) parametre bağımlılıklarını azaltmak için uyarlanımlı bir kontrol mekanizması geliştirilmiştir. Geliştirilen yaklaşım, bir takım bağımsız işin birkaç parallel işlemci üzerinde toplam artı gecikmeyi enküçüklemek amacıyla çizelgelenmesinden oluşan Paralel Makina Toplam Artı Gecikme problemi (PMTAG) üzerine uygulanmıştır. Bu çalışma, PMTAGnin en genel şeklini ele aldığından her iş için sıfırdan farklı ve ayrı termin tarihleri, sisteme giriş zamanlan, işlem zamanlan ve dizine bağlı iş hazırlık zamanlan dahil edilmektedir. NP-Zor yapısı nedeniyle problem, ilginç ve iddialı bir araştırma konusu haline gelmiştir. Bunlara bağlı olarak, bu çalışmanın motivasyonu Genetik Algoritmaların özellik ve yeterliklerini inceleyerek çeşitli uyarlanımlı kontrol mekanizmaları geliştirmek yönünde geleneksel paralel makina çizelgeleme probleminin getirdiği zorluklan aşmaktır. Sağlam bir GA mekanizması geliştirmek için, meta-hüristik yöntemin jenerasyon tipi, başlangıç toplumunun yapısı, ana-baba seçimi, gen kesiştirme ve mutasyon gibi temel öğeleri incelenmiştir. Basit bir Genetik Algoritmanın performansı için kritik olan bir takım parametreler baz alınarak uyarlanımlı kontrol mekanizmalan geliştirilmiştir. Geliştirilen yöntemlerin performans değerlendirmesi, literatürden alınmış ve biri deterministik Tabu Arama, diğeri de Genetik Algoritmalardan oluşan iki ayn çalışma ile ele alınmış birtakım problemler üzerinde yapılmıştır. Bu tezin konusu olan GA yaklaşımı ayrıntılı deneylerle incelenmiştir. Sonuç olarak, geliştirilen uyarlanımlı GA yönteminin literatürde yayınlanan ""bilinen en iyi"" veya ""en iyi"" çözümlere göre yüksek kalitede sonuçlar geliştirdiği görülmüştür. Bunun yanısıra, literatürde yayınlanan bazı ""bilinen en iyi"" sonuçlar daha iyi çözümler bulunarak geliştirilmiştir. Elde edilen geliştirilmiş çözümler, GA açısından oldukça önemli bir basan ve kazanımdır.","IV ABSTRACT GENETIC ALGORITHM APPROACH TO PARALLEL MACHINE TOTAL TARDINESS PROBLEM In this thesis, an adaptive control mechanism to reduce the parameter dependence of a Basic Genetic Algorithm (GA) is developed. The approach is implemented over the Parallel Machine Total Tardiness problem (PMTT), which consists of a set of independent jobs to be scheduled on a number of parallel processors to rmnimize total tardiness. As this study considers the generic version of PMTT, distinct ready times, processing times, due dates and sequence dependent setup times for each job are incorporated. The NP-hard nature of the problem renders it a challenging area for research. Hence, the motivation of this study has been to explore the ability of Genetic Algorithms and develop several adaptive control mechanisms to overcome the difficulties superimposed on the traditional parallel machine scheduling problem. In order to develop a robust GA mechanism, the key elements of the metaheuristic such as generation type, initial population structure, parent selection, crossover and mutation are investigated. Based on a Basic Genetic Algorithm, adaptive control mechanisms are implemented, which are structured over some parameters that are found to be critical for the GA performance. The performance evaluation for the strategies developed is done on a set of problems obtained from the literature, where the same problems are addressed in two different studies, one consisting of a GA approach and the other study consisting of a deterministic Tabu Search approach to the problem. The GA approach developed is extensively tested. As a result, it is seen that the adaptive GA approach developed in this study yields good quality results with respect to the optimal'best-known values reported in the literature. Also, some of the best-known results reported in the literature are further improved, which is a notable achievement from the GA point of view."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET.. GENETİK ALGORİTMALARDA DAĞILIM TAHMİNİ Genetik algoritmaların temel operatörlerinin toplum üzerindeki etkileri belir sizdir, önceden tahmin edilemez. Rasgele denilebilecek yeni bireylerin iyileri seçildiği için toplum gittikçe güçlenir ama üretilen yeni bireyin atalarından daha iyi olacağı garantisi yoktur. Hatta güçlü bireylerden çok güçsüz bireyler oluşabilir. Dağılım Tahmini Algoritmaları genetik algoritmaların ilerleyişini olasılık model leri kullanarak yönlendirir. Bu algoritmalar seçilen bireyler üzerine bir dağılım oturtup onun parametrelerini hesaplar ve bu dağılımdan yeni bireyler örnekler. Son yıllarda seçilen bireyleri değişik dağılımlarla modelleyen birçok algoritma önerilmiştir. Bu algoritmalar genlerin ayrık değerlerle ifade edildiği algoritmalardır. Biz sürekli sayılar dizilerinden oluşan bireyleri modelleyen üç algoritma geliştirdik. İlki, parametrik metod, seçilenlerin üzerine normal dağılım oturtarak ondan örnekler alır. ikincisi, seçilen bireyleri çözüm uzayında k gruba ayırarak her grubun üzerine bir normal dağılım oturtur. Sonuncusu ise her seçilen birey üzerine bir normal dağılım yerleştirir. Algoritmalarımızı bazı minimizasyon problemleriyle Çok Katmanlı Algılayıcıların ağırlıklarının öğrenilmesinde test ettik. Aldığımız sonuçlar gösteriyor ki, algoritmalarımız standard genetik algoritmadan daha az kuşakta daha iyi sonuçlar elde ediyor.","IV ABSTRACT ESTIMATING DISTRIBUTIONS IN GENETIC ALGORITHMS The canonical oprerators of genetic algorithms have nondeterministic effects on the population. They produce fitter individuals because they produce semi-random individuals and the fitter of them are selected. These operators can also deform the chromosomes of fit individuals and cause an interruption in the progression. Estimation of Distribution Algorithms (EDAs) use probabilistic models to guide the progression of genetic algorithms. They estimate the distributions of selected indi viduals and sample new individuals from these distributions. Many algorithms, which use different distributions to model the selected individuals, were proposed in recent years. We propose three algorithms, instantiations of EDA template, to estimate the distribution of selected individuals with chromosomes having continuous values. These algorithms fit a normal distribution on the selected set, cluster them into k and fit a normal distribution on each of the clusters or fit a normal kernel on each of the selected individuals. The methods are parametric, semiparametric and nonparametric, respectively. We tested our algorithms on two sets of problems: Some minimization problems and training of MLP weights. The results we get indicates that our algorithms find better solutions than the canonical genetic algorithm in smaller number of generations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TABU ARAMA YÖNTEMİ İLE LOJİSTİK FİLO YÖNETİMİ Filo yönetim sistemleri sahada çalışan araçların faaliyetlerini izlemek ve kontrol etmek için kullanılırlar. Filo çalışanlarım izlemenin yaran filo yöneticileri ile çalışanlar arasındaki eşgüdümün artırılmasıdır. Başarılı bir filo yönetim sistemi, izleme ve kontrol işlevleri dışında dağıtım faaliyetlerini de planlayabilir. Bu çalışma, filo araçlarının etkili bir şekilde yönlendirilmesi için gereken araca duyulan ihtiyaç nedeniyle gerçekleştirildi. Gerçek şartlarda bir coğrafi alana dağılmış müşterilerden gelen istekler bu yöntemle karşılanabilir. Yazar tarafından geliştirilen filo yönetimi sisteminin bir parçası olan Coğrafi Bilgilendirme Sistemi (CBS) müşterileri sayısal bir harita üzerinde işaretlemek için kullanılır. Bu tezin birinci safhası CBS üzerinde yol ağını oluşturmak ve Dijkstra tarafından geliştirilen en kısa yol yönteminin uygulanmasından oluşur. Çalışmanın ikinci safhası bilgisayar üzerinde sayisal harita ile temsil edilen bir coğrafi alan üzerinde dağıtım işerinin planlanmasını içerir. Dağıtım probleminin genel tanımı literatürde Araç Yönlendirme Problemi (AYP) 'ni işaret eder. Gerçek hayattaki olabilirlik koşullan problem içinde taşıma ağırlığı ve rota uzunluğu kısıtlan ile temsil edilir. AYP probleminin NP-zor olması nedeniyle bir Tabu Arama (TA) metahüristik yöntemi yaklaşık-eniyi çözümleri bulabilmek için geliştirilmiştir. Yeni planlama yöntemi, literatürden ve gerçek hayattan alınan dağıtım problemleri ile test edilmiştir. Kuramsal ve gerçek hayattaki problemler üzerindeki başarılı sonuçlar, lojistik dağıtım faaliyetlerini planlamak için sağlam bir araç geliştirmeye yönelik bu çalışmanın başarısını kanıtlar.","IV ABSTRACT LOGISTIC FLEET MANAGEMENT USING TABU SEARCH Fleet management systems monitor and control the activities of trucks that are operating at the field. The benefit of monitoring fleet members is largely due to the increased coordination between the fleet manager and workers. Besides monitoring and controlling, a successful fleet management system may achieve planning of distribution tasks. This study has been stimulated by the needs of a decision support tool for efficiently routing trucks in the fleet. The service requests from customers that are distributed on a real geographic area could be fulfilled by this scheduling algorithm. The Geographical Information System (GIS) module of the fleet management system developed by the author is used for pointing customer locations on a digital map. The first phase of this study covers storing network data on GIS module and then building a robust and fast shortest path computation software based on Dijkstra's algorithm. The second phase of the study includes scheduling of the distribution task on a geographical region that is represented by a digital map at computer. The general description of the distribution problem addresses Vehicle Routing Problem (VRP) in the literature. The feasibility conditions in real life are transferred into the problem as capacity and route length constraints. Since VRP is a NP-hard problem, a Tabu Search (TS) metaheuristics is designed for obtaining near-optimum solutions. The TS algorithm is tested against known problems in the literature together with a distribution problem in real life. The successful results on theoretical and real life problems prove that the study has reached its aim for designing a robust scheduling tool for logistic distribution operations."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET 3D YENİDEN YAPILANDIRMA : ÇİFT VE HAREKET EDEN KAMERALAR İÇİN TEKNİKLER Üç boyutlu yeniden yapılandırma, birden çok imgeden gelen bilgiyi kullanarak bir nesnenin üç boyutlu modelini üretme işlemine denir. Bu resimleri elde etmenin bir çok yolu olacağı için, üç boyutlu model üretmenin de doğal olarak bir çok yolu vardır. Ayrıca yaratılan modelin özniteliği, cismin ve kameranın özellikleriyle de yalandan ilgilidir. Bir çok çeşidi olmasına rağmen, 3D yapılandırma birbirini sırasıyla takip eden süreçlerden oluşur. Bunlar kalibrasyon, eşleme, yapılandırma ve modellemedir. Bu tez değişik üç boyutlu yapılandırma sistemleri için temel bileşenleri oluşturmayı amaçlamaktadır. Bu amaç için, kamera kalibrasyonu, nitelik eşleştirme, yapılandırma ve modelleme algoritmaları gerçeklendirildi. Bu tezin diğer bir katkısı da çift kamera ve düzlemsel kalibrasyon cisimleri kullanan bir sistem için, optimum kamera matris çiftinin seçimi üzerine yaptığımız öneridir. Üç boyutlu yeniden yapılandırmada karşılaşılan en büyük sorun, imgeler arasında düzgün nitelik eşleştirme yapabilmektir. Tezin son kısmı, imgeler üzerinde yapay nitelik yaratılması üzerine değişik tekniklerden ibarettir. Bu tekniklerden biri de yeni geliştirdiğimiz, çift kamera tabanlı bir yüzey sayısallaştırıcısıdır.","IV ABSTRACT 3D RECONSTRUCTION: TECHNIQUES FOR STEREO AND MOVING CAMERAS 3D reconstruction is the process for creating 3D models of a three dimensional object from multiple images. There are many ways to acquire the images; so there are many ways to reconstruct the three dimensional object. The quality of the reconstruction also depends on the various properties of the scene and the camera quality. Although there are many variants, 3D reconstruction is a pipeline-based process, which consists of calibration, matching, reconstruction and modeling, in order. This thesis aims to develop a general framework for different 3D reconstruction schemes. For this purpose, basic algorithms used in calibration, feature matching, reconstruction and modeling have been implemented. Contributions of this thesis also include a proposal for choosing an optimal camera matrix pair in the case of a stereo camera system and a planar calibration object. The most challenging problem in a 3D reconstruction from multiple images is to find the right correspondences between images. The last part of the thesis is mainly about generating artificial features between images and we present several techniques for creating them. One of these techniques is our innovative 3D stereo base surface digitizer."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET NESNE SIRALAMA OYUNUNDA OTONOM ROBOT DAVRANIŞLARININ BİRLEŞTİRİLMESİ Bu tez parça taşıyan bir gezgin robotun hareketlerinin birleştirilmesi ile ilgilidir. Disk şeklindeki cisimlerin iki boyutlu bir çalışma uzayında robot tarafından istenen nok taya götürülmesi istenmektedir. Robotun cisme yaklaşması ve cismi alıp taşıması için gereken ayrı ayrı potansiyel fonksiyonları bilinirken, tek bir yapay potansiyel fonksiyonu Lyapunov fonksiyonu olarak kulanılarak ve tek bir robot-parçalar sistemi modeli ile; bu iki iş bir tek geri beslemeli kontrol yasası tarafından yapılabilmektedir. Kontrol yasası tasarımında La Salle Değişmezlik Teoremi kullanılmıştır. Robotla parça arasındaki eşleşme kuvvetine bağlı olarak yaklaşma ve taşıma fonksiyonları aktive edilip deaktive edilebilmektedir. Robotla parça arasındaki eşleşme kuvvetinin modellemesi, robot ve parçanın pozisyonları ile, robotun tutma kuvvetinin bir fonksiyonu olarak yapılmıştır. Sonuç olarak robot ve parçanın hızları dinamik sistem içinde bir eşleşme faktörü ile bağıntılandırılmıştır. Eğer eşleşme faktörü iki değerli (binary) bir fonksiyon ise bu ayrı ayrı eşleşme ve tasıma fonksiyonlarının belirlenmesi anlamına gelmektedir. Bilgisayar benzetimleri gerçeklenmiş, ve simulasyonlarda robotun birleşik davranışı nitelik ve nicelik olarak incelenmiştir.","IV ABSTRACT COMBINATION OF BEHAVIOURS IN AUTONOMOUS ROBOT ASSEMBLY GAME IN 2D This thesis is mainly concerned with the composition of behaviours for a parts' mover robot. The robot is to move a collection of disk-shaped parts from their arbitrary initial positions to a specified final destination in a completely event-driven manner. Typically, in order to move a part, the robot is with two categories of behaviors: part mating and part moving. Consequently two sets of controllers need to be defined. In an event-driven framework, these controllers are constructed using two families of artificial potential functions, encoding the part moving and part mating tasks for each part respectively and using La Salle's invariance principle. In this study, we explore whether it is possible to compose the two behaviors and thus accomplish the same task with a single set of controllers. This is achieved by studying whether the two artificial potential functions can be combined to form single artificial potential function that can then be used to realize a part mating-moving task. In this new construction, the mating and moving potential functions are activated or de-activated depending on a coupling force defined between the robot and the part in question. The coupling force is modeled as a function of their relative position and the robot's gripper tightness. Hence, in the resulting dynamical system, the velocities of the part and the robot are related with this coupling factor. Furthermore.it turns out that the two category formulation of this task is a special case of this formalism - where the coupling function becomes a binary-valued function. Extensive simulations serve to demonstrate the performance of this approach."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÖRÜNTÜ TANIMADA GÖSTERİMİN DEĞERİ Örüntü tanıma, bilgisayarın veriye bakarak durumları nasıl ayırt edebileceğini inceler. Bilgisayarın bu tanımayı öğrenmesi gerekir. Öğrenme eksik tanımlanmış bir problem olduğu için, en iyi ve tek bir çözüm yoktur. Aynı problem için farklı öğreniciler farklı sonuçlar verebilir ve daha iyi başarımlar elde etmek için bunlar birleştirilebilir. Öğreniciler birleştirilirken genellikle sadece doğruluk göz önüne alınır ve maliyet ihmal edilir. Gerçek hayatta ise, kullanmadan önce öznitelik vektörlerinin çıkarılması gerekir ve bunun bir maliyeti vardır. Doğruluk ve maliyet arasında bir dengenin sağlanması gerekir. Bu amaçla doğruluk ve maliyet ölçütlerini birleştirmek için yararlık kuramı kullanılabilir. Bu çalışmada, öğrenicileri birleştirirken yararlık ölçütünün kullanıldığı iki yeni al goritma öneriyoruz. İlk algoritma CORA, değişik gösterimleri kullanan tüm öğreniciler arasından en yüksek beklenen yararlığa sahip olanını seçer. Hesaba katılan doğruluk ve işleme masraflarıdır. Tüm gösterimlerin bilindiği, fakat zaman ve bellek sınırları olduğunda CORA kullanılabilir, ikinci algoritma DANAE net beklenen yararlığa bakarak yeni bir gösterimin çıkarılıp çıkarılmayacağına karar verir. Burada hesaba katılan doğruluk ve çıkarım masrafıdır. DANAE tüm gösterimlerin bilinmediği ve sadece kullanmaya değerse özniteliklerin çıkarılmasının istendiği durumlarda kullanılabilir. Bu tezde önerilen algoritmalar, sadece doğruluk ölçütünün kullanıldığı diğer bilinen al goritmalardan öznitelik çıkarma ve işleme masraflarının da gözönüne alınması açısından farklıdır ve yararlık açısından bilinen algoritmalara göre daha iyi başarımlar sağlamaktadır.","ABSTRACT VALUE OF REPRESENTATION IN PATTERN RECOGNITION Pattern recognition studies how a computer can distinguish states from data. A computer should learn this identification. Since learning is an ill-posed problem, there is no optimal and unique solution. Different learners can give different results on the same problem, and these can be combined to obtain better performance. In combining learners, generally only accuracy is considered and costs are ignored. But in real life the feature vector of a sample should be extracted before it is used and this has a cost. Utility theory can be used to combine the two criteria, accuracy and cost. We propose two new algorithms for combining learners where utility is consid ered. In the first proposed algorithm, CORA, the learner which has the maximum expected utility is chosen among all available learners each of which is associated with a different representation. We consider accuracy and the processing costs. CORA can be used where all representations are known, but there are some time and space re strictions. The second proposed algorithm, DANAE, decides to extract an additional representation or not, by looking at the net expected value of extraction. We consider accuracy and the extracting costs. This algorithm can be used where we do not know all representations, and want to extract new features only if they are worth to using. The algorithms proposed in this thesis differ from the existing algorithms which use only accuracy in measuring the performance and give better performance in terms of utility compared to the existing ones."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GERÇEKÇİ BİR HAREKET MODELİ VE DS-CDMA SİSTEMLER İÇİN REZERVASYONA DAYALI BİR ÇAĞRI KABUL YÖNTEMİNE UYGULANMASI Telsiz gezgin sistemlerde hizmet kesintisinin nedeni çağrı tıkanması ve çağrı düşme sidir. El değiştiren çağrılara, yeni çağrı denemelerine karşı öncelik vermek için her hücrede koruma kanalları ayrılabilir. Yeni çağrı denemeleri, boşta koruma kanalları olduğu halde reddedilebileceği için çağrı düşme oranındaki düşüş çağrı tıkanma oranındaki artışla elde edilir. Bu yüzden, koruma kanalı sayısı sistem başarımını etkileyen önemli bir ölçüttür. Bu tezde, koruma kanalı sayısını devingen olarak ayarlayan bir çağrı kabul yöntemi öneriyoruz. Etkin her kullanıcı için kullanıcının hızı, yönü ve yakın geçmişteki hareket örün tüsüne göre bir rezervasyon alanı belirlenir. Rezervasyon alanıyla kesişen her aday hücreye, yakınlık değeri ile eşleştirilmiş bir rezervasyon isteği gönderilir. Her hücrede ayrılacak ko ruma kanalı sayısı gelen rezervasyon istekleri ile eşleştirilmiş yakınlık değerlerinin toplamın dan bulunur. Önerilen yöntemi sabit sayıda koruma kanallı klasik yöntemle karşılaştırdık ve önerilen yöntemin çağrı düşme oranını, çağrı tıkanma oranındaki artış açısından daha az masraflı olarak azalttığını gösterdik. Bu tezde ayrıca, insanların gerçek yaşamdaki birlikte hareket etme, bilinçli yolcu luk, eylemsizlik davranışı ve arazideki kimi yapıların içinden geçilmez özelliğini uygulayan gerçekçi bir hareketlilik modeli öneriyoruz. Kullanıcıların hareket örüntüleri farklı fiziksel yapılar içeren bir gerçek haritaya göre belirlenmektedir. Önerilen hareketlilik modelini yol noktası modeli ile karşılaştırdık ve hareketlilik modelinin sistem başarımında önemli etkisi olduğunu gösterdik.","ABSTRACT A REALISTIC MOBILITY MODEL AND ITS APPLICATION TO A RESERVATION-BASED CALL ADMISSION SCHEME FOR DS-CDMA CELLULAR SYSTEMS Call blocking and call dropping are the reasons for outage in mobile wireless systems. Guard channels can be allocated for handoff calls in each cell to give higher precedence to handoff calls over new call attempts. Since new call attempts may be rejected although there are free guard channels, the decrease in the call dropping rate is achieved at the cost of increased blocking rate. Therefore, the number of guard channels is an important metric that effects system performance. In this thesis, we propose a call admission scheme that adjusts the number of guard channels dynamically. A reservation area is constructed for each active subscriber according to his speed, direction and recent mobility pattern. A reservation request, associated with a likelihood value, is sent to each candidate cell intersected by the reservation area. The num ber of channels to be reserved in each cell is obtained from the aggregation of the likelihood values in the received reservation requests. We have evaluated the proposed scheme against the classical scheme with fixed number of guard channels, and shown that the proposed scheme performs better in the sense that call dropping rate is reduced with lower cost. We also propose a realistic mobility model that captures human behaviors from real life such as moving-in-groups, conscious traveling, inertia! behavior, and the non-pass-through feature of the physical structures in the terrain. The mobility patterns of the subscribers are determined according to a given real map composed of various types of physical structures. We have evaluated the proposed mobility model against the way point model, and shown that the choice of the mobility model results in a significant difference in system performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TASARIM EĞİTİMİ İÇİN GEOMETRİNİN WEB TABANLI GÖRSELLEŞTİRİLMESİ Tasarım eğitimi için geometri konuları geleneksel öğretim yöntembilimleri ve araçları ile yeterli bir biçimde sunulamaz ve incelenemez. Geometrideki problemler ve itirazlar ancak görselleştirme ve araştırma yolu ile etkileşimli bir çalışma ortamında ortaya çıkarılabilir. Böyle bir ortamı elde etmekte pek çok problemle karşılaşılmaktadır; birden fazla pahalı program paketi ihtiyacı, uygun donanınım sağlanması, bu programları tanımak için zaman kaybedilmesi bu problemlerden bazılarıdır. Geometri konularını görselleştirerek programlama egzersizlerinde temel olarak kullanılabilecek bir grafik aracına büyük ihtiyaç duyulmaktadır. Bu tezde, bahsedilen ihtiyacın karşılanması ve tasarım için matematik dersi konularının görselleştirilmesi ele alınmıştır. Bilgisayar grafiği kullanılarak; geometri temel kavranılan ile GeoDes (Geometri Destek) isimli WEB-tabanlı, etkileşimli bir ortam geliştirilmiştir. Bu ortam ile, pratik yaparak kuramsal bazı matematik konularının daha anlamlı hale getirilmesi, öğrencilerin görsel kabiliyetlerinin ve anlamalarının arttırılması, öğrenciyi öğrenmeye motive etmesi amaçlanmıştır. GeoDes, WWW yolu ile Java ve ilişkilendirilmiş metin yöntemi kullanarak öğrencilerin zaman ve yerden bağımsız olarak programlama egzersizlerini tamamlayabilecekleri ve araştırma yapabilecekleri platformdan bağımsız bir çalışma ortamı sağlamaktadır. Çalışma farklı bölümlerden öğrencilerden oluşan iki örnek grubu üzerinde test edilmiş olup yapılan değerlendirmenin sonuçları GeoDes ile çalışan öğrencilerde dikkate değer bir öğrenme başarısını göstermiştir.","ABSTRACT WEB-BASED VISUALIZATION OF GEOMETRY IN DESIGN EDUCATION Topics of geometry in design education cannot be adequately presented and explored with traditional teaching methodologies and tools. The problems and challenges in geometry can only be recognized through visualization and exploration in interactive study. Such an environment is achieved facing many problems. Some of these problems are the necessity of several expensive program packages, provision of appropriate hardware and loss of time spent to be familiar with these packages. A platform- independent graphics tool, which can be used as a basis for programming exercises visualizing geometry topics, is greatly needed. In this thesis, the realization of this need and the visualization of the topics for the ""mathematics for design"" course are discussed. Focusing on this discussion, an interactive, WEB-based learning environment called ""GeoDes"" (geometric support) is developed utilizing computer graphics with basic educational and geometrical concepts. With this environment, it is aimed to increase the learning efficiency of the students through practice, to increase their visual abilities, to enhance their understanding, and to motivate them for learning. GeoDes provides a study through the World Wide Web together with Java and Hypertext to enable the students complete and explore the programming exercises independent of time and place through its platform-independency. The results of the evaluation applied to two samples of students from different departments, point to a remarkable learning success with the students studying with GeoDes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GERÇEK BİR SINAİ BÜTÜNLEŞİK ÇEVRİM GUÇ SANTRALININ MODELLENMESİ VE OPTİMİZASYONU Bozüyük/Bilecik'te kurulu gerçek bir sınai bütünleşik çevrim kojenerasyon enerji santralinin benzetimini yapmak için adi türevsel denklem biçiminde modeli geliştirildi. Madde ve enerji korunumu prensiplerine dayanılarak geliştirilen modelin sonuçlan gerçek tesisin ölçüm değerleri karşılaştırılarak doğrulandı. Bazı farklılıklar olmakla beraber model sonuçlarının durağan çalışma koşullarında gerçek tesis ölçümleri ile örtüştüğü saptandı. Adi türevsel denklemlerden elde edilen durağan model tesisin ekonomik açıdan en iyi işletim koşullarını incelemek için kullanıldı. Matlab'in en iyileme alt paket programı iki adet gaz türbininin elektrik üretimi, düşük basınç buhar satış miktarı ve de iki adet gaz türbinine yapılan buhar enjeksiyon akışından oluşan beş değişkenin değişen koşullar altında en iyi değerlerini saptamak için kullanıldı.","ABSTRACT MODELING AND OPTIMIZATION OF AN INDUSTRIAL SCALE COMBINED-CYCLE POWER PLANT A dynamic model in the form of ordinary differential equations has been developed to simulate the behaviour of a real industrial scale combined-cycle cogeneration plant located in Bozüyük/Bilecik. The lumped model which has been developed based on first principles is validated by comparing its predictions with the measured real plant data. In general, though, there are deviations in the transient response of the measured process variables, the model is found to match in the steady state regimes with the real Aken plant. The steady-state model equations obtained from these differential equations have been used to investigate the optimal economical operating strategy of the plant. MATLAB optimization toolbox is used to find the optimum values for the five plant variables namely; power outputs of the two gas turbines, LP steam sales and the steam injection rates to the two gas turbines."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET OTOMATİK ÜÇ-BOYUTLU ARAZI MODEL YARATIM ORTAMI Arazi modelleme ile ilgili detaylı ve kapsamlı yükseklik bilgileri, coğrafi yapı bilgileri, ve uydu fotoğrafları gibi verilerin büyük miktarlarda elde edilmesi sonucunda otomatik arazi modelleme konusu, modelleme ve simülasyon topluluğu için büyük önem kazanmıştır. Arazi modelleme konusu çok büyük miktarlarda veri içerdiğinden, bu verileri işleyecek bilgisayar grafik donanımlarının performansları bir problem olarak ortaya çıkmıştır. Yüksek kaliteli, gerçekçi geometri kullanımı ile yüksek görüntü üretme hızlan arasındaki denge çok-çözünürlüklü modelleme teknikleri ile elde edilebilir. Bu teknikler ile belli bir nesnenin veya bölgenin Farklı Detay Seviyesine (FDS) sahip çoklu temsilleri yaratılır. Görüntü üretme sürecinde her kare için bu temsillerden uygun olanı seçilir. Çalışmalarımız, yazılım geliştiricilerin otomatik olarak yüksek kaliteli, farklı detay seviyeli arazi modelleri üreten programlar hazırlamalarına olanak sunan bir yazılım geliştirme ortamı yaratmak üzerine odaklanmıştır. Bu işin gereği olarak çeşitli uygun geometrik algoritmaları seçerek bunları gerçekledik. Bu algoritmaları gerçek dünyadan veriler ile çalıştırarak ortaya çıkan mühendislik sorunları ve performans üzerinde geliştirme ve iyileştirme araştırması yaptık. Sınırlı Delaunay üçgenlemesi ve bakış-açısı- bağımsız aşamalı ağ yaratımı algoritmalarım tutarlı bir yazılım çatısı içinde birleştirdik. Bunu yaparken çeşitli yazılım tasarım şablonlarından yararlandık. Sonuç olarak, bütünleşik bir yazılım geliştirme ortamında varolan algoritmaları ve kendi eklemelerimizi gerçekledik.","IV ABSTRACT AN AUTOMATIC 3-DIMENSIONAL TERRAIN MODEL GENERATION ENVIRONMENT With the introduction of high volumes of terrain-related data including elevation data, cultural feature maps and satellite imagery, automatic terrain model generation has become a very popular topic for the modeling and simulation community. Terrain modeling involves excessive amounts of data that raise performance issues for computer graphics hardware. The tradeoff between high quality, high fidelity geometry and high render frame rates can be achieved by the use of multi-resolution modeling techniques. These techniques involve creating multiple representations of the same region or object with varying Levels of Detail (LOD), and selecting or on-the-fly generating the appropriate version of each region or object for each frame being rendered. Our work has focused on developing a software environment that allows users to automatically generate high-quality terrain models with varying levels of detail. This task required us to select appropriate computational geometry algorithms, to apply them on real-world data, to examine the problems inherent in selected approach, to research and to develop remedies and optimizations to these engineering tasks. We used a version of the constrained Delaunay triangulation and view-independent progressive mesh generation within a coherent software framework based on several software design patterns. Consequently, we designed and implemented a unified pipelined development environment that incorporates the existing algorithms and our modifications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yapay zekanın bir alt alanı olan Doğal Dil İşleme'nin (DDİ) amacı bilgisayarların doğal dilleri, bu dilleri anadili olarak konuşan insanlarla karşılaştırılabilir başarım seviyelerinde kullanabilmesidir. Bu tezde anlatılan çalışma, gelecekte farklı dilbilimsel yaklaşımların denenmesinde ve Türkçe'nin anlaşılmasını da kapsayan yeni DDİ uygulamalarının geliştirilmesinde kullanılabilecek bir yazılım altyapısının tasarımı ve gerçeklenmesidir. Yazılım platformumuz doğal dili DDİ'nin üç temel düzeyinde işler: biçimbirim, sözdizim ve anlambilim. Biçimbirimsel düzey Türkçe kelimelerin köklerden ve eklerden oluşturulmasını inceler ve çift yönlü bir biçimbirimsel çözümleyici (parser) ile kelimeleri hem çözümler hem de üretir. Tezin sözdizimsel bölümü Türkçe cümle yapılarını öbek yapısı (ÖY) kuralları şeklinde tanımlar. Sözdizimsel öğelerin anlambilimsel gösterimleri ÖY kurallarını gerçekleyen Prolog yüklemlerinin argümanları olarak tanımlanmıştır. Dolayısıyla, bir cümle sözdizimsel olarak çözümlendiğinde, cümlenin tüm anlambilimsel gösterimi de elde edilir. Anlambilimsel gösterimden cümlenin kendisinin üretilmesi de mümkündür. Anlambilimsel gösterim birinci derece yüklem mantığı üzerine kurulmuştur. Cümlelerin anlamları basit ya da içiçe mantık benzeri ifadelerle gösterilmiştir. Bu ifadeler bilgi tabanına girilmeden önce Prolog gerçekleri ve kurallarına çevrilirler. Gerçeklediğimiz temel uygulama bir insan-makine iletişim programı olan TOY'dur. Kullanıcı Türkçe cümleler kullanarak TOY'a sorular sorabilir ve yeni bilgi verebilir. TOY sorguları yeni öğrendiği bilgiyi kullanarak cevaplayabilir. Diğer uygulamalar da bir biçimbirimsel çözümleyici, bir Türkçe fiil çekim programı ve bir sayı dönüştürücüdür.","Natural Language Processing (NLP) is a subfield of artificial intelligence whose ultimate aim is to enable computers to use natural languages with performance levels comparable to those of native humans. The work reported in this thesis is the design and implementation of a software infrastructure that can be of use in the future testing of different linguistic approaches and the development of new NLP applications involving the understanding of Turkish. Our software platform processes natural language at the three basic levels of NLP: morphology, syntax and semantics. The morphological level deals with the construction of Turkish words from roots and suffixes, and both analyzes and generates the words with a bi-directional morphological parser. The syntactic part of the thesis defines Turkish sentence structures in terms of phrase structure (PS) rules. The semantic representations of the syntactic constituents are defined as arguments of the Prolog predicates that implement the PS rules. Therefore, the overall semantic representation of a sentence is derived when the sentence is syntactically parsed. It is also possible to generate the sentence from its semantic representation. The semantic representation is based ön first order predicate calculus. The semantics of the sentences are represented as simple or nested logic-like expressions. These expressions are transformed into Prolog facts and rules before they are asserted to the knowledge base. The main application we implemented is TOY, which is a man-machine communication program. The user can ask questions and give new information to TOY by using Turkish sentences. TOY can answer the queries by using the knowledge it has already learned. Other applications are a morphological analyzer, a Turkish verb conjugation program, and a number transducer."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV ÖZET Değişik kümeleme teknikleri ve bu teknikler ile protein motiflerinin bulunması Proteinler yaşamın temelini oluştururlar. Moleküler biyolojinin önemli amaçla rından biri de belli bir fonksiyona sahip proteinleri üretmektir. Bir proteinin fonksiyo nunu o proteinin motif adı verilen kısımları belirler. Benzer fonksiyonlara sahip proteinlerin motif adı verilen bu kısımlarının birbir lerine çok benzedikleri araştırmacılar tarafından bulunmuştur. Bu çalışmadaki amaç, verilen proteinlerdeki motiflerin bir ön bilgiye sahip olunmaksızın bulunmasıdır. Bunun için parametrik olarak EM metodunu kullandık. EM reel uzay üzerinde çalıştığı için aminoasitleri MDS metotlarıyla vektörlere çevirdik. Bu sayede protein dizilerini reel vektörler olarak ifade edebildik. Bunun yanısıra parametrik olmayan metotlar da kullanıldı. Bilinen protein dizileri üzerindeki sonuçlar diğer motif algoritmalarıyla karşılaştırıldı. MDS metodunun protein motiflerinin bulunmasında bilgi kaybına yol açmadığı ve elde edilen amino asit vektörlerinin, amino asitlerin bazı fiziksel ve kimyasal özelliklerini koruduğu gözlendi. Proteinlerin fonksiyonunu belirleyen motifler sunulan yöntemler tarafından başarıyla bulundu.","Ill ABSTRACT UNSUPERVISED CLUSTERING AND ITS APPLICATION TO DISCOVERY OF MOTIFS IN PROTEIN SEQUENCES Proteins have a major role in living organisms. Designing a protein becomes a major topic in biological engineering. The aim here is to design the protein for the desired function. Subparts of proteins determine their function. These parts are called motifs. In this work the aim is to find an efficient algorithm to find the motifs in a set of protein sequences. Unsupervised vector quantization techniques are used in the motif discovery part. We use Expectation-Maximization (EM) method to find motifs, which is a parametric method. EM in these cases works on discrete domain. To extend the problem onto real domain, amino acids are mapped into continuous vectors using multidimensional scaling (MDS), that allows us to represent protein sequences and subsequences as real vectors. We also used non parametric clustering techniques. The results are compared with the existing algorithms on several well-known datasets. Our results indicate that there is not much information lost if continuous vectors for amino acids obtained from MDS methods are used instead of similarity matrices to solve motif discovery problem. It is shown that MDS also preserves some physio- chemical properties of amino acids. Proposed algorithms are able to detect functionally important motifs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,ÖZET TELSİZ ATM'DE lokal ve global ELDEĞİŞTİRMENİN BENZETİMİ Bu çalışma WATM'deki eldeğiştirme problemini inceliyor. WATM'in yapısı gez gin uçbirimlerin ve değişik veri trafik sınıflarının servis kalitesi garantileriyle destek lendiği bir ağ yapısı çerçevesinde irdeleniyor. Kayıpsız bir eldeğiştirme için tampon belleklerin kullanıldıği bir yöntem öneriliyor. Tampon bellekler anahtarlarda yer alıyor ve anahtar-arası ve anahtar-içi eldeğiştirmelerin bu tampon belleğe etkileri C++'da geliştirdiğimiz bir WATM eldeğiştirme benzetim modeli ile inceleniyor. Kullanılan yöntem rassal sonlu olay benzetimidir. Tampon belleğin doluluğu değişik yük durum larında ve farklı sistem değişkenleri için araştırıldı.,IV ABSTRACT SIMULATION OF LOCAL AND GLOBAL HANDOFF IN WIRELESS ATM This work is a concentration on the handoff problem in Wireless Asynchronous Transfer Mode (WATM) networks. The architecture of WATM is described with a view of a mobility enabled network supporting different traffic classes with Quality of Service (QoS). A buffering approach to implement lossless handoff is proposed. Buffers are placed in the switches and effect of intra-switch and inter-switch handoffs on these buffers is evaluated in a WATM handoff model implemented from scratch in C++. The method used is the stochastic discrete event simulation. Buffer occupancy under different loads and with different system parameters is investigated.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV ÖZET SIP UYGULAMALARINDA KERBEROS TEMELLİ GÜVENLİK SİSTEMİ SIP, IP ağlan üzerinden ses uygulamalarını sunmak amacıyla tasarlanmıştır. SIP, ses ve veri dünyasını bir araya getirerek, telefon görüşmelerinin özel İP ağları veya Internet üzerinden yapılabilmesine olanak sağlamaktadır. Ağlardaki performans ve servis kalitesi konusundaki gelişmeler, ses iletişiminde maliyeti azaltacak bu birleşmeye olanak sağlamaktadırlar. Ses iletişimi ve ses uygulamaları göz önüne alındığında, güvenlik en önemli konulardan biri olarak karşımıza çıkar. Oluşan bu yapıda, güvenliğin sağlanması için sadece mevcut ses sistemlerinin sağladığı güvenlik metodlarının kullanılması yeterli değildir. Bu metodların yanında tüm dünyaya açık olan İP ağlarının kullanılması ile oluşan güvenlik sorunlarını çözecek yeni metodların da uygulanması gerekmektedir. Ses ve veri ağlarındaki birleşimden kaynaklanacak bu güvenlik sorunları düşünülerek, SIP tasannu bir güvenlik altyapısı üzerinde kurulmuştur. SIP ve SIP için oluşturulan ek tasarımlar, bu güvenlik altyapısı üzerinde çalışacak metodlar önermektedirler. Ancak bu metodların hiçbiri ile değişik boyut ve gereksinimlerdeki SIP sistemlerinin güvenlik sorunları tümüyle çözümlenememektedir. Bu tezle doğrulama, bütünlük ve gizlilik gibi SIP güvenlik ihtiyaçlarının karşılanacağı Kerberos tabanlı bir çözüm önerilmektedir. Ses ve ses uygulamalarının güvenlik ihtiyaçlarını istenilen seviyede karşılayacak, esnek ve ölçeklenebilir bir SIP sistemi oluşturulması amaçlanmaktadır.","Ill ABSTRACT KERBEROS BASED SECURITY SYSTEM FOR SESSION INITIATION PROTOCOL Session Initiation Protocol (SIP) is developed to provide advanced voice services over IP networks. SIP unites telephony and data world, permitting telephone calls to be transmitted over Intranets and Internet. Increase in network performance and new mechanisms for guaranteed quality of service encourage this consolidation to provide toll cost savings. Security comes up as one of the most important issues when voice communication and critical voice applications are considered. Not only the security methods provided by traditional telephony systems, but also additional methods are required to overcome security risks introduced by the public IP networks. SIP considers security problems of such a consolidation and provides a security framework. There are several security methods defined within SIP specifications and extensions. But, suggested methods can not solve all the security problems of SIP systems with various system requirements. In this thesis, a Kerberos based solution is proposed for SIP security problems, including SIP authentication and privacy. The proposed solution tries to establish flexible and scalable SIP system that will provide desired level of security for voice communications and critical telephony applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET HATALI ELEKTRİK MOTORLARININ TANINMASI İÇİN PARAMETRE VE SINIFLAYICI BİRLEŞTİRME METODLARI Bu tezde üç değişik motor parametresinden faydalanarak hatalı motor tanıma çalışması yapılmıştır. K-nn, single layer perceptron ve multi layer perceptron metodları gruplayıcı olarak kullanılmıştır. Parametrelerin ve gruplayıcıların değişik bileşimleri kullanılarak veri hakkında daha detaylı bilgi edinilmesi ve hatalı motorların en verimli şekilde tanınması için çalışma yapılmıştır. Aynı gruplayıcının değişik motor parametreleri için sonuçlarının birleştirilmesinin yanında, farklı gruplayıcıların da farklı parametreler için verdiği sonuçlar da optimal, oylama ve yığma metodları ile birleştirilerek yeni sonuçlar da incelenmiştir. Farklı gruplama metodlarının sonuçlarının birleştirilmesinin faydaları görülmüştür. Farklı gruplama metodları belli motor parametreleri ile daha iyi sonuç vermektedir ve bu sonuçların birleştirmeleri incelendiğinde son karara olan etkilerin de farklı olduğu saptanmıştır.","ABSTRACT FEATURE AND CLASSIFIER COMBINATION METHODS FOR DETECTION OF FAULTY ELECTRIC MOTORS Faulty motor detection using three different motor features has been studied. K-tm, single layer perceptron and multi layer perceptron have been used as classifiers. Different combinations of the features and the classifier results have been studied to get a better understanding of the data and to find the most efficient way of classifying the faulty motors. In addition to the combination of the results for the different features with the same classifier, the combination of the results of different classifiers for different features have also been studied as the optimal combination, voting and stacking of the results. The advantages of using combination of different classifiers have been observed. It is seen that different classifiers perform better with certain features and these results have different affect on the final decision when their combinations are studied."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET XQ2DB : BİR XML SORGULAMA DILI - İLİŞKİSEL VERİ TABANI YÖNETİM SİSTEMİ ARA YÜZÜ XML, ortaya çıktıktan sonra büyük bir hızla, internetteki veri gösterim ve değişim standardı haline gelmiştir. XQuery yeni bir XML sorgulama dili olup World Wide Web Consortium (W3C, www.w3c.org) tarafından geliştirilmektedir ve bu yüzden standart XML sorgulama dili olmak için en büyük adaydır. Halen dünyadaki verilerin büyük bir kısmı İlişkisel Veri Tabam Yönetim Sistemleri (İVTYS) üzerinde saklanmaktadır. Bundan böyle, İVTY Sistemleri ilişkisel şema ve SQL kullanmak yerine XML ve XQuery kullanmayı tercih eden büyük bir uygulama/kullanıcı kitlesiyle karşılaşmaya hazır olmalıdır. Bu çalışmada, bir İVTY Sistemini XQuery kullanarak sorgulamayı destekleyen bir arayüz (XQ2DB), Java programlama dili kullanılarak geliştirilmiştir. Bu saf XML bir çözümdür, yani kullanıcı hiçbir şekilde ilişkisel şema ve SQL bilmek zorunda değildir. Kullanıcı ilişkisel veritabanını, XML dokümanları yığınıymış gibi görür. İlişkisel veritabanına ait şema bilgisi, ""doküman tipi tanımı"" (document type definition, DTD) olarak veya ""XML Şema Tanımlama Dili"" (XML Schema Definition Language) kullanılarak ifade edilir. Kullanıcı, XQ2DB arayüzüne bir XQuery sorgusu sunduğunda, sorgu önce analiz edilmekte ve sonra, sorgunun SQL karşılığı bulunmaktadır. Bulunan SQL karşılık İVTYS üzerinde çalıştırılmakta ve tablo şeklindeki SQL sonuçlan elde edilmektedir. Bu sonuçlar, orijinal sorgu tarafından istenen XML yapısına dönüştürülmekte ve kullanıcı XML sonuçları görmektedir.","ABSTRACT XQ2DB : IMPLEMENTATION OF AN XML QUERY LANGUAGE TO RDBMS INTERFACE Since its introduction, XML, the extensible Markup Language, has quickly emerged as the new standard for data representation and exchange on the World Wide Web. XQuery is a new XML query language that is currently being developed by World Wide Web Consortium (W3C, www.w3c.org), and thus, it is a natural candidate for being the standard XML query language. Much of the data in the world are on Relational Database Management Systems (RDBMSs), and RDBMSs must be ready to face a large number of applications and users, who would like to deal directly with XML and XQuery rather than being forced to deal with relational schema and SQL. In this work, a middleware layer (called XQ2DB) which supports querying RDBMS using XQuery is implemented in Java. This is a pure XML solution, that is. the user does not need to know any relational schema and SQL. The user sees the database as if it were bundles of documents. The schema information of the relational database is presented in Document Type Definitions (DTDs) or XML Schema Definition Language. When a user submits an XQuery statement to XQ2DB, the query is parsed, analyzed, translated into SQL, submitted to RDBMS. The tabular results are taken and converted into XML whose structure is imposed by the original query. Finally, the XML result is returned to the user."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET HÜCRESEL KABLOSUZ ŞEBEKELERDE HÜCRE KAPASİTELERİNİN ÖLÇÜME DAYALI PLANLANMASI Kablosuz iletişim de kablolu iletişim gibi teletrafik kuramına dayanır. Bunun amacı geniş kullanıcı sayısına sınırlı bandgenişliği içinde hizmet vermektir. Band genişliğinin sınırlı olması sonucu hücresel radyo sistemlerindeki kanal sayısı da sınırlıdır. Teletrafik analizi, kullanıcıların sınırlı sayıdaki kanallara ihtiyaç üzerine erişimlerinin istatistiksel çözümlemesini yapar. Kullanıcı tarafından bir çağrı yaratıldığında, eğer tüm radyo kanalları dolu ise, kullanıcıya erişim hakkı verilmez ve kullanıcı konuşma kanalı alamaz. Hücresel kablosuz iletişim ortamlarında, hücrelerin kapasite planlamasını zorlaştıran iki neden; otomatik tekrarlama ve tekrar aramalardır. Otomatik tekrarlamalar, kanal alınamadığında, hareketli istasyon tarafından kullanıcı bilgisi dışında yapılır. Tekrar aramalar ise tüm otomatik tekrarlamalar bittiğinde, kullanıcı tarafından yaratılan yeni çağrı istekleridir. Bütün otomatik tekrarlamalar ve tekrar aramalar sayaçlarda ayrı çağrı isteği olarak kayıt edilmektedir. Böylelikle, kanal kapasitesi iyi planlanmamış bir hücrenin en yoğun, saat incelemesi yapıldığında, toplam çağrı sayısı, gerçek çağrı sayısından çok daha fazla çıkmaktadır. Kapasite planlamasında, ölçülen bu değerlerin kullanılması hücrelere fazla kanal atanmasını gerektirmektedir. Bu tezde, otomatik tekrarlama ve tekrar arama probleminin çözümü için basit analitik modeller önerilmektedir. Bu modeller çağrı basma ortalama otomatik tekrar lama ve tekrar arama sayısının bulunması için kullanılmaktadır. Böylelikle ölçülen çağrı sayısından tekrarlama ve tekrar aramalar ayrıştırılarak, gerçek çağrı sayısı bu- lunabilir ve kanal planlaması daha sağlıklı bir şekilde yapılabilir.","IV ABSTRACT MEASUREMENT BASED REPLANNING OF CELL CAPACITIES IN CELLULAR WIRELESS NETWORKS The wireless telephony systems rely on the teletraffic theory to accommodate a large number of users in a limited spectrum. Because of the scarcity of the spectral resources, the number of channels is limited. Teletraffic analysis exploits the statistical behavior of the on-demand transmission access of users to a pool of channels. When a particular user requests service and all of the channels are already occupied, the user is denied access to the system and the user is blocked by the network. In cellular wireless networks, two of the reasons that make cell capacity replan- ning difficult are the retrial and redial phenomena. Automatic retrials are carried out without the user knowledge upon being blocked by the network. Redials are the re quests generated by the user after the original call and the automatic retrials are all blocked. All of the automatic retrials and redials are registered as separate calls. As a result, during the busy periods when blocking is observed in a cell, where the capac ity planning is not done adequately, counters register a much larger volume than the effective call attempts. In terms of capacity replanning, a load appearing larger than the effective one will require more channels than needed to be assigned to the cell. In this thesis, simple analytical models as a solution to the automatic retrial and redial problem are presented. These models are used to compute the mean number of retrials and redials per effective call. Consequently, it will be possible to extract the retrials and redials out from the measured statistics. Finding out the effective number of call attempts, the capacity replanning of a cell can be done more accurately."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET İLİŞKİSEL VERİ TABANLARI İÇİN NESNEYE DAYALI BİR ARAYÜZ TASARIM VE GERÇEKLENMESİ (NESNESEL-İLİŞKİSEL ARACI) Yıllar boyu nesneye dayalı teknolojide çalışan araştırmacıların ulaştığı ortak görüş ilişkisel veri tabanlarının nesne/ilişkisel uyuşmazlığı sebebiyle nesnelerin saklanmasında kullanılmaması gerektiği idi. Nesnesel düşünce ilişkisel düşünceden farklıdır fakat gerçekte çoğu zaman geliştirme ortamı nesneye dayalı ve bilgi saklama mekanizması ilişkisel veri tabanıdır. Bu yüksek lisans tezinde yapılan çalışma bu uyumsuzluğun ve nesneye dayalı mantık ile ilişkisel veri tabanı üzerinde oluşan problemlerin tespiti ve açıklanmasıdır. Burada MDB isimli, tezin parçası olan, nesne-ilişkisel izdüşüm aracını tanıtıyor olacağız ve bu araç geliştirmenlere ilişkisel veri tabanlarına nesneye dayalı bir arayüz sağlamakta yardımcı olacaktır. Bu yüksek lisans tezi problem tanımı içerir, bir ara program kullanımı için ihtiyaçları açıklar, bu ara program için gerekli özellikleri belirler, tezin bir parçası olarak geliştirilen bu ürünün kullanılmasını anlatır, diğer çözüm yaklaşımlarını anlatır ve değişik yaklaşımların karşılaştırmalarını listeler.","IV ABSTRACT DESIGN AND IMPLEMENTATION OF AN OBJECT-ORIENTED FRONT END FOR RELATIONAL DATABASES (OBJECT- RELATIONAL BROKER) For years researchers work in object-oriented technology claimed that one should not use relational databases to store objects because of the object/relational impedance mismatch. The object paradigm is different from the relational paradigm, but in reality most of the time development environment is object oriented and your persistence mechanism is a relational database. The work done in this MS thesis is the identification and explanation of this impedance mismatch and the problems encountered while developing software on top of relational database and object-oriented logic. Here we introduce the object relational mapping product named as MDB, which is a part of the thesis and this product helps the developer to maintain an object-oriented interface to the relational database. This MS thesis include the problem definitions, explain the need for a middleware, identify the needed properties of the middleware, explain the usage of the product that is developed as a part of this thesis, give information about other approaches for this problem and lists comparison of different approaches."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DEĞİŞKEN YAPILI SİSTEMLER KURAMININ AKILLI SİSTEMLERİN EĞİTİMİNE UYGULANMASI İşlemsel zeka içeren sistemler sahip oldukları esneklik ve doğrusal omayan fonksiyonları gerçekleyebilme özellikleri ile doğrusal olmayan sistemlerin kontrollünde geniş bir uygulama alanı bulmuştur. Bu bağlamda hata geri yayma yöntemi ve onun türevleri en çok kullanılan eğitim algoritmaları olmuştur. Fakat bu yöntemler kapalı çevrim sistemin kararsızlığı ve parametrelerin sınırlı tutulamaması gibi problemlerden dolayı pratik ugulamalarda sistem tasarımcısı tarafından dikkate alınması gereken bazı sorunlara yol açmaktadırlar. Bu sorunların üstesinden gelebilmek için Efe denetleyici parametrelerini zamanda sürekli gürbüz bir mekanizma ile güncelleyen bir yöntem önermiştir. İki serbestlik dereceli SCARA tipi robot modeli üzerindeki çalışmalar önerilen yöntemin başarılı sonuçlar verdiğini göstermiştir. Bu tezde, Efe tarafından önerilen metod birinci dereceden doğrusal olmayan sistemler için incelenmiştir. Elde edilen sonuçlar üzerinde yapılan incelemelere dayanarak değişik akıllı yapıların giriş-çıkış eğrilerinin zaman içindeki davranışının benzer olduğu görülmüştür. Ayrıca asıl algoritmada oluşan sınırsız parametre genişlemesi problemini önlemek için parametre güncelleme mekanizmasında bir değişiklik önerilmiştir. Son olarak, elde edilen benzetim sonuçlarına dayanarak uygulamalar için en iyi sistemin ""Adaptive Linear Element"" olduğu sonucuna varılmıştır. ~jsssr.s","IV ABSTRACT APPLICATION OF VARIABLE STRUCTURE SYSTEMS THEORY FOR TRAINING OF INTELLIGENT SYSTEMS Soft computing architectures with their extensive flexibility and strong mapping capabilities have been widely used for control of nonlinear systems. In this regard, error backpropogation and its derivatives have been the most popular and frequently employed schemes for parameter adjustment of these architectures. However, these schemes bring some serious problems together, like instability of closed loop system and sensitivity to uncertainties, which must be carefully addressed by a system designer. In order to alleviate these problems, recently, Efe has proposed a control strategy in which parameters of intelligent controllers are updated by a continuous-time robust parameters adjustment mechanism in order to robustify and stabilize the closed loop system dynamics. The results obtained for a two link SCARA robot in this study show that the proposed method is successful in achieving the control objectives. In this thesis, the methodology proposed by Efe is investigated for first order nonlinear systems. Based on the results, it has been observed that the time evolution of input-output curves of different structures show similar characteristics. Moreover, a modification is proposed for update mechanism of all architectures in order to prevent unbounded parameter evolution problem which occurs in the original algorithm. Lastly, based on the results for different systems, it has been concluded that the Adaptive Linear Element is the most suitable architecture for the control systems investigated because of its simplicity."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ADA'95 İÇİN GENİŞLETİLMİŞ ANLAM ANALİZÖRÜ Genişletilmiş anlam kuralı, bir yazılım dilindeki standart anlam kurallarından farklı olarak, uygulandığı yazılımın kalitesini arttırmak için tasarlanmış bir anlam kuralıdır. Bu tezde Ada yazılım dili için bir anlam kuralları kümesi tasarlanmış ve bu kuralların yazılım kalitesi üzerindeki etkinliği tartışılmıştır. Tezde ayrıca, Ada yazılım kodlarının bu anlam kurallarına uygunluğunu tesbit edebilen bir yazılım aracının geliştirilmesi anlatılmıştır. Bu yazılım aracının etkinliği bir örnek üzerinde tartışılmış, ayrıca geniş bir Ada yazılımı kodu üzerinde denenmiştir.","IV ABSTRACT AN EXTENDED SEMANTIC ANALYZER FOR ADA'95 An extended semantic rule is a rule which we expect a program in a particular language to obey in addition to the standard semantic rules enforced by the compiler for the language. Such extended semantic rules may be necessary to ensure that software has certain software quality attributes. In this work, an Extended Semantic Rule Set (ESRS) that contains certain semantic restrictions for Ada' 95 programs is defined and the effectiveness of that rule set to increase software quality attributes of Ada codes is examined. The work done in this thesis also describes the design and implementation of a software tool, a Semantic Analyzer (SCA) that checks the compliance of a given Ada code to the Semantic Rule Set. The effectiveness of the Semantic Analyzer is discussed on sample input and its output is analyzed for a large set of previously compiled Ada code."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET veri madenciliği için sepet analizi Birçok gelişmiş firma yıllar boyunca müşterilerinden çok fazla miktarda veri topladılar. Elektronik ticaret uygulamalarının da çoğalmasıyla şirketler artık çok fazla veriyi yıllar değil aylarla ölçülebilecek bir zamanda bir araya getirebiliyorlar. Verita- banlarında Bilgi Keşfi olarak da bilinen Veri Madenciliğinin amacı ilerki aşamalardaki kararlara yardımcı olması için veri içerisinde yönsemeler, örüntüler, ilintiler ve sapak lıklar bulmaktır. İlişki Kuralları Bulma Veri Madenciliğinin ana uygulama alanlarından bir tane sidir. Sepet analizinin amacı verilen bir satış raporları üzerinden mallar arasında ilin tiler bulmaktır. Bu tezde geniş bir mal satış veri tabanı üzerinde İlişki Madenciliği çalışması yaptık. İlk kısımda problemin genel hatlarla tanımını ve bu problemi çözmek için kullanılan yaklaşımları anlattık. Bu konuda ilk kullanılan algoritmalardan birisi olan ""Apriori Algoritması"" nı detaylı olarak inceleyerek bu algoritmanın büyük bir süper market zinciri olan Gima Türk A.Ş.'nin verileri üzerinde uygulanmasıyla ortaya çıkan sonuçları verdik. Ayrıca mal satışları arasında ilintiler bulmak için iki istatistiksel method kullandık: Ana Bileşen Analizi ve k-Ortalama Öbeklemesi.","IV ABSTRACT MARKET BASKET ANALYSIS FOR DATA MINING Most of the established companies have accumulated masses of data from their customers for decades. With the e-commerce applications growing rapidly, the com panies will have a significant amount of data in months not in years. Data Mining, also known as Knowledge Discovery in Databases (KDD), is to find trends, patterns, correlations, anomalies in these databases which can help us to make accurate future decisions. Mining Association Rules is one of the main application areas of Data Mining. Given a set of customer transactions on items, the aim is to find correlations between the sales of items. We consider Association Mining in large database of customer transactions. We give an overview of the problem and explain approaches that have been used to attack this problem. We then give the description of the Apriori Algorithm and show results that are taken from Gima Türk A.Ş. a large Turkish supermarket chain. We also use two statistical methods: Principal Component Analysis and fc-means to detect correlations between sets of items."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET OZNITELIGE DAYALI POZDAN BAĞIMSIZ YUZ TANIMA Yüz tanıma sistemlerindeki en önemli problemlerden biri yüz resimlerindeki poz değişimleridir. Çoğu yüz tanıma tekniği pozun önceden bilindiğini farzeder. Bu çalışmada pozdan bağımsız yüz tanıma problemi için iki farklı yüz gösterim metodu karşılaştırılmıştır. İlk yöntem yüzün standard özyüzler metodu ile gösterimine dayan maktadır, ikinci yöntemde ise yüz gösterimi için Gabor dalgacıklarına dayalı fil- treleme yöntemi kullanılmıştır, ikinci yöntemin, insan görme sistemindeki gibi, değişik frekanslara ve yönlere olan duyarlılığı, Gabor dalgacıklarının seçilme sebebidir. Ga bor dalgacıklarına dayalı yüz gösterimi, ayrıca, önemli bileşenler yöntemi kullanılarak tanıma performansını düşürmeyecek şekilde kodlanmıştır. Her iki gösterim yöntemi için, parametrik ve poza-bağlı yüz tanıma algoritmaları kullanılmıştır. Sonuçlar Gabor dalgacıklarına dayanan yüz gösterim metodunun her iki yüz tanıma algoritmasi için de özyüzlere dayalı gösterime oranla daha iyi sonuç verdiğini göstermektedir. Parametrik ve poza-bağlı yüz tanıma algoritmaları her iki yüz gösterim metodu için de birbirine yakın performans göstermiştir. Ön cepheden oluşan yüzler için de Gabor dalgacıklarına dayalı yüz gösterim metodunun üstünlüğü ayrıca gösterilmiştir.","IV ABSTRACT FEATURE BASED POSE INVARIANT FACE RECOGNITION One of the major difficulties in face recognition systems is the in-depth pose variation problem. Most face recognition approaches assume that the pose of the face is known. In this work we compared two different face representation methods for pose invariant face recognition. The first one is the conventional Eigenface coding of face images. The second one is based on the Gabor wavelet based filtering of face images. Gabor wavelets are chosen because of their sensitivity to both spatial frequency and orientation, like the early stages of human visual processing system. Subspace cod ing of Gabor wavelet-based face representation was also implemented using Principal Component Analysis without a significant loss in the recognition performance of the system. Both parametric and view-based pose invariant face recognition algorithms were used for each representation. Our results show that Gabor wavelet based filtering of images improves the overall performances of both parametric and view-based approaches where these two classifi cation methods have almost similar recognition performances. Effectiveness of Gabor wavelet-based representation was also shown for frontal face databases."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KONUŞMA, MÜZİK, GÜRÜLTÜ AYRIŞTIRMA SİSTEMİ Bu çalışmada işaret sınıflandırmada kullanılmak üzere genel bir veri çıkartım sistemi kurulmuş ve bu sistem konuşma, müzik, gürültü ayrıştırma probleminde kullanılmıştır. Problemde kullanılacak ses özelliklerinin belirlenmesi ve hesaplanması için bir işaret işleme çalışması gerçekleştirildi. Birincil ve ikincil ses özellikleri şöyle tanımlanmıştır: Birincil özellikler, spektral merkez, spectral maksima, spektral akı, düşük enerjili çerçeve oranı, spektral dönme noktası, sıfır geçiş oranı, sepstral kalıntı; ikincil özellikler ise, birincil özelliklerden çıkartılan ortama değer, varyans ve ortalama geçiş oranıdır. Sistemde gerçeklenen sınıflama yöntemleri k-yakın komşu sınırlandırıcısı (k-NN), en yakın küme sınıflandırıcısı ve çok katmanlı perseptron (MLP) sınıflandırmışıdır. Tek tek her özelliğin ve özellik kümelerinin gruplandırma performansları hesaplanmış ve karşılaştırılmıştır. Sistem daha sonra gerçek zamanda çalışma için optimize edilmiştir.","ABSTRACT A SYSTEM FOR SPEECH, MUSIC, NOISE DISCRIMINATION This study builds a general data retrieval system that is used for the classification of signals and applied to discrimination of speech, music and noise problem. A signal preprocessing is performed for the identification and computation of the features that can be useful for the problem. We define primary and secondary features: the primary features are spectral centroid, spectral maxima, spectral flux, percentage of low energy frames, spectral roll-off point, zero-crossing rate, cepstral-residue, spectral maxima; and the secondary features are mean, variance. The system implements the following classification methods: k-Nearest Neighbor classifier (k-NN), nearest cluster classifier, Multi-Layer Perceptron classifier (MLP). The discrimination performances of the individual features and the combination of them are computed and compared. The system is then optimized for real-time processing."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET TELSİZ ÇOK SEKMELİ PLANSIZ AĞLAR İÇİN YÖNLENDİRME PROTOKOLLERİNİN BAŞARIM DEĞERLENDİRMESİ Plansız ağlar belirgin bir altyapıya sahip değildir. Böyle bir ağın kullanıcıları merkezi yönetim gerektirmeyen geçici bir ağ oluştururlar. Kullanıcılar hareket etmeye başladık larında, oluşturmuş oldukları plansız ağ, ilingesini dinamik olarak değiştirmeye başlar. Böyle sine dinamik olarak değişen bir ilingede bütün gezginlerin yol atama becerisine sahip ol malarına ihtiyaç bulunmaktadır. Telsiz iletişimde, radyo erişim uzaklığı sınırlamalarından dolayı iki uzak gezginin iletişimi çok-sekmeli bağ üzerinden sağlanmak zorundadır. Bu işin başarılması için değişken bilgisayar ağ ilingesiyle uyarlanabilen farklı yol atama pro tokolleri önerilmiştir. Bu protokoller bant genişliği, CPU ve güç gibi değerli kaynakların az kullanımını sağlamalıdır. Bu çalışmada, genel plansız yönlendirme protokolleri, plansız bilgisayar ağlarının per formansına etki eden faktörler açısından incelenmiştir. Araştırmamızı yaparken, Mobile Ad- hoc Networking Charter tarafından önerilen başarılı paket dağıtımı, kontrol paketi yükü, or talama gecikme ve ortalama iş çıkarma yeteneği gibi başarım ölçüleri kullandık. Ek olarak, protokollerin enerjiyi ne kadar verimli kullandıklarını inceledik. Testler çift yönlü değişken bit hızlı trafik ve tek yönlü değişken bit hızlı çoklu-ortam trafik ve TCP trafiği gibi değişik trafik tipleriyle yapıldı. İP katmanına dayanan yönlendirme protokollerinin kontrol mesajlaş ması, komşuları keşfetmek ve bağlantının kopmasını farketmek için kullandığı bu mesajların kayıplarından dolayı kötü performans göstermektedir. Bu işlemler daha iyi başarım için daha alt katmanlarda yapılmalıdır. Düşük hareketlilikte enerjinin verimli kullanılması, kul lanımının dağıtılabilmesi için birden fazla yol kullanmalıdır.","ABSTRACT PERFORMANCE EVALUATION OF WIRELESS MULTI-HOP AD-HOC NETWORK ROUTING PROTOCOLS Ad-hoc networks do not have a specific infrastructure. Users of such a network form a temporary network, which requires no centralized administration. When the users start mov ing, the ad-hoc network they had formed starts changing its topology dynamically. In such a dynamically changing topology, we need all mobile nodes to have the ability of routing. In the wireless medium, because of radio transmission range limitations, communication between two remote hosts has to be established through a multi-hop link. To accomplish this task, various routing protocols capable of adopting to changing network topologies have been proposed. Those routing protocols should minimize the usage of valuable resources such as bandwidth, CPU, and power. In this study, common ad-hoc routing protocols are evaluated to observe the effects of miscellaneous factors on the performance of the ad-hoc network. While we were doing our research, we used the performance measures suggested by Mobile Ad-hoc Networking Charter, such as successful packet delivery, control packet overhead, average delay, average throughput. We additionally analyzed the power efficiency of protocols. We ran our tests with various traffic types such as bi-directional and uni-directional multimedia VBR traffic, TCP traffic, and their combination. Simulation results have shown that we need a better adap tive routing protocol handling high mobility. Routing protocols that depend on IP layer for control messaging perform poor, mainly because of the control packet loss, and the control message overhead while discovering neighbors and detecting link failures. These operations should be done in the lower layers for better performance. A power efficient routing protocol should use multiple routing paths to distribute power usage at low mobility."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET renkli imgelerge veri saklama Son yıllarda, medya ortamında kullanılan belirli formatların telif hakları önemli bir konu olmaya başladı. Bu sebeple, sayısal ortamda bilgi saklama konusu önem kazandı ve kaçınılmaz oldu. Sayısal ortamda bilgi saklama, imza, telif hakkı, oluşturulma tarihi vb. bilgileri saklanma amacıyla yapılan işlemdir. Gerçek renkli sayısal resimler 1 6 milyon ve daha fazla renk içerebilirler. Buna karşın paletli resimler, çok daha az sayıda renk içerirler. Bu az sayıda renk palet adı altında anılan ayrı bir tabloda tutulur. Bu durumda sayısal resim, bu palete işaretçiler içerir. Bu tezde, üç yeni, sayısal resimlerin paletlerini kullanan bilgi saklama yöntemi önerilmiştir. Bu yöntemlerden ikisi resimlerde hiç kullanılmayan veya göz ile ayırd edilemeyecek farklara sahip olan renkleri kullanmaktadır, böylece resmi görsel olarak değiştirmemektedir. Üçüncü yöntem yüksek sayıda renk içeren resimleri az sayıda renk içeren, paletli resimlere çevirirken palet içerisine bilgi saklama amaçlıdır. Bu üç yöntemi dayanıklılık, kapasite ve görünülme açılarından inceliyoruz. Bilgi saklama uygulamalarında kullanılabileceklerini gösteriyoruz.","ABSTRACT DATA HIDING IN COLOR IMAGES In recent years, copyright has become an important issue for certain kinds of media. Therefore, data hiding in digital images has become an unavoidable issue. Data hiding is the process for hiding information like signatures, copyright information, construction date etc. within multimedia objects like digital images, audio files, video etc. True colour images may contain up to more than 16 million colours. Paletted images, on the other hand, contain much fewer colours, which are kept in a separate table called a palette. The image then contains references to the palette. A number of recent techniques have been proposed for data hiding in paletted images. In this thesis, three novel techniques for hiding data using the palettes of color images are proposed. Two of the techniques can be implemented without interfering with the image data, by using unused entries or visually indistinguishable colors in the image palette. The last technique reduces a high colour image to an indexed image and encodes the watermark using the palette information. We test the performance of these three techniques with respect to robustness, data hiding capacity and perceptibility. We show that these techniques can be used for data hiding applications."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET YAPAY SİNİR AĞLARI YAPILARININ GENETİK ALGORİTMALARLA DOLAYLI KODLANARAK ENİYİLENMESİ Yapay sinir ağları, yapılan bilindiğinde öğrenme yordamları ile öğrenilebilirler. Yapay sinir ağlarının boyutları ve karmaşıklığı performansını büyük ölçüde etkiler. Sinir ağının yapısı probleme bağlı olduğundan en uygun ağ yapısını bulmak kolay değildir. Bu çalışmada sunulan genetik sistem bu problemi otomatik çözmeye yöneliktir. Birim-grup modellemesi ve genetik yordamlar bu genetik sistemin iki ana parçasıdır. Sinir ağının yapısı birim-grup modeli ile betimlenmiştir. Bu yapı üzerinde uygun olan genetik algoritma işlemleri uygulanmıştır. Kurulan genetik sistem ikili ve gerçek değerli problemler üzerinde denenmiştir.",ABSTRACT NEURAL NETWORK TOPOLOGY OPTIMIZATION WITH GENETIC ALGORITHMS USING INDIRECT ENCODING Neural networks can be trained with learning algorithms once their topology is known. The size and the complexity of the neural network greatly influence its performance. Since the topology of the neural networks is problem dependent it is not easy to construct the optimal neural network. The genetic system presented in this study is an approach to solve this problem automatically. The genetic algorithm and the unit-cluster model are the two main parts of this genetic system. The structure of the neural network is represented by the unit-cluster model. Suitable genetic algorithm operators are applied on them. The success of the implemented genetic system is tested on the binary and real valued problem sets.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET POZDAN BAĞIMSIZ YUZ TANIMA Bu çalışmada pozdan bağımsız yüz tanıma yapılmıştır. Kullandığımız metod iki aşamalı olup, ilk aşamada yüzün hangi yöne döndüğü belirlenip ikinci aşamada da benzer tarafa bakan diğer yüzler arasında kimlik tesbiti yapılmıştır. Pozdan bağımsız yüz tanıma üzerinde kendi metodumuzu uygulayabilmek için kendi veri tabanımızı oluşturduk. Her kişiden yukarıya, aşağıya ve kameraya bakarak başım sağdan sola doğru çevirmesini istedik ve elde ettiğimiz resimleri dokuz ana yönde grupladık. Yüz verileri boyutunu indirgemek amacıyla, tanıma işlemine geçmeden önce her yüzün ortak dağılımın öz vektörlerine iz düşümünü aldık ve çıkan vektörleri kullandık. Önemli bileşenler yöntemi, doğrusal ayırtaç yöntemi ve gözeticisiz gruplama yöntemlerini kullandık. İlk iki doğrusal metod için iki değişik yöntem denedik: poz ayrımı yapılmadan bütün resimlerin aynı dağılımdan geldiğine dayanan 'Parametrik' yöntem ve resimlerin ayrı poz dağılımlarından geldiğine dayanan 'Poza bağlı' yöntem. Pozu belirlemek için girdinin dağılımdaki en yakın komşusunun yönüne baktık. Değişik uzaklık ölçütleri denedik. Sonuç olarak, poza bağlı yöntemin parametrik yönteme göre daha iyi olduğunu ve Doğrusal Ayırtaç Yönteminin Önemli Bileşenler Yöntemine göre daha başardı olduğunu gördük. Gözeticisiz gruplama metodlanndan C-Ortalama metodunun en iyi performansı dört tane ortalamayla verdiğini ve bu ortalama resimlerden iki tanesinin cepheden, diğer ikisinin de sağ ve sol profillerden çekilmiş resimlere benzedikleri görülmüştür. Yaptığımız deneyler poz bilgisini öncelikle kullanmanın sistemin performansını arttırdığı yönündedir. fÜkitEKÛGRElBi lüJiMJLii","IV ABSTRACT POSE INVARIANT FACE RECOGNITION The purpose of this work is recognition of human faces independent of the pose. We have used a two-fold method, where first, the viewing angle of the image is determined and then the identity of the person is found from the images classified into the same viewing angle. We have constructed our own database of subjects captured while looking in different directions. Each face image is labeled to belong to one of the nine directions. As the face image is high dimensional, we have used Principal Component Analysis to reduce the dimensionality. All the methods that are mentioned hereafter take this reduced data as input. We have tried Principal Component Analysis, Linear Discriminant Analysis and unsupervised clustering. For the two linear methods, we have tried two approaches: Parametrical, where all the images from all viewing angles are considered as belonging to the same distribution, and View-Based approach, where the images are classified according to their viewing angles first. To determine the viewing angle, k-Nearest Neighbor classifier is used. Different distance metrics are tried. It was seen that view-based approach performs better than the parametric approach and Linear Discriminant Analysis performs better than Principal Component Analysis. As unsupervised clustering method, we have used C-Means clustering. Hard C-means was seen to perform best when number of clusters is four. It was observed that two of the means resemble a frontal image and the other two are like profile images. Our experiments show that incorporating the viewing angle information increases the recognition performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET HÜCRESEL ŞEBEKELERDE SERVİS KALİTESİNİ KORUYAN ÇOKLU-YAYIN Internet'te sayıları giderek artan çoklu-ortam uygulamaları ve bunlara hareketli şebekelerden de erişim kolaylığının sağlanması, yeni şebeke mimarilerinin kurulmasını gerektirmektedir. Bu altyapı mimarileri kullanılan çoklu-yayın yöntemlerini ve servis kalitesini destekleyebilmelidir. Bu tezde, servis kalitesi korunmak kaydıyla hücresel şebekelerde çoklu-yayın problemi formüle edilip çözülmeye çalışılmıştır. Servis kalitesini etkileyen parametreler olarak, çoklu-yayının kaynak ve alıcıları arasındaki maksimum gecikme ile alıcıların gecikmeleri arasındaki fark seçilmiştir. Önerilen çözüm teknikleri, maksimum gecikme ve gecikme farkları sınırlandırılmışken ağ başarımının eniyilenmesini sağlamaya çalışmaktadır. Bu amaçla, telli şebekelerle telsiz şebekeleri bağlayan çoklu- yayın ağaçları kurulmuştur. Ayrıca bu ağaçlar, çoklu-yaym grubuna katılım, gruptan ayrılma, handover ve düğüm ya da hat düşmelerinden sonra da ayakta kalabilecek şekilde çözümler sunulmuştur. Yine bir çoklu-yayın grup üyesinin tek bir ana düğüm ya da birden fazla olası ana düğüm üzerinden çoklu-yayın ağacına bağlanmasının etkileri araştırılmıştır.","ABSTRACT MULTICAST ROUTING IN CELLULAR NETWORKS CONSIDERING QUALITY OF SERVICE Increasing multimedia applications on the Internet and flexibility of accessing these services over mobile networks created a necessity to build new architectures that are capable of supporting multicasting and QoS over mobile networks. In this thesis, we formulate and try to solve the problem of multicasting in cellular networks with the objective of optimizing the network performance while satisfying end to end delay and delay variation constraints. For this purpose, we construct a multicast tree that connects wired and wireless network elements. We also provide solutions to maintain the tree after various events such as joins, leaves, handovers, node and link failures. Moreover, we also investigate the effect of adding a mobile member via a single parent and via several potential parents."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GERÇEK ZAMANDA SANAL POSTER SUNUŞU İÇİN GERÇEKÇİ DAVRANIŞ ÜRETİMİ Bu tezin amacı gerçek zamanda sanal poster sunuşu için gerçekçi davranışların üretimidir. Bu, sanal insanların davranışlarının etkinliğini göstermeyi amaçlayan süregiden bir projenin parçasıdır. Sesle birlikte gerçekçi konuşma davranışlarının zaman çözümlemesini yapan gerçek zamanda çalışan bir planlayıcı gerçekleştirdik. Durum uzayı planlayıcısı, üretilen davranışların zaman planlamasında kullanıldı. Poster sunuşlarda en çok kullanılan davranışlar incelendi ve tanımlandı. Konuşmayla eşzamanlı el hareketleri üzerinde yoğunlaştık. Kendi davranış kalıbı kütüphanemizi ve aktivite tanım veritabanımızı oluşturduk. Davranışlar, daha küçük aktivitelerin bileşimi olarak tanımlanırlar; aktiviteler ise olayların birleşimidir. Davranış üreticinin nesneye dayalı tasarımı, gelecek geliştirmelere uygun bulunmuştur. Bütün modüller, kaynak kodundan bağımsız olarak metin dosyalarında tanımlanmıştır. Zaman çözümlemesi için her davranış kalıbı için geçici bağımlılık çizelgeleri tanımlanır. Davranış kalıbı kütüphanelerinin oluşturulması sırasında bu çizelgeler, tek geçişte zaman çözümlenmesinin yapılmasına imkan sağlayan sıralı bağımlılık tablolarına dönüştürülür. Bu tez insan davranışlarının derinlemesine anlaşılmasının sanal insanların animasyonunun doğal ve inanılır olmasındaki önemini vurguluyor ve gerçekçi davranış üretilmesi için bir yöntem öneriyor. Bu yöntem, gerçekleştirilen bir sanal poster sunuşu sisteminde kullanılmıştır.","IV ABSTRACT A REALISTIC BEHAVIOR GENERATION FOR REAL-TIME VIRTUAL POSTER PRESENTER The purpose of this thesis is to generate realistic behavior for real-time poster presenter. This is an ongoing project to demonstrate the effectiveness of behavior of virtual humans. We have implemented a real time planner, which involves time resolution for believable co-speech conversational behavior. State Space Planner is used for this time planning of the generated behaviors. Most commonly used behaviors for poster presentations are investigated and defined. We concentrated on hand gestures synchronized with speech. We generated our own Behavior Template Library and Activity Definitions Database. Behaviors are defined as a combination of small Activities, whereas Activities are defined as a combination of Events. Object oriented design of the behavior generator is very suitable for future improvements. All of the modules are defined within text files independent of the source code. For the time resolution temporary dependency graphs are defined for each behavior template. During the generation of behavior template library those graphs are converted into sorted dependency tables, which allow time resolution in only one pass. This thesis argues that deep understanding of human behavior is crucial for the virtual human animation to be natural and believable and proposes a method to generate behavior. This method has been used in the implementation of a virtual human presenter."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"genetik algoritmalar kullanarak peptidlerde motif bulma Alıcı moleküllere bağlanan peptid motiflerini bulmak, aşı ve ilaç dizaynında çok önemlidir. Bunun en önemli uygulaması ise MHC-peptid problemidir. Bu çalışmada belirli MHC moleküllerine bağlanan peptid motiflerine karar vermek için regresyon analizi kullanıldı. Geleneksel regresyon analizi metodlan ile her zaman optimum sonuç yakalanamadığı için optimum regresyon doğrusunu bulmak için genetik algoritma (GA) teknikleri kullanıldı. GA ile bulunan optimum regresyon doğrusu peptid motifini belirlemekle beraber MHC moleküllerinde, peptidlerin bu moleküllere bağlanması için gerekli olan etkenleri de bulmaktadır. GA'nm yeterliliği değişik uygulama teknikleri ile test edilmiş ve bu problem için optimum parametre seti belirlenmiştir. Sonuçlar, peptid motifinin ikinci pozisyonunun bulunmasında yüzde 95 birebir uyumluluk ve yüzde 100, bir standart sapma ile uyumluluk göstermiştir. Son pozisyonu iki regresyon doğrusuyla açıklayabilmek için veri ikiye bölünmüştür. İlk regresyon doğrusu ile peptid motifinin son pozisyonunun bulunmasında yüzde 80, ikinci regresyon doğrusu ile ise yüzde 75 doğru tahmin yapılabilmiştir.","Finding the ligand motifs binding to the receptor molecules is crucial in vaccine and drug design, especially for the MHC-peptide problem. In this work, for determining the peptide motifs binding to specific MHC molecules, we have used regression analysis. In order to find the the optimum regression line, genetic algorithm (GA) techniques are used because in traditional regression analysis methods, you may not be able to reach the optimum solution. The optimum regression line generated by the GA also determines the factors on the MHC molecules mat makes the peptide bind to these MHC molecules. The efficiency of the GA is tested by doing several tests on its different parameters, and the optimum set of parameters are determined for this problem. Results have shown that we are able to predict second position of a peptide motif with 95 per cent exact match or 100 per cent close match within one standard deviation of the predicted equation. We have divided last position's data into two parts in order to explain it with two regression lines. Predictions for the last position of the peptide motif with the first regression line resulted in 80 per cent exact match. Second regression line resulted in 75 per cent exact match."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DENEYSEL İKİ TANKLI BİR SİSTEMİN DAYANIKLI DENETİMİ Bu çalışmada geleneksel PI ve dayanıklı //* denetim yöntemleriyle tasarlanan çokdeğişkenli denetleyiciler iki tanktan oluşan deneysel bir düzenek üzerinde denendi. Çokdeğişkenli sistemlerle ve dayanıklık kavramlarıyla ilgili kısa bir özet verildikten sonra deneysel düzeneğin modeli geliştirildi ve çokdeğişkenli analiz yöntemleriyle modelin analizi yapıldı. Sistemin etkileşimliliği ve yönülüğü belirlendi. Doğrusal model deneysel düzenek üzerinde birim basamak giriş deneyleri yapılarak doğrulandı. Sürücülerdeki ve modeldeki belirsizlikler incelendi. PI denetleyiciler klasik tasarım yöntemleriyle, // optimal denetleyiciler D-K iterasyonu kullanılarak else edildi, ju optimal denetleyicilerin uygulanabilir halleri model indirgeme yöntemleri kullanılarak elde edildi. Denetleyicilerin kullanımı ile ilgili konular, sürücülerin doyma sınırlaması vurgulanarak incelendi. Simulasyon sonuçları ve deneysel veriler sunuldu ve denetleyicilerin genel bir karşılaştırılması verildi. Köşegen PI denetleyicisin genel olarak iyi bir performans sergilediği, fakat performansın giriş yönlülüğüne bağımlı olarak kötüleştiği görüldü. Durağan durum ayrıştırması ile elde edilen PI denetleyicisinin kötü bir performans verdiği ve genel olarak gerçek uygulamalar için tercih edilemeyeceği görüldü. Dayanıklı ju optimal denetleyicilerin en iyi performansı sergiledikleri ve iyi dayanıklılık özellikleri sergiledikleri görüldü. 1C itoSESfeOta OflDBH","IV ABSTRACT ROBUST CONTROL OF AN EXPERIMENTAL TWO TANK SYSTEM In this study, multivariable controllers designed with conventional PI controllers and //-optimal controllers are implemented on an experimental two-tank system. After a brief introduction to MIMO systems and robustness, the model of the plant is derived. The model is analysed using multivariable analysis concepts. The interaction inside plant and the directionality is studied. The linear model is verified by step response experiments done on the experimental system. The uncertainties associated with the actuators and inherent inside the plant are investigated. The conventional PI controllers are designed using multivariable schemes. The p. optimal controllers are designed using D-K iteration and the final controllers that are used are obtained by using model reduction methods. The issues associated with the implementation for both PI controllers and ju optimal controllers are presented emphasizing the saturation anti-windup schemes. The simulated and experimental results are presented and the comparison of the controllers is given. The simple diagonal PI controller performs reasonably well; however performance degradation is observed depending on the reference direction. The steady state decoupling PI controller fails to give reasonable performance. Mostly the inverse based controllers are not preferred in practical applications. The robust ju optimal controllers give the best performance and they posses good robustness properties."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET SÖZ DİZİMSEL İNCELEME YÖNTEMLERİNİN DOĞRULUK İSPATLERININ ORTAK YAPISI ÜZERİNE KARŞILAŞTIRMALI ÖN ARAŞTIRMA Söz dizimsel inceleme yöntemleri, belli bir gramer ve belli bir kelime için, bu kelimenin verilen gramerden türetilip türetilemiyeceğine karar veren araçlardır. Başka bir deyişle, bu kelimenin verilen gramerin oluşturduğu dile ait olup olmadığına karar verirler. Bunun için, hangi söz dizimsel inceleme yöntemi kullanılırsa kullanılsın, hepsinin de sağlaması gereken önemli bir özellik vardır: doğruluk özelliği. Bütün söz dizimsel inceleme yöntemleri aynı amacı güttüğüne göre (verilen kelimenin dile ait olup olmadığına karar vermek), ve bu amacı yerine getirmek için hepsi de aynı gramer, aynı dil ile uğraştığına göre, doğruluk ispatlarının benzer olabileceğini düşündük. Bu yüksek lisans tez çalışmasının ana konusu böyle bir benzerliğin olup olmadığını araştırmak. Bunun için üç ayrı söz dizimsel inceleme yöntemini ele aldık, ve bunların doğruluk ispatlarını tekrar baştan yaparak, karşılaştırdık. Böylece, gerçekten benzerlik olup olmadığını tespit etmeye çalıştık Bulmuş olduğumuz benzerlikler bize tüm söz dizimsel inceleme yöntemine ortak genel bir doğruluk ispatı yapısı olabileceğine dair kuvvetli ip uçları vermektedir.","ABSTRACT AN INVESTIGATION OF THE COMMON STRUCTURE UNDERLYING THE CORRECTNESS AND COMPLETENESS PROOFS OF PARSING ALGORITHMS Parsing algorithms are methods that permit, given a string and a grammar, to decide if this string is obtainable from the grammar. Whatever the method, all parsing algorithms have to satisfy two properties: soundness and completeness. It seems natural to think that since all parsing algorithms are dealing with the same entities (grammar, language, recognizer...), with the same aim (to see if the given string is in the language), their correctness proofs should be similar. The work done in this MS thesis is a comparative analysis on three parsing algorithms. In order to see if really there exist similarities among the correctness proofs of different parsing algorithms, we tried to rewrite those proofs for the analyzed algorithms, in a homogeneous manner. The similarities found among the correctness proofs make us think that there is a generic proof architecture lying under all correctness proofs of all context free grammar architecture."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET MİKROİŞLEMCİ MİMARİSİ İÇİN BİLGİSAYAR DESTEKLİ BİR EĞİTİM ARACI Temel komut kümesi ve kayıt bellek modeli, bilgisayar mimarisinin iki önemli özelliğidir. Kayıt bellek ve operatörlerin gerçeklenme ve birbirlerine bağlanma şekline ve komutların bu yapıda çalışma planının kararlaştırılmasına donanım organizasyonu denir. Aynı mimari farklı donanım organizasyonları ile tanımlanabilir. Bu da farklı verimlilik/maliyet oranlan doğurur. Donanım organizasyonlarında edinilmiş tecrübeler tasarım kuralları ve tasanm araçları içine entegre edilebilmektedir. Ancak donanım organizasyonu çoğunlukla interaktif bir işlemdir. Komut, öngörülen donanım organizasyonunda benzetimle denenir, sonuçlar yorumlanır, donanım organizasyonunda değişiklikler yapılır ve komut tekrar benzetimle denenir. Bu tez çalışmasında fiziksel donanım yapısının ve mikro-komutlann formal gösterimin içeren kullanıcı dostu görsel bir simulator gerçeklenmiştir. Ayrıca komutların öngörülen mimari üzerinde en iyiye yalan zamanda bitimini sağlayacak mikrokodu üretmek için bir bulgusal (heuristic) algoritma geliştirilmiştir. Geliştirilmiş olan sistemin eğitsel bir paket olması amaçlanmıştır. Bu sebepten hem tanımlamalarda hem de benzetimde görsellik ön planda tutulmuştur. Geliştirilen araç, bulgusal öngörülerin önem katsayıları değiştirilip tekrar çalıştırılarak komutlar için en iyiye yakın mikrokod derlemesinde kullanılabilir. Ayrıca simülasyon sonucunda gözlenen problem noktalarını rahatlatmak üzere bir kayıt bellek veya veri yolu eklemekle, mimarinin ince ayarının yapılmasına da yarar.","IV ABSTRACT A COMPUTER AIDED INSTRUCTION (CAI) TOOL FOR CPU MICRO ARCHITECTURE Basic instruction set and register model are two important characteristics of computer architecture. The way local memory (registers) and operators are implemented and interconnected and mapping of instruction execution on this structure is called hardware organization. An architecture may be implemented by different hardware organizations, which yields different performance/cost ratios. Although past experience in hardware organization may be embedded into guidelines like design rules and design tools, the process is mostly iterative, i.e. instruction execution is simulated on proposed hardware organization, results interpreted, modifications are done and simulation is conducted again. In this thesis work a visual simulator is developed which allows the representation of both the instructions and the physical structure via a user-friendly interface. Furthermore a heuristic mapper is developed and embedded which may be used as a suboptimal microcode generator prior to simulation. The developed system is intended to be used as an educational package, Therefore visuality in both representation and simulation is emphasized. The tool may be used to find a near optimal microcode for instruction execution via iterative simulation and weight adjustment for heuristics. An alternative use of the tool is to fine-tune the architecture via adding a register or link to relieve bottlenecks observed as a result of simulation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"İşlem gücü ile çoğul ortam ve telsiz iletişimlerinde sivil alanda gerçekleştirilen ilerlemeler, daha sağlam ve etkin muharebe iletişim sistemlerinin geliştirilmesi için yeni olanaklar yaratmaktadır. Bununla beraber, askeri ve sivil iletişim arasında bazı temel farklılıklar bulunmaktadır. Bu farklılıklardan en önemli iki tanesini, muharebe sahasındaki düşmanca ortam ve acil konuşlandırılma gereksinimi olarak sıralayabiliriz. Çalışmamızda, bu temel farklılıklara rağmen, üçüncü nesil PCS sistemleri olarak adlandırılan, kullanıma sunulmuş ve geliştirilmeye devam edilen sivil iletişim teknolojilerinin askeri ortama nasıl uyarlanabileceğim inceliyoruz. İletişim yapılacak alanı, bir referans noktasından başlayarak düzgün şekilli ve sabit boyutlu sanal hücrelerle kapladığımız, Sanal Hücre Kalıbı (SHK) yaklaşımını bu amaca hizmet edecek bir çözüm olarak öneriyoruz. Hem hücresel hem de ""ad hoc"" teknikleri kullandığımız karışık çok katmanlı bir ağda, sanal hücre kalıbını kullanarak telsiz kaynaklan yönetiyoruz. Taktik iletişim sistemlerinin başanmlannm değerlendirilmesi amacıyla bir benzetim yöntemi de öneriyoruz. Bu yöntemde, önceden gerçekleştirilen bilgisayar destekli askeri tatbikatlarda girilen emirleri, çok sayıdaki birliğe ait hareket, görev ve durum gibi verileri toplayan bir yapıcı (muharebe) model kullanarak tekrar işletmekteyiz. Daha sonra toplanan bu veriler daha da detaylandınlarak, basan ölçütlerimize ait değerleri üreten benzetimi sürmekte kullanılmaktadır. Sistemi değerlendiren başanm ölçümleri, SHK' dan yararlanılarak geliştirilen mimarinin, acil konuşlandınlma ihtiyacını karşıladığım ve kabul edilebilir bir hizmet derecesine sahip olduğunu göstermektedir.","The advances in high-speed computations, multimedia and wireless communications promise new opportunities to develop more robust and agile battlefield communications systems. However, there are some major distinctions between the military and commercial communications. We can enumerate the most basic two of them as the hostile environment in battlefield, and the rapid deployment requirement. In our study, we discuss how to employ emerged and evolving civilian commercial technologies, namely the third generation (3G) Personal Communications Services (PCS) techniques for military communications in spite of the existence of such distinctions. We propose an approach called Virtual Cell Layout (VCL) in which the communications area is tessellated with regularly shaped fixed virtual cells starting from a geographic reference location. The radio resources are managed in a multitier hybrid network by employing both cellular and ad hoc techniques and using VCL. We also propose a simulation approach for the performance evaluation of the tactical communications systems. In this approach, the commands entered during the military computer aided exercises are replayed by running a constructive (combat) model which generates mobility, posture and status data for a number of units, then these data are enhanced and drive a simulation which produces the data related to the performance metrics. The evaluated performance of the system shows that the VCL based architecture satisfies the rapid deployment requirement and gives an acceptable grade of service."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"r ÖZET Kapalı alanlarda taşıma lojistiğinde, otomatik güdümlü araçlar gibi hareketli araçlar için dinamik kontrol algoritması tasarlanmış ve uygulanmıştır. Algoritma, görüntü işleme fonksiyonları üzerine inşaa edilmiştir. Hareketli araç üzerindeki kameradan gelen anlık görüntü kameranın kalibrasyonu sırasında hesap edilmiş parametrelere, hareket ve ortamdaki hareketsiz engellerin yer bilgilerine göre katsayılara gore işlenerek hareketin bir basamak sonrasındaki görüntü hesap edilmeye çalışılır. Kameranın kalibrasyonu Song De Ma'nın oto-kalibrasyon tekniği kullanılarak gerçekleştirilmiştir. Kontrol algoritmamız S.D. Köprülü'nün rota belirleme algoritması ile birleştirilmiştir. Nesne yönelimli programlama teknikleri kullanılarak yazılan programların uygulanması için 3 boyutlu bir simulasyon hazırlanmış ve sanal bir ortamda sanal bir aracın hareket etmesi sağlanmıştır.","IV ABSTRACT A dynamic control of a moving vehicle, like an automatic guided vehicle, AGV, on a planned path is designed and implemented for internal company transport logistics. The approach is based on real time image processing. The present image is processed to estimate the next image that the vehicle will face with according to the parameters that are calculated while the vehicle is calibrating its camera. Song De Ma's self-calibration technique is also implemented as a part of the control mechanism. This control mechanism is integrated with S.D. Köprülü's path planning algorithm. A virtual environment with a virtual moving vehicle is simulated to try our control mechanism that is implemented with an object-oriented software."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET GENETİK ALGORİTMA KULLANARAK BULANIK MANTIĞA DAYALI ROBOT KOLU KONTROL YÖNTEMİ GELİŞTİRİLMESİ Modern kontrol teorisi tüm iyi tanımlanmış sistemler için başarılı sonuçlar vermektedir fakat bu yaklaşım moddelenmesi zor olan, doğrusal olmayan veya değişkenliği yüksek ortamlarda bulunan birçok mühendislik uygulamasında sorunlarla karşılaşmaktadır. Otomatik kontrol sistemlerine insan zekasının eklenmesi bu sistemleri klasik kontrol sistemlerine göre aşağıdaki noktalardan daha avantajlı hale getirmektedir: niceliği dayalı modellere daha az bağımlı olma, doğal karar verme, öğrenme kabiliyeti, daha yüksek serbestlik derecesi ve uygulama kolaylığı. Robot kontrolü zor bir işlemdir ve robotlar kontrol hassasiyeti çok önemli iyi tanımlanmış deterministik sistemler olduklarından genellikle PID kontrol sistemleri kullanılmaktadır. Öte yandan ters kinematik hesaplamaları karmaşıklık derecesi yüksek işlemler olduklarından oldukça uzun hesaplama zamanı gerektirmektedirler. Robot kontrolünde bulanık mantığa dayalı bir kontrol sisteminin kullanılması ters kinematik hesaplan yapma gerekliliğim ortadan kaldırmaktadır. Kontrol sisteminin öğrenme mekanizmasında genetik algoritmalar sayesinde belli bir sayıdaki nesilden en iyi bireyin kullanılmış olması performansı darttırmaktadır. Bu çalışmada üç eksenli bir robotu kontrol edebilen genetik algoritma yardımıyla öğrenen bulanık mantığa dayalı bir sistem geliştirilmiştir. Genetik algoritmalar kontrol sistemine kuralları öğretmede kullanılmışlardır.","IV ABSTRACT DEVELOPMENT OF A FUZZY CONTROLLER FOR A ROBOT ARM USING EVOLUTIONARY ALGORITHMS Modern control theory has been successful for well defined systems. This approach, however encounters problems in many engineering applications where systems to be controlled are difficult to model, have a strong non-linearity or are embedded in a changing environment with uncertainty. Incorporating human intelligence into automatic control systems make them more advantageous over conventional control schemes in the following aspects: less dependency on quantitative models, natural decision making, learning capability, greater degree of autonomy and ease of implementation. Robot control is a difficult task generally PED controllers are being used for robot control because the robot is a well-defined deterministic system and precision is extremely important for the controller. On the other hand inverse kinematics computation is an operation with high complexity which requires reasonable computational time. Using a fuzzy controller for robot control eliminates the need for inverse kinematics calculation, what is more training the fuzzy controller with genetic sets will yield the best performance since using genetic operators the fittest elements in the population can be produced in several generations. In this work a fuzzy controller for a three-link robot has been developed. Evolutionary algorithms have been used in the generation of the rulebase of the controller."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmada, kalp deformasyonlarının teşhisi için kalbin sol ventrikülünün üç boyutlu örtük çokterimlilerle modellenmesi amaçlanmıştır. Sol ventrikülden üç boyutlu veri alınması için, manyetik rezonans (MR) ve bilgisayarlı tomografi (CT) görüntüleri kullanılmaktadır. Bu veriler kullanılarak örtük çokterimlilerle yapılan modelleme, 4- dereceli örtük çokterimlilerin bile sol ventrikülün ve kalbin sağlıklı çalışması için gerekli olan asimetrik konik şeklini 2 ve 3 boyutta başarıyla yansıttığını göstermiştir. Bu çalışma insan kalbinin örtük çokterimlilerle modellenmesini, elde edilen 2 ve 3 boyutlu modellerin görüntülenmesini, ilgili değişmezlerin hesaplanmasını ve bu değişmezlere dayanan bir teşhis algoritmasının belirlenmesini içermektedir. Ayrıca, insan ve köpek kalplerinden elde edilen değişmezler arasında olası bir benzerlik de incelenmiştir.","IV ABSTRACT This study aims modeling of left ventricles of human hearts with 2D and 3D implicit polynomials for inspection of heart deformations. Extracting 3D information of left ventricle is made possible by utilization of magnetic resonance (MR) and computerized tomography (CT) technologies. Our research has shown that 4th degree impicit polynomials are adequate both in 2D and 3D for representing the shape of left ventricule and the asymmetric conic shape of the heart for proper functioning. This study consists of a throughout elaboration starting from modeling of human hearts with implicit polynomials, visualization of these 2D and 3D implicit polynomials, calculation of euclidean, affine, and projective invariants and realization of an inspection based on these invariants. Also, a study on any resemblance between the invariants extracted from human and dog hearts is conducted."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Gürültü bağışıklığı, sistem-model uyumsuzluklarının aşılması ve yapısal olan ya da olmayan belirsizliklerin bertaraf edilmesi sistem ve kontrol mühendisliği uygulamalarında sıkça karşılaşılan önemli sorunlardır. Bahsedilen güçlüklerin olumsuz etkilerinin azaltılmasının ve iyi bir izleme hassasiyetinin elde edilmesinin bir yolu özellikle kesinlik ve hassasiyet içermeyen problemler için iyi yapılandırılmış çözümler öneren değişken yapılı sistemler kuramının tekniklerinin kullanımıdır. Bu çalışmada işlemsel akıl içeren sistemlerin eğitiminde değişken yapılı sistemler kuramına dayalı stratejiler ele alınmaktadır. Belirtilen güçlüklerin aşılması için iki yaklaşım geliştirilmiş ve öğrenme katsayısı seçimi problemi kayma kipli denetim açısından incelenmiştir. İlk yaklaşımda dinamik bir parametre uyarlama kuralı türetilmekte ve algoritmanın kontrol mühendisliği açısından uygulanabilirliği tartışılmaktadır. Yapılan analiz, sistemin kayma kipli denetimi ile denetleyici içerisinde kayma kipli öğrenme arasındaki denklik koşullarının çıkarsanmasım amaçlamaktadır. İkinci yöntem genişletilmiş bir Lyapunov fonksiyonunun seçimi ile oluşturulmaktadır. Bu yöntemde karesel hata ölçütüne ek olarak maliyet ölçütünün uyarlanabilir parametrelere duyarlılığı da en aza indirilmektedir. Son olarak türeve dayalı üç değişik parametre uyarlama kuralı için öğrenme katsayısının seçimi üzerinde durulmaktadır. Buradaki seçimin amacı sistemi bir kayma kipine sürerken denetleyici çıkışını da benzer bir rejime zorlamaktır. Geliştirilen yöntemlerin başarımı, iki hareket serbestisine sahip, doğrudan sürümlü bir SCARA robotunun dinamik modeli üzerinde değerlendirilmektedir ve sistem denklemlerinin bilinmediği varsayılmaktadır. Benzetimlerde gözlem gürültüsünün ve değişken yük koşullarının olumsuz etkileri de irdelenmiştir.","Noise rejection, handling the plant-model mismatches and alleviation of structured or unstructured uncertainties constitute prime challenges that are frequently encountered in the practice of systems and control engineering. One way of reducing the adverse effects of the stated difficulties and obtaining a good tracking precision is to utilize the techniques of variable structure systems theory, which offers well formulated solutions particularly to problems containing uncertainty and imprecision. In this thesis, variable structure systems theory based training strategies of computationally intelligent systems are discussed. Two approaches are developed for alleviating the above mentioned difficulties. Additionally, the learning rate selection problem is treated from the point of variable structure control. In the first approach described, a dynamic parameter adaptation law is derived and the applicability of the algorithm is discussed. The analysis presented aims to extract the conditions for establishing equivalence between sliding mode control of the plant and sliding mode learning in the controller. The second method is based on the selection of an extended Lyapunov function, by the use of which the sensitivity of the cost measure to the adjustable parameters are minimized together with the half squared error measure. Lastly the selection of the learning rate for three different gradient based parameter tuning strategies are discussed. The objective of the learning rate selection is to drive the plant to a sliding mode while the output of the controller is driven to a similar regime. The performances of the methods developed are assessed on the dynamic model of a two degrees of freedom direct drive SCARA robotic manipulator, whose dynamic equations are assumed to be unknown throughout the results presented. In the simulations, the alleviation of the adverse effects of observation noise and varying payload conditions are studied."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET KOMUTA VE KONTROL SİSTEMLERİ İÇİN ÇORBA TABANLI ALTYAPI YAZILIMI Askeri platformlarda kullanılan komuta ve kontrol sistemleri (KKS) gelişip, karmaşık bir hal aldıkça, güvenilir, değiştirilebilirin-, ölçeklenebilinir, platform ve işletim sistemlerinden bağımsız, dağıtık ortamda çalışan ve belli bir kişi / kuruma ait olmayan program geliştirme ortamları sistem mühendisleri ve geliştiricileri açısından önem kazanmaktadır. Halihazırda bu sistemlerde kullanılan yazılım mimarileri, bir çok kullanışlı özelliklere sahip olmalarına rağmen, KKS isterlerine tam cevap verecek nitelikte değildirler. Bu tez ile, Ortak Nesne İstek Aracısı Mimarisi (Common Object Request Broker Arcbitecture-CORBA) de kullanılarak tasarlanan, komuta ve kontrol sistemlerinin güvenilirlik ve hataya dayamlırlık isterlerine cevap verecek yazılım geliştirme altyapısı üzerinde yapılan çalışmalar sunulmaktadır. Geliştirilen altyapı, ÇORBA tarafından belirlenen servislere ilave olarak bazı imkanlar ile komuta ve kontrol yazalım birimlerinin kolay bir şekilde sisteme dahil edilmesini veya sistemden çıkarılmasını sağlayan bir ortam sunmaktadır. Ayrıca tez kapsamında, bu altyapıyı kullanacak şekilde tasarlanmış bütün bir komuta ve kontrol sistemine ilişkin yazılım mimarisi de anlatılmaktadır. Takdim edilen ÇORBA tabanlı altyapı yazılımı (CORBIS) uygulama yazılımlarına dağıtılmış ortamda, hızlı veri ulaşımı, veri sorgulama, değişik anahtar değerlerine göre veri depolama, ve olaylardan tetiklenebilme imkanları sağlayan bir ortam sunmaktadır. Bu konuda tez kapsamında ortaya konulan konseptlerin geçerliliğini gösteren (""proof of concept"" seviyesindeki) yazalım, CORBIS'in belirtilen servisleri yakın gerçek zamanda iyi performans gerektiren uygulama yazılımlanna sağlayabildiğim göstermiştir. Sunduğu ilave imkanlar yarımda, büyük ölçekli sistemlerde CORBIS'in mevcut ÇORBA uygulamalarına oranla daha iyi performans gösterdiği ve daha iyi ölçeklenebildiği tespit edilmiştir.","IV ABSTRACT A CORBA BASED INFRASTRUCTURE FOR COMMAND AND CONTROL SYSTEMS As command and control systems (CCS) in military platforms are getting larger and more complex, need for reliable, modifiable, scalable, platform and operating system independent, distributed and non-proprietary programming environments become important for system engineers and developers. Although there are some architectures available offering many useful features, none of them fully complies with the requirements of CCS domain. In this thesis, an infrastructure is proposed to satisfy the reliability and fault- tolerancy requirements of a CCS software architecture over Common Object Request Broker Architecture(CORBA). The infrastructure provides some additional services over CORBA and an environment which enables run-time reconfiguration of the command and control system software modules. An overall software architecture that utilizes this infrastructure in CCS domain is also presented. The proposed CORBA based infrastructure (CORBIS) provides an event based system enriched with fast access to the data, query and view services over data, and typed event notification capabilities. Our proof of concept level implementation showed that CORBIS can provide the proposed services for performance sensitive applications in CCS. In addition to extra services that it provides, CORBIS performs and scales better than the current commercial CORBA implementations in large-scale systems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tezde, tek değişkenli, doğrusal, ve doğrusal olmayan çok değişkenli karar ağaç kurma metodlan karşılaştırıldı. Tek değişkenli karar ağaçları için örnek olarak ID3, çok değişkenli karar ağaçlan için CART yöntemi kullanıldı. Doğrusal ve doğrusal olmayan metodlar içinse karar düğümünde değişik sinir ağlan yapılarından faydalanıldı. Ayrıca Fisher' in doğrusal ayırma analizinin çok değişkenli karar ağacı oluşturulmasında kullanılması önerildi. Tek değişkenli karar ağaçlan her karar düğümünde tek değişkenin değerine bakarak eksenlere dik bölmeler yaparlar. Doğrusal karar ağaçlarında ise her dalda giriş uzayı rasgele bir düzlemle bölünür. Doğrusal olmayan karar ağaçlarında ise çok katmanlı sinir ağlan giriş uzayını rasgele böler. Bu tezde melez ağaçlar önerildi. Bu ağaçlarda karar düğümü doğrusal veya değildir. Kararın doğrusal olup olmamasına ise bir istatistik testinin sonucuna bakılarak karar verilmektedir. Doğrusal ayırma analizi ile doğrusal çok değişkenli karar ağaçlan yapay sinir ağı temelli karar ağaçlarından çok daha hızlı öğrenilir. Sonuçlanınız gösteriyor ki, eğer veri kümesi küçük ve bu kümede az smıf varsa, tek değişkenli metod yeterli olabilir ve ID3 çok değişkenli metodlardan daha iyi performans gösterir. ID3 hızlı ve kolay öğrenir, kurallan da kolayca yorumlanabilir. Eğer değişkenler birbiriyle çok ilişkiliyse, tek değişkenli metod yeterli olmayabilir ve çok değişkenli metodlan kullanabiliriz. Bu tezde gösterildi ki ID-LDA metodu CART'tan daha başanlı, daha küçük ağaçlar üretmekte ve daha az zaman harcamaktadır. Aynı zamanda ID-LP den daha hızlı ve eşit başanlıdır. ID-LDA ID3 ve CART'tan daha küçük ağaçlar üretir. Bu da gösteriyor ki çok değişkenli ağaç üretmek için ID-LDA CART' a göre tercih edilebilir ve eğer zaman önemli ise ID-LP'ye gore de tercih edilebilir.","IV ABSTRACT In this thesis, we detail and compare univariate, linear and nonlinear decision tree methods using a set of simulations on twenty standard data sets. For univariate decision tree methods, we have used the ID3 algorithm and for multivariate decision tree methods, we have used the CART algorithm. For linear and nonlinear methods, we have used neural networks at each decision node. We also propose to use the LDA algorithm in constructing linear multivariate decision trees. Univariate decision trees at each decision node consider the value of only one feature leading to axis-aligned splits. In a linear multivariate decision tree, each decision node divides the input space into two with an arbitrary hyperplane leading to oblique splits. In a nonlinear one, a multilayer perceptron at each node divides the input space arbitrarily, at the expense of increased complexity. We propose hybrid trees where the decision node may be linear or nonlinear depending on the outcome of a statistical test on accuracy. We also propose to use linear discriminant analysis at each decision node. Our results indicate that if the data set is small and has few classes, then a univariate technique does not overfit and can be sufficient and the univariate ID3 has better performance than multivariate linear methods. ID3 learns fast, learns simple and interpretable rules. If the variables are highly correlated, then the univariate method is not sufficient and we may resort to multivariate methods. We have shown that ID-LDA has better performance than CART in terms of accuracy, node size and very significantly in learning time. It has also smaller learning time than ID-LP and the same accuracy. ID-LDA generates smaller trees than ID3 and CART. This shows that to generate a linear multivariate tree, using ID-LDA is preferable over CART, and may be preferable over ID- LP if learning time is critical. tC YÜKSEKÖ?RETİM KURUUj DOKÜMANTASYON MERKgg"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"SERVİS KALİTESİ GEREKTİREN UYGULAMALAR İÇİN ÇOKLU-YAYIN ÖZET Dağılmış gerçek zamanlı çoklu-ortam uygulamalarına olan ilgi, yüksek hızlı haberleşme ağlarının gelişmesi ve yaygınlaşmasıyla her geçen gün artmaktadır. Çoklu- yaym teknolojisi bu uygulamaların band genişliği gibi eldeki kaynakların verimli kullanmasınına olanak sağlar. Servis kalitesi, hızla yaygınlaşan bu uygulamalar için vazgeçilmez bir ihtiyaçtır. Bu çalışmada servis kalitesinin önemli olduğu uygulamalar için bir çoklu-yayın algoritması üzerinde çalışılmıştır. Servis kalitesini etkileyen parametreler olarak, çoklu-yayımn kaynak ve alıcıları arasındaki maksimum gecikme ile alıcıların gecikmeleri arasındaki fark seçilmiştir. Önerilen algoritma maksimum gecikme sınırlandırılmışken, alıcılar arasındaki gecikme farkının azaltılması problemini çözmeye çalışmaktadır. Ayrıca, yapay zekâ tekniklerinden biri olan genetik algoritma kullanılarak problem çözümünün kalitesi araştırılmıştır. Uygulanan yöntemler değerlendirilmiş ve değişik parametrelerin çözüme etkileri incelenmiştir.","IV MULTICAST ROUTING FOR APPLICATIONS REQUIRING QUALITY OF SERVICE ABSTRACT With the advances in high speed networking and Internet connectivity, there is an explosively growing interest for the distributed real-time multimedia applications. Multicast technology allows these applications to use the resources efficiently, without overloading the network infrastructure. All of these emerging multimedia applications require a certain Quality of Service (QoS) to be satisfied. In this study, a multicast routing algorithm for applications requiring QoS is considered. The end-to-end delay and the delay variation were selected as the quality of service parameters. A source-based multicast routing algorithm is proposed for multicast trees with lower delay variation satisfying an end-to-end delay constraint. A genetic algorithm is also used for solving the same problem for comparison purposes. Performances of the proposed algorithms are evaluated and effect of different parameters on the quality of results are investigated."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET ELEKTRONİK MARKETLER İÇİN BİR KULLANICI ARAYÜZÜ AJANININ TASARIMI VE GERÇEKLEŞTİRİLMESİ Bu tez kapsamında, MOPPET ismi verilen ajan tabanlı iş akışlarını kullanan bir elektronik market için kullanıcı arayüzü ajanı önerilmektedir. İş akışı sistemlerinin sağladığı ""abstraction"" sayesinde elektronik ticaret işlemlerinin değişik kullanıcılara göre ayarlanması mümkün olmaktadır. MOPPET kullanıcı arayüzü ajanı, kullanıcılara tekrarlanan yada zaman kaybettiren işlerin kolaylıkla ve en verimli şekilde yapılmasında yardım eden asistan yada ajanın gerekli fonksiyonlarını yerine getirmek amacına sahiptir. Bunlara ek olarak, bu kullanıcı arayüzü ajanı, kullanıcılara iş akışı şablonlarının adapte edilebilmesi için onların gereksinimlerini alan grafiksel kullanıcı arayüzleri sağlamaktadır. Önerilen sistemde, bütün veri alışverişi, sadelik, açık ve birlikte çalışabilir ve düzenlilik sunabilmek amacı ile XML( Geliştirilebilir İşaretleme Dili) ile yapılmaktadır. Uygulamanın metadatası, RDF(Kaynak Tanımlama Framework) ile tanımlanmaktadır. DTD (Dokuman Çeşit Tanımlaması) ve XML şema tanımlama standartları, doküman içeriğininin dağıtımını yapmak için sisteme ek fonksiyonlar katmaktadır.","ABSTRACT DESIGN AND IMPLEMENTATION OF A USER INTERFACE AGENT FOR AN OPEN MARKETPLACE In this thesis, a user inteface agent architecture for an electronic marketplace called MOPPET, where the commerce processes in the marketplace are modelled as adaptable agent-based workflows, is proposed. The higher level of abstraction provided by the workflow technology makes the customization of electronic commerce processes possible for different users. MOPPET user interface agent addresses the need for computer based assistants or agents that cooperate with users, helping them perform tedious, repetitive or time consuming tasks more easily and efficiently. Additionally, this user interface agent architecture provides graphical user interfaces to their users and gets the requirements of the users to compose workflow definitions by adapting the existing workflow templates. In the proposed architecture all data exchanges are realized through XML (extensible Markup Language) providing uniformity, simplicity and a highly open an interoperable architecture. Metadata of activities are expressed through RDF (Resource Description Framework). DTD and XML Schema standards provide a number of additional functions that make contributions to document content. tc vvKMKi&kntsi m^ms"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET IMKB 100 DEĞER AĞIRLIKLI ENDEKSİNİN VE VARYANSININ BULANIK MANTIK VE SİNİR AĞLARI YAPISI İLE TAHMİNİ Bu çalışmada, ekonomik zaman serilerini bulanık mantık yaklaşımı ile sinir ağlan yapışım kullanarak analiz ettik. Türkiye gibi gelişmekte olan pazarlarda mevcut olan değişkenliğe uyum sağlayabilecek bir yapı oluşturmaya çalıştık. Problemimizde, İstanbul Menkul Kıymetler Borsası 100 endeksinin dolar bazlı kapanış değerlerini kullandık. Kendimize dönem olarak 1989 ile 1996 yıllan arasım seçtik çünkü bu dönem gelişen politik ve sosyal olaylar nedeniyle oldukça değişkenlik göstermekteydi. Klasik ekonomik modellerin günlük veriyle uygulanmalan, verilerin içerdiği dönemsel eğilimler ve bozucu etkiler nedeniyle oldukça zordur. Biz Puslu Karar Verme Sistemini kullanarak, endeksin kapanış değerlerini tahmin etmeye çalıştık ve aynca bu sistemi klasik bir sinir ağlan yapısı ile karşılaştırdık. Varyans, yüksek değişkenliğe sahip pazarlarda, yatırımcılar için önemli bir yatırım kriteri olduğundan, bu çalışmada zaman serilerindeki varyansı tahmin etmek amacı ile kullanılan GARCH yöntemini de inceledik. Sinir ağlan ve bulanık mantığın birlikte kullanıldığı yapı ile varyansı da tahmin etmeye çalıştık. ÎC YÜKSEKÖĞRETİM MJMU","IV ABSTRACT ESTIMATING THE VALUE WEIGHTED ISE 100 INDEX AND ITS VARIANCE USING A NEURO-FUZZY ARCHITECTURE In this study, we have applied a fuzzy logic approach to the analysis of economic time series using a neural network structure. We tried to form an architecture to be able to adapt to the volatility present in most of the emerging markets like Turkey. In our problem, we have used the USD based closing prices of the Istanbul Stock Exchange 100 Index. The period we have chosen is between 1989 and 1996, which is highly unstable, because of the political and social status of that period. Classical economic models are hard to implement using daily data because of the seasonal trends and the disturbance existing in the data. We have used the Fuzzy Decision Making Architecture to estimate the return of the index and benchmarked it with a classical neural network architecture. We have had a look at the GARCH process, which is used for estimating the variance in time series since variance is a key investment criteria for investors in highly volatile markets. We have also used the neurofuzzy architecture for the estimation of the variance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET KARDIOLO JİK ACİL VAKALAR İÇİN TEŞHİS UZMAN SİSTEMİ Elektrokardiografi (EKG) kalp ile ilgili hastalıkların teşhisinde önemli bir yer tutmaktadır. EKG'nin önemi kayıtların, hastalığın teşhisinde fiziksel olarak ölçülebilir büyüklüklerin belirlemesinden kaynaklanmaktadır. Acil durumlarda ise EKG'nin önemi bir kat daha artmaktadır. Acil odasında doktorlar hastaya teşhis koyarken, hastanın hikayesini dinleyecek ve hastayı muayene edecek zamana sahip olmadıklarından ötürü, teşhisi sadece EKG kayıtlarına bakarak yaparlar. Acilde doktorların uyguladıkları teşhis yöntemi, acil olmayan durumlarda kardioloji servislerinde uyguladıkları yöntemden farklıdır. Acil durumlarında sadece hayati önem taşıyan bulgular incelenip bu bulgulara göre zaman yitirilmeden uygulanması gereken tedaviler yapılır. Bu bulgular: bazı ventriküler ve atrial ritm bozuklukları, pulmonar ve mitral P dalgası anormallikleri ve ST segment yükselmeleridir. Bu bulguların hızlı ve hatasız olarak ortaya çıkartılması hayati önem taşımaktadır. Bu çalışmada, acil vakalar için ECG teşhisi yapan bir uzman sistem geliştirilmiştir. Kullanılan yöntemler, teşhis edilmek istenen bulgulara göre çeşitlilik göstermektedir. Ventriküler analizler için basit istatistiksel yöntemler, atrial aritmiler için güç izgesi tahmini, P dalgası anormallikleri için basit bir yapay sinir ağı modeli kullanılmıştır. Geliştirilen uzman sistem, ritim bozukluklarım ve P dalgası anormalliklerini 80 örnek içinden basan ile teşhis etmiştir. Diğer analizlerde basan yüzdesi veri çözünürlüğüne bağlı olarak değişmektedir. Sistemin gerçek zamanlı veri kaydeden bir donanım ile birleştirilmesi durumunda bahsedilen analizlerde de basan oranının yükselmesi olasıdır.","ABSTRACT AN EXPERT ECG DIAGNOSIS SYSTEM IN EMERGENCY CARE Electrocardiography (ECG) is the recording of heart's electrical activity from various locations on the patient's body. The importance of ECG lies in the fact that it gives an accurate picture of the patient's heart. In emergency; the sole input for diagnosis to record the ECG signals of the patient. The examination of the ECG is different from the diagnosis process of non-emergency cases. Experts in the emergency room look for diseases that require an urgent response. In this thesis, developed an expert system solution to the rapid diagnosis problem in emergency. Work focused on four main diagnosis types: in ventricular analysis, we used a statistical approach, whereas in the detection of atrial fibrillation we used a Fourier Transform analysis, and in P wave analysis we applied a neural network algorithm. Miocardial Infarction (MI) analysis and other auxiliary analyses are done either directly or using the functional properties of the signals. Developed system, diagnosed arrhythmias and P wave abnormalities within 80 samples with a 100 per cent accuracy. The performance of other analysis methods depends on the frequency resolution of the data. Development of a real time data acquisition module may increase the success rate of the algorithm."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET DEĞİŞKEN BOYUTLU GİRDİLİ ÇOK KATMANLI PERCEPTRONLAR İLE SES TANIMA İlk olarak, popüler istatistiksel ve sinirsel yöntemler olan, Saklı Markov Modelleri (HMM), k- Yalan Komşu, Tek ve Çok-Katmanlı Perceptronlar (MLP), Radyal-Tabanlı Fonksiyonlar, ve Uzmanlar Karışımları, ses sınıflandırma problemi üzerinde karşılaştırıldı. İstatistiksel yöntemler benzerlik tabanlı, sinir ağlan ise ayırt edici şekilde eğitilir. HMM, sesi, geçici sinyaller olarak modellerken, diğer yöntemler zaman gecikmesi kullanarak, zamanı uzaya izdüşürürler ve tüm sinyali tek bir vektör olarak gösterirler. Bu yüzden, bu metodlann girdileri sabit uzunlukta olmalıdır. Değişken uzunlukta sesbirimlerinin sınıflandırılmasında, MLP'nin ayırt edici gücünden faydalamlabilmesi için, özel eğitilmiş MLP'lerden oluşan, Değişken Boyutlu Girdili Çok Katmanlı Perceptronlar (VSIMLP) metodu önerildi. Birbirine yakın altı Japon sesbirimini, /b,d,g,m,n,N/, içeren veriseti, yukarıda adı geçen yöntemlerin karşılaştırılmasında kullanıldı. VSIMLP metodu, UMU 39-sınıf sesbirimi tanıma problemi üzerinde test edildi. Girdi uzayının fazla boyutluluğu ve ses sentez fizyolojisi sebepleriyle, yerel yöntemlerin, ses tanıma probleminde önemli bir yeri olduğu sonucuna varıldı. VSIMLP-HMM melez yöntemlerinin kelime veya cümle tanımada kullanışlı olduğu ve VSMLP'nin temel aldığı fikirlerin, MLP yerine, yerel yöntemlere de uygulanabileceği görüldü.","IV ABSTRACT VARIABLE SIZED INPUT MULTI LAYER PERCEPTRONS FOR SPEECH RECOGNITION First, we review popular statistical and neural methods for classification, which are Hidden Markov Models (HMM), ^-Nearest Neighbor, Single and Multi-Layer Perceptrons (MLP), Radial-Basis Functions, and Mixture of Experts. Then, we apply them to the classification of speech phonemes. The statistical methods are likelihood-based, whereas neural network methods are trained discriminatively. HMMs model the speech as a temporal signal whereas the other methods map time to space using time-delay and represent the whole signal as one vector. Therefore, the input to the latter systems should be of a fixed length. To make use of the discriminative power of MLPs for classification of variable length phonemes, we propose Variable Sized Input Multi Layer Perceptrons (VSIMLP), which is composed of a set of special-type MLPs. The database used for the review part contains instances from six closely pronounced Japanese phonemes, /b,d,g,m,n,N/. We test VSIMLP on the ITMIT 39-class phoneme problem. We conclude that focusing on the localities is an important issue in phoneme recognition because of the high dimensionality of input space and the nature of speech synthesis. We also conclude that VSIMLP is a promising and extendable technique for phoneme classification. The idea of VSIMLP can be applied to local models with better feature vectors, and it can be used with HMM as a hybrid method to classify words or sentences."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET OTONOM HAREKETLİ ROBOTLAR İÇİN SAĞLAM BİR BİLİŞSEL MİMARİYE DOĞRU Bu tezde, robota karmaşık dünyalarda serbestçe dolaşma ve nesneden kaçınma olanağı veren, otonom hareketli robotlar için kullanılabilecek sağlam bir bilişsel mimari tasarlanması amaçlanmistir. Mimari modüler olmali, yol planlama ve harita oluşturma gibi daha karmaşık davranışlar eklenmesine olanak vermeli ve benzetimi yapilan dünyada olduğu kadar gerçek dünyada da çalışabilmelidir. Gezinti için Genelleştirilmiş Voronoi Çizgesi (GVG) tekniğine dayalı bir çözüm kullanilmiştir. Genelleştirilmiş Voronoi Çizgesi, sadece alıcılardan okunan bilgilere dayalı, bilinmeyen bir çevrede keşif, harita oluşturma ve robotun konuşlanmasini sağlayan bir metoddur. Yanısıra sesli ve yetersiz alıcı bilgilerini yeniden düzenlemek ve hareketin yönünü tayin etmek için Bulanık Mantık kullanılmıştır. Bulanık mantığın kullanımı mimariye gerçek bir basan getirmiştir. Bulanık Mantık sayesinde problemlerin pek çoğu donanım ve çevreden bağımsız olarak çözülmüştür. Bu mimarinin genelleştirilmesine imkan verir. Mimari mümkün olduğu kadar esnek ve modüler tasarlanmıştır, bu yüzden gelecekte daha fazla davranış eklenebilir. Sonuçlar Braitenberg prensiplerine dayalı benzer kontrol programları ile karşılaştırıldığında başarılı ve kabul edilebilir bulunmuştur.","IV ABSTRACT TOWARDS A ROBUST COGNITIVE ARCHITECTURE FOR AUTONOMOUS MOBILE ROBOTS In this thesis, it is aimed to design a robust cognitive architecture for autonomous mobile robots, which gives the robot the capability to navigate freely in complex environments, with object avoidance. It should be modular, and enable the researchers to add more complex behaviors, like path planning and map construction, in the future, and work in real world as well as in the simulated environment. A solution based on Generalized Voronoi Graph (GVG) technique is used for navigation. Generalized Voronoi Graph is a method to explore, map and localize a robot in an unknown environment, based only on sensor readings. Besides, Fuzzy Logic is used to refine the sensor data, which is noisy and inadequate, and detects the direction of next move. Usage of Fuzzy Logic brings a real success into the architecture. By means of Fuzzy Logic, most of the problems were solved in a hardware and environment free manner. This fact enables the generalization of the architecture. The architecture is designed as flexible and modular as possible, so more behaviors could be added, in the future. The results were successful, and acceptable when compared to similar controllers based on Braitenberg principle."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÇOK KATMANLI YAPAY SİNİR AĞLARI İÇİN AĞIRLIK NİCEMLEMESİ Bu çalışmada çok katmanlı yapay sinir ağlarının etkin bir şekilde oluşturulması için parametrelerinin çeşitli metotlarla nicemlemesi tartışılmaktadır. Bu metotlar para metreleri sabit sayılar gibi değil bir Gauss karışım dağılımından çekilmiş rassal değişkenler gibi düşünür ve herbiri bu karışım dağılımı üzerinde çeşitli varsayımlar yapar. Bunların içinde özel haller olarak düzenli nicemleme ile A;-merkezli öbekleme vardır. Paramet relerin dağılımının öğrenilmesi ile çok katmanlı yapay sinir ağının eğitiminin birleştirilme sinde ""esnek ağırlık paylaşımı (soft weight sharing)"" kullanılması önerilmektedir. Bağlanım ve sınıflandırma veri kümeleri üzerindeki benzetim sonuçları çeşitli nicemleme metot larını karşılaştırır ve dağılım parametrelerinin eğitiminin yapay sinir ağı parametrelerinin eğitimi ile birleştirilmesinin üstünlüğünü göstermektedir.",IV ABSTRACT WEIGHT QUANTIZATION FOR MULTI-LAYER PERCEPTRONS In this work various methods for quantizing the weights of a multi-layer percep tion for efficient VLSI implementation is discussed. These methods consider weights not as constant numbers but as random variables drawn from a Gaussian mixture distribution where each of these methods make a certain assumption about the compo nents of the mixture. These include as special cases uniform quantization and /s-means clustering. It is proposed to use soft weight sharing in learning the distribution of the weights coupled with the training of the multi-layer perceptron. Simulation results on regression and classification data sets compare various quantization schemes and demonstrate the advantage of coupled training of distribution parameters.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vıı ÖZET ODAYERİ DÜZENLİ DEPOLAMA SAHASI SÜZÜNTÜ SUYUNUN KARAKTERİZASYONU VE İNSİNERASYONU Düzenli depolama, kat atık uzaklaştırma yöntemlerinin en yaygın olanıdır. Düzenli depolama sahalarından kaynaklanan süzüntü suyunun arıtılması, bu yöntemin problemli ve pahalı bir unsurudur. Bu çalışmanın ana amacı, süzüntü suyunun arıtılması için, uygun bir yakma sistemi geliştirilmesidir. Deneysel çalışmalar, atıkların kompozisyonu, ebat dağılımı, su ve organik içeriği ile kalorifık değerinin ekonomik gelire göre ve de mevsimsel olarak önemli değişiklikler gösterdiğini ortaya koymuştur. Odayeri düzenli depolama sahası süzüntü suyunun karakterizasyon çalışması ise, sahada anaerobik asidik fermentasyon fazının etkin olduğunu göstermiştir. Yazın, süzüntü suyunun kirlilik oram, depolanan atıktaki organik içeriğin artmasına bağlı olarak oldukça artmıştır. Yapılan deneysel çalışmalar, dizayn edilen pilot ölçekli yeni yakma sisteminin, süzüntü suyunun insinerasyonunda başarılı olduğunu ispatlamıştır. Diğer yandan, çift aşamalı sıvı atık yakma sistemindeki çalışmalardan elde edilen veriler, akışkan yatakta, birincil yakma ünitesinden taşman yanma ara ürünleri ve organiklerin oksidasyonunun tamamlandığım göstermiştir. Bu nedenle de, düşük gaz emisyonları elde edilmiştir. Ancak, atıktaki yüksek Na, Ca ve K içeriği nedeniyle aglomerasyon problemi yaşanmıştır. Equitherm bilgisayar programı ile yapılan yakma sistemlerinin termodinamik modellemesi deneysel bulguları destekler niteliktedir. Dolayısıyla, termal proseslerin esnekliğini göz önünde bulundurarak, süzüntü suyu insinerasyonunun Odayeri düzenli depolama sahası ile birlikte bir çok depolama sahasında başarıyla uygulanabilineceği sonucuna varılmıştır. LC YÜKSEKÖĞRETİM Kblfe*. MJKÖMANTASYON MDKRİ","VI ABSTRACT CHARACTERIZATION AND INCINERATION OF THE ODAYERI LANDFILL LEACHATE Sanitary landfilling is the most common technique for waste disposal in the world. The treatment of the leachate generated is a troublesome and a costly factor in sanitary landfill operations. The main aim of this study is to develop an appropriate incineration system for the treatment of landfill leachate. The experimental study demonstrated that the composition, size distribution, water and organic contents, and calorific values of the waste changed significantly not only with the income levels of the people, but also seasonally. The composition of the leachate sampled from the Odayeri landfill showed that an anaerobic acidic fermentation phase was dominant in the landfill. Furthermore, the strength of the leachate increased dramatically in summer, due to the increase in the organic content of wastes disposed to the landfill. During the experimental study, the capability of the new pilot-scale incineration system was proven to incinerate the landfill leachate. On the other hand, the experimental data -obtained during the testing period of the double-phase liquid waste incineration system, indicated that the fluidised bed incinerator provided an extra unit sufficient to complete the oxidation of partial products of combustion and organics carried from the initial incinerator. Therefore, lower gaseous emissions were noted. However, an agglomeration problem has occurred, due to the high concentrations of Na, Ca and K. The results of the thermodynamical modeling of the incineration systems by means of a software program, the Equitherm, supported the findings of the experimental study. It was concluded that considering the flexibility of the thermal processes, leachate incineration could successfully be applied to Odayeri landfill, as well as to many landfills."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"VI ÖZET nitel benzetimde göreceli surelerin incelenmesi Bu tezde, nitel benzetim algoritmalarının, girdilerini daha iyi kullanarak, çıktılanndaki davranış tahminlerindeki zaman aralıklarının göreceli uzunlukları hakkında önemli miktarda çıkarımda bulunabilecekleri gösterilmektedir. Simetri, dönemlilik ve iki zaman aralığındaki olayların karşılaştırılması gibi kavramları kullanan basit teknikler, uslamlayıcının göreceli süreler hakkında çıkarsanmış bilgileri gösteren bir liste oluşturabilmesini sağlar. Bu bilgiler, önerilen davranışlar arasından çelişkili süre verilerine yolaçan sahte davranışları eleyen yeni süzgeçler tarafından kullanılır. Süzgeçler tarafından elenmeyen davranışlara, çıkarılan göreceli süre bilgilerinin yanı sıra, sistem değişkenlerinin niteliksel özelliklerini betimleyen daha zengin ifadeler iliştirilir. Önerilen bazı süzgeçlerin, aynı bilgiyi kullanan olası süzgeçler arasında en iyileri olduğu kanıtlanmaktadır. Bu süzgeçleri geliştirmek ve doğruluklarını kanıtlamak için, literatürde mevcut olan Sİ ve SRİ işaret cebirlerini genişleten yeni bir işaret cebiri olan SRİ* ve bahsedilen süzgeçlerde göreceli süre gerçeklerinin çıkarılmasının yanı sıra, bir karşılaştırmalı çözümleme yöntemi olan Nitel Fark Çözümlemesi 'nin çözemediği problemleri çözmekte de kullanılabilen, SRİ* üzerine kurulu yeni bir karşılaştırmalı çözümleme yöntemi olan Karşılaştırma Hesabı önerilmektedir.","ABSTRACT EXPLOITING RELATIVE DURATIONS IN QUALITATIVE SIMULATION We show that qualitative simulation algorithms can make better use of their input to deduce significant amounts of information about the relative lengths of the time intervals in their output behavior predictions. Simple techniques employing concepts like symmetry, periodicity, and comparison of the circumstances in two time intervals can enable the reasoner to build a list of facts representing the deduced information about relative durations. These facts are used by new filters, which eliminate proposed spurious behaviors leading to inconsistent duration data. Surviving behaviors are annotated with richer descriptions of the qualitative properties of system variables, in addition to the extracted relative duration information. For some of the filters, we prove that they are the best ones among the possible filters that use the same information. For the purpose of developing these filters and proving that they are sound, we propose a new sign algebra SRI* by extending the existing sign algebras SI and SRI and a new Comparative Analysis Method, Comparison Calculus, which can be used not only to design filters that eliminate spurious behaviors, but also to solve Comparison Analysis Problems. tc tûmmö?mfM sasmss"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET SEÇİCİ DİKKAT TEMELLİ BİR ELLE YAZILMIŞ RAKAM TANIMA YÖNTEMİ Primatların görsel mekanizması görüntü tanımada yüksek performans sağlayan karmaşık bir sistemdir. Primatlar görüntünün tamamını bir anda algılamak yerine görüntünün daha çok bilgi içeren yerlerini seçerek sırayla buralara bakarlar. Bir mühendislik problemi olarak incelendiğinde, paralel örüntü tanıma çok fazla kaynağa ihtiyaç duyduğundan, seri tanıma daha verimlidir. Bu çalışmada örüntü tanıma için seçici dikkate dayalı seri bir model öneriyoruz. Seçici dikkat iki aşamalı bir sistemdir. Basit seviyede bileşenlerden oluşan bi rinci aşama görüntünün tamamından düşük çözünürlükte öznitelikler çıkartır. Yüksek çözünürlüğe sahip fovea dikkate değer bulunan noktalardan daha fazla bilgi toplaya bilmek için yönlendirilir. Birinci aşamayı bir ilginçlik haritası ile, daha karmaşık ikinci aşama ve zaman içindeki sıralı birleştirmeyi ise Markov modelleri ile benzetiyoruz. Kurduğumuz iki aşamalı modeli elle yazılmış sayıları tanıma problemi ile deniyoruz. İlginçlik haritası görüntüden öznitelikler çıkartır. Foveadan alınan yer ve içerik bilgisini Markov modelleriyle birleştirerek tanıma problemini zaman içinde sıralı hale getiriyoruz. İki aşama arasında bölgesel uzman sistemler kullanarak birinci aşamadan gelen bilgiyi düzenliyor ve ikinci aşamanın tanıma işlemini kolaylaştırıyoruz. Birinci aşama için değişik ilginçlik haritalarını, uzman sistemler için basit ve çok katmanlı yapay sinir ağlarını, ikinci aşama içinse görünür ve saklı Markov modellerini karşılaştırıyoruz. Ayrıca baktığımız noktaların sayısını örüntünün zorluğuna göre be lirlemek için bir dinamik fovea benzetiyoruz. Sonuçlarımız bu yöntemin daha karmaşık örüntü tanıma problemlerine uygulanabilirliğini gösterir niteliktedir.","IV ABSTRACT A SELECTIVE ATTENTION BASED METHOD FOR RECOGNITION OF OPTICAL HANDWRITTEN DIGITS Primates have a very complex and efficient system for visual recognition. Primates do not absorb the whole information content of the visual field at once, but selectively and serially attend to locations that contain high information. Since parallel recognition requires great computational resources, doing serial recognition is interesting from an engineering point of view. In this work, we propose a serial recognition model for pattern recognition that is based on selective attention. The selective attention mechanism operates at two levels. The primitive, bottom-up attentive level extracts low-resolution features over the whole visual field. The high- resolution fovea is directed around the visual field to gather more information about spots of interest. We simulate the attentive level with a saliency scheme, and the more complex, top-down, temporally sequential associative level with Markov models. We test our model on a well-studied handwritten numeral recognition problem. The saliency scheme extracts features like oriented lines from a downsampled image. We simulate the movement of the fovea by passing a window over the image, and extract location and content information that are combined with the Markov model. We use local experts between the two levels of processing to sort out the output of the attentive level and to help the associative level in classification. We compare different saliency schemes in the attentive level, linear vs. multi-layer perceptrons for the local experts, and hidden vs. observable Markov models in the associative level. We simulate a dynamic fovea to control the number of attended spots for classification. Our results show that this model can be applied to more demanding pattern recognition tasks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET VoD (talep üzerine video), ağlaştırma alanının önemli bir araştırma konusudur. Bu servisin geliştirilmesi ve eniyileştirilmesi amacıyla yapılan geniş araştırma ve standartlaştırma çabalan bunun bir göstergesidir. Bu çalışmada, video sıkıştırması, video iletim protokolleri ve geçerli video akışı uygulamalarını da içeren standart ve süregiden araştırma teknolojilerinin incelemesi yapılmıştır. Birtakım performans testleri yapılmış ve deneysel bir intranet video servis sağlayıcısı uygulaması sunulmuştur.","IV ABSTRACT VoD (Video on Demand) is an important topic in networking research. This can be deduced from the large research and standarization effort that are focused on improving and optimizing this service. In this thesis we survey the standard and the on going research technology enabling VoD, consisting of video compression, video transport protocols and the available video streaming applications. A number of performance tests were conducted and an experimental intranet video sever implementation is proposed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ELEKTRİK SÜPÜRGESİ ROBOTU İÇİN ALAN TARAMA ALGORİTMALARININ GELİŞTİRLMESİ ÖZET Bu çalışma hareketli bir elektrik süpürgesi robotun süpürme yöntemlerine bir nesneye yönelik bir çerçeve getirmektedir. Bu çerçeve birbirlerine belirlenmiş bilgi aktarımı yapan katmanlardan oluşmaktadır. Her katman bir diğerinden bağımsız uyarlanabilir. Dahası, bu uyarlamalar birden fazla sayıda olabilir ve bu da son kullanıcılara çeşitli programlar arasından seçim şansı tanıyabilir. Bu fikir programlanabilir bulaşık ve çamaşır makineleri gibi evde kullanılan bir çok elektronik araçta kullanılmaktadır. Çalışma sırasında, harita yaratma, yerini saptama ve alam tamamen dolaşma konulan ile ilgili katmanlar için çeşitli uyarlamalara yer verilmiştir. Bu uyarlamalar teorik anlamda bir simulator üzerinde denenmiş ve yer sapmaları, çarpışmalar gibi gerçek uyarlamalarda rastlanan konular kapsam dışında tutulmuştur. Bu modüller için literatürde çok fazla ve başarılı uyarlamalar mevcuttur. Harita yaratma, Boru Metodu olarak adlandırdığımız ve Voronoi Keşif stratejilerini de kullanan bir yöntemle gerçekleştirilmiştir. Alanı tamamen dolaşma modülleri ızgara gösterimleri üzerine dayandığı için, diğer katmanlarda oluşturulan haritalar ızgara gösterimine dönüştürülmektedir. Alan tarama topolojik dönüşümler ile gerçeklenmiştir ve NP-tamdır ve robotun girebildiği tüm boş alanın taranabilmesini garantilemektedir. ""EC wstaxoGaeriiM $wm>&","IV DEVELOPMENT OF AREA COVERAGE ALGORITHMS FOR AN AUTONOMOUS VACUUM CLEANER ROBOT ABSTRACT This study presents an object-oriented framework for a vacuum cleaner mobile robot's sweep strategies. The framework consists of layers that pass information to the next. Each layer can be implemented without affecting others and may several implementations giving the end user a chance of selecting a sweep program. This idea is very common in household use devices such as programmable dishwashers and stoves. Throughout this study, implementations for the layers that deal with map construction, localization and area coverage have been covered. The implemented layers are purely theoretical and need to be supported by dead reckoning and obstacle avoidance modules, which are well studied and have very successful implementations. Map construction modules introduce an algorithm named Pipes Method, and uses ideas in Voronoi Exploration Strategies. Voronoi graphs also help in localization of the robot in the pre-constructed internal map. Area coverage implementations are based on grid representation of the real world so the constructed map is transformed into a grid representation. Coverage is achieved using different transforms. The implemented algorithms are NP complete and guarantee full area coverage of the empty space the robot can access."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ROBOTLAR İÇİN YAPAY SİNİR AĞLARI İLE KONTROL METODLARININ KARŞILAŞTIRMASI ÖZET Robotlar fabrika otomasyonunda ve esnek imalatta önemli bir yere sahiptirler. Bundan dolayı robot kontrolü pek çok araştırıcının ilgisini çekmektedir. Çalışmalarıda çok sayıda denetimci tasarımı ele alınmış ve bu denetimcilerin performansları karşılaştırılıp tartışılmıştır. Denetimci tasarlarken göz önüne alınması gereken en önemli nokta sistemin parametrelerinin zamana bağlı değişebileceğidir. Robotun taşıdığı yük değiştiğinde atalet, örneğin dinamiği değişir.Bundan dolayı denetimci bu değişikliklerin üstesinden gelecek şekilde tesarlanmahdır. Bu çalışmada ele alınan ilk denetimci, PD denetimcisi ile birlikte ileri geri beslemeli lineerleştirmedir.Lineerleştirme yapay sinir ağı kullanılarak sağlanır ve bu yönteme ters dinamik modelleme yöntemi adı verilmektedir. İkinci olarak popüler olan diğer bir yapay sinir ağı ile kontrol algoritması kullanıldı.Bu metod hata geri besleme öğrenmeli denetimci olarak anılmaktadır. Bu online öğrenen bir denetimci olup modelleme hataları, gürültü ve diğer bozucuları kompanse etmek için ikinci bir denetimciye ihtiyaç duyar. Üçüncü kontrol yöntemi yapay sinir aği ile kayan kipli kontrol. Bu online öğrenen bir denetimci olup ikinciden farkı denk kontrol (equivalent control) hesaplanmasıdır. Dördüncü kontrol metodu olarak da yapay sinir ağı ile PD kontrol yapıldı.Buradaki amaç ise gürbüz bir kontrol elde etmektir. Denetimci yapay sinir ağıdır. Bütün algoritmaları bilgisayar ortamında simüle edilmiştir.","IV COMPARISON OF NEUROCONTROLLERS FOR ROBOT MANIPULATORS ABSTRACT Robots have a significant importance in factory automation and flexible manufacturing. The control of a robot has therefore attracted the attention of many researchers. In his work a number of controller designs are considered and their performances are compared and discussed. When designing a controller the most important point is that the system parameters may change in time. With the change of the load of the robot, the inertia, i.e. the dynamics of the robot may change. Therefore, the controller should be designed to overcome any parameter changes. The first controller considered in this work is a feedback-feedforward linearization together with a PD control algorithm. This linearization achieved by using neural network and this method is called direct inverse modeling architecture. Secondly, another popular neurocontrol algorithm is used. This method is called Feedback Error Learning Architecture. It is an online learning controller and it need a secondary controller in order to compensate the modeling errors and also noise and disturbance The third one is neurosliding mode controL It is an online control method and the Third one differs from the second one only the estimation of equivalent control The fourth method is Neuro PD controller and the aim is to design a robust controller. The controller is a neural network All algorithms are simulated on a digital computer."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ATM (Asenkron Transfer Mod) teknolojisini kullanımı için iki metod bulunmaktadır. Bunlardan ilki eski ağ yöntemlerinin ATM teknolojisi üstüne oturtulmasını öngören ve halen CLIP (Klasik İP), MPOA (ATM Ağlan Üstünde Çoklu Protokol) ile LANE (Yerel Ağ Öykünmesi) tekniklerini kapsayan yöntemlerdir. Bu taklit bazlı yöntemler üstünden varolan internet protokollerinin kullanılması mükün olmaktadır. Diğer yöntem ise doğrudan ATM teknolojisini kullanmaya izin veren fakat mevcut yerel ağlar ve yazılımlar ile uyumlu olmayan teknikleri kapsamaktadır. Tez kapsamında da mümkün olan bu metodların, gerçek bir test ortamında, çok çeşitli kombinasyonlar altında, başarımları ölçülmüş ve yorumlanmıştır. Bu ölçme çalışmasında, sistem yöneticisinin erişimine açık olan protokol parametreleri değiştirilerek, bunların performans üstündeki etkileri ortaya konulmuştur. Değiştirelen parametreler arasında mesaj uzunluğu, yastık bellek büyüklüğü, MTU boyu, TCP pencere büyüklüğü ve ATM'ye özgün bazı QoS ayarlamaları sayılabilir. Bu sonuçlar doğrultusunda sistem performansının nasıl daha iyiye götürülebileceği mümkün oldukça açıklanmıştır.","IV ABSTRACT When an underlying network is ATM based, two methods exists to utilize the network resources. The first method is based upon direct use of native ATM protocols, while the second is based upon emulation methodologies. The latter method can be put in to operation by use of CLIP (Classical IP), LANE (LAN Emulation), or MPOA (Multi Protocol over ATM Networks) techniques which provides seamless integration of current networks to ATM networks. In this thesis, a large set of experiments are performed for measuring the performance of different protocols over ATM in a real test environment. Different experiments are designed for measuring the performance, such as throughput and cell loss ratio, of these protocols by investigating the effects of changing the configurable options of the protocols, such as message size, buffer size, MTU size, TCP window size, and QoS parameters of ATM. In addition, when possible techniques to improve the performance are investigated."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu tez, yazılım projelerinin yönetilmesi üzerinde bir çalışmadır. Yeni bir entegre proje destek ortamı altyapısı olarak işakışı yönetim sistemleri incelenmiştir. İşakışı yönetim sistemlerinin yazılım geliştiren kurumların proje planlama, izleme ve konfıgürasyon yönetimi ihtiyaçlarını karşılayacak entegre bir yazılıma uygun bir mimari olduğu ortaya konmuştur. Yazılım projelerinin yüksek seviyede esneklik ihtiyacından dolayı işakışı yönetim sistemlerinin esneklik kabiliyetlerini genişletecek yeni yordamlar da bu paralelde gözden geçirilmiştir. Tartışmalardan alman sonuçlan somutlaştırmak için WOSE adıyla anılan bir yazılım gereci geliştirilmiştir.","IV ABSTRACT Requirements for better project management of software are evaluated. For a new integrated project support environment, workflow management systems as the underlying framework are evaluated. It is found out that workflow management systems can enable an integrated tool to support project planning, tracking and configuration requirement requirements for a software developing organization. Since software management processes require high order of flexibility, workflow management systems' new features are also evaluated to be used in the proposed tool. A software tool named WOSE is developed to solidify the results obtained from the discussions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"DOĞRUSAL OLMAYAN EVRENSEL MOTOR PARAMETRELERİNİN 8-UYARLAMALI SİNİR AĞI YÖNTEMİ İLE TANILANMASI ÖZET Yapay sinir ağlarının paralel olarak dağılmış işleme kapasitesi ve dar bir aralıktaki herhangi devamlı doğrusal olmayan fonksiyonu öğrenme yeteneği onları bir çok araştırmacıya çekici kılan özellikleri arasındadır. Günümüzde, yapay sinir ağlarının dinamik sistem modelleme ve tanılamada kullanılmasına olan ilgi artmaktadır. Doğrusal sistem tanılamasında bir çok değişik tanılama algoritmaları bulunmasına karşın, doğrusal olmayan sistemlerde parametre tanılaması için yaygın kullanılan algoritmalar az bulunmaktadır. Bu tezde 0-uyarlamalı sinir ağı (TUŞA) parametre tanılama metodu doğrusal olmayan özellikler gösteren bir universal doğru akım motoru (EDAM) üzerinde tatbik edilmiştir. Tezin benzetim aşamasında, uygun görülen ileri-beslemeli sinir ağı mimarUerinin eğitiminden sonra tanılanacak her bir motor parametresi için aynı anda uyarlamah tanılama gerçekleştirilmiştir. Aynı yöntem, deneysel veriler kullanılarak da gerçekleştirilmiş ve elde edilen tanılanmış parametreler model değerleri ile karşılaştınlmıştır. Tanılanmış parametre değerleri kullanılarak oluşturulan yeni modelin hız çıktısıyla deneysel motorun hız çıktısı kıyaslanarak TUŞA yönteminin EDAM' m parametrelerini tanılamada başardı olduğu sonucuna varılmıştır. TUŞA metodunun diğer elektrik motorların parametre tanılamasına da uyarlanabileceği kanısı oluşmuştur.","IV NONLINEAR PARAMETER ESTIMATION OF A UNIVERSAL MOTOR BY 9-ADAPTIVE NEURAL NETWORKS ABSTRACT The parallel distributed processing capacity, and the ability of learning any continuous nonlinear function on a compact interval with one or more hidden layers are some of the traits that have made artificial neural networks so attractive to many researchers. Recently, interest has been increasing towards the usage of neural networks for modeling and identification of dynamic systems. Although there are various identification algorithms for linear systems, there is lack of widespread methodology in parameter estimation for nonlinear systems. In this thesis, 9-adaptive neural network (TANN) parameter estimation method has been implemented on a universal direct current motor (UDCM), exhibiting a slightly nonlinear nature. In the simulation part, an adaptive estimation scheme is carried out simultaneously for each parameter to be estimated, after the off-line training of the selected feed-forward neural network architectures. The same methodology has been applied using experimental data, and the obtained estimates are compared to that of the motor model. The estimates are also verified by comparing the speed outputs of the actual motor and the motor model utilizing the estimates. Results indicate that TANNs have performed remarkably well in estimating the parameters of UDCM, and they might be applicable to commercially available electrical motors."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV ÖZET Üç boyutlu insan modellerinin konuşması canlandırmada olduğu kadar insan- bilgisayar iletişiminde de giderek daha sık kullanılmaktadır. Konuşmanın üç boyutlu yüz modeli ile ağız eşzamanlaması genelde grafik animatörlerce yapılan uzun ve mekanik bir işlemdir. Otomatik ağız eşzamanlı yüz animasyonu için çeşitli çalışmalar yapılmıştır. Bu tip çalışmalar genelde yazı tabanlı olmaktadır. Biz bu çalışmamızda sesi girdi olarak kullandık. Seslendirenin kaydedilen sesi verilen üç boyutlu yüz modelinde dudak hareketlerine çevrilmektedir. Bunu için kaydedilen ses analiz edilip eğitim kümesi ile karşılaştırılarak dudak hareketine sınıflandırılmaktadır. Yüz modelimizde dudak hareketleri yüz kasları ve çene kullanılarak yapılır. Üç boyutlu yüz modelimiz üzerine insan yüzünün fiziksel kas yapısı dikkate alınarak yüz kasları modellendi. Gerçekçi yüz animasyonu için insan yüzünü oluşturan deri, yağ, kas ve kemik katmanları da modellenerek aralarındaki etkileşimler hesaplandı. Oldukça hızlı bir şekilde doğal görünüşlü canlandırma yapılabilmektedir. Gerçek zamanlı çalışan kırpılmış bir canlandırma motoru da hazırlanmıştır.","in ABSTRACT Talking three-dimensional (3D) synthetic faces are now used in many applications involving human-computer interaction. The lip-synchronization of the faces is mostly done mechanically by computer animators. Although there is some work done on automated lip- synchronized facial animation, these studies are mostly based on text input. In our work we used speech in Turkish as an input to generate lip-synchronized facial animation. Speakers' recorded voice is converted into lip-shape classes and applied to the 3D model. Voice is analyzed and classified using a training set. Lip animation is facilitated by activating facial muscles and the jaw. Facial muscles are modeled onto our facial model. For more realistic facial animation, facial tissue is modeled as well, and the interactions between epidermis, subcutenous layer and bone are taken into account. High-speed natural-looking lip- synchronized facial animation is achieved. A real-time version of the engine is also implemented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vıı ÖZET Son zamanlarda ileri beslemeli yapay sinir ağlan üzerinde yoğun bir ilgi oluşmuştur. Bunun başlıca nedeni bu sistemlerin son derece karmaşık gerçek problemleri büyük bir basan ile çözebilmesidir. Bu sinir ağlannın eğitimi için birçok teknikler ve metodlar geliştirilmiştir. Bu metodlan başlıca üç gruba ayırmak mümkündür: küçük bir ağdan başlayıp inşa, büyük bir ağı budama ve bu iki tekniğin kanşımı. Bir başka Önemli nokta ise yazılım ortamında geliştirilen bu ağların donanıma ugulanmasıdır. Optimizasyon konusunda bir çok metod olmasına rağmen donanımı dikkate alarak optimizasyon yapan bir metod mevcut değildir. Bu tezin birinci kısmında inşa ve budama birleştiren bir metod ile bir genetik metodun karşılaştınlması yatpılmıştır. Tezin ikinci kısmında ise yukanda belirtilen ağlardaki bağlantılar için bir hassasiyet analizi geliştirilip, genetik metodla birleştirilerek donanıma uygun sinir ağı optimizasyonu gerçekleştirilmiştir. Buradaki amaç daha az hassas olan bağlantılann belirlenip donanım uygulamasında bu bağlantılar için daha basit donanım birimlerinin kullanılması ve böylece alan tasarrufu sağlanmasıdır.","IV ABSTRACT Designing on an appropriate size of a neural network is one of the main problems. Several methods are proposed to find optimum structures for feedforward neural networks. These methods are based on pruning, construction and combination of these two. Another important subject is hardware implementation of neural networks. In the first part of this thesis, two optimisation algorithms, a Genetic Algorithm and an algorithm combining pruning and construction are implemented and compared. In the second part of the thesis a new sensitivity based optimisation technique is developed. The weights of a resultant network obtained by above algorithms are updated according to a sensitivity criterion to obtain optimum structure for hardware implementation. The results showed that, if the process is carefully applied suitable network structures can be obtained without loss of performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Sayısal sertifikalar, klasik sertifikasyon sistemlerinde açık anahtarları onaylamak için kullanılmaktadırlar. Bu tezde, içice sertifikasyon isimli yeni bir sertifikasyon modeli önerilmiştir. Basit bir deyişle, içice sertifika, başka bir sertifikayı onaylayan sertifika olarak tanımlanabilir. İçice sertifikasyon modeli, konu sertifika doğrulama isimli yeni bir sertifika doğrulama yöntemini de ortaya çıkarmıştır. İçice sertifikalar, Açık Anahtar Altyapıları 'nda (PKI) klasik sertifikalar ile birlikte kullanılabilirler. İçice sertifika tabanlı PKI (NPKI) denen bu şekildeki bir PKI da bu tezde önerilmiştir. Bunlardan başka olarak bu tezde, konu sertifika doğrulama ve NPKI'da sertifika yolu doğrulamanın, klasik şifreleme tabanlı sertifika ve sertifika yolu doğrulama yöntemleri ile aym güvenceye sahip olduğu gösterilmiştir. İçice sertifikalar, klasik sertifikalardan daha az garanti verirler ve onları üretmek için hiçbir güven varsayımında bulunmaya gerek yoktur. Bu şekilde, NPKI 'daki sertifika üreticileri ve doğrulayıcıları daha esnek olurlar. Bu tezde, içice sertifikasyon ek yükü ve verim artışım gösterebilmek için analitik ve benzetimsel başarım analizleri de yapılmıştır. Bu analizler, konu sertifika doğrulama yönteminin ve NPKI'da içice sertifika kullanımının, şifreleme tabanlı sertifika ve sertifika yolu doğrulama yöntemlerine göre doğrulama zamanını önemli derecede iyileştirdiğini göstermiştir. İçice sertifikasyonun mecbur tutulduğu durumlarda, fazla sayıda içice sertifika üretiminin getirdiği ek yük, NPKI'daki içice sertifikasyonun dezavantajıdır. Ancak, bu ek yük, hızlı bir şekilde doğrulanabilen sertifika yollan elde edebilmek için kabul edilebilir bir ek yüktür.","IV ABSTRACT Digital certificates are employed in existing classical certification systems to certify the public keys of the users. In this thesis, a new certification scheme, which is called nested certification, is proposed. In simple terms, a nested certificate is defined as a certificate to certify another certificate. The nested certification scheme brings out a new certificate verification method, called subject certificate verification. Nested certificates can be used together with classical certificates in the Public Key Infrastructures (PKIs). Such a PKI, which is called Nested certificate based PKI (NPKI), is proposed in this thesis also. Moreover, it is shown in this thesis that subject certificate verification and the verification of certificate paths in NPKI have the same confidence as the classical cryptographic certificate and certificate path verification methods. Nested certificates give less assurance than the classical certificates and no trust assumptions are necessary to issue them. In this wav, the certificate issuers and verifiers of NPKI become more flexible. In this thesis, analytical and simulation based performance analyses are also carried out, in order to show the nested certification overhead and the efficiency improvement in certificate and certificate path verification. These analyses show that the subject certificate verification method and the usage of nested certificates in NPKI significantly improve the verification times as compared to cryptographic certificate and certificate path verification methods. The disadvantage of nested certification in NPKI is the overhead of a large number of nested certificate issuances, for the cases where nested certification is enforced. However, this overhead is acceptable in order to have quickly verifiable certificate paths."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Konuşma tanımada görsel bilgi kullanılması insan konuşmasının tanınmasında önemli ipuçları verir. Görsel-işitsel konuşma tanıma sistemleri akustik ses bilgisinin yanısıra konuşma esnasında dudakların hareketine bağlı öznitelikleri de kullanırlar. Bu tezde değişik insanlardan örneklenmiş olan 'sıfır' dan 'dokuz' a kadar Türkçe rakamları yüksek başarıyla tanıyabilecek görsel ve işitsel bilgi kullanani, kısıtlı kelime hazneli bir konuşma tanıma sistemi geliştirilmesi hedeflenmiştir. Kullanılan tekniklerin bir kısmı literatürde varolan güncel tekniklerdir, diğer kısmıysa güncel tekniklerin geliştirilmesiyle elde edilmiştir. Çalışma üç ana başlıkta toplanabilir: öznitelik çıkarımı, konuşma tanıma, ve tanıma motorlarından elde edilen sonuçların birleştirilmesi. Öznitelik çıkarımı konuşmanın görsel ve işitsel karakteristiklerini çıkarsama amaçlıdır. İşitsel öznitelik olarak kepstral katsayılar seçilmiştir. Görsel öznitelik çıkarımı kısmında ise değişik teknikler denenmiştir: resmin yoğunluğu ve geometrisi dikkate alınmıştır; dudak modelinin katsayılarına bakılmıştır; dudakların biçim ve konumunda değişikliğe yol açan dinamik öznitelikler gözlemlenmiştir. Tanıma amacıyla iki sınıflandıncı yaratılmıştır. Bunlardan birincisi Saklı Markov Modeü, ikincisi Bulanık K- Yakın Komşu sınıflandırıcısıdır. Son olarak sonuçların birleştirilmesi amacıyla iki değişik teknik geliştirilmiştir.","IV ABSTRACT Visual information in speech recognition provides important clues for the understanding of human speech. Audio-Visual Speech Recognition systems use features that are related to Up movements in addition to acoustic information. In this thesis an attempt is made for building a limited-vocabulary speech recognition system that gives good results in the recognition of isolated Turkish digits from zero to nine, uttered by different speakers, using both audio and visual information. Some of the techniques used here are similar to contemporary approaches and some are modifications of the existing ones. The work consists of three main parts: feature extraction, speech recognition, and integration of the results achieved by the recognition engines. Cepstral coefficients, have been selected as audio features. In visual feature extraction, different approaches have been taken: intensity and geometry of the image are considered; parameters of the Up-model are used; and dynamics features, which account for the changing of lip shapes and positions, are considered. For the recognition purposes, two different classifiers are created. The first one is an HMM and the second one is a Fuzzy K-Nearest Neighbor classifier. Furthermore, two different kinds of techniques for integration of the results are developed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"YAPAY SINIR AĞLARI İLE ROBOT KOLU YÖRÜNGESİNİN DENETİMİ ÖZET Gün geçtikçe, robot manipülatörlerinin endüstriyel otomasyon ve bilgisayar destekli üretim alanlarındaki önemi artmaktadır. Diğer yandan robot kontrolü uygulamalarında gerekli olan yüksek hassasiyet ve yüksek işlem hızı gibi özelliklerin sağlanması için, robotun etkileşimli ve doğrusal olmayan yapısı nedeniyle buna uygun, yeni. ve daha etkin kontrol metotları gerekmektedir. Bununla birlikte günümüzdeki robot kollarının büyük bir kısmı doğrusal olmayan davranışları dikkate almayan kontrol yapıları ile işletilmektedir. Doğal yapısı itibari ile. sahip olduğu geniş işlem hacmi, karmaşık ve doğrusal olmayan sistemlere uygunluğu nedeniyle yapay sinir ağları robotların tanılanmasında ve kontrolünde etkili olmaktadırlar. Bu çerçevede, gerek farklı blok diyagramları gerekse farklı öğrenme tipilerine göre yapay sinir ağlarıyla gerçekleştirilen robot kontrol çalışmaları başarılı bir şekilde gerçekleştirilmiştir. Ayrıca, gerçek zamanda gerçekleşecek öğrenme ile de, robotun dinamik yapısındaki önceden kestirilemeyen veya bilinmeyen değişikliklere uyum sağlayan bir kontrolör tasarımı mümkündür.","TRAJECTORY CONTROL OF A ROBOTIC MANIPULATOR USING ARTIFICIAL NEURAL NETWORKS ABSTRACT Robotic manipulators have become increasingly important in the field of flexible automation. On the other hand, high-speed and high-precision trajectory tracking is one of the indispensable requirements for versatile robotic applications. Thus, the need of new control strategies capable of dealing with highly complex and nonlinear systems even under uncertainties has appeared. Although numerous conventional control architectures are still used in the industrial applications, most of them assume the plant to be linear with unknown parameters and hence the more abrupt the nonlinearity, the stronger decline in the performance of the controller. Due to the natural properties of the neural networks, they are ideally suited for path tracking control process. Using these attractive features, artificial neural networks have been shown to be extremely efficient in identification and control of the two-link planar robot arm. Several controllers proposed in this work differ from each other mainly by their training procedure as well as their block diagram structure. Additionally, the neuro-control architectures may be also realized by using on-line learning procedure so that the neuro-controller has adaptation capability to unpredicted dynamics changes."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET On yedi adet naif dişi sıçana uygulanan Porsolt Testi'nden elde edilen veri yapay sinir ağları kullanılarak analiz edilmiştir. Öğrenilmiş çaresizlik düzeyini öngörmek için Porsolt Testi'nin ilk günündeki hareketsizleşme süresi ve kafa sallama sayısının kul lanıldığı bir model öne sürülmektedir. Öğrenilmiş çaresizlik düzeyini öngörmede beşinci ve altıncı dakikalardaki kafa sallama sayısının özellikle etkili olduğu bulunmuştur. Ayrıca Porsolt Testi'nin ilk günündeki hareketsizleşme süresinin de öngörme miktarına katkıda bulunduğu, fakat çırpınma süresinin etkili olmadığı gözlemlenmiştir. Bir yapay sinir ağları yazılımı geliştirilmiştir ve çalışmaya eklenmiştir.","IV ABSTRACT Porsolt Test data of seventeen naive female rats have been analyzed using artificial neural networks. A model for predicting LD using the duration of immobilization and number of wet-dog-shake behaviors in PST1 has been proposed. It has been found out that the number of wet-dog-shake behaviors in the fifth and sixth minutes of PST1 is an especially effective variable in predicting learned despair. Duration of immobilization in PST1 also proved to be effective, however the struggle behavior turned out to be irrelevant. An ANN Software package has been included."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KAOTIK SİSTEMLER İÇİN YAPAY SINIR AĞI TABANLI LOKAL DENETİM VE HEDEFLEME YÖNTEMİ Son on yılda, kaotik dinamikler için Ott, Grebogi ve Yorke tarafından önerilen lokal denetim yöntemi (OGY yöntemi) lineer olmayan sistemler konusunda çalışan pek çok araştırmacının ilgisini çekmiştir. Bu yöntem, kabul edilebilir bir denetim performası sağlamak için kaotik dinamiklerin bazı özelliklerini kullanır. OGY yöntemi bir hedefi yani seçilmiş bir kararsız denge noktasını veya kararsız bir periyodik yörüngeyi sistemin denklemlerini gerektirmeden kararlı hale getirebilir. Literatürde bu yaklaşımın pek çok uyarlamaları mevcuttur. Denetimin lokal doğrusallaştırmaya dayanmasından dolayı bu yöntemlerin, sistemin hedef civarına gelene kadar beklemek zorunda olması onların en önemli dezavantajıdır. OGY yöntemi ve onun genişletilmiş versiyonlarına ek olarak yapay sinir ağlan da kaos denetiminde halen kullanılmaktadır. Bu çalışmanın amacı öncelikle, sistemin denklemlerini gerektirmeden hedefi kararlı hale getirirken, sistemin hedefe ortalama erişim zamanını azaltmaktır. Sistem dmamiklerinin lokal ve yan global modellenmesi, radyal bazlı fonksiyonlan kullanan bir yapay sinir ağı ile gerçeklenmiştir. Bu yöntemle, ortalama erişim zamanında yeterli bir azalma ve istenilen hedefte doyurucu bir kararlılık elde edilmiştir","IV A NEURAL NETWORK BASED LOCAL CONTROL AND TARGETING METHOD FOR CHAOTIC DYNAMICS The local control method for chaotic dynamics as proposed by Ott, Grebogi and Yorke (the OGY method) has drawn the attention of many nonlinear system researchers within the last decade.This method exploits the properties of chaotic dynamics for an acceptable control performance. The OGY method can stabilize a target, i.e. a chosen unstable equilibrium point or an unstable periodic orbit, without prior knowledge about the system dynamics. In the literature there exist many extensions and modifications of this approach. The major drawback of these methods is the fact that they have to wait until the system converges to a close neighbourhood of the target because the control is based on linearization. In addition to the OGY method and its extensions, neural networks are also being utilized for chaotic control. The aim of this work is to achieve the stabilization of the target without prior knowledge about the system dynamics, while reducing the average time to reach the close neighbourhood. The local and semiglobal modelling of the dynamics is achieved using a neural network employing radial basis functions. A sufficient reduction in the reaching time and satisfactory stabilization of the desired target has been achived by this method."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışma ATM ağlarında sanal yolların paralel tavlamalı genetik algoritması (PAGA - Parallel Annealed Genetic Algorithm) kullanılarak eniyilemesi üzerinedir. Günümüz bilgisayar ağlarında her biri ayrı servis kalitesi (QoS - Quality of Service) gerektiren birçok değişik hizmetin bir arada varolabilmesi, kaynakların etkili kullanımını temel bir konu durumuna getirir. Sanal yol kavramı çok esnek bir araçtır ve eniyilemesi ağ performansını önemli ölçüde etkiler. Bu eniyilemenin amacı, ağ topolojisi, bağ kapasiteleri ve trafik isterleri verilmişken ağdaki maksimum kullanım oranım en aza indirmektir. Bu problemi çözmek için paralel tavlamalı genetik algoritması kullanılmıştır. Genetik algoritmalarının performansı parametrelerine çok bağlı olduğundan her bilgisayardaki genetik algoritmayı değişik parametrelerle paralel olarak çalıştırdık. Programın çalışması sırasında da bilgisayarlar arasında bazı bilgilerin alışverişini gerçekleştirdik. Sonuçların iyiliğini ve çözüm yönteminin performansım ölçmek için algoritma çeşitli ağ topolojilerinde ve çeşitli trafik isterlerinde çalıştırıldı. Bu koşullarda PAGA'nın performansı bir dizi sonuçla karşılaştırıldı. Tüm bu ölçümler algoritmanın çok iyi çözümler sağladığım gösterdi.","IV ABSTRACT This study is about the optimization of virtual paths in ATM networks using parallel annealed genetic algorithm (PAGA). The coexistence of a wide range of services with different quality of service (QoS) requirements in today's networks makes the efficient use of resources a major issue. The virtual path concept is a very flexible tool, and its optimization affects the performance of the network greatly. The objective of this optimization is to minimize maximum utilization in the network, where network topology, link capacities, and traffic requirements are given. To solve the problem parallel annealed genetic algorithm is used. Since the performances of genetic algorithms depend a lot on the parameters, we run each genetic algorithm with different parameters on each computer in parallel. We also perform some information exchange between the computers during the run. In order to measure the goodness of the solutions and the performance of the solution method; the algorithm is run with different network topologies, and different traffic requirements. The performance of PAGA is compared to several competitors under these conditions. All these measurements show that the algorithm provides very good solutions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Günümüzün rekabetin yüksek olduğu küresel pazarlarında, hayatta kalabilmek için kalite odaklı bir yaklaşım kaçınılmazdır. Kalite ile ilgili konularda bilincin, motivasyonun ve özverinin artırılabilmesi için, şirketlerde, kuruluşlarda ve nihayet toplumun bütününde toplam kalite yönetimi (TKY) konusunda eğitim şarttır. Bu çalışma, toplam kalite yönetimi için web tabanlı bir benzetim oyunu geliştirmek üzere yapılmıştır. Ana amaç, yöneticilerin TKY konusundaki düşünce modellerini zenginleştirmektir. Bu yönetim oyununun iskeleti oluşturulurken, ""Malcolm Baldrige National Quality Award"" Performans Mükelliği Kriterleri ve ""The European Quality Award"" Modeli'nden yararlanılmıştır.","IV ABSTRACT In today's highly competitive global markets, quality mind set is essential for survival. In order to increase management awareness, motivation and commitment in quality related issues, effective training in total quality management (TQM) is crucial at all levels of business companies, institutions and ultimately for the society as a whole. This study is undertaken to develop a Web-based simulation game for total quality management. The primary objective is to enrich the managers' mental models about TQM practice. The components of Malcolm Baldrige National Quality Award Criteria for Performance Excellence and The European Quality Award Model have been influential in structuring the conceptual framework for this management game."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tezde, renkli imgelerin nicemlenmesi ve kıpırtılanması maksadıyla üç grup bulanık algoritma önerilmiştir. İlk grupta yer alan algoritmalar bulanık nicemleme maksatlıdır. İlk algoritma ile bir bölütleme indisini içeren objektif fonksiyon en küçüklenmiştir. Amaç, bulanık c- merkez algoritmasından daha hızlı ve kaliteli bir palet üretmektir, ikinci algoritma ile öbekler arası mesafe artırılarak kıpırtılama sonrası daha fazla renk sanısı yaratılmıştır. Bulanık hata dağıtımı yeni bir kıpırtılama algoritmasıdır. Amaç, piksellerin tüm palet renklerine olan üyeliklerinin hesaplanması ve bir itme-çekme mekanizması ile hata dağıtımı yöntemiyle nicemleme sonucu oluşan bozulmaların en az hata artımı ile giderilmesidir. Ayrıca, önerilen L-filtre metodlarıyla hata önemli ölçüde artınlmaksızm algoritma hızı artırılmıştır. Gerek sübjektif testlerimiz, gerekse objektif hata kriterleri her iki algoritmanın da üstünlüğünü ortaya koymuştur. Nicemlemenin amacı hatayı en küçüklemek iken, kıpırtılama hatayı artırarak görsel kaliteyi artırır. Bu çelişki nedeniyle, renkli imgelerin bileşik nicemleme ve kıpırtılanması maksadıyla iki yeni bulanık yöntem önerilmiştir. Her iki algoritma da bağımsız eşleniklerine göre hatayı azaltmışlardır.","IV ABSTRACT In this thesis, three new groups of algorithms using fuzzy techniques axe de veloped for color image quantization and dithering. The algorithms in the first group are for fuzzy quantization. In the first algo rithm, we minimize an objective function including a term for partition index. The goal is to obtain a better codebook faster than the fuzzy c-means algorithm. In the sec ond algorithm, we minimize an objective function including an inter-cluster separation term to obtain a color palette which is more suitable for dithering. The algorithms for fuzzy error diffusion introduce a novel way to perform error diffusion dithering. The goal is to hide the quantization errors by error diffusion, while preventing the excess accumulation of errors that cause visual artifacts such as color streaks and impulses through an attraction-repulsion schema utilizing fuzzy membership values. We also explored methods to speed up the fuzzy error diffusion process through an L-filter approach. Our subjective tests as well as objective error measures show the superiority of both algorithms. The goal of the quantization is to minimize mse, while dithering increases the mse to obtain a visually better image. Because of this contradiction, we introduced two new fuzzy methodologies to jointly quantize and dither the color images. Two algorithms are developed for this purpose and better performance is obtained relative to their separate counterparts."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"SEÇİCİ ALGI KULLANILARAK IKI BOYUTLU ŞEKİL TANIMANIN TEORİK VE PRATİK ANALİZİ ÖZET Bu tezde, seçici algı ile sabitlerime noktalan dizisi oluşturulması ve bu dizinin şekil tanıma işleri için kullanımı, yapay potansiyel fonksiyonlar kullanılarak matematiksel bir çerçevede incelenmiştir. Yalan zamandaki çalışmalar, seçici algılamanın tanıma işlemlerinin gerçek zamanda uygulanabilirliğini önemli ölçüde arttırdığını göstermektedir. Fakat seçici algının temelini oluşturan sabitlerime noktaları dizisinin oluşturulmasının formülasyonu konusunda sınırlı sayıda teorik çalışma yapılmıştır. Önceki çalışmalarımızda, hali hazırdaki sabitlerime noktasının etrafında basit hesaplamalar yaparak bir sonraki sabitlerime noktasını belirleyen buluşsal bir algoritma geliştirilmişti. Sunulan tez, bunu - sabitlerime noktaları dizisinin oluşturulması ve kullanılması- matematiksel bir çerçevede yapay potansiyel fonksiyonları kullanarak gerçekleştirmektedir. Çalışmamız BUVIS -görsel algı yeteneği olan bir denetleme sistemi- üzerinde uygulamaya geçirilmişti. Sistemin değişik ışıklandırma koşullarındaki performansı ve gerçek zamanda uygulanabilirliği, endüstriyel nesneler kullanılarak yapılan deneylerle irdelenmiştir.","IV THEORETICAL AND PRACTICAL ASPECTS OF 2D SHAPE ASSESSMENT USING SELECTIVE FIXATIONS ABSTRACT In this thesis, we present a mathematical framework for selective fixation generation and its usage through artificial potential functions. Recent research suggests that computational advantages may be realized for vision problems when cameras are capable of fixating on areas of interest. Studies on the formalization of the task of selecting a sequence of fixation points and saccade directions that efficiently examine the area being searched have been limited. In our earlier work, we have developed a simple heuristic algorithm based on simple computations on the periphery region of current fixation point to determine a new visual target. The MS research presented here aims to construct the underlying theory of selective fixation control using artificial potential functions. We implemented the approach on BUVIS, an inspection system endowed with visual attention capability. Experiments demonstrating the robustness to lighting conditions and real-timeness of the system are presented for industrial objects with varying illumination conditions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖRTÜK ÇOKTERİMLİLER İÇİN CEBİRSEL DEĞİŞMEZLER ÖRNEK-OLAY İNCELEMESİ: TÜRK EL DOKUMASI HALILARDAKİ DESENLER ÖZET Örtük çokterimliler, karmaşık nesneler için çok iyi temsil gücüne sahip olmalari ile tanınırlar ve bu yüzden bilgisayar görüsü, grafik, ve bilgisayar destekli tasarim alamnda gittikçe büyüyen kullanım alanları mevcuttur. Nesneleri örtük çokterimlilerle modellemeye dayalı olarak tammaya çalışan her sistem, çokterimlilere atanıp, öklid ve ilgin gibi kordinat dönüşümleri altında değişmeyen değerler olan değişmezleri kullanır. Bu tezde, örtük çokterimli eğrilerin kullanımını ele alınmakla birlikte, literatürde takdim edilmiş bulunan çeşitli değişmezlerin performansları da değerlendirilmiştir. Bunun ötesinde, konik faktör merkezleri ve çizgi kesişimlerini içeren ilintili noktalar kullanılarak, nesnelerimizin örtük çokterimli modellerinin kuvantik ve ilgin denkliği, karşılık gelen değişmezlerle test edilmiştir. Bu tezde Tük el dokuması halılarından çıkarılan nesneler bilgi bankasında depolanmak üzere örtük çokterimli fonksiyonlar ile modellenmiş; daha sonra, kordinat dönüşümü geçirmiş bir nesnenin örtük çokterimli fonksiyonu verilerek bu nesnenin değişmezler öznitelik olarak kulanılmak suretiyle tanınması senaryosu tartışılmıştır. Bunun ötesinde, değişmezlerin gürültüye olan direncini görmek için; bazı nesnelere gürültü eklenmiştir.","IV ALGEBRAIC INVARIANTS FOR IMPLICIT POLYNOMIALS CASE STUDY: PATTERNS IN TURKISH HAND-WOVEN CARPETS ABSTRACT Implicit polynomials are known as having very good representation power for complicated objects, and there is growing use of them in computer vision, graphics and CAD. Every system that tries to recognize objects based on their representation by implicit polynomials uses invariants, which are quantities assigned to polynomials that do not change under coordinate transformations such as Euclidean and affine. In this thesis, we treat the use of implicit polynomial curves and asses the performances of many different invariants already introduced in the literature. Moreover, by using the related points, which includes conic factor centers and line intersections, we test the quantic and affine equivalence of implicit polynomial models of our objects by using respective invariants. The scenario discussed in this thesis is one where we have a set of objects extracted from Turkish Hand-woven Carpets and modeled as implicit polynomial functions to be stored in the database. Then, given an implicit polynomial function of an object, which experienced coordinate transformation, we want to recognize which object it is originally by using invariants as features of it. Moreover, noise is added to the some objects to see the resistance of these invariants to noise."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Robot uygulamaları çağdaş teknolojinin hızla gelişen bir alanı olup, daha iyi robot denetimi sağlayabilmek için bir çok denetim algoritması geliştirilmektedir. Yüksek hız ve yüksek hassasiyet performansına olan gereksinimin artması, yeni ve alternatif denetim yöntemleri bulmayı zorunlu kılmaktadır. Uyarlamah denetim yöntemi, uzun bir geçmişe sahip olmasına rağmen sürekli olarak geliştirilmekte ve özellikle değişken koşullarda çalışan robotlar için en uygun denetim yöntemi olarak görünmektedir. Bu tez çalışmasında, uyarlamalı robot denetiminin ana yöntemleri ile birlikte, oldukça yeni olan bir doğrudan uyarlamalı denetim yöntemi araştırılmış ve test edilmiştir. Uygulanan her bir yöntemin istenilen yolu izlemedeki başarısı, kararlılığı ve gürültü duyarlılığı formülize edilerek Matlab 5.0 simülasyonlanna uyarlanmıştır. Son olarak, günümüzde hala geniş bir uygulama alanına sahip bulunan klasik PD denetim yöntemi ile bir karşılaştırma yapılmış ve doğrudan uyarlamalı denetim yöntemleri detaylı olarak ele alınmıştır.","IV ABSTRACT Robotics is a rapidly developing area of modern technology and various control algorithms have been proposed in order to provide better robotic control. Increasing demands for high-speed, high-precision performance force the researches through advising alternative and new control methods. Adaptive control, though it has relatively long past, is continuously improving and seems to be the optimal control method for some robot control tasks requiring higher precision in a changing environment. Available main methods of adaptive control have been investigated and tested in this thesis study, as well as a very recent method of direct adaptive control. Success of each method to follow the desired trajectory, stability and noise sensitivity have been formulated and simulated. All the simulations have been performed in Matlab 5.0 and results are included. Finally, a brief comparison of adaptive control to classical PD control, which is being still widely used, is given and characteristics of direct adaptive control is discussed in detail."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Benzeşim modellemesi, çok işlemcili bilgisayar sistemlerinin başarım modellenmesinde kullanılan en yaygın metodlardan biridir. Bu çalışmada, yol tabanlı bellek paylaşımlı çok işlemcili sistemlerin başarım ölçümü amacıyla yeni bir benzeşim modeli geliştirilmiş ve bu modele dayalı bir simulator gerçekleştirilmiştir. Simülatörün ana girdileri, bilgisayar sisteminin mimarisi ve işyükü parametreleridir. Simülatörde, bu girdileri işleyen birçok algoritma vardır. Ana algoritmalar, yol bulma, posta kutusu yeri ve hafıza ünitelerini sınıflama algoritmalarıdır. Bunlara ek olarak, simülatörde birçok protokol mevcuttur. Geçerlilik ve doğrulama çalışmaları da, benzeşim modeli geliştirmede çok önemli çalışmalardır. Benzeşimin doğrulanması, literatürde bulunan birçok analitik model ile gerçekleştirilmiştir. Geçerlilik ise TOMP prototipinin performans sonuçlan ile gerçekleştirilmiştir. Çalışmanın sonunda, birçok örnek bulunmaktadır. Bazı mimarilerin farklı işyükü koşullarındaki performans değerleri sunulmuş ve karşılaştırılmıştır.","Simulation modelling is one of the most common methods to predict the performance of multiprocessor computer systems. In this study, a new simulation model is developed and a simulator based on this model is implemented to predict the performance of the bus based shared memory multiprocessor systems. The main inputs of the simulator are representation of the architecture and workload parameters. There are several proposed algorithms to process these inputs, including path finding, mailbox location, and memory units clustering algorithms. A number of protocols are also devised and implemented in the simulator. The verification and validation studies are very important for a simulator. The verification study is realised by the help of several analytical models, which are available in the literature. The validation is realised by the performance results of the TOMP prototype. In the last part of the thesis, several sample runs are provided to analyse and compare certain architectures under various workload conditions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Son otuz yılda artan petrol fiyatları ve yoğunlaşan deniz trafiği, bilim adamlarını büyüyen yakıt tüketimini azaltmak ve güvenliği arttırmak amacıyla gemiler için otomatik pilotlar geliştirmeye zorladı. Gemilerin burun açılarını denetlemek amacıyla önerilen ilk denetleyicilerde uyarlama yani değişen çevre şartlarına göre kendini ayarlama özelliği yoktu. Uyarlamasız denetim yöntemlerin değişken çevre şartlan altında yetersizliğinin ispatlanması, daha gelişmiş denetleyicilerin tasarımına neden oldu. Ve ardından değişik adaptasyon tipleri önerildi ve geliştirildi. Bunların pekçoğu hala gemi yönlendirilmesinde kullanılmaktadır. Bu tezde uyarlama özelliği olmayan denetleme mekanizmalarından oransal-türevsel (OT) ve doğrusal karesel denetleyici (DKD), uyarlama özelliği olan denetleyicilerden de model dayanaklı uyarlamalı denetim (MDUD) yöntemlerinin iki tipi, doğrusal olmayan kargo gemi modeli üzerinde denenmiştir. Herbir metod için, denetim yöntemi hakkında kısa bir bilgi verildikten sonra denetim işaretinin çıkanını gösterilmiştir. Daha sonra da herbir teknik için, doğrusal olmayan kargo gemi modeli üzerinden alman simülasyon sonuçlan sunulmuştur. Çevresel bozucu faktörlerin genel performans üzerindeki etkisini gösterebilmek amacıyla, denetleme yordamlarının herbirisinde rüzgar etkisi dümen üzerine eklenmiştir. Son olarak, yapılan simülasyonlar göz önüne alınarak tüm denetleme mekanizmalarının avantaj ve dezavantajlan birbirleri ile karşılaştınlmıştır.","In the last three decades, climbing fuel prices and crowding sea traffic have forced scientists to develop autopilots for ships to reduce an enormous amount of fuel consumption and to increase safety. The earlier control schemes proposed for controlling the directional heading of the ships were nonadaptive, which means that the control strategy does not have any adjustment mechanism to update its parameters depending on environmental changes. Since nonadaptive schemes proved to be inadequate under varying environmental conditions, research was directed towards the design of advanced controllers. So, several strategies for adaptation of the controllers have been proposed and improved. Most of them are still in use in steering cargo ships. In this thesis, two nonadaptive strategies, namely PD and linear quadratic control, and two adaptive schemes, namely model reference adaptive control with gradient and Lyapunov approaches are utilized to control heading of the ship. For each method, the derivation of control signal is developed, after some brief information about the theory of the control scheme. Then, for each technique, the simulation results on the nonlinear cargo ship model are presented. In order to illustrate the effects of disturbances on the overall performance, a wind effect is added to the rudder for each control scheme. Lastly, based on these simulations, the advantages and disadvantages of the schemes are compared."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde iyi bilinen iki standart kullanılarak her çeşit yazilim ürünü için kullanılabilecek bir yazilim hayat çevrimi geliştirilmiştir. Geleneksel waterfall modeli temel model olarak kullanılmış ve iki standarttan seçilen aktiviteler bu model üzerinde gereken aşamalarda uygulanmıştır. Bu hayat çevrimi geliştirildikten sonra, onun projeye özel hayat çevrimleri tanımlamakta kullanılmasını sağlayan bir yazilim geliştirilmiştir. Bu yazilim projeye özel hayat çevriminin tanımlanmasının yanında, tanımlanan hayat çevrimi içinde yapılan aktivitelerle ilgili bilgilerin saklanmasını da sağlamaktadır.","In this thesis a generic software lifecycle is developed using the two well known standards. The traditional waterfall lifecycle model is used as the basic model onto which the activities selected from these two standards are mapped. After developing the generic lifecycle, a management tool is developed to use the generic lifecycle to define project specific software lifecycles. Besides the definition of the lifecycle, keeping the records related to the activities performed in that lifecycle, is performed using this tool."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Artan bir uygulama alanına sahip olan robot kollarına, görevlerini yerine getirmeleri amacıyla çeşitli kontrol yöntemleri uygulanmaktadır. Bu noktadan hareketle çalışmada PID kontrol, melez bulanık mantıklı PDD kontrol ve kayan yüzey kipli kontrol yöntemleri iki eklemli robot koluna uygulanmıştır. PID ve bulanık mantıklı PID kontrol yöntemleri için robot koluna bir doğrusallaştırma yöntemi uygulanmıştır. Bu yöntem sayesinde doğrusal olmayan bağımlı robot dinamik yapısı doğrusallaştınlmaktadır. Kayan yüzey kipli kontrol yönteminde uygulanacak kontrol kuralının belirlenmesi için uygulanabilen yöntemlerden ulaşma kuralı yöntemi seçilmiş ve benzeşimi yapılmıştır. Son olarak belirtilen kontrol teknikleri başaran ölçütlerine göre karşılaştırılmaktadır.","Robotic manipulators which have an increasing usage in the industrial applications, are subjected to various control methods to perform their tasks. Through that point, in this work PID control, hybrid fuzzy-PID control and also variable structure control methods are simulated on two-degree of freedom manipulator. A linearization method is used for the PID and fuzzy-PID controller applications, by which the nonlinear, coupled robot dynamic structure is linearized. Among the available methods to derive the control law in VSC, the reaching law method is selected and simulated on the manipulator. All the mentioned control techniques are compared according to some performance criteria's."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Robot yönlendirme alanında, belirsizlik en önemli problemlerden biridir. Biz, mantıklı davranan robotlara ihtiyaç duyuyoruz. Fakat, belirsiz durumlar, olasılık içeren ortamlar ve mekanik problemler önümüzde durun ana engellerdir. Bugün, ""Partially Observable Markov Decision Process (POMDP)""ler bu problemler için tatmin edici tek çözüm olarak görünmektedir. POMDP'ler ""Markov Decision Process (MDP)""lerden kismi gözlemlenebilme özelliği eklenerek elde edilmiş bir kümedir. POMDP'ler yardımıyla bir robot, labirent benzeri bir ortamda yolunu kaybetme problemini çözümleyebilir. Yani bu konuda mantıklı hareket edebilir. Bu tez boyunca POMDP'lerin robotlar üzerinde uygulanmaları, bunları içeren problemler ve bu problemlere uygun çözümler incelenmiştir. Buna ek olarak POMDP problemleri için hazırlanmış bazı algoritmalar hayata geçirilmiştir. Bu algoritmalar bu tür problemler üzerinde çalıştırılmış ve sonuçlar toplanmıştır. Bu çalışmada hayata geçirilen algoritmalar, Cheng algoritması, SPOVA algoritması, SPOVA- RL algoritması ve Value Iteration algoritmasıdır. Bunların herbiri kendine has özelliklere sahiptir ve herbiri bir çözüme ulaşabilmek için değişik yöntemler kullanır. Aslında, bu dört algoritma POMDP algoritmalarının başka başka katagorilerinin örnekleridir. Özet olarak, bu tez iki ana bölüme ayrılabilir; birinci bölümde POMDP'lerin teorisi açıklanmıştır, ikinci bölümde ise pratikte nasıl çalıştıkları gösterilmiştir.","IV ABSTRACT In robot navigation field, uncertainty is one of the most important problems. We need robots, which are behaving rationally. But, uncertain cases, probabilistic environments and mechanical problems are the main obstacles in front of us. Today, ""Partially Observable Markov Decision Processes (POMDPs)"" seem to be the only satisfactory solution for these problems. POMDPs are elements of a set generated from Markov Decision Processes (MDPs) where partial observability is taken into account. By the help of POMDP structures, the robot can find a way around the problem of loosing its position in a maze-like environment. That means it can behave rationally. Throughout this Thesis, we have examined the POMDP usage in the field of robotics, problems concerning POMDPs and solutions that are suitable to them. In addition to these, to see the things working, we have implemented a bunch of algorithms, which are designed to attack POMDP problems. They are run on such problems and results are collected. The algorithms, which are implemented in this study, are Cheng's algorithm, SPOVA algorithm, SPOVA-RL algorithm and Value Iteration algorithm. Each of them has its own characteristics and every one of them uses different ways to obtain a solution to a POMDP problem. Actually, these four algorithms are examples from different categories of POMDP algorithms. So, in brief this Thesis is divided into two separate parts; the first part presents POMDPs in theory and the second part presents them at work."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma kendi kendine hareket edebilme yeteneğine sahip bir elektrikli süpürge robotunun gelişimi üzerinedir. Bu robot son yıllarda oluşan yeni kavramlar üzerine tasarlanmıştır. Bu kavramlar yapay us, dışlama mimarisi ve diğer baştan aşağı yöntemlerden oluşur. Bütün bu fikirler hareketli bir robot tasarımı için kullanılır: Robotun şeklinden algılayıcılarına, elektroniğinden kontrol yazılımına kadar her kısmı bu fikirler tarafından yönlendirilirler. Robotu tasarlayıp, meydana getirdikten sonra bir takım tepkisel davranışlar göstermesi için programladık. Özerk çalışabilen bu hareketli elektrik süpürgesi robot, kapalı bir alanı bu tepkisel davranışların yardımı ile tarayıp süpürebilmektedir. Robot üzerinde çalıştırılan algoritmalarda 11 adet algılayıcı kullanılmıştır. Tepkisel davranışları robota engellerden kaçınabilme, duvar takip edebilme, kapalı ve dar alanlardan çıkabilme, yer algılama ve park edebilme gibi yetenekler kazandırmıştır. Robotun performans testleri öncelikle yazılan bir simulator üzerinde daha sonra da robotun gerçek bir ortamda çalıştırılması ile sağlanmıştır. Denenen algoritmalar ile yapılan tüm testler sonucunda en iyi performansın yüzde 10 olasılıklı duvar takibi yapan rasgele süpürme hareketinde sağlandığını ortaya koymuştur.","This study presents the results of the development of an autonomous mobile robot which is a domestic autonomous vacuum cleaner. The robot is designed according to some new concepts established in this field during the last decade. These principles are artificial life, subsumption architecture and other bottom-up methodologies. These ideas have been applied to the complete robot design, spanning from the shape of the robot to the sensors, from the electronics to the software control structure. We have built the robot and programmed it to perform various reactive behaviours. The autonomous vacuum cleaner performs area coverage in a room by combining distinct behaviors. The robot has eleven sensors which are used in the algorithms examined. The robot behaviors allow it to avoid obstacles, follow walls, break out of confined areas, detect floor and find a docking area. The performance tests are done through a dedicated simulator and by observation. The experiments performed here were both in the simulator and real-time it appears that the best area coverage algorithm among those tried consisted of a random walk with a probability of 0.10 for following a wall after each encounter with an obstacle."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yazılım geliştirme süreçlerinin iyileştirilebilmesi için öncelikle mevcut sürecin incelenmesi, zayıf ve aksayan yönlerinin belirlenmesi gerekmektedir. Ülkemizdeki yazılım geliştiren firmaların, yazılım geliştirme süreçlerinin araştırılıp incelenmesi de ülkemiz yazılım sektörünün bu alandaki seviyesinin ortaya konulması, zayıf ve güçlü yanlarının belirlenmesi yolunda atılan yararlı bir adımdır. Ülkemizde uygulanan yazılım geliştirme pratiklerinin araştırılmasını konu alan bu tez çalışmasında, ülkemizdeki yazılım geliştiren 30 firmaya uygulanan ESI İyi Yazılım Geliştirme Pratiği Anketi sonuçlan incelenerek değerlendirilmiştir. Ayrıca, elde edilen sonuçlar, Avrupa Topluluğu ülkeleri sonuçlarıyla karşılaştırılmıştır.","Improvement of the software development processes can be accomplished by first assessing the current software process and pointing out the weaknesses and strengths in it. Assessing the software development practices of software developing organizations in our country, is a big step forward, for getting a general idea of the current status of software development process in our country. In this thesis, whose main purpose is to assess the software development practices in our country, the results of the ESI Software Best Practice Questionnaire, that has been applied to 30 software-developing organizations in Turkey, are analyzed. The results are also compared with the implementations of the same questionnaire to the European countries by the European Commission."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışma, yerleri değişmeyen engeller içeren iki boyutlu bir ortamda hareketli bir araç için rota belirlenmesi problemini konu almıştır. Kullanılan yaklaşım, son yıllarda engel dönüşümü ve yol dönüşümü gibi türevleri geliştirilmiş olan uzaklık dönüşümü kavramına dayalıdır. Bu dönüşümler birlikte kullanılarak Voronoi şeması, konfıgürasyon uzayı, çarpışma analizi, ve uzay taraması için yerel ekstremleri olmayan yol gösterici fonksiyonlar kolayca hesaplanmıştır. Çalışma özgün olarak, dar geçişlerin Voronoi şeması yardımıyla kapatılmasını sağlayan tıkayıcı daireler, ve kalınlaştırılmış Voronoi şeması tekniklerini sunmaktadır. Problem uzayı A* tarama yordamıyla yol dönüşümü kullanılarak taranmış ve elde edilen çözüm rotası aracın hareket özelliklerine göre yeniden biçimlendirilmiştir. Bu işlemde öziçli eğrilerden yararlanılmıştır. Aracın önerilen yolu izlemesi için kontrolü ve refleks tepkiler konusu incelenmiştir. Gerçekleştirilen bütün yordam ve veri yapılan nesne yönelimli bir yazılım çatısı altında biraraya getirilmiştir.","A combining and practical approach to the path planning problem of a moving vehicle in a two-dimensional environment with static obstacles is presented. The approach is based on distance transform concept, which has lead to the recent exploration of a set of similar transforms including obstacle transform, and path transform. When used in combination, these transforms provide efficient implementations of Voronoi diagram, C-space, collision detection, and search heuristics without local minima. As new methods, blocking circles (a Voronoi based obstacle growing technique,) and dilated Voronoi diagrams, are proposed. A* search has been implemented using path transform as the heuristic, and results have been smoothed for vehicle constraints. Intrinsic splines have been utilized for smoothing. Control of the vehicle on the planned path, and reactivity issues are discussed. All implementations are collected under an object oriented software framework."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Günümüz bilgisayar ağlarında her biri ayrı servis kalitesi (QoS - quality of service) gerektiren birçok değişik hizmetin bir arada varolabilmesi, kaynakların etkili kullanımını temel bir konu durumuna getirir. Kaynaklan, değişik bant genişliği gereksinimleri olan servislere uyum sağlayacak biçimde atayarak ağ etkinliğini artırmak aranan bir özelliktir. Bu yüzden, Genişbantlı Tümleşik Servisler Sayısal Ağlan 'nın (B- ISDN - Broadband Integrated Services Digital Networks) gerçeklenmesi trafikteki beklenmedik değişiklikleri karşılayabilecek bir denetim düzeneği gerektirir. Esansız Aktanm Kipi (ATM - Asynchronous Transfer Mode) teknolojisi, sanal yol (VP - virtual path) kavramıyla ağ kaynaklannı sanallaştırarak bu esnekliği sağlar. B-ISDN ortamındaki yeni hizmetlerin trafik gereksinimleri yüksek oranda patlamalı, öngörülmesi zor olabilir. Eşdeğer bant genişliği kavramının uygulanması, kapasite gereksinimlerinin kestirilebilmesi için etkili bir yöntem sağlar. Bu kavram aynı zamanda ağ yönetimi, yönlendirme, en iyi biçimde kullanım için ortak bir bağlantı ölçütü tanımlar. Bu çalışmada, VP temelli bir ATM ağ tasanm yöntemi önerilir. Akıl yürütme yoluyla geliştirilen tasanm algoritması, bağlantı isteklerinin kapasite gereksinimlerini bulmak için eşdeğer bant genişliği kavramından yararlanır. Bu yolla, hücre kayıp olasılığı ile tanımlanan QoS yerine getirilir. Algoritma, işlem gecikmesi kısıtlan altında en yüksek fiziksel hat kullanım oranını en aza indirmek üzere, VP yönlendirme, VP ayrıştırma teknikleri uygular. Tasanm algoritmasının elde ettiği çözümlerin kalitesi, değişken ağ topolojileri ile trafik koşullan altında bir dizi sonuçla karşılaştınlır. Algoritmanın başanmı üzerinde yapılan gözlemler, geliştirilen yöntemin VP'ler tanımlayarak ağ kaynaklannın etkin biçimde kullanımını kolaylaştırdığını gösterir.","The coexistence of a wide range of services with different quality of service (QoS) requirements in today's networks makes the efficient use of resources a major issue. It is desirable to improve network efficiency by adaptively assigning resources to services that have different bandwidth demands. Implementing Broadband Integrated Services Digital Networks (B-ISDN) therefore requires a network control scheme that can absorb unexpected traffic fluctuations. Asynchronous Transfer Mode (ATM) technology provides this flexibility by virtualizing network resources through the use of the virtual path (VP) concept. The traffic demand of new services in a B-ISDN environment may be highly bursty and difficult to predict. The implementation of the equivalent bandwidth concept provides an efficient method to estimate capacity requirements. The concept also defines a unified connection metric to be used for network management, routing and optimization. In this study, a method for designing a VP-based ATM network is proposed. The developed heuristic design algorithm uses the equivalent bandwidth concept to compute the capacity requirements of the connection requests. This way, the desired QoS defined by the cell loss probability is guaranteed. The algorithm applies VP routing and separation techniques to minimize the maximum link utilization under processing delay constraints. The quality of the solutions achieved by the heuristic design algorithm is compared to several competitors under varying network topologies and traffic conditions. The observations on the algorithm performance show that the developed method is able to facilitate an efficient use of network resources through the introduction of VPs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Yüksek mertebe daraltma, yüksek mertebe birleştirmeyi denklemsel uslamlamada kullanan bir tekniktir. Bu tezde, yüksek mertebe mantık programlama dili L? çerçevesinde yüksek mertebe daraltmanın tasarımı ve gerçeklemesi sunulmaktadır. Bizim araştırmamızın önceki çalışmalardan ana farkı, bizim yeni meta-programlama tekniklerini yüksek-düzey meta-düzey bir sistemde geliştirmemizdir. Bu yaklaşım, programcıyı bir çok hasaplamayı gerçeklemeden kurtarır ve sonuç olarak gerçekleme problemini programlamacının bakış açısından basitleştirir. Bizim çalışmamız, yüksek mertebe daraltmanın ilk elle tutulur gerçeklemesidir.",IV ABSTRACT Higher-order narrowing is a technique which exploits higher-order unification in equational reasoning. We present the design and the implementation of higher-order narrowing in the framework of the higher-order logic programming language L*.. The main difference between our research and previous work is that we develop new meta- programming techniques in a high-level meta-level system. This approach frees the programmer from implementing most of the computations and as a result significantly simplifies the implementation problem from the programmer's point of view. Our work is the first concrete implementation of higher-order narrowing.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmanın amacı öncelikle Kişisel Yazılım Süreci'ni (KYS) incelemektir. KYS, kişisel ölçekte yazılım sürecini değerlendirmek ve geliştirmek için geliştirilmiş bir yöntemdir, yazılımcıların daha iş tahmini ve ölçmesini sağlamayı temel hedef edinmiştir. KYS, şu anki kullanımı itibariyle yazılan satır sayısını temel sistem ölçüsü olarak kabul eder. Yazılım dünyasında yeni teknik ve araçların hızla gelişmesiyle birlikte, yazılmış program satır sayısı güvenilirliğini kaybeden bir sistem ölçüsü olmuştur. Bu eksikliği gidermek için çeşitli yollar denenmiştir. Bunlardan birisi olan Fonksiyon Noktası Analiz (FNA) yöntemi, yazılmış program satırından daha sağlam ve tahmin oranı yüksek bir metotdur. FNA teknoloji ve çevre etkilerinden bağımsız bir sistem ölçütüdür. Bu çalışmada FNA'nın KYS içinde kullanılması incelendi ve ortaya çıkan karışım metoda uygun, onu destekleyen ve otomatik yapan bir bilgisayar programı yazıldı.","The subject of this work is Personal Software Process (PSP) which is a methodology to assess and improve the software process at personal level. It also helps programmers to estimate and make assessment of their work size. PSP uses Lines of Code (LOC) as the main measure for system sizing. With the development of new techiques and tools in the software world, LOC is no more a reliable size measure. Function Point Analysis (FPA) is a more sound and predictive measure than LOC. FPA is independent of technology and environment system sizing measure.This study proposes using FPA in PSP. A software tool is developed to automate the proposed approach."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bilgisayarlar giderek daha yoğun şekilde renkli imge saklama ve erişim aracı olarak kullanılmaktadır. Renkli imgeler üzerine en çok uygulanan işlemlerden biri renk sayısının azaltılmasıdır. Bu işlem, genellikle birbirinden ayrı uygulanan ve bağımsız olarak çalışan ""nicemleme"" ve ""kıpırtılama"" safhalarından oluşur. Hız ve hassasiyet açısından farklar taşıyan pek çok nicemleme algoritması ve ""hata dağıtma"" gibi çok iyi sonuç veren kıpırtılama algoritmaları mevcuttur. Bu tez, imgenin kıpırtılama sonrası daha iyi gösterilmesini sağlamaya yönelik olarak standart algoritmaların değiştirilmesini konu almaktadır. Bileşik nicemleme ve kıpırtılama yaklaşımlarının prensipleri ve sonuçlan anlatılmaktadır. Bu konudaki mevcut çalışmalar derlenmekte, yeni metodlar sunulmaktadır. Renk paletinin kıpırtılamaya uygunluğuna dayalı yeni bir hata ölçütü önerilmekte ve başarısı gösterilmektedir.","ABSTRACT Computer systems are increasingly used for color image storage and retrieval. One of the main operations on color images is the reduction of the number of different colors used to represent it. This consists of ""quantization"" and ""dithering"" steps, which are usually applied separately and are not aware of each other. There are various quantization algorithms trading off speed and accuracy, and very good dithering algorithms like ""error diffusion"". This thesis describes modification of standard algorithms to get a better representation of the image after dithering. Principles and results are provided on joint quantization and dithering approaches. Existing work is summarized, and new methods are introduced. A new error measure based on the suitability of a palette to dithering is proposed and its performance demonstrated."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"HAVADAN HAVAYA BİR FÜZE OTOPİLOT DENETLEYİCİSİNDE GENETİK ALGORİTMALAR İLE BAŞARIM ARTHHMI ÖZET Modern optimal kontrol teorisi, fiziksel yapısı belirlenen ve dizayn özelliklerini karşılayan bir sistemin performans ölçütünü maksimize veya minimize ederek en uygun denetleyiciyi belirler. Gürbüz çok değişkenli geribesleme dizayn alanındaki son ilerlemeler sistem duyarlılığı ve kararlılık kriterleri gibi klasik yöntemleri adresleyen ek başarım şırıldamalarının gerekliliğini ortaya koyar. Bu önemli gelişmelere rağmen, varolan teorik teknikler ile arzu edilen sistem başarım sınırlamaları giderilemeyen birçok pratik dizayn problemi artış göstermektedir. Havadan havaya bir füzenin denetleyici tasannu gürbüz kontrol problemi olarak ele alınır. Denetleyici parametrelerindeki varyasyonları, modellenmemiş dinamik yapılan, modelleme anında yapılan hataları, ve atmosfer içindeki bilinmeyen karmaşık sinyalleri hesaba katarak sabit bir kontrol sistemi kurmak bu problemde ulaşılması gereken noktadır. Doğrusal ve doğrusal olmayan gürbüz kontrol teknikleri bu problemin çözümünde sürekli hal geri beslemesi baz alınarak tartışılmaktadır. Genetik algoritmalar plant karakteristliğinden bağımsız olarak analitik başarım oluşumuna ihtiyaç duymadan, olasılıksal geçiş kurallarını kullanan nümerik bir araştırma metodudur. Doğrusal geri besleme denetleyicisi sayesinde doğrusal bir füze iskelet dinamiği ve aktuatör durum uzay modeli geliştirilir, ve ayrık zaman simülasyonu gerçekleştirilir. Basit bir genetik algoritma, ağırlıklı doğrusal quadratik başarım indeksini temel alarak oluşturulan uygunluk fonksiyonu ile doğrusal denetleyici parametrelerini optimize etmek için yapılandırılır. Farklı denetleyiciler için gerçekleştirilen simülasyon sonuçlan, genetik algoritmaların yükselme zamanı, yerleşme zamanı, ve aşım değeri gibi sınırlayıcı koşullar karşısında en iyi geri besleme kazanç parametrelerini elde ederek, bu raporun amacını karşılamaktadır.","IV ABSTRACT Modern optimal control theory provides analytical solutions for a set of linear feedback design problems with linear quadratic performance criteria. Recent progress in the field of robust multivariable feedback design has incorporated additional constraints that have addressed the classical concerns with stability margins, system sensitivity, and disturbance rejection. Despite these important advances, many practical design problems arise in which the desired system performance constraints can not be accommodated by the available theoretics techniques. The robust control problem considered here is to design a fixed control system that guarantees the design requirements in the presence of significant bounded uncertainties. These uncertainties consist of variations in the system parameters, unmodeled dynamics, modelling errors, time varying parameters, and unknown disturbances. Genetic Algorithms (GA's), on the other hand, offer a numerical search method that does not require a statement of the mathematical relationship between the performance criteria and the parameter update rule. The objective of this thesis is to demonstrate that GA's provide a method of optimising control system problems with analytically intractable constraints. A linear missile airframe and actuator state space model is developed with linear feedback controller, and implemented in a discrete time simulation. A genetic algorithm is constructed to optimize the linear controller parameters, first with respect to a weighted linear quadratic performance index. Additional performance constraints are then imposed to meet rise time, peak actuator effort, and settling error specifications. Computer simulation results show that the genetic algorithm provides good convergence to near optimal controller designs for each successive combination of constraints."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Kablosuz haberleşme sistemleri, son kullanıcıların hareketliliğine izin verir. Kablosuz haberleşme ağlarının pek çoğu hücresel ağlardır. Hücresel ağların başarımını arttırmak için çeşitli yöntemler bulunmaktadır. Hücresel ağların başarımı sistem mimarisi ve trafik gereksinimlerine olduğu gibi, tasarım değişkenlerinin doğru belirlenmesine de dayanır. Bu başarım aynı zamanda sistem sistem maliyetine de bağlıdır. Hücresel ağların başarımını arttırmanın yollarından birisi de küçük hücre düzeyinin üzerine büyük hücre katmanı kurmaktır. Sistem başarımı, koruma kanallarının kullanılması ve gerektiğinde aramaların üst katmana taşmalarına izin verilmesiyle daha da arttırılabilir. Bu çalışmada tavlama benzetimini, maliyeti en aza indirilecek olan iki katmanlı, koruma kanallı ve taşmalı hücresel ağların, tasarım değişkenlerinin belirlenmesinde kullandık. Örnek çalışmalar üzerinde yaptığımız denemeler oldukça iyi sonuçlar vermiştir.","Wireless communications systems enable the end users to be mobile. Majority of the wireless communications networks are cellular networks. Several methods are developed to increase the performance of the cellular networks. The performance of the cellular networks depend on the correct determination of the design parameters as well as the architecture of the system and the traffic requirements. The performance of cellular networks also depends on their implementation cost. One of the ways to improve the performance of the cellular networks is to build a second layer of macrocells on top of the microcell level. The system performance can further be increased by using guard channels and allowing calls to overflow to the upper layer when needed. In this thesis, we used simulated annealing (SA) to determine the design parameters of two-tier cellular networks with guard channels and overflow, for which the cost is minimized. We tested the system on example problems and obtained promising results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmada, Windows NT ortamında çalışan, bilgisayar telefon uygulamaları için bir uygulama geliştirme programı tasarlanmıştır. Bunun için uygulama geliştirme' de kullanılan değişik yöntemler kullanılmıştır. PC tabanlı ses işleme temelleri Dialogic ses işleme modeli kullanılarak açıklanmıştır. Değişik yazılım parçalan karşılaştırılmış, OLE teknolojisi tartışılmıştır. Bu çalışmada kullanılan yöntem iki bölümden oluşmaktadır: İlk bölümde bilgisayar telefon uygulamalarında kullanılan fonksiyon ve parametreler incelenmiş ve kullanıma açılmıştır. İkinci bölümde ise bu fonksiyon ve parametreler görsel olarak programcıya sunulmuş, ve uygulamının görsel olarak geliştirilmesi tasarlanmıştır. Bilgisayar telefon uygulamasının fonksiyonlarının ve parametrelerinin kullanması uygulama geliştirme yazılını tarafından, yazılmış parçalan ile sağlanmıştır.","IV ABSTRACT In this study, we developed an application generator for computer telephony systems for Windows NT environment. Different approaches for developing the application generator are discussed. Basics of PC-voice processing with specific information about dialogic voice processing model are explained. Different software components are compared and OLE technology is discussed. The approach followed in this study has two parts: the first is exposing computer telephony functionalities and properties for use by other applications. The second part is representing these functionalities and properties visually so that the telephony applications programmers will be able to design and develop their applications visually. Software components are used to enable the applications generator expose computer telephony functionalities and properties."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu çalışma bir konuşma ve konuşmacı tanıma sistemi oluşturulmasında iki değişik ses tanıma yöntemi kullanmaktadır. Birincisi k-Nearest Neighbor (kNN- k inci En Yakın Komşu) yöntemi, ikincisi de Artificial Neural Network (ANN - Yapay Sinir Ağı) yöntemidir. Bu iki yöntem, ses örneklerinin sınıflandırılmasında iki değişik yaklaşımı temsil eder. Sesin ayırdedici özelliklerini bulma işlemi sırasında ilk olarak Sessizlik Ayrıştırma Algoritmasından yararlanılmaktadır. Bu yöntemle örneklerin ses bilgisi taşımayan kısımları ayırdedilir ve dikkate alınmaz. Ses örnekleri Hamming penceresiyle parçalara bölünür ve her parça için Doğrusal Öngörü Katsayıları (LPC) hesaplanır. Bu katsayılar rakam ve konuşmacı tanıma aşamasında kNN ve ANN sınırlandırıcılarının girişinde kullanılmaktadır. Zaman eşleştirmesi için Dinamik Zaman Eşleştirmesi yöntemi kullanıldı. Böylece daha yüksek tanıma yüzdeleri elde edilmesi amaçlandı. Konuşmacı grubu 26 bayan ve 22 erkek konuşmacıdan oluşturuldu ve her konuşmacı her rakamı on kere tekrarladı. Toplam 4800 ses örneği toplandı. Bu örneker eğitim ve test kümelerine ayrıldı ve sistemlerin eğitim ve test aşamalarında kullanıldı. Konuşmacı-bağımlı ve konuşmacı-bağımsız test kümeleri için rakam ve konuşmacı tanıma testleri yapıldı. Sonuçlar çalışmanın Deneyler ve Sonuçlar bölümünde sunuldu.","IV ABSTRACT This study comprises two different recognition methods in the building of a speech and speaker recognition system. The first is the k-Nearest Neighbor (kNN) method, and the second is the Artificial Neural Networks (ANN). These two methods represent two different approaches to the problem of classification of speech samples. The feature extraction phase consists of a pre-processing on samples which is based on the silence detection algorithm. Then the Linear Predictive Coefficients (LPC) are calculated and stored for each speech sample frame which are Hamming windowed. These coefficients are used in the distance measurements for the kNN recognizer and as inputs to the MLP classifier. The patterns are time-aligned using the dynamic time warping technique. The speaker corpus contains 26 female and 22 male speakers who have uttered each digit ten times, thus coming up with a total of 4800 utterances. This data set is divided into training, test and cross-validation sets. These sets were utilized in the training and testing of the kNN and ANN recognizers. Tests are performed with the speaker-dependent and speaker-independent test sets for digit and speaker recognition. The results are presented in the Experiments and Results section of the study."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Asenkron makinalar, diğer elektrik sürücülerine üstünlükleri dolayısıyla, en yaygın olarak kullanılan elektrik makinalarıdır. Vektör denetimi yöntemleri, alternatif akım makinalarının değişken hız uygulamalarında yüksek verimle kullanılmasını sağlayan kontrol metodlardır. Rotor akısı yönlendirmeli denetim, asenkron makina sürücülerine sıkça uygulanan vektör denetimi yöntemleri çeşitlerinden biridir. Bu yöntemin gerçekleştirilebilmesi için, veriminin ve işlemesinin çok duyarlı olduğu rotor mıknatıslama akısının, hem büyüklüğünün hem de hava aralığındaki dağılımının, hızlı ve doğru bir şekilde izlenmesi gerekmektedir. Yapay sinir ağları, son zamanlarda, başka birçok alanlarda olduğu gibi, dinamik sistemlerin tanınması ve kontrol edilmesi alanında yenilikler getirmektedir. Gerekli büyüklüklerin yapay sinir ağlan ile gözlenmesi, diğer tahmin edici tekniklere göre, çok hızlı paralel işlem yapabilme, hata toleranslı olma ve harmonik dalgalılığa karşı duyarsız olma özellikleri gibi bazı üstünlükler sağlamaktadır. Bu çalışmada, rotor akısı yönlendirmeli kontrol yöntemini mümkün kılan, rotor akısı bileşenlerinin yapay sinir ağlan ile gözlenmesinin uygulaması simüle edilmiştir. Yapay sinir ağlarının bu karmaşık kontrol sistemi içerisinde kullanılmasının işletim üzerindeki etkisi ve kullanılması ile birlikte gelen yenilikler tartışılmıştır.","IV ABSTRACT Induction machines are the most widely used electrical machines because of their many advantages compared to the other electrical drives. Recent developments in the field of variable speed drives have made possible the large scale variable speed applications with induction machines. Vector control methods of alternating current machines have become a powerful method among other high performance variable speed applications. Rolor flux oriented control is one of the most commonly used vector control techniques applied to high performance induction machine drives. In order to implement the rotor flux oriented control, the fast and accurate monitoring of the rotor magnetizing flux, both in magnitude and in spatial distribution, is required,where the performance of the control method is very sensitive to the measurement and/or estimation of the quantities to be determined. Neural networks are recently showing good promise for applications in identification and control systems as well as in many other fields. Estimation of the required feedback signals in an induction machine drive by using neural networks brings some distinct advantages of extremely fast parallel computation, immunity from harmonic ripple, and fault tolerance characteristics due to distributed network intelligence, when compared to the DSP based implementations which are using conventional methods other than neural network based identification models. In this study, the successful application of neural networks in estimation of the rotor flux components, which make possible the implementation of rotor flux oriented control, is simulated. The performance of using a neural network based observer in this complex control scheme is tested and the advantages / disadvantages of this technique are discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bilgisayar ağları üzerindeki trafik ile ilgili son ölçümlerde toplam trafiğin uzun dönem bağımlı olduğu ve özbenzeşimli karakteristikler gösterdiği gözlemlenmiştir. Ancak klasik Markov modelleri kullanıldığında toplam trafikte gerçekte olduğu gibi gözlemlenen karakteristiklere ulaşılamamaktadır. Gerçek trafikte gözlemlenen uzun dönem bağımlılığı ve ani çıkışları modelleyebilmek için farklı yaklaşım arayışları doğmuştur. Özbenzeşimli modeller bu tip arayışlara cevap verecek niteliktedir. Ancak özbenzeşimli modeller kullanılarak doğrudan izler üretebilmek modellerin karmaşıklığı ve hesap-yoğunluğu yüzünden bilgisayar ortamında yapılabilir değildir. Bu yüzden yaklaşık izler üretebilecek yöntemler geliştirilmiştir. Bu çalışmada özbenzeşimli modellerin özelliklerini takiben, bahsedilen yöntemlerden dördünün hesaplanabilirliği ve ürettikleri izler istatistiki açıdan incelenmiş, bunlardan üçünün kullanıldığı bir özbenzeşimli iz üreten yazılım paketi geliştirilmiştir. Ayrıca bu yöntemlerle oluşturulan izler üst üste bindirilerek oluşan izin özbenzeşim özellikleri incelenmiştir.","IV ABSTRACT Observations on the actual traffic data collected on various networks revealed the fact that the network traffic is long-range dependent, synonymously self-similar. This uncovered the discrepancy between the classical Markovian models of the network traffic and the actual network traffic. Aggregation of the traffic generated from the individual sources modeled by conventional Markovian approaches generates an aggregate traffic which behaves like white noise, which is contrary to the observations. The need for employing alternative models of network traffic like self-similar models became evident. Since exact trace generation from self-similar stochastic models is computationally infeasible, algorithms generating approximations to the self-similar processes that are previously developed are discussed in this work. Comparisons and both statistical and computational evaluations of the algorithms are carried out. The properties of the software package developed for synthetic self-similar trace generation for computer simulations and statistical evaluations of the generated data are described. The results of aggregation of the different self-similar traces generated by the algorithms mentioned above are also explored."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Endüksiyon motorları endüstride en fazla karşılaşılan, basit, ucuz, ve kolay bakımı olan motorlardır. Ne yazık ki, bu motorlarda verimli bir hız kontrolü ancak ayarlanabilir hız kontrol sürücüleri ile mümkündür. Bu yüzden, bu tezde endüksiyon motorlarının hız kontrolü için microişlemci tabanlı bir kontrol sistemi geliştirildi. Endüksiyon motorlarının hız kontrolü için, klasik alan yönlendirici kontrol tekniği kullanıldı. Alan yönlendirici kontrol tekniği endüksiyon motorlarının yalnızca doğru akım motorlarının kullanılabildiği yüksek performanslı uygulamalarda kullanılmasına olanak sağlar. Alan yönlendirici kontrol tekniği endüksiyon motorlarının doğru akım motorunun kontrolü ile aynı şekilde kontrolüne olanak sağlar. Düzenekte, alan yönlendirici kontrol algoritması seri haberleşme kartı vasıtası ile bir PC ile haberleşen 8088 tabanlı mikroişlemci sistemi üzerinde çalışır. İki tane geri besleme kartı, kodlayıcı kart ve akım ölçme kartı, motorun hızını ve herbir fazdaki akımı ölçmek için kullanılır. Sinüsoydal pwm sinyal üreteç kartı çevirim kartında bulunan altı transistoru tetiklemek için kullanılır. Bu sistem 250 Watt1 lık bir endüksiyon motorunun hızını kontrol etmek için kullanıldı.","IV ABSTRACT Induction motors are the most frequently encountered motors in industry, since they are simple, low-cost and easy to maintain motors. Unfortunately, efficient wide range speed control of these motors are only possible when an adjustable speed control drive is available. Therefore, a microprocessor based control system has been developed to control the speed of the induction motors. In order to control the speed of the induction motor, a classical standard field oriented control has been used. The field oriented control techniques make possible the application of induction motor for high performance applications where only dc drives were applied. The field oriented control scheme enables the control of the induction motor in the same way as a separately excited dc motor. In the implementation, the field oriented control algorithm runs on a 8088 based microprocessor system which communicates with a PC by means of a serial communication card. Two feedback card, encoder card and current detection card, is used to detect the speed of the motor and currents of each phase of the motor, respectively. Sinusoidal pwm signal generator card is used to trigger the six transistors of the inverter card. Finally, this system has been used to control the speed of a 250W induction motor."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V ÖZET Bu tezde, iki eklemli robot üzerinde Biriken Toplam (BT) testinin sürekli zamanda hata tespitinde uygulanması incelenmiştir. Geleneksel olarak BT testi bir ayrık zaman istatiksel testi olmasına rağmen, bu çalışmada sürekli zaman eşdeğeri kullanılmıştır. Robot için hata modelleri çıkarılmış ve Kalman fıltreleme ile sistem durumlarının kestiriminde bu modeller kullanılmıştır. Kalman filtresinde, robotun yan doğrusal bir modelinden elde edilen durum denklemleri kullanılmıştır. Bu yan doğrusal denklemler, ölçme hatalarının sıfır civarında değerleri için klasik modelin parametrelerine Taylor seri açılımı uygulanması ile elde edilmiştir. Böylece, bu modelde ölçme gürültüsü durum denklemlerinde yan doğrusal hale getirilmiştir. Robot üzerinde üç tip hata modeli incelenmiştir. Bunlar algılayıcıdaki kaymalar, hareket ettirici torkunda meydana gelen kaymalar ve yükteki değişimlerdir. Benzetimler Matlab ortamında gerçekleştirilmiştir.","IV ABSTRACT In this thesis, application of Cumulative Sum (CUSUM) test for detecting faults on a two-link robot manipulator is investigated in continuous time. Traditionally, CUSUM test is a discrete-time statistical test, however a continuous-time analog is used in this work. The fault models for the manipulator are generated and used to estimate system states by Kalman filtering. The Kalman filter uses a quasi-linear model of the manipulator as state equations. This quasi-linear model is obtained by Taylor-series expansion of equations with respect to measurement error around zero. In this model measurement noise is linearised from state equations by using Taylor-series expansion. Three types of faults are investigated. These are sensor bias, actuator torque bias and changes in payload. The simulations are developed on Matlab environment."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Büyük resim veri tabanlarının varlığı, güvenilir içerik tabanlı sorgulama tekniklerine ihtiyacı arttırmaktadır. Amaç ise resimlerden oluşan bir veritabanını, yazılı bilgi olmaksızın indeksleyebilmek ve sorgulayabilmektir. Resimleri ve içerilerindeki objeleri sorgulayabilmek için şekil, renk ve/veya yapı özellikleri kullanılabilir. Verilen bir resimdeki insan yüzlerinin tesbiti araştırmacıların her zaman ilgisini çekmiştir. Her ne kadar resimlerdeki yüzlerin lokasyonunu bulmak için çeşitli yaklaşımlar geliştirildiyse de, kullanılan resimler hakkında bazı ön şartlar arandığından bu yöntemlerin genel amaçlı kullanımı pek mümkün olmamaktadır. Daha genel durumlarda programın basan gösterebilmesi için boyut, duruş ve bakış açısındaki değişikliklerden etkilenmemesi gerekmektedir. Bu tez, renkli resimlerdeki insan yüzlerinin lokasyonunu tesbit edecek bir içerik tabanlı sorgulama metodu geliştirmeyi amaçlamaktadır. Bulma algoritması insan teninin renk özelliklerini baz alıyor. Aday bölgeler, renklerinin önceden oluşturulmuş bir ten rengi kümesi ile benzerliğine göre belirleniyor. Daha sonra bu aday bölgeler şekil özelliklerine göre inceleniyor. Adayların belirlenmesi, incelenmesi ve ayrıt edici özelliklerin ortaya çıkarılması bir dizi resim işleme ve analiz teknikleri ile gerçekleştiriliyor. Uygulama ayrıca kullanıcının verilen bir dizi kriter ile resim veritabanını tarayıp, istenilen resimlere ulaşmasını sağlıyacak bir sorgulama arayüzüne sahip. Uygulama, içinde ten rengi objelerin olduğu ama insan yüzünün olmadığı resimlerde dahil olmak üzere, farklı özellikler taşıyan çeşitli resimlerden oluşan bir veritabanı üzerinde denendi, içlerinde toplam 90 insan yüzü bulunan bu 86 resimde, yüz bulma algoritması %92 başarı gösterdi.","IV ABSTRACT The availability of large image databases brings up the need for reliable content- based retrieval techniques. The idea is to be able to index and query a database of images according to their content even if no text description of the picture exists. Image properties such as shape, color and/or texture can be used to query the images and the individual objects in them. Detection of human faces in a given image has always attracted the attention of researchers. Though numerous attempts have been made to localize faces, these approaches have made assumptions that restrict their extension to more general cases. To address more general cases, the important criteria of invariance to scale, orientation and viewpoint have to be met. This thesis attempts to develop a content-based query method for locating human faces in color images. The detection algorithm is based on the color properties of human faces. Candidate regions are extracted based on the similarity of their colors to a set of pre defined skin colors. The candidate regions are then verified on the basis of their shape properties. Image processing and analysis techniques are used for hypothesis forming, verification and extraction of distinguishing features. The program also has a query interface that enables the user to search the image database to find sets of pictures satisfying a given search criteria. The program has been tested with a set of 86 images of a wide context; including some pictures which contain skin-colored objects. From a total of 90 faces in these 86 images, the face detection algorithm has been successful in 92%."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tez çalışmasının temel amacı, Boğaziçi Üniversitesi 'ne ait Mekatronik Laboratuvarının bünyesinde yer alan elektromekanik aksamın, laboratuvarın işlemsel kapasitesi ile bütünleştirilerek, gerek klasik gerekse gelişmiş denetim yordamlarının uygulanabilmesine müsait deneysel bir düzeneğin kurulmasıdır. Çalışmanın en az bu kadar önemli ve daha fazla akademik değeri olan diğer bir hedefini de doğrusal olmayan sistem denetiminde esnek bilgi işlem metodlarının incelenip, uygulanabileceği bir deney sisteminin kurulması ve bu sistem üzerinde deneyler yapılması oluşturmaktadır. Hem teorik hem de pratik uygulamaları içeren bu tezin pratiğe yönelik kısmını, bahsi geçen ve Deney Bahçesi adı verilen ortamda deney tasarımı ve buna uygun yazılımın geliştirmesi oluştururken, esnek bilgi işleme metodları kullanılarak tasarlanıp, Deney Bahçesinde uygulanan denetim yordamları da çalışmanın teorik yönünü oluşturmaktadır. Tez çalışmasının bir parçası olarak Deney Bahçesi için geliştirilen yazılımlar iki ana gruba ayrılabilir. Birinci grupta uygulamaya yönelik deneysel tasarımlar yer alırken, ikinci grupta ise gelişmiş denetim yordamlarını gerçeklemeye yönelik C dosyalan bulunmaktadır. Bu sayede, gerek benzetimler gerekse gerçek zamanda uygulamalar ile uyarlamalı ve uyarlamasız bulanık denetleyiciler üzerinde çalışmalar yapılmıştır. Yazılımı esnasında tezin bulanık ve bulanık-sinirsel denetleyiciler için bir giriş teşkil edecek şekilde derlenmiş olması, tez çalışmasına öğretici bir vasıf da kazandırmaktadır. Bu sebepten ötürü, bulanık mantık ve bulanık-sinirsel denetleyicilerin, temel kavranılan mümkün olduğunca detaylı fakat bir o kadar da berrak ve takip edilebilir bir tarzda bölümler halinde işlenmiştir. Bu tezin bazı kısımları, Deney Bahçesini daha sonra kullanacak olanların düzeneği kullanırken zorluklarla karşılaşmasını engellemek amacı ile bir kullanım kılavuzu niteliği taşımaktadır. Tezin sonundaki ekler vasıtası ile de, elektromekanik aksam, yazılım ve donanım hakkında kullanıcıya açıklayıcı bilgiler sunulmuştur.","The main objective of this thesis work is the formation of an experimental garden, suitable for the demonstration of classical and advanced control concepts, by an integration of the computational capabilities and the electromechanical equipment that exist in the Mechatronics Laboratory of Boğaziçi University. An equally important and more scholarly objective has been to construct an experimental platform on which the use of soft computing methodologies in the control of nonlinear systems can be studied and experimented with and to actually carry out some experimental investigations in this respect. The thesis has both theoretical and experimental constituents, on the practical side it details the electromechanical construction of the X-Garden (stands for experimental Garden), the development of the software and the experimental designs, whereas the control algorithms designed and implemented using Soft Computing methodologies make up the theoretical side. The software support developed for the X-Garden as a part of this thesis work can be grouped into two. The first group constitutes the C codes written and the second one is on the experimental designs. Both adaptive and non-adaptive fuzzy controllers are studied both by simulations and by real-time implementations. The thesis carries a didactic objective too. It is intended to provide a first reading on fuzzy and fuzzy-neuro control. The fundamental concepts of fuzzy logic are and füzzy- neuro control are therefore explained in detail, in a clear and tractable manner. The thesis, in some parts, intentionally carries the style of a user's manual, this is to ensure that further users of the X-Garden will have no difficulty in experimenting on the platform constructed, being able to find clear explanations and instructions in this thesis and its appendices on the use of both the mechanical and the software environments."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Geçen otuz yıl boyunca psikofizik, sinir bilimleri ve mühendislik, imge işleme, analiz ve bilgisayarla görme gibi alanlardaki araştırmacılar, insan ya da bilgisayar tarafından yapılan yüz tanımayla ilgili birçok sonuçlar elde etmişlerdir. Doksanlı yıllarda da yüz tanıma araştırmalarında yeniden bir büyüme görülmüştür. Yüz tanımada uygulanan ortak strateji öznıtelik tabanlı bir yaklaşım olmuştur. Öznitelik tabanlı yüz tanımada yüzü tanımlayan öznitelikler kümesi elde edilir ve yüz tanımada kullanılır. Bu öznitelik kümesinin seçilmesi, tanıma performansında kritik bir rol oynar. Bu tezde, farklı öznitelik kümeleri için yüz tanıyıcılar denedik ve bunların tanıma performanslarını karşılaştırdık. Öznitelik kümelerinin boyutlarını azaltmayı ve farklı öznitelik kümelerini kullanan farklı tanıyıcıların kararlarını birleştirmeyi denedik. Farklı tanıyıcıların birleştirilmesinde, oylama ve standart hale getirip birleştirme yöntemlerinin tanıma başarısını düzeltebildiğim gördük. 47 adet deneme resmi içinden 45'ini doğru ve 2'sini yanlış sınıflandırdık. Başarı oranımız yüzde 95.74'tür.","IV ABSTRACT Over the last 30 years researchers in psychophysics, neural sciences and engineering, image processing, analysis and computer vision have investigated a number of issues related to face recognition by humans and machines. The '90's have seen a resurgent growth in face recognition technology research. A common strategy for face recognition is the feature based approach. In feature based face recognition, a set of characteristics that describe a face are derived and used in the recognition of the face. The selection of this feature set is critical in recognition performance. In this thesis, we have experimented with face recognizers using different feature sets and compared their recognition performances. We have tried to reduce the dimensions of the feature sets and to combine the decisions of different recognizers using different feature sets. We have shown that the voting and merging with normalization methods for combining different recognizers can improve recognition performance: For 47 images in the test set, 45 images were classified correctly, 2 were misclassified. The success rate was 95.74 per cent."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"UNIVERSAL DC MOTOR DİNAMİĞİNİN İLERİBESLEMELİ SİNİR AĞLARI İLE TANIMLANMASI ÖZET Yapay sinir ağlan, dinamik sistemler ve kontrol ve de sinyal işleme konularında yeni ufuklar açmıştır. YSA'ların yoğun biribirine bağlı yapılan ve paralel işleme yetenekleri, onların karışık doğrusal olmayan dinamik sistemlerin incelenmesinde çok faydalı araçlar olmasını sağlamıştır. Doğrusal olmayan ve dinamiği bilinmeyen bir sistemin kontrolü için genelde bir tanımlayıcı gerekir. Yapay sinir ağlan sistem tanımlama probleminde kullanılabilir. Bu çalışmada doğrusal olmayan universal DC motorun dinamiği yapay sinir ağlan aracılığıyla tanımlanmıştır. Tanımlama yöntemi hem simülasyon modeline hem de deneysel yapıya uygulanmıştır. Gürültünün tanımlayıcı üzerindeki etkisi incelenmiştir. Sonuçlar, yapay sinir ağlarının karışık doğrusal olmayan sistemlerin dinamik davranışını, gürültü olsa bile başarıyla öğrenebildiğini göstermiştir. Uygulanan yöntem deneysel olarak adaptif kontrol algoritmalarıyla birlikte kullanılabilir.","IV ABSTRACT Artificial neural networks opened a new horizon in the field of dynamic systems and control as well as signal processing. The highly interconnected structure and parallel processing capability of ANNs make them very valuable tools for dealing with unknown dynamic systems of mostly complex nonlinear dynamics. Control of a nonlinear plant of unknown dynamics often requires the plant to be identified by an identifier model. Artificial neural networks can be used for the system identification problem. In this study the dynamics of the nonlinear universal DC motor was identified by the artificial neural networks. The identification method was applied to the simulation model as well as to the experimental setup. Effect of noise on the identifier performance was discussed. Results indicate that artificial neural networks can learn the dynamic behavior of the complex nonlinear plants efficiently, in the presence of noise. The method can be incorporated into adaptive control algorithms for experimental implementation."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV ÖZET Mekatronik sistemler mekanik, hidrolik, pnömatik ve elektrikli parçalar içermekte ve mikroişlemci destekli kontrol ünitelerince idare edilmektedirler. Bu gibi sistemler, kontrol parametrelerini girmek veya değiştirmek veya sistem durum bilgilerim göstermek için bir operatör konsoluna ihtiyaç duymaktadırlar. Bu tez çalışmasının amacı, yukarıda belirtilen kontrol ünitelerinin çoğuyla kullanılabilecek şekilde kolayca uyarlanabilen genel amaçlı bir operatör konsolunun tasarımı ve gerçekleştirilmesi olmuştur. Herhangi bir mekatronik sistem için uyarlama yapılabilmesi için kullanımı kolay ve PC ortamında çalışabilecek bir destek programj_biktez çalışmasına dahil edilmiştir. Operatör konsolu, içerisinde boyutları ayarlanabilen bir sıvı kristal ekran, bir grup durum bildirici LED, manuel kontrol tuşlarına sahip bir matris klavye, kontrol ünitesiyle ve merkezi bir bilgisayarla iletişim kurabilecek seri kanallar bulunduran zeki bir yapıya sahiptir. Mekatronik sistemi ilgilendiren parametre değerleri, bitişik olarak bir hafıza bloğu içerisinde tutulmaktadır. Mekatronik sistemin daha farklı parametre değerleriyle çalışması gerektiğinde diğer bir parametre bloğu aktif duruma geçirilebilmektedir. Operatör konsolu üzerinde bu parametre değerlerini tutabilecek bir hafıza ünitesi bulunmaktadır. Konsol programı ayrıca, sistemdeki hataların bulunmasını kolaylaştırabilecek bazı yardımcı bilgiler içeren ekranlara da yer verebilmektedir. Destek programı ise konsol uyarlamalarında kullanılacak ekranları ve içeriklerini, klavye üzerinde bulunacak tuşların yerleri ve işlevlerim, sistem parametrelerini ve değişik dillerde bulunan özgün karakterleri tanımlamak için kullanılmaktadır. Destek programı, konsol program rutinleri tarafından kullanılabilecek yapıda bir veri dosyası üretmektedir. Bu veri dosyası, kullanımdan önce konsol program rutinleri ile birleştirilerek konsol programına katılmakta ve konsol donanımına yerleştirilmektedir.","m ABSTRACT Mechatronic systems include mechanical, hydraulic, pneumatic and electrical components and are controlled by microprocessor based controllers. Such systems require an operator console to set and modify the control parameters and display the system status. The aim in this work has been to design a general purpose operator console which can easily be configured for use with most of such systems. An interactive and user friendly design tool has also been developed to run on PC to allow for configuring the console for a particular mechatronic system. The operator console is an intelligent unit to include an LCD display of configurable size, a set of status LEDs, a contact matrix keypad which includes manual control buttons, a serial port for communication with a master PC and another serial port for communication with the controller of the underlying mechatronic system. The parameter values concerning the mechatronic system are cumulatively stored in a block of memory called a batch. Multiple batches are used interchangeably if multifunctionality of the mechatronic system is desired. The operator console provides on board memory to hold operator set parameters for a particular batch and allows easy batch selection to download the parameter values. The operator console program can be supplied with operator defined diagnostic information to help the operator to locate faults. The interactive design tool allows console designer to specify the contents of the screens, number of keys and their functions, all system parameters, and character fonts to allow for use of the console program with as many languages as necessary. The design tool outputs the machine code which can be linked with operator console program support libraries to yield the actual operator console program that must be embedded into the operator console board."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Piyasalardaki yoğun rekabet ve sürekli gelişen şirketler proseslerini geliştirmek zorundalar, ki bazen bu durum mevcut yazılımlarının değiştirilmesine yol açabilmektedir. Yazılım mühendisliğinin teknik uygulama eksikliği, kısıtlı zaman, görev değişikliği gibi nedenlerden dolayı sadece maddi kayba değil, zaman ve işgücü kaybına da neden olmaktadır. Buna rağmen yeni bir yazılımın satın alınması daha pahalı ve yazılımın içindeki bilgi birikiminin bir yenisine adapte edilmesi oldukça güçtür. Bu nedenle tersine mühendislik (reverse engineering) bu tür şirketlerde yazılıma uygulanmasını gerektirmek tedir ve bunun sonucunda proseslerin yeniden yapılanmasına (Business process reengi- neering) neden olmaktadır, veya tam tersi proseslerdeki geliştirmeler yazılımın yeniden yapılanmasını gerektirmektedir. Proseslerle yazılımın eMleşiminin çok fazla olması, konseptin ve programın anlaşılmasını güçleştirmektedir. İnsan zekası ve bilgisi basit, fakat güçlü bir araç ile yeniden yapılanmada kullanılmalıdır. COBOL yazılım dili için geliştirilen bir aracm (tool) dizayn edilmesinin ana fikri, birden fazla programın (saymm fazlalığı prosesin karmaşıklığı ile doğru orantılıdır) analiz edilmesi ve yeniden yapılanma tekniğinin sadece bir değil, birçok programa uygulanmasıdır. COBOL RETool'un dizaynına, dosya yapısının çıkartılması ve program komutları ile değişkenlerin listelenmesi için öncelikle bir kelime tarayıcısının (parser) yazılmasıyla başlandı. Bu kelime tarayıcısı Visual Basic diliyle entegre edilerek, birden fazla dosyanın işlenebileceği, kullanıcının kolayca çalışabileceği bir ortam yaratılmıştır. Aracm başka önemli bir özelliği ise çok amaçlı karşılaştırma fonksiyonuna sahip olması ve yazıların, dosya yapılarının, değişkenlerin, komutların vb. programlar arası karşılaştırılması için kullanılabilmesidir. Bu temel fonksiyonlar bu şirketin COBOL dilinde yazılmış programlarına uygulanmıştır ve bazıları bir ""case study"" de tartışılmıştır.","IV ABSTRACT Facing high level of competition, ever-growing companies feel the need to alter their business processes which eventually leads to changes in their software. Not using software engineering techniques because of time limitations, job rotations etc., firms encounter an increase in maintenance costs not only in terms of money, but also in time and effort. Nevertheless buying a new software is still more expensive and it is very difficult to transfer the know-how embedded in the coding to a new one. Consequently, in such companies reverse engineering on software is required which may lead to a business process reengineering, or vice versa, the improvement of business processes may lead to a reengineering on software. The interaction of business processes with software is so high, that the concept and therefore understanding of programs becomes very complicated. The intelligence and know-how of a programmer has to be used in reengineering together with a simple, but powerful tool. The main idea in designing a tool for COBOL codings is the need to analyze multiple programs (the number of which depends on the complexity of the business processes) and apply reengineering techniques not only to a single, but to a set of programs. We designed the COBOL RETool by first writing a parser to extract the file structures, and list all identifiers and the command usages in the procedure division. We integrated the parser in Visual Basic to manipulate multiple documents in a user-friendly and graphical environment. Another important part of the tool is the multi-purpose compare function which we designed to achieve the similarities (or from another point of view, the differences) of text blocks, file structures, identifiers, procedures etc. between the programs. These basic functions are applied to COBOL programs in use in a company and some of them are discussed as a case study."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tezde, zor bir kabşımsal optimizasyon problemi olan güvenilir bilgisayar ağlan için topoloji tasannu konusu incelenmiştir. Bu problemde, ağ elemanlarının güvenilirlikleri verilmesi halinde, hedef, maksimum güvenilirliğe sahip topolojiyi bulmaktır. Aynı zamanda, bir maliyet kısıtı kontrol edilmekte ve böylece en son bulunan topolojinin maliyetinin belli bir limitin üzerinde olmaması sağlanmaktadır. Bu problemi çözmek için tavlama benzetimi (simulated annealing) tekniği kullanılmıştır. Tavlama Benzetimi sonuçlarının doğruluğunu test etmek için, değişik testler gerçeUeştirilrniştir. Bu testleri iki ana grupta toplamak mümkündür: Küçük boyutlu ağlar üzerinde yapılan testler ve büyük boyutlu ağlar üzerinde yapılan testler. Güvenilirliğin hesaplanması sırasında, bir olasılık ifadesi bulunmakta, ve daha sonra bu ifade de yer alan olasılık terimlerinin yerine güvenilirlik değerleri yerleştirilmektedir. Olasılık ifadesini bulmak için de, her düğüm çifti arasındaki farklı yolların bulunması gerekmektedir. Bu amaçla Max- Flow algoritması kullanılmıştır. Tavlama benzetimi algoritmasındaki parametrelerin sonuca etkileri tartışılmış ve her bir algoritmanın zaman karmaşıklığı hesabedilmiştir. Test sonuçlan, tavlama benzetiminin bu problemde iyi sonuç verdiğini, ve problemin boyutunun artmasıyla, algoritmanın performansının da arttığını göstermiştir.","IV ABSTRACT In this thesis, we have investigated the problem of reliable network topology design which is an NP-complete problem. In this problem, given the reliability of network elements, the goal is finding the topology with maximum reliability. At the same time, a cost constraint is checked so that the final topology has a cost below a given threshold. In order to solve this difficult problem, simulated annealing technique is used. In order to test the quality of the simulated annealing results, different kinds of tests with small and large size networks were performed. During the reliabiliy evaluation phase, a probability expression is found and then the probability terms are replaced with the reliability values so that the reliability of the topology is calculated. In order to find the probability expression, we have to find the disjoint paths between each node pairs. Max- Flow algorithm is used for that purpose. The effects of simulated annealing parameters on the results are discussed and the time complexity of each algorithm is also evaluated. The results show that simulated annealing performs well on this problem. Furthermore, this performance increases with the size of the networks."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Yapay sinir ağlan birçok araştırma alanlarında yeni bir ufuk açtı. Bu anlayış, kontrol kavramına da yeni bir düşünüş tarzı getirdi. Artan teknolojik talepler kontrol mühendislerini daha yetenekli denetleyiciler tasarlamaya yöneltti. Bu noktada yeni bir yaklaşım olarak paralel veri işleyebilme özellikleri, uyarlanabilirlik ve güçlü dönüştürme yetenekleri nedeniyle yapay sinir ağlan önerildi, özellikle öğrenebilme özelliği bu ağlan daha çekici kıldı. Yapay sinir ağlarının eğitiminde birçok yöntem kullanılmaktadır. Bu çalışmada iki yöntem ele alınmıştır: hata geriye yayma yöntemi ve Levenberg-Marquardt optimizasyon tekniği. Hata geriye yayma yönteminde performans fonksiyonunun birinci türevi kullanıldığından öğrenme zamanı özellikle minimum etrafında çok uzundur, buna karşılık Levenberg-Marquardt yönteminde öğrenme zamanı daha kısadır ve bu, ikinci türevlerden gelen ek bilginin de kullanılmasına atfedilir. Levenberg-Marquardt yönteminde işlem karmaşıklığı ve donanım ihtiyaçları daha fazladır. Doğrusal olmayan dinamik sistemlerin tanımlanması denetleyici eğitiminde önemli bir bölümdür. Bu yüzden tanıma, bu çalışmanın kapsamına alınmış ve simulasyon sonuçlan ile birlikte tartışılmıştır. Prosedürün altında yatan ana düşünce ilgilenilen sisteme ilişkin düzenli ve matematiksel olarak kolay işlenebilir bir modelin elde edilmesidir. Bu iki eğitim yöntemine ve tanıma kavramına dayanarak çeşitli kontrol stratejileri bu çalışma içerisinde tartışılmıştır. Hata geriye yayma ile kontrol, sistem tersini elde etme ile kontrol, kendini ayarlayan kontrol, model referanslı uyarlamalı kontrol, kendi kendine öğrenme ile kontrol ve dinamik sinir ağı modeli ile kontrol yaklaşımları ile denetleyici tasarımı metodolojisi birçok simulasyon sonuçlan ile ele alınmıştır.","IV ABSTRACT Artificial neural networks opened a new horizon in many research areas. This understanding, also, brought a new way of thinking into the concept of control. The ever- increasing technological demands steered the control engineers to design more sophisticated controllers. In this respect, artificial neural networks were proposed as a new approach because of their massively parallel data processing properties, adaptiveness and powerful mapping capabilities. Especially the learning property of these networks made them extremely attractive. There are various methods that are used for the training of artificial neural networks. Two of them are included in this study. These are, namely, the backpropagation method and the Levenberg-Marquardt optimization technique. The learning time for the former is excessively long especially around the minima since it uses the first order derivatives of the performance function, while in the latter, the learning time is very short because of the extra information coming form the second derivatives of the performance function. The computational complexity and the hardware requirements are large for the latter. The identification of nonlinear dynamical systems is a substantial part of the controller training therefore it is included in this work and discussed in the simulation results. The main idea that lie under the procedure is obtaining a regular and mathematically tractable model of the system which is of interest. Based on these two learning methods and concept of system identification, various control strategies are discussed in this work. Design methodology for error backpropagation, inverse control, self-tuning control, model reference adaptive control, self-learning control and dynamical neural unit based control are explained and numerous simulation results are discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Gelişmiş insan/makine arabirimleri ile ilgili potansiyelinden dolayı, elyazısı tanıma çok büyük bilimsel ilgi çekmiştir. İstatistiksel ve yapay sinir ağı temelli yaklaşımlara dayalı olan birçok teknik inceledikten sonra, elle yazılmış rakamları tanıyan bir sistem tasarladık ve gerçekleştirdik. Tanıma amaçlı olarak 44 kişiden bir rakam veritabanı topladık. Önişleme sonrasında iki gösterim kullanıyoruz. Dinamik gösterimde örnekleme noktaları sabit uzunlukta bir öznitelik vektörüne dönüştürülüyor. Bu noktalar kalem yolu üzerinde birbirlerinden eşit uzaklıktadır. Statik gösterimde ise dinamik bilgi bir görüntüye çevriliyor. Daha sonra çok bilinen istatistiksel sınıflandıran a metodu en yakın &-komşu (Aı-NN), yapay sinir ağı temelli çok katmanlı perseptron (MLPJ_ye özbağlı ağlarının bu gösterimler üzerindeki başarısını deniyoruz. Dinamik ve statik gösterimleri öğrenen sınıflandırıcılar farklı örnekler üzerinde başarısız oluyor, ilk olarak hem dinamik hem de statik öznitelik vektörlerini birbirine ekleyerek yeni bir öznitelik vektörü elde ediyoruz. Daha yüksek başarım elde ede bilmek için sınıflandırıcıları oylama, uzmanların karışımı, yığınlaştırılmış genelleştirme ve ardışık sınıflandırıcılar ile birleştiriyoruz. Sımflandırıcı seçme kriteri sınıflandırıcının birbirine benzerliğine bağlı. Birleştirme için dinamik verileri öğrenmiş bir MLP ve statik verileri öğrenmiş bir MLP seçiyoruz. Tüm metodlar için sonuçları sunuyoruz ve aralarında genelleştirme doğruluğu, bellek ihtiyacı ve öğrenme zamanına göre karşılaştırmalar yapıyoruz. Sonuç olarak iki gösterimi kullanmak, bellek ihtiyacını ve öğrenme zamanını önemli ölçüde arttırmadan, doğruluğu önemli ölçüde yükseltiyor.","IV ABSTRACT Handwriting recognition has attracted enormous scientific interest because of its potential for improved man/machine interfaces. We have designed an on-line hand written digit recognition system after the examination of different techniques based on statistical and neural pattern recognition approaches. We collected a digit database from 44 people. We use two representations. The dynamic representation is based on constant length feature vectors of equally distanced points on the pen trajectory. The static representation converts the dynamic informa tion to an image similar to images used in off-line recognition tasks. Then, we tested the well known statistical classification method fc-nearest neighbor (fc-NN) and neural multi-layer perceptron (MLP) and recurrent networks using both representations. Classifiers trained with dynamic and static representations make misclassifica- tions for different samples. We combine them first by forming a feature vector composed of dynamic and static representations. In order to achieve higher accuracy, we com bine different classifiers using voting, mixture of experts, stacked generalization and cascading. The classifiers' selection criteria is based on the similarity among individual learners. We combine one MLP trained with dynamic data and one MLP trained with static data. We provide the results for all methods and make comparisons in terms of gen eralization accuracy, memory requirement and learning time. We conclude that using two representations increase accuracy considerably without significantly increasing the memory requirements and learning time."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde; 1, 2 ve 3-boyutlu süzgeç kümelerinin tasarımı özellikle sıkıştırma uygulamalarına yönelik olmak üzere ele alınmış ve yöntemler önerilmiştir. Bir boyutta verilen dalgabiçimini ya da işaret istatistiklerini gözönüne alarak tasarımlanan uyumlu dalgacık süzgeçleri ile elde edilebilecek sıkıştırma kazancının alt ve üst sınırları araştırılmış, bu sınırlar Karhunen Loeve Dönüşümü kazancı cinsinden ifade edilmiştir ve tasarımda kullanılan parametrelerin ödünleşimi incelenmiştir. Zaman domeninde yeni bir uyumlu dalgacık tasarım tekniği geliştirilerek sıklık domeninde tasarımlanmış Frazier Kumar tekniği ile başarım karşılaştırmaları yapılmıştır. İki ve üç boyutlu M-bantlı doğrusal-evreli, ayrışmaz, tam geriçatmalı dikgen süzgeç kümelerinin zaman domeninde tasarımları için bir yöntem geliştirilmiştir. Tasarım önce bir alçak-geçiren süzgeç bulmağa dayandırılmış olup diğer süzgeçler bu alçak- geçiren süzgecin katsayılarının yer ve işaret değiştirilmeleri ile elde edilmektedir. Kodlama kazancı gibi eniyileme isterleri ve dikgenlik, düzenlilik gibi süzgeç kümeleri için aranılan özelliklerin tümü alçak-geçiren süzgecin katsayıları üzerine yüklenebilmektedir. Bu yöntemin kullanılmasıyla elde edilebilecek avantajlar şöyle sıralanabilir : i) gerçek iki ve üç-boyutlu yapılar kullanılmaktadır, ii) ayrışır süzgeçlemeyle karşılaştırıldığında aynı boyutta daha fazla değişken içerdikleri için daha iyi tasarım imkanı sağlarlar, iii) iki ve üç boyut için sırasıyla dört ve sekiz bantta bile doğrusal evre elde edilebilir ve bu yöntemle elde edilen sonuçlar genel bakışımlılıkla tasarımı yürütmektedirler, iv) işaretli karılmalar kullanılarak değişken ve kısıt denklemi sayısındavııı büyük azalmalar elde edilmiştir. Katsayılar M bantta da yinelendiği için süzgeç yürütümü hızlı olabilmektedir. İki boyutlu ayrışmaz süzgeçler için işlem karmaşası ve bellek sorunları azaltılmış genel bir tasarım yöntemi geliştirilmiştir. İşaretli karılmalara dayalı iki ve üç boyuttaki ayrışmaz, doğrusal evreli süzgeç kümeleri kullanılarak Ayrık Kosinüs Dönüşümüne ve ayrışmaz süzgeçlemeye göre dönüşüm kodlama kazancı cinsinden iyileşme elde edilmektedir.","In this thesis, design of 1, 2 and 3-dimensional filter banks, specially for compression applications is studied and related methods are proposed. In 1-D, design issues related to statistically and waveform matched wavelet design, where one has an analyzing filter that statistically matches a process or that resembles a given waveform, are proposed. Parameters tradeoffs with proper bounds in statistically matched wavelets and energy compaction performance of two-band schemes vis-â-vis Karhunen Loeve transform (KLT) is investigated. A novel matched wavelet design technique based on time domain approach has been proposed and compared with Frazier Kumar frequency domain design technique in terms of flexibility and exactness. A novel time domain method is proposed for the design of nonseparable, linear phase, two and then three dimensional perfect reconstruction filters where linear phase and nonseparability are guaranteed by the centrosymmetry of the filters, so that no additional constraint equations have to be solved. The proposed design method first finds for all sampling lattices, a suitable lowpass filter, while the remaining M-l filters are obtained through use of signed shuffling operations on the coefficients of that filter. These filter structures for M-band design are solved then using an optimization procedure and applied to digital image and video signal. All filter requirements are imposed on the lowpass filter (nonseparability, linear phase, regularity, etc.). This design method could be of interest for its following advantages : i) true 2 and 3-dimensional processing can be done by allowing 2 and 3-dimensional filtering, ii)VI increase in the number of free variables, when compared to separable filtering case, allows better design performances, iii) centrosymmetry is used as general symmetricity (the design can be applied to all other kind of symmetries) and linear phase is guaranteed even for 4 and 8-band cases in 2 and 3 -dimensions respectively, iv) repeated coefficients mitigates the computational load and memory requirements brought in by the nonseparable structure. The method is proposed for possible combinations of filter structures in nonseparable linear phase perfect reconstruction filter banks design. The results show that the proposed design method can provide higher transform coding gains vis-â-vis Discrete Cosine Transform (DCT) and separable filtering"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV ÖZET Anahtarlar yüksek hızda veri taşıyan ağlarda en önemli darboğazlarından biridir. Hızlı veri ortamlarına yerleştirilen anahtarlar giriş bağlantı kapılarına gelen verileri yönlendirebilmek için çok yüksek hızlarda çalışmak zorundadır. Eğer anahtarlar yüksek hızlarda gelen verileri yönlendirmeye uygun bir şekilde tasarlanmamışlarsa yüksek hızlı iletişim ağlarım etkin bir şekilde kullanmak olanaksızlasın ATM ağlan yüksek hızlarda bilgi iletimi için kullanılır. ATM ortamına uygun anahtarlar tasarlayabilmek için pek çok teknik geliştirilmiştir. Kullanılan tekniklerin en önemlileri yüksek derecede paralellik, kendi başına yönlendirme, modülerlik ve VLSI uygulamasına olan yatkınlıktır. Bir çok arabağlantı yapısı arasında, banyan ağlan ATM anahtarlarında çokça kullanılırlar. Bu tezde banyan ağı temelli yeni bir arabağlantı yapısı (Plane Interconnected Parallel Network: Yüzey Arabağlantıh Paralel Ağ) önerilmiştir. Burada amaçlanan banyan ağlarının ATM anahtarlarında kullanılan özelliklerinden faydalanmak ve daha iyi başarımı olan bir arabağlantı yapısı gehştirmektir. Önerilen yapının iş çıkarma başanrmmn tektürel trafik alfanda banyan ağı temelli arabağlantı yapılannm başaranından daha iyi olduğu çözümlemeli olarak ve benzetim yöntemleri kullanılarak gösterilmiştir. Aynca, bu tezde, banyan ağlannın başanmmı iyileştirmede kullanılan başlıca teknikler irdelenmiş ve bunlann bir sınıflandırması sunulmuştur. Önerilen arabağlantı yapısı ve onun başanmmı değerlendirmek için yapılan çalışmaların yam sıra ATM ağı ortamının gereksinimlerine uyan bir trafik yaratan benzetim temelli bir anahtar trafik üreteci de önerilmiştir. Bunun yam sıra, çoktürel anahtar trafiği modellemesinin önemi düşünülerek entropi temelli bir heterojenlik ölçütü önerilmiştir ve bu ölçütün çoktürel anahtar trafikleri ile ilintisi saptanmıştır.","IH ABSTRACT In networks capable of transfering high data rates, switches create the most significant bottlenecks. Switches deployed in such fast transmission environments should also operate at very high rates to be able to handle the flood of data arriving at their input ports. If the switches are not properly designed and constructed to handle the high rates of arriving data, then it is not possible to benefit from new networks with high speed transmission media. ATM networks are used to transfer high data rates. In order to design switches appropriate for the ATM environment, various techniques and structures which are mainly based on a high degree of parallelism, self-routing, modularity, and suitability for the VLSI implementation are employed. Among many interconnection structures, banyan networks are widely preferred to be used in multistage ATM switches. In this thesis, a new banyan network based interconnection structure, called the Plane Interconnected Parallel Network (PIPN), is introduced. The aim is to exploit the properties of banyan networks for use in ATM switches while improving the performance by alleviating drawbacks of banyan networks. It is shown analytically and by simulation that the performance of the PIPN is better than those of banyan network based interconnection structures under heterogeneous traffic requirements. Moreover, all major performance enhancing techniques employed in banyan network based interconnection structures and switches are studied and their taxonomy is presented. In relation to the proposal of the PIPN and the work to evaluate its performance, a simulation based ATM switch traffic generator which creates traffic adhering to the requirements of ATM networks is also introduced. Furthermore, considering the importance of modeling the heterogeneous traffic, a heterogeneity measure mainly based on the entropy of the incoming switch traffic is proposed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Yapay sinir ağlarının boyutları ve karmaşıklığı performansını büyük ölçüde etkiler. Bir ağ için en uygun yapı, eğitim verisini öğrenirken deneme verisini de genelleyebilen bir yapıdır. Ne var ki, bu yapıyı bulmak oldukça zordur. Sinir ağlarının yapılarının bulunmasının otomatikleştirilmesi için teknikler geliştirilmesi son yıllarda büyük ilgi çekmektedir. Tekniklerin geliştirilmesinin yanı sıra, herhangi bir öğrenme yordamından bağımsız tekniklerin geliştirilmesi oldukça önemlidir. Genetik yordamların, sinir ağlarının yapılarını en iyilemesindeki basan, ağ içindeki yararlı bölümlerin korunmasına ve yararlı olmayan bölümlerin iyileştirilmesi esasına dayanır. Bir yapay sinir ağının yapışım betimlemek basit değildir. Bu çalışmada, genetik algoritmalar için uygun olan bir yapay sinir ağı yapısı gösterimi geliştirilmiştir. Uygun olan genetik algoritma işlemleri uygulanmış ve öğrenme yordamlarından bağımsız bir genetik yordam yazılımı kurulmuştur. Kurulan algoritmalar, dışlamalı-veya öğesi, sinüs fonksiyonu, düzensiz zaman serileri tahmini ve göğüs kanseri tahmini problemleri üzerinde denenmiştir. Bahsedilen problemler için kurulan algoritmaların hem basit, hem de uygun ve etkili sinir ağı yapılan bulduğu görülmüştür.","IV ABSTRACT The size and the complexity of a neural network greatly influences its performance. The optimal topology of a network is the one with the smallest complexity which still allows the network to learn the training data and generalize. Such a topology however can be quite difficult to find. Devising techniques for automating the design of neural networks have been of interest recently. Not only devising techniques for design, but also devising techniques that are independent of training algorithms is important. The success of genetic algorithms for neural network topology optimization is based on the fact that, the useful parts of the neural networks are kept, and the useless parts are improved. Representing the structure of a neural network using genetic algorithms is not straightforward. In this study, a suitable neural network architecture representation for the genetic algorithms is devised. Suitable genetic algorithm operators are applied on them and a genetic algorithm tool, that is independent of training algorithms, together with a neural network training tool has been implemented. The success of the implemented genetic algorithm tool is tested on four problem sets: exclusive-OR problem, sine function, chaotic time series prediction problem and breast cancer prediction problem. For the mentioned problem sets, we observed that our genetic algorithm tool has found simple and efficient neural network topologies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET D-LOGOB nesne yönelimli ve mantıksal veri tabam modeli üzerinde tasarlanan dağıtık bir veri tabanı yönetim sistemidir. Bu çalışma Bilgisayar Mühendisliği Departmanında daha önceden yapılmış M.S. tezlerinin bir uzantısıdır. Dağınık veri tabanları üzerinde pek çok ticari ve araştırma çalışmaları var olmasına rağmen, bu çalışmaların büyük kısmı ilişkisel veri tabam modelleri üzerine inşa edilmiştir. Bu tez çalışmasında, dağıtık veri tabanı kavramları nesne yönelimli ve mantıksal LOGOB veri modeli üzerine uyarlanmıştır. D-LOGOB mimarisi dağıtık veri tabanı konularının büyük kısmım nesne yönelimli ve mantıksal veri tabam modeline göre yapılan değişikliklerle içerir. Veri dosyalan kompleks objeleri göz önünde bulundurarak dikey şekilde parçalanarak sistemde dağıtılır. Dağıtık sorgu cevaplama yönetimi dağıtılmış bulunan veri dosyalarını lokal veri tabanlarından çekerek bir araya getirafe vazifesini ifa eder. Dinamik sorgulama optimizasyonu bilgisayar ağı üzerinde minimum maliyet sağlayarak verilere ulaşmayı sağlar. Dağıtık sorgu grubu yönetimi paylaşılan veriye referansiyel bütünlüğü göz önünde bulundurarak ve surgu grubunun atomizasyon, ayrılık ve süreklilik özelliklerini korumak yoluyla ulaşmayı sağlar. Sorgu grubu yönetimi başlığı altında dağıtık kilitleme, iki aşamalı ifa, değtık ölü kilit tanımlama ve düzeltme meseleleri de tasarlanmıştır.","IV ABSTRACT D-LOGOB is a distributed DBMS for LOGOB, a deductive data model with object oriented features. This study is on the distributed database extension of the previous studies on LOGOB. Although, there are many commercial and research studies on distributed databases, most of these studies are devoted to relational database models. In this thesis, distributed database concepts are tuned to the LOGOB data model which is deductive and object oriented. The D-LOGOB architecture includes most of the distributed database management system issues with some modifications with respect to object oriented and deductive data model. Data files are vertically fragmented by taking into account the complex objects. Distributed query processing provides the ability to combine fragmented data from different local databases into a single retrieval operation. Dynamic query optimization methods have been applied to fetch data over the network with minimum cost. Distributed transaction management gives access to shared data by considering the referential integrity constraints defined on the object predicates while preserving the transaction properties of atomicity, isolation, and durability. Under the header of transaction management, distributed locking, two phase commitment, distributed deadlock detection and recovery have been devised."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bir çok durumda, fiziksel bir sistemin dinamik modellenmesi için eldeki bilgiler yeterli değildir. Modelleme hataları ve bozan etkenler denetim sistemleri üzerinde bazı kötü etkilere neden olabileceklerinden, her pratik tasarım bunları gözönüne almalıdır. Belirsiz sistemleri denetlemek için esas olarak dört yaklaşım vardır: uyarlamalı denetim, gürbüz denetim ve bunların iki farklı biçimde birleştirilmesi, yani gürbüz uyarlamalı denetim (GUD) ve uyarlamalı gürbüz denetim (UGD). Bu tez UGD'nin önemli bir çeşidi olan uyarlamalı kayma kipli denetimle (UKKD) ilgilidir. Kayma kipli denetimde (KKD), şimdiye kadar önerilmiş olan kayma yüzeylerinin çoğu sıfırdan farklı başlangıç izleme hatalarını gözönüne almadan belirlenmiştir. Dolayısıyla kayma kipi, izleme başatımı, gürbüzlük özelliği ve denetim girdileriyle ilgili bazı sorunları olan bir ulaşma sürecinden sonra başlar. KKD'nin ulaşma sürecini ve böylece ilgili sorunları azaltmak veya ortadan kaldırmak için belirli yaklaşımlar olmasına karşın, bu yaklaşımlar bu tezin sorun tümcesini oluşturan bazı yetersizliklere sahiptir. Bu tezde, model dayanaklı uyarlamalı denetimden (MDUD) bazı kavramlar kullanılarak, belirsiz doğrusal olmayan sistemlerin kayma kipli denetimi için bir uyarlamalı kayma yüzeyi (UKY) tasarımının hem doğrusal hem de doğrusal olmayan biçimleri önerilmiştir. UKY yaklaşımında, klasik kayma yüzeyinin sabit parametreleri bir uyarlama yordamı tarafından güncelleştirilen parametrelerle değiştirilmektedir. Bu uyarlama yordamı, sistemin izleme hatalarını uygun dayanak hata modellerinin davranışlarını izlemek zorunda bırakır. UKY'de sıfırdan farklı başlangıç izleme hataları ile kayma yüzeyi arasındaki uzaklığı azaltmak olasıdır. Çünkü güncelleştirilen kayma yüzeyi parametrelerinin başlangıç değerlerini seçerken bu izleme hataları gözönüne alınır. Dolayısıyla UKY yaklaşımı ulaşma sürecini azaltır ve böylece çıtırtı sorununa yol açmadan, çok büyük denetim girdileri kullanmadan ve bazı kısıtlayıcı varsayımlar yapmadan sistemin gürbüzlük özelliğini ve izleme başarımını iyileştirir. UKY yaklaşımı basit bir yapıda olduğu için, belirsiz çok-girdili doğrusal olmayan sistemlerin geniş bir grubuna uygulanabildiği için ve bu tezde gösterildiği gibi farklı KKD veya uyarlamalı KKD yordamlarını tamamlayabildiği için, bu yaklaşımın değişik pratik uygulamalarda uygun olması beklenmektedir.","In many cases, the available information for dynamic modeling of a physical system, is not sufficient. Since modeling inaccuracies and disturbances can cause some adverse effects on control systems, any practical design must consider them. There are mainly four approaches to control uncertain systems: adaptive control, robust control and their combinations in two different ways, namely robust adaptive control (RAC) and adaptive robust control (ARC). This thesis deals with adaptive sliding mode control (ASMC) which is an important type of ARC. In sliding mode control (SMC), most of the sliding surfaces proposed so far have been determined without considering the non-zero initial tracking errors. Therefore sliding mode starts after a reaching period which has some problems related to the tracking performance, the robustness property and the control inputs. Although there exist certain approaches to reduce or eliminate the reaching period of SMC and thus the corresponding problems, these approaches have some drawbacks which form the problem statement of this thesis. In this thesis, using some concepts from model reference adaptive control (MRAC) theory, both linear and nonlinear versions of an adaptive sliding surface (ADSS) design, are proposed for the sliding mode control of uncertain nonlinear systems. In the ADSS approach, the constant parameters of the conventional sliding surface are replaced by the parameters which are updated by an adaptation algorithm. This adaptation algorithm forces the tracking errors of the system to follow the behaviors of appropriate reference error models. It is possible in ADSS to reduce the distance between the non-zero initial tracking errors and the sliding surface since these tracking errors are considered while choosing the initial values of the updated sliding surface parameters. Therefore the ADSS approach reduces the reaching period and thus improves the robustness property and the tracking performance of the system without causing the chattering problem, without using very large control inputs and without making some restrictive assumptions. It is expected that ADSS will be suitable in various practical applications since it is simple in structure; it is applicable to a large class of uncertain multi-input nonlinear systems and it is able to complement various SMC or adaptive SMC algorithms as shown in this thesis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET ÇOK BÜYÜK KALIPSIZ VERİTABANLARINDA DİKEY DİLİMLENMİŞ İMZA KÜTÜKLERİ İLE KISMİ SORGU HESABI Seyit KOÇBERBER Bilgisayar ve Enformatik Mühendisliği Doktora Tez Yöneticisi: Doçent Dr. Fazlı CAN Ocak 1996, 131 Sayfa İmza kütükleri sorgulara uygun olmayan kayıtların çoğunu eleyerek kalıplı ve kalıpsız bilgi kütüklerine randımanlı bir şekilde erişimi sağlar. İkil Dilimlenmiş İmza Kütükleri (İDİK) yöntemi okunacak ve işlenecek bilgi miktarını azaltarak randımanı daha da artırır. Fakat, artan sorgu sözcüklerinin daha fazla ikil dilim işlenmesini gerektirmesi İDİK yönteminin sorguya yanıt süresini artırır. Tez kapsamında, İDİK yöntemi için sorgu hesabının imza kütüğü işleme safhasını sorgu imzasının bütün ""1"" ikillerini kullanmadan tamamlamaya çalışan bir durma koşulu tanımlandı. Durma koşulunun amacı, beklenen yanlışlıkla uyan kayıt sayısını ikil dilimlenmiş imza kütükleri için en düşük yanıt süresini sağlayacak düzeye indirmektir. Bu kısmi hesap stratejisini kullanan Kısmi hesaplanan İkil Dilimlenmiş İmza Kütükleri (K- İDİK) yöntemi önerildi. K-İDİK durma koşulu ile birlikte çok sözcüklü sorgu ortamlarında farklı sayıda sözcük içeren sorguların sunulma olasılıklarını da gözleyerek sorgu yanıt süresini enküçük düzeyine indirir. Deneyler K-İDİK' in kullanılan disk alanı ve sorgu sözcük sayısına bağlı olarak İDİK' e göre yanıt süresinde yüzde 85 iyileşme sağladığını göstermektedir. Çok sözcüklü sorgu ortamlarında imza kütüğü parametrelerinin daha da eniyileştirilmesini sağlamak için, K-İDİK yönteminin geliştirilmişi olan, Çok Kısımlı İmza Kütüğü (ÇKİK) yöntemi önerildi. ÇKİK yöteminde kısmi hesap stratejisini kullanarak yanıt süresini eniyileştirmek amacıyla imza kütüğü herbiri farklı ""1"" yoğunluğuna sahip değişik büyüklükte dikey kısımlara ayrılmıştır. Sorgu hesabında vııdüşük ""1"" yoğunluklu kısımlara ait sorgu imzası ""1"" leri öncelikle kullanılır. Sorgulardaki sözcük sayısı artarken düşük ""1"" yoğunluğuna sahip kısımlarda bulunan sorgu imzası ""1"" lerinin sayısı da artar. Böylece durma koşuluna daha az hesaplama adımı ile erişilir ve dolayısıyla artan sorgu sözcük sayısı için ÇKİK'in sorgu yanıt süresi azalır. Analizler ek bir disk alanı gerektirmeden ÇKİK'in K-İDİK ve genellenmiş çerçeve dilimli imza kütüğü yöntemlerinden daha iyi sonuçlar verdiğini göstermektedir. İmza üretiminde kullanılan, sözcüklerden rasgele ikil konumu elde etme ve üst üste bindirme işlemleri nedeniyle sorguya uygun olmayan bir kaydın imzası sorgu imzasına uygun olabilmektedir. Bu türden kayıtlara yanlışlıkla uyan kayıt denir. İstenir bir yanıt süresi elde edebilmek için yanlışlıkla uyan kayıtların sayısının doğru kestirimi gereklidir. Değişken sayıda farklı sözcük içeren kayıtlardan oluşan veritabanlannda ortalama farklı sözcük sayısı kullanmak yerine yanlışlıkla uyan kayıtların sayısını daha doğru kestiren bir yöntem önerildi. Önerilen yöntemde veritabanmdaki kayıtlar içerdikleri farklı sözcük sayılarına göre kavramsal kısımlara ayrılır ve her kısımdaki yanlışlıkla uyan kayıt sayısı ayrı ayrı kestirilir. Gerçek veri ile yapılan deneylerde kullanılan disk alanına bağlı olarak sıradan erişimli, genellenmiş çerçeve dilimli ve ÇKİK yöntemleri için yüzde 33'e, yüzde 25'e ve yüzde 20'ye kadar varan sorgu yanıt süresi iyileştirmeleri elde edilmiştir. Çok büyük veritabanlannda ÇKİK'in bir ikil dilimi bile birçok disk bloğunu kapsayabilmektedir. ÇKİK'in ikil dilimlerini daha yoğun olarak saklayan Sıkıştırılmış Çok Kısımlı İmza Kütüğü (S-ÇKİK) yöntemi önerildi. ÇKİK'in seyrek ""1"" içeren ikil dilimlerinin sıkıştırılması daha düşük sorgu yanıt süreleri sağlamaktadır. Disk erişim sayısını eniyileştirmek için disk blok büyüklüğü ikil dilimlerin çoğunun sıkıştırma işleminden sonra bir disk bloğuna sığmasını sağlayacak biçimde ayarlanabilir. Böyle ortamlarda S-ÇKİK ikiden fazla terim içeren sorgulan sözcük başına bir disk erişimi ile hesaplayabilmektedir. Aynı ortamlarda tersyüz edilmiş kütükler ise biri sorgu sözcüğünü aramak diğeri de sorgu sözcüğüne ait kayıt listesine erişmek için olmak üzere ild disk erişimine gereksinim duymaktadır. Açar Sözcükler: Bilgi Erişimi, İmza Kütükleri, Dikey Kısımlanmış İmza Kütükleri, Sıkıştırma. vııı","ABSTRACT PARTIAL QUERY EVALUATION FOR VERTICALLY PARTITIONED SIGNATURE FILES IN VERY LARGE UNFORMATTED DATABASES Seyit KOÇBERBER Ph.D. in Computer Engineering and Information Science Supervisor: Assoc. Prof. Dr. Fazlı CAN January 1996, 131 Pages Signature file approach is a well-known indexing technique. The Bit Sliced Signature File (BSSF) method provides an efficient retrieval environment by only accessing on-bits of query signatures. However, its response time increases for increasing number of query terms. For BSSF we define a stopping condition that tries to avoid the processing of all on-bits of query signatures through partial evaluation. The aim of the stopping condition is to reduce the expected number of false drops to the level that also provides the lowest response time within the framework of BSSF. We propose the Partially evaluated Bit-Sliced Signature File (P-BSSF) method that employs the partial evaluation strategy and minimizes the response time in a multi-term query environment by considering the submission probabilities of the queries with different number of terms. Experiments show that P- BSSF provides 85% improvement in response time over BSSF depending on space overhead and the number of query terms. To provide better optimization of the signature file parameters in multi-term query environments, we propose Multi-Fragmented Signature File (MFSF) method as an extension of P-BSSF. In MFSF, a signature file is divided into variable sized vertical fragments with different on-bit densities to optimize the response time using a similar query evaluation methodology. In query evaluation the query signature on-düşük ""1"" yoğunluklu kısımlara ait sorgu imzası ""1"" leri öncelikle kullanılır. Sorgulardaki sözcük sayısı artarken düşük ""1"" yoğunluğuna sahip kısımlarda bulunan sorgu imzası ""1"" lerinin sayısı da artar. Böylece durma koşuluna daha az hesaplama adımı ile erişilir ve dolayısıyla artan sorgu sözcük sayısı için ÇKİK'in sorgu yanıt süresi azalır. Analizler ek bir disk alanı gerektirmeden ÇKİK'in K-İDİK ve genellenmiş çerçeve dilimli imza kütüğü yöntemlerinden daha iyi sonuçlar verdiğini göstermektedir. İmza üretiminde kullanılan, sözcüklerden rasgele ikil konumu elde etme ve üst üste bindirme işlemleri nedeniyle sorguya uygun olmayan bir kaydın imzası sorgu imzasına uygun olabilmektedir. Bu türden kayıtlara yanlışlıkla uyan kayıt denir. İstenir bir yanıt süresi elde edebilmek için yanlışlıkla uyan kayıtların sayısının doğru kestirimi gereklidir. Değişken sayıda farklı sözcük içeren kayıtlardan oluşan veritabanlannda ortalama farklı sözcük sayısı kullanmak yerine yanlışlıkla uyan kayıtların sayısını daha doğru kestiren bir yöntem önerildi. Önerilen yöntemde veritabanmdaki kayıtlar içerdikleri farklı sözcük sayılarına göre kavramsal kısımlara ayrılır ve her kısımdaki yanlışlıkla uyan kayıt sayısı ayrı ayrı kestirilir. Gerçek veri ile yapılan deneylerde kullanılan disk alanına bağlı olarak sıradan erişimli, genellenmiş çerçeve dilimli ve ÇKİK yöntemleri için yüzde 33'e, yüzde 25'e ve yüzde 20'ye kadar varan sorgu yanıt süresi iyileştirmeleri elde edilmiştir. Çok büyük veritabanlannda ÇKİK'in bir ikil dilimi bile birçok disk bloğunu kapsayabilmektedir. ÇKİK'in ikil dilimlerini daha yoğun olarak saklayan Sıkıştırılmış Çok Kısımlı İmza Kütüğü (S-ÇKİK) yöntemi önerildi. ÇKİK'in seyrek ""1"" içeren ikil dilimlerinin sıkıştırılması daha düşük sorgu yanıt süreleri sağlamaktadır. Disk erişim sayısını eniyileştirmek için disk blok büyüklüğü ikil dilimlerin çoğunun sıkıştırma işleminden sonra bir disk bloğuna sığmasını sağlayacak biçimde ayarlanabilir. Böyle ortamlarda S-ÇKİK ikiden fazla terim içeren sorgulan sözcük başına bir disk erişimi ile hesaplayabilmektedir. Aynı ortamlarda tersyüz edilmiş kütükler ise biri sorgu sözcüğünü aramak diğeri de sorgu sözcüğüne ait kayıt listesine erişmek için olmak üzere ild disk erişimine gereksinim duymaktadır. Açar Sözcükler: Bilgi Erişimi, İmza Kütükleri, Dikey Kısımlanmış İmza Kütükleri, Sıkıştırma. vııı"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bazı çoklu-ortam uygulamaları aynı bilgi paketlerinin bir grup alıcıya gönderilmesini gerektirir. Bu gibi uygulamalarda çoklu-yayın teknikleri kullanılmalıdır. Çoklu-yayın konuşmalarını yapabilmek için özel protokoller gereklidir. Bu protokoller, toplam ağ ücretini en aza indirecek çoklu-yayın ağacını bulurken, çoklu-ortam uygulamasının tanımladığı kaynak ile bütün hedef düğümler arasındaki olabilecek en yüksek gecikme şuurlarım aşmamalıdır. Çoklu-yayında yer alan birimlerin arasındaki toplam ağ ücretim en aza indirecek yol atama yöntemleri, çizgelerde Steiner Ağacı Problemi olarak bilinir ve polinomsal karmaşıklıktaki algoritmalarla çözülemeyen problemlerden biridir. Bu problemin çözümü için polinomsal zamanda çalışan pek çok buluşsal yöntem öne sürülmüştür. Ancak bu yöntemlerin dezavantajı, belirli servis kalitesinin garanti edilmesini bekleyen çoklu-ortam uygulamaları için uygun olmamalarıdır. Bu çalışmada, tavlama benzetimini Steiner Ağacı Problemi'nin çözümüne uyguladık. Örnek çalışmalar üzerinde yapılan denemeler oldukça iyi sonuçlar vermiştir.","Some multimedia applications require delivery of the same data to a group of hosts, where multicast communication techniques should be used. Special protocols are needed to support multicast communication. The protocols should be able to compute the routing tree that minimizes the total network cost without exceeding the bounds for end-to-end delay from the source node to any destination given by the underlying multimedia application. Choosing a route that minimizes the network cost between multicasting parties is a decision problem which is closely related with the Steiner Tree Problem (STP), and is known to be iVf-complete. Several heuristics have been proposed for solving STP that run in polynomial time and result in reasonable solutions. However, they have the drawback that they are not designed for multimedia applications which require certain quality of service (QoS) guarantees. In this thesis, we have investigated the success of simulated annealing (SA) for solving the STP. We experimented with example problems of different size and obtained promising results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tez ATM ağlan üzerinden yerel iletişim ağlan (LAN) ve metropalitan iletişim ağlarının (MAN) optimize edilmiş bağlantılan hakkındadır. Bağlantı yönelimli ATM ağlan üzerinden LAN ve MAN'lan birleştirmek için bağlantısız servis koşullan incelendi. Yeni bir ağ kurulmak veya var olan ağ genişletilmek istenildiğinde ağ idarecisi tarafından karşılaşılan problemler araştınlıdı. Kaynak ve hedef LAN/MAN çiftleri arasındaki rotalan, sanal yollan ve kapasitelerini, bağlantısız hizmet birirrderinin yerlerini, iletişim ağındaki bağlann maximum yükünü en aza indirerek bulan sanal yol ve bağlantısız hizmet birimi arama problemi, ağ topolojisi, bağ kapasiteleri, trafik gereksinimleri ve bağlantısız hizmet hirimlerinin sayısı verilerek formüle edildi. VCA problemini çözmek için dağıtılmış ve bitişik çözüm teknikleri ""Simulated Annealing"" algoritması kullanılarak uygulandı. Çözümlerin iyilik derecelerini ve çözüm metodlannın performansım ölçmek için dağıtılmış ve bitişik metodlar farklı ağ topolojileri, farklı trafik gereksinimleri, değişken trafik gereksinim desenleri ve ağ yükleri ile koşuldu ve iyilik dereceleri ve diğer çözüm teknikleri ile kıyaslandı. Bütün bu ölçümler her iki metodun da; SA dağıülımış ve SA bitişik çok tatminkâr çözümler verdiğini gösterdi. ANAHTAR KELİMELER: Bağlantı, ATM ağlan, LAN/MAN, yüksek hızlı ağlar, bağlantısız servisler, sanal yol atamalan, bağlantısız hizmet birimi, simulated annealing, optimizasyon, yerel tarama.","IV ABSTRACT This thesis is about optimized interconnection of LANs/MANs over ATM networks. The provision of connectionless service for interconnecting LANs/MANs on top of a connection oriented ATM network is addressed. The problems faced by network administrators whenever a new network is to be setup or expanded are examined. The virtual path and connectionless server assignment (VCA) problem is formulated to determine the routes between each origin and destination LAN/MAN pairs, the virtual paths and their capacities, and locations of the connectionless servers. The objective of the VCA problem is to minimize the maximum link load ratio in the network where network topology, link capacities, traffic requirements and number of connectionless servers are given. To solve the VCA problem, joint and decomposed solution techniques are applied by using simulated annealing algorithm. In order to measure the goodness of the solutions and the performance of the solution methods; the decomposed and the joint were run with different network topologies, different traffic requirements, varying traffic requirement patterns and network loads, and compared with goodness measures and other solution techniques. All these measurements show that both methods the SA joint and the SA decomposed gave very satisfactory solutions. KEYWORDS: Interconnection, ATM networks, LANs/MANs, high speed networks, connectionless services, virtual path assignment, connectionless server, simulated annealing, optimization, local heuristic search."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmada, yapay sinir ağlarının farklı katmanlarına uygulanan gecikmenin fonem tanıma problemi üzerindeki etkileri incelenmiştir. Gecikmenin giriş hatanda olduğu Kısımsal Giriş Gecikmeli Sinir Ağlan (KGGSA), Parçasal Giriş Gecikmeli Sinir Ağlan (PGGSA), Pencereye Dayalı Sinir Ağlan (PDSA); gecikmenin çıkış hatunda yer aldığı Çıkış Gecikmeli Sinir Ağlan (ÇGSA); gecikmenin gizli katmanda bulunduğu Gizli Katmanda Gecikmeli Sinir Ağlan (GKGSA) ve gecikmenin hem çıkış hatanda hem de gizli katmanda gözlendiği Çıkış ve Gizli Katmanda Gecikmeli Sinir Ağlan (ÇGKGSA) ayrıntılı olarak araştırılmıştır. Bu yapılar arasından, KGGSA, PDSA ve PGGSA sıra ile standart hata geri yayma, ağırlıkların paylaşıldığı hata geri yayma ve Sığasal Gerçek-Zaman Özyinelemeli öğrenme yöntemleri kullanılarak eğitilmiştir. ÇGSA, GKGSA ve ÇGKGSA yapılan için Zaman İçinde Açılma, Gerçek-Zaman özyinelemeli öğrenme ve Sığasal Gerçek-Zaman Özyinelemeli öğrenme yöntemleri incelenmiştir. Deneyler, 5240 konuşmacı bağımlı Japonca kelime ve ibarelerden elde edilmiş oldukça zor ayırdedilebilen /b, d, g, m, n, N/ fonemlerini kullanarak gerçeklenmiştir. Her bir yapı için basan sonuçlan tartışılmış ve ayrıntılı bir karşılaştırma yapılmıştır.","IV ABSTRACT In this study, the effects of delays on phoneme recognition problem when they are applied to various layers of artificial neural networks have been analyzed. We have examined in detail the Segment-wise Input Delayed Neural Networks (SIDNN), the Piece- wise Input Delayed Neural Networks (PIDNN), the Window Based Neural Networks (WBNN) where the delay is on the input line, the Output Delayed Neural Networks (ODNN) where the delay is on the output line, the Hidden Layer Delayed Neural Networks (HLDNN) where the delay is on the hidden layer and the Output and Hidden Layer Delayed Neural Networks (OHLDNN) where the delay is on both the output line and hidden layer. Among these structures, we have trained the SIDNN, WBNN and PIDNN using standard backpropagation, backpropagation with weight sharing and Capacitive Real-Time Recurrent Learning respectively. For the ODNN, HLDNN and OHLDNN structures, we have examined three different approaches which are Unfolding of Time, Real-Time Recurrent Learning and Capacitive Real-Time Recurrent Learning. The experiments are conducted using the hardly distinguishable lb, d, g, m, n, N/ phonemes that are extracted from S240 speaker dependent Japanese words and phrases. Performance results are discussed for each structure and a detailed comparison of them is provided."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Yerel ağlar şirketlerin ve üniversite ağlarının belkemiğidir. Yerel ağların önemi arttıkça bu ağlar üzerindeki istekler tek bir ağın kapasitesini aştı. Bu durum köprüler üzerine büyük ilgi oluşturdu. Köprüler, bir yerel ağ ortamının fiziksel olarak büyümesini, istasyon sayısının artmasını, performansın ve güvenilirliğin çoğalmasını sağlarlar. 802 yerel ağlarını direk olarak bağlayan köprülere yerel köprüler denir. Geniş alan iletişim olanaklarını birbirine bağlayan saydam köprüler de bulunmaktadır ve bunlara ayrık köprüler denir. Bu tezin konusu, ayrık köprülerin uygulanması ve performans analizidir. Ayrık köprüler bazen yaran köprüler olarak da anılır; bunun nedeni, iki köprü ve aralarındaki hat, bir köprü olarak düşünülebilir. Bu tezde, iki yarım köprü arasındaki hat X.25 iletişim olanağı olacaktır. Bu tezde uygulanan köprü saydam ve 802.3 yerel ağlan için çalışmaktadır. Köprüler bir adet Ethernet kartı ve bir adet X.25 kartı olan bir Pc üzerinde gerçekleşmiştir. Tezin performans bölümünde, yapılan ölçümlerin sonuçlan verildi, sistemin kuyruk modeli oluşturuldu ve köprülerin kapasiteleri araştırıldı.","IV ABSTRACT Local area networks (LANs) are the backbone of corporate and university networks. As the importance of LANs grows, the requirements placed on these networks are exceeding the capacity of a single LAN. This caused considerable interest in bridges. Bridges provide a means to extend the LAN environment in physical extent, number of stations, performance, and reliability. Bridges also provide a means to interconnect dissimilar LANs. Bridges that interconnect 802 LANs directly are called ""local bridges."" Bridges to interconnect LANs across wide area communications facilities also exist and are called ""remote bridges."" This thesis is consists of the implementation and performance analysis of a remote bridge. Remote bridges are also called as ""half bridges,"" because the combination of the two bridges plus the link between them can be thought of as a single bridge. In this thesis, the link between two half bridges is an X.25 communication facility. The bridge implemented in this thesis is transparent, and working for 802.3 LANs. The implementation consists of a PC equipped with an Ethernet Card and an X.25 Communications Card. In the performance part of the thesis, throughput characteristics were investigated, some measurements were presented and a queueing model of the system was prepared."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Çok işlemcili sistemler, kontrol uygulamalarında yüksek performans elde edebilmek için en uygun çözümdür. Bu tez, arka yüzey veri yolu (backplane bus) adı verilen ve değişik tipteki işlemcileri destekleyen, çok amaçlı, çok işlemcili veri yolunun tasarımıyla ilgili çalışmayı içerir. Bu çalışmada, endüstriyel işlemlerin kontrolüne uygun, mümkün olan en yüksek performansı gösterebilecek, oldukça ucuz çok işlemcili bir sistemin elde edilmesi amaçlanmıştır. Uygun görülen sistem, VME, Multibus ve Futurebus gibi yaygın olarak kullanılan veri yolu standartlarının özelliklerinin yorumlanmasıyla kurulmuştur. Çok işlemcili sistemlerle ilgili genel kavramlar ve bu sistemlerin mimari yapısı hakkında yapılan araştırmalardan sonra, önerilen veri yolu sunulmuştur. Veri alış verişi, hakemlik ve işkesme mekanizması için gerekli sinyaller, protokoller ve zamanlama çizelgeleri tasarlanmıştır. Mevcut sistemler incelenerek, çoğullanmış veri alışveriş protokolüne sahip, tam eşzamansız veri yolu yapısı belirlenmiştir. Hakemlik, merkezi olarak yapılmaktadır ve her işlemciye eşit kullanım hakkı verilmektedir. İşkesmeîer, daisy-chain mekanizması kullanılarak organize edilmiştir. Veri yolunda düzgün sinyal iletiminin sağlanabilmesi için, elektriksel özellikler ve parametreler dikkate alınmıştır. Donanım gerçeklenmesi sırasında, 64 hatlı veri yoluna karar verip, en fazla sekiz 'master', 16-bit bilgi sinyali ve 24-bit adresler desteklenmiştir. Tasarımın çalıştığını gösterebilmek için, iki Motorola 68000 işlemcili ana kart, bir hafıza kartı ve sistem denetleyicisi gerçeklenmiştir. Tüm sistem bileşenleri, üniversitenin mevcut laboratuvar donanımından faydalanarak oluşturulmuştur. Son aşamada, basit test programları yazılarak, sistem test edilmiştir.","IV ABSTRACT Multiprocessor systems are the key solution for obtaining higher performance in control applications. The current thesis considers the design of a universal multiprocessor bus, called backplane bus, that supports processors of various types. The aim is to obtain a very cheap multiprocessor system with maximum possible performance, that Is suited to be used to control industrial processes.The system incorporates ideas and decisions from popular backplane bus standards such as VME, Multibus and Futurebus. After a short review of general multiprocessing concepts and architectures, the proposed bus design is discussed. The required signals, protocols and timing diagrams are designed for the data transfer, arbitration and interrupt machanisms. Considering the available systems, fully asynchronous bus with multiplexed data transfer protocol is decided. The arbitration is centralized and implements a fair policy, while the interrupts are handled by a simple daisy-chain mechanism. The electrical specifications and parameters are considered, so that proper signal transmission on the bus may be guaranteed. The hardware implementation uses 64-pin bus with maximum eight possible masters, 16-bit data lines and 24-bit addresses. To prove the functionality of the design, a minimal system with two Motorola 6K0Ü0 based master boards, one memory board slave and a system controller is implemented. All of the system components are produced with the available laboratory equipment at the university. Finally to test the system simple test programs have been written and executed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Çerçeve iletimi teknolojisi bağlantı yönelimli bir anahtarlama tekniğidir ve coğrafi olarak uzak yerel alan ağlarının arabağlantısı için amaçlanmıştır. Çerçeve iletimi iletişimi ISDN paket iletiminin performansını artırmak için önerilmiştir ancak daha sonra tek basma hesaplı bir iletişim tekniği olarak kullanılabileceği anlaşılmışın-. Bu MS tezinde yapılan iş Bilgisayar Ağlan Araştırma Laboratuvarı bünyesinde bir çerçeve iletimi anahtarı, çerçeve iletimi uçbirimleri, ve çerçeve iletimi yolatayıcıları içeren bir yüksek hızlı ağ test ortamı oluşturulmasına yönelik ortak bir çalışmanın bir parçasıdır. Test ortamı için çerçeve iletimi hat hızı 2048 Kbps olarak seçilmiştir. IBM uyumlu PCler ucuz maliyetleri ve nispeten kolay arayüz geliştirme sorunları yüzünden çerçeve iletimi uçbirimleri ve yolatayıcıları olarak seçilmiştir. Bir Motorola VME bus temelli çok işlemcili bilgisayar sistemi çerçeve iletimi anahtannm ana birimi olarak seçilmiştir. ISA veri taşıtı için çerçeve iletimi arayüzünün ve çerçeve iletimi anahtar arayüzünün geliştirilmesi bu MS tezinin konusudur. Her iki arayüz de bir çok ortak işlevlere, alt sistemlere, ve birimlere sahiptir. ISA veri taşıtı için çerçeve iletimi arayüzü tam olarak tasarlanmış, bir kart olarak gerçeklenmiş, ve çalışması test edilmiştir. Çerçeve iletimi anahtar arayüzü ISA veritaşıtı için çerçeve iletimi arayüzünün geliştirilmesi sırasında kazanılan tecrübelerle tasarlanmıştır.","IV ABSTRACT Frame relay is a connection oriented packet switching technique and it is intended for the interconnection of geographically separated local area networks. Frame relay communication was proposed to improve the performance of ISDN packet transmission, but later it was found out that it alone could be used as a cost effective communication technique. The work done in this MS thesis is part of a joint effort to develop a high speed network test bed that involves a frame relay switch, frame relay terminals and frame relay routers in the Computer Networks Research Laboratory. The frame relay line speed in the test bed has been selected as 2048 Kbps. IBM compatible personal computer's (PC's) with ISA bus were selected as frame relay terminals and routers, since they have low cost and it is relatively easier to solve their interfacing problems. A Motorola VME bus based multiprocessor computer system was selected as the main component of the frame relay switch. The development of the frame relay ISA bus interface and the development of frame relay switch interface are the subjects of this MS thesis. Both interfaces have many common functions, subsystems and components. The frame relay PC ISA bus interface has been fully designed, realized as a board and tested for operation. The frame relay switch interface has been designed based on the experiences accumulated while developing the frame relay PC ISA bus interface."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Tam olarak çözülmemiş bir problem olan deprem tahmin problemini yapay nöron ağîanna uyguladık. Manyitüt ve iki deprem arasındaki zamandan oluşan verilerin bir zaman serisini meydana getirdikleri ve bu serinin deprem sırası hakkında tüm gerekli bilgiyi içerdiğim kabul ederek, daha önce çeşitli zaman serilerini tahmin etmede ve modellemede kullanılan bazı nöron ağlarını çalıştırdık. Tezde deprem tahmin etme amacıyla kullanılan algoritmaların en başarılılarından olan Canada-Nevada algorithması kısaca açıklanıyor ve bu algoritmanın başarılı olurken, tezde uygulanlann başarısız olmasının nedenleri tartışılıyor. Aynca nöron algorithmalanyîa birlikte Box Jenkins yöntemi de uygulanıyor.","Earthquake Prediction is a mainly unsolved problem. A îarge number of different approaches have been tried and only a small number of attempts were fruitfuî. A few of these are explained briefly in this thesis. Öne of the most succesfui earthquake prediction sytems in use today is the Canada-Nevada, CN, algorithm. it is discussed and contrasted to the neural networks impiemented in the project. For this project the earthquake prediction problem is treated as a time series prediction problem and neural networks that have been used for ordinary time series prediction with some success have been applied to the problem. The data used was treated as a two dimensionaî time series with two variables; the magnitude of the present earthquake, and the time elapsed since the previous earthquake. The neural network architectures impiemented were the multilayer perceptron network with sigmoidal activation îunction, NADINE, and a multilayer network with chaotic activation îunction. Theresults were not succesfui because of the complex nature of input data and the earthquake generation process."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bilgisayarlar birçok kurumlarda kullanılır. Bütün bu bilgisayarlar birbirinden yalıtılmıştı. Bunun yanında, bu makinelerde yapılan işler arasında kuvvetli bir bağ bulunmaktadır. Yazıcı ve disk kapasitesi gibi özel donanım veya işlem gücü yüksek makinelerin paylaşımı için bu bilgisayarlar yerel bilgisayar ağlarıyla birbirlerine bağlandılar. Yerel bilgisayar ağlan, elektriksel kısıtlamalar nedeniyle, coğrafik olarak birbirinden uzakta bulunan alt kurumlar veya kurumların bölümleri için kullanılamıyordu. Bu probleme çözüm olarak yerel ağların bir geniş alan ağı ile birbirine bağlanması öne sürüldü ve uygulandı. Bu tezde, bağlantı makinası olabilecek bir yönlendirici öneriliyor. Haberleşen yerel ağlardaki bilgisayarların ana protokolü olarak Internet Protokolü (İP) seçilmiştir. Yerel ağlar IEEE 802.3 standardının en popüler uygulaması olan Ethernet ağlandır. Geniş alan ağı protokolü olarak Çerçeve İletimi önerilmiştir. Çerçeve İletiminin seçilmesindeki ana neden tarihi haberleşme protokollerinden hızlı olması. Çerçeve İletimi haberleşmede en hızlı metod değildir, fakat problem için yeterli bir çözüm olmasının yanında ekonomik olaması da dikkati çeker. Bu tezde, yerel ağlan Çerçeve İletimi üzerinden birbirine bağlayacak bir İP yönlendirici önerilmiştir. Tasarımının bilgisayardaki benzetimi ve başarımı etkili bir ağ analiz yazılımı olan OPNET'te incelenmiştir. Tasarım kişisel bilgisayarlar kullanılıp uygulanmış ve oluşan sistemin başarımı incelenmiştir. Bu tez Ethernet' i, Çerçeve İletimi'ni, yönlendiricileri, Ethernet'ten Çerçeve İletimi'ne yönlendirme problemlerini, bilgisayar benzetimi neticelerini ve gerçekleştirilen sistemin başarım ölçümü neticelerini kapsar.","Many organizations have a substantial number of computers in operation. All these computers were isolated from each other. Whereas, the jobs done on these machines were strongly correlated. In order to share the computing power and special hardware as the printing machines or extensive disk storage these computers have been interconnected with Local Area Networks (LAN)- For geographically distant parts of organizations and companies, the local area networks, due to electrical limitations, are impossible to use. As a solution to this problem, interconnection of LANs over a Wide Area Network (WAN) is proposed and implemented. In this thesis, a gateway is proposed as an interconnection machine. The main communication protocol of nodes in LANs is taken as Internet Protocol (IP). LANs are consisting of well known implementations of IEEE 802.3 standards: Ethernet networks. As a WAN protocol Frame Relay (FR) is proposed. FR is chosen because of its speed compared to traditional communication methods. FR is not the fastest way for interconnection but an economical and sufficient method for the problem. In this thesis, an IP router is proposed to interconnect LANs over FR service. The design is simulated and evaluated on a powerful computer network analysis tool, OPNET, implemented by using PCs and also the system's performance is measured. This thesis covers Ethernet, FR, Internet Protocol, Routers, Ethernet to FR routing problems, computer simulation results and the implemented system's performance measurement results."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmada sınıflandırmada öge seçimi problemini inceledik. Bu amaç için Genetik Yordamlar ve Sırayla Geri Arama (SGA) teknikleri kullanıldı. Bu iki yöntemin de sınıflamadaki basan oranını düşürmeden sınıflamada kullanılan öge sayışım azaltma basanları ölçüldü, öge seçiminde kullanılan, başka araştırmacılar tarafından uygulanmış diğer yöntemler de özetlendi. öge seçimi deneyleri, En Yakın Komşu sınırlayıcısı kullanılarak bizim taraflınızdan hazırlanmış üç veri kümesi ve gerçek verilerden oluşan iki küme üzerinde yapıldı. Genetik Yordamlar ilk grup veri kümeleri üzerinde ikinci gruba göre daha yüksek basan gösterdi. İncelenecek öge sayısı arttıkça, SGA, Genetik Yordamlara göre daha iyi sonuç vermeye başladı. Bu araştırmada kullanılan iki yöntemin seçmiş olduğu öğelerin kullanılmasında da, gerçek veri kümeleri üzerinde, tüm elde bulunan öğeleri kullanan başka araştırmacılann elde etmiş olduğundan daha yüksek sınıflama değerlerine ulaşıldı. Genetik Yordamlar ve SGA yöntemlerinin ikisinin de bulduğu öge kümeleri kullanılarak erişilen sınıflama değerleri başka araştırmacılann daha önce sınıflamada En Yakın Komşu ve Geriyayma Yapay Sinir Ağı kullanarak ulaştıklan değerlerden yüksek oldu.","IV ABSTRACT In this study, we investigated the feature selection problem in classification. Genetic Algorithms (GAs) and Sequential Backward Search (SBS) were used for this purpose. The ability to reduce the number of features used in classification without decreasing the classification success rate was tested on different data sets, for these two methods. Feature selection experiments were done on three artificial data sets and on two real data sets, using the Nearest Neighbor as the classifier. GAs showed better performance on the first group of data sets rather than on the second group. SBS gave better results than the results obtained using GAs, as the number of features increased. With the features selected by both methods we achieved higher classification rates on the real data sets than obtained by other researchers (who used all the features). Both GAs and SBS found feature sets that yielded higher classification rates than the rates obtained previously by other researchers, who used Nearest Neighbor and Backpropagation Neural Network in classification."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Önce ""spline""lann yumuşak aradeğerleme özellikleri sınandı. Gürültülü veriden yola çıkıp geri plandaki işlevi yaklaşıklaştırmak için bir veri gruplama yöntemiyle birlikte çalışıldı. Daha sonra, özgün veriye dokunmadan yalnızca ""spline"" yöntemiyle yumuşatma yapıldı. Az zaman kullanma açısından ""spline""la yumuşatma, hata geri yayma ağlarına göre üstün bulundu. Ancak ortalama mutlak yanılgıları benzer çıktı. ""Spline ""la yumuşatma yöntemini iki boyuta uyarlayabilmek amacıyla bir eklemeli model kullanıldı. Çıktı işlevi, her bir değişkene ait tek boyutlu işlevlerin toplamı olarak düşünüldü. İki boyutta eklemeli ""spline""lann elde edilmesi amacıyla bir geri yerleştirme algoritması kullanıldı. Umut verici sonuçlar alındı. Ancak, eklemeli ""spline'lann, özellikle geri plandaki işlev tümsekler içeriyorsa, çok genel yaklaşıklaştırmalar yapabildiği görüldü. "" Spline ""lann tek boyutlu aradeğerleme ve yaklaşıklaştırma problemlerinde başarıyla kullanılabileceği sonucuna vardık. Çok boyutlu problemlerde ise her bir değişkenin genel eğilimini göstermek amacıyla kullanılabilirler.","IV ABSTRACT First the smooth interpolation capability of the splines is tested. Then, a cooperation with a clustering technique is done to obtain an approximation to a function underlying a given noisy data set. Next, the smoothing spline is used without manipulating the original data. To make a comparison, an error backpropagation network is used. The smoothing spline is found to be superior to the error backpropagation networks in that it uses less time, but they have similar mean absolute error. To adapt the smoothing spline method to the two dimensional case, an additive model is used. The output function is assumed to be the sum of two one dimensional functions of each of the variables. A backfitting algorithm is performed to obtain the additive splines in two dimensions. The results are promising but additive splines seem to make a more general approximation which is not always good, especially when the underlying function has some bumps. We conclude that splines can be used efficiently in one dimensional interpolation and smoothing problems. In higher dimensions they can be used as a tool showing the general tendency of the effect of each of the variables."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET LOGOB Bilgisayar Mühendisliği Bölümünde daha önceki bir M.S. tezi çerçevesinde geliştirilmiş ve nesne yönelimli özellikleri bulunan mantıksal (dedüktif) bir veri modelidir. Bu tezde, LOGOB veri modeli için bir veri tabanı yönetim sisteminin (LOGOB DBMS) mimarisi tasarlanmış ve gerçeklenmiştir. Gerçekleştirme esnasında, orijinal modelin bazı eksiklikleri ile karşılaşılmış ve modelde değişiklikler yapılmıştır. LOGOB DBMS'in mimarisi, desteklenmek zorunda olan kompleks nesneler ve mantıksal (dedüktif) sorgulamalar dikkate alınarak tasarlanmıştır. Tasarlanan mimari geleneksel sistemlerinkilerden oldukça farklılıklar gösterir. Nesneler ve kurallar için etkili saklama ve erişim mekanizmaları tasarlanmıştır. Nesne tipleri, kurallar ve nesneler üzerindeki güncelleme işlemleri tasarlanmış ve gerçekleştirilmiştir. Mantıksal (dedüktif) sistemler için kullanılan geleneksel sorgu cevaplama yordamları nesneler ile çalişabilecek şekilde değiştirilmiş ve sorgulama optimizasyonu sağlamak amacıyla birkaç yordam gerçeklenmiştir. Join işlemleri sıralama ve Magic Set transformasyonları gibi geleneksel sorgulama optimizasyonu metodları adapte edilmiş ve gerçeklenmiştir.","IV ABSTRACT LOGOB is a deductive data model with some object oriented features, which was originally developed within the framework of a previous M.S. thesis in Computer Engineering Department. In this thesis, a database management system based on LOGOB data model (LOGOB DBMS) has been architectured and implemented. During implementation, some shortcomings of the original model were encountered and the model has been modified. The architecture of the LOGOB DBMS has been designed by taking into account the complex objects and deductive queries to be supported. The architecture designed differs significantly from that of a traditional system. Efficient storage and access mechanisms for objects and rules have been devised. The schema update and the object update operations have been designed and implemented. The traditional query evaluation algorithms for deductive systems have been modified for handling objects and several of them have been implemented for query optimization purposes. Some traditional query optimization methods like join ordering and Magic Sets transformation have been adopted and implemented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tez çalışmasında, üç eksenli ve eksenleri adım motorları ile kontrol edilen makina tezgahı için denetleyici tasarımı ve gerçekleştirimi anlatılmaktadır. Denetleyici donanımı üç kısımdan oluşmaktadır. Bunlar mikroişlemci birimi, zamanlayıcı-sayıcı birimi ve operatör ara birimi olarak tuş takımı ve likit kristal ekran olarak özetlenebilir. Bu donanım için 2D (iki boyut) dairesel ve doğrusal ara değerleme yazılımı geliştirilmiştir. Ayrıca kişisel bilgisayar için tasarlanmış bir kart için DXF çıktı formatı için derleyici yazılımı geliştirilmiştir. Mikroişlemci birimi, sekiz bitlik bir denetleyici yongası, 32 K byte RAM, 32 K byte ROM, ve adres seçici yongalarından oluşmaktadır. Bu birim standard bir ara birim ile diğer birimlere bağlıdır. Zamanlayıcı-sayıcı birimi 2 adet programlanabilir zamanlayıcı yongasından, adres seçici devrelerden ve tuş takımı-ekran birimi için ara birimden oluşur. Ayrıca motorlar için sinyal çıkış ara birimi de bu birim üzerindedir. Kullanıcı ara birimi tuş takımı ve likit kristal ekrandan oluşmaktadır. Tuş takımı kontrolü için programlanabilir bir denetleyici yongası kullanılmaktadır. Ara değerleme yordamları denetleyicinin derleyici dilinde geliştirilmiştir. DXF çıktı formatı derleyicisi ise C dilinde tasarlanmış ve gerçeklenmiştir.","IV ABSTRACT In this MS thesis, a microprocessor based controller design for a stepper driven three axis machine tool is described. Controller hardware consists of three parts: CPU module, Timer-counter module and keypad-display module as a user interface. Controller software is developed for 2D circular and linear interpolation for this hardware. A DXF file interpreter is developed for a PC add-on three axis stepper motor controller board. CPU module consists of an 8-bit microcontroller chip, 32K byte RAM, 32K byte ROM, and address decoding chips. This module has an interface to other modules. Timer- counter module consists of 2 programmable timer-counter chips, address decoding chips and interface to keypad-display module. Morever interface for stepping motors is also on this module. Keypad-display module consists of 24-key keypad and an LCD display. For the purpose of keypad control programmable keyboard controller chip is used. Interpolation routines has been developed in controller's assembly language. DXF file interpreter has been developed in C language for ready made PC add-on controller board."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tez el yazısı rakam tanıma üzerinedir. Standard bir formun ikili görüntüsünden rakamların tanınmasına kadar olan tüm işlemler tartışılmaktadır. Kısa bir zaman önce, Amerikan NIST kurumu el yazılı formlar içeren bir veri tabanı ve bu formları işleyebilecek programlan isteyenlerin kullanımına sundu. Biz de bu programlan kendi amacımıza uygun hale getirdik. Ancak NIST'in tanıma üzerine olan programlan iyi sonuç vermedi (%82.2). Bunun en büyük sebebi de Türklerin ve Amerikalıların el yazısı stilleri arasındaki farktır. Bu nedenden dolayı, sınıflandırma yöntemlerini üzerinde deneyip, kıyaslayabileceğimiz bir el yazısı rakam veri tabam oluşturduk. Temel sınıflandırma yöntemleri olarak, En Yalan k Komşu, Büyü ve öğren, ve Çok Katmanlı Algılayıcı'yı kullandık ve kendi aralarında karşılaştırdık. Esas çalışma, birden çok sınıflandırıcının birleştirilmesi teknikleri üzerinde oldu. Bu konu ile ilgili olarak, önce oylama sistemi denendi. Sonra, Yığılmış Genelleştiriciler yöntemi ve İtekleme yöntemi kullanıldı. Son olarak, Ardışık Sınıflandırıcılar isimli, yeni bir çok sınıflandırıcılı yöntem geliştirilmiştir. Ayrıca uygulanan tüm yöntemlerin sonuçlan ve aralarındaki çeşitli kıyaslamalar da sunulmuştur. Ulaşılan en yüksek basan kısıtlı yazıcı için %98.3 ve yazıcıdan bağımsız tanımada %97.3'dir. ANAHTAR KELİMELER: El yazısı rakam tanıma, Ayrıştırma, En Yalan k Komşu, Büyü ve Öğren, Çok Katmanlı Algılayıcı, birden çok sınıflandırıcının birleştirilmesi, Oylama, Yığılmış Genelleştiriciler, İtekleme, Ardışık Sınıflandıncılar.","IV ABSTRACT This thesis report is about handwritten digit recognition. It explains a system that takes the binary image raster of the standard form and generates a text output of its handwritten content. National Institute of Standards and Technology (NIST) of US recently made available a database of handwritten forms and programs that manipulate them. We adopted their form processing programs for our purpose. Their programs for recognition however did not work well (82.2%) due to the difference of handwriting styles of Turkish and Americans. So, we created a large database of handwritten digits on which to test and compare our recognizers. For classification, K-Nearest Neighbor (KNN), Grow And Learn (GAL), and Multi- Layer Perceptron (MLP) methods are implemented and compared. Then, we concentrated on the techniques of combining multiple classifiers. We implemented voting as the first technique for combining multiple classifiers. Then, we implemented the Stacked Generalization over different types of classifiers. Later, the Boosting method is tried on our problem. Finally, we propose a new method of combining multiple classifiers, called the Cascaded Classifiers. We also provide the results of all methods implemented and make comparisons among them. The highest success we have is 98.3% in the writer dependent case and 97.3% in the writer independent case. KEYWORDS: Handwritten digit recognition, Segmentation, K-Nearest Neighbors (KNN), Grow and Learn (GAL), Multi-Layer Perceptron (MLP), Combination of multiple classifiers, Voting, Stacked Generalization, Boosting, Cascaded Classifiers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tezin konusu Türkçe'nin biçimbiliminin incelenmesidir. Türkçe bitişimli diller grubuna dahildir. Bu özelliğinden dolayı Türkçe'nin biçimbilimi oldukça karmaşıktır ve pek çok istisnai durumlar içerir. Son zamanlarda yapılan çalışmalarda dilin sadece bir kısmı incelenmiştir. Bu çalışmalar özellikle temel bazı kuralların açıklanması ve gösterilmesi üzerine kurulmuştur. Bu tezin başlıca amacı, Türkçe'nin tüm biçimbilimsel yapısını açığa çıkarmak ve bu yapının bilgisayardaki gösterimini oluşturmaktır. Bu işlem tamamlanmadan, dilin sözdizimsel ve anlambilimsel olarak incelenmesi hemen hemen olanaksızdır. Bu çalışmada biçimbilim analizini iki kısma ayırıyoruz: Eklerin yapısının ve sıralanmasının incelenmesi. Dilin biçimbilimini bu iki kısmı göz önüne alarak tanımlayacağız. Daha sonra bu tanımlamaları Genişletilmiş Geçiş Ağı formasyonunda birleştireceğiz. Böylece, Türkçe'nin biçimbilimsel yapısının bilgisayardaki gösterimini elde edeceğiz. Bu önerilen yapı, Türkçe konusundaki dil uygulamaları için bir temel oluşturacaktır. Bu uygulamalar arasından, bir biçimbilimsel tarama programı ile yazım düzeltme elemanı da içeren bir yazım kontrol programı hazırlayacağız. Bu biçimbilimsel gösterimi ve hazırlanan programları kullanarak Türkçe hakkında istatistik bilgi üreteceğiz. Bu üretim iki kısımdan oluşuyor: sözlük ve biçimbilimi analizi ile metin analizi. Bunlardan ilki dilin yapısal kısımları hakkındaki bilgilerden yararlanır. İkincisi ise dilin günlük kullanımıyla ilgilidir. Bu amaçla, bir metin oluşturacağız ve yazım kontrol programını bu metin üzerinde çalıştıracağız. Anahtar sözcükler : Bilgisayarlı dilbilimi, Doğal dil işleme, Biçimbilimsel analiz, Türkçe, Genişletilmiş geçiş ağları, Yazım kontrolü, Metin","ABSTRACT The morphological analysis of Turkish is the subject of this thesis. Turkish belongs to the group of agglutinative languages. Because of its agglutinative nature, Turkish morphology is quite complex and includes many exceptional cases. Most recent research on Turkish morphology have limited themselves with a partial treatment of the language. The study has concentrated especially on the explanation and representation of the basic rules. The main objective of this thesis is to bring the full morphological structure of Turkish to light and to build its computer representation. Before this analysis is handled, the syntactic or semantic parsing of the language is quite impossible. In this study, we divide the analysis of the morphology into two interrelated parts: morphophonemic analysis and morphotactic analysis. We investigate and define the morphological structure for both of these. Then we combine these in the Augmented Transition Network (ATN) formalism. This forms the formal representation of the Turkish morphological structure. This proposed morphological structure forms a basis for the language applications about Turkish. Among these applications, we design and implement a morphological parser and a spelling checker which incorporates a spelling corrector component. We perform statistical analysis of Turkish based on this morphological representation and the implemented programs. This analysis is formed of two parts: lexical and morphological analysis, and corpus analysis. The first one uses the information about the structural parts of the language. The second one deals with the daily usage of the language. For this purpose, we form a corpus and run the spelling checker program on this corpus. Key words : Computational linguistics, Natural language processing, Morphological analysis, Turkish, Augmented transition networks, Spelling checking, Corpus IV"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu çalışmada değişik sınıflandırma yöntemleri uygulayarak, üretimden gelen bozuk motor verisini sınıflandırdık ve yöntemlerin veriyi sınıflandırma başarısını kıyasladık. Sınıflandırma yöntemi olarak ağaç sınırlandırıcılar, yapay sinir ağlan ve k- merkez sınıflandıncılar gibi alışılagelmiş yöntemlerin yanısıra, bunların çeşitlemelerinden olan doğrusal ve doğrusal olmayan görsel sınırlandırıcılar ve bulanık sinir ağlan, ve karma bir sınıflandıncı olan genetik öbekleme sınıflandıncılannı kullandık. Her smıflandıncıyı, bazen görsel muayene, doğrusal birleşim, Fisher doğrusal ayırma yöntemi, en önemli bileşenler çözümlemesi yöntemi ve doğrusal olmayan korelasyon yapan yapay sinir ağı gibi değişik öznitelik bulma ve seçme yöntemleri de kullanarak, kendi başına inceledik. Son olarak birini-dışanda-bırak ( çapraz-doğrulama ) yöntemiyle, sınıflandıncdanmızın veriyi doğru sınıflayabilme basanlarını kıyasladık. Doğrusal ve doğrusal olmayan görsel sınıflandıncılar, bulanık sinir ağlarının bir çeşidi, genetik öbekleme sınıflandıncısı ve doğrusal olmayan korelasyon yapan yapay sinir ağı, bu çalışmada ortaya konan yeni kavramlardır.","IV ABSTRACT In this thesis, we have processed a data of defective motors coming from production, with different pattern classification methods and we have compared their performances in classifying our data. We have applied selected well-known classifiers, the tree classifiers, neural networks and k-means classifiers, as well as variations of some well-known classifiers, the linear and nonlinear visual classifiers, neuro-iuzzy classifiers and finally a hybrid one, the genetic clustering classifiers. Each classifier was first analyzed individually, sometimes trying alternative feature extraction and selection methods which were the visual inspection, linear combination, Fisher linear discrimination method, Principal Components analysis and the NonLinear Correlating Neural Network. Finally a comparison of all the classifiers was done on the basis of their performance in classifying the data by using the leave-one-out or crossvalidation method. The visual classifiers, genetic clustering classifiers, a variation of the neuro-fuzzy classifier and the NonLinear Correlating Neural Network are new concepts introduced with this thesis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu çalışma elyazısı rakamların tanınmasında kullanılan yeni bir yaklaşımı içerir. Elyazısı rakamlarını tanıma sistemi (EYRTS) hemen tüm diğer klasik damga tanıma sistemleri gibi iki tane birbirini takip eden ana parçadan oluşur: Bölütleme ve Tanıma. Her iki parçada, yapay sinir ağı (YSA) sınırlayıcılarını kullanır ve bu sınırlayıcılar YSA bölütleyici ve YSA tanıyıcı olarak adlandırılırlar. Bölütleme parçasında, imge işleme (gürültü azaltma, kayma düzeltme vs.) ve öznitelik çıkarım teknikleri kullanılmadı. Bu parçada giriş olarak 300 dpi sayısallaştınlmış imgeler kullandı. İlk iş, imge içinde rakam dizilerini (alan) bulmak ve bunları belli bir büyüklüğe getirmektir. Bu çalışmadaki yenilik rakamların bölütlendirilmesinin bir YSA tarafından yapılmasıdır. Genellikle bölütlendirme sezgisel yöntemlerle yapıldığı için, bu yöntemler damgaların değmesi durumunda doğru bölütlendirme yapamazlar. YSA bölütleyici değen veya kırılmış damgaları doğru olarak bölütleyebilir. YSA bölütleyici her bir alanın üzerinde bir pencere dolaştırarak o alanın içindeki rakam sınırlarını bulur. YSA bölütleyici burada her bir pencere için 0 veya 1 üretir. Bu çıktı pencerenin merkezinde rakam sınırı olup olmadığını gösterir. Sonra alanın içindeki tüm rakamlar YSA bölütleyicisinin o alan için ürettiği tüm çıktılar kullanılarak bölütlenir. YSA bölütleyici tarafından bölütlenmiş rakamlar tanıma parçasının girişlerini oluşturur. Bu rakamlar YSA tanıyıcısının kullanabileceği büyüklüğe getirilirler ve YSA tanıyıcı bunları 0 ile 9 arasındaki bir rakam olarak sınıflar. YSA bölütleyici öznitelik çıkarımı ve sınıflamayı reddetme mekanizması kullanmaz. EYRTS 18 kişiden alınmış 15,895 damga içeren bir veri tabanı ile eğitildi. Deneme için kullanılan veri tabanında ise 10 kişiden alınmış 3,000 damga vardır. Sonuç olarak bölütlendirmede %97.80, tanımada yazıcı bağımlı durumda %93.66, yazıcı bağımsız durumda ise %85.65 başarı elde edildi.","IV ABSTRACT This study outlines a new approach to handwritten digit recognition. The handwritten digit recognition system (the HWDRS) consists of two successive phases like other classical OCRs: Segmentation and Recognition. The HWDRS uses neural network (NN) classifiers in both phases: the NN Segmenter and the NN Recogniser. In the segmentation phase, no particular image processing (noise elimination, skew correction, etc.) and feature extraction techniques have been carried out. Digitised handwritten digit images are input to the segmentation phase. The fields (digit strings) are extracted and normalised. The novelty of this work is that the segmentation of digits are done by a neural network that is trained for this task. Normally this is done based on heuristics and they frequently fail when characters are touching. The NN Segmenter can learn to segment touching or broken characters. All digit boundaries are found using the NN Segmenter by sliding a window on each field. The NN Segmenter produces a binary output which can be interpreted as ""there is"" or ""there is not"" a digit boundary at the window centre. Then all digits in each field are segmented by the help of these binary values. The digits segmented by the NN Segmenter are input to the recognition phase. The digits are normalised to a fixed dimension which can be accepted by the NN Recogniser. The NN Recogniser classifies each input pattern as one of the numerals. It does not use feature extraction and rejection mechanisms for the classification purposes. The HWDRS trained with the database of 15,895 digits from 18 writers. The test database contains 3,000 characters from 10 writers. Results are 97.80% for segmentation and 93.66% for recognition in the writer dependent case and 85.65% for recognition in the writer independent case."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vu ÖZET Tek sesli müzik işaretlerinin ana doğuşkan sıklıklarının kestirilmesi amacıyla, dalgacık teorisine dayanan verimli ayrıştırma yöntemleri incelendi. Seyreltme yapılarak veri miktarını azaltan yapılar kullanılarak müzik ayrıştırmak için gerekli olan kestirim çözünülürlüğünün yakalanabildiği görüldü. Bu amaçla, çalışmalarda dalgacık dönüşümünün özellikleri incelendi ve bir zaman-ölçek gösterimine eşit olan bu gösterimin, müzik işaretlerinin ayrıştırılması için doğal bir yaklaşım olduğu saptandı. Ana doğuşkan sıklığı kestirim yöntemleri iki ana başlık altında incelendi: zamanda kestirim ve sıklıkta kestirim. Zaman kümesi yöntemleri altında, sonlu dürtü yanıtlı (FIR) ve kafes-sonsuz dürtü yanıtlı süzgeçler (IIR) denendi ve klasik yöntemlerle karşılaştırıldı. Bütün sıklık kümesi yöntemleri ise zaman-sıklık düzleminin değişik parametrik bölütlenmeleri olarak incelendi. İlgili dönüşümlerin verimli bir şekilde hesaplanması için algoritmalar ve benzetim sonuçları verildi.","VI ABSTRACT We investigate efficient digital signal analysis techniques based on the wavelet theory when applied for pitch detection of digitized monophonic musical signals for transcription purposes. The aim is to reduce the computational burden by multirate signal processing techniques and still meeting the heavy analysis resolution requirements. In this respect the properties of the wavelet transform are investigated. This approach is equalent to a time scale representation, a more natural representation for musical signals than e.g. short-time Fourier transform. Pitch tracking methods are classified into two domains: time domain methods and frequency domain methods. Under time domain techniques, FIR and IIR-lattice subband filter bank solutions with different regularity and phase conditions are compared against conventional methods. All frequency domain methods are presented as parametric tilings of the time- frequency plane. Efficient numerical algorithms for the calculation of the respective transforms and corresponding simulation results are given."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Solunum yolu hastalıklarının tanısında, en yaygın olarak kullanılan yöntemlerden biri, solunum seslerinin steteskop aracılığıyla dinlenmesidir. Bu yöntem, tamamen doktorların kişisel değerlendirmelerine ve tecrübelerine bağlı olduğu için hataya sebep olabilmektedir. Bundan dolayı, daha iyi bir tıp hizmeti için, tanıda daha yüksek başarım gösterebilecek bir yönteme ihtiyaç vardır. Bu ihtiyaç, sesleri toplayıp analizini yaparak tamda doktorlara yardımcı olabilecek bilgisayar destekli bir sistemle karşılanabilir. Bu tez çalışması, böyle bir sistemin kurulmasına yardımcı olmayı amaçlamaktadır. Çalışmalar 3 ayrı sınıftan denek üzerinde gerçekleşmiştir: Sağlıklılar, kronik tıkayıcı solunum yolu hastalıklılar, kısıtlayıcı solunum yolu hastalıklılar. Solunum seslerinin özellikleri bir durumdan diğerine değişiklik gösterirler. Sistemin amacı, bir durumu diğerinden veriyi sınıflandırarak ayırdetmektir. Veri, solunum seslerinin özbağîanımlı (AR) ve cepstral modelleme teknikleri kullanılarak elde edilmiş olan özniteliksel gösterimlerinden oluşmuştur. Sınıflandırma, Yapay Sinir Ağlan (YSA) yapılarından Çok Katmanlı Algılayıcı (ÇKA), Radyal Temel Fonksiyonu Ağı (RTF A) ve Vektör Ayrıştırmayı Öğrenme (VAÖ) sınıflandıncılan ve bunlara ek olarak, klasik yaklaşımlardan k-En Yakın Komşu (k-EYK) ve bulanık k-EYK algoritmaları kullanılarak yapılmıştır. Veri çeşitli kombinasyonlarda alınarak birçok deneyler yapılmış, sonuçlar analiz edilmiş ve kıyaslanmıştır. Bu deneylere ek olarak, veri sayısının azlığına karşılık öznitelik boyutunun çok yüksek olmasının yarattığı işlem karmaşıklığını azaltmak için öznitelik azaltma yöntemi kullanılmış ve daha az sayıda öznitelikle temsil edilen denekler üzerinde de deneyler yapılmıştır.","iv ABSTRACT In the diagnosis of respiratory diseases, one of the most common methods that is currently used is to listen to the respiratory sounds of the patients using a stethoscope. Since it solely depends on the personal judgments and experience of the doctors, it is prone to error. Therefore, a new method which will allow more precise diagnostics is a necessity for improved medical service. The mentioned need can be provided by a computer aided system, which will collect and analyze the sounds and thus help doctors during diagnosis. This thesis work aims to help the establishment of such a system in order to make the decision of doctors more accurate. The decisions are made on three types of subjects: Healthy ones, chronic obstructive patients and restrictive lung disease patients. The characteristics of the respiratory sounds show the differences from one type to another. The objective of the system described is to distinguish one case from another by classifying the data. The data is the parametric representations of the sounds which were obtained using Auto Regressive (AR) and cepstral analysis techniques. The classification process was investigated by using Artificial Neural Network (ANN) structures such as Multi Layer Perceptron (MLP), Radial Basis Function (RBF) and Learning Vector Quantization (LVQ), and in addition to these, using the conventional approaches like k-Nearest Neighbour (k-NN) and fuzzy k-NN algorithms. Using different combinations of the data, several experiments were conducted and the results were analyzed and compared. In addition to these experiments, in order to decrease the complexity caused by the inconsistency of smaller number of subjects versus high dimensionality, the feature reduction process was also used and experiments were performed on the subjects which were represented by the smaller amount of data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışma, Türkçe dokümanlara yönelik bir Doküman Analizi Sisteminin gereklerini ve öğelerini tanıtmaktadır. Literatürde böyle bir sistemin bazı kritik problemlerine ve yapılması gereken bölümlerine çözümler getirilmiştir. Bazı problemler için de, bu çalışmada yeni yaklaşımlar geliştirilrniştir. ikili görüntüler elde etmek amacıyla, gönümüz okuyucularında kullanılan geleneksel görüntü dosya tipleri mcelenmiştir. Görüntülerin herhangi bir tipte saklanmasından sonra, gri-tonhı görüntülerden, ikili görüntüler elde etmek işlemlerin ileriM bölümlerinde rahat çalışabilmek için önemlidir. Bir Doküman Analizi Sistemindeki önemli problemlerin arasında her görüntüde olabilen, gürültü veya eğim açısı gibi hataların anlaşılması ve düzeltilmesi gelir. Açıyı anlamak için çizgi yerleştirme metodu güzel bir yaklaşımdır; açı düzeltmek için ise basit matematiksel denklemler kullanılmıştır. Gürültü giderimi için birkaç yaklaşım tanıtıldıktan sonra Uzamsal Pürüz Giderme metodu en uygun bulunmuştur. Diğer bir problem, yazı içeren kısımların, grafik veya çevre çizgileri gibi diğer bölümlerden ayrılmasıdır. Siyah bölgelerin ayrılıp, bazı özellMerinin analiz edilmesi bu problemi çözmekte yardımcı olacaktır. Görüntüyü içindeki ayrı bölümlere dilimlendirmek için üç yöntem tanıtılmıştır; sınır takip etme, noktalara bağlı diliııüendirme, ve satırlara bağlı dilimlendirme. Sınır takip etme yöntemi literatürden alınmış, diğer iki yöntem ise bu çalışmada geh^tirilmiştir. Bölümlenmiş kısımlar daha sonra uygun bir şekilde tanımlanıp, bu tanımlardan gösterdikleri şekle göre sınıflandmlmahdırlar (Harf, sayı, v.b.). Tanımlama her bir bölümün tipik bazı özelliklerine göre yapılır. Bu özellikler, asıl karakter tanımlama bölümü olan sınıflandırmada kullanılırlar. Yazı tipine, harf boyuna, veya duruş şekline bağlı kalmayan bir sınıflama yapmak için yapay sinir ağlarında hata geri yayma yöntemi kulanurnıştır.","IV ABSTRACT This study outlines the requirements and components of a Document Analysis System for Turkish texts. Several critical solutions are given in literature for some of the main problems. Here we present new approaches to solve other problems. In order to obtain binary images, the image formats of typical files used in conventional scanners are investigated. After storing the image in any format, binarization of the gray-scale images is crucial, in order to process documents easily. Among the most common topics of a Document Analysis System are detection and elimination of noises and skew angles that occur in almost every scanning environment For angle detection, line fitting is a good approach; to correct angles simple mathematical equations may be used. After discussing popular noise elimination approaches, spatial smoothing is found to best fit to this problem. The separation of the text part, from non-text shapes such as graphical parts or gridlines, is another problem. Separating black regions and analysing them as lines of text or graphics, helps to overcome this problem. For segmentation of the image into distinct symbol images, three methods are discussed: boundary following, pixel based segmentation, and line based segmentation. Boundary following algorithm is taken from literature whereas the other two methods are developed in this study. The segmented portion then must be well represented, and according to this representation, must be classified (letters, digits, etc.). The representation is done according to certain features of each segment. Then these features are used in the classification process which is the main character recognition part. In order to have a character recognition system not constrained by font, size, and orientation, artificial neural networks with Back Propagation learning algorithm is used."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmada, sinir ağlan yapısı kullanılarak, genel bir puslu mantık deneticisi geliştirildi. Sinir ağlan yapısı, puslu mantık deneticisinin kural tabanım, İlk bilgi olmaksızın elde etmek ve ilgili üyelik fonksiyonlannı ayarlamak için kullanıldı. İki değişik kural elde etme yöntemi uygulandı. İlki, Puslu Karar Verme Sistemi-I (FDMS-I), bu amaçla rekabetçi öğrenme yöntemi kullanır. Fakat, bu tezde önerdiğimiz, Puslu Karar Verme Sistemi-II (FDMS-II), öğrenme örnekleri arasındaki ilişkiyi kullanır. İki kural elde etme yöntemi de kullanılarak sistemin performansını sınamak için iki problem uygulandı. İlk problem örneği, sistemi eğitmek ve sınamak için kullanılan doğrusal olmayan fonksiyondur. Sonuçlar gösteriyor ki, FDMS-II, öğrenme zamanı ve sistem performansı açısından daha iyi sonuçlar vermektedir. Aynca, FDMS-I'den elde edilen üyelik fonksiyonlan, epeyce geniş çakışan alanlardan dolayı, pek fazla bir bilgi vermemektedir. Bu nedenle, FDMS-II ikinci probleme uygulanmak için seçilmiştir. İkinci problem örneği, doğrusal modelli H.B. Robinson nükleer güç santralidir. Sonuçlar gösteriyor ki, doğrusal örnekte, sistem performansı artarken, öğrenme zamanı da dikkate değer miktarda azalmıştır. Nihai kural setlerinin tutarlılığı ve sağlamlığı, öğrenilen üyelik fonksiyonlarıyla kural çıkanmı tekrarlanarak kontrol edilmiştir. Sonuç olarak, FDMS-II ile oluşturulan kural tabanı, her kural çıkanmı sonucunda aynı kural setini verdiğinden, kararlıdır. Fakat, bu durum, değişik kural setleri üreten FDMS-I için geçerli değildir.","IV ABSTRACT In this study, we have developed a general fuzzy logic controller using a neural network structure. The neural network structure is used to construct the rule base of the fuzzy logic controller without any initial information available and to tune the associated membership functions. We have implemented two different rule extraction methodologies. The first one, namely Fuzzy Decision-Making System-I (FDMS-I), uses competitive learning for this purpose. However, Fuzzy Decision-Making System-II (FDMS-II), which we propose in this thesis, uses the relation among training samples. Two test problems were applied to test the performance of the system by using both of the rule extraction methodologies. The first problem case is a nonlinear function used to train and test the system. Results show that FDMS-II performs better in terms of the learning time and system performance. Moreover, the resulting membership functions of FDMS-I do not give much information because of the quite large overlapping areas. Thereby, FDMS-II is chosen to apply to the second problem. The second one is a linear model of PWR-type H.B. Robinson nuclear power plant. Results show that the system performance is increased whereas the learning time is decreased by a remarkable amount in the linear case. The consistency and robustness of the ultimate rule sets are checked by reextracting the rules with the learned membership functions for a set of iterations. As a result, we have seen that the rule base constructed by FDMS-II is stable, yielding the same rule set after each reextraction. However, this is not the case with FDMS-I which yields a different rule set."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tezde, dağıtılmış işlemleri destekleyen Logical Unit (LU) 6.2 protokolü kullanılarak, sistemler arasındaki programların alt- sistemlere bağımlı kalınarak iletişim kurabilme problemine çözüm getirilmiştir. Uzak mesafelerdeki database ""lere erişimi kolaylaştırmak ve eksik kaynak kullanımını en aza indirmek amacıyla tüm yüksek ve alçak seviyeli programlama dillerinden çağırılabilecek bir genel arabirim tasarlanmıştır. Client- server modeli baz alınarak yapılan bu tasarım ile kullanıcı veya uygulama programı, uzak yer adı, uzak program adı ve programa hangi parametreleri geçireceği gibi bilgileri kodlayarak uzak mesafelerdeki database'ler üzerindeki bilgilere kolaylıkla ve saydam bir şekilde erişebilmektedir. Ayrıca LU 6.2'nin dağıtılmış işlemler içindeki yeri ve biribirinden farklı sistemler arasındaki kaynakların kullanımını nasıl desteklediği de incelenmiştir.","iv ABSTRACT In this thesis, a solution has been introduced against to the problem of sub-system dependency of program-to-program communication, via Logical Unit (LU) 6.2 protocol that supports distributed processing. In order to eliminate misuse system resources and ease access to the distributed databases, a generic interface has been devised for the programming languages. By coding remote host identification, remote program name and program parameters, a user or an application program is able to access remote databases in a transparent manner by implementing client-server model. Additionally, the place of LU 6.2 within distributed processing and how it supports the distributed resources that reside in heteregeneous systems are discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Fonem tanıma, fonem sınıflarının kesin tanımlanmamış ve bulanık sınırlara sahip olduğu zor bir işlemdir. Yapay sinir ağları ise sınıflar arası sınırları başarıyla ayarlayabilen öğrenme metodlarının varolması dolayısıyla fonem tanıma problemleri için ümit vadeden bir tekniktir. Bununla birlikte, bu teknikte kullanılabilecek birçok metot olduğu gibi seçilebilecek birçok da ağ yapısı vardır. Bu tez, gerisayma öğrenme tekniğiyle ve farklı hedef fonksiyonlar kullanılarak eğitilen ileri beslemeli sinir ağlarının fonem tanıma problemi üzerindeki performanslarını araştırmaktadır. Hedef fonksiyonlarının detaylı bir karşılaştırmasını yapabilmek ve öğrenme performanslarını belirleyebilmek için, farklı hedef fonksiyonlar kullanılarak eğitilmiş bir, iki gizli katmanlı ve farklı sayılarda gizli düğümü bulunan ileri beslemeli ağlar kullanılmıştır. Beş farklı hedef fonksiyon sınanmıştır: Ortalama Karesel Hata, Çapraz-entropi, Bir Birleşik Hata Ölçümü, Ağırlık Azaltma, Ağırlık Eleme. Bu hedef fonksiyonlarla eğitilmiş ileri beslemeli ağların ve en yakın komşu metodunun tanıma performansları, Japonca'nın en zor ayırdedilebilen altı fonemi, /b, d, g, m, n, N/, kullanılarak konuşmacı bağımlı durum için sınanmıştır. Sonuçlar tartışılmış ve bazı öneriler getirilmiştir.","IV ABSTRACT Phoneme recognition is a difficult task where the phoneme classes have ill-defined, fuzzy boundaries. Artificial neural networks are promising in phoneme classification as there are learning methods which adjust the class boundaries with satisfaction. However, there are a big number of methods that can be used and many network architectures that can be chosen for the task. This thesis investigates the performances of feedforward neural networks trained with backpropagation algorithm using various objective functions for phoneme recognition problem. Feedforward networks with one and two hidden layers and various number of hidden nodes are considered with different objective functions in order to obtain a detailed comparative study of objective functions and their performances in recognition. Five different objective functions are tested: Mean Square Error, Cross-entropy, A Combinational Error Measure, Weight Decay and Weight Elimination. The recognition performances of the networks trained by using these objective functions and the Nearest Neighbor method are compared by using hardly distinguishable six phonemes /b, d, g, m, n, N/ of Japanese for the speaker dependent case. The results are discussed and some advices are presented."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bir model bazlı iki boyutlu nesne tanıma sisteminin bir transputer ağı üstünde paralel olarak gerçeklenmesi ve performans analizi anlatılmaktadır. ""Tanıma"" yaklaşımı özellikli dizi eşlemenin bir dinamik programlama olarak gerçeklenmesi esasına dayanır ve hem üstüste duran hem de ayrık objeler için etkin olarak çalışır. Alçak seviyeli görüntü işleme operasyonları sözkonusu ağda geometrik paralelizm kullanılarak gerçeklenmiştir. Özellik çıkarma için işlem hasadı (process farming) ve tanıma fazındaki hipotez oluşturulması ve doğrulanması için ise işlem hasadı ile görev paralelizminin bir kombinasyonu kullanılmıştır. Tanıma için hemen hemen ideal bir hızlanma elde edilmiştir. Paralel sistemin değişik sayılardaki transputer için çalışma zamanı, hızlanma ve verimlilik cinslerinden performans değerlendirmeleri verilmektedir.","IV ABSTRACT The parallel implementation and performance analysis of a model-based two- dimensional (2-D) object recognition system on a transputer network is described. The recognition approach is based on a dynamic programming implementation of attributed string matching and works effectively for both nonoccluded as well as occluded objects. The low level image processing operations are mapped onto the network by using geometric parallelism. Process farming is employed for feature extraction, and a combination of process farming and task parallelism is used for hypotheses generation and verification in the recognition phase. An almost ideal speedup is achieved for the recognition. Performance evaluation in terms of execution time, speedup and efficiency of the parallel system are given for different number of transputers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Günümüzde kullanılan değerlendirme programlarının çoğunun ön bellek erişim başarı oranı bire yakındır. Kodun küçük olması, az veri kullanılması ve sıralı program mantığı ön bellek denetleyicisinin gereken bilgileri önceden hazırlamasına neden olmaktadır. Ön bellek denetleyicisi büyüdükçe değerlendirme programlan daha hızlı çalışarak işlemcinin hızını hatalı değerlendirmektedir. Bazen, değerlendirme programının kodu ve verisinin ön belleğe tamamıyla sığması, kullanıcının ana belleği sınamasına engel olur. Böylece, değerlendirme programlarının iki sistem için verdikleri sonuçların incelenmesince, sistemlerden birinin başarısı yalnızca daha büyük bir ön belleğe sahip olmasından kaynaklanıyor olabilir. Bu tezde gelişigüzel adresleme kullanılarak, veri boyutu ön belleğe göre oranlanarak ve aynı adres mümkün olduğu kadar seyrek adreslenerek ön bellek başarı oranı oldukça düşük dört tane değerlendirme programı geliştirilmiştir. Değerlendirme programları bir sistemin çeşitli ön bellek büyüklükleri için aynı sonuçlan vermişlerdir. Ancak, ön belleğin mevcudiyetinden kaynaklanan içsel bir başarım söz konusudur. Kodun yerelliği, döngü sayaçlarının tekrar tekrar kullanılması ve ara değişkenlerinin kullanımı yalnızca bir kilobayt büyüklüğünde bir ön belleği bulunması halinde dahi içsel bir başarım artışına neden olmaktadır.","IV ABSTRACT Most of the benchmarks currently being used execute at a hit ratio close to one. Since the code is very small, only a small amount of data is accessed and the sequential logic of the program enables the cache controller to anticipate the memory accesses. As cache size increases, the benchmark programs execute faster, which is a false indicator of the processor speed. In some cases, the benchmark code and data fit completely into the cache, preventing the user from testing the memory subsystem at all. Consequently, while comparing benchmark results for two systems, higher performance of one of the systems might mean only the existence of a larger cache. In this thesis, four benchmarks with low temporal and spatial data locality have been developed by scaling the data size, making random references and referring to the same addresses as scarcely as possible. The benchmarks have yielded approximately the same results for various cache sizes of a system. However, there is an inherent increase in performance caused by the existence of a cache. The locality of code and repeated access of loop counters and intermediate variables cause an increase in performance even with the existence of one kilobyte of cache."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,"This thesis is a study of the Hospital Information Systems (HIS), with special interest in the selection of the underlying technology and possible integration of HIS to a nationwide Health Information System. An integrated HIS approach through database administration has been adopted and an application software has been developed and installed at the Farabi Hospital of Karadeniz Technical University of Trabzon. Clinical Information System, still under development, will be installed at the same hospital in the near future. Apart from the widely accepted requirements of HIS, three distinctive features of this study are; (i) integrated HIS approach through database administration, (ii) client-server architecture with distributed database capabilities, (iii) physician-configurable tree structure for the symptoms and signs allowing physicians to customize the application for their own style of medical case recording."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu çalışmada, elyazısı rakamların seçici dikkate dayalı optik tanınmasıyla ilgileniyoruz. Paralel tanıma yöntemleri girdinin bütününü bir defada işlerler. Seçici dikkate dayalı tanımada, girdinin parçaları belli önemlilik ölçütlerine uyarak seri olarak işlenir. Seçici dikkatin doğal olabilirliği ve yararlılığı savunulmuştur. Seçici dikkate dayalı bir tekniğin taşanım ayrıntılı olarak açıklanmıştır. Böyle bir tanıma tekniği üç paralel teknikle birlikte karşılaştırmalı olarak uygulanmıştır. Paralel teknikler hata geri yayma yöntemine dayalı olup, bunların ikisi öğreticisiz bir ön aşama kullanan melez öğrenme yöntemleridir. Böylece, çalışma paralel ve dikkate dayalı tanıma tekniklerinin işleyiş ve başarılarının karşılaştırılması için bir görüş açısı vermektedir. Uygulamada, aşağıdan-yukarıya önemlilik ölçütü hesaplanırken, en önemli bileşenler çözümlemesi yöntemiyle elde edilen öznitelikler kullanılmıştır. Girdi ile sınıf ve sınıf ile bakılacak yer arasındaki ilişkileri saklayan uzun erimli bellekler doğrusal hata geri yayma ağlarıyla öğrenilmiştir. Kısa erimli bellekler unutmaya ya da yanal bağlantılara dayalıdır. Basan, paralel tekniklerden düşük olmakla birlikte benzer bir seri tekniğe yakındır. Tanıma, girdinin dörtte birinden azanı işleyerek gerçekleştirilmiştir. Sistemin eksik yanlan ve olası iyileştirmeler de tartışılmıştır.","IV ABSTRACT In this study we deal with selective attention based optical recognition of handwritten digits. Parallel recognition schemes process the entire input at once. In selective attention based recognition, parts of the input are processed in series according to certain saliency criteria. A case is made for the plausibility and usefulness of selective attention. Design of a selective attention scheme is explained in detail. Such a recognition scheme is implemented comparatively with three parallel schemes. Parallel schemes are based on backpropagation, two of them being hybrid schemes using a prior unsupervised stage. The study hence gives a perspective to compare the operation and performance of parallel and attentional recognition schemes. In the implementation, features obtained through principal components analysis are used as basis for bottom-up saliency computation. Long-term memories storing input-to-class and class-to-saccade-location relationships are learned using linear backpropagation networks. Short-term memories are based on forgetting or lateral connections. Performance is worse than that of the parallel schemes but close to that of a similar serial system. Recognition is achieved by looking at less than one fourth of the input. Deficiencies of the system and possible improvements are also discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Hata geri yayma ağının öğrenme evresi, bir şarta bağlı olmayan optimizasyon problemi olarak kolaylıkla incelenebilir. Böyle bir problemin çözümü, bağımsız değişkenler serisini sistematik bir şekilde değiştirerek bir hedef fonksiyonunun azaltılmasını veya artırılmasını içerir. Birçok uygulamalarda, yapay sinir ağındaki bağlantı sayısı oldukça fazla olduğundan dolayı, klasik hata geri yayma metodu için öğrenme zamanı oldukça uzun sürer. Sayısal optimizasyon teorisinin sunduğu zengin ve güçlü teknikler sinir ağlarının öğrenme oranını geliştirmek için kolaylıkla uygulanabilir. Bu çalışma dört adet sayısal optimizasyon metodunu (Conjugate Gradient, Quasi-Newton.Levenberg-Marquardt, Nelder-Mead metodları) ve bunların çok katmanlı perseptronlar için uygulanmasını içerir. Bu çalışmada ayrıca dışlamalı- veya öğesi, parite (eşlik) biti, ve düzensiz zaman serileri tahmini problemleri için klasik geri yayma ağı metodu ile sayısal optimizasyon metodlarının karşılaştırma sonuçları da verilmiştir. Dışlamalı-veya öğesi, parite (eşlik) biti, ve düzensiz zaman serileri tahmini problemleri için, kullanılan sayısal optimizasyon metodlarının klasik hata geri yayma metoduna göre daha hızlı olduğu bulunmuştur. Ayrıca, sayısal optimizasyon metodlarının klasik hata geri yayma metoduna göre çok daha az sayıda fonksiyon ve türev hesaplanması gerektirdiği de gözlenmiştir.","IV ABSTRACT The learning phase of a backpropagation network can easily be viewed as an unconstrained optimisation problem. The solution of such a problem typically involves modifying a set of independent variables in a systematic fashion to minimise or maximise some objective function. In many applications, the number of interconnects or weights in a neural network is so large that the learning time for the conventional backpropagation algorithm can be excessively long. Numerical optimisation theory offers a rich and robust set of techniques which can be applied to neural networks to improve learning rates. In this work four groups of numerical optimisation methods (Conjugate Gradient Methods, Quasi-Newton Methods, Levenberg-Marquart Method and Nelder-Mead Method) and their application to the multi-layer perceptrons is examined. The results of exclusive-OR, three-bit parity and chaotic time series prediction problems, which compare conventional backpropagation and numerical optimisation methods, are also presented in this work. For exclusive-OR, three-bit parity and chaotic time series prediction problems we found that the above mentioned numerical methods are faster than conventional backpropagation. It was also observed that numerical methods also require much less number of function and gradient evaluations than conventional backpropagation with momentum."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Ardışık görüntülerden hareket bilgisinin tahmini bilgisayarla görmenin temel ilgi alanlarından biridir. Bilgisayarla hareket analizinde birden fazla görüntü aynı anda işlendiği için, hareket belirleme algoritmasının performansı çok önemlidir. Seri bir sistemin işlem hızının } kimi zaman hareket analizi için yetersiz olabilecek, bir sının vardır. Bu durumda, paralel işlem hız sorunu için iyi bir çözüm olarak görünmektedir. Nokta temelli ve pencere dolaştırma operasyonları paralel işlemeye uygundur. Fakat bu cins algoritmalar hareket analizinin ilk seviyelerinde kullanılır. Daha yüksek seviyeli algoritmalar değişik bir doğaya sahiptir. Bunların paralellikleri, paralel sistemin avantajlarım kullanmak için daha derin araştırılmalıdır. Bu çalışma bilgisayarla hareket analizi algoritmalarının paralel bir sistem üzerinde uygulanmasının yollarını aramayı amaçlamıştır. Bu çalışmadaki paralel sistemin kurulmasında Transputer işlemcileri kullanılmıştır. Bu işlemciler link tabanlı işlemcilerdir ve link tabanlı ağlar kurmak için dört linkleri vardır ki bu hareket analizi için uygun gözükmektedir. Bir hareket analizi algoritmasında en temel problem ardışık görüntü parçalan arasındaki karşılıkları bulmaktır. Karşılıkları eşleme yöntemi ile bulmanın diğer yöntemlerden bazı üstünlükleri olduğundan, bu çalışmada karşılık gelme problemini çözmek için seçilmiştir. ""Nokta seviyesinde eşleme"" ve ""doğru seviyesinde eşleme"" adıyla iki örnek algoritma hareket analizim paralel transputer ağında test etmek için geliştirilmiştir. Algoritmalar önce seri şekilde gerçekleştirilmiş ve denenmiştir, sonra, paralelleştirilip transputer ağına uygulanmıştır.","IV ABSTRACT The estimation of motion information from a sequence of images is one of the prime interests of Computer Vision. Since more than one image is handled at the same time in motion analysis performance of the motion extraction algorithm is very important. There is a limit of processing speed of a sequential system which may be sometimes inadequate for motion analysis. In this case, parallel processing seems to be a good solution for speed problem. Point-wise and window operations are well fitted to parallel processing. But these types of algorithms are used in very early levels of motion analysis. Higher level algorithms are of different nature. Their inherent parallelism must be investigated deeper to take advantage of a parallel system. This work is intended to find the ways to implement the computer motion algorithms on a parallel system. In this work, transputer is used as the building block of the parallel system. These processors are link based processors and have four links to build link based networks which seems suitable for motion analysis. In a motion analysis algorithm the basic problem is to find correspondence between sequential image fragments. There are several ways to handle this problem. Since finding correspondence through matching has several advantages over other algorithms, it is selected to handle correspondence problem in this work. Two example algorithms, namely ""line-level match"" and ""selected-point-level match"", are developed to test motion analysis on the parallel transputer network. Algorithms are firsts implemented and tested in sequential fashion, then, they are parallelised and applied to transputer network."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Makine çevirisi bilgisayarların doğal bir dilden bir diğerine metin çevirimine uygulanmasıdır. Makine çevirisi için önerilmiş üç değişik yaklaşım vardır; dolaysız çevirim, aktarma temelli çevirim, geçiş dili temelli çevirim. Bu yaklaşımların hiç biri Türkçeden diğer Türk dillerine makine çevirisi için uygun olmadığından biz sözlük temelli bir metot önerdik. Türkçe ve diğer Türk dillerinin temsilcisi olan Azeri dilinin sözdizimi yapılan benzer olduğundan sözdizimi analizi yapmadık. Çeviri için biçimbilimsel ve anlamsal analizler gerçekleştirildi. Kaynak ve hedef dillerin sözdizimi yapılan benzer olsa bile makine çevirisi kelimeden kelimeye olarak düşünülemez. Bunun sebebi birden çok anlamı olan belirsiz kelimelerdir. Türkçeden Azericeye çeviride belirsizlik konusu açıklandı ve bu belirsizlikleri çözmek için muhtemel yollar ortaya kondu. Önerilen yaklaşım tarzı kullanılarak Türkçeden Azericeye bir çeviri programı gerçekleştirildi. Çeviri programından alınan sonuçlar önerilen yaklaşımın Türkçeden Azericeye çeviri için uygulanabilir olduğunu gösterdi.","Machine translation is the application of computers to the translation of texts from one natural language into another. There are three different approaches proposed for machine translation; direct translation, transfer-based translation and interlingua-based translation. Since none of these approaches are suitable for the problem of machine translation from Turkish to other Turkic languages, we propose a lexicon-based approach. As the sentence syntax is similar for Turkish and the Azeri language, chosen as a representative of Turkic languages, we do not employ any syntactic analysis. Morphological and semantic analyses are carried out for the translation. Translation can not be viewed as a word for word translation even though the source and the target languages have a similar syntactic structure. This is due to the existence of ambiguous words with multiple meanings. The subject of the ambiguity in translation from Turkish to Azeri is explained and possible ways to resolve the ambiguities are put forward. A translator from Turkish to Azeri is implemented using the proposed approach. The results obtained from the translator show that the proposed approach is feasible for machine translation from Turkish to the Azeri language."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmada belleğe dayalı modellerin, hata geri yayma ağlarının ve dairesel bakışımlı taban işlev ağlarının basanları işlev yaklaşıklaştırma, el yazımı rakam tanıma, nükleer reaktör denetimi ve ses tanıma uygulamalarında karşılaştırıldı. En yakın komşu sınırlandırıcı modelinde olduğu gibi deneyimlerini doğrudan parametrelerinde saklayan sistemler belleğe dayalı modeller olarak adlandırılmıştır. Bahsedilen modellerin karşılaştırılmasında, genelleme yeteneği, ağ büyüklüğü ve öğrenme hızı ölçüt olarak alındı. Genelleme yeteneği, işlev yaklaşıklaştırma sorunlarında ortalama karesel yanılgı ölçütü ile değerlendirilirken, sınıflandırma sorunlarında deney kümesindeki doğru sınıflandırılan örneklerin sayısıyla belirlendi. Öğretici bir örnek olan işlev yaklaşıklaştırma sorununda, genelleme yeteneği ve ağ büyüklüğü açılarından belleğe dayalı modellerin, hata geri yayma ve dairesel bakışımlı taban işlev ağlarından daha başarısız olduğu görüldü. Buna karşın gerçek uygulamalarda, belleğe dayalı modeller şaşırtıcı derecede başarılı bulundu. Belleğe dayalı modellerin basitliğin, hızlı ve iyi öğrenmenin önemsendiği ancak bellek kullanımının kısıtlayıcı olmadığı uygulamalarda kullanılmalısı gerektiği sonucuna vardık.","IV ABSTRACT We compared performances of memory based models, backpropagation networks and radial basis function networks on several applications; a one dimensional function approximation task, recognition of handwritten digits, nuclear reactor control and phoneme recognition. Systems which directly store experiences in their parameters, like the nearest neighbor classifier, are referred to as memory based models. Our criteria for comparing the mentioned models were generalization ability, network size and learning speed. For approximation problems generalization ability was measured by the well known mean squared error criterion on a test set of unseen patterns during training whereas for classification tasks generalization ability was determined by the number of correctly classified samples of the test set. On the didactic function approximation problem memory based models were found to be inferior to backpropagation nets and radial basis function networks in both respects, generalization ability and network size. Nevertheless, on real world applications we found memory based models to be surprisingly successful. We conclude that memory based schemes be employed when a simple, fast learning, and accurate scheme is desired and memory is not at a premium."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Çerçeve aktarma teknolojisi, Tümleşik Hizmetler Sayısal Şebekesi (ISDN) kavramının isterlerini saniyede 2 milyon bit iletim hızıyla karşılamak üzere teklif edilmiştir. Çerçeve aktarma, bağlantı yönlü bir paket anahtarlama tekniğidir ve yerel alan ağlarının arabağlantısı için amaçlanmıştır. Çerçeve aktarmanın temel özelliği, veri bağlantı katmanının iki altkatmana ayrılmasıdır. Bunlar, çekirdek veri bağlantı (VB_ÇEKİRDEK) ve veri bağlantı kontrol (VB_KONTROL) altkatmanlandır. DL_CORE altkatmanı kullanıcı-ağ arabiriminde (KAA) işler ve X.25 gibi diğer paket anahtarlama teknolojilerine nazaran arabirim işlevini azaltır. Bu işlev, iletim ve çerçeve hatalarının saptanması, çerçeveleme işlemlerini, ve sıkışma denetimini içerir. VB_KONTROL altkatmanı bütün olağan veri bağlantı katmam işlevlerim uçtan uca usulüne göre gerçekleştirir. Bu tezde, VBÇEKİRDEK altkatmanı için bir tasarım teklif edilmiş ve ilişkin yazılım gerçeklenmiştir. Bu aslında çerçeve aktarma temelli bir sistemin KAA'sıdır. VBÇEKÎRDEK tasarımı bir durum geçiş modeline dayanmaktadır. Altkatman yazılımı C dilinde geliştirilmiştir ve gelecekte bölümümüzde yapılacak çerçeve aktarma iletişim ve anahtarlama yazılımlan geliştirilmelerine temel teşkil edecektir. Bu yüzden yazılımımız, sonradan yapılacak eklemeleri imkanlı kılacak halde tasarlanmıştır. Çerçeve aktarma yazılımı, klasik VB_ÇEKİRDEK işlevlerinin yanısıra bir benzetim çıktısı yaratılmasını da içerir. Benzetim çıktısı bütün kritik olayların kayıtlarından oluşur. Bu tasarım ve gerçekleme çerçeve aktarma ile ilgili CCITT standartlarına dayansa da bunlarla kısıtlanmamıştır.","IV ABSTRACT The frame relay technology has been proposed to satisfy the requirements of Integrated Services Digital Network (ISDN) concept with a transmission rate of 2 Mbps. Frame relay is a connection oriented packet switching technique and is intended for the interconnection of local area networks. The basic characteristic of frame relay is the division of the data link layer into two sublayers. These are the Data Link Core (DLCORE) and the Data Link Control (DL_CONTROL) sublayers. The DL_CORE sublayer operates at User- Network Interface (UNI) and reduces the interface functionality as compared to the other packet switching technologies like X.25. The interface functionality includes the detection of transmission and frame errors, framing operations and congestion control. The DLCONTROL sublayer performs all the usual data link layer functions in an end-to-end manner. In this thesis, a design for the DL_CORE sublayer has been proposed and the corresponding software has been implemented. This is actually the UNI of a communication system based on frame relay. The design for DLCORE is based on a state transition model. The sublayer software has been developed in C language and it will constitute a basis for future development of the frame relay communication and switching software in our department. Therefore, our software has been designed so that future additions to it would be possible. The software for frame relay includes both the classical DLCORE functions as well as the generation of a simulation output. Simulation output consists of the recording of all critical events. The design and implementation are based, but not limited to, the CCITT standards on frame relay."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Özet Çok eklemli robot düzeneklerinde yüksek kinematik ve dinamik karmaşıklık ve durumlar arası etkileşim bulunmaktadır. Son on yılda doğrusal olmayan kon trol teorisi alanında birçok çalışma yapılmış ve bunların büyük çoğunluğu geri beslemeli doğrusallaştırma konusuna adanmıştır. Bu tezde geri beslemeli doğrusallaştırma sonuçları kullanılmış ve soruna daha basit bir çözüm önerisi getirilmiştir. Çalışmada, uygun doğrusal olmayan kon- trolcüyü bulmak için yordam, önerilen kontrol yönteminin sezgisel açıklaması ve Tek- Girdi- Tek- Çıktılı ve Çok- Girdi- Çok- Çıktık sistemler üzerinde benzetimlerle yöntemin doğrulanması sunulmuştur.","IV Abstract Multi-link articulated mechanisms exhibit high kinematic and dynamical com plexities and coupled states. During the last decade there have been many re searches in the field of nonlinear control theory and most of them were dedicated to feedback linearization. This thesis makes use of the results of feedback linearization and proposes a simpler solution to the problem. The work consists of the algorithm to find the appropriate nonlinear controller, a discussion on the heuristics of the proposed scheme, and justification via simulations on both SISO and MIMO systems."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV PIAGET: NESNE YÖNELİMLİ FONKSİYONEL BİR DİLİN TANIMI VE SA?LANMASI Piaget nesne yönelimli fonksiyonel bir dildir. Piaget, Henson [1] tarafından önerilen bir dilin uzantısıdır. Henson'ın dili fonksiyonel ve başvuruca şeffaftır (hiçbir değişken değerini değiştiremez). Piaget dili Henson'in dilinin Özelliklerini korur ve onu nesne yönelimli olarak genişletir. Nesne yönelimli ekler, çalışırken yöntem belirleme, bilgi soyutlama ve soya çekimdir. Henson'ın dilinin sentaksına ayrıca C++ dilinin işlemcileri ve işlemcileri yeniden tanımlama özelliği de eklenmiştir. UNIX işletim sisteminin derleyici kurma gereçleri olan yacc ve lex ile derleyerek, elde edilen sentaksın belirli olduğu gösterilmiştir. Yazı boyunca verilen örnekler, yacc ve lexin ürettiği bir ayrıştıncı ile sağlanmıştır. Dilin formal ve formal olmayan tanımları verilmektedir. Dilin formal tanımı da Henson'ın dilininkinin bir uzantısıdır. Formal tanımlardaki ekler Henson'ın yöntemlerini izleyerek doğrulanmıştır. Nesne yönelimli eklerin tanımları sadece Henson' un dilinde olan yapılarla verilmiştir. Piaget dilinin basitliğini ve gücünü göstermek için bazı örnek yazılımlar, Henson'un dilindeki ve başka dillerdekilerle karşılaştırılmışım","Ill P1AGET: DEFINITION AND VERIFICATION OF AN OBJECT ORIENTED FUNCTIONAL LANGUAGE The Piaget language is an object-oriented functional language. It is an extension of a language proposed by Henson [1]. Henson's language is functional and referentially transparent (no variable can change its value during execution). The Piaget language keeps the properties of Henson's language and extens it to be object-oriented. The object- oriented extensions are, namely, runtime method determination, data abstraction, and inheritance. The syntax of Henson's language is also extended to have the operators and operator redefinition facility of the C++ language. The final syntax is verified to be unambiguous by compiling the syntax with yacc and lex, which are the compiler construction utilities of the UNIX operating system. The example programs given throughout the text are checked by a parser generated by yacc and lex. An informal and a formal definition of the language are presented. The formal definition of the language is also an extension of the formal definition of Henson's language. Extensions on the formal definitions are verified following the methods used by Henson. Informal definitions of the object-oriented extensions are purely in terms of already existing constructs in Henson's language. Some example programs are compared with the ones written in Henson's language and other languages to illustrate the power and simpilcity of the Piaget language."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"QSIMDE SORB ANALİZİ VE QSIM'İN KESÎKLÎ-ZAMAN SİSTEMLERİNE GENİŞLETİLMESİ Fiziksel Sistemler üzerine nitel akıl yürütme, insanlara özgü sağduyu yeteneği ile fiziksel sistem modellerini birleştirerek bilgisayarlara, formel ve algoritmik bir akıl yürütme stratejisi olarak aktarmayı hedefleyen bir araştırma programıdır. Nitel benzetim algoritması QSIM, sistemin nitel davranışını, tek tek parametrelerin belirli durumlarda aldıkları değerlerin bir dizisi olarak vermektedir. Bu tezde QSIM'e iki yönde katkıda bulunulmuştur: Süre Analizi algoritması ve QSIM yaklaşımının kesikli-zaman sistemlerine genişletilmesi. Süre Analizi, kinematik bağıntılar model alınarak, bu bağıntıların nitel kısıtlarla tanımlanan tüm fiziksel sistemler üzerinde çalışan genel akıl yürütme stratejilerine dönüştürülmesini hedefler; sonuç olarak da, farklı aralıkların sürelerinin karşılaştırması olan bir listeyi, ya da formel terimlerle ifade edecek olursak, kısmi sıralanmış bir sembolik süre setini verir. OSIM'in kesikli-zaman sistemleri üzerine genişletilmesi ise, sürekli fonksiyonlardan oluşan sistemler konusunda geliştirilen formalizmin yeniden tanımlanması ve kesikli-zaman sistemlerini karakterize eden fark eşitliklerini nitel kısıtlara mekanik olarak çeviren bir yöntemin tanımlanmasına dayanmaktadır. Daha sonra da nitel benzetim algoritması uygulanmakta ve kesikli-zaman sisteminlerinin davranışına ilişkin nitel tasvir ortaya çıkarılmaktadır.","IV DURATION ANALYSIS IN QSIM AND EXTENSION OF QSIM TO DISCRETE-TIME SYSTEMS Qualitative reasoning about physical systems is a research area which attempts to merge humans' common sense ability and physical system models into formalized and algorithmic reasoning strategies. Qualitative simulation algorithm QSIM furnishes a well- defined algorithm which can turn out the qualitative behavior of a given system as a sequence of states expressing the behaviors of individual parameters. The contributions presented in this thesis are two extensions to QSIM, a Duration Analysis algorithm and the extension of the approach over discrete-time systems. Duration analysis focuses on the discovery of temporal properties, by exploiting the model of kinematical relations and by transforming them into general reasoning strategies encompassing all physical systems described by qualitative constraints. It produces a list of comparison results on the durations of intervals, or in formal terms, a partially ordered symbolic duration set. For the extention of QSIM to discrete-time systems, the formalism put forward for a system of continuous functions is redefined and a mechanical way of converting difference equations characterizing discrete-time systems, into qualitative constraint equations is described. Next, the qualitative simulation algorithm is applied and the qualitative description of the behavior of the system is obtained."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"BİR VERİ AKIŞI MAKİNASININ BENZETİMİ Veri tarafından sürülen paralel bilgisayarlar, basit yapı prensipleri üzerine kurulmuşlardır ve programlanmaları, bakımları, ve geliştirilmeleri çok basittir. Manchester veri akışı makinası. bu makinaların en karmaşık ve geliştirilmiş olanlarından biridir. Temel yapısı, değişik modüllerden oluşmuş bir halkadır. Bu halkayı oluşturan modüller jeton kuyruğu, eşleştirme ünitesi, işlem deposu ve işleme ünitesidir. Manchester veri akışı makinası. kuyruklar ve bu kuyruklara yanıt verenlerden oluşan bir halka şeklinde modellenmiştir. Ayrık olay benzetimi teknikleri kullanılarak, bu modelin benzetimi gerçekleştirilmiştir. Bu benzetim üzerinde yapılan hızlanma değerlendirmesi ve akış analizi, bu modelin verimlilik ve kullanım düzeyi olarak genel eğilimlere uyduğunu göstermektedir. Ancak fiziksel olarak daha paralelleştirildikçe, modelin belli bir noktada doyuma ulaştığı gözlenmiştir. Bu doyumun, kullanılan veri akışı programlarındaki paralelliğin yetersizliği sonucu ortaya çıktığı ileri sürülmüştür.","iv SİMULATİON OF A DATAROW MACHINE Data driven parallel computers are based on simple architectural principles and are easy to program, maintain, and extend. Manchester Dataflow Machine is one of the most complex and developed dataflow machines. It has a tagged-token nature. The basic structure of Manchester Dataflow Machine Is a ring of different modules, which are the Token Queue, the Matching Unit, the Instruction Store, and the Processing Unit. This machine can be modelled by a ring of queues and servers. Based on this model, it can be simulated using discrete event simulation techniques. Speed-up evaluation and flow analysis performed on this model show that the model conforms to the expected trends in performance and utilization. However, as more physical parallelism is introduced, the model reaches a saturation. This saturation is Identified to be because of lack of sufficient parallelism in the input dataflow programs."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"PARMAKLAMA EŞLEMESİ ÎLE DO?AÇLAMA STİLİNİN Ö?RENİLMESİ Tezimiz algoritmik kompozisyonu yeni bir açıdan değerlendirmektedir. Uygulamamız gitar üzerinde caz doğaçlamasının öğrenilmesidir. Caz doğaçlaması gruptaki diğer müzisyenlerin kurduğu armonik zemin ve bu zeminin üzerine doğaçlamacının o an yarattığı melodidir. Bu doğaçlama, başka bir açıdan da bir parmaklamalar dizisidir. Parmaklama, bir müziğin enstrüman üzerinde seslendirilmesi için parmakların ne şekilde kullanılacağıdır. Telli enstrümanlarda bir ses birden fazla değişik parmaklama ile gerçekleştirilebilir. Doğaçlamacının fiziksel özellikleri ve enstrümanının fiziksel yapısı zaman içinde doğaçlamacının parmaklama stilini oluşturur. Parmaklama stili ise doğaçlamacının müzik stilinde belirleyici rol oynar. Parmaklama dizilerini öğrenmek, doğaçlamacının müzik stilini öğrenmektir. Bu çalışmada, zaman-gecikmeli yapay sinir ağına parmaklama dizisi eşlemesi öğretildi. Bu sinir ağının öğrenme kümesini, doğaçlamacının parmaklamaları oluşturdu. Sisteme deneme safhasında başlangıç parmaklamalar dizisi vererek bu diziyi takip eden parmaklamalar ürettirildi. Daha sonra bu parmaklamalar seslere görüntülendi. Sonuç olarak caz müziğine uygun dört ölçülük özgün melodiler elde edildi.","IV CONNECTIONIST APPROACH TO IMPROVISATION USING FINGERING PATTERN ASSOCIATION This thesis brings a new approach to algorithmic composition. The domain of this study is blues jazz improvisation. Jazz improvisation is generally considered as an improvised melody over a chordal background formed by other performers in the group. Improvisation can also be considered as a sequence of fingerings which are the arrangement of the fingers of the performer to realize a meFodic sequence with the instrument. In string instruments different fingering sequences may correspond to same melody. In improvisation both the melody and the corresponding fingering are created in real time. Fingerings style of an improvisor is subjective to his musical characteristics of the improvisor. A time-delay neural network that generalizes from fingering sequence examples is proposed. The network is trained with the fingering sequences of an improvisor-guitarist. In the testing phase an initial fingering sequence was fed to the network and let it generate successive fingerings. Then these outputs were mapped to musical domain. The network was successful in creating original melodies four measures long, similar to that of the improvisor."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu tezde iki eklemli düzlemsel ve 3 er eklemli silindirik ve küresel robotlar için her biri sinir ağları içeren Oransal-Türevsel denetim yöntemi ile Oransal-Türevsel ve Sabit Hata İvmeli denetimler arasında açkılamak yapıya sahip bir denetim yöntemi arasında karşılaştırma yapılmıştır. İlk aşamada robotların dinamik davranışlarını modelleyen denklemler, bir sembol işleme paketi ile türetilmiştir. Bu iki denetim yöntemi de ayrıklaştırılmış robot modellerini gerektirmektedir. Robot durum değişkenlerini ayrıklaştıran bir yöntem verilmiştir ve ayrıklaştırma işlemi sonucunda kalan terimlerin doğrusal olduğu gösterilmiştir. Birincil ve ikincil denetim çevrim kavramları dile getirilmiştir ve birincil çevrimin sinir ağlarıyla oluşturulması için bir temel verilmiştir. Aynı anda iki çevrim birden kullanmanın gerekçesi şöyle açıklanabilir : birincil çevrim robot dinamiğinin tersinin bulunmasına yararken, ikincil çevrim birincil çevrimin uygulanması sonucunda ortaya çıkan hataların sıfıra indirilmesi için kullanılmaktadır. Kullanılan ikincil çevrim teorileri de bütünlük için verilmiştir. Robotu denetlemek için gerekli tüm verilerin elde edildiği çevrim dışı gerçekleştirilen veri üretme koşumları açıklanmıştır. Hata indirgeme çevriminin kullanıldığı durumlarda elde edilen sonuçların, sinir ağları ile gerçekleştirilmiş birincil çevrimin kendi başına kullanıldığı durumlara göre daha başarılı olduğu gösterilmiştir. Bu çalışma herhangi bir robotun denetim sorununa basit ve doğal bir çözüm getirmiştir, çünkü robot hakkında hiçbir ön bilgi gerektirmemektedir. Robotun bilgisayar ekranında canlandırılabilmesi için üç-boyutlu bir arayüz yazılmıştır. Tüm yazdım, MS-DOS işletim sistemi altında ve C dili kullanılarak oluşturulmuştur.","IV ABSTRACT In this thesis, a Proportional-Derivative (PD) control scheme and a switching algorithm between PD and Constant Error Acceleration (PD+CEA) control scheme which involve multilayered feedforward Neural Networks are compared for a two Degree of Freedom (DOF) planar robot and three DOF cylindrical and spherical robots. The dynamical equations describing the robots are derived first, using a symbolic computation package. Those two control schemes are to be used with decoupled models of the robots. A method of decoupling the states of the robot is given and the remaining terms after decoupling become linear. The concepts of Primary and Secondary Controllers are stated and a framework for using the Neural Networks as the Primary Controllers is presented. The main idea of using two controllers is that the Primary Controller approximates the inverse of the system, and the Secondary Controller offers a way of reducing the errors occuring between the reference states and actual robot states after the control input due to the Primary Controller is applied. The theories of the Secondary Controllers used are presented for completeness. The procedure of generation of the training patterns for the Neural Networks is explained where all the data necessary to control the robot is gathered during off-line pattern generation runs. It is shown that satisfactory results are obtained compared to the cases where no error reduction is present and the only controller is a Neural Primary Controller. This thesis offers an easy and natural solution to the control problem of arbitrary robot configurations, since no apriori knowledge of the robot is assumed. Also a 3-D graphical interface is written to visualize the robots on the computer display. All of the programs are developed under MS- DOS operating system using C language."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V ÖZET Mikroislemci lerin gelişmesi çok hızlı bir süreç olmuştur. Mikroislemci tasarımcıları daha hızlı çalışan mikroişlemcileri rakip firmalardan daha önce piyasaya çıkar mak için uğraşmaktadırlar. Bu süreçte hata payına ve tasarımı tekrar yapmakla kaybedilecek paraya yer yoktur, ürünlerin üretilmeden önce kontrol edilmeleri gereklidir. Bu amaca yönelik tasarım araçları, profesyonel tasarımcıların yanısıra akademik ortamda öğrenciler tarafından da kullanılmaktadır, öğrenciler, mevcut tasarımları ve alınmış olan tasarım karar larının nedenlerini anlayabilmek ve yeni tasarımlar yapabil mek için bu araçları kullanmaktadırlar. Bu tez çalışmasında, mikroislemci tasarımını ve bu tasarımın performansının değerlendirilmesini sağlayan bir araç program gerçeklenmistir. Bu programı kullanarak bir mikroişlemcinin mimarisine ait tanımlamalar bilgisayara verilebilir. Program bu mimaride komutların nasıl ve kaç saat çevriminde işleneceğini ya da işlenmesinin mümkün olamayaca ğını belirler. Ayrica bu program, verilen bir komutun belir tilen parametreleri ile bu mimaride kaç farklı şekilde işle nebileceğini de bulur ve kullanıcıya sunar. Bu mikroislemci tasarım ve kontrol araç programı, saklayıcı aktarımı düzeyinde çalışır ve üzerinde komut işle nilen mikroişlemcinin hızı hakkında, her komutu kaç saat çevriminde işlediğini belirterek bilgi verir.","IV ABSTRACT The evolution of microprocessors has emerged to be a very fast process. Microprocessor designers are trying to develop products with better performance and earlier than the other vendors. There are no tolerance for design errors and repetition of costly design process. Designers need to design and test the microprocessors with computer aided tools before they are actually manufactured. The tools which help to design and test microprocessors are also being used by engi neering students in academical institutes. Students extend their knowledge on commercial architectures, understand and interpret the design rules and finally do new designs with the help of such tools. A tool which is used for microprocessor design and performance evaluation has been developed in this study. This tool allows to define the architectural specifications of microprocessor and examine the instruction execution on this defined architecture. The tool finds every possible execution for the given instruction with defined parameters using every operator and bus in the system. The execution simulation method works for every architecture defined, thus the archi tecture is dynamic. If the execution of a particular instruc tion is not possible with the given parameters, the program tells that the instruction can't be run on this architecture. The microprocessor design and verification tool represents the system at register transfer level and gives performance values of defined microprocessor depending on the cycle counts of every instruction execution."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"NİTEL SİSTEM TANILAMA Yapay Zeka'nın nitel uslamlama alanındaki bu araştırmanın temel katkısı, nitel sistem tanılama algoritması QSI'in geliştirilmesidir. QSI'm girdisi, tanılanacak sistemin nitel davranışlarının bir betimlemesidir. Çıktısı bu davranışları gösteren sistemin Kuipers'in QSIM nitel benzetim algoritmasının biçeminde ve sistemin girdide belirtilmemiş ""derin"" parametrelerini de içerebilen bir kısıt modelidir. Nitel modellemeye QSI yaklaşımı sistem parametrelerinin ""anlamları"" hakkında hiç bir varsayım yapmaz ve bilgiye gereksinmez. QSI geniş biçimde tartışılmakta ve örneklenmektedir. Diğer katkılar, bir grup ""sahte"" QSIM davranışını elemek için yeni bir yöntem ve bir sonradan tahmin algoritmasıdır. Sahte davranışları azaltma konusuna başka yaklaşımların aksine, burada sunulan yöntem girdideki model hakkında kısıtlayıcı varsayımlar gerektirmez. Belli bir tür sahte davranışın saf QSIM'in model kısıtlan için kullanılan karşılık değer takımlarında sadece nokta değerlerin tutulması konusundaki İsrarı nedeniyle ortaya çıktığı saptanmıştır. Sunulan çözüm, verilen işletim örnekleri ve ispatların da gösterdiği gibi, algoritmanın genel karmaşıklığını kötüleştirmeden daha doğru çıktıların oluşmasını sağlar. Sonradan tahmin, değişim yasaları ve şimdiki durum verildiğinde olasıgeçmişleri bulma işidir. Algoritmayı elde etmek için, zamanın ""geçişi"" ile ilgili değişikliklerin yanısıra, benzetimce üretilen durum ağacını yorumlamanın farklı bir yöntemi getirilmiştir. Tanı uygulamaları için umut vaadeden bu uslamlama türüyle ilgili konular tartışılmıştır.","IV QUALITATIVE SYSTEM IDENTIFICATION The main contribution of this research in the qualitative reasoning area of Artificial Intelligence is the development of the qualitative system identification algorithm QSI. QSI's input is a description of the qualitative behaviors of the system to be identified. Its output is a constraint model (possibly containing ""deep"" parameters absent in the input) of that system, in the format of Kuipers' qualitative simulation algorithm QSIM. The QSI approach to qualitative modeling makes no assumptions and requires no knowledge about the ""meanings"" of the system parameters. QSI is discussed in detail. Other contributions are a new method of eliminating a class of spurious QSIM predictions, and an algorithm for postdiction. Unlike other approaches to spurious behavior reduction, the method presented here does not require restricting assumptions about the input model. A particular kind of spurious behavior is shown to be caused by pure QSIM's insistence on assigning only point values to ""corresponding value tuples"" associated with model constraints. The solution put forward here preserves the overall complexity of the algorithm, while producing fewer incorrect predictions, as shown by the presented reports of the case runs and proofs. Postdiction is the task of finding out the possible pasts of the system underconsideration, given the laws of change and the current state. For obtaining the algorithm, a different scheme of interpreting the tree built by simulation is imposed, as well as the handling of the ""flow"" of time. Issues of this reasoning task, which is promising for diagnosis applications, are discussed."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Petri ağlan paralel sistemlerdeki bilgi ve kontrol akışının soyut ve biçimsel modelleridir. Günümüzde zamanlı ve Stokastik Petri ağlan ile sözü geçen sistem modellerinin işleme değerlendirmeleri yapılabilmektedir. Stokastik Petri ağlarının elle incelenmesi, özelliklerinin araştırılması ve istatistiksel ölçümlerinin yapılması oldukça güçtür. Bu durum bir benzetim aracına olan ihtiyacı ortaya çıkarmaktadır. Bu tez yukarda açıklanan ihtiyacı karşılayacak bir yazılımı sunar. Bu yazılım Stokastik Petri Ağlan için Etkileşimli Benzetim Sistemi (ISSPN) olarak adlandırılmıştır. ISSPN tez içersinde tanımı verilmiş olan tahmini Petri ağlatının etkileşimli olarak tanımlanmasını, benzetiminin yapılıp istatistiksel bilgilerin toplanmasını sağlar. Benzetim sırasında istendiğinde bir Petri ağı üzerinde değişiklik yapılmasına ve benzetime devam edilmesine veya yeniden başlanmasına olanak tanır. Yazılım Petri ağlatının kendi içlerinde küçük Petri ağcıklanndan oluşmasına izin verir. Stokastik Petri Ağlannın metin formunda tanımlanabilmesi amacıyla Stokastik Petri Ağlan için Tanımlama Dili (SPNDL) adlı yazdım dili önerilmiş ve geliştirilmiştir. ISSPN, SPNDL dilinde verilen ağlan okuyabilir ve istenirse ağın tanımım bu dilde üretebilir. Yazılımın sonuçlan ile kullanıcılar modeli doğruluyabilir ve işlemesini değerlendirebilir.","IV ABSTRACT Petri Nets are abstract, formal models of information and control flow in systems exhibiting concurrency and synchronous behavior, and are widely used for modeling parallel systems. With the introduction of timed and stochastic Petri Nets, Petri Nets are now also used in performance evaluation of the modeled systems. Given a stochastic Petri Net (SPN) model, it is very difficult to manually analyze it and look for its certain properties, as well as to carry out statistical measurements, which thus requires the need for an automated tool. This thesis presents the design and implementation of a software tool, called Interactive Simulator for Stochastic Petri Nets (IS SPN), to simulate an SPN model. SPNs as accepted by ISSPN are defined. The ISSPN allows the user to define an SPN interactively and graphically. Stochastic Petri Net Definition Language (SPNDL) is proposed and defined to help specify SPNs in text form. SPNs that are specified in SPNDL are also accepted by ISSPN. A SPN may consist of subSPNs, thus the concept of hierarchic SPNs is available for the modeler. During the simulation, the SPN being simulated may be modified and the simulation may be continued or restarted. Intermediate statistical results are available during the simulation. The ISSPN is also able to generate a SPNDL definition of a SPN created in graphical form to ease transportation. Using the results of the simulation, the user can evaluate the performance of the modeled system and validate the correctness of the model by analyzing the statistical measurements."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Veri tabanlarına tamamlanmamış bilginin katılabilmesi özellikle bağıntısal veri tabanları bağlamında çeşitli araştırmacılar tarafından irdelenmiştir. Bu tezde, nesne yönelimli özelliklere sahip mantık temelli bir veri modeli olan Logob'a tamamlanmamış bilginin katılmasıyla ortaya çıkan sorunlar incelenmektedir. Ex-Logob veri modelinin formel tanımı yapılmakta ve söz dizimi tanımlanmaktadır. Dışarmalı, içermeli ayırtlam ve olası bilgilerin gösterimi için bir veri yapısı (E-tablo) önerilmektedir. E-tablolarında gereksiz bilgi türleri irdelenmekte ve nasıl giderilebileceği gösterilmektedir. Ex- Logob'un sorgu değerlendirmesi için E-tablolarını işleyen bir genişletilmiş bağıntısal cebir de tanımlanmaktadır. Ayrıca, tamamlanmamış bilgi içeren Ex-Logob kuralının bir Horn cümle kümesine nasıl çevrildiği gösterilmektedir. Ve son olarak, sunulan önerilerin Ex-Logob sorgularının değerlendirilmesinde nasıl kullanıldığı gösterilmektedir.","IV ABSTRACT Incorporating incomplete information into databases has been studied by various researchers especially in the context of relational databases. In this thesis, the problems brought about by the incorporation of incomplete information in Logob, a logic based data model with object oriented features, are examined. A formal definition of the Ex-Logob data model is given and its syntax is described. A data structure, E-table, to represent inclusive, exclusive disjunctions and maybe information is presented. The types of redundancies in E~ tables is discussed and it is shown how they are eliminated. Also an extended relational algebra is defined to operate on E-tables for the query evaluation of Ex-Logob. It is further shown how an Ex-Logob rule with indefinite information is converted into a set of Horn clauses. And finally, it is demonstrated how the ideas presented are applied to the evaluation of Ex-Logob queries."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmanın amacı klasik PID kontrol ile bulanık PID kontrol algoritmalarının karşılaştırılmasıdır. Her iki algoritmanın değerlendirilmesi için de, tipik endüstriyel süreçlerin simülasyonunda basit ama yeterli olan, ikinci dereceden gecikme-zamanlı bir sistem modeli kullanılmıştır. Çalışmada önce, sürece parametreleri muhtelif ayar teknikleri (Kalman, Ziegler-Nichols, Dahlin vs.) kullanılmak suretiyle belirlenmiş geleneksel PID kontrolü uygulanmıştır. Sonra, geleneksel PID kontrolü yerine çeşitli yaklaşımlarla gerçekleştirilebilen, bulanık PID kontrolü denenmiştir. Son olarak, geçici-zaman cevap performansları bir tabloda toplanmış ve karşılaştırılmıştır. Simülasyon sonuçları bulanık PID kontrolünün, performans tablosundaki kriterlere göre, daha iyi olduğunu göstermiştir.","IV ABSTRACT The object of this study is to make a comparison of conventional and fuzzy PID control algorithms. For the evaluation of both algorithms, a second- order system model with a dead-time, which is simple but adequate in the simulation of a typical industrial process, is used. In the study, first, the conventional PID control, whose parameters are selected by using miscellaneous tuning techniques (Kalman, Ziegler-Nichols, Dahlin etc.), is applied to the process. Then, the fuzzy PID control, which can be realized in various approaches, is implemented instead of conventional PID. Eventually, the transient response performances are evaluated through a performance index and compared. The simulated results showed that fuzzy PID control is better than conventional PID control regarding the criteria used as performance index."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bugün, pek çok uygulamada sistem modellemesi ve analizi için sistem cevabının istatistiksel karakteristiğini bulmak önem taşımaktadır. Bu çalışmada temel olarak sistem modelleme ve analiz metodlarını araştırdık. özellikle, Autoregressive Moving Average (ARMA) ve Pade1 metodlarını sistem transfer fonksiyonu katsayılarını bulma yönünden inceledik. Transfer fonksiyonu katsayılarını bulmak için literatürde pek çok metod vardır. Bizim çalışmalarımızda ARMA metodunun Modified Yule Walker equations ve AKAIKE algoritmaları, ve Biyiksiz tarafından geliştirlen yeni bir Pade' algoritması incelendi. Bu üç metod denendiğinde, Pade1 algoritmasının bilgisayarda kullanılan sözcük uzunluğundan dolayı ortaya çıkan hatalara karşı daha az duyarlı olduğu görüldü, öte yandan Pade' algoritması bazen orijinal sisteme göre kötü sonuçlar verdi. Düşük düzeyde üslü terim kullanıldığında Pade' algoritması diğer MYWE ve AKAIKE metodlarından genel olarak daha iyi sonuç verdi. ARMA ve AKAIKE'den ise genellikle yüksek düzeyde üslü terim kullanıldığında daha iyi sonuçlar alınabildi. Fakat bu düzey numaralarının da mutlaka geliştirilen düzey seçme algoritmalarından biri kullanılarak seçilmesi gerektiği gözlemlendi. Ayrıca durum uzayı modellemelerine karşı her iki algoritmanın bulduğu transfer fonksiyonlarının duyarlılığını inceledik. Araştırmanın bu kısmında ise farklı durum uzayı gerçekleme tiplerini karşılaştırdık. Burada elde edilen sonuçlar Pade'nin hepsinde olmasa bile bazı gerçekleme tiplerinde hataya daha az duyarlı bir transfer fonksiyonu üreteceğini gösterdi.","Today, in a variety of application the statistical characteristics of a system response is important in order for analysis and model the systems. In this study, we mainly made an investigation to the system analyzing and modelling methods. Especially, we considered Autoregressive Moving Average (ARMA) and Pade' approximation methods to find the modelled system transfer function coefficients. There are several algorithms to calculate these coefficients. In our study we used Modified Yule Walker Algorithm (MYWE) and AKAIKE algorithms for ARMA and a new Pade1 algorithm developed by Biyiksiz for Pade' approximation. When these three methods were simulated, it was seen that Pade* is mainly less sensitive to the coefficient quantization error and arithmetic round-off error accumulation introduced by finite word length. On the other hand it is not a good approximation for higher orders. it was seen that if the lower orders were used, Pade' approximation gave really good results compared to the MYWE and AKAIKE. But these ARMA models also are not guaranteed to give stable solutions for higher orders. In some cases for higher or lower order ARMA models produced good results especially for higher orders. But these orders should be choosen with one of the methodologies described for model order selection. An extension of research was done to the state-space error sensitivity. When the mentioned errors were investigated for different representation types of the state-space approach, it was shown that Pade' algorithm was less sensitive to such errors especially for some of the representation types."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu çalışmada Hopfield'ın ikili düzen beyinsel ağ modeli Blitzen yoğun paralel işlemcisi (BYPÎ) adında bit seri tek komut çok veri esaslı iki boyutlu ağ düzenindeki dizilim işlemciyi benzeten bir yazılım paketi kullanılarak benzetilmiştir, ilk olarak benzetim için gerekli algoritmalar tasarımlanmıştır. Daha sonra, bu algoritmalar kullanılarak, Hopfield ağının paralel gerçekleştirimi formüle edilmiştir. Paralel gerçekleştirim hızlanma ve işlemci yararı açısından analiz edilmiştir. Bunu yapabilmek için, paralel gerçekleştirimin zaman karmaşıklığı türetilmiş ve bu karmaşıklık sırasal bir işlemcinin zaman karmaşıklığıyla karşılaştırılmıştır. Son olarakta, benzetim sonuçları analiz edilmiş ve analitik türetmelerle karşılaştırılmıştır. Hopfield beyinsel ağ modelinin BYPÎ mimarisi üzerinde benzetimi için bu çalışmada betimlenen paralel algoritma kullanılan işlemci sayısının en fazla karekökü düzeyinde bir hızlanma sağlamaktadır. Aynı algoritma için, en yüksek hızlanmanın sadece sonlu sayıda işlemciyle gerçekleştirilebildiği ve işlemci yararının işlemci sayısı arttıkça azaldığı da gösterilmiştir.","In this study, Hopfield's binary neural network model is simulated using a software package simulating a bit serial single instruction multiple data (SIMD) mesh array processor, called the Blitzen massively parallel processor (BMPP). First, the parallel algorithms required for the simulation are designed. Then, the parallel implementation of the Hopfield network model has been formulated using these algorithms. The parallel implementation has been analyzed for the speed and the processor utilization. To do this, time complexity of the parallel implementation is derived and compared with the time complexity of a sequential algorithm. Finally, simulation results are analyzed and compared with the analytical derivations. The parallel algorithm described in this study for the simulation of the Hopfield network model on the BMPP architecture achieves a maximum speedup in the order of the square root of the number of processors employed. It is also shown that, for the same algorithm, the maximum possible speedup can be achieved only at a finite number of processors, and the processor utilization decreases as the number of processors is increased."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Hareket Analizi, Bilgisayarla Görme' nin önemli bir altalanıdır. Bu çalışmada, hareket analizi alanındaki yaklaşımların bir analizi ve kategorizasyonu yapılmıştır. Bu yaklaşımları kullanan altı algoritma tasarlanmış, ve bunların üçü gerçekleştirilmiştir. Hareketi farketmek için birden fazla görüntünün ele alınması gerektiğinden, bütün hareket çalışmalarında görüntüler arasında bir karşılık gelme problemi vardır. Bu problem görüntülerin elemanları arasında eşleme işlemi yardımıyla çözülmektedir. Bilgisayarla görme, görüntü oluşturmadan cisim bilgisinin çıkarılmasına kadar adımları içermektedir. Bilgisayarla görme algoritmalarındaki adımlar dizisi içinde eşlemenin seviyesi -bir başka deyişle, eşlenecek elemanların cinsi- yaklaşımların analizi ve kategorizasyonunda ölçüt olarak alınmıştır. Eşleme seviyesiyle ilgili bilinen üç yaklaşım sunulmuş (cisim, seçilmiş noktalar ve piksel seviyesi eşlemeler), ve üç tanesi de geliştirilmiştir (doğru, köşe ve bölge seviyesi eşlemeler). Bu yaklaşımları katagorizasyonumuzu göstermek için altı algoritma tasarlanmış ve tartışılmıştır. Daha sonra, tasarlanan altı algoritmadan üçü gerçekleştirilmiştir. Bunlardan biri birinci gruptan olup, seçilmiş noktaları eşlemektedir. Diğer ikisi ikinci gruptan olup, görüntülerden çıkarılmış doğru ve köşeleri eşlemektedir. Programların sonuçları sunulmuş, algoritmaların güvenilirlikleri ve performansları hesaplanmış ve karşılaştirılmiştir.","XV ABSTRACT Motion Analysis is a significant subfield of Computer Vision. In this study, an analysis and categorization of approaches in the area of motion analysis is performed. Six algorithms are designed using these approaches, and three of them are implemented. Since more than one image must be handled to detect motion, a correspondence problem exists among the images in all motion studies. This problem is solved by means of matching processes between some elements of the images. Computer vision includes steps from image formation to extraction of object information. The level of matching in the whole sequence of steps in computer vision algorithms in other terms, the type of elements to be matched- was taken as the criterion at the analysis and categorization of the approaches. Three known approaches to the level of matching were presented (object, selected-point and pixel -level matchings) ; and three more of them were devised (line, vertex and region-level matchings). Six algorithms were designed and discussed to demonstrate our categorization of these approaches. Then, three of six designed algorithms were implemented. One of them is from the first group, and matches selected- points. Other two are from the second group, and match straight lines and vertices that are extracted from the images. Results of the programs were presented; and the reliabilities and performances of the algorithms were evaluated and compared."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Üçgenleştirilmiş Düzensiz Ağlarının Coğrafîk Veri Tabanlarında yüzey modellemesi amacıyla kullanımı gittikçe artmaktadır. Üçgenleştirilmiş Düzensiz Ağlar, üçgenlerin kesişmemesi ve modellenen arazideki düzensizlikleri tanımlayabilme özellikleri nedeni ile tercih edilmektedir. Arazi modellemesi için bu özellikleri sağlayan Delaunay uçgenlemesi yeterince uygundur. Delaunay üçgenlemesi doğrudan Thiessen tessellasyondaki komşuluklar kullanılarak oluşturulabilir yani eşçözümlerdir. Thiessen tessellasyonu bir düzlemdeki ana noktalara göre düzlemin etki alanlarına bölünmesidir. Şöyleki her ana noktaya ait olan düzlem parçası bu ana noktaya diğer ana noktalardan daha yakın olan konveks bir kapak bölgedir. Bu tezde verilen bir noktalar kümesi için düzlemi etki-bölgelerine ayıran bir algoritma tasarlanmış ve gerçeklenmiştir. Algoritmada Green ve Sibson'ın [1] önerdikleri bölümleme metodunun bir benzeri kullanılmıştır ve problemi parçalara ayırarak çözme tekniği eklenmiştir. Bu yöntemde etki-bölgelerine ayrılacak düzlem parçası ardışık olarak dörde bölünür, istenen küçüklüğe ulaşan alt düzlem parçası etki-bölgelerine ayrılır ve sonunda bitişik düzlem parçalan birleştirilerek nihai çözüm elde edilir. Algoritmanın performans ölçümleri ve alt parçalara ayırmadan yapılan tessellasyon ile karşılaştırması için değişik nokta kümeleri ile testler yapılmıştır. Bu testler sonunda önerilen algoritmanın böl-ve-çöz yöntemi ile performansının arttığı ve mertebesinin O(NlogN) olduğu bulunmuştur. Ayrıca böl-ve-çöz yöntemini kullanan algoritmanın gerçeklenmesi dörtlü ağaç veri yapışırım katkısı ile daha verimli sonuçlar verdi. Algoritma üzerinde gelecekte yapılabilecek çalışmalar olarak çoklu işlem yapan ortamlarda gerçeklenmesi ve analizinin yapılması önerilmektedir.","IV ABSTRACT Triangulated Irregular Networks (TIN) are extensively used to represent surfaces in Geographic Information Systems. The surface is represented as a set of non-overlapping and irregularly shaped triangular facets. Delaunay triangulation satisfies such properties and is therefore considered well- suited as a basis for a surface model. Delaunay triangulation of a set of points is defined as the straight-planar dual of Thiessen tessellation which is a subdivision of the plane into polygons, each belonging to a point and defined as the planar region which is closer to the point than to any other point in the set. In this thesis-, we design and implement an algorithm which produces Thiessen tessellation of a planar region for a data set of points. The algorithm uses the idea of tessellation algorithm proposed by Green and Sibson [1] and introduces a divide-and-conquer technique. This technique divides the region into subregions, then tessellates the subregionsi and merges the resulting tessellation of the subregions. Several tests are performed on different data sets of points to see the performance of the algorithm and to compare the results of divide-and-conquer technique with the results of the method without decomposition. Comparison of the test results have shown that the proposed tessellation method by divide-and-conquer technique performed much better with order O(NlogN). A quadtree data structure is adopted to support devide-and-conquer technique. Implementation of the algorithm on a parallel proccessing environment is suggested as further studies."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"V) 1 1 ÖZET PALLEDYEN GRAMER TABANLI İKİ KATLI KONUT TASARIMI Bilgisayar destekli mimari tasarım bugün artık teknolojik ekonomik acıdan ulaşılabilir olmuştur. 1960' lı yılların basından başlayarak bu alandaki teori ve uygulamalar mimariyi kökten değiştirecek noktaya ulaşmış bulunmaktadır. Bu tezin konusu iki katlı konut tasarımında bir sistem uygulamasıdır. Kullanılmış olan method ice ""construc tion procedure"" alarak adlandırılan ve sıfırdan başlayarak kullanım alanlarının peşi sıra atanması sonucu tasarımı ortaya çıkaran bir metottur. Tarifi erimiş olan gramer ise Paladyen stili bir gramerdir. Bu gramer kullanılarak yapı matrisi belli bir sentez uyarınca yerleştirme işlemi gerçekleştiril erek yapı oluşturulur. Bu yaklaşımda heuristik programlama yöntemlerinden biri olan ""oluşturmasına"" yöntemi kullanılmaış bulunmaktadır. Kullanılmış olan yaklaşım DESIGNER olarak adlandırılan bir uygulamayla tamamlanmıştır. Sistem değişik sınır şartlarında test edilmiştir. Beş'e üç matris ürerine kurulmuş olmasına rağmen, matris büyüklüğünün sistem performansı üzerindeki etkisini tespit edebilmek amacıyla, farklı matris boyutlarıyla da çeşitli testler yapılmıştır.","VI 1 ABSTRACT TWO STOREY DWELLING UNIT DESIGN BASED ON PALLADIAN GRAMMAR Computer aided architectural design is now becoming a technologically and economically -feasible reality. From simple beginnings in the early 1960's, the theory and prac tice of this field have developed to the point where it will radically transform the practice of architecture. The scope of this thesis is an application in ""Two Storey Dwelling Unit Design"". The method used is construction procedure which build up the layout from a null solution, by making a successive assignment of activity areas defined as a kind of Palladian style shape grammar in the site matrix according to a certain synthesis order. In this approach generate-and-test procedure in heuristic programming are in use. The approach is implemented in terms of a system called DESIGNER. The system is tested many times by specify ing different constraints. Although the system is based on a five by three site matrix, the system is also tested with different matrix sizes in order to determine the effect of the matrix sise on the performance."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,V ÖZET Bu tezde yeni bir heuristic program yerleştirici algoritma tanı- tılmıştır. önce literatürde bulunan çeşitli algoritmalar incelen- r mistir. Sonra ^en önemli yerleştirme hedefleri toplanmış ve bu he deflere ulaşmak için kullanılan kurallar belirlenmiştir. Sonuç olarak bu hedeflerin optimizasyonu için öncelik ağırlıklı bir algoritmaya dayanan bir algoritma geliştirilmiştir. Bu algoritma tarafından gerçekleştirilen yerleştirme bir çok yerleştirme hedefini öncelik sırasına göre yerine getirmektedir.Bu yerleştirme hedeflerinin program yerleştirmeyi ve sistem performansını nasıl etkilediğini görmek için simülasyon yapılmıştır. Bunun sonucunda program özelliklerine bağlı olarak yerleştirme hedeflerinin en uygun önceliklerinin ne olması gerektiği konusunda bazı yorumlarda bulunulmuştur. Bu yorumlar özellikle ilerde bir uzman program yerleştiricisinin kurulmasında faydalı olacaktır.,"IV ABSTRACT In this thesis a new heuristic task allocation algorithm has been introduced. First various algorithms in the literature has been examined. Then the most important allocation goals..has been collected and the heuristics used for each goal has been determined. Finally an algorithm based on a Weighted-Priority Algorithm ' has been developed for the optimization of the allocation goals. The allocation performed by this algorithm satisfies multiple allocation goals according to their priority order. Some simulations has been performed in order to see the effect of these allocation goals on task allocation and system performance. As a result of this some valuable comments about what the most appropriate priorities of the allocation goals depending on the characteristics of tasks should be, has been given. These comments will be useful especially for future activities involving the construction of an expert task allocator."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışma, nükleer reaktörlerin sayısal bilgisayar denetimi sorununa bir yaklaşım olarak nöron ağları uygulamasını inceler. Nöron ağları yaklaşımını kullanmaktaki gerekçe, nükleer reaktör sistemi için detaylı bir matematiksel model gereksinimini ortadan kaldırmaktır. Bu çalışmada, doğrusal olmayan nükleer reaktör sisteminin güç çıktısını denetlemeyi nöron ağının nasıl öğrendiği gösterilmektedir. Doğrusal olmayan nükleer reaktör modelinin dinamik özelliklerini tanımlayan diferansiyel denklem kümesinden, denetleyici nöron ağının eğitimi ve hata oranının ölçümü için gerekli girdi verilerinin elde edilmesinde yararlanılır. Bu bağlamda, elde edilen girdi verileri, nöron ağları uygulamaları için geliştirilen kullanıcı arabirimiyle denetleyici nöron ağının eğitiminde kullanılır. Sayısal benzeşim kullanılarak, nöron ağı yapısının denetim dizgesi üzerindeki etkisi gözlenmiştir. Bu gözlem, saklı katman sayısını, saklı katmandaki nöron sayısını değiştirerek yapılmıştır. Nöron ağının eğitiminde, farklı eğitim kümeleri ile farklı sayıda örnek veriler kullanılmıştır. Ağır yük izleme konumunda, onaylanır denetim dizgesinin elde edilebilir olduğu, ve denetleyicinin daha gerçekçi durumlarda gerekli yeterliliği olduğu görülmüştür. Gürültü olduğu durumlarda da, denetleyicinin yavaş yavaş yeterliliğini yitirdiği gözlenmiştir.","IV ABSTRACT In this study, the application of neural networks to digital computer control of nuclear reactors was investigated. The purpose of using the neural network approach is to alleviate the requirement for a detailed mathematical model of the nuclear reactor system. In this work, it is shown how a neural network can learn to control the power of the nuclear reactor system, which is a nonlinear dynamic system. The set of differential equations, which represent the dynamic characteristics of the nonlinear nuclear reactor model are utilized to obtain a set of input tuples to train and test the controller, which is actually a neural network assumed to be controlling the power output of the given nuclear reactor. In this respect, the obtained input tuples are used to train the neural network in the user interface developed for the purpose of neural network applications. Using numerical simulation, the effect of the architecture of the neural network on the final control is investigated. This was accomplished by varying the number of hidden layers and the number of nodes in the hidden layers. Several training sets with different number of tuples were used for training. It was seen that an acceptable control in a tight load following mode was attainable, and that the controller has a satisfactory performance in more realistic situations. It was also observed that in the presence of noise the controller degrades gracefully."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV OZST Yapay zeka teknikleri endüstriyel kontrol sistemlerinin onarımında gün geçtikçe daha fazla önem kazanmaktadır. Kontrol sistemlerinin artan karmaşıklıkları ve verimli onarım yapabilecek eleman bulabilmenin zorluğu, araştırmacıları uzman sistemleri bu alanda kullanmaya zorlamıştır. Bu tez, geri beslemesi olmayan kontrol sistemlerinin onarım servisinde kullanılabilecek bir akıllı rehber tasarlama amacı ile hazırlanmıştır. Ana fikir, sistemin bağlantı bilgisini ve kontrol elemanlarının hata olasılıklarını kullanarak, teknisyene rehberlik etmek ve sonuçta sistem elemanlarının çalışma prensiplerini tanımlayan kuralları kullanarak hatalı kısmı tespit etmektir. Hata takip yöntemi olarak olasılık ve nedensel yaklaşım ların bir karışımı kullanılmış ve bu yaklaşımları tercih ne denleri açıklanmıştır.","11.1 ABSTRACT In recent years, AI techniques have gained great importance in the field of diagnosing industrial control systems. The increasing complexity of the control systems and the difficulty of finding expert technicians to do effective troubleshooting had forced the researchers to use expert systems in this area. This thesis is prepared to design an intelligent guide that is capable of troubleshooting control systems without feedback loops. The main idea is to use the connectivity knowledge of the system and fault probabilities of the components to guide the technician in troubleshooting and finally to use the causal rules that describe the behaviours of the components to detect the faulty part. A mixture of probabilistic and causal approaches is used in diagnosis procedure and it is also explained why they are chosen instead of other approaches."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Ö21T Dağıtımlı (distributed) sistemlerin yaygın kullanımını önleyen ciddi sorunlardan birisi doyum etkisi nedeniyle iş çıkarma kapasitesindeki azalmadır. Görev dağıtımı, dağılımlı sistemlerde performansı arttırma konusundaki seçeneklerden birisidir, Bu tezde, gerçek zamanlı sistemlerde görev yanıt suresinin optimizasyonu amacıyla tasarlanmış bir statik, optimal dağıtım algoritması sunulmaktadır. Görev modülleri arasındaki haberleşme hacimlerinin kestirimi için bir model geliştirilerek, dağıtımın etkinliğini değerlendirmek amacıyla bir maliyet fonksiyonu önerilmektedir. Önerilen fonksiyon, görevlerin birden fazla defa çağırılmalarından doğan işlemci kuyruk gecikmelerini hesaba katmakta ve alıcı modüldeki haberleşme maliyetini olduğundan yüksek alarak, modüller arasındaki öncelik ilişkilerinin ortaya çıkardığı etkiyi kapatmaya çalışmaktadır. İki optimizasyon ölçütü önerilmiştir. Birincil olanı, yani minimaks ölçütü, en yüklü işlemcinin yanıt süresini en aza indirme üzerine kurulmuştur. Minimaks ölçütünün birden fazla çözüm verdiği durumlarda sistemin toplam yükünü en aza indirmeye dayanan ikincil ölçüt devreye sokulur. Daha sonra da, önerilen maliyet fonksiyonu ve optimizasyon ölçü tüyle, görev dağıtım problemi, Shen ve Tsai' nin [1] yaklaşımlarına dayanan durum-uzay arama problemi olarak yeniden formole edilir. Modüllerin işlemcilere verilmesi işlemi de, aramanın hızlandırılması için uygun buluşsal (heuristic) bilgilerin önerilmesinden sonra, yapay zeka uygulamalarında kullanılan A* algoritması kullanılarak çözülecek olan zayıf- homomorphic grafik eşleme problemine dönüştürülür. Modül verme işleminin sırasının üretilen grafik elemanlarının sayısı üzerindeki etkisi de formel olarak incelenmiş ve arama etkinliğini artıran, yaklaşık olarak optimal bir modül verme sırasını belirleme stratejisi geliştirilmiştir. Modüllerin çalışır hale gelmeleri için geçmesi gereken sürenin ozyenilemeyle (recursion) belirlendiği, öncelik ilişkilerinden doğan etkilerin açık olarak hesaba katıldığı ikinci bir maliyet fonksiyonu önerilmiş ve bu da benzeri bir yaklaşımla çözülmüştür.","IV ABSTRACT Â serious problem that prevents widespread use of distributed systems is the degradation in throughput caused by the saturation effect. Task allocation is one of the alternatives for improving performance in distributed systems. * This thesis presents a static, optimal allocation algorithm designed for task response time optimization in real-time systems. A model for estimating the communication volumes among task modules is developed, and a cost function is proposed for evaluating the effectiveness of the allocation. The proposed cost function considers processor queueing delays resulting from multiple invocations of tasks, and tends to compensate for the effects of precedence relations among modules by overestimating the ^communication costs at the receiver module. Two optimization criteria are also proposed. Tha primary one, called the minimax criterion, is based on minimizing the turnaround time of the bottleneck processor. In cases where the minimax criterion yields multiple solutions, a second criterion based on minimizing the total load on the system is employed. With the proposed cost function and optimization criteria, the task allocation problem is then formulated as a state-space search problem based on the approach proposed by Shen and Tsai [1], Module assignment to processors is transformed into a weakiy-homomorphic graph matching problem, which is then solved by the A* Algorithm used in artificial intelligence applications after proper heuristic information for speeding up the search is suggested. The effect of module allocation order on the number of generated nodes is also formally investigated, and a near-optimal strategy is developed for determining an allocation order which improves search efficiency. A second cost function which explicitly considers the effect of precedence relations by recursively computing release times of modules is also proposed, and solved using a similar approach."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Gerek nesneye-dayalı yaklaşım, gerekse mantıksal yaklaşım bir çok güçlü özelliklere sahip olmaları nedeniyle veri modeli tasarımında tercih edilen yaklaşımlardır. Her ne kadar, bu iki yaklaşımın tezat oluşturan bazı özellikleri olduğu biliniyorsa da, her ikisinin uyumlu özellikleri seçilerek bir veri modeli oluşturmak olasıdır. Hem nesneye-dayalı yaklaşım, hem de mantıksal yaklaşım özelliklerine sahip bir modelin güçlü bir model olacağına inanılmaktadır. Çünkü, böyle bir modelle verinin semantiği de gösterilebilecek ve genel bilginin gösterimi ve sorgulanması mümkün olabilecektir. Bu tezde geliştirilen LOGOB isimli veri modeli, bazı nesneye- dayalı yaklaşım özelliklerine sahip mantıksal bir veri modelidir. 'Nesne tipleri' sistemde saklanan nesneleri, özellikleri ve diğer nesnelerle olan ilişkileriyle tanımlar. Nesneler arası hiyerarşi de 'nesne tipi' ile tanımlanır. LOGOB'da genel bilgi, 'kurallar' ile gösterilir. 'Kurallar' mantıksal deyimlerdir ve LOGOB'da 'kural' tanımında karmaşık nesne tipleri kullanılabilinir. Bu tezde, veri modelinin yanı sıra, modelde mevcut olan karmaşık yapıların geliştirilmesiyle ilgili bazı öneriler de verilmiştir. LOGOB veri tabam yönetim sisteminin sorgu değerlendirme unsuru, bir 'kural'da geçen karmaşık yapıların ele alınışını göstermek amacıyla, geliştirilmiştir.","IV ABSTRACT Object-oriented approach and logic approach each has many powerful features that make them attractive in the design of data models. Although it has been argued that these two approaches are conflicting because of some of their features, it is possible to design a data model including compatible features of both. It is believed that, a data model having both object oriented and logic based features will be powerful, especially because semantics of data can be represented and representation and querying of general knowledge are possible. The data model developed in this thesis, LOGOB, is a logic based data model with some object oriented features. Object types define the objects stored in the system in terms of the properties of the objects and their relationships to other objects. Hierarchy of objects is another thing defined by object types through isa-relationships. General knowledge is represented by rules in LOGOB. Rules of LOGOB are logical expressions which allow the use of complex objects types in the representation of general knowledge. In the thesis, besides the data model, some implementation suggestions especially about the complex structures present in the data model are proposed. The query evaluation component of the DBMS of LOGOB is implemented with the aim of showing the handling of complex structures referred in a rule."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu tez çalışmasında, 'robot kolları' ve 'uyarlamalı denetim' konuları beraber ele alınmıştır. Robot dizgeleri üzerine gerekli bilgiler verildikten sonra, öz-ayarlayıcı tip uyarlamalı denetimin robot kollarının yol izleme sorununa nasıl uygulanacağı açıklanmıştır. Uygulanan deneticiler Genelleştirilmiş Enküçük Varyans, Genelleştirilmiş ÖngöTülü (GÖD), Kutup- yerleştirme ve Düşürülümüş Varyans (DV) Kutup-yerleştirme denetimlerdir. İstenen açısal hızları küçülten ters kinematik algoritmaları, öz- ayarlayıcı ile daha basitleştirilmiş kompanzasyon kullanılmasını sağlar. Böylece, yalnız pozisyon geri beslemesi ile deneticiler gerçekleştirilebilir. Bu deneticilerin verimlilikleri, üç-kollu bir robot kolunun simülasyonuna uygulanmaları ile sınanmıştır. Denetici gerçekleştirirken robot kolu için doğrulaştırılmış ya da tedirgi modeli kabul edilir. Her iki model de yeterli sonuçlar vermiştir. Bu tez çalışmasında GÖD'In çift-kapılı olarak ve DV kutup-yerleştirme algoritmasının izleme için formülasyonu gerçekleştirilmiştir. DV Kutup- yerleştirme algoritmasının diğerlerine göre tasarım kolaylığı ve hata iyiliği açılarından üstün olduğu görülmüştür.","ABSTRACT In this thesis, two topics 'robotic manipulators' and 'adaptive control"" have been dealt. After giving necessary knowledge on robotic systems how self-tuning type adaptive controllers can be used for the trajectory control of robotic manipulators is explained. The controllers applied are namely Generalised Minimum Variance, Generalised Predlctive(GPC), Pole-placement and Reduced Variance (RV) Pole-placement. Use of inverse kinematics algorithms that minimizes the desired angular velocities permits a simpler compensator to use along with the self- tuner. So, it has been possible to design controllers with only positional feedback. The performance of these controllers are compared by application to a three-link manipulator through simulations. A linearized or perturbation model for the manipulator is assumed to design a controller. Both methods have given satisfactory results. The interpertation of GPC as two-port controller with a different formulation and application of RV pole-placement algorithm to tracking have been accomplished in this thesis. The Reduced Variance Pole-placement algorithm has been superior to other in two fold; easiness in the design and output error performance. iv"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"DO?RUSAL VE DENETLENEBİLİR SİSTEMLERİNİN DURUM VE GİRİŞ UZAYLARIN EŞBİÇİMSEL DÖNÜŞÜMLER GRUBUNA GÖRE KANONÎK GÖSTERİMLERİ KISA ÖZET Bu çalışmada denetlenebilir doğrusal sistemlerin durum ve giriş uzayların eşbiçimsel dönüşümler grubu altındaki kanonik gösterimleri aranmaktadır. Bu dönüşüm grubunun sistemin gösterimi üstündeki etkisini elde ettikten sonra iki girişli sistemlerin kanonik gösterimleri inşa edilmektedir. Bu tür kanonik gösterimler, yalnızca durum uzayının eşbiçimsel dönüşümlerine göre kanonik olan gösterimler ile karşılaştırıldığında, inşa edilen gösterimlerinin daha az sayıda parametre tarafından belirlendiği, bunların bir kısmının ise Boolean olduğu ortaya çıkmaktadır. Bu çalışmada genel m-girişli sistemlerin kanonik gösterimlerinin inşa edilmemesine karşın, durum ve giriş uzaylarının eşbiçimsel dönüşümler grubunun bu gösterimler üstündeki etkilerini veren bağıntılar kısmen türetilmektedir. Bunun bir sonucu olarak m-girişli sistemlerin kanonik gösterimlerinin kaç parametre tarafından belirlendğini bulmak mümkün olmaktadır.","IV CANONICAL REPRESENTATIONS OF CONTROLLABLE LTI SYSTEMS UNDER THE STATE AND INPUT SPACE ISOMORPHISMS GROUP ABSTRACT We investigate the canonical representation of controllable linear, time-invariant (LTI) systems under the state and input space isomorphisms group and devise a framework out of which the action of this group on a system representation can be obtained. We explicitly construct canonical representations for the class of two-input systems. Compared to the canonical representations under state space isomorphisms alone, these new representations contain a fewer number of parameters some of which moreover are of Boolean type. Though we do not construct the canonical representations of the general m-input system, the relations showing the action of the state and input space isomorphisms group are derived in part. These relations can be used in particular for finding the number of parameters that the subsequent canonical representations will contain."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"vıı ÖZET Bu tezde, genelleştirilmiş doğrusal zamanda değişmeyen sistemlerin üzerine tanımlı ulaşılabilirlik, denetlenebilirlik ve gözlemlenebilirlik kavramları çalışılmıştır. Olağan teori üzerine gerekli tanımlar ve diğer eklemeler sunulmuştur. Denetlenebilirlik sekiz değişik şekilde ve gözlemlenebilirlik üç değişik şekilde tanımlanmıştır. Bu tanımların herbiri ayrı ayrı isimlendirilmiş ve geometrik nitelendirilmeleri verilmiştir. Durum uzayının herhangi bir başlangıç noktasından herhangi bir başka noktaya polinomsal güzergah izleyerek ulaşmak için gerekli girdi ve izlenen güzergah ilk defa bu tezde sunulmuştur. Gözlemlenebilirlik için verilen cebirsel nitelendirmeler ilk defa sunulmuştur.","VI ABSTRACT Controllability and observability problems of the usual linear time invariant systems are investigated for generalized linear time- invariant systems with necessary extensions in the theory. The concept of reachability is studied, controllability and observability concepts are modified defining eight different criteria for controllability and three different criteria for observability. Geometric characterizations of the reachability and the controllability criteria are given and alternative characterizations for the observability criteria are presented. Polynomial trajectories from an arbitrary initial condition to an arbitrary final state are investigated with the corresponding inputs. This is the first time that these kind of trajectories are found."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu tez çalışmasında, sürekli-zaman dizgelerinin ayrık-zaman dizgeleri olarak modellenmeleri yöntemi ile denetimlerinin sağlanması amacı ile Genelleştirilmiş Öngörülü Denetim algoritmasının uygulanması gerçekleş tirilmiştir. Denetimleri sağlanacak olan sistemlerin yapısı hakkında fazla bir ön bilgi bulunmadığı ve/ya da sistem yapısının, ölü-zaman, kerte ve katsayı bakımından değişken olabileceği durumlarda da kararlı bir algoritma olabileceği görülmüştür. Ayrıca bazı denetleyicilerin kararsız bir çıkış verdiği açık-çevrim kararsız ve enaz-olmayan-faz yapısındaki dizgelerin de benzetimleri gerçekleştirilmiştir ve Genelleştirilmiş Öngörülü Denetimin kararlılığı sulanmıştır. Orijinal algoritma üzerine uyarlanabilecek iki değişik süzgeç tasarlanmış ve bunların yaralılıkları ile eniyi süzgeç tipleri araştırılmıştır. Ayrıca, Genelleştirilmiş Öngörülü Denetim algoritmasının diğer ""Öz- ayarlayıcı"" algoritmalardan Enaz-Değişinti (Minimum-variance) ve Kutup- yerleştirme (Pole-Placement) ile olan farklılıkları ve üstünlükleri tartışılmıştır. Benzetimlerin gerçekleştirildiği bilgisayar programı Pascal dilinde yazılmış ve üçüncü kerteye kadar bütün dizgelerin yörünge izleme yeteneklerini sınayabilecek bir genel yapıda hazırlanmıştır. Kestirim ufuğu en fazla dokuz, denetim ufuğu ise en fazla yedi adıma kadar olabilmektedir. Denetimi sağlanacak olan dizge benzetimleri ayrık zamanda tanımlanabileceği gibi sürekli zamanda da tanımlanabilir. Sürekli zamanda dizge benzetimi amacı ile sayısal integral yöntemlerinden ""Dördüncü dereceden Runge-Kutta"" ve ""Euler Tümleme"" kullanılmış ve bilgisayar programı içerisine dahil edilmiştir.","ABSTRACT In this thesis work, the Generalized Predictive Control algorithm is utilized for the control of continuous-time plants modelled as discrete- time systems. The performance of the controller is examined from the stability and from the trajectory following ability points of view when there is no a priori knowledge about the system under control and/or when the dead-time, system order, parameters of the system are variable. Besides, open-loop unstable and nonminimum-phase plants, for which many of the previous algorithms fail to give stable control, are also simulated for the GPC algorithm. The original GPC algorithm is upgraded by application of two different filters and the advantages of the filters and the choice of the filter coefficients are examined. Advantages of the GPC algorithm over the two most popular adaptive sell-tuner algorithms, Minimum-variance and Pole-placement, are discussed and differences in their structures are explained. Simulation of the plants and the control algorithm are accomplished by a computer program written in Pascal language. The program can simulate systems up to the third order and can check the trajectory tracking ability of the plant under control. Maximum prediction horizon is nine and the control horizon can be extended up lo seven steps. Systems to be simulated can be defined in the continuous-time as well as in the discrete-time. For the continuous-time system simulation, two of the most popular numerical integration techniques; Runge-Kutta forth order and Euler integration, are utilized and included in the computer program. IV"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Dinamik bir ortamda büyük ve karmaşık yazdım dizgelerine duyulan gereksinim, ilgiyi yazılım tasarımı ve geliştirmede yeni yaklaşımlara yöneltmiştir. Klasik yaşam sürecini kullanan geleneksel yazılım geliştirme problemlerinde iterasyona yer verilmez, yeniden kullanım üzerinde durulmaz, ve evreleri birleştirici bir model yoktur. Nesneye-dayalı yaklaşımlar tüm bu çıkarımlara hitap eder. Nesneye-dayalı yaşam sürecine bakıldığında çözümleme, tasarım ve uygulamadan oluşan üç geleneksel aktivite görülür. Çözümleme yazılım geliştirmenin en önemli evrelerinden biridir. Gelişim sürecinin başlangıç evrelerinde gözden kaçan hatalar sonraki evrelerde genel karışıldığa neden olabilir. Bu çalışmada nesneye-dayalı çözümleme için yeni bir metod geliştirilmiştir. Metod, nesneye-dayalı yazılım yaşam sürecinde çözümlemeden tasarım evresine daha kolay ve yumuşak geçişi amaçlamaktadır. Metodun en önemli özelliklerinin kolay okunulabiliriik ve anlaşılabilirlik olması hedeflenmiştir.","IV ABSTRACT The need to develop and maintain large complex software systems in a competitive and dynamic environment has driven interest in new approaches to software design and development Problems with traditional development using the classical life cycle include no iteration, no emphasis on reuse, and no unifying model to integrate the phases. The object- oriented paradigm addresses each of these issues. A look at the object-oriented life cycle identifies the three traditional activities of analysis, design and implementation. Analysis is one of the most critical tasks in software development Unrecognized errors made early in the development process may cause widespread confusion in the later phases. In this study, a new methodology for object-oriented analysis is developed. The methodology is intended to provide an easier, smoother transition from analysis to design phase in the object-oriented software life cycle. Human readability and understandability are expected to be the most important features of the methodology."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu çalışmanın amacı, PID ayar metodları ve bulanık denetim algoritmalarının bilgisayar denetimli bir DC motor düzeneyi ile deneysel karşılaştırılması dır. Motor şaft hızı ve konumu değişik PID algoritmaları ve bulanık denetleyici kullanarak kontrol edilmiştir. İncelenen denetim yöntemleri şunlardır: PID hız ve konum algoritmaları ile lineer ve lineer olmayan bulanıklaştırma ve bulanıklıktan kurtar ma yöntemlerini kullanan bulanık denetleyici. Yanısıra bir deneysel bulanık denetim ayar metodu da uygulanmıştır. Teorik çalışmada, DC motor hız ve konum denetim matematik modeli geliştirilmiş ve lineer olmayan bir süreç modeli kullanılmıştır. Bu modeller kullanılarak PID ve bulanık denetim algoritmalarıyla benzeşim programları çalıştırılmış ve iki denetim metodu teorik olarak karşılaştırılmış tır. Deneysel çalışmada, bir bilgisayar denetimli DC motor sistemi kurul muş. PID ve bulanık denetim algoritmalarını kullanarak sistemi denetleyecek bir program geliştirilmiştir. Denetim algoritma ve paremetre değişimlerinin sistem performansına etkileri incelenmiş ve iki method deneysel olarak da karşılaş tırılmış tır. Simulasyon ve deneysel çalışmalar, kullanılan bulanık denetleyicinin klasik PID denetleyicileri kadar iyi olduğunu ve deneysel PID ayar metodunun bulanık denetleyicileri ayarlamak için de kullanılabileceğini göstermiştir.","IV ABSTRACT The object of this study is to make an experimental comparison of fuzzy control algorithms and PID tuning methods on a computer controlled DC motor set - up. The speed and position of the dc motor shaft has been controlled using various forms of PID algorithm and a fuzzy controller. The control methods which are investigated can be stated as follows: the velocity and position forms of PID algorithm, fuzzy controller with linear, nonlinear fuzzification and defuzzification. Moreover, an experimental tuning method of fuzzy controller is also implemented. In the theoretical study, the mathematical model of the speed and position control of the DC servo system was developed and a nonlinear process model was used. Then, by using these models the simulation programs with PID and fuzzy control algorithms was implemented and the two control methods were compared theoretically. For the experimental investigation, a microcomputer controlled DC motor system has been installed. A computer program was developed to control this system using PID and fuzzy control algorithms. The effects of the control al gorithm and parameter changes on the control performance of the system were investigated and the two methods were also compared experimentally. The simulation and experimental results have showed that the con structed fuzzy controller is as good as classical PID controllers and the ex perimental PID tuning method can be used for fuzzy controllers."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu tezde, veri tabanlarıyla Türkçe iletişim kurmayı hedefleyen, taşınabilir bir doğal dil arabirim sistemi geliştirilmiştir. Sistem, bir Türkçe sorgulama ifadesini önce ara birim anlam temsili dili olan D&Q'ya, daha sonra da hedef veri tabanı dili SQL`e çevirerek iki aşamalı bir dönüştürme işlemi gerçekleştirmektedir. Sistem, dil işleme, iç sorgulama ve SQL'e çeviri gibi birbirinden farklı üç aşamanın herbiri için kullanım alanından bağımsız modüllerden oluşmuştur. Modüller, içinde kullanım alanı ve veri tabanı hakkında çeşitli bilgilerin saklandığı bilgi tabanına başvururlar. Sistemin parçası olan diğer iki ek modül de imla düzelticisi ve tarih kaydedicisidir. Sorgulamaların analizinde sentaktik bir ayrıştırıcı kullanılmaktadır. Sentaktik ayırıcı için, sözcükler arasında anlam niteleme nosyonuyla bütünleştirilmiş basit genel kategorizasyon ilkesi üzerine kurulan bir Türkçe gramer altkümesi formalizasyonu önerilmekte ve cümlelerin formel temsilleri için kullanılan yeniden yazma kuralları kümesinden oluşan bir gramer tartışılmaktadır. İsimlerin morfolojik ayrıştırılmasmda sonekleri atarak çalışan bir karar ağacı yaklaşımı kullanılmaktadır. Formelleştirilmiş gramerden yararlanarak farklı tipde cümleler için üretilen ayrıştırma ağaçları verilmektedir. Anlam temsili bakımından da, kurala dayalı akıl yürütme yeteneğine sahip akıllı' bir anlam temsili üreticisi tasarlanmıştır. Bazı anlam aiteleme ilişkilerinin yorumlanmaları da ayrıntılı biçimde tartışılmaktadır. Son olarak da tam bir cümlenin yorumlanışı gösterilmektedir. Sistem, hayali bir öğrenci-ders-hoca veri tabanı üzerinde denenmiştir ve tezdeki tüm örnekler bu veri tabanına dayanmaktadır. Tezin sonunda da ayrıştırıcı -ve anlam temsili üreticisi için olası geliştirmeler üzerinde durulmaktadır.","In this thesis, a portable natural language interface system for communicating with databases in Turkish is developed. The system does a two step transformation from a Turkish query in user's view to an intermediate meaning representation language D&Q and finally to a target database language SQL. It is composed of domain independent run time modules for different processing stages, namely language processing, internal query generation and translation to SQL. Modules refer to the knowledge base in which diverse knowledge about the domain and the database are maintained. Two additional modules, to wit a spelling corrector and a history keeper are incorporated in the system. A syntactic parser is used in analyzing queries. For the syntactic parser, a formalization of a subset of Turkish grammar based on the simple principle of general categorization incorporated with the notion of modifications between words is proposed and a grammar that consists of a collection of rewrite rules for the formal representation of sentences is discussed. A decision tree which works with suffix strip off approach is used for the morphological parsing of nouns. Parse trees produced for different types of sentences using the formalized grammar are given. Regarding to the meaning representation, an ""intelligent"" meaning representation generator which has a rule based reasoning capability is designed. The interpretations of some modification relations are discussed in details. Finally the interpretation of a full sentence is shown. The system is tested on an imaginary studettt-course-instructor database, all examples refers to this database. Possible extensions for both the parser and the meaning representation generator are also proposed at the end of the thesis."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bilgisayarlar günümüzde dünyanın birçok dilinde yazım yanlışlarını bulmakta kullanılmaktadır. Fakat, sözcükleri kök formlarına ekler ilave edilerek türetilen diller birçok ek güçlük ortaya koymaktadır. Bu diller bitiş imli diller olarak adlandırılırlar. Bitiş imli dillerin yazım yanlış larını bilgisayar yardımıyla bulmak için birçok yöntem öne sürülmüş tür. Tümüyle listeleme yöntemi bu amaçla kullanılan geleneksel bir metoddur. Her sözcüğün aynı zamanda ""bilinen"" bir sözcükler sözlüğünde olup olmadığım anlamak için bir arama yöntemi kullanır. Fakat, bitiş imli dillerin biçimbilimi öylesine karmaş ıktır ki, böyle bir sözlükte yer alması gereken sözcüklerin sayısı iş lenemeyecek kadar büyüyebilir. Bu listedeki sözcüklerin sayısını azaltmanın bir yolu, kök ve ekler için iki ayrı sözlük kullanan tarama yöntemlerinden birini kullanmaktır. Ek atma algoritması sözcükleri sağdan sola doğru tararken, kök eşleme algoritması bu iş lemi soldan sağa doğru yapar. Bu çalış mada, öncelikle tümünü listeleme yaklaş iminin bitiş imli bir dil için uygun olmadığına karar verildikten sonra, kök eş leme algoritmasının seçilmesini sağlayan psiko-linguistik ve hesapsal sebepler irdelenmektedir. Tümüyle sondan ekli bir dil olan Türkçe'nin biçimbilimsel kurallar yapısını taşıyan bir ağ kullanılarak kök eşleme algoritması baş arıyla uygulanabilir. Bu yöntemi kullanan bir biçimbilimsel analiz programı Türkçe için Hankamer (1) tarafından geliş tirilmiş tir. Bu analiz programı, bir yazım kontrol programı olarak yeniden yazılmış ve kök ve ek sözlüklerine verimli bir eriş imi sağlayacak yapılar geliş tirilmiş tir. Yapısal olarak basitliğine. rağmen, bu yöntemi kullanan bir tarayıcı tüm Türkçe biçimbilimini kapsamakta yeterli görünmektedir. v","ABSTRACT Computers are widely used to spell check texts of many languages of the world. However, languages whose words are formed by adding affixes to root stems present additional complexities. These languages are called agglutinative languages. There are different approaches proposed for spell checking texts of agglutinative languages. Full listing hypothesis is the traditional method for spell checking. It uses a dictionary-lookup method to see if each word in the text is also contained in a list of ""known"" words. But, agglutinative morphology is very productive that the number of words that should be contained in such a list may grow infinitely large. One way to decrease the number of entries in the list is to choose one of the parsing methods which employ two different lexicons, one for roots and the other for suffixes. While the suffix stripping algorithm tries to parse words from right to left, the root matching parser analyzes words from left to right. After showing that a full listing approach is not useful for an agglutinative language at all, the psycholinguistic and computational reasons to choose a root matching algorithm are discussed. The root matching parser may be successfully implemented with the use of a finite state transition network that represents the morphotactics of the Turkish, which is a strictly suffixing language. A morphological analyzer using this method has been developed by Hankamer (1) for Turkish. This analyzer has been implemented as a spell checker, and methods for an efficient access to root and suffix lexicons have been developed. Despite its conceptual simplicity the parser implemented this way appears adequate for all of Turkish morphology. IV"
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Kapalı alanlarda çalışacak bir gezici robotun tasarımı ve gerçeklenmesi anlatılmaktadır. Tecimsel bir gezici robot, işyeri ve yapımevi gibi yerlerde, yapı üzerinde herhangi bir sınırlama olmadan çalışabilecek şekilde gerekli donanım ve yazılım ile değiştirilmiştir. Bir alıcı, bir sesüstü uzaklık bulucu ve çarpışma algılayıcıları engellerden sakınma ve çevreyi kavrama amacıyla kullanılmaktadır. Çevre, aşamalı haritalar şeklinde modellenmiştir. Bir genel harita odaların ve aralarındaki kapıların konumlarını' bir ardışıklık ""graph"" yapısında tutar. Bir odanın iç yapısı, iki boyutlu bir ızgara veri yapısı ile içerideki cisimlerin ayrıtlarını oluşturan doğru denklemleri listesi şeklinde gösterilir, ki bunlar birlikte bir yöresel harita oluştururlar. Yakın çevrenin yapısı ayrı bir haritada tutulmaktadır. Değişik algılayıcılardan gelen yeni bilgiler algılayıcı haritalarında tutulur. Bir aşamalı program kümesi bu haritaları çarpışmasız yollar tasarlamak ve yürütmek için kullanmaktadır. Yönetici modül diğer modüllerin çalışmalarını, mesaj yollayıp veri paylaşmalarını sağlar. Aşamalı düzenlenmiş olan Ön Derleyici, Planlayıcı, Yol Bulucu, Kota Düzenleyici ve Motor modülleri yapılması istenen işi değişik düzeyde çözümlemeler ile planlar ve yürütür. Görme modülü çevreyi cisimlerin ayrıtlarını bulmak amacıyla inceler. Engel Önleyici, bir engelle karşılaşılması durumunda hedefe giden yolun yeniden planlanmasını sağlar. Harita Çizici ise algılayıcılardan gelen bilgilerin iç dünya gösterimine çevrilmesini sağlar, ilgili konularda geniş bir kaynak araştırması ve sınıflandırması yapılmış, programların benzetimli ve gerçek çalışma sonuçları verilmiş, gelecekteki araştırma alanları belirtilmiştir.","IV ABSTRACT The design and implementation of a mobile robot for indoor environments are described. A commercial educational mobile robot is modified with necessary hardware and software to operate in environments such as offices or factories with little or no restriction imposed on the building structure. A camera, an ultrasonic rangefinder and bump sensors are used for obstacle avoidance and environment perception. The environment is modeled as hierarchical maps. The global map keeps location of the rooms and the doors between them, in the form of an adjacency graph. The internal of a room is represented as a two dimensional grid structure and a list of line equations forming the edges of the object inside, which together form the local map. The cartographer map represents the structure of the immediate environment. Sensor maps keep recent information coming from different sensors. A set of hierarchically organized programs use these maps to plan and execute collision free paths. The Executive allows module invocation, message passing and data sharing between other modules. Pseudo-Compiler, Planner, Pathfinder, Navigator and Motor modules, arranged in a hierarchical manner, plan and execute the commanded task at different levels of resolution. The Vision module analyses the environment to find the edges of objects. The Obstacle- A voidance module aids replanning of the path in the case of obstacle detection, and the Cartographer module maps the sensory information coming from visual, ultrasonic and bump sensors into internal world representation. An extensive literature survey on related topics is made and former research are classified, results of simulations and actual runs of these modules are given, directions for further research are mentioned."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET BİR DATABASE İŞLETİM SİSTEMİNİN OTOYOL PROJESİNDE JEOTEKNIK VERİLERE UYGULANMASI Son senelerde mini kompüterlerde kaydedilen gelişmelerle eskiden yalnız kompüter merkezlerinde yapılabilen programlar bundan böyle PC lerde de uygulanabilir olmuştur. Bugün, database ' de hazırlanmış programların mühendislikte, bilhassa kullanılan verilerin çok olduğu büyük inşaat projelerinde, uygulanması kaçınılmaz olmaktadır. En son gelişmiş database sistemlerinden Paradox, R:Base,dBASE IV, bünyelerindeki ayıklama, indexleme ve aynı zamanda çeşitli dosyalara erişme ve aralarında veri alışverişi yapılabilmesi özellikleriyle büyük kolaylıklar sağlamaktadırlar. Örnek olarak, bir otoyol projesinin gerçekleşmesinde, jeoteknik analizlerin rolü büyüktür ve bu analizlerin çoğu güzergah üzerin den elde edilen çeşitli jeoteknik verilere dayanmaktadır. Jeoteknik uzmanın, görevi gereği yapacağı bu analizlerde ve alacağı kararlarında randımanlı olabilmesi ve talepleri gecikmeden karşılayabilmesi için elde edilen jeoteknik verileri organize bir şekilde derleyen gelişmiş bir dosyalama sistemine ihtiyacı vardır. Bu çalışmada Önce günümüzdeki en son database sistemlerinden biri olan dBASE IV ele alinmiş ve buna dayalı bir database ve computer programı geliştirilmiştir.Bu program yol güzergahından elde edilen sondaj ve araştırma çukurları verileri ile bu numunelerden elde edilen labratuvar ve saha deney sonuçlarının, güzergahın belirgin jeolojik özelliklerinin, durumunun ve güzergah boyunca mevcut otoyol yapılarının temel Özelliklerinin kompütere girilmesini, bu verilerin organize bir şekilde derlenmesini ve girilen bu verilerin istenilen kritiklere göre basılı yada ekrançıktısının alınmasını sağlar. Programın database'i 10 database dosyası ve 7 index dosyasından oluşur. Program menü sistemine gore işler ve toplam 46 program dosyasının birleşmesinden oluşmuştur.","ABSTRACT A DATABASE MANAGEMENT SYSTEM APPLICATION TO THE GEOTECHNICAL DATA OF A MOTORWAY PROJECT With the development of the micro-computers in the recent years, programs only available in the main frames became available for personnel computer users. Today, database programs have a special place in engineering ap plications especially in large construction projects where huge amount of data are processed. Systems like Paradox, RîBase or dBASE IV provides many facilities to store, organize and retrieve data with their developed filter conditions, indexing system and multiple file access capacity. As an example, during the construction of a motorway, geotechnical analysis play the most important role and most of these analysis are based on the geotechnical data obtained along the motorway. For the geotechnical engineer to be efficient and quick at his analysis and decisions, he needs a good filing system to store, organize and retrive these geotechnical data. In this study, as an example of a developed and recent database management system, dBASE IV has been studied and a computer program has been developed to store, organize, combine and retrieve geotechnical data obtained from the boreholes and trial pits with laboratory and insitu test results and the general information about the geology, road layout and structures along the motorway. The program is applicable to all of the motorway projects.lt is a menu driven program.lt is formed of 46 program files linked together, ten database files and seven index files. The program allows as screen view or as printout, the detailed reports containing informations about the geology, roadlayout, structures and their foundations, geotechnical data formed of the borehole and trial pit records with insitu and labratory test results for different range of chainages."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"iv ÖZET PC-DOS ortamında sonlu eleman programları için bir ön ve son işlemci geliştirilmiştir. İşlemciler, ticari paketleri kullanmak yerine kendi programlarını geliştirip kullanan analistler için bir araç grubu olarak tasarlanmıştır. İşlemcilerin gereksinimleri doğrultusunda bir veri yapısı geliştirilmiştir, ön işlemci doğrusal ve üçgensel sonlu eleman tanım kümelerinde adaptif ağ zenginleştirme ve uyumsuz ağlarla çalışabilme yeteneklerine sahiptir, ön işlemci, biri uzun kenarı ikiye bölme diğeri de dört benzer üçgen metoduna dayalı iki ağ zenginleştirme algoritması, bir uyumlulaştırma algoritması, bir etkileşimli ve grafiksel ağ zenginleştirme modülü ve bir cephe minimizasyon algoritmasından oluşmaktadır. Ağ zenginleştirme modülleri sonlu eleman tanım kümesini lokal veya global olarak zenginleştirebilmektedir. Sistemin tüm altyapısını oluşturan bir veri yapısı geliştirilmiş, Rivara'nın moleküler liste yapısı temel alınarak genişletilmiş moleküler liste yapısı tasarlanmış ve önerilmiştir. Sonlu eleman sonuçlarını grafiksel veya metinsel olarak verebilen bir son işlemci geliştirilmiştir. Self-adaptif analiz döngüsünün gerçekleştirilebilmesi için gerekli olan hata tahmin modülü yazılmamış, ancak sistemle olan arayüzü tanımlanmıştır.","Ill ABSTRACT The design and implementation of a finite element pre- and post-processor in PC-DOS environment are presented and discussed. Emphasis is given to the design and development of a data structure which will suit the demands of the processors. The processors are designed to constitute a toolbox for programmers who wish to use their own finite element programs instead of commercial software packages. The pre-processor is capable of adaptively refining meshes in linear, triangular finite element spaces and can handle non-conforming triangulations as well. The pre-processor toolbox consists of two different mesh refinement modules, a conforming module which may or may not be used depending on the utilized finite element module's capability of handling non-conforming meshes, an interactive graphical mesh refinement module and a frontwidth minimizer. One of the mesh refinement algorithms is based on the bisection on the longest side and the other is based on four-congruent triangles algorithm and they can be used both locally and globally over the finite element domain. A data structure which forms the basis of the entire system is designed and implemented. This data structure is the extended molecular list structure which is based on Rivara's molecular list structure. A post-processor is also devised which can graphically and textually display the outcoming results. A posteriori error estimator is not implemented but the interface of it is clearly defined, so that the full self-adaptive analysis cycle can be realized."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Katı gerçek zamanlı sistemlerin özelliği olan süre sınırlaması, bu sistemleri geleneksel bilgisayar sistemlerinden farklı kılmaktadır, çünkü bu tür sistemlerde talep edilen işler yalnızca görev bakımından doğru olarak değil, aynı zamanda vaktinde yerine getirilmelidirler. Bu tezde dağıtılmış sistemlerde katı gerçek zamanlı işlerin planlanması sorunu ayrıntılı olarak incelenmektedir. Katı gerçek zamanlı işlerin planlanması konusunda şimdiye dek önerilmiş algoritmalar gözden geçirilmektedir. Sadece MIB planlamasını değil, işlerin genel kaynak ihtiyaçlarını da dikkate alan bir buluşsal algoritma değerlendirilmek üzere seçilmiştir. Bu algoritma tarafından kullanılabilinecek bir grup buluşsal fonksiyon, bir seri benzetim çalışması ile incelenmektedir. En iyi performansı verdiği gözlenen buluşsal fonksiyon dağıtılmış planlama algoritmasında kullanılmaktadır. Bu algoritmada yerel olarak garanti edilemeyen iş için hedef düğümün seçiminde pey sürme ve direkt gönderme algoritmalarını birleştiren bir teknik esas alınmaktadır. Algoritmanın performansını gözlemlemek amacı ile çeşitli uygulama şartları için benzetim çalışmaları yapılmaktadır. Algoritmanın performansı başka üç değişik dağıtılmış planlama algoritmasının performansları ile de karşılaştırılmaktadır. Bu algoritmanın, uygulama alanının özelliklerine hassas olmasına rağmen, geniş bir uygulama alanı içinde, diğer algoritmalara kıyasla iyi bir performans gösterdiği gözlenmektedir.","The unique feature, the time constraint, of hard real-time systems makes them different from the traditional computer systems because in such systems the required tasks must be executed not only functionally correctly but in a timely manner. In this thesis, the scheduling problem of hard real-time tasks in distributed systems is examined in detail. Previous work on the algorithms proposed for scheduling in hard real-time systems is reviewed. A heuristic algorithm which considers not only CPU scheduling but also general resource requirements of tasks is chosen to be evaluated. A set of heuristics that can be used by this algorithm is studied through a sequence of simulations. The heuristic function which is observed to perform the best is incorporated in the distributed scheduling algorithm. In this algorithm the determination of a good destination node for a locally nonguaranteed task, is based on a technique that combines bidding and focused addressing algorithms. Simulation studies are conducted in order to evaluate the performance of the algorithm in a wide range of application environments. The performance of the algorithm is also compared to that of three other distributed scheduling algorithms. It is observed that though this algorithm is sensitive to the characteristics of the environments, it performs well in a wide range of environments, compared with the other algorithms."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Yazılımların kullanıma sunuş sürelerinin eniyileme ortamında belirlenmesi yazılım sanayini ilgilendiren konuların önde gelenlerinden biridir. Yazılımın güve nilirliğini yükseltmek amacıyla deneme süresinin uzatılması ile yazılımın toplam maliyetini düşürmek amacıyla yazılımın kullanıma sunuluşu arasında bir ö dünleşim (tradeoff) vardır. Yazılım firmalarının amacı sözkonusu ödünleşime yazılımın toplam maliyetinin beklenen değerini enazlayarak bir çözüm bulmaktır. Bu çalışmada yazılımların eniyi kullanıma sunuş sürelerinin belirlenmesi için toplam maliyetin beklenen değerinin enazlanmasma dayalı genel bir dinamik programlama yöntemi önerilmiştir. Ayrıca, deneme ve geçerlilik sınaması yöntemlerine genel bir bakış ile birlikte, varolan yazılım güvenilirlik modelleri ve kullanıma sunuş için eniyileme modelleri üzerine ayrıntılı bir literatür taraması da sunulmuştur.","IV ABSTRACT The determination of the optimal release time of software systems is one of the major concerns of the software industry. There is a tradeoff between testing the software system further to increase its reliability, and releasing it to decrease the total cost of the software. The aim of each software company is to settle this tradeoff by minimizing the expected total cost of the software. This study presents a general dynamic procedure for the determination of the optimal release time of software systems based on the expected total cost criterion. Moreover, a detailed literature survey on the existing software reliability mod els and optimal release time models is also presented together with an overview of the testing and validation techniques."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Günümüzde, gelişen LSI teknolojisi ve gittikçe azalan mikroişlemci fiyatları çok işlemcili sistemleri ekonomik açıdan cazip hale getirmişlerdir. Bu sistemler geniş veri tabanlarından PLClere kadar yayılmışlardır. Bu tezin amacı PLC benzeri bir modül tasarlayıp gerçeklemek ve bir grup modülü çok işlemcili ortamda çalıştırmaktır. Buna bağlı olarak programlamayı kolaylaştıracak bir de temel işletim sistemi yazılmıştır.",ABSTRACT The advent of LSI technology and the reduced cost of replicating processors in a system made multiple processor systems economically attractive. Multiprocessing applications range from large data base installations to PLC systems. The objective of this thesis is to design a PLC-like module and to combine a set of these modules in a multiprocessing environment. A compiler is also written with particular attention to ease the programming.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Veri modeli bir veri tabanında saklanan verinin türünü tarif eden plandır. Bu plan verinin nasıl yapılanabileceğini ve veriye nasıl ulaşılınabileceğini gösterir. Bir veri tabanı verinin kendisini ve verinin türünü veri modelinin olanakları ile tarif eden veri planını içerir. Bu tezde anlamsal (semantic) veri modelleri ve ilişkisel (relational) veri modelinin özelliklerini içeren bir varlık-ilişki (entity-relationship) veri modeli önerilmektedir. Model biricik isimli varlıklar kavramını, varlık türleri hiyerarşisini, ilişki özellikleri için tür ve biriciklik kısıtlamalarını, ve veri tabanlarının fiziksel dağıtımlılığını ve bağımsızlığını sağlayacak mantıksal bölümleme olanaklarını içermektedir. Kullanılmakta olan veri modelleri üzerinde yapılan inceleme hiç bir veri modelinin bir veri tabanı tasarımcısının tüm istek ve ihtiyaçlarını karşılayamadığını göstermektedir. Bazı modeller kolaylıkla veriden anlam çıkarabilmede fakat bunu yapar iken karmaşıklık ve performans problemleri yaratmaktadır. Bazı modellerin anlaşılması çok kolay olduğu halde bilgisayar donanımının kısıtlamalarını içermektedir. Burada önerilen model bir çok modelin zayıf ve güçlü olduğu yanların incelenmesi sonucunda önerilmiştir ve çeşitli yaklaşımları biraraya getirmektedir.vi Önerilen model çeşitli modellerde çeşitli şekillerde kullanılan ve kabul edilmiş özellikleri içermektedir. Model karakter katarı, integer, yüksek düzeyli veri türleri (örnek : nokta, çizgi, bölge), gibi veri değerleri ile gerçek veya soyut nesneleri temsil eden varlıkları, varlıklar ve/veya veri değerleri arasındaki ilişkileri temsil eden temel elemanlara sahiptir. Ayrıca, tür hiyerarşisi, ilişkisel anahtarlar, ve veri tabanın bağımsız dizilere bölümlenmesi için de olanaklar sağlanmaktadır.","İÜ ABSTRACT A data model is a scheme for describing the types of data that may be stored in a database: how these data may be structured, and how they may be accessed. Any particular database consists of the data themselves plus a data schema that describes the types of data in terms of the data description primitives of the data model. This dissertation proposes an entity-relationship data model that includes features of the Relational model and distillations of desirable features of more recent semantic models. The model includes the concept of entities with unique names, a hierarchy of types of entities, types and uniqueness constraints on relation attributes, and a logical segmenting mechanism that can be used to facilitate physical distribution and independence of databases. A survey of existing data models shows that there is no perfect data model that can fulfill all of the requirements of database designers. Some models can easily capture the semantics of the stored data at the cost of introducing complexity and performance problems. Some models are easy to understand but machine oriented. The data model proposed herein is the result of analyzing the strengths and weaknesses of a number of models and integrates a variety of viewpoints. It includes features that are accepted in someiv form in a number of models. The data model primitives include simple data values such as strings or integers, higher level data values such as points, lines or regions, entities representing real or abstract objects, and relationships among entities and/or data values. Mechanisms for a hierarchy of types, relational keys, and segmentation of databases into independent files are also provided."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Hizmet gecikmesi ve yolcuların ortalama bekleme zamanı tarifeli hizmet veren ulaştırma sistemlerini tasvir eden iki önemli ölçüdür. Bu sistemler genel likle yoku geliş, süreci, hizmet süreci ve hizmet mekanizmasının fiziksel ve yönetsel Özelliklerinin bir kombinasyonu olarak modellenirler. Literatürdeki çoğu modelin aksine, bu çalışmada bu iki sürecin arasında tarife mekanizması vasıtasıyla bir ilişki olduğunu varsayıyoruz. Fiziksel ve yönetsel özellikler göz önüne alınırsa modelimiz İstanbul da Sirkeci- Halkalı arasında çalıdan banliyö tren hattını temel almaktadır. Ulaşımın güvenliği sinyalizasyon sistemi ile sağlanmıştır. Bunun sonucu olarak trenler eğer kendi lerinden öncekiler henüz hedeflerine varmamışlarsa, istasyonda bekletilirler ve dolayısıyla tarifeler gecikmeli olarak yerine getirilir veya iptal edilir. Bu çalışmada (X, L) hizmet politikaları kullanılarak trenler ulaştırma otoritesi tarafından nor mal veya hızlı süratte gönderilmekte ya da çok gecikmeli tarifeler iptal edilmek tedir. Yolcuların izole edilmiş, tren istasyonuna önceden belirlenmiş tarifeye göre geldikleri varsayılarak belirlenmiş, bir (K^L) politikası için tarifelerin gecikme dağılımını ve yolcuların ortalama bekleme zamanını hesaplayan pratik bir yöntem geliştirilmiştir.","The service delay and the average waiting time of passengers demanding service are two important performance measures associated with a transp ortation system with scheduled services. These systems can usually be modeled as a combination of the passenger arrival pattern, the service pattern and physical and managerial aspects of the service mechanism. Unlike most of the models in the literature j in this study we assume a relationship between these two processes through a scheduling mechanism. As fax as the managerial and physical aspects of the service mechanism are concerned, our model is based on the Sirkeci- Halkalı suburban train transporta tion system in Istanbul, where the security of the transportation is attained by a traffic signal system. As a result, trains are blocked at the station whenever their predecessor have not arrived at the destination yet, and hence, schedules are delayed or even cancelled. We introduced the so-called (K,L) dispatching policy, according to which the transportation authority decides either to dispatch trains with normal or fast speed, or to cancel those schedules with long delays. Assuming that passengers arrive at the isolated train station according to a predetermined timetable, we compute the schedule delay distribution and theaverage waiting time of passengers in terms of the scheduled interdepartuxe pe riod, the normal and fast service time distributions, passenger arrival rate and the dispatching policy {KyL)."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Karmaşık bir mekanik sistemin arıza giderilmesi işlemi son derece zaman alıcı ve emek isteyen bir iştir. Uzman sistem teknolojisi uzun süreden beri teknisyen ve mühendislere arıza tesbiti ve bakım konularında yardımcı olmaktadır. Bu tezde parçaların bozuk olma olasılığına dayalı bir yaklaşımın arıza tesbiti uzman sistemlerinin geliştirilmesinde ne şeklide kullanılabileceği, ve bu yaklaşımın varolan arıza tesbit ve giderici uzman sistemlerinde kullanılan yaklaşımlara göre kazandırdıkları incelenecektir. Sonuçların gösterilmesi amacıyla Airbus A-310 yolcu uçağının arıza tesbitinde kullanılmak üzere bir uzman sistem geliştirilmiştir. Bu yapılırken eldeki arıza tesbiti el kitaplarından, ortalama ömür verileri ve her bir uçağın bakım bilgilerinden faydalan ılmıştır. Arıza tesbiti el kitabındaki temel arıza tesbiti ağacından hareketle, parçaların son değiştirilme tarihleri ve ortalama ömürleri kullanılarak, arıza tesbiti ağacında bulunulan yere bağlı olan parçaların bozuk olma ihtimalleri hesaplanmakta ve ağacın geri kalan kısmı akıllı bir yöntemle, kullanıcıya mümkün olduğunca az soru sorularak taranmaktadır,","iv ABSTRACT The troubleshooting process of a complex mechanical system is time consuming and laborious, Expert System technology has been used for a long time in this area to aid technicians and engineers in locating faults and maintaining systems. In this thesis it is shown how a failure probability based approach can be used to implement an expert system for troubleshooting mechanical systems, and the reason for choosing this approach over other solutions used in available diagnostic and troubleshooting expert systems is explained. A sample expert system for the troubleshooting of the Airbus A-310 commercial aircraft is developed to illustrate the results. For implementation purposes the available Troubleshooting Manuals, Mean Time Between Failure data, and the Maintenance Record of each aircraft are utilized. Starting off with the basic troubleshooting tree in the Troubleshooting Manual, Last Removal Date and Mean Time Between Failure data are used to calculate the failure probabilities of the parts connected to the relevant node of the troubleshooting tree, and by using these probabilities the rest of the tree is traversed in an intelligent manner to locate the faulty part requiring minimum user intervention."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tez çalışmasında elektronik, mekanik ve optik elemanlardan meydana gelen ve standart A4 ebadında dokümanların sayısal 1 aştın İmasında kullanılabilen düz yataklı (flat bed) bir tarayıcı yapılması amaçlanmıştır. Tarayıcı, enine ve boyuna her inçte 270 nokta tarayabilme, ve her nokta için iki, dört, onaltı veya altmışdört gri seviyesi kodlayabilme özelliklerine sahiptir. Sistemin elektronik donanımı kontrol kartı, görüntü algılama ve sayısallaştırma kartı, ve güç kaynağı ve adım motoru sürücü kartı olmak üzere üç baskılı devreye ayrılmıştır. Işığı elektriksel sinyallere dönüştüren sistem, üzerine düşürülen ince bir çizgi halindeki ışığı 2592 görüntü elemanlı bir sinyale dönüştüren CCD entegre devresi ile oluşturulmuştur. Bu entegre devrenin analog çıkışı hızlı bir analog/dijital dönüştürücü tarafından sayısallaştırılmakta, elde edilen sayısal bilgi ise bir hafıza entegresinde saklanmaktadır. Mekanik bir aksam görüntü algılayıcı kartı dokümanın bir ucundan öbür ucuna kadar taşıyarak CCD entegresinin düzenli aralıklarla görüntü örneklemesi yapmasına imkân sağlar. Bu şekilde, bir doküman için 6,415,200 örneğe varan miktarda bilginin bir araya gelmesiyle bir resim oluşturulur. Sayısallaştırılmış bilginin saklanması, kodlanması ve dışarı yollanması, görüntü algılayıcı kartın hareketini sağlayan adım motorunun kumandası, ve satır tarama işleminin başlatılması işleri kontrol kartında ve bir mikroişlemcinin denetiminde gerçekleştirilir. Bu mikroişlemci, bağlı olduğu haricî bilgisayardan gelen komutlara bağımlı olarak çalışır. Haricî bilgisayardan tarama parametrelerini ve taramaya başlama komutunu alır ve ona resim bilgisini gönderir.","IV ABSTRACT This thesis work has aimed at the building of a standard A4-sized document-digitizing flat-bed scanner incorporating electronic, mechanical and optical components. The scanner features a scan density of 270 dots per inch in both horizontal and vertical directions, each sample being digitized into two, four, sixteen or sixty-four gray levels. The electronics of the system is realized in three printed circuit boards, the controller card, the image sensor and digitizer card, and the power supply and stepper motor driver card. The light-transducing system is built with a- Charge Coupled Device (CCD) integrated circuit that converts the light intensity of 2592 pixels of a thin line that is projected on its photo-sensitive region. The analog output of the integrated circuit is converted into digital form with a flash analog/digital converter, and stored in memory. A mechanical assembly carries the image sensor card from one end of the document to the other, while the CCD takes snap-shot images of the document at regular intervals. In this way, a complete picture of as much as 6,415,200 samples is formed. The handling of digitized data, its coding and transmission, control of the stepper motor that moves the image sensing card, and initiation of line scans are all accomplished on the controller card, and are supervised by a microprocessor unit. This microprocessor is slaved to an external computer, which sets the scanning parameters, instructs the microprocessor to start scanning, and receives the output data."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"KISA ÖZET Bu tezde, benzetim dili ACSIM ile ilgili yeni bir yaklaşım - ACSIM 3 prototipi tanıtılmaktadır. ACSIM 3 görsel benzetim gerçekleştirmek amacıyla geliştirilmiş bir bilgisayar benzetim sistemidir. Bu sistemde, kullanıcı ile bilgisayar arasındaki ilişki grafiksel nesneler yardımıyla yürütülmektedir. Benzetim modelinin bilgisayara girilmesi ACSIM 3 tarafından yaratılan ve üzerlerinde benzetim için gerekli olacak her türlü bilgiyi taşıyan sorgu ekranları aracılığıyla gerçekleştirilir. ACSIM 3 benzetimin ekranda gerçek hayattaki akışa benzer bir şekilde yansıtılmasını ve istenildeği anda benzetime müdahale etme imkanım sağlamaktadır. Ayrıca, model ile bu modele ait verileri ayn dosyalarda saklayarak bunların daha sonra istenildiği gibi kullanılmasına ve değişik senaryoların denenmesine imkan verir.","IV ABSTRACT In this thesis, the Prototype of ACS I M 3, a new approach to the simulation language ACSIM, is introduced. The prototype of ACSIM 3 is a computer implementation of ACSIM on a computer with a graphics-oriented user interface. This program is developed to realize visual simulations. In the graphics-oriented user interface, the user and the computer communicate through graphical objects that appear in the screen. The screen displays a representation of the ""world"" the computer creates for the user. In this interface, the model input is realized through dialog boxes, which show the necessary information for the simulation. The progress of the simulation is reflected on the screen imitating the real world, and giving the opportunity to interfere with it. ACSIM 3 keeps the model framework separate from the experimental framework, and thus makes it possible to examine various scenarios more effectively."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"IV ÖZET Bu tez amaç-güdümlü karatahta sistemleri için bir kontrol mimarisi ortaya atmaktadır. Mimari, genel amaç ağaçlarının taranmasına dayanmaktadır. Amaçlar, genkurallar, stratejiler, yöntemler ve bilgi kaynakları mimarinin temel elemanlarını oluşturmaktadır. Ana kontrol döngüsü o anda ki çevrimde işlenecek bilgi kaynağını belirlemek için bir pey sürme mekanizması kullanmaktadır. Burada genkurallar bilgi kaynaklarının hangi niteliklerinin kullanılacağını belirleyen lokal zamanlama kriterleridir. öte yandan strateji, önce-derine, önce-enine önce' iyiye gibi global zamanlama kriteridir. Yöntemler ise bir problemi nasıl çözmek gerektiği üzerine varolan yüksek düzeyde ki bilgiyi tanımlayan kısmen tamamlanmış genel amaç ağacı yapısıdır. Mimari, ayrı kontrol ve domen karatahtaları kullanır. Kontrol problemi ve domen ile ilgili bilgiler ayrı bilgi kaynakları ile temsil edilir. Ana kontrol döngüsü basittir, önerilen mimari, kendi bilgi ve davranışını genkurallar, stratejiler ve yöntemler yardımıyle değiştirebilir ve böylece kendini dinamik prob lem-çözme durumlarına uyarlayabilir. Bütün bu özellikleri basit ve eşyapı lı bir mekanizma ile sağlar. Mimari, Smalltalk dili ile gerçeklenmiş ve çoklu-iş planlama problemi üzerinde test edilmiştir. Smalltalk uygulaması mimarinin mantıksal tasarımını yansıtmaktadır. Ortaya atılan mimari, veri-güdümlü tarama stratejisi, ek kontrol bilgi kaynakları, ek karatahta elemanları ve benzeri diğer yapıları içerecek şekilde geliştirilmek üzere oldukça esnektir.","ili ABSTRACT This thesis introduces a control architecture for goal-driven blackboard systems. The architecture is based on searching a general goal tree. The basic elements of the architecture are goals, policies, strategies, methods, and knowledge sources. The basic control loop employs a bidding mechanism to determine the knowledge source to be executed at the current cycle. A policy is a local scheduling criteria which guides the bidding process and it indicates which of the attributes of the knowledge sources are relevant in this process. A strategy is a global scheduling criteria such as depth-first, breath-first, or best-first. A method is a partially complete general goal tree structure representing high level knowledge on how to solve a problem. The architecture employs separate control and domain blackboards, and separate knowledge sources for the control problem and for representing the domain knowledge. The basic control loop is simple. Is is able to adopt itself to dynamic problem-solving situations by interpreting and modifying its own knowledge and behavior with the help of policies, strategies, and methods. It realizes all these features in a simple and uniform mechanism. The architecture is implemented in Smalltalk and tested on a multiple-task planning problem. Smalltalk implementation closely resembles the logical design of the architecture. The design and implementation is flexible enough to extend the architecture to include other structures such as data-driven search strategy, additional control KSes, additional blackboard elements, etc."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Derse ait metin türünde bilgileri saklamak için 'hypermedia' sistemleri kavramına dayanan bir düzenleme aracı tasarlandı ve uygulandı. Düzenleme aracının kullanıcı arabirimi Türkçedir. Sistem iki tür kullanıcı için olanaklar sağlıyor: Düzenleyiciler derse ait uygulamaları tasarlayıp, yerleştiriyor ve okurlar bu uygulama içinde dolaşıyor. Yapı ve içerik değiştirme araçları düzenleyici tarafından kullanılırken, dolaşma araçlarından her iki kullanıcı da yararlanıyor. Sayfalarda tutulan metin bilgileri belirli bir büyüklüğe sahip. Kullanıcı tümünü ekranda görebiliyor. Düzenleyici metni değiştirebiliyor. Değiştirilen metin için yeni bir versiyon oluşturabiliyor. Ana komutların yanı sıra, editor metin türü bilgileri başka sayfalara taşımak için kullanılan ""kopyalama, çıkarma, ekleme' özelliğini de sağlıyor. Birbiri ile ilişkili bilgilere sahip sayfalar kompozit bir yapı içinde bir araya getirilip, kompozit işlemleri araçlarını kullanarak sıra ile arka arkaya dolaşılabiliyor. Okurların, sayfaları önceden belirlenen bir sırada dolaşmalarını sağlayan yollar tanımlanabiliyor. Sayfa düzeyinde dört çeşit erişim kısıtlaması tanımlanıyor. Kullanıcının sayfa sahibi olduğu durumlarda erişim iznine bakılmıyor.","IV ABSTRACT Using the hypermedia system concept, an authoring tool for creating courseware material of text type is designed and implemented. The user interface of the authoring tool is Turkish. The tool offers facilities for two types of users: Authors design and implement courseware application, and readers navigate in the application. The structure and content editing tools serve to the author whereas navigation tools are used by both of the users. The text information kept in nodes has a limited size, the user can see the whole content on the screen. The author can edit the text. He can make a new version for the edited text. The editor represents the %copy, cut, paste' facility, which is used for carrying text information to other nodes, in addition to the basic editor commands. Nodes with related information can be aggregated in a composite structure to be navigated successively using the composite operation tools. Paths can be defined which makes readers navigate nodes in a prespecified order. Restriction of access is introduced at node level in four types. Access right of a node is ignored when the user is the owner of the node."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"iv ÖZET Bu tezde, bir bilgi işlem merkezinde batch işlerin, planlanma ve sisteme gönderilmelerini sağlayan bir işletim yönetimi sistemi sunulmaktadır. Kullanıcı, bir batch işi, 1) çalışma devreleri, 2) işin, öncüllerine olan bağımlılığı (precedency relation), 3) işin herhangi bir kaynağın kullanılabilir olmasına bağımlılığı (data dependency) ve 4) çalışma (execution) sırasında gerekecek olan kaynaklar aracılığıyla tanımlayabilir, öncüllere olan bağımlılık yönlü grafiklerle (directed graphs) belirtilir. Kaynakların kullanılabilirliğine olan bağımlılık ise, işlerin, paylaşılan bir kütükteki değişkenlere çeşitli değerler atamasıyla gerçekleştirilir. Sistemin sağladığı planlama işlevleri uzun-dönem planlama ve günlük planlamadır. Uzun-dönem plan, belli bir sürede çalıştırılacak olan işleri listeler ve günlük planlama için temel oluşturur. Günlük işlem planı, o gün çalıştırılacak olan işlerin birbirlerine olan bağımlılıklarını, çalışma sırasını ve sistem kaynaklarına olan gereksinimlerini listeler. Bu planın çalıştırılması aynı anda çalışan iki ayrı program ile sağlanır. Bunlardan ilki, iş gönderme (job submission), işlerin belirlenen sırada sisteme gönderilmelerini sağlar. Bu, işlerin önceki işlere bağımlılıklarını gösteren grafiğin, sanki, birden fazla işlemciye iş gönderiliyormuş gibi çoklu iş zinciri oluşturularak izlenmesi ile sağlanır. Diğer program, iş izleme (job tracking) ise, sistemde çalışan işleri takip eder ve tamamlanan işleri, iş gönderme programına bildirir. Tüm sistem PL/1 dili ve PL/l'nın multi-tasking programlama özelliklerinden yararlanılarak gerçekleştirilmiştir. MVS/XA işletim sisteminde çalışan ISPF/PDF ve SDSF ürünlerinden de faydalanılmıştır.","İÜ ABSTRACT This thesis introduces an operations management system which I provides features to plan and to schedule batch workload in the operations department of a DP center. The user can define a CPU- job in terms of its 1) processing cycles, 2) job dependencies - prerequisite jobs, 3) data dependencies - dependencies on availability of a resource and finally 4) its special resource requirements. Job dependencies are represented by a directed, acyclic graph. Data dependencies are realized by flags in a shared file which jobs themselves update. The planning functions available are long-term planning and daily scheduling. The long-term plan documents the future batch workload of the installation for a specified time range and serves as a basis for the daily scheduling function. The daily operating plan, which is actually a graph, represents the dependencies and requirements of jobs scheduled to run on a single day. The execution of the daily schedule is fulfilled by two concurrent tasks, job submission and job tracking. The job tracking task monitors the jobs executing and signals the end of jobs to job submission task. The design of job submission task consists of a graph traversing algorithm which is extended to include outputting 'n' streams of jobs as if 'n' parallel servers are executing. The system is realized in MVS/XA operating system with JBS2 as its job entry subsystem. It is implemented in Pk/1 language, using its multi-tasking features. Also, the products ISPF/PDF and SDSF in MVS/XA are made use of. The design and implementation can be extended to include job restart/recovery functions."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"Bu teşde bilgisayar sistemlerindeki kilitlenme yakalama sorunu incelenmektedir. Kilitlenme modelleri ve konu hakkında yayınlanmış bazı algoritmalar tanıtılmaktadır. Daha Once düzeltilmiş ""önceliğe Dayalı Bir Kilitlenme Yakalama Algoritması"" açıklanmaktadır. Algoritmayı daha verimli ve doğru yapmak için bazı değişiklikler önerilmektedir. Algoritmanın son hali tek işlemcili bir sistem için benzetimlenmektedir. Değişikliklerin etkisini göstermek amacı ile, alınan sonuçlar değişiklikler yapılmadan alınan sonuçlarla karşılaştırılmaktadır. Yapılan değişikliklerle sistemin daha başarılı olduğu gözlenmektedir. Ayrıca ileride yapılacak olan benzetim çalışmaları için dağıtılmış bir sistem modeli önerilmektedir.","In this thesis, the deadlock detection problem in computing systems is examined in detail. Deadlock models and some published algorithms on deadlock detection are discussed. A modified priority based algorithm is introduced and some more s modifications are offered to make the algorithm correct and more efficient The final version of the algorithm is simulated for a single-site system. To show the effects of these modifications, the simulation results obtained with modifications are compared with the results obtained without them. It is observed that after the modifications, the system performed better. For further simulation studies, a distributed system model is offered."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Sistem analizi peke ok bilim dalını ilgilendiren bir konudur. Bölümleri arasında düzenli bağlantılar bulunan herhangi bir olayı bir sistem olarak tarif edebiliriz. Bir sistem matematik modelleme yoluyla ifade edilir. Böylece bir sistemin analizi sisteme ait matematik modelin analizi ile yapılır. Bir sistemin matematik modeli sistem hakkında önemli bilgiler içerir: değişik durumlarda sistem nasıl davranır, değişkenler arasındaki ilişkiler nelerdir, değişkenlere ait sebep-sonuç sırası ne şekilde düzenlenmiştir, vb. Günümüzde sistemi doğru olarak anlayabilmek için bu bilgilerin çıkarımı genellikle insanlar tarafından yapılmaktadır. Bu tez, bu işlemin otomasyonu yönünde bir adım atmayı amaçlamaktadır ve bu sebeple bazı teknikler ortaya koymaktadır. Bu teknikler yaygın olarak kullanılan birtakım matematik metotlara dayanmaktadır: bir sistemi tarifleyen kapalı fonksiyonların kısmi türevleri -ve toplam türevleri. Kısmi ve toplam türevler modeldeki değişkenler arasındaki sebep-sonuç ilişkilerini ortaya çıkarmak amacıyla kullanılmaktadır. Bu çalışmada yer alan matematik modeller cebirsel denklemlerden oluşmaktadır. viSistem analizi işlemini iki gruba ayırabiliriz: Sayısal analiz ve niteliksel analiz. Bu çalışmada ortaya atılan teknikler genel olarak nitelikseldir, ancak bir modelde bulunan sayısal bilgi de dikkate alınmaktadır. vii","ABSTRACT System analysis is an important topic for many scientific disciplines. By a system, we mean an orderly, interconnected arrangement of parts describing a phenomenon. The formal representation of systems is done through mathematical modeling. Thus the analysis of a system is performed by analysing the mathematical model of the system. The mathematical model of a system contains implicit information about the system it describes - how the system behaves under various conditions, what are the relationships between the variables, how the cause-effect sequence of the variables be arranged, etc. Currently, the exposition of this information in order to understand the system truly is usually performed by humans. This thesis is a step towards the automation of this process and introduces for this purpose some techniques. These techniques are based on the use of some well-known mathematical tools: partial derivatives and total differentials of the closed form functions defining a system. Partial derivatives and total differentials are analysed to make the causal relations implied by the model explicit. The mathematical models addressed by our work are restricted to models of the form of algebraic equations. ivWe can classify the process of system analysis into two: Quantitative analysis and qualitative analysis. The techniques introduced in this work are mostly qualitative in nature, but they also take into account the quantitative information available in a model."
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,"ÖZET Bu tezde geleneksel yazılım güvenilirliği çözümlemesi ve önkestiriminde kullanılabilecek bir model anlatılmaktadır, önerilen model işletimsel durumda olan büyük ölçekli dağıtımlı ticari bir yazılım sistemi üzerinde uygulanmıştır. Model üç bilinmeyen parametresi olan gama dağılımı ile tanımlanmaktadır. Bu parametreler başarısızlık zaman verilerinden en çok olabilirlik kestirimi yöntemi kullanılarak kestirilmektedir. Modelin, çözümlenmekte olan yazılım sistemi üzerine daha fazla bilgi yokluğunda, diğer bilinen modellerden verilere daha iyi uyduğu gösterilmektedir.",İV ABSTRACT İn this thesis a model that can be used for conventional software reliability analysis and prediction is described. The proposed model has been applied on a large-scale distributed commercial software system which is already operational. The model is characterized by the gamma distribution having three unknown parameters. The parameters are estimated from failure time data by using the method of maximum likelihood estimation. The model is shown to fit the data better than other well-known models in the absence of additional information on the software system being analyzed.
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
Boğaziçi Üniversitesi,Bilgisayar Mühendisliği Bilimleri-Bilgisayar ve Kontrol = Computer Engineering and Computer Science and Control,,
