{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# input_file = 'terms/merged/merged.csv'\n",
    "# df = pd.read_csv(input_file)\n",
    "# def normalize_term(term):\n",
    "#     \"\"\"Normalize special characters in a term and return its URL part.\"\"\"\n",
    "#     replacements = {\"â\": \"a\", 'ç': 'c', 'ğ': 'g', 'ı': 'i', 'ö': 'o', 'ş': 's', 'ü': 'u', 'Ç': 'C', 'Ğ': 'G', 'İ': 'I',\n",
    "#                     'Ö': 'O', 'Ş': 'S', 'Ü': 'U', \"'\": \"\", \"’\": \"\", }\n",
    "#     # replace all punctiation with empty string\n",
    "#     term = term.translate(str.maketrans('', '', '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'))\n",
    "#     out = ''.join(replacements.get(c, c) for c in term).lower().replace(' ', '')\n",
    "#     # if last character exist and is 's'\n",
    "#     if len(out) > 0 and out[-1] == 's':\n",
    "#         out = out[:-1]\n",
    "#     return out\n",
    "# # remove NaNs\n",
    "# df = df.fillna('')\n",
    "# df['normalized_name'] = df['name'].apply(normalize_term)\n",
    "# df['normalized_tr_title'] = df['tr_title'].apply(normalize_term)\n",
    "# df['normalized_en'] = df['en'].apply(normalize_term)\n",
    "# df['normalized_en_title'] = df['en_title'].apply(normalize_term)\n",
    "# df['new_category'] = [0.0] * len(df)\n",
    "# df.loc[(df['en_exists'] == False) & (df['tr_exists'] == False), 'new_category'] = 1.0\n",
    "# df.loc[df['id'] == 3278, 'new_category'] = 1.0\n",
    "# df.loc[(df['en_exists'] == True) & (df['normalized_en'] == df['normalized_en_title']) & (df['tr_exists'] == False), 'new_category'] = 2.0\n",
    "# df.loc[(df['en_exists'] == True) & (df['normalized_en'] != df['normalized_en_title']), 'new_category'] = 1.0\n",
    "# \n",
    "# df.loc[(df['en_exists'] == True) & (df['tr_exists'] == True) & (df['normalized_en'] == df['normalized_en_title']) & (df['normalized_name'] == df['normalized_tr_title']), 'new_category'] = 3.1\n",
    "# df.loc[(df['en_exists'] == True) & (df['tr_exists'] == True) & (df['normalized_en'] == df['normalized_en_title']) & (df['normalized_name'] != df['normalized_tr_title']), 'new_category'] = 3.2\n",
    "# df.loc[(df['en_exists'] == True) & (df['tr_exists'] == True) & (df['normalized_en_title'] == df['normalized_tr_title']), 'new_category'] = 1.0\n",
    "# # if df['new_category'] == 1.0: fill following columns with NaN: en_page_id, en_title, en_fullurl, en_length, en_summary, tr_page_id, tr_title, tr_fullurl, tr_length, tr_summary also fill en_exists and tr_exists with False\n",
    "# \n",
    "# df.loc[df['new_category'] == 1.0, 'en_pageid'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'en_title'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'en_fullurl'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'en_length'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'en_summary'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'en_exists'] = False\n",
    "# \n",
    "# \n",
    "# df.loc[df['new_category'] == 1.0, 'tr_pageid'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'tr_title'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'tr_fullurl'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'tr_length'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'tr_summary'] = np.nan\n",
    "# df.loc[df['new_category'] == 1.0, 'tr_exists'] = False\n",
    "# \n",
    "# \n",
    "# # if df['new_category'] == 2.0: fill following columns with NaN: tr_page_id, tr_title, tr_fullurl, tr_length, tr_summary also fill tr_exists with False\n",
    "# df.loc[df['new_category'] == 2.0, 'tr_pageid'] = np.nan\n",
    "# df.loc[df['new_category'] == 2.0, 'tr_title'] = np.nan\n",
    "# df.loc[df['new_category'] == 2.0, 'tr_fullurl'] = np.nan\n",
    "# df.loc[df['new_category'] == 2.0, 'tr_length'] = np.nan\n",
    "# df.loc[df['new_category'] == 2.0, 'tr_summary'] = np.nan\n",
    "# df.loc[df['new_category'] == 2.0, 'tr_exists'] = False\n",
    "# \n",
    "# # df['category'] becomes df['new_category']\n",
    "# df['category'] = df['new_category']\n",
    "# # drop df['new_category']\n",
    "# df = df.drop(columns=['new_category'])\n",
    "# # 'en_exists' and 'tr_exists' are boolean, convert them to int\n",
    "# df['en_exists'] = df['en_exists'].astype(int)\n",
    "# df['tr_exists'] = df['tr_exists'].astype(int)\n",
    "# \n",
    "# \n",
    "# # fill empty cells with NaN\n",
    "# df = df.replace('', np.nan)\n",
    "# # fill NaNs empty cells\n",
    "# df = df.fillna('')\n",
    "# \n",
    "# # save \n",
    "# df.to_csv('terms/final/final_one2one.csv', index=False)\n",
    "# df.to_excel('terms/final/final_one2one.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:09.046981Z",
     "start_time": "2024-03-04T09:46:09.043028Z"
    }
   },
   "id": "4044e885470ca535",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "input_file_1 = 'terms/terimler_org/terimler_org_all.csv'\n",
    "input_file_2 = 'terms/terimler_org/terimler_org_one2one.csv'\n",
    "input_file_3 = 'terms/final/final_one2one.csv'\n",
    "\n",
    "df1 = pd.read_csv(input_file_1)\n",
    "df2 = pd.read_csv(input_file_2)\n",
    "df3 = pd.read_csv(input_file_3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:09.798342Z",
     "start_time": "2024-03-04T09:46:09.048227Z"
    }
   },
   "id": "bebce6db4b2da7a0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'name', 'slug', 'number_of_definitions', 'scope', 'content',\n       'number_of_synonyms', 'synonyms', 'number_of_en', 'number_of_de',\n       'number_of_fr', 'number_of_lat', 'en', 'de', 'fr', 'lat'],\n      dtype='object')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique 'id' in df1\n",
    "df1.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:09.802634Z",
     "start_time": "2024-03-04T09:46:09.799458Z"
    }
   },
   "id": "ce7745517f6ab0ef",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "23424"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique 'id' in df2\n",
    "len(df2['id'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:09.805608Z",
     "start_time": "2024-03-04T09:46:09.803173Z"
    }
   },
   "id": "460187a44b93e895",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['id', 'name', 'slug', 'number_of_definitions', 'scope', 'content',\n       'number_of_synonyms', 'synonyms', 'number_of_en', 'number_of_de',\n       'number_of_fr', 'number_of_lat', 'en', 'de', 'fr', 'lat'],\n      dtype='object')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:09.808887Z",
     "start_time": "2024-03-04T09:46:09.806801Z"
    }
   },
   "id": "213fc97bf37ff5f5",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "23407"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique 'id' in df3\n",
    "len(df3['id'].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:09.811772Z",
     "start_time": "2024-03-04T09:46:09.809387Z"
    }
   },
   "id": "745143ae2c8485c6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# save df3['category'] == 3.2\n",
    "df3_32 = df3[df3['category'] == 3.2]\n",
    "df3_32.to_excel('terms/final/final_one2one_32.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T09:46:10.284197Z",
     "start_time": "2024-03-04T09:46:09.812292Z"
    }
   },
   "id": "904cc265590a8bec",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce427c0a4219ca7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
