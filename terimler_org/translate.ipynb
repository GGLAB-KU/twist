{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Jupyter Notebook: Turkish-to-English Batch Translator\n",
    "# %%\n",
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "from itertools import islice\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Setup logging to output in Jupyter\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# %%\n",
    "# Cell 2: API Key Configuration\n",
    "# Option 1: Set environment variable OPENAI_API_KEY before running\n",
    "API_KEY = \"\"\n",
    "\n",
    "# Option 2: Uncomment to enter manually (not recommended for production)\n",
    "# from getpass import getpass\n",
    "# API_KEY = getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise EnvironmentError(\n",
    "        \"Please set the OPENAI_API_KEY environment variable or enter it manually.\"\n",
    "    )\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)\n",
    "\n",
    "# %%\n",
    "# Cell 3: Helper Functions\n",
    "\n",
    "def chunked(iterable, size):\n",
    "    \"\"\"Yield successive chunks of specified size from iterable.\"\"\"\n",
    "    it = iter(iterable)\n",
    "    while (batch := list(islice(it, size))):\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def build_prompt(batch: list[str]) -> str:\n",
    "    \"\"\"Builds a numbered prompt from a list of sentences.\"\"\"\n",
    "    numbered = \"\\n\".join(f\"{i+1}. {sentence.strip()}\"\n",
    "                        for i, sentence in enumerate(batch))\n",
    "    return (\n",
    "        \"You are a professional translator fluent in Turkish and English. \"\n",
    "        \"Translate the following Turkish sentences into fluent, natural English. \"\n",
    "        \"Preserve the original meaning, tone, and context. \"\n",
    "        \"Return only the translations, numbered, one per line, in the same order.\\n\\n\"\n",
    "        f\"{numbered}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_translations(response_text: str, expected_count: int) -> list[str]:\n",
    "    \"\"\"Extracts numbered translations from the model output.\"\"\"\n",
    "    matches = re.findall(r\"\\d+\\.\\s+(.*)\", response_text.strip())\n",
    "    if len(matches) != expected_count:\n",
    "        logger.warning(\n",
    "            \"Expected %d translations but got %d; padding or trimming.\",\n",
    "            expected_count, len(matches)\n",
    "        )\n",
    "        matches = (matches + [\"\"] * expected_count)[:expected_count]\n",
    "    return matches\n",
    "\n",
    "\n",
    "def translate_batch(batch: list[str]) -> list[str]:\n",
    "    \"\"\"Translate a batch of Turkish sentences to English using OpenAI.\"\"\"\n",
    "    prompt = build_prompt(batch)\n",
    "    logger.debug(\"Prompt:\\n%s\", prompt)\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        raw_output = response.choices[0].message.content\n",
    "        return parse_translations(raw_output, len(batch))\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\"Unexpected error: %s\", e)\n",
    "        # On error, return blanks\n",
    "        return [\"\"] * len(batch)\n",
    "\n",
    "# %%\n",
    "# Cell 4: Translation Workflow Function (for single-file use)\n",
    "\n",
    "def translate_file(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    column_name: str = \"turkish\",\n",
    "    row_limit: int = None,\n",
    "    batch_size: int = 50\n",
    ") -> None:\n",
    "    \"\"\"Read input Excel, translate, and save results.\"\"\"\n",
    "    logger.info(\n",
    "        \"Reading %s (column=%s)%s\",\n",
    "        input_file,\n",
    "        column_name,\n",
    "        f\", up to {row_limit} rows\" if row_limit else \"\"\n",
    "    )\n",
    "    df = pd.read_excel(input_file)\n",
    "    if row_limit:\n",
    "        df = df.head(row_limit)\n",
    "\n",
    "    texts = df[column_name].dropna().astype(str).tolist()\n",
    "    all_translations: list[str] = []\n",
    "\n",
    "    for batch in tqdm(chunked(texts, batch_size), desc=\"Translating\"):\n",
    "        all_translations.extend(translate_batch(batch))\n",
    "\n",
    "    df[\"definition_in_english\"] = all_translations[: len(df)]\n",
    "    df.to_excel(output_file, index=False)\n",
    "    logger.info(\"Done! Translations saved to %s\", output_file)\n",
    "\n",
    "# %%\n",
    "# Cell 5: Batch‐splitting and translation driver (for 68k rows → 2k‐row files)\n",
    "\n",
    "# Parameters\n",
    "input_file  = \"turkish.xlsx\"\n",
    "column_name = \"definition_in_turkish\"\n",
    "batch_size  = 50    # sentences per API call\n",
    "chunk_size  = 2000  # rows per output file\n",
    "\n",
    "# Read the entire sheet once\n",
    "logger.info(\"Reading full file %s...\", input_file)\n",
    "df_full = pd.read_excel(input_file)\n",
    "\n",
    "total_rows = len(df_full)\n",
    "n_chunks   = (total_rows + chunk_size - 1) // chunk_size\n",
    "logger.info(\n",
    "    \"Total rows: %d, will write %d files of up to %d rows each\",\n",
    "    total_rows, n_chunks, chunk_size\n",
    ")\n",
    "\n",
    "for i in range(n_chunks):\n",
    "    start = i * chunk_size\n",
    "    end   = min(start + chunk_size, total_rows)\n",
    "    df_chunk = df_full.iloc[start:end].copy()\n",
    "\n",
    "    texts = df_chunk[column_name].dropna().astype(str).tolist()\n",
    "    all_translations: list[str] = []\n",
    "    for batch in tqdm(chunked(texts, batch_size),\n",
    "                      desc=f\"Chunk {i+1}/{n_chunks} Translating\"):\n",
    "        all_translations.extend(translate_batch(batch))\n",
    "\n",
    "    df_chunk[\"definition_in_english\"] = all_translations[: len(df_chunk)]\n",
    "    out_fname = f\"turkish_translated_{start+1}_to_{end}.xlsx\"\n",
    "    df_chunk.to_excel(out_fname, index=False)\n",
    "    logger.info(\"Saved rows %d–%d to %s\", start+1, end, out_fname)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
