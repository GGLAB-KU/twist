{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "GROUND_TRUTH_MAIL = ''\n",
    "file_path = 'outputs/excel/group5_results.xlsx'  # TODO: update\n",
    "txt_output_path = 'outputs/txt/group5.txt'  # TODO: update\n",
    "\n",
    "task_agreements = [59.81, 72.16, 59.62, 62.27, 55.54] # TODO: update\n",
    "task_ids = [127902439, 127902443, 127902456, 127902467, 127902480] # TODO: update\n",
    "group = 'group5' # TODO: update\n",
    "nan_position = False # TODO: update\n",
    "\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "\n",
    "# Filter out the ground truth mail\n",
    "number_of_tests = df.loc[df['mail'] == GROUND_TRUTH_MAIL, 'number_of_tasks_completed'].values[0]\n",
    "df = df[df['mail'] != GROUND_TRUTH_MAIL]\n",
    "\n",
    "def calculate_f1(tp, fp, fn):\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    return 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "def calculate_kappa(tp, fp, fn, tn):\n",
    "    kappa_above = 2*(tp*tn - fn*fp)\n",
    "    kappa_below = (tp+fp)*(fp+tn)+(tp+fn)*(fn+tn)\n",
    "    kappa = kappa_above / kappa_below if kappa_below > 0 else 0\n",
    "    return kappa\n",
    "\n",
    "\n",
    "def calculate_exact_match(intersection, difference):\n",
    "    return intersection / (intersection + difference) if (intersection + difference) != 0 else 0\n",
    "\n",
    "def generate_results(df, task_prefix):\n",
    "    # Overall results for the task\n",
    "    eng_term_detection_f1 = calculate_f1(df[f'{task_prefix}_english_term_detection_tp'].sum(), \n",
    "                                         df[f'{task_prefix}_english_term_detection_fp'].sum(), \n",
    "                                         df[f'{task_prefix}_english_term_detection_fn'].sum())\n",
    "    \n",
    "    tr_term_detection_f1 = calculate_f1(df[f'{task_prefix}_turkish_term_detection_tp'].sum(), \n",
    "                                        df[f'{task_prefix}_turkish_term_detection_fp'].sum(), \n",
    "                                        df[f'{task_prefix}_turkish_term_detection_fn'].sum())\n",
    "    \n",
    "    eng_term_detection_kappa = calculate_kappa(df[f'{task_prefix}_english_term_detection_tp'].sum(),\n",
    "                                                df[f'{task_prefix}_english_term_detection_fp'].sum(),\n",
    "                                                df[f'{task_prefix}_english_term_detection_fn'].sum(),\n",
    "                                                df[f'{task_prefix}_english_term_detection_tn'].sum())\n",
    "    \n",
    "    tr_term_detection_kappa = calculate_kappa(df[f'{task_prefix}_turkish_term_detection_tp'].sum(),\n",
    "                                                  df[f'{task_prefix}_turkish_term_detection_fp'].sum(),\n",
    "                                                  df[f'{task_prefix}_turkish_term_detection_fn'].sum(),\n",
    "                                                  df[f'{task_prefix}_turkish_term_detection_tn'].sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    exact_match_turkish_labels = calculate_exact_match(df[f'{task_prefix}_turkish_labels_intersection_num'].sum(), \n",
    "                                                       df[f'{task_prefix}_turkish_labels_difference_num'].sum())\n",
    "    \n",
    "    exact_match_turkish_corrections = calculate_exact_match(df[f'{task_prefix}_turkish_corrections_intersection_num'].sum(), \n",
    "                                                            df[f'{task_prefix}_turkish_corrections_difference_num'].sum())\n",
    "    \n",
    "    exact_match_english_term_linking = calculate_exact_match(df[f'{task_prefix}_english_term_linking_intersection_num'].sum(), \n",
    "                                                             df[f'{task_prefix}_english_term_linking_difference_num'].sum())\n",
    "    \n",
    "    # Collect overall results for the specified task\n",
    "    overall_results = {\n",
    "        \"task\": task_prefix,\n",
    "        \"eng_term_detection_f1\": round(eng_term_detection_f1, 3),\n",
    "        \"tr_term_detection_f1\": round(tr_term_detection_f1, 3),\n",
    "        \"eng_term_detection_kappa\": round(eng_term_detection_kappa, 3),\n",
    "        \"tr_term_detection_kappa\": round(tr_term_detection_kappa, 3),\n",
    "        \"exact_match_turkish_labels\": round(exact_match_turkish_labels, 3),\n",
    "        \"exact_match_turkish_corrections\": round(exact_match_turkish_corrections, 3),\n",
    "        \"exact_match_english_term_linking\": round(exact_match_english_term_linking, 3),\n",
    "    }\n",
    "    \n",
    "    # Collect results for each annotator\n",
    "    annotator_results = []\n",
    "    for _, row in df.iterrows():\n",
    "        eng_term_detection_f1 = calculate_f1(row[f'{task_prefix}_english_term_detection_tp'], \n",
    "                                             row[f'{task_prefix}_english_term_detection_fp'], \n",
    "                                             row[f'{task_prefix}_english_term_detection_fn'])\n",
    "        \n",
    "        tr_term_detection_f1 = calculate_f1(row[f'{task_prefix}_turkish_term_detection_tp'], \n",
    "                                            row[f'{task_prefix}_turkish_term_detection_fp'], \n",
    "                                            row[f'{task_prefix}_turkish_term_detection_fn'])\n",
    "        \n",
    "        eng_term_detection_kappa = calculate_kappa(row[f'{task_prefix}_english_term_detection_tp'],\n",
    "                                                row[f'{task_prefix}_english_term_detection_fp'],\n",
    "                                                row[f'{task_prefix}_english_term_detection_fn'],\n",
    "                                                row[f'{task_prefix}_english_term_detection_tn'])\n",
    "        \n",
    "        tr_term_detection_kappa = calculate_kappa(row[f'{task_prefix}_turkish_term_detection_tp'],\n",
    "                                                    row[f'{task_prefix}_turkish_term_detection_fp'],\n",
    "                                                    row[f'{task_prefix}_turkish_term_detection_fn'],\n",
    "                                                    row[f'{task_prefix}_turkish_term_detection_tn'])\n",
    "        \n",
    "        \n",
    "        exact_match_turkish_labels = calculate_exact_match(row[f'{task_prefix}_turkish_labels_intersection_num'], \n",
    "                                                           row[f'{task_prefix}_turkish_labels_difference_num'])\n",
    "        \n",
    "        exact_match_turkish_corrections = calculate_exact_match(row[f'{task_prefix}_turkish_corrections_intersection_num'], \n",
    "                                                                row[f'{task_prefix}_turkish_corrections_difference_num'])\n",
    "        \n",
    "        exact_match_english_term_linking = calculate_exact_match(row[f'{task_prefix}_english_term_linking_intersection_num'], \n",
    "                                                                 row[f'{task_prefix}_english_term_linking_difference_num'])\n",
    "        \n",
    "        annotator_results.append({\n",
    "            \"annotator\": row['mail'],\n",
    "            \"eng_term_detection_f1\": round(eng_term_detection_f1, 3),\n",
    "            \"tr_term_detection_f1\": round(tr_term_detection_f1, 3),\n",
    "            \"eng_term_detection_kappa\": round(eng_term_detection_kappa, 3),\n",
    "            \"tr_term_detection_kappa\": round(tr_term_detection_kappa, 3),\n",
    "            \"exact_match_turkish_labels\": round(exact_match_turkish_labels, 3),\n",
    "            \"exact_match_turkish_corrections\": round(exact_match_turkish_corrections, 3),\n",
    "            \"exact_match_english_term_linking\": round(exact_match_english_term_linking, 3),\n",
    "        })\n",
    "\n",
    "    return overall_results, annotator_results\n",
    "\n",
    "# Identify all unique task prefixes\n",
    "task_columns = df.columns[df.columns.str.contains(r'^task_\\d+')]\n",
    "task_prefixes = {re.match(r'^(task_\\d+)', col).group(1) for col in task_columns}\n",
    "\n",
    "# Cumulative Results\n",
    "cumulative_eng_term_detection_f1 = calculate_f1(df['cumulative_english_term_detection_tp'].sum(), df['cumulative_english_term_detection_fp'].sum(), df['cumulative_english_term_detection_fn'].sum())\n",
    "cumulative_tr_term_detection_f1 = calculate_f1(df['cumulative_turkish_term_detection_tp'].sum(), df['cumulative_turkish_term_detection_fp'].sum(), df['cumulative_turkish_term_detection_fn'].sum())\n",
    "exact_match_turkish_labels = calculate_exact_match(df['cumulative_turkish_labels_intersection_num'].sum(), df['cumulative_turkish_labels_difference_num'].sum())\n",
    "exact_match_turkish_corrections = calculate_exact_match(df['cumulative_turkish_corrections_intersection_num'].sum(), df['cumulative_turkish_corrections_difference_num'].sum())\n",
    "exact_match_english_term_linking = calculate_exact_match(df['cumulative_english_term_linking_intersection_num'].sum(), df['cumulative_english_term_linking_difference_num'].sum())\n",
    "\n",
    "cumulative_eng_term_detection_kappa = calculate_kappa(df['cumulative_english_term_detection_tp'].sum(), df['cumulative_english_term_detection_fp'].sum(), df['cumulative_english_term_detection_fn'].sum(), df['cumulative_english_term_detection_tn'].sum())\n",
    "\n",
    "cumulative_tr_term_detection_kappa = calculate_kappa(df['cumulative_turkish_term_detection_tp'].sum(), df['cumulative_turkish_term_detection_fp'].sum(), df['cumulative_turkish_term_detection_fn'].sum(), df['cumulative_turkish_term_detection_tn'].sum())\n",
    "\n",
    "\n",
    "cumulative_results = {\n",
    "    \"eng_term_detection_f1\": round(cumulative_eng_term_detection_f1, 3),\n",
    "    \"tr_term_detection_f1\": round(cumulative_tr_term_detection_f1, 3),\n",
    "    \"eng_term_detection_kappa\": round(cumulative_eng_term_detection_kappa, 3),\n",
    "    \"tr_term_detection_kappa\": round(cumulative_tr_term_detection_kappa, 3),\n",
    "    \"exact_match_turkish_labels\": round(exact_match_turkish_labels, 3),\n",
    "    \"exact_match_turkish_corrections\": round(exact_match_turkish_corrections, 3),\n",
    "    \"exact_match_english_term_linking\": round(exact_match_english_term_linking, 3),\n",
    "}\n",
    "\n",
    "# Collect cumulative results for each annotator\n",
    "cumulative_annotator_results = []\n",
    "for _, row in df.iterrows():\n",
    "    cumulative_eng_term_detection_f1 = calculate_f1(row['cumulative_english_term_detection_tp'], row['cumulative_english_term_detection_fp'], row['cumulative_english_term_detection_fn'])\n",
    "    cumulative_tr_term_detection_f1 = calculate_f1(row['cumulative_turkish_term_detection_tp'], row['cumulative_turkish_term_detection_fp'], row['cumulative_turkish_term_detection_fn'])\n",
    "    cumulative_eng_term_detection_kappa = calculate_kappa(row['cumulative_english_term_detection_tp'], row['cumulative_english_term_detection_fp'], row['cumulative_english_term_detection_fn'], row['cumulative_english_term_detection_tn'])\n",
    "    cumulative_tr_term_detection_kappa = calculate_kappa(row['cumulative_turkish_term_detection_tp'], row['cumulative_turkish_term_detection_fp'], row['cumulative_turkish_term_detection_fn'], row['cumulative_turkish_term_detection_tn'])\n",
    "    exact_match_turkish_labels = calculate_exact_match(row['cumulative_turkish_labels_intersection_num'], row['cumulative_turkish_labels_difference_num'])\n",
    "    exact_match_turkish_corrections = calculate_exact_match(row['cumulative_turkish_corrections_intersection_num'], row['cumulative_turkish_corrections_difference_num'])\n",
    "    exact_match_english_term_linking = calculate_exact_match(row['cumulative_english_term_linking_intersection_num'], row['cumulative_english_term_linking_difference_num'])\n",
    "    \n",
    "    cumulative_annotator_results.append({\n",
    "        \"annotator\": row['mail'],\n",
    "        \"eng_term_detection_f1\": round(cumulative_eng_term_detection_f1, 3),\n",
    "        \"tr_term_detection_f1\": round(cumulative_tr_term_detection_f1, 3),\n",
    "        \"eng_term_detection_kappa\": round(cumulative_eng_term_detection_kappa, 3),\n",
    "        \"tr_term_detection_kappa\": round(cumulative_tr_term_detection_kappa, 3),\n",
    "        \"exact_match_turkish_labels\": round(exact_match_turkish_labels, 3),\n",
    "        \"exact_match_turkish_corrections\": round(exact_match_turkish_corrections, 3),\n",
    "        \"exact_match_english_term_linking\": round(exact_match_english_term_linking, 3),\n",
    "    })\n",
    "\n",
    "# Generate results for all detected tasks\n",
    "task_results = {}\n",
    "for task_prefix in sorted(task_prefixes):\n",
    "    overall_results, annotator_results = generate_results(df, task_prefix)\n",
    "    task_results[task_prefix] = {\n",
    "        \"overall\": overall_results,\n",
    "        \"annotators\": annotator_results\n",
    "    }\n",
    "    \n",
    "# Generate the summary text based on the results\n",
    "\n",
    "summary_text = \"\"\n",
    "\n",
    "# Add Cumulative Results (Overall)\n",
    "summary_text += \"CUMULATIVE RESULTS (Overall) For \"\n",
    "summary_text += group + \":\\n\"\n",
    "summary_text += f\"- Cumulative English Term Detection F1: {cumulative_results['eng_term_detection_f1']}\\n\"\n",
    "summary_text += f\"- Cumulative Turkish Term Detection F1: {cumulative_results['tr_term_detection_f1']}\\n\"\n",
    "summary_text += f\"- Cumulative English Term Detection Kappa: {cumulative_results['eng_term_detection_kappa']}\\n\"\n",
    "summary_text += f\"- Cumulative Turkish Term Detection Kappa: {cumulative_results['tr_term_detection_kappa']}\\n\"\n",
    "summary_text += f\"- Cumulative Turkish Labels Exact Match: {cumulative_results['exact_match_turkish_labels']}\\n\"\n",
    "summary_text += f\"- Cumulative Turkish Corrections Exact Match: {cumulative_results['exact_match_turkish_corrections']}\\n\"\n",
    "summary_text += f\"- Cumulative English Term Linking Exact Match: {cumulative_results['exact_match_english_term_linking']}\\n\\n\"\n",
    "\n",
    "print(summary_text)\n",
    "\n",
    "# Add Cumulative Results for Each Annotator\n",
    "summary_text += \"CUMULATIVE RESULTS FOR EACH ANNOTATOR:\\n\"\n",
    "for annotator_result in cumulative_annotator_results:\n",
    "    summary_text += f\"\\tAnnotator: {annotator_result['annotator']}\\n\"\n",
    "    summary_text += f\"\\t  - English Term Detection F1: {annotator_result['eng_term_detection_f1']}\\n\"\n",
    "    summary_text += f\"\\t  - Turkish Term Detection F1: {annotator_result['tr_term_detection_f1']}\\n\"\n",
    "    summary_text += f\"\\t  - English Term Detection Kappa: {annotator_result['eng_term_detection_kappa']}\\n\"\n",
    "    summary_text += f\"\\t  - Turkish Term Detection Kappa: {annotator_result['tr_term_detection_kappa']}\\n\"\n",
    "    summary_text += f\"\\t  - Turkish Labels Exact Match: {annotator_result['exact_match_turkish_labels']}\\n\"\n",
    "    summary_text += f\"\\t  - Turkish Corrections Exact Match: {annotator_result['exact_match_turkish_corrections']}\\n\"\n",
    "    summary_text += f\"\\t  - English Term Linking Exact Match: {annotator_result['exact_match_english_term_linking']}\\n\\n\"\n",
    "    \n",
    "    \n",
    "\n",
    "# Add Task-Specific Results\n",
    "for task, results in task_results.items():\n",
    "    summary_text += f\"{task.upper()} RESULTS (Overall):\\n\"\n",
    "    summary_text += f\"- English Term Detection F1: {results['overall']['eng_term_detection_f1']}\\n\"\n",
    "    summary_text += f\"- Turkish Term Detection F1: {results['overall']['tr_term_detection_f1']}\\n\"\n",
    "    summary_text += f\"- English Term Detection Kappa: {results['overall']['eng_term_detection_kappa']}\\n\"\n",
    "    summary_text += f\"- Turkish Term Detection Kappa: {results['overall']['tr_term_detection_kappa']}\\n\"\n",
    "    summary_text += f\"- Turkish Labels Exact Match: {results['overall']['exact_match_turkish_labels']}\\n\"\n",
    "    summary_text += f\"- Turkish Corrections Exact Match: {results['overall']['exact_match_turkish_corrections']}\\n\"\n",
    "    summary_text += f\"- English Term Linking Exact Match: {results['overall']['exact_match_english_term_linking']}\\n\\n\"\n",
    "    \n",
    "    summary_text += f\"{task.upper()} RESULTS FOR EACH ANNOTATOR:\\n\"\n",
    "    for annotator_result in results['annotators']:\n",
    "        summary_text += f\"\\tAnnotator: {annotator_result['annotator']}\\n\"\n",
    "        summary_text += f\"\\t  - English Term Detection F1: {annotator_result['eng_term_detection_f1']}\\n\"\n",
    "        summary_text += f\"\\t  - Turkish Term Detection F1: {annotator_result['tr_term_detection_f1']}\\n\"\n",
    "        summary_text += f\"\\t  - English Term Detection Kappa: {annotator_result['eng_term_detection_kappa']}\\n\"\n",
    "        summary_text += f\"\\t  - Turkish Term Detection Kappa: {annotator_result['tr_term_detection_kappa']}\\n\"\n",
    "        summary_text += f\"\\t  - Turkish Labels Exact Match: {annotator_result['exact_match_turkish_labels']}\\n\"\n",
    "        summary_text += f\"\\t  - Turkish Corrections Exact Match: {annotator_result['exact_match_turkish_corrections']}\\n\"\n",
    "        summary_text += f\"\\t  - English Term Linking Exact Match: {annotator_result['exact_match_english_term_linking']}\\n\\n\"\n",
    "\n",
    "# save the summary text to a file\n",
    "with open(txt_output_path, 'w') as f:\n",
    "    f.write(summary_text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# store overall task results in a dataframe, add task_agreements and task_ids, and group too\n",
    "overall_task_results = []\n",
    "count = 0\n",
    "for task, results in task_results.items():\n",
    "    overall_task_results.append({\n",
    "        \"task\": task,\n",
    "        \"english_term_detection_f1\": results['overall']['eng_term_detection_f1'],\n",
    "        \"turkish_term_detection_f1\": results['overall']['tr_term_detection_f1'],\n",
    "        \"english_term_detection_kappa\": results['overall']['eng_term_detection_kappa'],\n",
    "        \"turkish_term_detection_kappa\": results['overall']['tr_term_detection_kappa'],\n",
    "        \"exact_match_turkish_labels\": results['overall']['exact_match_turkish_labels'],\n",
    "        \"exact_match_turkish_corrections\": results['overall']['exact_match_turkish_corrections'],\n",
    "        \"exact_match_english_term_linking\": results['overall']['exact_match_english_term_linking'],\n",
    "        \"task_agreement\": task_agreements[count],\n",
    "        \"task_id\": task_ids[count],\n",
    "        \"group\": group, \n",
    "        \"nan_position\": nan_position\n",
    "    })\n",
    "    count += 1\n",
    "\n",
    "overall_task_results_df = pd.DataFrame(overall_task_results)\n",
    "# save the dataframe to a xlsx file with group name and nan_position\n",
    "overall_task_results_df.to_excel(f\"outputs/summary/{group}.xlsx\", index=False)"
   ],
   "id": "82013b0c82dfa79c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "overall_task_results_df",
   "id": "e4ab57e1061ee49b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
