{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "LABEL_STUDIO_URL = 'https://app.heartex.com'\n",
    "TASK_ID = 123043171\n",
    "API_TOKEN = ''\n",
    "GROUND_TRUTH_MAIL = ''\n",
    "ANNOTATION_1_MAIL = ''\n",
    "ANNOTATION_2_MAIL = ''\n",
    "SMTP_SERVER = ''\n",
    "SMTP_PORT = 465\n",
    "SMTP_SENDER = ''\n",
    "SMTP_PASSWORD = ''\n",
    "CHECK_INTERVAL = 5  # in seconds\n",
    "MAX_RUNTIME = 600  # in seconds\n",
    "YOUTUBE_LINK = ''\n",
    "\n",
    "# Global variable to track email sending status\n",
    "is_mail_sended = {ANNOTATION_1_MAIL: False, ANNOTATION_2_MAIL: False}\n",
    "\n",
    "def send_email(subject, body, recipient):\n",
    "    msg = MIMEText(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['From'] = SMTP_SENDER\n",
    "    msg['To'] = recipient\n",
    "    with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as smtp:\n",
    "        smtp.login(SMTP_SENDER, SMTP_PASSWORD)\n",
    "        smtp.sendmail(SMTP_SENDER, recipient, msg.as_string())\n",
    "    print(f\"Mail sent to {recipient}\")\n",
    "    is_mail_sended[recipient] = True\n",
    "\n",
    "def get_task_data():\n",
    "    url = f'{LABEL_STUDIO_URL}/api/tasks/{TASK_ID}'\n",
    "    headers = {'Authorization': f'Token {API_TOKEN}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def extract_paragraph_data(task_data):\n",
    "    all_paragraph = task_data['data']['my_text_1']\n",
    "    sections = ['TR-1', 'EN-2', 'TR-2', 'EN-3', 'TR-3']\n",
    "    positions = [all_paragraph.find(section) for section in sections] + [len(all_paragraph)]\n",
    "    intervals = [(positions[i], positions[i+1]) for i in range(len(positions) - 1)]\n",
    "    return all_paragraph, intervals\n",
    "\n",
    "def separate_clean_data(paragraph):\n",
    "    lines = paragraph.strip().split('\\n')\n",
    "    english_data, turkish_data = {}, {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('EN-'):\n",
    "            key, value = line.split(': ')\n",
    "            english_data[key] = value\n",
    "        elif line.startswith('TR-'):\n",
    "            key, value = line.split(': ')\n",
    "            turkish_data[key] = value\n",
    "    return english_data, turkish_data\n",
    "\n",
    "def count_words(data, keys):\n",
    "    return sum(len(data[key].split()) for key in keys)\n",
    "\n",
    "def get_annotation_results(annotation, email, intervals_for_sentences):    \n",
    "    results = {'email': email, 'ground_truth': annotation['ground_truth']}\n",
    "    features = {\n",
    "        'english_detected_terms': [],\n",
    "        'turkish_detected_terms': [],\n",
    "        'turkish_detected_labels': [],\n",
    "        'turkish_detected_corrections': [],\n",
    "        'english_terimler_org_detected': []\n",
    "    }\n",
    "    \n",
    "    for item in annotation['result']:\n",
    "        if 'value' in item and 'labels' in item['value']:\n",
    "            label = item['value']['labels'][0]\n",
    "            text, start, end = item['value']['text'], item['value']['start'], item['value']['end']\n",
    "            meta_text = item.get('meta', {}).get('text', [None])[0]\n",
    "            section = None\n",
    "            if 0 <= start < end <= intervals_for_sentences[0][0]:\n",
    "                section = 'EN-1'\n",
    "            elif intervals_for_sentences[0][0] <= start < end <= intervals_for_sentences[0][1]:\n",
    "                section = 'TR-1'\n",
    "            elif intervals_for_sentences[1][0] <= start < end <= intervals_for_sentences[1][1]:\n",
    "                section = 'EN-2'\n",
    "            elif intervals_for_sentences[2][0] <= start < end <= intervals_for_sentences[2][1]:\n",
    "                section = 'TR-2'\n",
    "            elif intervals_for_sentences[3][0] <= start < end <= intervals_for_sentences[3][1]:\n",
    "                section = 'EN-3'\n",
    "            elif intervals_for_sentences[4][0] <= start < end <= intervals_for_sentences[4][1]:\n",
    "                section = 'TR-3'\n",
    "            else:\n",
    "                print(f\"Invalid interval: {start}-{end}\")\n",
    "            if label == 'TERM':\n",
    "                features['english_detected_terms'].append((text, start, end,section))\n",
    "                if meta_text:\n",
    "                    features['english_terimler_org_detected'].append((text, start, end, section, meta_text))\n",
    "            elif label in ['CORRECT_TRANSLATION', 'WRONG_TRANSLATION']:\n",
    "                features['turkish_detected_terms'].append((text, start, end, section))\n",
    "                features['turkish_detected_labels'].append((text, start, end, section, label))\n",
    "                if label == 'WRONG_TRANSLATION' and meta_text:\n",
    "                    features['turkish_detected_corrections'].append((text, start, end, section, meta_text))\n",
    "    \n",
    "    results.update(features)\n",
    "    return results\n",
    "\n",
    "def calculate_term_detection_score(annotation, ground_truth, num_words_en, language='english'):\n",
    "    feature = 'english_detected_terms' if language == 'english' else 'turkish_detected_terms'\n",
    "    pred = set(annotation[feature])\n",
    "    truth = set(ground_truth[feature])\n",
    "\n",
    "    tp_set = pred.intersection(truth)\n",
    "    tp = sum(len(term[0].split()) for term in tp_set)\n",
    "    \n",
    "    fp_set = pred - truth\n",
    "    fp = sum(len(term[0].split()) for term in fp_set)\n",
    "    \n",
    "    fn_set = truth - pred\n",
    "    fn = sum(len(term[0].split()) for term in fn_set)\n",
    "    \n",
    "    tn = num_words_en - tp - fp - fn\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if tp + tn + fp + fn > 0 else 0\n",
    "    \n",
    "    all_sets = [tp_set, fp_set, fn_set]\n",
    "\n",
    "    return round(precision, 2), round(recall, 2), round(f1_score, 2), round(accuracy, 2), all_sets\n",
    "\n",
    "def calculate_exact_match(annotation, ground_truth, feature):    \n",
    "    pred = set(annotation[feature])\n",
    "    truth = set(ground_truth[feature])\n",
    "    \n",
    "    pred_first_three = {(x[0], x[1], x[2], x[3]) for x in pred}\n",
    "    truth_first_three = {(x[0], x[1], x[2], x[3] ) for x in truth}\n",
    "    \n",
    "    intersection = pred_first_three.intersection(truth_first_three)\n",
    "    \n",
    "    pred_dict = { (x[0], x[1], x[2], x[3]): x[4] for x in pred }\n",
    "    truth_dict = { (x[0], x[1], x[2], x[3]): x[4] for x in truth }\n",
    "    \n",
    "    pred = [ (x[0], x[1], x[2], x[3], pred_dict[x]) for x in intersection]\n",
    "    truth = [ (x[0], x[1], x[2],x[3], truth_dict[x]) for x in intersection]\n",
    "    \n",
    "    pred = set(pred)\n",
    "    truth = set(truth)\n",
    "    \n",
    "    intersection_num = len(pred.intersection(truth))\n",
    "    difference_num = len(truth - pred)\n",
    "    \n",
    "    intersection_set   = pred.intersection(truth)\n",
    "    difference_set = pred - truth\n",
    "    \n",
    "    all_sets = [intersection_set, difference_set]\n",
    "    \n",
    "    exact_match = intersection_num / (intersection_num + difference_num) if intersection_num + difference_num > 0 else 0\n",
    "    \n",
    "    return round(exact_match, 2), all_sets\n",
    "\n",
    "def get_annotation_scores(annotation, ground_truth, email, num_words_en, num_words_tr, intervals_for_sentences):\n",
    "    annotation = get_annotation_results(annotation, email, intervals_for_sentences)\n",
    "    precision_en_term, recall_en_term, f1_score_en_term, accuracy_en_term, sets_en_term = calculate_term_detection_score(annotation, ground_truth, num_words_en, 'english')\n",
    "    \n",
    "    precision_tr_term, recall_tr_term, f1_score_tr_term, accuracy_tr_term, sets_tr_term = calculate_term_detection_score(annotation, ground_truth, num_words_tr, 'turkish')\n",
    "    \n",
    "    exact_match_tr_labels, sets_tr_labels = calculate_exact_match(annotation, ground_truth, 'turkish_detected_labels')\n",
    "    exact_match_tr_corrections, sets_tr_corrections = calculate_exact_match(annotation, ground_truth, 'turkish_detected_corrections')\n",
    "    exact_match_en_links, sets_en_links = calculate_exact_match(annotation, ground_truth, 'english_terimler_org_detected')\n",
    "    \n",
    "    message = \"\"\n",
    "    opening_message = f\"Hello, \\n\\nHere is your performance report for task_id: {TASK_ID}.\\n\\n\"\n",
    "    message += opening_message\n",
    "    # make -- for separation\n",
    "    message += \"-\"*50 + \"\\n\"\n",
    "    message += f\"English Term Detection:\\n\"\n",
    "    number_of_correct_terms_en_term = len(sets_en_term[0])\n",
    "    message += f\"You detected {number_of_correct_terms_en_term} English Terms correctly.\\n\"\n",
    "    number_of_not_detected_terms_en_term = len(sets_en_term[2])\n",
    "    message += f\"You did not detect {number_of_not_detected_terms_en_term} English Terms which are: {sets_en_term[2]}\\n\"\n",
    "    number_of_detected_words_not_terms_en_term = len(sets_en_term[1])\n",
    "    message += f\"You labelled {number_of_detected_words_not_terms_en_term} words/phrases that are not terms which are: {sets_en_term[1]}\\n\\n\"\n",
    "    message += f\"Your scores for English Term Detection are as follows:\\n\"\n",
    "    message += f\"Precision: {precision_en_term}\\n\"\n",
    "    message += f\"Recall: {recall_en_term}\\n\"\n",
    "    message += f\"F1 Score: {f1_score_en_term}\\n\"\n",
    "    message += f\"Accuracy: {accuracy_en_term}\"\n",
    "    \n",
    "    message += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "    \n",
    "    # now turkish term detection\n",
    "    message += f\"Turkish Term Detection:\\n\"\n",
    "    number_of_correct_terms_tr_term = len(sets_tr_term[0])\n",
    "    message += f\"You detected {number_of_correct_terms_tr_term} Turkish Terms correctly.\\n\"\n",
    "    number_of_not_detected_terms_tr_term = len(sets_tr_term[2])\n",
    "    message += f\"You did not detect {number_of_not_detected_terms_tr_term} Turkish Terms which are: {sets_tr_term[2]}\\n\"\n",
    "    number_of_detected_words_not_terms_tr_term = len(sets_tr_term[1])\n",
    "    message += f\"You labelled {number_of_detected_words_not_terms_tr_term} words/phrases that are not terms which are: {sets_tr_term[1]}\\n\\n\"\n",
    "    \n",
    "    \n",
    "    # print scores for turkish term detection\n",
    "    message += f\"Your scores for Turkish Term Detection are as follows:\\n\"\n",
    "    message += f\"Precision: {precision_tr_term}\\n\"\n",
    "    message += f\"Recall: {recall_tr_term}\\n\"\n",
    "    message += f\"F1 Score: {f1_score_tr_term}\\n\"\n",
    "    message += f\"Accuracy: {accuracy_tr_term}\"\n",
    "    \n",
    "    message += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "    \n",
    "    # now turkish labels\n",
    "    message += f\"Translation Labels:\\n\"\n",
    "    number_of_correct_labels_tr_labels = len(sets_tr_labels[0])\n",
    "    message += f\"Your {number_of_correct_labels_tr_labels} Turkish Labels are valid.\\n\"\n",
    "    number_of_detected_labels_not_correct_tr_labels = len(sets_tr_labels[1])\n",
    "    message += f\"Your {number_of_detected_labels_not_correct_tr_labels} Turkish Labels are not valid which are: {sets_tr_labels[1]}\\n\\n\"\n",
    "    message += f\"Your score for Turkish Labels Detection are as follows:\\n\"\n",
    "    message += f\"Exact Match: {exact_match_tr_labels}\"\n",
    "    message += \"\\n\" + \"-\"* 50 + \"\\n\"\n",
    "    \n",
    "    # now turkish corrections\n",
    "    message += f\"Corrections for Wrong Translation:\\n\"\n",
    "    number_of_correct_corrections_tr_corrections = len(sets_tr_corrections[0])\n",
    "    message += f\"Your {number_of_correct_corrections_tr_corrections} Turkish Corrections are valid.\\n\"\n",
    "    number_of_detected_corrections_not_correct_tr_corrections = len(sets_tr_corrections[1])\n",
    "    message += f\"Your {number_of_detected_corrections_not_correct_tr_corrections} Turkish Corrections are not valid which are: {sets_tr_corrections[1]}\\n\\n\"\n",
    "    message += f\"Your score for Turkish Corrections are as follows:\\n\"\n",
    "    message += f\"Exact Match: {exact_match_tr_corrections}\"\n",
    "    message += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "    \n",
    "    # now english links\n",
    "    message += f\"English Links:\\n\"\n",
    "    number_of_correct_links_en_links = len(sets_en_links[0])\n",
    "    message += f\"Your {number_of_correct_links_en_links} English Links are valid.\\n\"\n",
    "    number_of_detected_links_not_correct_en_links = len(sets_en_links[1])\n",
    "    message += f\"Your {number_of_detected_links_not_correct_en_links} English Links are not valid which are: {sets_en_links[1]}\\n\\n\"\n",
    "    message += f\"Your score for English Links are as follows:\\n\"\n",
    "    message += f\"Exact Match: {exact_match_en_links}\"\n",
    "    message += \"\\n\" + \"-\"*50 + \"\\n\"\n",
    "    \n",
    "    # give youtube link for ground truth\n",
    "    message += f\"Here is the youtube link for the correct annotation: {YOUTUBE_LINK}\\n\"\n",
    "    \n",
    "    # please check the video for the correct annotations\n",
    "    message += f\"Please check the video for the correct annotation.\\n\"\n",
    "    return message"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Main loop\n",
    "start_time = time.time()\n",
    "while time.time() - start_time < MAX_RUNTIME:\n",
    "    print(\"Checking for new annotations...\")\n",
    "    task_data = get_task_data()\n",
    "    # print number of annotations\n",
    "    print(f\"Number of annotations: {len(task_data['annotations'])}\")\n",
    "    all_paragraph, intervals_for_sentences = extract_paragraph_data(task_data)\n",
    "    english_data, turkish_data = separate_clean_data(all_paragraph)\n",
    "    num_words_en = count_words(english_data, ['EN-1', 'EN-2', 'EN-3'])\n",
    "    num_words_tr = count_words(turkish_data, ['TR-1', 'TR-2', 'TR-3'])\n",
    "    annotations = task_data['annotations']\n",
    "    \n",
    "    \n",
    "    ground_truth = get_annotation_results(annotations[0], GROUND_TRUTH_MAIL, intervals_for_sentences)\n",
    "\n",
    "    annotation_1_message = get_annotation_scores(annotations[1], ground_truth, ANNOTATION_1_MAIL, num_words_en, num_words_tr, intervals_for_sentences)\n",
    "    if not is_mail_sended[ANNOTATION_1_MAIL]:    \n",
    "        send_email(f'Your Performance for task_id: {TASK_ID}', annotation_1_message, ANNOTATION_1_MAIL)\n",
    "    if len(annotations) > 2:\n",
    "        annotation_2_message = get_annotation_scores(annotations[2], ground_truth, ANNOTATION_2_MAIL, num_words_en, num_words_tr, intervals_for_sentences)\n",
    "        if not is_mail_sended[ANNOTATION_2_MAIL]:\n",
    "            send_email(f'Your Performance for task_id: {TASK_ID}', annotation_2_message, ANNOTATION_2_MAIL)\n",
    "    time.sleep(CHECK_INTERVAL)\n"
   ],
   "id": "9405186da9e857e4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
