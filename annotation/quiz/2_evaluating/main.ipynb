{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Importing the annotation results\n",
    "df = pd.read_csv('new_annotation_results.csv')\n",
    "COLUMNS = ['mail', 'task_1_full_annotation', 'task_2_full_annotation',\n",
    "           'task_3_full_annotation', 'task_4_full_annotation',\n",
    "           'task_5_full_annotation', 'task_6_full_annotation',\n",
    "           'task_7_full_annotation', 'task_8_full_annotation',\n",
    "           'task_9_full_annotation', 'task_10_full_annotation']\n",
    "\n",
    "df[\"number_of_tasks_completed\"] = df[COLUMNS].notnull().sum(axis=1) - 1\n",
    "\n",
    "GROUND_TRUTH_MAIL = \"gosahin@ku.edu.tr\"\n",
    "ground_truth = df[df[\"mail\"] == GROUND_TRUTH_MAIL]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_tasks_as_json(input_file):\n",
    "    with open(input_file, 'r') as f:\n",
    "        task_data = json.load(f)\n",
    "    return task_data\n",
    "\n",
    "tasks_json = read_tasks_as_json('tasks_results.json')\n",
    "\n",
    "def extract_paragraph_data(task_data):\n",
    "    all_paragraph = task_data['data']['my_text_1']\n",
    "    sections = ['TR-1', 'EN-2', 'TR-2', 'EN-3', 'TR-3']\n",
    "    positions = [all_paragraph.find(section) for section in sections] + [len(all_paragraph)]\n",
    "    intervals = [(positions[i], positions[i+1]) for i in range(len(positions) - 1)]\n",
    "    return all_paragraph, intervals\n",
    "\n",
    "def separate_clean_data(paragraph):\n",
    "    lines = paragraph.strip().split('\\n')\n",
    "    english_data, turkish_data = {}, {}\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('EN-'):\n",
    "            key, value = line.split(': ')\n",
    "            english_data[key] = value\n",
    "        elif line.startswith('TR-'):\n",
    "            key, value = line.split(': ')\n",
    "            turkish_data[key] = value\n",
    "    return english_data, turkish_data\n",
    "\n",
    "def count_words(data, keys):\n",
    "    return sum(len(data[key].split()) for key in keys)\n",
    "\n",
    "def get_annotation_results(annotation, mail, intervals_for_sentences):\n",
    "    is_ground_truth = mail == GROUND_TRUTH_MAIL\n",
    "    results = {'email': mail, 'ground_truth': is_ground_truth}\n",
    "    features = {\n",
    "        'english_detected_terms': [],\n",
    "        'turkish_detected_terms': [],\n",
    "        'turkish_detected_labels': [],\n",
    "        'turkish_detected_corrections': [],\n",
    "        'english_terimler_org_detected': []\n",
    "    }\n",
    "    \n",
    "    for item in annotation['result']:\n",
    "        if 'value' in item and 'labels' in item['value']:\n",
    "            label = item['value']['labels'][0]\n",
    "            text, start, end = item['value']['text'], item['value']['start'], item['value']['end']\n",
    "            meta_text = item.get('meta', {}).get('text', [None])[0]\n",
    "            section = None\n",
    "\n",
    "            # Check if text is not empty before modifying it\n",
    "            if text:\n",
    "                # Remove non-alphanumeric characters from the end\n",
    "                if not text[-1].isalnum():\n",
    "                    text = text[:-1]\n",
    "                    end -= 1\n",
    "                \n",
    "                # Remove non-alphanumeric characters from the beginning\n",
    "                if text and not text[0].isalnum():\n",
    "                    text = text[1:]\n",
    "                    start += 1\n",
    "\n",
    "            # Determine the section based on the start and end positions\n",
    "            if 0 <= start < end <= intervals_for_sentences[0][0]:\n",
    "                section = 'EN-1'\n",
    "            elif intervals_for_sentences[0][0] <= start <= end <= intervals_for_sentences[0][1]:\n",
    "                section = 'TR-1'\n",
    "            elif intervals_for_sentences[1][0] <= start <= end <= intervals_for_sentences[1][1]:\n",
    "                section = 'EN-2'\n",
    "            elif intervals_for_sentences[2][0] <= start <= end <= intervals_for_sentences[2][1]:\n",
    "                section = 'TR-2'\n",
    "            elif intervals_for_sentences[3][0] <= start <= end <= intervals_for_sentences[3][1]:\n",
    "                section = 'EN-3'\n",
    "            elif intervals_for_sentences[4][0] <= start <= end <= intervals_for_sentences[4][1]:\n",
    "                section = 'TR-3'\n",
    "                \n",
    "                \n",
    "            if text:  # Only process if text is not empty\n",
    "                if label == 'TERM':\n",
    "                    features['english_detected_terms'].append((text, start, end, section))\n",
    "                    if meta_text:\n",
    "                        features['english_terimler_org_detected'].append((text, start, end, section, meta_text))\n",
    "                elif label in ['CORRECT_TRANSLATION', 'WRONG_TRANSLATION']:\n",
    "                    features['turkish_detected_terms'].append((text, start, end, section))\n",
    "                    features['turkish_detected_labels'].append((text, start, end, section, label))\n",
    "                    if label == 'WRONG_TRANSLATION' and meta_text:\n",
    "                        features['turkish_detected_corrections'].append((text, start, end, section, meta_text))\n",
    "    \n",
    "    results.update(features)\n",
    "    return results\n",
    "\n",
    "def calculate_term_detection_score(annotation, ground_truth, num_words, language='english'):\n",
    "    feature = 'english_detected_terms' if language == 'english' else 'turkish_detected_terms'\n",
    "    pred = set(annotation[feature])\n",
    "    truth = set(ground_truth[feature])\n",
    "\n",
    "    tp_set = pred.intersection(truth)\n",
    "    tp = sum(len(term[0].split()) for term in tp_set)\n",
    "    \n",
    "    fp_set = pred - truth\n",
    "    fp = sum(len(term[0].split()) for term in fp_set)\n",
    "    \n",
    "    fn_set = truth - pred\n",
    "    fn = sum(len(term[0].split()) for term in fn_set)\n",
    "    \n",
    "    tn = num_words - tp - fp - fn\n",
    "\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if tp + tn + fp + fn > 0 else 0\n",
    "    \n",
    "    result = {'precision': precision, 'recall': recall, 'f1_score': f1_score, 'accuracy': accuracy, 'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn, 'tp_set': tp_set, 'fp_set': fp_set, 'fn_set': fn_set, 'name': feature}\n",
    "\n",
    "    return result\n",
    "\n",
    "def calculate_exact_match(annotation, ground_truth, feature):    \n",
    "    pred = set(annotation[feature])\n",
    "    truth = set(ground_truth[feature])\n",
    "    \n",
    "    pred_first_three = {(x[0], x[1], x[2], x[3]) for x in pred}\n",
    "    truth_first_three = {(x[0], x[1], x[2], x[3]) for x in truth}\n",
    "    \n",
    "    intersection = pred_first_three.intersection(truth_first_three)\n",
    "    \n",
    "    pred_dict = { (x[0], x[1], x[2], x[3]): x[4] for x in pred }\n",
    "    truth_dict = { (x[0], x[1], x[2], x[3]): x[4] for x in truth }\n",
    "    \n",
    "    pred = [ (x[0], x[1], x[2], x[3], pred_dict[x]) for x in intersection]\n",
    "    truth = [ (x[0], x[1], x[2],x[3], truth_dict[x]) for x in intersection]\n",
    "    \n",
    "    pred = set(pred)\n",
    "    truth = set(truth)\n",
    "    \n",
    "    intersection_num = len(pred.intersection(truth))\n",
    "    difference_num = len(truth - pred)\n",
    "    \n",
    "    intersection_set   = pred.intersection(truth)\n",
    "    difference_set = pred - truth\n",
    "    \n",
    "    exact_match = intersection_num / (intersection_num + difference_num) if intersection_num + difference_num > 0 else 0\n",
    "    \n",
    "    result = { 'intersection_set': intersection_set, 'difference_set': difference_set, 'exact_match': exact_match, 'name': feature}\n",
    "    \n",
    "    return result\n"
   ],
   "id": "b5a8c577e8896507",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize a list to store all results for each annotator\n",
    "all_annotator_results = []\n",
    "\n",
    "\n",
    "# Loop through each annotator\n",
    "for index, row in df.iterrows():\n",
    "    ANNOTATOR_MAIL = row['mail']\n",
    "    annotator_results = {}\n",
    "\n",
    "    # Initialize cumulative metrics\n",
    "    total_tp_english_term_detection = 0\n",
    "    total_fp_english_term_detection = 0\n",
    "    total_fn_english_term_detection = 0\n",
    "    total_tn_english_term_detection = 0\n",
    "    total_num_words_en = 0\n",
    "    \n",
    "    total_tp_turkish_term_detection = 0\n",
    "    total_fp_turkish_term_detection = 0\n",
    "    total_fn_turkish_term_detection = 0\n",
    "    total_tn_turkish_term_detection = 0\n",
    "    \n",
    "    total_intersection_turkish_labels = 0\n",
    "    total_difference_turkish_labels = 0\n",
    "    \n",
    "    total_intersection_turkish_corrections = 0\n",
    "    total_difference_turkish_corrections = 0\n",
    "    \n",
    "    total_intersection_english_term_linking = 0\n",
    "    total_difference_english_term_linking = 0\n",
    "\n",
    "    # Loop through each task from 1 to 10\n",
    "    for task_num in range(1, 11):\n",
    "        # Get the annotator's task data\n",
    "        annotator_task = row[f'task_{task_num}_full_annotation']\n",
    "\n",
    "        \n",
    "        # Check if the annotator's task data is NaN\n",
    "        if pd.isna(annotator_task):\n",
    "            # If NaN, set all relevant columns to NaN\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_tp'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fp'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fn'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_tn'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_precision'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_recall'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_f1_score'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_accuracy'] = float('nan')\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_tp'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fp'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fn'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_tn'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_precision'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_recall'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_f1_score'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_accuracy'] = float('nan')\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_labels_exact_match'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_exact_match'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_linking_exact_match'] = float('nan')\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_english_term_detection_tp_set'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fp_set'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fn_set'] = float('nan')\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_tp_set'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fp_set'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fn_set'] = float('nan')\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_labels_intersection_set'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_labels_difference_set'] = float('nan')\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_intersection_set'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_difference_set'] = float('nan')\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_english_term_linking_intersection_set'] = float('nan')\n",
    "            annotator_results[f'task_{task_num}_english_term_linking_difference_set'] = float('nan')\n",
    "        \n",
    "        else:\n",
    "            # If not NaN, proceed with the regular processing\n",
    "            ground_truth_task = eval(ground_truth[f'task_{task_num}_full_annotation'].values[0])\n",
    "            annotator_task = eval(annotator_task)\n",
    "            \n",
    "            # Extract paragraph data and intervals\n",
    "            all_paragraph, intervals_for_sentences = extract_paragraph_data(tasks_json[task_num - 1])\n",
    "            \n",
    "            # Separate and count words in English and Turkish\n",
    "            english_data, turkish_data = separate_clean_data(all_paragraph)\n",
    "            num_words_en = count_words(english_data, ['EN-1', 'EN-2', 'EN-3'])\n",
    "            num_words_tr = count_words(turkish_data, ['TR-1', 'TR-2', 'TR-3'])\n",
    "            \n",
    "            # Get annotation results for both ground truth and the current annotator\n",
    "            ground_truth_annotation_results = get_annotation_results(ground_truth_task, GROUND_TRUTH_MAIL, intervals_for_sentences)\n",
    "            annotator_annotation_results = get_annotation_results(annotator_task, ANNOTATOR_MAIL, intervals_for_sentences)\n",
    "            \n",
    "            # Calculate English and Turkish term detection metrics\n",
    "            english_term_detection_data = calculate_term_detection_score(annotator_annotation_results, ground_truth_annotation_results, num_words_en, 'english')\n",
    "            turkish_term_detection_data = calculate_term_detection_score(annotator_annotation_results, ground_truth_annotation_results, num_words_tr, 'turkish')\n",
    "            \n",
    "            # Calculate exact matches for Turkish labels and corrections, and English term linking\n",
    "            turkish_labels_exact_match_data = calculate_exact_match(annotator_annotation_results, ground_truth_annotation_results, 'turkish_detected_labels')\n",
    "            turkish_corrections_exact_match_data = calculate_exact_match(annotator_annotation_results, ground_truth_annotation_results, 'turkish_detected_corrections')\n",
    "            english_term_linking_exact_match_data = calculate_exact_match(annotator_annotation_results, ground_truth_annotation_results, 'english_terimler_org_detected')\n",
    "            \n",
    "            # Store the metrics in the dictionary for the current annotator\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_tp'] = english_term_detection_data['tp']\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fp'] = english_term_detection_data['fp']\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fn'] = english_term_detection_data['fn']\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_tn'] = english_term_detection_data['tn']\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_precision'] = english_term_detection_data['precision']\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_recall'] = english_term_detection_data['recall']\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_f1_score'] = english_term_detection_data['f1_score']\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_accuracy'] = english_term_detection_data['accuracy']\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_tp'] = turkish_term_detection_data['tp']\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fp'] = turkish_term_detection_data['fp']\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fn'] = turkish_term_detection_data['fn']\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_tn'] = turkish_term_detection_data['tn']\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_precision'] = turkish_term_detection_data['precision']\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_recall'] = turkish_term_detection_data['recall']\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_f1_score'] = turkish_term_detection_data['f1_score']\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_accuracy'] = turkish_term_detection_data['accuracy']\n",
    "            \n",
    "            # Store exact match results\n",
    "            annotator_results[f'task_{task_num}_turkish_labels_exact_match'] = turkish_labels_exact_match_data['exact_match']\n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_exact_match'] = turkish_corrections_exact_match_data['exact_match']\n",
    "            annotator_results[f'task_{task_num}_english_term_linking_exact_match'] = english_term_linking_exact_match_data['exact_match']\n",
    "            \n",
    "            # Store sets as strings in the dictionary for the current annotator\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_tp_set'] = str(english_term_detection_data['tp_set'])\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fp_set'] = str(english_term_detection_data['fp_set'])\n",
    "            annotator_results[f'task_{task_num}_english_term_detection_fn_set'] = str(english_term_detection_data['fn_set'])\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_tp_set'] = str(turkish_term_detection_data['tp_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fp_set'] = str(turkish_term_detection_data['fp_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_term_detection_fn_set'] = str(turkish_term_detection_data['fn_set'])\n",
    "            \n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_labels_intersection_set'] = str(turkish_labels_exact_match_data['intersection_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_labels_difference_set'] = str(turkish_labels_exact_match_data['difference_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_labels_intersection_num'] = len(turkish_labels_exact_match_data['intersection_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_labels_difference_num'] = len(turkish_labels_exact_match_data['difference_set'])\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_intersection_set'] = str(turkish_corrections_exact_match_data['intersection_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_difference_set'] = str(turkish_corrections_exact_match_data['difference_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_intersection_num'] = len(turkish_corrections_exact_match_data['intersection_set'])\n",
    "            annotator_results[f'task_{task_num}_turkish_corrections_difference_num'] = len(turkish_corrections_exact_match_data['difference_set'])\n",
    "            \n",
    "            annotator_results[f'task_{task_num}_english_term_linking_intersection_set'] = str(english_term_linking_exact_match_data['intersection_set'])\n",
    "            annotator_results[f'task_{task_num}_english_term_linking_difference_set'] = str(english_term_linking_exact_match_data['difference_set'])\n",
    "            annotator_results[f'task_{task_num}_english_term_linking_intersection_num'] = len(english_term_linking_exact_match_data['intersection_set'])\n",
    "            annotator_results[f'task_{task_num}_english_term_linking_difference_num'] = len(english_term_linking_exact_match_data['difference_set'])\n",
    "\n",
    "            # Update cumulative metrics\n",
    "            total_tp_english_term_detection += english_term_detection_data['tp']\n",
    "            total_fp_english_term_detection += english_term_detection_data['fp']\n",
    "            total_fn_english_term_detection += english_term_detection_data['fn']\n",
    "            total_tn_english_term_detection += english_term_detection_data['tn']\n",
    "            \n",
    "            total_tp_turkish_term_detection += turkish_term_detection_data['tp']\n",
    "            total_fp_turkish_term_detection += turkish_term_detection_data['fp']\n",
    "            total_fn_turkish_term_detection += turkish_term_detection_data['fn']\n",
    "            total_tn_turkish_term_detection += turkish_term_detection_data['tn']\n",
    "            \n",
    "            total_intersection_turkish_labels += len(turkish_labels_exact_match_data['intersection_set'])\n",
    "            total_difference_turkish_labels += len(turkish_labels_exact_match_data['difference_set'])\n",
    "            \n",
    "            total_intersection_turkish_corrections += len(turkish_corrections_exact_match_data['intersection_set'])\n",
    "            total_difference_turkish_corrections += len(turkish_corrections_exact_match_data['difference_set'])\n",
    "            \n",
    "            total_intersection_english_term_linking += len(english_term_linking_exact_match_data['intersection_set'])\n",
    "            total_difference_english_term_linking += len(english_term_linking_exact_match_data['difference_set'])\n",
    "\n",
    "\n",
    "    # Calculate cumulative metrics\n",
    "    cumulative_english_term_detection_data = {\n",
    "        'tp': total_tp_english_term_detection,\n",
    "        'fp': total_fp_english_term_detection,\n",
    "        'fn': total_fn_english_term_detection,\n",
    "        'tn': total_tn_english_term_detection\n",
    "    }\n",
    "    \n",
    "    cumulative_turkish_term_detection_data = {\n",
    "        'tp': total_tp_turkish_term_detection,\n",
    "        'fp': total_fp_turkish_term_detection,\n",
    "        'fn': total_fn_turkish_term_detection,\n",
    "        'tn': total_tn_turkish_term_detection\n",
    "    }\n",
    "    \n",
    "    cumulative_turkish_labels_exact_match_data = {\n",
    "        'intersection_num': total_intersection_turkish_labels,\n",
    "        'difference_num': total_difference_turkish_labels\n",
    "    }\n",
    "    \n",
    "    cumulative_turkish_corrections_exact_match_data = {\n",
    "        'intersection_num': total_intersection_turkish_corrections,\n",
    "        'difference_num': total_difference_turkish_corrections\n",
    "    }\n",
    "    \n",
    "    cumulative_english_term_linking_exact_match_data = {\n",
    "        'intersection_num': total_intersection_english_term_linking,\n",
    "        'difference_num': total_difference_english_term_linking\n",
    "    }\n",
    "    \n",
    "    # Calculate cumulative scores\n",
    "    cumulative_english_term_detection_precision = cumulative_english_term_detection_data['tp'] / (cumulative_english_term_detection_data['tp'] + cumulative_english_term_detection_data['fp']) if cumulative_english_term_detection_data['tp'] + cumulative_english_term_detection_data['fp'] > 0 else 0\n",
    "    \n",
    "    cumulative_english_term_detection_recall = cumulative_english_term_detection_data['tp'] / (cumulative_english_term_detection_data['tp'] + cumulative_english_term_detection_data['fn']) if cumulative_english_term_detection_data['tp'] + cumulative_english_term_detection_data['fn'] > 0 else 0\n",
    "    \n",
    "    cumulative_english_term_detection_f1_score = (2 * cumulative_english_term_detection_precision * cumulative_english_term_detection_recall) / (cumulative_english_term_detection_precision + cumulative_english_term_detection_recall) if cumulative_english_term_detection_precision + cumulative_english_term_detection_recall > 0 else 0\n",
    "    \n",
    "    cumulative_english_term_detection_accuracy = (cumulative_english_term_detection_data['tp'] + cumulative_english_term_detection_data['tn']) / (cumulative_english_term_detection_data['tp'] + cumulative_english_term_detection_data['tn'] + cumulative_english_term_detection_data['fp'] + cumulative_english_term_detection_data['fn']) if cumulative_english_term_detection_data['tp'] + cumulative_english_term_detection_data['tn'] + cumulative_english_term_detection_data['fp'] + cumulative_english_term_detection_data['fn'] > 0 else 0\n",
    "    \n",
    "    cumulative_turkish_term_detection_precision = cumulative_turkish_term_detection_data['tp'] / (cumulative_turkish_term_detection_data['tp'] + cumulative_turkish_term_detection_data['fp']) if cumulative_turkish_term_detection_data['tp'] + cumulative_turkish_term_detection_data['fp'] > 0 else 0\n",
    "    \n",
    "    cumulative_turkish_term_detection_recall = cumulative_turkish_term_detection_data['tp'] / (cumulative_turkish_term_detection_data['tp'] + cumulative_turkish_term_detection_data['fn']) if cumulative_turkish_term_detection_data['tp'] + cumulative_turkish_term_detection_data['fn'] > 0 else 0\n",
    "    \n",
    "    cumulative_turkish_term_detection_f1_score = (2 * cumulative_turkish_term_detection_precision * cumulative_turkish_term_detection_recall) / (cumulative_turkish_term_detection_precision + cumulative_turkish_term_detection_recall) if cumulative_turkish_term_detection_precision + cumulative_turkish_term_detection_recall > 0 else 0\n",
    "    \n",
    "    cumulative_turkish_term_detection_accuracy = (cumulative_turkish_term_detection_data['tp'] + cumulative_turkish_term_detection_data['tn']) / (cumulative_turkish_term_detection_data['tp'] + cumulative_turkish_term_detection_data['tn'] + cumulative_turkish_term_detection_data['fp'] + cumulative_turkish_term_detection_data['fn']) if cumulative_turkish_term_detection_data['tp'] + cumulative_turkish_term_detection_data['tn'] + cumulative_turkish_term_detection_data['fp'] + cumulative_turkish_term_detection_data['fn'] > 0 else 0\n",
    "    \n",
    "    \n",
    "    # Calculate cumulative exact matches\n",
    "    cumulative_turkish_labels_exact_match = cumulative_turkish_labels_exact_match_data['intersection_num'] / (cumulative_turkish_labels_exact_match_data['intersection_num'] + cumulative_turkish_labels_exact_match_data['difference_num']) if cumulative_turkish_labels_exact_match_data['intersection_num'] + cumulative_turkish_labels_exact_match_data['difference_num'] > 0 else 0\n",
    "    \n",
    "    cumulative_turkish_corrections_exact_match = cumulative_turkish_corrections_exact_match_data['intersection_num'] / (cumulative_turkish_corrections_exact_match_data['intersection_num'] + cumulative_turkish_corrections_exact_match_data['difference_num']) if cumulative_turkish_corrections_exact_match_data['intersection_num'] + cumulative_turkish_corrections_exact_match_data['difference_num'] > 0 else 0\n",
    "    \n",
    "    cumulative_english_term_linking_exact_match = cumulative_english_term_linking_exact_match_data['intersection_num'] / (cumulative_english_term_linking_exact_match_data['intersection_num'] + cumulative_english_term_linking_exact_match_data['difference_num']) if cumulative_english_term_linking_exact_match_data['intersection_num'] + cumulative_english_term_linking_exact_match_data['difference_num'] > 0 else 0\n",
    "    \n",
    "    # Store the cumulative metrics in the dictionary for the current annotator\n",
    "    \n",
    "    annotator_results['cumulative_english_term_detection_tp'] = cumulative_english_term_detection_data['tp']\n",
    "    annotator_results['cumulative_english_term_detection_fp'] = cumulative_english_term_detection_data['fp']\n",
    "    annotator_results['cumulative_english_term_detection_fn'] = cumulative_english_term_detection_data['fn']\n",
    "    annotator_results['cumulative_english_term_detection_tn'] = cumulative_english_term_detection_data['tn']\n",
    "    \n",
    "    annotator_results['cumulative_english_term_detection_precision'] = cumulative_english_term_detection_precision\n",
    "    annotator_results['cumulative_english_term_detection_recall'] = cumulative_english_term_detection_recall\n",
    "    annotator_results['cumulative_english_term_detection_f1_score'] = cumulative_english_term_detection_f1_score\n",
    "    annotator_results['cumulative_english_term_detection_accuracy'] = cumulative_english_term_detection_accuracy\n",
    "    \n",
    "    annotator_results['cumulative_turkish_term_detection_tp'] = cumulative_turkish_term_detection_data['tp']\n",
    "    annotator_results['cumulative_turkish_term_detection_fp'] = cumulative_turkish_term_detection_data['fp']\n",
    "    annotator_results['cumulative_turkish_term_detection_fn'] = cumulative_turkish_term_detection_data['fn']\n",
    "    annotator_results['cumulative_turkish_term_detection_tn'] = cumulative_turkish_term_detection_data['tn']\n",
    "    \n",
    "    annotator_results['cumulative_turkish_term_detection_precision'] = cumulative_turkish_term_detection_precision\n",
    "    annotator_results['cumulative_turkish_term_detection_recall'] = cumulative_turkish_term_detection_recall\n",
    "    annotator_results['cumulative_turkish_term_detection_f1_score'] = cumulative_turkish_term_detection_f1_score\n",
    "    annotator_results['cumulative_turkish_term_detection_accuracy'] = cumulative_turkish_term_detection_accuracy\n",
    "\n",
    "    annotator_results['cumulative_turkish_labels_intersection_num'] = cumulative_turkish_labels_exact_match_data['intersection_num']\n",
    "    annotator_results['cumulative_turkish_labels_difference_num'] = cumulative_turkish_labels_exact_match_data['difference_num']\n",
    "    annotator_results['cumulative_turkish_labels_exact_match'] = cumulative_turkish_labels_exact_match\n",
    "    \n",
    "    annotator_results['cumulative_turkish_corrections_intersection_num'] = cumulative_turkish_corrections_exact_match_data['intersection_num']\n",
    "    annotator_results['cumulative_turkish_corrections_difference_num'] = cumulative_turkish_corrections_exact_match_data['difference_num']\n",
    "    annotator_results['cumulative_turkish_corrections_exact_match'] = cumulative_turkish_corrections_exact_match\n",
    "    \n",
    "    annotator_results['cumulative_english_term_linking_intersection_num'] = cumulative_english_term_linking_exact_match_data['intersection_num']\n",
    "    annotator_results['cumulative_english_term_linking_difference_num'] = cumulative_english_term_linking_exact_match_data['difference_num']\n",
    "    annotator_results['cumulative_english_term_linking_exact_match'] = cumulative_english_term_linking_exact_match\n",
    "    \n",
    "    # Append results to the list\n",
    "    all_annotator_results.append(annotator_results)\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame and concatenate it with the original DataFrame\n",
    "all_annotator_results_df = pd.DataFrame(all_annotator_results, index=df.index)\n",
    "df = pd.concat([df, all_annotator_results_df], axis=1)\n"
   ],
   "id": "e8b47be3849113b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Save the results to a CSV file\n",
    "df.to_csv('results/3_all_results_old_ground_truth_ibrahim.csv', index=False)\n",
    "# drop task_1_full_annotation, task_2_full_annotation, task_3_full_annotation, task_4_full_annotation, task_5_full_annotation, task_6_full_annotation, task_7_full_annotation, task_8_full_annotation, task_9_full_annotation, task_10_full_annotation\n",
    "df.drop(['task_1_full_annotation', 'task_2_full_annotation', 'task_3_full_annotation', 'task_4_full_annotation', 'task_5_full_annotation', 'task_6_full_annotation', 'task_7_full_annotation', 'task_8_full_annotation', 'task_9_full_annotation', 'task_10_full_annotation'], axis=1, inplace=True)\n",
    "\n",
    "df.to_csv('results/4_only_metrics_old_ground_truth_ibrahim.csv', index=False)"
   ],
   "id": "df4ac231c78b32a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_excel('results/4_only_metrics_old_ground_truth_ibrahim.xlsx', index=False)",
   "id": "4db621763db1e247",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
