{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_all = pd.read_excel('results/df_all.xlsx')\n",
    "\n",
    "\n",
    "# Function to generate message for a given task and annotator\n",
    "def generate_task_message(annotator_mail, task_number, ground_truth_mail):\n",
    "    task_prefix = f'task_{task_number}'\n",
    "    \n",
    "    # Filter the relevant columns for the specific task\n",
    "    task_columns = [col for col in df_all.columns if col.startswith(task_prefix)]\n",
    "    \n",
    "    # Extract data for the specific annotator and ground truth\n",
    "    annotator_data = df_all.loc[df_all['mail'] == annotator_mail, ['mail'] + task_columns].squeeze()\n",
    "    ground_truth_data = df_all.loc[df_all['mail'] == ground_truth_mail, task_columns].squeeze()\n",
    "    \n",
    "    if annotator_data.empty:\n",
    "        return f\"No data found for {annotator_mail} on Task {task_number}.\"\n",
    "    \n",
    "    if ground_truth_data.empty:\n",
    "        return f\"No ground truth data found for {ground_truth_mail} on Task {task_number}.\"\n",
    "    \n",
    "    # Begin constructing the message\n",
    "    message = f\"Task {task_number} results are as follows:\\n\"\n",
    "\n",
    "    # English Term Detection\n",
    "    message += (\n",
    "        \"1. English Term Detection:\\n\"\n",
    "        f\"    - Number of TP: {annotator_data.get(f'{task_prefix}_english_term_detection_tp', 'N/A')}\\n\"\n",
    "        f\"    - Number of FP: {annotator_data.get(f'{task_prefix}_english_term_detection_fp', 'N/A')}\\n\"\n",
    "    )\n",
    "\n",
    "    # Process FP Set\n",
    "    fp_set = eval(annotator_data.get(f'{task_prefix}_english_term_detection_fp_set', '[]'))\n",
    "    message += ''.join(f'    \\t * \"{word}\" in {sentence_index} is incorrectly labeled as a term.\\n' for word, _, _, sentence_index in fp_set)\n",
    "\n",
    "    message += f\"    - Number of FN: {annotator_data.get(f'{task_prefix}_english_term_detection_fn', 'N/A')}\\n\"\n",
    "\n",
    "    # Process FN Set\n",
    "    fn_set = eval(annotator_data.get(f'{task_prefix}_english_term_detection_fn_set', '[]'))\n",
    "    message += ''.join(f'    \\t * \"{word}\" is a term in {sentence_index} but you missed it.\\n' for word, _, _, sentence_index in fn_set)\n",
    "\n",
    "    # Add Precision, Recall, F1 Score, and Accuracy\n",
    "    message += (\n",
    "        f\"    - Precision: {annotator_data.get(f'{task_prefix}_english_term_detection_precision', 'N/A'):.2%}\\n\"\n",
    "        f\"    - Recall: {annotator_data.get(f'{task_prefix}_english_term_detection_recall', 'N/A'):.2%}\\n\"\n",
    "        f\"    - F1 Score: {annotator_data.get(f'{task_prefix}_english_term_detection_f1_score', 'N/A'):.2%}\\n\"\n",
    "        f\"    - Accuracy: {annotator_data.get(f'{task_prefix}_english_term_detection_accuracy', 'N/A'):.2%}\\n\"\n",
    "    )\n",
    "\n",
    "    # Turkish Term Detection\n",
    "    message += (\n",
    "        \"2. Turkish Term Detection:\\n\"\n",
    "        f\"    - Number of TP: {annotator_data.get(f'{task_prefix}_turkish_term_detection_tp', 'N/A')}\\n\"\n",
    "        f\"    - Number of FP: {annotator_data.get(f'{task_prefix}_turkish_term_detection_fp', 'N/A')}\\n\"\n",
    "    )\n",
    "\n",
    "    # Process Turkish FP Set\n",
    "    fp_set = eval(annotator_data.get(f'{task_prefix}_turkish_term_detection_fp_set', '[]'))\n",
    "    message += ''.join(f'    \\t * \"{word}\" in {sentence_index} is incorrectly labeled as a term.\\n' for word, _, _, sentence_index in fp_set)\n",
    "\n",
    "    message += f\"    - Number of FN: {annotator_data.get(f'{task_prefix}_turkish_term_detection_fn', 'N/A')}\\n\"\n",
    "\n",
    "    # Process Turkish FN Set\n",
    "    fn_set = eval(annotator_data.get(f'{task_prefix}_turkish_term_detection_fn_set', '[]'))\n",
    "    message += ''.join(f'    \\t * \"{word}\" is a term in {sentence_index} but you missed it.\\n' for word, _, _, sentence_index in fn_set)\n",
    "\n",
    "    # Add Precision, Recall, F1 Score, and Accuracy for Turkish Term Detection\n",
    "    message += (\n",
    "        f\"    - Precision: {annotator_data.get(f'{task_prefix}_turkish_term_detection_precision', 'N/A'):.2%}\\n\"\n",
    "        f\"    - Recall: {annotator_data.get(f'{task_prefix}_turkish_term_detection_recall', 'N/A'):.2%}\\n\"\n",
    "        f\"    - F1 Score: {annotator_data.get(f'{task_prefix}_turkish_term_detection_f1_score', 'N/A'):.2%}\\n\"\n",
    "        f\"    - Accuracy: {annotator_data.get(f'{task_prefix}_turkish_term_detection_accuracy', 'N/A'):.2%}\\n\"\n",
    "    )\n",
    "\n",
    "    # Turkish Translation Labels\n",
    "    message += (\n",
    "        \"3. Turkish Translation Labels:\\n\"\n",
    "        f\"    - Number of Intersection: {annotator_data.get(f'{task_prefix}_turkish_labels_intersection_num', 'N/A')}\\n\"\n",
    "        f\"    - Number of Difference: {annotator_data.get(f'{task_prefix}_turkish_labels_difference_num', 'N/A')}\\n\"\n",
    "        f\"    - Exact Match: {annotator_data.get(f'{task_prefix}_turkish_labels_exact_match', 'N/A'):.2%}\\n\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Process Turkish Translation Labels Difference Set\n",
    "    difference_set = eval(annotator_data.get(f'{task_prefix}_turkish_labels_difference_set', '[]'))\n",
    "    ground_truth_label_set = eval(ground_truth_data.get(f'{task_prefix}_turkish_labels_intersection_set', '[]'))\n",
    "    \n",
    "    # get the indicies of the same start, end tuples\n",
    "    same_indices = []\n",
    "    for i, (word, start, end, sentence_index, label) in enumerate(difference_set):\n",
    "        for j, (word_gt, start_gt, end_gt, sentence_index_gt, label_gt) in enumerate(ground_truth_label_set):\n",
    "            if start == start_gt and end == end_gt:\n",
    "                same_indices.append((i, j))\n",
    "                break\n",
    "    \n",
    "    same_indices = list(set(same_indices))\n",
    "    difference_set = list(difference_set)\n",
    "    ground_truth_label_set = list(ground_truth_label_set)\n",
    "    \n",
    "    for i, j in same_indices:\n",
    "        word, start, end, sentence_index, label = difference_set[i]\n",
    "        word_gt, start_gt, end_gt, sentence_index_gt, label_gt = ground_truth_label_set[j]\n",
    "        if label != label_gt:\n",
    "            message += f'    \\t * \"{word}\" is labeled as \"{label}\" in {sentence_index} but it should be \"{label_gt}\".\\n'\n",
    "    \n",
    "\n",
    "    # Turkish Translation Corrections\n",
    "    message += (\n",
    "        \"4. Turkish Translation Corrections:\\n\"\n",
    "        f\"    - Number of Intersection: {annotator_data.get(f'{task_prefix}_turkish_corrections_intersection_num', 'N/A')}\\n\"\n",
    "        f\"    - Number of Difference: {annotator_data.get(f'{task_prefix}_turkish_corrections_difference_num', 'N/A')}\\n\"\n",
    "    )\n",
    "    difference_set_turkish_corrections= eval(annotator_data.get(f'{task_prefix}_turkish_corrections_difference_set', '[]'))\n",
    "    ground_truth_correction_set = eval(ground_truth_data.get(f'{task_prefix}_turkish_corrections_intersection_set', '[]'))\n",
    "    \n",
    "    # get the indicies of the same start, end tuples \n",
    "    same_indices = []\n",
    "    for i, (word, start, end, sentence_index, label) in enumerate(difference_set_turkish_corrections):\n",
    "        for j, (word_gt, start_gt, end_gt, sentence_index_gt, label_gt) in enumerate(ground_truth_correction_set):\n",
    "            if start == start_gt and end == end_gt:\n",
    "                same_indices.append((i, j))\n",
    "                break\n",
    "    \n",
    "    same_indices = list(set(same_indices))\n",
    "    difference_set_turkish_corrections = list(difference_set_turkish_corrections)\n",
    "    ground_truth_correction_set = list(ground_truth_correction_set)\n",
    "    \n",
    "    \n",
    "    for i, j in same_indices:\n",
    "        word, start, end, sentence_index, label = difference_set_turkish_corrections[i]\n",
    "        word_gt, start_gt, end_gt, sentence_index_gt, label_gt = ground_truth_correction_set[j]\n",
    "        if label != label_gt:\n",
    "            message += f'    \\t * \"{word}\" is rectified as \"{label}\" in {sentence_index} but it should be \"{label_gt}\".\\n'\n",
    "\n",
    "\n",
    "        \n",
    "    # exact match score\n",
    "    message += f\"    - Exact Match: {annotator_data.get(f'{task_prefix}_turkish_corrections_exact_match', 'N/A'):.2%}\\n\"\n",
    "    \n",
    "    # 5. English Term Linking\n",
    "    message += (\n",
    "        \"5. English Term Linking:\\n\"\n",
    "        f\"    - Number of TP: {annotator_data.get(f'{task_prefix}_english_term_linking_intersection_num', 'N/A')}\\n\"\n",
    "        f\"    - Number of Difference: {annotator_data.get(f'{task_prefix}_english_term_linking_difference_num', 'N/A')}\\n\"\n",
    "    )\n",
    "    \n",
    "    # Process English Term Linking Difference Set\n",
    "    difference_set_english_term_linking = eval(annotator_data.get(f'{task_prefix}_english_term_linking_difference_set', '[]'))\n",
    "    ground_truth_linking_set = eval(ground_truth_data.get(f'{task_prefix}_english_term_linking_intersection_set', '[]'))\n",
    "    \n",
    "    # get the indicies of the same start, end tuples\n",
    "    same_indices = []\n",
    "    for i, (word, start, end, sentence_index, label) in enumerate(difference_set_english_term_linking):\n",
    "        for j, (word_gt, start_gt, end_gt, sentence_index_gt, label_gt) in enumerate(ground_truth_linking_set):\n",
    "            if start == start_gt and end == end_gt:\n",
    "                same_indices.append((i, j))\n",
    "                break\n",
    "    \n",
    "    same_indices = list(set(same_indices))\n",
    "    difference_set_english_term_linking = list(difference_set_english_term_linking)\n",
    "    ground_truth_linking_set = list(ground_truth_linking_set)\n",
    "    \n",
    "    for i, j in same_indices:\n",
    "        word, start, end, sentence_index, label = difference_set_english_term_linking[i]\n",
    "        word_gt, start_gt, end_gt, sentence_index_gt, label_gt = ground_truth_linking_set[j]\n",
    "        if label != label_gt:\n",
    "            message += f'    \\t * \"{word}\" is linked as \"{label}\" in {sentence_index} but it should be \"{label_gt}\".\\n'\n",
    "    \n",
    "    # exact match score\n",
    "    message += f\"    - Exact Match: {annotator_data.get(f'{task_prefix}_english_term_linking_exact_match', 'N/A'):.2%}\\n\"\n",
    "    \n",
    "\n",
    "    return message\n",
    "\n",
    "\n",
    "# Example usage\n",
    "annotator_mail = ''\n",
    "task_number = 10\n",
    "GROUND_TRUTH_MAIL = ''\n",
    "print(generate_task_message(annotator_mail, task_number, GROUND_TRUTH_MAIL))\n"
   ],
   "id": "202eba6cb5da3e8e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
