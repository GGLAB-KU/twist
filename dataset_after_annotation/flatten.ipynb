{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "export_term_pairs.py\n",
    "--------------------\n",
    "Flatten the `term_pairs` in dataset.json into a tidy CSV.\n",
    "\n",
    "Usage:\n",
    "    python3 export_term_pairs.py\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Configuration – change these paths if your files live elsewhere\n",
    "# --------------------------------------------------------------------------- #\n",
    "DATA_PATH = Path(\"dataset.json\")        # input JSON\n",
    "OUT_CSV   = Path(\"dataset.xlsx\")      # output CSV\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Helper functions\n",
    "# --------------------------------------------------------------------------- #\n",
    "def load_json(path: Path):\n",
    "    \"\"\"Read a JSON file and return the parsed Python object.\"\"\"\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def flatten_term_pairs(records):\n",
    "    \"\"\"\n",
    "    Turn each (sentence, term_pair) combination into a single flat dict.\n",
    "\n",
    "    Returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for sent in records:\n",
    "        # sentence-level fields to carry over\n",
    "        base = {\n",
    "            \"id\"             : sent.get(\"id\"),\n",
    "            \"global_id\"      : sent.get(\"global_id\"),\n",
    "            \"sentence_id\"    : sent.get(\"sentence_id\"),\n",
    "            \"data_source\"    : sent.get(\"data_source\"),\n",
    "            \"category\"       : sent.get(\"category\"),\n",
    "            \"wikipedia_id\"   : sent.get(\"wikipedia_id\"),\n",
    "            \"yok_id\"         : sent.get(\"yok_id\"),\n",
    "            \"source_sentence\": sent.get(\"source_sentence\"),\n",
    "            \"target_sentence\": sent.get(\"target_sentence\"),\n",
    "        }\n",
    "\n",
    "        for pair in sent.get(\"term_pairs\", []):\n",
    "            # merge the two dicts (Python 3.9+ “|” operator)\n",
    "            rows.append(base | pair)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # optional: remove exact duplicates\n",
    "    df = df.drop_duplicates(subset=[\"global_id\", \"sentence_id\", \"pair_id\"])\n",
    "\n",
    "    # nicer column names\n",
    "    df = df.rename(columns={\"en\": \"english\", \"tr\": \"turkish\"})\n",
    "\n",
    "    # re-order a bit (totally optional)\n",
    "    preferred = [\n",
    "        \"global_id\", \"sentence_id\", \"pair_id\",\n",
    "        \"english\", \"turkish\", \"correction\", \"link\",\n",
    "        \"en_start\", \"en_end\", \"tr_start\", \"tr_end\",\n",
    "        \"category\", \"data_source\", \"id\", \"wikipedia_id\",\n",
    "        \"yok_id\", \"source_sentence\", \"target_sentence\"\n",
    "    ]\n",
    "    df = df[[c for c in preferred if c in df.columns]]\n",
    "\n",
    "    return df\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "# Main script logic\n",
    "# --------------------------------------------------------------------------- #\n",
    "def main():\n",
    "    if not DATA_PATH.exists():\n",
    "        raise FileNotFoundError(f\"⚠️  {DATA_PATH.resolve()} not found.\")\n",
    "\n",
    "    data = load_json(DATA_PATH)\n",
    "    df   = flatten_term_pairs(data)\n",
    "\n",
    "    # write the xlsx\n",
    "    df.to_excel(OUT_CSV, index=False)\n",
    "\n",
    "\n",
    "    # show a quick peek so you can verify\n",
    "    with pd.option_context(\"display.max_columns\", None,\n",
    "                           \"display.width\", 120,\n",
    "                           \"display.max_rows\",   5):\n",
    "        print(\"\\nPreview:\")\n",
    "        print(df.head())\n",
    "        return df\n",
    "\n",
    "# --------------------------------------------------------------------------- #"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_m = main()",
   "id": "ecae6a8233ba0444",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_m",
   "id": "1d537e11616ab50",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
